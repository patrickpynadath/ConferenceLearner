"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"The difference learning of hidden layer between autoencoder and variational autoencoder","Q. Xu; Z. Wu; Y. Yang; L. Zhang","Electrical & Information Engineering, Shandong University, Weihai; Electrical & Information Engineering, Shandong University, Weihai; Electrical & Information Engineering, Shandong University, Weihai; Electrical & Information Engineering, Shandong University, Weihai","2017 29th Chinese Control And Decision Conference (CCDC)","17 Jul 2017","2017","","","4801","4804","Autoencoder is an excellent unsupervised learning algorithm. However, it can not generate kinds of sample data in the decoding process. Variational autoencoder is a typical generative adversarial net which can generate various data to augment the sample data. In this paper, we want to do some research about the information learning in hidden layer. In the simulation, we compare the hidden layer learning of hidden layer in conventional autoencoder and variational autoencoder.","1948-9447","978-1-5090-4657-7","10.1109/CCDC.2017.7979344","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7979344","Autoencoder;Variational autoencoder;Hidden layer learning;Probabilistic model;MNIST","Probabilistic logic;Unsupervised learning;Conferences;Clustering algorithms;Data models;Encoding;Image reconstruction","decoding;image coding;probability;unsupervised learning;variational techniques","difference learning;variational autoencoder;unsupervised learning algorithm;decoding process;generative adversarial net;information learning;hidden layer learning","","6","","5","","17 Jul 2017","","","IEEE","IEEE Conferences"
"Dynamical Variational Autoencoders: A Comprehensive Review","L. Girin; S. Leglaive; X. Bie; J. Diard; T. Hueber; X. Alameda-Pineda",NA; NA; NA; NA; NA; NA,"Dynamical Variational Autoencoders: A Comprehensive Review","","2021","","","","","Variational autoencoders (VAEs) are powerful deep generative models widely used to represent high-dimensional complex data through a low-dimensional latent space learned in an unsupervised manner. In this monograph the authors introduce and discuss a general class of models, called dynamical variational autoencoders (DVAEs), which extend VAEs to model temporal vector sequences. In doing so the authors provide: • a formal definition of the general class of DVAEs • a detailed and complete technical description of seven DVAE models • a rapid overview of other DVAE models presented in the recent literature • discussion of the recent developments in DVAEs in relation to the history and technical background of the classical models DVAEs are built on • a quantitative benchmark of the selected DVAE models • a discussion to put the DVAE class of models into perspective This monograph is a comprehensive review of the current state-of-the-art in DVAEs. It gives the reader an accessible summary of the technical aspects of the different DVAE models, their connections with classical models, their cross-connections, and their unification in the DVAE class in a concise, easy-to-read book. The authors have put considerable effort into unifying the terminology and notation used across the various models which all students, researchers and practitioners working in machine learning will find an invaluable resource.","","9781680839135","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9638605.pdf&bkn=9638604&pdfType=book","","","","","","","","","","7 Dec 2021","","","now","Now Foundations and Trends Books"
"Unsupervised Anomaly detection of LM Guide Using Variational Autoencoder","M. S. Kim; J. P. Yun; S. Lee; P. Park","Pohang University of Science and Technology, Pohang, Gyeongsangbuk-do, KR; Korea Institute of Industrial Technology, Cheonan, KR; Korea Institute of Industrial Technology, Cheonan, KR; Pohang University of Science and Technology, Pohang, Gyeongsangbuk-do, KR","2019 11th International Symposium on Advanced Topics in Electrical Engineering (ATEE)","30 May 2019","2019","","","1","5","Linear Motion (LM) is a linear motion guide that helps directional moving of machine. It is important to judge the anomaly state of LM guides because LM guides are used in various industries to support various task in industry application. In this paper, we proposed a machine learning algorithm for determining the anomaly state of LM guide. Considering that it is difficult to actually generate the anomaly signal, we trained model with only healthy state data. One of the generative models, variational autoencoder, is used for training healthy state data and the distribution of healthy state data is trained. Our trained model determines whether or not anomaly state has occurred based on a reconstruction error of the trained network.","2159-3604","978-1-7281-0101-9","10.1109/ATEE.2019.8724998","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8724998","LM guide;Anomaly detection;Variational autoencoder","Image reconstruction;Data models;Spectrogram;Anomaly detection;Training;Machine learning algorithms;Hidden Markov models","learning (artificial intelligence);security of data;unsupervised learning;variational techniques","unsupervised anomaly detection;LM guide;variational autoencoder;linear motion guide;anomaly state;anomaly signal;trained model;machine learning algorithm;generative models;healthy state data;reconstruction error","","7","","12","","30 May 2019","","","IEEE","IEEE Conferences"
"Self-Organized Variational Autoencoders (Self-Vae) For Learned Image Compression","M. A. Yílmaz; O. Kelesş; H. Güven; A. M. Tekalp; J. Malik; S. Kíranyaz","Dept. of Electrical & Electronics Eng., Koç University, İstanbul, Turkey; Dept. of Electrical & Electronics Eng., Koç University, İstanbul, Turkey; Dept. of Electrical & Electronics Eng., Koç University, İstanbul, Turkey; Dept. of Electrical & Electronics Eng., Koç University, İstanbul, Turkey; Tampere University, Tampere, Finland; Qatar University, Doha, Qatar","2021 IEEE International Conference on Image Processing (ICIP)","23 Aug 2021","2021","","","3732","3736","In end-to-end optimized learned image compression, it is standard practice to use a convolutional variational autoencoder with generalized divisive normalization (GDN) to transform images into a latent space. Recently, Operational Neural Networks (ONNs) that learn the best non-linearity from a set of alternatives, and their “self-organized” variants, Self-ONNs, that approximate any non-linearity via Taylor series have been proposed to address the limitations of convolutional layers and a fixed nonlinear activation. In this paper, we propose to replace the convolutional and GDN layers in the variational autoencoder with self-organized operational layers, and propose a novel self-organized variational autoencoder (Self-VAE) architecture that benefits from stronger non-linearity. The experimental results demonstrate that the proposed Self-VAE yields improvements in both rate-distortion performance and perceptual image quality.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506041","end-to-end learned image compression;variational autoencoder;self-organized operational layer;rate-distortion performance;perceptual quality metrics","Convolutional codes;Measurement;Visualization;Image coding;Codecs;Neurons;Rate-distortion","data compression;image coding;learning (artificial intelligence);neural nets","self-organized operational layers;variational autoencoder architecture;nonlinearity;Self-VAE yields improvements;perceptual image quality;Self-organized variational autoencoders;end-to-end optimized learned image compression;standard practice;convolutional variational autoencoder;generalized divisive normalization;latent space;Operational Neural Networks;ONNs;convolutional layers;fixed nonlinear activation;convolutional GDN;rate-distortion performance","","","","26","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"SIFT Features for Deep and Variational Autoencoders: A Performance Comparison","F. Barreto; S. Yadav; S. Patnaik; J. Sarvaiya","Department of Electronics and Telecommunication, Xavier Institute of Engineering, Mumbai, India; Jio Platforms Limited, Mumbai, India; School of Electronics, Kalinga Institute of Industrial Technology, Bhubaneswar, India; Department of Electronics, Sardar Vallabhbhai National Institute of Technology, Surat, India","2020 2nd International Conference on Advances in Computing, Communication Control and Networking (ICACCCN)","1 Mar 2021","2020","","","652","655","Object detection tasks widely use the Scale Invariant Feature Transform (SIFT). SIFT key-points are extracted from model images of an object and are used to form descriptors. To achieve an object's existence from a query image, we find the candidate's matching features based on their feature vector's Euclidean distance. The goal is to maximize the SIFT features so that classification can be more accurate and reliable. In this work, we compare the encoding efficiency using the number of SIFT matches found in the images of Deep Autoencoder with that of Variational Autoencoder.","","978-1-7281-8337-4","10.1109/ICACCCN51052.2020.9362843","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9362843","Convolutional Autoencoder (CAE);Deep Autoencoder;Scale Invariant Feature Transform (SIFT);Variational Autoencoder (VAE)","Image coding;Transforms;Feature extraction;Reliability;Object tracking;Task analysis;Pattern matching","feature extraction;image matching;image retrieval;object detection;transforms","Scale Invariant Feature Transform;SIFT key-points;model images;query image;candidate;feature vector;SIFT features;Deep Autoencoder;Variational Autoencoder;object detection tasks","","1","","10","","1 Mar 2021","","","IEEE","IEEE Conferences"
"Weak Label Supervision for Monaural Source Separation Using Non-negative Denoising Variational Autoencoders","E. Karamatlı; A. T. Cemgil; S. Kırbız","Bogazici Universitesi, Istanbul, TR; Bogazici Universitesi, Istanbul, TR; MEF Üniversitesi, İstanbul, , Türkiye","2019 27th Signal Processing and Communications Applications Conference (SIU)","22 Aug 2019","2019","","","1","4","Deep learning models are very effective in source separation when there are large amounts of labeled data available. However it is not always possible to have carefully labeled datasets. In this paper, we propose a weak supervision method that only uses class information rather than source signals for learning to separate short utterance mixtures. We associate a variational autoencoder (VAE) with each class within a nonnegative model. We demonstrate that deep convolutional VAEs provide a prior model to identify complex signals in a sound mixture without having access to any source signal. We show that the separation results are on par with source signal supervision.","2165-0608","978-1-7281-1904-5","10.1109/SIU.2019.8806536","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8806536","weak supervision;source separation;variational autoencoders","NOMA;Dogs;Source separation;Noise reduction;Data models;Convolution;Art","learning (artificial intelligence);signal denoising;source separation","variational autoencoder;nonnegative model;deep convolutional VAEs;complex signals;sound mixture;source signal supervision;weak label supervision;monaural source separation;nonnegative denoising variational autoencoders;deep learning models;carefully labeled datasets;weak supervision method;short utterance mixtures;class information","","4","1","","","22 Aug 2019","","","IEEE","IEEE Conferences"
"A Disentangled Variational Autoencoder for Prediction of Above Ground Biomass from Hyperspectral Data","P. Naik; M. Dalponte; L. Bruzzone","Sustainable Agro-ecosystems and Bioresources Department, Fondazione Edmund Mach, Italy; Sustainable Agro-ecosystems and Bioresources Department, Fondazione Edmund Mach, Italy; Department of Information Engineering and Computer Science, University of Trento, Italy","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2991","2994","The prediction of forest biophysical parameters is an important task in remote sensing for understanding global carbon cycle. Spectral remote sensing data are available globally at a relatively economical cost making them a viable resource for forest remote sensing. However, the main drawbacks associated with such data is the uncertainty of predictions and cluttered process of selecting band combinations from hyperspectral/multispectral data to produce spectral features for modelling. In this paper, we present an approach that exploits the latest developments in generative variational autoencoders (VAE) that produce disentangled representation from input data to assess the capability of hyperspectral data to model forest aboveground biomass (AGB). The proposed VAE generates a special kind of deep spectral features that are proportional to AGB. A modelling accuracy of R2 = 0.57 (cross-validated) was obtained by the proposed approach, thus pointing out the potential of hyperspectral data to model AGB using disentangled deep spectral features. The proposed approach also enables in bypassing the unreliable process of selecting band combinations to produce spectral features and shows good prospects for mapping global level biomass.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554415","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554415","variational autoencoders;disentangled representation;hyperspectral data;deep features;AGB","Uncertainty;Costs;Biological system modeling;Forestry;Predictive models;Data models;Biomass","forestry;geophysical image processing;remote sensing;vegetation;vegetation mapping","forest biophysical parameters;global carbon cycle;spectral remote sensing data;relatively economical cost;forest remote sensing;band combinations;generative variational autoencoders;disentangled representation;hyperspectral data;forest aboveground biomass;AGB;disentangled deep spectral features;global level biomass;disentangled variational autoencoder;ground biomass","","1","","23","","12 Oct 2021","","","IEEE","IEEE Conferences"
"Ship Detection in SAR Images Using Convolutional Variational Autoencoders","N. Ferreira; M. Silveira","Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal; Institute for Systems and Robotics, Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","2503","2506","We propose an unsupervised framework for ship detection in SAR image data, based on anomaly detection. We first learn representations of the SAR images with a convolutional Variational Autoencoder. Aftwerwards, we perform anomaly detection based on those representations, with a clustering algorithm. Experimental results with real SAR data are provided to illustrate the performance of the proposed algorithm.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9324389","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9324389","Variational autoencoders;unsupervised learning;ship detection;synthetic aperture radar","Marine vehicles;Training;Radar polarimetry;Data models;Synthetic aperture radar;Image reconstruction;Decoding","learning (artificial intelligence);pattern clustering;radar imaging;ships;synthetic aperture radar","SAR images;convolutional Variational Autoencoder;anomaly detection;SAR data;ship detection;convolutional variational autoencoders;unsupervised framework;SAR image data","","1","","17","","17 Feb 2021","","","IEEE","IEEE Conferences"
"Different latent variables learning in variational autoencoder","Q. Xu; Y. Yang; Z. Wu; L. Zhang","Shandong University, Jinan, Shandong, CN; Shandong University, Jinan, Shandong, CN; Shandong University, Jinan, Shandong, CN; Shandong University, Jinan, Shandong, CN","2017 4th International Conference on Information, Cybernetics and Computational Social Systems (ICCSS)","2 Nov 2017","2017","","","508","511","Unsupervised learning is a good neural network training way. However, the unsupervised learning algorithm is rare. The generative model is an interesting algorithm which can generate the similar data as the sample data by building a probabilistic model of the input data, and it can be used for unsupervised learning. Variational autoencoder is a typical generative model which is different from common autoencoder that a probabilistic parameter layer follows the hidden layer. Some new data can be reconstructed according to probabilistic model parameters. The probabilistic model parameter is the latent variable. In this paper, we want to do some research to test the data reconstruct effect of the variational autoencoder by different latent variables. According to the simulation, the more latent variables the more style of the sample is.","","978-1-5386-3257-4","10.1109/ICCSS.2017.8091468","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8091468","variational autoencoder;probabilistic model;latent Variable;MNIST","Probabilistic logic;Neurons;Image reconstruction;Training;Data models;Writing;Cybernetics","learning (artificial intelligence);neural nets;pattern classification;probability;unsupervised learning","hidden layer;probabilistic model parameter;variational autoencoder;unsupervised learning algorithm;sample data;input data;probabilistic parameter layer;neural network training","","1","","6","","2 Nov 2017","","","IEEE","IEEE Conferences"
"Deep Clustering Analysis via Dual Variational Autoencoder With Spherical Latent Embeddings","L. Yang; W. Fan; N. Bouguila","Department of Computer Science and Technology, Huaqiao University, Xiamen 361021, China.; Department of Computer Science and Technology, Huaqiao University, Xiamen 361021, China (e-mail: wentao.fan@hqu.edu.cn); Concordia Institute for Information Systems Engineering (CIISE), Concordia University, Montreal, QC H3G 1T7, Canada.","IEEE Transactions on Neural Networks and Learning Systems","","2021","PP","99","1","10","In recent years, clustering methods based on deep generative models have received great attention in various unsupervised applications, due to their capabilities for learning promising latent embeddings from original data. This article proposes a novel clustering method based on variational autoencoder (VAE) with spherical latent embeddings. The merits of our clustering method can be summarized as follows. First, instead of considering the Gaussian mixture model (GMM) as the prior over latent space as in a variety of existing VAE-based deep clustering methods, the von Mises-Fisher mixture model prior is deployed in our method, leading to spherical latent embeddings that can explicitly control the balance between the capacity of decoder and the utilization of latent embedding in a principled way. Second, a dual VAE structure is leveraged to impose the reconstruction constraint for the latent embedding and its corresponding noise counterpart, which embeds the input data into a hyperspherical latent space for clustering. Third, an augmented loss function is proposed to enhance the robustness of our model, which results in a self-supervised manner through the mutual guidance between the original data and the augmented ones. The effectiveness of the proposed deep generative clustering method is validated through comparisons with state-of-the-art deep clustering methods on benchmark datasets. The source code of the proposed model is available at https://github.com/fwt-team/DSVAE.","2162-2388","","10.1109/TNNLS.2021.3135460","National Natural Science Foundation of China(grant numbers:61876068); Open Research Projects of Zhejiang Laboratory(grant numbers:2021KH0AB01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9662055","Clustering;data augmentation;dual variational autoencoder;mixture models;variational autoencoder (VAE);variational inference;von Mises-Fisher mixture model","Clustering methods;Training;Data models;Mixture models;Data mining;Probabilistic logic;Neural networks","","","","","","","IEEE","23 Dec 2021","","","IEEE","IEEE Early Access Articles"
"Predictive Vector Quantized Variational AutoEncoder for Spectral Envelope Quantization","T. Srikotr; K. Mano","Division of Functional Control System, Graduate School of Engineering and Science, Shibaura Institute of Technology, Japan; Division of Functional Control System, Graduate School of Engineering and Science, Shibaura Institute of Technology, Japan","2020 International Conference on Electronics, Information, and Communication (ICEIC)","2 Apr 2020","2020","","","1","4","The Predictive Vector Quantized Variational AutoEncoder is proposed to improve the reconstruction error of the conventional VQ-VAE. The proposed model can predict the current data from the previous data. The performance of the quantized spectral envelope parameters of the high-quality 48 kHz WORLD vocoder is evaluated. The results indicate that the Predictive Vector Quantized Variational AutoEncoder has a lower distortion with four target bitrates in term of log-spectral distortion, compared with the conventional VQ-VAE.","","978-1-7281-6289-8","10.1109/ICEIC49074.2020.9051233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9051233","predictive vector quantization;spectral envelope;vector quantized variational autoencoder;WORLD vocoder","Vocoders;Vector quantization;Bit rate;Predictive models;Distortion;Data models","audio coding;distortion;spectral analysis;vector quantisation;vocoders","VQ-VAE;spectral envelope quantization;quantized spectral envelope parameters;predictive vector quantized variational autoencoder;reconstruction error;WORLD vocoder;log-spectral distortion;frequency 48.0 kHz","","1","","12","","2 Apr 2020","","","IEEE","IEEE Conferences"
"A method for generating power data samples based on variational autoencoders","J. Sun; C. Hu; Q. Sun; P. Wang; C. Zhang; R. Lu","Information and Communication Branch of State Grid Anhui Electric Power Co., Ltd., Hefei, China; Information and Communication Branch of State Grid Anhui Electric Power Co., Ltd., Hefei, China; Information and Communication Branch of State Grid Anhui Electric Power Co., Ltd., Hefei, China; Information and Communication Branch of State Grid Anhui Electric Power Co., Ltd., Hefei, China; Information and Communication Branch of State Grid Anhui Electric Power Co., Ltd., Hefei, China; Information and Communication Branch of State Grid Anhui Electric Power Co., Ltd., Hefei, China","2022 IEEE 10th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)","3 Aug 2022","2022","10","","1743","1747","The gradual application of artificial intelligence has a significant impact on the production efficiency and technological change of the industry. Due to the difficulty of sample collection, high cost, and personal privacy, traditional industries face the problems of small samples and unbalanced data when conducting deep learning. Existing There is a problem that the generation effect cannot take into account the generality and rationality of the sample expansion method of. Therefore, a sample expansion algorithm based on the semantic extraction of the latent variable of the variational autoencoder is proposed, and the weight of the neural network is used as the input feature and the latent variable. Correlation measurement, obtain the dependency between input features and variational autoencoder latent variables, provide an important basis for assigning semantics to latent variables, realize explicit control of different dimensions of latent variables, and generate data that satisfies the overall distribution and is not included in the original training set. Samples. The results of sample expansion of the power grid database show that this method can effectively generate samples of specific attributes, and can solve the problem of small samples and unbalanced data to a certain extent.","2693-2865","978-1-6654-2207-9","10.1109/ITAIC54216.2022.9836739","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9836739","variational autoencoder;semantic refinement;virtual sample generation;small sample data;imbalanced data","Training;Industries;Weight measurement;Semantics;Refining;Production;Feature extraction","data handling;learning (artificial intelligence);neural nets;power engineering computing","power data samples;artificial intelligence;production efficiency;personal privacy;deep learning;sample expansion method;sample expansion algorithm;semantic extraction;latent variable;power grid database;variational autoencoder;correlation measurement","","","","17","IEEE","3 Aug 2022","","","IEEE","IEEE Conferences"
"A Conditional Variational Autoencoder Algorithm for Reconstructing Defect Data of Magnetic Flux Leakage","S. Lu; J. Wu; J. Zhang","School of Information Science and Engineering, Northeastern University, Shenyang, P. R. China; Liaoning Provincial Institute of Measurement, Shenyang, P. R. China; School of Information Science and Engineering, Northeastern University, Shenyang, P. R. China","2020 Chinese Control And Decision Conference (CCDC)","11 Aug 2020","2020","","","1246","1250","Magnetic flux leakage (MFL) testing is widely used in pipeline nondestructive testing. The acquisition quality of MFL signal is an important prerequisite for the accuracy of pipeline detection and evaluation. However, data loss often occurs in the process of detection, due to the interference of external environmental factors. Therefore, it is important to reconstruct the missing data. This paper analyzes four types of MFL data loss, and presents a conditional variational autoencoder algorithm to reconstruct defect data of MFL for these types of loss. The algorithm effectiveness is tested by comparing with traditional variational autoencoder method. The results demonstrate that the proposed method can improve the accuracy of reconstructing defect data loss.","1948-9447","978-1-7281-5855-6","10.1109/CCDC49329.2020.9164107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9164107","Magnetic Flux Leakage;Data Loss;Conditional Variational Autoencoder;Defect Data Reconstructing","Magnetic flux leakage;Pipelines;Decoding;Data models;Robot sensing systems;Image reconstruction;Voltage measurement","magnetic flux;magnetic leakage;nondestructive testing;pipelines","MFL data loss;conditional variational autoencoder algorithm;algorithm effectiveness;defect data loss;magnetic flux leakage testing;pipeline nondestructive testing;acquisition quality;MFL signal;pipeline detection;external environmental factors;missing data","","","","15","","11 Aug 2020","","","IEEE","IEEE Conferences"
"Variational Autoencoder based Latent Factor Decoding of Multichannel EEG for Emotion Recognition","X. Li; Z. Zhao; D. Song; Y. Zhang; C. Niu; J. Zhang; J. Huo; J. Li","Key Laboratory of Medical Artificial Intelligence, Shandong Computer Science Center, National Supercomputer Center in Jinan, Qilu University of Technology, Shandong Academy of Sciences, China; Key Laboratory of Medical Artificial Intelligence, Shandong Computer Science Center, National Supercomputer Center in Jinan, Qilu University of Technology, Shandong Academy of Sciences, China; School of Computer Science and Technology, Beijing Institute of Technology, China; Software Engineering College, Zhengzhou University of Light Industry, China; Key Laboratory of Medical Artificial Intelligence, Shandong Computer Science Center, National Supercomputer Center in Jinan, Qilu University of Technology, Shandong Academy of Sciences, China; School of Computer Science and Technology, Tianjin University, China; Key Laboratory of Medical Artificial Intelligence, Shandong Computer Science Center, National Supercomputer Center in Jinan, Qilu University of Technology, Shandong Academy of Sciences, China; Jiuquan Satellite Launch Center, China","2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","6 Feb 2020","2019","","","684","687","Robust cross-subject emotion recognition based on multichannel EEG has always been a hard work. In this work, we hypothesize there exists default brain variables across subjects in emotional processes. Hence, the states of the latent variables that related to emotional processing must contribute to building robust recognition models. We propose to utilize variational autoencoder (VAE) to determine the latent factors from the multichannel EEG. Through sequence modeling method, we examine the emotion recognition performance based on the learnt latent factors. The performance of the proposed methodology is verified on two public datasets (DEAP and SEED), and compared with traditional matrix factorization based (ICA) and autoencoder based (AE) approaches. Experimental results demonstrate that neural network is suitable for unsupervised EEG modeling and our proposed emotion recognition framework achieves the state-of-the-art performance. As far as we know, it is the first work that introduces VAE into multichannel EEG decoding for emotion recognition.","","978-1-7281-1867-3","10.1109/BIBM47256.2019.8983341","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8983341","Affective Computing;Latent Factor Decoding;Emotion Recognition;EEG;Variational Autoencoder","","electroencephalography;emotion recognition;feature extraction;medical signal processing;neural nets","variational autoencoder;multichannel EEG;emotional processing;emotion recognition;unsupervised EEG modeling;emotion recognition framework;latent factor decoding;neural network","","3","","9","","6 Feb 2020","","","IEEE","IEEE Conferences"
"Unsupervised Anomaly Video Detection via a Double-Flow ConvLSTM Variational Autoencoder","L. Wang; H. Tan; F. Zhou; W. Zuo; P. Sun","School of Instrumentation Science and Opto-Electronics Engineering, Beihang University, Beijing, China; Ji Hua Laboratory, Foshan, China; School of Instrumentation Science and Opto-Electronics Engineering, Beihang University, Beijing, China; School of Electrical Engineering, University of South China, Hengyang, China; School of Instrumentation Science and Opto-Electronics Engineering, Beihang University, Beijing, China","IEEE Access","2 May 2022","2022","10","","44278","44289","With the rapid increase of video surveillance points in the market in recent years, video anomaly detection has gained extensive attention in the security field. At present, the distribution of normal and anomalous data is unbalanced in unlabeled video data. Variational autoencoder (VAE), as one of the typical deep generative models, gets increasingly popular in unsupervised anomaly detection. However, this model is not good at processing time-series data, especially video data. In addition, the strong generalization ability which is over-reconstructing anomaly behavior of many autoencoder-based works leads to the missed anomaly detection. To solve these problems, in this paper, we present a double-flow convolutional long short-term memory variational autoencoder (DF-ConvLSTM-VAE) to model the probabilistic distribution of the normal video in an unsupervised learning scheme, and to reconstruct videos without anomaly objects for anomaly video detection. Experiments verify the effectiveness and competitiveness of our DF-ConvLSTM-VAE on multiple public benchmark datasets. In particular, our model achieves the state-of-the-art performance on anomalous event count.","2169-3536","","10.1109/ACCESS.2022.3165977","Ji Hua Laboratory of Guangdong Province, China(grant numbers:X200051UZ200); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9758677","Autoencoder;variational autoencoder;LSTM;ConvLSTM;anomaly detection","Image reconstruction;Anomaly detection;Data models;Feature extraction;Mathematical models;Unsupervised learning;Task analysis","convolutional neural nets;data handling;deep learning (artificial intelligence);statistical distributions;unsupervised learning;video signal processing;video surveillance","normal video;unsupervised learning;anomaly objects;DF-ConvLSTM-VAE;unsupervised anomaly video detection;double-flow ConvLSTM variational autoencoder;video surveillance;video anomaly detection;security field;normal data;anomalous data;unlabeled video data;unsupervised anomaly detection;time-series data processing;generalization ability;anomaly behavior;short-term memory variational autoencoder;probabilistic distribution;deep generative models;double-flow convolutional long short-term memory variational autoencoder","","","","48","CCBY","15 Apr 2022","","","IEEE","IEEE Journals"
"Unsupervised Speech Enhancement Using Dynamical Variational Autoencoders","X. Bie; S. Leglaive; X. Alameda-Pineda; L. Girin","Inria Grenoble Rhône-Alpes, Université Grenoble Alpes, Grenoble, France; CentraleSupélec, IETR (UMR CNRS 6164), Cesson-Sevigne, France; Inria Grenoble Rhône-Alpes, Université Grenoble Alpes, Grenoble, France; Univ. Grenoble Alpes, Grenoble-INP, CNRS, GIPSA-lab, Grenoble, France","IEEE/ACM Transactions on Audio, Speech, and Language Processing","28 Sep 2022","2022","30","","2993","3007","Dynamical variational autoencoders (DVAEs) are a class of deep generative models with latent variables, dedicated to model time series of high-dimensional data. DVAEs can be considered as extensions of the variational autoencoder (VAE) that include temporal dependencies between successive observed and/or latent vectors. Previous work has shown the interest of using DVAEs over the VAE for speech spectrograms modeling. Independently, the VAE has been successfully applied to speech enhancement in noise, in an unsupervised noise-agnostic set-up that requires neither noise samples nor noisy speech samples at training time, but only requires clean speech signals. In this paper, we extend these works to DVAE-based single-channel unsupervised speech enhancement, hence exploiting both speech signals unsupervised representation learning and dynamics modeling. We propose an unsupervised speech enhancement algorithm that combines a DVAE speech prior pre-trained on clean speech signals with a noise model based on nonnegative matrix factorization, and we derive a variational expectation-maximization (VEM) algorithm to perform speech enhancement. The algorithm is presented with the most general DVAE formulation and is then applied with three specific DVAE models to illustrate the versatility of the framework. Experimental results show that the proposed DVAE-based approach outperforms its VAE-based counterpart, as well as several supervised and unsupervised noise-dependent baselines, especially when the noise type is unseen during training.","2329-9304","","10.1109/TASLP.2022.3207349","ANR-3IA MIAI(grant numbers:ANR-19-P3IA-0003); ANR-JCJC ML3RI(grant numbers:ANR-19-CE33-0008-01); EC(grant numbers:GA #871245); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9894060","Speech enhancement;dynamical variational autoencoders;nonnegative matrix factorization;variational inference","Speech enhancement;Noise measurement;Training;Recording;Inference algorithms;Time-domain analysis;Time series analysis","expectation-maximisation algorithm;matrix decomposition;parameter estimation;speech enhancement;time series;unsupervised learning;vectors","speech spectrograms;unsupervised noise-agnostic set-up;noise samples;noisy speech samples;training time;clean speech signals;single-channel unsupervised speech enhancement;speech signals unsupervised representation learning;unsupervised speech enhancement algorithm;DVAE speech;noise model;variational expectation-maximization;general DVAE formulation;specific DVAE models;DVAE-based approach;VAE-based counterpart;supervised noise-dependent baselines;unsupervised noise-dependent baselines;noise type;dynamical variational autoencoders;deep generative models;latent variables;time series;high-dimensional data;variational autoencoder;successive observed vectors;latent vectors;VEM;variational expectation-maximization algorithm","","","","79","IEEE","16 Sep 2022","","","IEEE","IEEE Journals"
"Laughter synthesis: A comparison between Variational autoencoder and Autoencoder","N. Mansouri; Z. Lachiri","Signal, Image and Information Technology Research Laboratory LR-SITI National Engineering School of Tunis ENIT, Tunis El Manar University, Tunis, Tunisia; Signal, Image and Information Technology Research Laboratory LR-SITI National Engineering School of Tunis ENIT, Tunis El Manar University, Tunis, Tunisia","2020 5th International Conference on Advanced Technologies for Signal and Image Processing (ATSIP)","20 Oct 2020","2020","","","1","6","Laughter is one of the most famous non verbal sounds that human produce since birth, it conveys messages about our emotional state. These characteristics make it an important sound that should be studied in order to improve the human-machine interactions. In this paper we investigate the audio laughter generation process from its acoustic features. This suggested process is considered as an analysis-transformation synthesis benchmark based on unsupervised dimensionality reduction techniques: The standard autoencoder (AE) and the variational autoencoder (VAE). Therefore, the laughter synthesis methodology consists of transforming the extracted high-dimensional log magnitude spectrogram into a low-dimensional latent vector. This latent vector contains the most valuable information used to reconstruct a synthetic magnitude spectrogram that will be passed through a specific vocoder to generate the laughter waveform. We systematically, exploit the VAE to create new sound (speech-laugh) based on the interpolation process. To evaluate the performance of these models two evaluation metrics were conducted: objective and subjective evaluations.","2687-878X","978-1-7281-7513-3","10.1109/ATSIP49331.2020.9231607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9231607","Laughter;audio generation;variational autoencoder;autoencoder;interpolation;objective and subjective evaluation","Mathematical model;Hidden Markov models;Databases;Computer architecture;Spectrogram;Decoding;Neural networks","acoustic signal processing;feature extraction;interpolation;vocoders","variational autoencoder;emotional state;human-machine interactions;audio laughter generation process;acoustic features;analysis-transformation synthesis benchmark;unsupervised dimensionality reduction techniques;standard autoencoder;VAE;laughter synthesis methodology;high-dimensional log magnitude spectrogram;low-dimensional latent vector;synthetic magnitude spectrogram;laughter waveform;interpolation process","","","","17","","20 Oct 2020","","","IEEE","IEEE Conferences"
"Exploring DNA Methylation Data of Lung Cancer Samples with Variational Autoencoders","Z. Wang; Y. Wang","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China","2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","24 Jan 2019","2018","","","1286","1289","Lung cancer causes over one million deaths each year worldwide. DNA methylation is a well-defined epigenetics factor in genome data analyses for model training. In this article, we explore the applications of unsupervised deep learning method, variational autoencoders, using DNA methylation data of lung cancer samples downloaded from the GDC TCGA project and perform further work with latent features. We show the logistic regression classifier on the encoded latent features accurately classifies cancer subtypes.","","978-1-5386-5488-0","10.1109/BIBM.2018.8621365","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8621365","DNA methylation;lung cancer;variational autoencoder","Cancer;DNA;Lung;Tumors;Bioinformatics;Heating systems;Deep learning","biology computing;cancer;DNA;genetics;genomics;learning (artificial intelligence);lung;molecular biophysics;pattern classification;regression analysis;unsupervised learning","lung cancer samples;cancer subtypes;DNA methylation data;variational autoencoders;epigenetics factor;genome data analyses;unsupervised deep learning method;GDC TCGA project;latent features;logistic regression classifier","","10","","19","","24 Jan 2019","","","IEEE","IEEE Conferences"
"Observation of Human Response to a Robotic Guide Using a Variational Autoencoder","H. -S. Moon; J. Seo","School of Integrated Technology Y onsei University, Incheon, Korea; School of Integrated Technology Y onsei University, Incheon, Korea","2019 Third IEEE International Conference on Robotic Computing (IRC)","28 Mar 2019","2019","","","258","261","This paper proposes a robotic-guide system equipped with a haptic device that can deliver kinesthetic feedback to and receive kinesthetic reaction from a follower. In addition, a feature-extraction method from a depth image of a user following the robotic guide based on a variational autoencoder (VAE) model is presented. One of the major roles of a sensory assistive robot is to help visually impaired people to walk through unknown spaces while avoiding obstacles. Haptic sensory information can be used as a directional cue for these people in recognizing the correct direction. We focus on how people react to haptic guidance from the assistive robot because an accurate prediction for human response enables robots to perform a more active role in not interfering with the human movement. In an indoor experiment, we observed the user reaction following our robotic guide in terms of the kinesthetic force that the user received and the depth image taken from the robot. Using the VAE model, the latent variable well represented the feature of the depth image, e.g., brief position information of a user torso. Furthermore, we tracked the precise trajectory of both the user and robotic guide using a motion-capture system.","","978-1-5386-9245-5","10.1109/IRC.2019.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8675594","assistive robot;human-robot interaction;haptic interface;variational autoencoder","Haptic interfaces;Force;Trajectory;Cameras;Robot vision systems","collision avoidance;feature extraction;force feedback;handicapped aids;haptic interfaces;image coding;robot vision","human response;robotic-guide system;kinesthetic reaction;depth image;variational autoencoder model;sensory assistive robot;haptic sensory information;indoor experiment;motion-capture system;feature-extraction method;visually impaired people","","7","","16","","28 Mar 2019","","","IEEE","IEEE Conferences"
"Deep Variational Autoencoder for Modeling Functional Brain Networks and ADHD Identification","N. Qiang; Q. Dong; Y. Sun; B. Ge; T. Liu","School of Physics and Information Technology, Shaanxi Normal University, Xi'an, China; Department of Computer Science, University of Georgia, GA, USA; School of Physics and Information Technology, Shaanxi Normal University, Xi'an, China; School of Physics and Information Technology, Shaanxi Normal University, Xi'an, China; Department of Computer Science, University of Georgia, GA, USA","2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)","22 May 2020","2020","","","554","557","In the neuroimaging and brain mapping communities, researchers have proposed a variety of computational methods and tools to learn functional brain networks (FBNs). Recently, it has already been proven that deep learning can be applied on fMRI data with superb representation power over traditional machine learning methods. Limited by the high-dimension of fMRI volumes, deep learning suffers from the lack of data and overfitting. Generative models are known to have intrinsic ability of modeling small dataset and a Deep Variational Autoencoder (DVAE) is proposed in this work to tackle the challenge of insufficient data and incomplete supervision. The FBNs learned from fMRI were examined to be interpretable and meaningful and it was proven that DVAE has better performance on neuroimaging dataset over traditional models. With an evaluation on ADHD-200 dataset, DVAE performed excellent on classification accuracies on 4 sites.","1945-8452","978-1-5386-9330-8","10.1109/ISBI45749.2020.9098480","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9098480","Resting-state fMRI;Variational Autoencoder;ADHD;Deep Learning;Generative Learning","Functional magnetic resonance imaging;Data models;Feature extraction;Brain modeling;Machine learning;Pipelines;Decoding","biomedical MRI;brain;learning (artificial intelligence);medical disorders;medical image processing;neurophysiology","generative models;deep learning suffers;fMRI volumes;high-dimension;traditional machine learning methods;superb representation power;fMRI data;FBNs;computational methods;brain mapping communities;ADHD identification;modeling functional brain networks;Deep Variational Autoencoder;ADHD-200 dataset;neuroimaging dataset;DVAE","","3","","10","","22 May 2020","","","IEEE","IEEE Conferences"
"A Novel Variational Autoencoder based Radar Signal Reconstruction Algorithm Using Polluted Data","Z. Jing; B. Wu; P. Li; R. Yang; J. Li; Z. Wang","Key Laboratory of Electronic Information Countermeasure and Simulation Technology Ministry of Education, School of Electronic Engineering, Xidian University, Xi'an, Shaanxi Province, China; Key Laboratory of Electronic Information Countermeasure and Simulation Technology Ministry of Education, School of Electronic Engineering, Xidian University, Xi'an, Shaanxi Province, China; Key Laboratory of Electronic Information Countermeasure and Simulation Technology Ministry of Education, School of Electronic Engineering, Xidian University, Xi'an, Shaanxi Province, China; Key Laboratory of Electronic Information Countermeasure and Simulation Technology Ministry of Education, School of Electronic Engineering, Xidian University, Xi'an, Shaanxi Province, China; Key Laboratory of Electronic Information Countermeasure and Simulation Technology Ministry of Education, School of Electronic Engineering, Xidian University, Xi'an, Shaanxi Province, China; Key Laboratory of Electronic Information Countermeasure and Simulation Technology Ministry of Education, School of Electronic Engineering, Xidian University, Xi'an, Shaanxi Province, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","2715","2718","In the transmission process, radar signal could be polluted easily, and the radar individual recognition process will be undermined by the polluted data. Some existing algorithms so far use the image denoising method to deal with this issue while ignoring the essential characteristics of the signal, and thus the noise reduction effect is poor. To address this issue, a novel variational autoencoder based radar signal reconstruction algorithm is proposed in this paper to reconstruct high quality data from the polluted ones by compressing the one-dimensional polluted signal and learning the essential characteristics. The experiments prove that the algorithm indeed improves the quality of the reconstructed data compared with the polluted signal.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323729","Radar individual recognization;Deep Neural Network;Variational autoencoder;Noise reduction","Signal to noise ratio;Radar;Training;Image reconstruction;Signal reconstruction;Radar countermeasures;Radar imaging","image denoising;image reconstruction;radar signal processing;signal denoising;signal reconstruction","reconstructed data;polluted data;transmission process;radar individual recognition process;image denoising method;essential characteristics;noise reduction effect;novel variational autoencoder based radar signal reconstruction algorithm;polluted ones;one-dimensional polluted signal","","2","","6","","17 Feb 2021","","","IEEE","IEEE Conferences"
"Feature Dimensionality Reduction with Variational Autoencoders in Deep Bayesian Active Learning","P. E. Çöl; Ş. Ertekin","Bilgisayar Mühendisliği Bölümü, Orta Doğu Teknik Üniversitesi, Ankara, Türkiye; Bilgisayar Mühendisliği Bölümü, Orta Doğu Teknik Üniversitesi, Ankara, Türkiye","2021 29th Signal Processing and Communications Applications Conference (SIU)","19 Jul 2021","2021","","","1","4","Data annotation for training of supervised learning algorithms has been a very costly procedure. The aim of deep active learning methodologies is to acquire the highest performance in supervised deep learning models by annotating as few data points as possible. As the feature space of data grows, the application of linear models in active learning settings has become insufficient. Therefore, Deep Bayesian Active Learning methodology which represents model uncertainty has been widely studied. In this paper, a study has been conducted in order to increase the performance of Deep Bayesian Active Learning method. Feature dimensionality reduction is performed on data set by using Variational Autoencoder model. Low dimensional data is used to train a Bayesian Multi Layer Perceptron. The proposed method outperformed the Bayesian Multi Layer Perceptron model which is trained on entire feature space in terms of accuracy performance. The accuracy of the proposed method is tested on baseline datasets.","2165-0608","978-1-6654-3649-6","10.1109/SIU53274.2021.9477979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9477979","Deep Active Learning;Variational Autoencoder;Bayesian Neural Networks;Feature Learning","Bayes methods;Dimensionality reduction;Uncertainty;Training;Supervised learning;Signal processing;Neural networks","Bayes methods;data reduction;deep learning (artificial intelligence);multilayer perceptrons;supervised learning","Bayesian multilayer perceptron;feature dimensionality reduction;data annotation;supervised deep learning;deep Bayesian active learning;model uncertainty;variational autoencoders","","","","","IEEE","19 Jul 2021","","","IEEE","IEEE Conferences"
"Controlling Weather Field Synthesis Using Variational Autoencoders","D. A. B. Oliveira; J. G. Diaz; B. Zadrozny; C. D. Watson; X. X. Zhu","IBM Research, Brazil; IBM Research, Brazil; IBM Research, Brazil; IBM Research, Brazil; Technical University of Munich, Germany","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","5027","5030","One of the consequences of climate change is an observed increase in the frequency of extreme climate events. That poses a challenge for weather forecast and generation algorithms, which learn from historical data but should embed an often uncertain bias to create correct scenarios. This paper investigates how mapping climate data to a known distribution using variational autoencoders might help explore such biases and control the synthesis of weather fields towards scenarios with more frequent extreme weather events. We experimented using a monsoon-affected precipitation dataset from southwest India, which should give a roughly stable pattern of rainy days and ease investigating the suitability of our solution. We report compelling results showing that mapping complex weather data to a known distribution implements an efficient control for weather field synthesis towards more (or less) extreme scenarios.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884668","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884668","Variational Autoencoders;Weather Generators;Extreme Climate Events;Weather Data Synthesis","Climate change;Weather forecasting;Geoscience and remote sensing;Generators;Data models;Meteorology","atmospheric precipitation;climatology;weather forecasting","controlling weather field synthesis;variational autoencoders;climate change;observed increase;extreme climate events;weather forecast;generation algorithms;historical data;uncertain bias;correct scenarios;mapping climate data;known distribution;weather fields;frequent extreme weather events;monsoon-affected precipitation dataset;roughly stable pattern;mapping complex weather data;extreme scenarios","","","","8","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Facial Image Inpainting with Variational Autoencoder","C. -T. Tu; Y. -F. Chen","Department of Applied Mathematics, National Chung Hsing University, Taichung City, Taiwan; Dept. of Computer Science and Information Engineering, Tamkang University, New Taipei City, Taiwan","2019 2nd International Conference of Intelligent Robotic and Control Engineering (IRCE)","4 Jun 2020","2019","","","119","122","This paper proposed a learning-based approach to reveal diversity possible appearances under the missing area of an occluded unseen image. In general, there are a lot of possible facial appearances for the missing area; for example, a male with a scarf, it is difficult to predict he has a beard in the covered area or not? In this paper, we propose a novel method for facial image inpainting, which generates the missing facial appearance by conditioning on the observable appearance. Given a trained standard Variational Autoencoder (VAE) for un-occluded face generation. To be specified, we search for the possible set of VAE coding vector for the current occluded input image, and the predicted coding should be robust to the missing area. The possible facial appearance set is then recovered through the decoder of VAE model. Experiments show that our method successfully predicts recovered results in large missing regions; these results are diverse, and all are reasonable to be consistent with the observable facial area, i.e., both the facial geometry and the personal characteristics are preserved.","","978-1-7281-4192-3","10.1109/IRCE.2019.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9107633","image inpainting;variational autoencoder;sampling","","face recognition;image restoration;learning (artificial intelligence);neural nets","trained standard variational autoencoder for un-occluded face generation;facial geometry;observable facial area;missing regions;possible facial appearance set;predicted coding;current occluded input image;VAE coding vector;possible set;observable appearance;missing facial appearance;covered area;occluded unseen image;missing area;diversity possible appearances;learning-based approach;facial image inpainting","","","","6","","4 Jun 2020","","","IEEE","IEEE Conferences"
"Designing Novel Functional Peptides by Manipulating a Temperature in the Softmax Function Coupled with Variational Autoencoder","S. Chen; H. U. Kim","Department of Chemical and Biomolecular Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Chemical and Biomolecular Engineering, KAIST Institute for Artificial Intelligence, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea","2019 IEEE International Conference on Big Data (Big Data)","24 Feb 2020","2019","","","6010","6012","Development of an efficient peptide design method is crucial for tackling medical problems, such as designing antimicrobial peptides for combating drug-resistant pathogens and anticancer peptides for various cancers. Here, we present Variational Autoencoder (VAE) coupled with a Softmax function having a temperature factor (T) for high-throughput design of novel functional peptides. VAE is a generative machine learning model, which has proved to be useful for generating peptide sequences. In this study, we additionally use a Softmax function with T to facilitate determining the most probable amino acids at each position of peptide sequences to be generated, which is difficult to achieve using a conventional VAE. In particular, by manipulating T in the Softmax function, we select biologically most feasible peptides with a desired function. This method is demonstrated for designing novel antimicrobial and anticancer peptides in this study. The method presented herein should be useful for designing various peptides with a desired function upon availability of relevant datasets.","","978-1-7281-0858-2","10.1109/BigData47090.2019.9006253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9006253","peptide design;Softmax function with a temperature factor;Variational Autoencoder","Peptides;Amino acids;Databases;Gold;Standards;Training;Biological system modeling","antibacterial activity;biochemistry;bioinformatics;cancer;cellular biophysics;drug delivery systems;drugs;learning (artificial intelligence);microorganisms;molecular biophysics;proteins","biologically most feasible peptides;peptide sequences;generative machine learning model;VAE;anticancer peptides;drug-resistant pathogens;antimicrobial peptides;efficient peptide design method;Variational Autoencoder;Softmax function;functional peptides","","","","10","","24 Feb 2020","","","IEEE","IEEE Conferences"
"Variational Autoencoder Based Approach for Imbalance Process Fault Detection","K. Wang","College of Art and Science, Boston University, Boston, US","2021 International Conference on Electronics, Circuits and Information Engineering (ECIE)","20 Apr 2021","2021","","","149","152","Process fault detection has drawn growing attention from various industrial sectors. Efficient detection of process faults can help to avoid abnormal event progression and reduce productivity loss. However, in the complex process system, there are uncontrollable factors or variables which are not captured by sensors that lead to problems with the high imbalance ratio and the curse of dimensionality. It becomes more challenging for many traditional fault detection methods to diagnose the faults in the process or capture the process's hidden characteristics when the data distribution is imbalanced. Therefore, motivated by deep generative models, we proposed a variational-autoencoder (VAE) based approach which can efficiently boost the fault detection performance from imbalanced process data. The proposed approach is highly suitable for dimension reduction and feature extraction of abnormal data: fault samples with new characteristics can be generated. The prediction accuracy evaluated by state-of-the-art classification algorithms can be improved significantly. We have tested our proposed approach using one real dataset collected from a packaging production line of semiconductor integrated circuits (PoSIC), and one public dataset describes a sample of pular candidates collected during High Time Resolution Universe Survey (HTRU2). Our experimental results demonstrate that the proposed approach can be well applied to imbalance process data and significantly improve prediction accuracy.","","978-1-6654-1869-0","10.1109/ECIE52353.2021.00038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9403695","Process Fault Detection;Deep Generative Model;Variational Autoencoder;Imblaanced Classification;Feature Extraction","Productivity;Fault detection;Sensor phenomena and characterization;Electrical fault detection;Data models;Stability analysis;Sensor systems","fault diagnosis;feature extraction;integrated circuit packaging;monolithic integrated circuits;neural nets;production engineering computing;sensors","semiconductor integrated circuits;packaging production line;state-of-the-art classification algorithms;feature extraction;sensors;deep generative models;data distribution;complex process system;productivity loss;abnormal event progression;industrial sectors;imbalance process fault detection;variational autoencoder based approach;high time resolution universe survey","","","","17","","20 Apr 2021","","","IEEE","IEEE Conferences"
"Transfer Learning from Synthetic to Real Images Using Variational Autoencoders for Precise Position Detection","T. Inoue; S. Choudhury; G. De Magistris; S. Dasgupta","IBM Research, Japan; IBM Research, Japan; IBM Research, Japan; Ascent Robotics Inc., Japan","2018 25th IEEE International Conference on Image Processing (ICIP)","6 Sep 2018","2018","","","2725","2729","Capturing and labeling camera images in the real world is an expensive task, whereas synthesizing labeled images in a simulation environment is easy for collecting large-scale image data. However, learning from only synthetic images may not achieve the desired performance in the real world due to a gap between synthetic and real images. We propose a method that transfers learned detection of an object position from a simulation environment to the real world. This method uses only a significantly limited dataset of real images while leveraging a large dataset of synthetic images using variational autoen-coders. Additionally, the proposed method consistently performed well in different lighting conditions, in the presence of other distractor objects, and on different backgrounds. Experimental results showed that it achieved accuracy of 1.5 mm to 3.5 mm on average. Furthermore, we showed how the method can be used in a real-world scenario like a “pick-and-place” robotic task.","2381-8549","978-1-4799-7061-2","10.1109/ICIP.2018.8451064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8451064","deep learning;position detection;transfer learning;variational autoencoder;computer simulation","Lighting;Training;Task analysis;Robots;Decoding;Image color analysis;Cameras","image processing;neural nets;object detection","transfer learning;variational autoencoders;labeled images;simulation environment;large-scale image data;synthetic images;object position;variational autoen-coders;position detection;camera image labeling;transfers learned detection;pick-and-place robotic task","","13","","21","","6 Sep 2018","","","IEEE","IEEE Conferences"
"Anomaly Detection in Hyperspectral Image Using 3D-Convolutional Variational Autoencoder","J. Zhang; Y. Xu; T. Zhan; Z. Wu; Z. Wei","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Jiangsu Key Construction Laboratory of Audit Information Engineering, Nanjing Audit University, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2512","2515","Anomaly detection (AD) has become a hot topic in hyperspectral image (HSI) analysis. Anomalies are samples that are significantly different from the surrounding background in space or spectrum. However, the rich spectral-spatial features in HSI are not fully discovered by most traditional AD methods. In this paper, a 3D-convolutional Variational Au-toencoder (3D-CVAE) based AD method is proposed to make full use of the spectral-spatial information. The spectral-spatial features are extracted by the 3D-CVAE encoder and the background is reconstructed using these features through 3D-CVAE decoder. The residual between the original input and the reconstructed background contains the anomalies which can be easily detected by the Reed-Xiaoli(RX) detector in the residual. Experimental results on two HSI datasets demonstrate the advantage of the proposed method.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554184","National Natural Science Foundation of China(grant numbers:62071233); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554184","Anomaly detection (AD);hyperspectral image (HSI);convolutional Variational Autoencoder (CVAE);RX detector","Training;Geoscience and remote sensing;Detectors;Feature extraction;Decoding;Anomaly detection;Image reconstruction","feature extraction;geophysical image processing;hyperspectral imaging;image classification","3D-CVAE decoder;reconstructed background;HSI datasets;anomaly detection;3D-convolutional Variational autoencoder;hyperspectral image analysis;surrounding background;spectral-spatial features;traditional AD methods;3D-convolutional Variational Au-toencoder;spectral-spatial information;3D-CVAE encoder","","3","","10","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Joint Source Separation and Classiﬁcation Using Variational Autoencoders","Ç. Hızlı; E. Karamatlı; A. T. Cemgil; S. Kırbız","Bilgisayar Mühendisliği Bölümü, Boğaziçi Üniversitesi, İstanbul, Türkiye; Bilgisayar Mühendisliği Bölümü, Boğaziçi Üniversitesi, İstanbul, Türkiye; Bilgisayar Mühendisliği Bölümü, Boğaziçi Üniversitesi, İstanbul, Türkiye; Elektrik-Elektronik Mühendisliği Bölümü, MEF Üniversitesi, İstanbul, Türkiye","2020 28th Signal Processing and Communications Applications Conference (SIU)","7 Jan 2021","2020","","","1","4","In this paper, we propose a novel multi-task variational auto encoder (VAE) based approach for joint source separation and classification. The network uses a probabilistic encoder for each sources to map the input data to latent space. The latent representation is then used by a probabilistic decoder for the two tasks: source separation and source classification. Throughout a variety of experiments performed on various image and audio datasets, source separation performance of our method is as good as the method that performs source separation under source class supervision. In addition, the proposed method does not require the class labels and can predict the labels.","2165-0608","978-1-7281-7206-4","10.1109/SIU49456.2020.9302092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302092","Source separation;variational autoencoders;classiﬁcation;multi-task learning","Source separation;Probabilistic logic;Task analysis;Nanoelectromechanical systems;NOMA;Graphics processing units;Decoding","blind source separation;learning (artificial intelligence);pattern classification;source separation","joint source separation;variational autoencoders;probabilistic encoder;latent space;latent representation;probabilistic decoder;source classification;source separation performance;source class supervision;multitask variational auto encoder based approach","","","","","","7 Jan 2021","","","IEEE","IEEE Conferences"
"mmFall: Fall Detection Using 4-D mmWave Radar and a Hybrid Variational RNN AutoEncoder","F. Jin; A. Sengupta; S. Cao","Department of Electrical and Computer Engineering, The University of Arizona, Tucson, AZ, USA; Department of Electrical and Computer Engineering, The University of Arizona, Tucson, AZ, USA; Department of Electrical and Computer Engineering, The University of Arizona, Tucson, AZ, USA","IEEE Transactions on Automation Science and Engineering","6 Apr 2022","2022","19","2","1245","1257","Elderly fall prevention and detection becomes extremely crucial with the fast aging population globally. In this article, we propose mmFall, a novel fall detection system, which comprises 1) the emerging millimeter-wave (mmWave) radar sensor to collect the human body’s point cloud along with the body centroid and 2) a hybrid variational recurrent neural network (RNN) autoencoder (HVRAE) to compute the anomaly level of the body motion based on the acquired point cloud. A fall is detected when the spike in anomaly level and the drop in centroid height occur simultaneously. The mmWave radar sensor offers privacy-compliance and high sensitivity to motion, over the traditional sensing modalities. However, 1) randomness in radar point cloud and 2) difficulties in fall collection/labeling in the traditional supervised fall detection approaches are the two major challenges. To overcome the randomness in radar data, the proposed HVRAE uses variational inference, a generative approach rather than a discriminative approach, to infer the posterior probability of the body’s latent motion state every frame, followed by a RNN to summarize the temporal features over multiple frames. Moreover, to circumvent the difficulties in fall data collection/labeling, the HVRAE is built upon an autoencoder architecture in a semisupervised approach, which is only trained on the normal activities of daily living (ADL). In the inference stage, the HVRAE will generate a spike in the anomaly level once an abnormal motion, such as fall, occurs. During the experiment,1 we implemented the HVRAE along with two other baselines, and tested on the data set collected in an apartment. The receiver operating characteristic (ROC) curve indicates that our proposed model outperforms baselines and achieves 98% detection out of 50 falls at the expense of just 2 false alarms. Note to Practitioners—Traditional nonwearable fall detection approaches typically make use of a vision-based sensor, such as camera, to monitor and detect fall using a classifier that is trained in a supervised fashion on the collected fall and nonfall data. However, several problems render these methods impractical. First, camera-based monitoring may trigger privacy concerns. Second, fall data collection using human subjects is difficult and costly, not to mention the impossible ask of the elderly repeating simulated falls for data collection. In this article, we propose a new fall detection approach to overcome these problems 1) using a palm-size mmWave radar sensor to monitor the elderly, that is highly sensitive to motion while protecting privacy and 2) using a semisupervised anomaly detection approach to circumvent the fall data collection. Further hardware engineering and more training data from people with different body figures could make the proposed fall detection solution even more practical.","1558-3783","","10.1109/TASE.2020.3042158","The University of Arizona.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9305931","Anomaly detection;fall detection;millimeter wave (mmWave) radar;recurrent autoencoder (RAE);semisupervised learning;variational autoencoder","Radar;Three-dimensional displays;Radar detection;Senior citizens;Doppler radar;Radar antennas;Radar measurements","Bayes methods;geriatrics;image motion analysis;inference mechanisms;millimetre wave detectors;object detection;patient monitoring;probability;recurrent neural nets","human body;body centroid;hybrid variational recurrent neural network autoencoder;HVRAE;anomaly level;body motion;acquired point cloud;sensing modalities;radar point cloud;radar data;variational inference;generative approach;discriminative approach;autoencoder architecture;abnormal motion;vision-based sensor;palm-size mmWave radar sensor;semisupervised anomaly detection;mmFall;4-d mmWave radar;fall prevention;fall detection system;millimeter-wave radar sensor;hybrid variational RNN autoencoder;nonwearable fall detection;nonfall data;body figures;supervised fall detection;RNN;activities of daily living;ADL;inference stage","","7","","63","IEEE","23 Dec 2020","","","IEEE","IEEE Journals"
"Learning Hierarchical Variational Autoencoders with Mutual Information Maximization for Autoregressive Sequence Modeling","D. Qian; W. Cheung","Department of Computer Science, Hong Kong Baptist University, 26679 Kowloon, Hong Kong, Hong Kong; Department of Computer Science, Hong Kong Baptist University, 26679 Kowloon, Hong Kong, Hong Kong","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2022","PP","99","1","1","Variational autoencoders (VAEs) are a class of effective deep generative models, with the objective to approximate the true, but unknown data distribution. VAEs make use of latent variables to capture high-level semantics so as to reconstruct the data well with the help of informative latent variables. Yet, training VAEs tends to suffer from posterior collapse, when the decoder is parameterized by an autoregressive model for sequence generation. On the other hand, VAEs can be further extended to contain multiple layers of latent variables, but posterior collapse still happens, which hinders the usage of hierarchical VAEs in real-world applications. In this paper, we introduce InfoMaxHVAE, which integrates mutual information estimated via neural networks into hierarchical VAEs to alleviate posterior collapse, when powerful autoregressive models are used for modeling sequences. Experimental results on a number of text and image datasets show that InfoMaxHVAE, in general, outperforms the state-of-the-art baselines and exhibits less posterior collapse. We further show that InfoMaxHVAE can shape a coarse-to-fine hierarchical organization of the latent space.","1939-3539","","10.1109/TPAMI.2022.3160509","Research Grants Council University Grants Committee(grant numbers:General Research Fund RGC/HKBU12202621); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9739027","Variational autoencoders (VAEs);hierarchical variational autoencoders (HVAEs);mutual information neural estimation;neural autoregressive sequence modeling","Decoding;Data models;Training;Mutual information;Computational modeling;Task analysis;Predictive models","","","","","","","IEEE","21 Mar 2022","","","IEEE","IEEE Early Access Articles"
"Variational Autoencoder Inverse Mapper: An End-to-End Deep Learning Framework for Inverse Problems","M. Almaeen; Y. Alanazi; N. Sato; W. Melnitchouk; M. P. Kuchera; Y. Li","Department of Computer Science, Old Dominion University, Norfolk, VA, USA; Department of Computer Science, Old Dominion University, Norfolk, VA, USA; Jefferson Lab, Theory Center, Newport News, VA, USA; Jefferson Lab, Theory Center, Newport News, VA, USA; Department of Physics, Davidson College, Davidson, NC, USA; Department of Computer Science, Old Dominion University, Norfolk, VA, USA","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","8","Inverse problems - using measured observations to determine unknown parameters - are well motivated but challenging in many science and engineering problems. In this paper, we propose an end-to-end deep learning framework, the Variational Autoencoder Inverse Mapper (VAIM), as an autoencoder-based neural network architecture for inverse problems. The encoder and decoder neural networks approximate the forward and backward mapping, respectively, and a variational latent layer is incorporated into VAIM to learn the posterior parameter distributions with respect to given observables. We demonstrate the effectiveness of VAIM for several toy inverse problems, with both finite and infinite solutions, and for constructing the inverse function mapping quantum correlation functions to observables in a Quantum Chromodynamics analysis of nucleon structure.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9534012","Commonwealth of Virginia; US Department of Energy(grant numbers:DE-AC05-060R23177); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534012","inverse problems;variational autoencoder;end-to-end learning;latent space analysis;ill-posed","Deep learning;Correlation;Inverse problems;Software packages;Toy manufacturing industry;Artificial neural networks;Generative adversarial networks","deep learning (artificial intelligence);inverse problems;mathematics computing;neural net architecture;variational techniques","decoder neural networks;variational latent layer;VAIM;inverse problems;inverse function mapping quantum correlation functions;end-to-end deep learning;autoencoder based neural network architecture;variational autoencoder inverse mapper","","","","26","","20 Sep 2021","","","IEEE","IEEE Conferences"
"Disentanglement Learning for Variational Autoencoders Applied to Audio-Visual Speech Enhancement","G. Carbajal; J. Richter; T. Gerkmann","Signal Processing (SP), Universität, Hamburg, Germany; Signal Processing (SP), Universität, Hamburg, Germany; Signal Processing (SP), Universität, Hamburg, Germany","2021 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)","13 Dec 2021","2021","","","126","130","Recently, the standard variational autoencoder has been successfully used to learn a probabilistic prior over speech signals, which is then used to perform speech enhancement. Variational autoen-coders have then been conditioned on a label describing a high-level speech attribute (e.g. speech activity) that allows for a more explicit control of speech generation. However, the label is not guaranteed to be disentangled from the other latent variables, which results in limited performance improvements compared to the standard variational autoencoder. In this work, we propose to use an adversarial training scheme for variational autoencoders to disentangle the label from the other latent variables. At training, we use a discriminator that competes with the encoder of the variational autoencoder. Simultaneously’ we also use an additional encoder that estimates the label for the decoder of the variational autoencoder, which proves to be crucial to learn disentanglement. We show the benefit of the proposed disentanglement learning when a voice activity label, estimated from visual data, is used for speech enhancement.","1947-1629","978-1-6654-4870-3","10.1109/WASPAA52581.2021.9632676","German Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9632676","Speech enhancement;conditional generative model;variational autoencoder;disentanglement learning;adversarial training;semi-supervised learning;audio-visual","Training;Visualization;Conferences;Speech enhancement;Signal processing;Probabilistic logic;Acoustics","learning (artificial intelligence);speech enhancement;speech processing;speech recognition","high-level speech;speech activity;speech generation;latent variables;standard variational autoencoder;disentanglement learning;voice activity label;variational autoencoders applied;audio-visual speech enhancement;speech signals;variational autoen-coders","","","","31","IEEE","13 Dec 2021","","","IEEE","IEEE Conferences"
"Topic Embedded Representation Enhanced Variational Wasserstein Autoencoder for Text Modeling","Z. Xiang; X. Liu; G. Yang; Y. Liu","Henan Key Laboratory on Public Opinion Intelligent Analysis, Zhengzhou, China; School of Computer Science, Zhongyuan University of Technology, Zhengzhou, China; Henan Key Laboratory on Public Opinion Intelligent Analysis, Zhengzhou, China; Key Lab of Cryptologic Technology and Information Security, Ministry of Education, Shandong University, Xi’an, China","2022 IEEE 5th International Conference on Electronics Technology (ICET)","14 Jul 2022","2022","","","1318","1322","Variational Autoencoder (VAE) is now popular in text modeling and language generation tasks, which need to pay attention to the diversity of generation results. The existing models are insufficient in capturing the built-in relationships between topic representation and sequential words. At the same time, there is a massive contradiction between the commonly used simple Gaussian prior and the actual complex distribution of language texts. To address the above problems, we introduce a hybrid Wasserstein Autoencoder (WAE) with Topic Embedded Representation (TER) for text modeling. TER is obtained through an embedding-based topic model and can capture the dependencies and semantic similarities between topics and words. In this case, the learned latent variable has rich semantic knowledge with the help of TER and is easier to explain and control. Our experiments show that our method is competitive with other VAEs in text modeling.","2768-6515","978-1-6654-8508-1","10.1109/ICET55676.2022.9824959","National Natural Science Foundation of China; State Key Laboratory of Virtual Reality Technology and Systems; Beihang University; Ministry of Education; Shandong University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9824959","variational autoencoders;text modeling;topic embedded representation;Wasserstein autoencoder;topic model","Conferences;Semantics;Aerospace electronics;Task analysis","learning (artificial intelligence);natural language processing;text analysis","text modeling;Topic Embedded Representation enhanced variational Wasserstein Autoencoder;Variational Autoencoder;language generation tasks;generation results;topic representation;language texts;hybrid Wasserstein Autoencoder;TER;embedding-based topic model","","","","22","IEEE","14 Jul 2022","","","IEEE","IEEE Conferences"
"Embodied Language Learning with Paired Variational Autoencoders","O. Özdemir; M. Kerzel; S. Wermter","Department of Informatics, Knowledge Technology Group, University of Hamburg, Hamburg, Germany; Department of Informatics, Knowledge Technology Group, University of Hamburg, Hamburg, Germany; Department of Informatics, Knowledge Technology Group, University of Hamburg, Hamburg, Germany","2021 IEEE International Conference on Development and Learning (ICDL)","20 Aug 2021","2021","","","1","6","Language acquisition is an integral part of developmental robotics, which aims at understanding the key components in human development and learning to utilise them in artificial agents. Similar to human infants, robots can learn language while interacting with objects in their environments and receiving linguistic input. This process, also coined as embodied language learning, can enhance language acquisition in robots via multiple modalities including visual and sensorimotor input. In this work, we explore ways to translate a simple action in a tabletop environment into various linguistic commands based on an existing approach which exploits the idea of multiple autoencoders. While the existing approach focuses on strict one-to-one mappings between actions and descriptions by implicitly binding two standard autoencoders in the latent space, we propose a variational autoencoder model to facilitate one-to-many mapping between actions and descriptions. Additionally, for extracting visual features, we employ channel-separated convolutional autoencoders to better handle complex visual input. The results show that our model outperforms the existing approach in associating multiple commands with the corresponding action.","","978-1-7281-6242-3","10.1109/ICDL49984.2021.9515668","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9515668","embodied language learning;variational and recurrent autoencoders;one-to-many mapping;robot actions","Training;Visualization;Image color analysis;Conferences;Learning (artificial intelligence);Linguistics;Robot sensing systems","feature extraction;image representation;knowledge acquisition;learning (artificial intelligence);linguistics;mobile robots;multi-agent systems","embodied language learning;paired variational autoencoders;language acquisition;developmental robotics;human development;human infants;receiving linguistic input;visual sensorimotor input;multiple autoencoders;standard autoencoders;variational autoencoder model;channel-separated convolutional autoencoders;complex visual input","","","","15","","20 Aug 2021","","","IEEE","IEEE Conferences"
"Variational autoencoders with triplet loss for representation learning","Ç. Işıl; B. Solmaz; A. Koç","Akıllı Veri Analitiği Araştırma Program Müdürlüğü, Aselsan Araştırma Merkezi, Ankara, Türkiye; Akıllı Veri Analitiği Araştırma Program Müdürlüğü, Aselsan Araştırma Merkezi, Ankara, Türkiye; Akıllı Veri Analitiği Araştırma Program Müdürlüğü, Aselsan Araştırma Merkezi, Ankara, Türkiye","2018 26th Signal Processing and Communications Applications Conference (SIU)","9 Jul 2018","2018","","","1","4","Learning low dimensional meaningful representations of data is an important task for classification, visualization and compression. Using autoencoders for representation learning is a successful application of deep learning. Recently, variational autoencoders have also been developed. These are more advantageous than autoencoders since these are generative and have a compact form in the latent space. In order to improve the clustering performance of variational autoencoders in the latent space, the use of variational autoencoders with triplet loss is proposed in this study.","","978-1-5386-1501-0","10.1109/SIU.2018.8404227","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8404227","deep learning;autoencoders;representation learning;triplet loss","Dogs;Support vector machines;Conferences;Machine learning;Computer vision;Face recognition","data visualisation;learning (artificial intelligence);pattern clustering","representation learning;deep learning;variational autoencoder clustering performance improvement","","","","","","9 Jul 2018","","","IEEE","IEEE Conferences"
"Link Activation Using Variational Graph Autoencoders","S. Jamshidiha; V. Pourahmadi; A. Mohammadi; M. Bennis","Department of Electrical Engineering, Amirkabir University of Technology, Tehran, Iran; Department of Electrical Engineering, Amirkabir University of Technology, Tehran, Iran; Department of Electrical Engineering, Amirkabir University of Technology, Tehran, Iran; Centre for Wireless Communications, University of Oulu, Oulu, Finland","IEEE Communications Letters","9 Jul 2021","2021","25","7","2358","2361","An unsupervised method is proposed for link activation in wireless networks by identifying clusters of interfering users. A k-nearest neighbors interference graph is first defined for the wireless network which is then mapped to a stochastic latent space. The users are then clustered in the latent space using a Gaussian mixture model, and one user from each interfering cluster is activated while the rest of the users in that cluster remain idle. The proposed framework is scalable, works across several network topologies such as device to device (D2D), and is close to the optimal solution in performance.","1558-2558","","10.1109/LCOMM.2021.3076190","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9417216","Graph embedding;variational graph autoencoder;wireless networks;Bayesian deep learning","Interference;Wireless networks;Transmitters;Device-to-device communication;Stochastic processes;Receivers;Deep learning","Gaussian processes;graph theory;mixture models;nearest neighbour methods;optimisation;pattern clustering;radio links;radio networks;radiofrequency interference;telecommunication computing;telecommunication network topology;unsupervised learning","network topologies;link activation;variational graph autoencoders;unsupervised method;wireless network;interfering users;k-nearest neighbors interference graph;stochastic latent space;Gaussian mixture model;interfering cluster","","","","9","IEEE","28 Apr 2021","","","IEEE","IEEE Journals"
"Emotional Response Generation using Conditional Variational Autoencoder","Y. -J. Lee; H. -J. Choi","School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","2020 IEEE International Conference on Big Data and Smart Computing (BigComp)","20 Apr 2020","2020","","","553","554","Neural response generation is to generate human-like response given human utterance by using a deep learning. In the previous studies, expressing emotion in response generation improve user performance, user engagement, and user satisfaction. Also, the conversational agents can communicate with users at the human level. However, the previous emotional response generation model cannot interpret why the model generates such response with emotions. We propose an interpretable emotional response generation model which generates emotional responses by using a latent space. The extraction part is to extract the emotion of input utterance as a vector form by using the Bidirectional GRU based classification model. The generation part is to generate an emotional response to the input utterance by exploiting emotion vector and latent space. All of these parts are jointly optimized at the training process. We will evaluate our model on the emotion-labeled dialogue dataset: DailyDialog.","2375-9356","978-1-7281-6034-4","10.1109/BigComp48618.2020.000-4","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070547","Emotional response generation;emotion classification model;conditional variational autoencoder;interpretability","Psychology;Training;Computational modeling;Neural networks;Standards;Computer architecture;Probability distribution","emotion recognition;human computer interaction;interactive systems;learning (artificial intelligence);neural nets","emotional response generation model;emotion vector;emotion-labeled dialogue dataset;conditional variational autoencoder;neural response generation;user engagement;user satisfaction;deep learning;bidirectional GRU based classification model","","","","11","","20 Apr 2020","","","IEEE","IEEE Conferences"
"An Introduction to Variational Autoencoders","D. P. Kingma; M. Welling",NA; NA,"An Introduction to Variational Autoencoders","","2019","","","","","In this monograph, the authors present an introduction to the framework of variational autoencoders (VAEs) that provides a principled method for jointly learning deep latent-variable models and corresponding inference models using stochastic gradient descent. The framework has a wide array of applications from generative modeling, semi-supervised learning to representation learning. The authors expand earlier work and provide the reader with the fine detail on the important topics giving deep insight into the subject for the expert and student alike. Written in a survey-like nature the text serves as a review for those wishing to quickly deepen their knowledge of the topic. An Introduction to Variational Autoencoders provides a quick summary for the reader of a topic that has become an important tool in modern-day deep learning techniques.","","9781680836233","","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9051781.pdf&bkn=9051780&pdfType=book","","","","","","","","","","2 Apr 2020","","","now","Now Foundations and Trends Books"
"Graph Embedding For Link Prediction Using Residual Variational Graph Autoencoders","R. K. Keser; I. Nallbani; N. Çalik; A. Ayanzadeh; B. U. Töreyin","Informatics Institute, Istanbul Technical University, Istanbul, Turkey; Informatics Institute, Istanbul Technical University, Istanbul, Turkey; Informatics Institute, Istanbul Technical University, Istanbul, Turkey; Informatics Institute, Istanbul Technical University, Istanbul, Turkey; Informatics Institute, Istanbul Technical University, Istanbul, Turkey","2020 28th Signal Processing and Communications Applications Conference (SIU)","7 Jan 2021","2020","","","1","4","Graphs are usually represented by high dimensional data. Hence, graph embedding is an essential task, which aims to represent a graph in a lower dimension while protecting the original graph's properties. In this paper, we propose a novel graph embedding method called Residual Variational Graph Autoencoder (RVGAE), which boosts variational graph autoencoder's performance utilizing residual connections. Our method's performance is evaluated on the link prediction task. The results demonstrate that our model can achieve better results than graph convolutional neural network (GCN) and variational graph autoencoder (VGAE).","2165-0608","978-1-7281-7206-4","10.1109/SIU49456.2020.9302271","Istanbul Technical University (ITU) Vodafone Future Lab(grant numbers:ITUVF20180901P04); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302271","Graph Embedding;Variational Graph Autoen-coders;Residual Learning","Task analysis;Predictive models;Training;Standards;Measurement;Generators;Deep learning","convolutional neural nets;graph theory","high dimensional data;graph embedding;link prediction task;residual variational graph autoencoders;RVGAE;graph convolutional neural network;GCN","","1","","19","","7 Jan 2021","","","IEEE","IEEE Conferences"
"Optimizing Variational Graph Autoencoder for Community Detection","J. J. Choong; X. Liu; T. Murata","Department of Computer Science, Tokyo Institute of Technology, Tokyo, Japan; Industrial Science and Technology, National Institute of Advanced, Tokyo, Japan; Department of Computer Science, Tokyo Institute of Technology, Tokyo, Japan","2019 IEEE International Conference on Big Data (Big Data)","24 Feb 2020","2019","","","5353","5358","Variational Graph Autoencoders (VGAE) has recently been a popular framework of choice for learning representations on graphs. Its inception has allowed models to achieve state-of-the-art performances for challenging tasks such as link prediction, rating prediction and node clustering. However, a fundamental flaw exists in Variational Autoencoder (VAE) based approaches. Specifically, the objective function of VAE (reconstruction loss), deviates from its primary objective (i.e clustering). In this paper, we attempt to address this issue by introducing two significant changes to Variational Graph Autoencoder for Community Detection (VGAECD). Firstly, we introduce a simplified graph convolution encoder to increase convergence speed and reduce computational time. Secondly, a dual variational objective is introduced to encourage learning of the primary objective. The outcome is a faster converging model with competitive community detection performance.","","978-1-7281-0858-2","10.1109/BigData47090.2019.9006123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9006123","community detection;graph neural network;variational autoencoder;network embedding","Optimization;Machine learning;Training;Benchmark testing;Convergence;Machine learning algorithms;Task analysis","network theory (graphs);neural nets;optimisation;pattern clustering","simplified graph convolution encoder;dual variational objective;competitive community detection performance;rating prediction;node clustering;variational autoencoder based approaches;variational graph autoencoder;VGAE","","1","","39","","24 Feb 2020","","","IEEE","IEEE Conferences"
"Multi-Modal Domain Adaptation Variational Autoencoder for EEG-Based Emotion Recognition","Y. Wang; S. Qiu; D. Li; C. Du; B. -L. Lu; H. He","Beijing Institute of Control and Electronic Technology, Beijing, China; University of Chinese Academy of Sciences, Beijing; School of Mathematics and Information Sciences, Yantai University, Yantai, China; University of Chinese Academy of Sciences, Beijing; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Science, Beijing, China","IEEE/CAA Journal of Automatica Sinica","23 Aug 2022","2022","9","9","1612","1626","Traditional electroencephalograph (EEG)-based emotion recognition requires a large number of calibration samples to build a model for a specific subject, which restricts the application of the affective brain computer interface (BCI) in practice. We attempt to use the multi-modal data from the past session to realize emotion recognition in the case of a small amount of calibration samples. To solve this problem, we propose a multi-modal domain adaptive variational autoencoder (MMDA-VAE) method, which learns shared cross-domain latent representations of the multi-modal data. Our method builds a multi-modal variational autoencoder (MVAE) to project the data of multiple modalities into a common space. Through adversarial learning and cycle-consistency regularization, our method can reduce the distribution difference of each domain on the shared latent representation layer and realize the transfer of knowledge. Extensive experiments are conducted on two public datasets, SEED and SEED-IV, and the results show the superiority of our proposed method. Our work can effectively improve the performance of emotion recognition with a small amount of labelled multi-modal data.","2329-9274","","10.1109/JAS.2022.105515","National Natural Science Foundation of China(grant numbers:61976209,62020106015,U21A20388); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9754329","Cycle-consistency;domain adaptation;electroencephalograph (EEG);multi modality;variational autoencoder","Emotion recognition;Adaptation models;Brain modeling;Data models;Electroencephalography;Image reconstruction;Calibration","brain-computer interfaces;electroencephalography;emotion recognition;learning (artificial intelligence);medical signal processing","multimodal domain adaptive variational autoencoder method;cross-domain latent representations;multimodal variational autoencoder;multiple modalities;shared latent representation layer;labelled multimodal data;multimodal domain adaptation variational autoencoder;EEG-based emotion recognition;traditional electroencephalograph-based emotion recognition;calibration samples;affective brain computer interface","","","","53","","8 Apr 2022","","","IEEE","IEEE Journals"
"Brain Lesion Detection Using A Robust Variational Autoencoder and Transfer Learning","H. Akrami; A. A. Joshi; J. Li; S. Aydore; R. M. Leahy","Signal and Image Processing Institute, University of Southern California, Los Angeles; Signal and Image Processing Institute, University of Southern California, Los Angeles; Signal and Image Processing Institute, University of Southern California, Los Angeles; Electrical and Computer Engineering, Stevens Institute of Technology, NJ, USA; Signal and Image Processing Institute, University of Southern California, Los Angeles","2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)","22 May 2020","2020","","","786","790","Automated brain lesion detection from multi-spectral MR images can assist clinicians by improving sensitivity as well as specificity. Supervised machine learning methods have been successful in lesion detection. However, these methods usually rely on a large number of manually delineated images for specific imaging protocols and parameters and often do not generalize well to other imaging parameters and demographics. Most recently, unsupervised models such as autoencoders have become attractive for lesion detection since they do not need access to manually delineated lesions. Despite the success of unsupervised models, using pre-trained models on an unseen dataset is still a challenge. This difficulty is because the new dataset may use different imaging parameters, demographics, and different pre-processing techniques. Additionally, using a clinical dataset that has anomalies and outliers can make unsupervised learning challenging since the outliers can unduly affect the performance of the learned models. These two difficulties make unsupervised lesion detection a particularly challenging task. The method proposed in this work addresses these issues using a two-prong strategy: (1) we use a robust variational autoencoder model that is based on robust statistics, specifically the j)-divergence that can be trained with data that has outliers; (2) we use a transfer-learning method for learning models across datasets with different characteristics. Our results on MRI datasets demonstrate that we can improve the accuracy of lesion detection by adapting robust statistical models and transfer learning for a variational autoencoder model.","1945-8452","978-1-5386-9330-8","10.1109/ISBI45749.2020.9098405","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9098405","variational autoencoders;lesion detection;robust variational autoencoders;brain imaging;unsupervised machine learning;anomaly detection","Lesions;Robustness;Training;Data models;Magnetic resonance imaging;Image reconstruction","biomedical MRI;brain;image classification;image segmentation;learning (artificial intelligence);medical image processing;statistical analysis;unsupervised learning","transfer learning;automated brain lesion detection;multispectral MR images;supervised machine learning methods;manually delineated images;specific imaging protocols;unsupervised models;manually delineated lesions;imaging parameters;pre-processing techniques;unsupervised learning;unsupervised lesion detection;robust variational autoencoder model;transfer-learning method;robust statistical models","","2","","17","","22 May 2020","","","IEEE","IEEE Conferences"
"RVAE-ABFA : Robust Anomaly Detection for HighDimensional Data Using Variational Autoencoder","Y. Gao; B. Shi; B. Dong; Y. Chen; L. Mi; Z. Huang; Y. Shi","SPKLSTN Lab, School of Computer Science and Technology, Xi'an Jiaotong University, Xi'an, China; SPKLSTN Lab, School of Computer Science and Technology, Xi'an Jiaotong University, Xi'an, China; National Engineering Lab of Big Data Analytics, School of Distance Education, Xi'an Jiaotong University, Xi'an, China; SPKLSTN Lab, School of Computer Science and Technology, Xi'an Jiaotong University, Xi'an, China; SPKLSTN Lab, School of Computer Science and Technology, Xi'an Jiaotong University, Xi'an, China; SERVYOU GROUP, Hangzhou, China; SERVYOU GROUP, Hangzhou, China","2020 IEEE 44th Annual Computers, Software, and Applications Conference (COMPSAC)","22 Sep 2020","2020","","","334","339","The curse of dimensionality is a fundamental difficulty in anomaly detection for high dimensional data. To deal with this problem, the autoencoder based approach is an elegant solution. However, existing works require a clean training dataset that is not always guaranteed in real scenarios. In this paper, we propose a novel anomaly detection method named RVAE-ABFA (robust variational autoencoder with attention based feature adaptation for high dimensional data anomaly detection), which significantly improves the anomaly detection performance when training data is contaminated. Rather than only utilize reconstruction error, we take the learned low dimensional embeddings generated by variational autoencoder into consideration. In RVAE-ABFA, the learned low dimensional embeddings are helpful to detect anomalies in contaminated data because of the ability of variational inference. We also propose an ABFA (attention based feature adaptation) mechanism to adjust the weights of low dimensional embeddings and reconstruction error. Furthermore, we adopt the adversarial training criterion to perform variational inference by the adversarial network named RAAE-ABFA (robust adversarial autoencoder with attention based feature adaptation for high dimensional data anomaly detection) in which we can generate extra samples when training data is not enough. Experimental results on several benchmark datasets show that the proposed method significantly outperforms state-of-the-art unsupervised anomaly detection methods and is more robust when training data is contaminated.","0730-3157","978-1-7281-7303-0","10.1109/COMPSAC48688.2020.0-224","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9202465","Anomaly Detection;Robust Learning;Variational Autoencoder;Adversarial Neural Network","Anomaly detection;Training;Robustness;Estimation;Feature extraction;Training data;Decoding","learning (artificial intelligence);neural nets;security of data","variational inference;attention based feature adaptation;adversarial autoencoder;high dimensional data anomaly detection;RVAE-ABFA;high dimensional data;robust variational autoencoder;low dimensional embeddings;contaminated data;curse of dimensionality;reconstruction error;adversarial training criterion","","5","","43","IEEE","22 Sep 2020","","","IEEE","IEEE Conferences"
"Fake News Detection Using BERT-VGG19 Multimodal Variational Autoencoder","R. Jaiswal; U. P. Singh; K. P. Singh","Department of IT, MLO Lab, IIIT Allahabad, Prayagraj, UP, India; Department of IT, MLO Lab, IIIT Allahabad, Prayagraj, UP, India; Department of IT, MLO Lab, IIIT Allahabad, Prayagraj, UP, India","2021 IEEE 8th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)","10 Jan 2022","2021","","","1","5","In this era of readily accessible Internet, there has been a monumental shift in the way information is created, processed and disseminated to the netizens. Moreover, social media has played a very vital role where users can not only interact with one another and share information but also have the capability to influence the thought process of others through their content. One of the major drawbacks of these platforms remains the absence of credibility in the information being circulated and this inherent vulnerability is exploited by many to circulate fake news over these platforms. This falsehood not only jeopardises the credibility of information and the platform itself but is also a growing technological mess simply because fake news spreads much more rapidly and has the capacity to even cause unrest, discontent and misery among the masses. We propose a BERT and VGG19 based multi-modal variational autoencoder for fake news detection. Our proposed model combines the information present in text and image modality to obtain better discriminatory power. The model takes both text and image data of fake news and extract textual feature and visual feature of the News and process both the feature simultaneously into variational autoencoder so the purposed model is call as multi-model variational autoencoder. Specifically, Bert and VGG19 embeddings are obtained for text and image modalities respectively after which the two embeddings are concatenated and passed through a multi-modal variational autoencoder for obtaining the shared latent representation. The shared latent representation so obtained is then fed to a binary classifier that outputs a probability that the input is fake. Our proposed model gives state of the art results on MediaEval2015 data set (with a 0.924 f-score) and remains competitive with state of the art approaches on Weibo dataset (0.656 f-score).","2687-7767","978-1-6654-0962-9","10.1109/UPCON52273.2021.9667614","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9667614","Fake News;Modality;Variational Autoencoder;Encoder;Decoder;Latent Representation","Visualization;Social networking (online);Blogs;Bit error rate;Natural languages;Feature extraction;Data models","feature extraction;Internet;learning (artificial intelligence);social networking (online);text analysis","fake news detection;BERT-VGG19 multimodal variational autoencoder;readily accessible Internet;monumental shift;social media;share information;thought process;growing technological mess;fake news spreads;VGG19 based multimodal;image modality;image data;multimodel variational autoencoder;VGG19 embeddings;image modalit;shared latent representation","","","","38","IEEE","10 Jan 2022","","","IEEE","IEEE Conferences"
"Epitomic Variational Graph Autoencoder","R. A. Khan; M. U. Anwaar; M. Kleinsteuber","Mercateo AG, Munich, Germany; Mercateo AG, Munich, Germany; Mercateo AG, Munich, Germany","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","7203","7210","Variational autoencoder (VAE) is a widely used generative model for learning latent representations. Burda et al. [3] in their seminal paper showed that learning capacity of VAE is limited by over-pruning. It is a phenomenon where a significant number of latent variables fail to capture any information about the input data and the corresponding hidden units become inactive. This adversely affects learning diverse and interpretable latent representations. As variational graph autoencoder (VGAE) extends VAE for graph-structured data, it inherits the over-pruning problem. In this paper, we adopt a model based approach and propose epitomic VGAE (EVGAE), a generative variational framework for graph datasets which successfully mitigates the over-pruning problem and also boosts the generative ability of VGAE. We consider EVGAE to consist of multiple sparse VGAE models, called epitomes, that are groups of latent variables sharing the latent space. This approach aids in increasing active units as epitomes compete to learn better representation of the graph data. We verify our claims via experiments on three benchmark datasets. Our experiments show that EVGAE has a better generative ability than VGAE. Moreover, EVGAE outperforms VGAE on link prediction task in citation networks.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9412531","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9412531","Graph auto encoder;Variational graph autoencoder;Graph neural networks;Over-pruning;VAE;EVGAE","Benchmark testing;Pattern recognition;Task analysis;Standards","graph theory;learning (artificial intelligence);neural nets","EVGAE;epitomic variational graph autoencoder;VAE;generative model;graph-structured data;over-pruning problem;epitomic VGAE;generative variational framework;graph datasets;multiple sparse VGAE models;latent space;variational graph autoencoder;learning latent representations","","","","28","","5 May 2021","","","IEEE","IEEE Conferences"
"Convolutional Variational Autoencoders for Image Clustering","I. A. Nellas; S. K. Tasoulis; V. P. Plagianakos","Department of Computer Science and Biomedical Informatics, University of Thessaly, Greece; Department of Computer Science and Biomedical Informatics, University of Thessaly, Greece; Department of Computer Science and Biomedical Informatics, University of Thessaly, Greece","2021 International Conference on Data Mining Workshops (ICDMW)","20 Jan 2022","2021","","","695","702","The problem of data clustering is one of the most fundamental and well studied problems of unsupervised learning. Image clustering, refers to one of the most challenging specifications of clustering, concerning image data. Thankfully, the emerging Deep Neural Networks, and in particular Deep Autoencoders lead to the automation of image clustering, which until recently, was time consuming and labor intensive. However, the effect of the consideration of local structure during feature extraction from a Variational Autoencoder on clustering, is still an unstudied subject in the literature, while simultaneously constitute a baseline approach for supervised learning (Convolutional Neural Networks). For this reason, the methodology proposed in this paper, is composed from a Variational Autoencoder (VAE) surrounded by a convolutional network in a symmetric way. The resulting embedded image data are fed to various established clustering algorithms to examine clustering performance. In addition, we propose a modification of this approach, able to reduce complexity while achieving similar or even better clustering performance. Finally, we investigate the combination of VAE’s produced embedding and manifold learning for image clustering. The extensive experimental analysis, verified the importance of the proposed methodology, exposing the potential for further developments.","2375-9259","978-1-6654-2427-1","10.1109/ICDMW53433.2021.00091","Hellenic Foundation for Research and Innovation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679990","Deep Learning;Image Clustering;Convolutional Neural Networks;Autoencoders;Variational Autoencoders","Manifolds;Training;Supervised learning;Clustering algorithms;Feature extraction;Inference algorithms;Manifold learning","computational complexity;convolutional neural nets;deep learning (artificial intelligence);feature extraction;image classification;pattern clustering;supervised learning;unsupervised learning","convolutional variational autoencoders;image clustering;data clustering;deep neural networks;deep autoencoders;convolutional neural networks;embedded image data;clustering algorithm;unsupervised learning;feature extraction;complexity reduction;manifold learning","","","","31","IEEE","20 Jan 2022","","","IEEE","IEEE Conferences"
"Deep nonnegative matrix factorization using a variational autoencoder with application to single-cell RNA sequencing data","D. J. Jee; Y. Kong; H. Chun","KAIST, 34968 Daejeon, Daejeon, Korea (the Republic of), 34141; Boston University, 1846 Boston, Massachusetts, United States; KAIST, 34968 Daejeon, Daejeon, Korea (the Republic of)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2022","PP","99","1","1","Single-cell RNA sequencing is used to analyze the gene expression data of individual cells, thereby adding to existing knowledge of biological phenomena. Accordingly, this technology is widely used in numerous biomedical studies. Recently, the variational autoencoder has emerged and has been adopted for the analysis of single-cell data owing to its high capacity to manage large-scale data. Many different variants of the variational autoencoder have been applied, and have yielded superior results. However, because it is nonlinear, the model does not provide parameters that can be used to explain the underlying biological patterns. In this paper, we propose an interpretable nonnegative matrix factorization method that decomposes parameters into those shared across cells and those that are cell-specific. Effective nonlinear dimension reduction was achieved via a variational autoencoder applied to the cell-specific parameters. In addition to achieving nonlinear dimension reduction, our model could estimate the cell-type-specific gene expression. To improve the estimation accuracy, we introduced log-regularization, which reflects the single-cell property. Overall, our approach displayed excellent performance in a simulation study and in real data analyses, while maintaining good biological interpretability.","1557-9964","","10.1109/TCBB.2022.3172723","National Research Foundation of Korea(grant numbers:2019R1A6A1A100388713); Samsung(grant numbers:IO201209-07885-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9769995","Deep neural networks;Nonlinear dimension reduction;Nonnegative matrix factorization;Single-cell RNA sequencing data;Variational autoencoder","Dimensionality reduction;Matrix decomposition;Neural networks;Data models;Decoding;Analytical models;Sequential analysis","","","","","","","IEEE","5 May 2022","","","IEEE","IEEE Early Access Articles"
"A Method to Inspect the Implementation of Electricity Price Based on Deep Learning Variational Autoencoder","X. Gao; N. Ye; J. Song; H. Wang; Y. Zhang; Y. Guan; X. Song; Y. Cai; W. Zhang; Q. Hui; D. Li","State Grid Liaoning Electric Power Research Institute, Shenyang, China; The School of Mechanical Engineering and Automation, Northeastern University, Shenyang, China; The School of Mechanical Engineering and Automation, Northeastern University, Shenyang, China; State Grid Liaoning Electric Power Marketing Department, Shenyang, China; State Grid Liaoning Electric Power Research Institute, Shenyang, China; State Grid Liaoning Electric Power Research Institute, Shenyang, China; State Grid Liaoning Electric Power Research Institute, Shenyang, China; State Grid Liaoning Electric Power Research Institute, Shenyang, China; State Grid Liaoning Electric Power Research Institute, Shenyang, China; State Grid Liaoning Electric Power Research Institute, Shenyang, China; State Grid Liaoyang Electric Power B&E Office, Liaoyang, China","2018 2nd IEEE Conference on Energy Internet and Energy System Integration (EI2)","20 Dec 2018","2018","","","1","5","In this paper, we propose a method for performing electricity price execution inspection by using a variational autoencoder technology in deep learning. The variational auto encoder based anomaly detection algorithm(VABAD) can be used both as a discriminant model and as a feature of the generation model, which effectively solves the calculation problem of multiple heterogeneous parameters of current electricity price inspection implementation. The reconstruction probability is a probabilistic measure that takes into account the variability of the distribution of variables. It is used by autoencoder based anomaly detection methods. Experimental results show that the proposed method has been validated and compared to the existing approaches. The databases used in this paper come from Power Marketing System that occurred in Liaoning, China in 2015.","","978-1-5386-8549-5","10.1109/EI2.2018.8582186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8582186","deep learning;variational autoencoder;electricity price inspection implementation;data heterogeneity","Inspection;Anomaly detection;Power supplies;Data models;Decoding","inspection;learning (artificial intelligence);power engineering computing;power markets;power system economics;pricing;probability","deep learning variational autoencoder;electricity price execution inspection;electricity price inspection implementation;VABAD;variational auto encoder based anomaly detection algorithm;power marketing system;Liaoning China;anomaly detection methods;multiple heterogeneous parameters;calculation problem;generation model;discriminant model;variational autoencoder technology","","","","11","","20 Dec 2018","","","IEEE","IEEE Conferences"
"Deep Clustering of Compressed Variational Embeddings","S. Wu; E. Diao; J. Ding; V. Tarokh","Duke University, Durham, NC, USA; Duke University, Durham, NC, USA; University of Minnesota-Twin Cities, Minneapolis, MN, USA; Duke University, Durham, NC, USA","2020 Data Compression Conference (DCC)","2 Jun 2020","2020","","","399","399","Motivated by the ever-increasing demands for limited communication bandwidth and low-power consumption, we propose a new methodology, named joint Variational Autoencoders with Bernoulli mixture models (VAB), for performing clustering in the compressed data domain. The idea is to reduce the data dimension by Variational Autoencoders (VAEs) and group data representations by Bernoulli mixture models (BMMs). Once jointly trained for compression and clustering, the model can be decomposed into two parts: a data vendor that encodes the raw data into compressed data, and a data consumer that classifies the received (compressed) data. In this way, the data vendor benefits from data security and communication bandwidth, while the data consumer benefits from low computational complexity. To enable training using the gradient descent algorithm, we propose to use the Gumbel-Softmax distribution to resolve the infeasibility of the back-propagation algorithm when assessing categorical samples.","2375-0359","978-1-7281-6457-1","10.1109/DCC47342.2020.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9105763","Clustering;Variational Autoencoder (VAE);Bernoulli Mixture Model (BMM)","","computational complexity;data compression;gradient methods;learning (artificial intelligence);mixture models;pattern classification;pattern clustering","deep clustering;communication bandwidth;low-power consumption;Bernoulli mixture models;performing clustering;compressed data domain;data dimension;group data representations;compression;raw data;data vendor benefits;data security;data consumer benefits;low computational complexity;joint variational autoencoders;compressed variational embeddings","","","","0","","2 Jun 2020","","","IEEE","IEEE Conferences"
"Hybrid Variational Autoencoder for Collaborative Filtering","J. Liu; Y. Xiao; K. Zhu; W. Zheng; C. -H. Hsu","Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Tianjin University of Technology, Tianjin, China; Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Tianjin University of Technology, Tianjin, China; Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Tianjin University of Technology, Tianjin, China; Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Tianjin University of Technology, Tianjin, China; Department of Computer Science and Information Engineering, Asia University, Taichung, Taiwan","2022 IEEE 25th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","20 May 2022","2022","","","251","256","In recent years, Variational AutoEncoder (VAE) based methods have made many important achievements in the field of collaborative filtering recommendation system. VAE is a kind of Bayesian model which combines latent variable model with variational inference, but its optimization is often troubled by posterior collapse. By comparing the optimization process of VAE and ordinary autoencoder, we observe that the mismatch between poorly optimized encoder and decoder with too strong characterization capabilities makes it difficult to learn the mapping from the data manifold to the parameterized graph. Since the learning of a posteriori network corresponds to the encoder, we think that the problem of a posteriori collapse can be alleviated by balancing the encoder and decoder better. Therefore, we proposed Hy-VAE, which combines conventional VAE with deterministic autoencoder, and has the advantages of both VAE and deterministic autoencoder. Experiments on three real-world recommendation data sets show that our method alleviates the posterior crash problem in VAE and improves the recommendation performance.","","978-1-6654-0527-0","10.1109/CSCWD54268.2022.9776247","Nature; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9776247","Recommendation System;Collaborative filtering;Autoencoder;Rating Prediction;Deep Learning","Manifolds;Collaborative filtering;Conferences;Collaborative work;Computer crashes;Decoding;Bayes methods","Bayes methods;collaborative filtering;graph theory;information filtering;learning (artificial intelligence);optimisation;recommender systems","hybrid Variational autoencoder;Variational AutoEncoder based methods;important achievements;collaborative filtering recommendation system;Bayesian model;latent variable model;variational inference;posterior collapse;optimization process;ordinary autoencoder;poorly optimized encoder;decoder;strong characterization capabilities;posteriori network corresponds;posteriori collapse;Hy-VAE;conventional VAE;deterministic autoencoder;real-world recommendation data sets","","","","23","IEEE","20 May 2022","","","IEEE","IEEE Conferences"
"Health Indicator for Low-Speed Axial Bearings Using Variational Autoencoders","M. Hemmer; A. Klausen; H. V. Khang; K. G. Robbersmyr; T. I. Waag","MHWirth AS, Kristiansand, Norway; Department of Engineering Sciences, University of Agder, Grimstad, Norway; Department of Engineering Sciences, University of Agder, Grimstad, Norway; Department of Engineering Sciences, University of Agder, Grimstad, Norway; NORCE Norwegian Research Centre AS, Grimstad, Norway","IEEE Access","27 Feb 2020","2020","8","","35842","35852","This paper proposes a method for calculating a health indicator (HI) for low-speed axial rolling element bearing (REB) health assessment by utilizing the latent representation obtained by variational inference using Variational Autoencoders (VAEs), trained on each speed reference in the dataset. Further, versatility is added by conditioning on the speed, extending the VAE to a conditional VAE (CVAE), thereby incorporating all speeds in a single model. Within the framework, the coefficients of autoregressive (AR) models are used as features. The dimensionality reduction inherent in the proposed method lowers the need of expert knowledge to design good condition indicators. Moreover, the suggested methodology allows for setting the probability of false alarms when encoding new data points to the latent variable space using the trained model. The effectiveness of the proposed method is validated based on two different datasets: from a workshop test of an offshore drilling machine and from an in-house test rig for axial bearings. In both datasets, the HI is exceeding the warning and alarm levels with a probability of false alarm (PFA) of 10-6, and the method is most effective at lower shaft speeds.","2169-3536","","10.1109/ACCESS.2020.2974942","Norges Forskningsråd(grant numbers:237896); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9001012","Bearing fault detection;condition monitoring;unsupervised learning;variational autoencoder;conditional variational autoencoder;generative models","Training;Decoding;Dimensionality reduction;Drilling machines;Fault detection;Industries;Rolling bearings","autoregressive processes;condition monitoring;drilling machines;fault diagnosis;mechanical engineering computing;neural nets;probability;rolling bearings;shafts","bearing fault detection;in-house test rig;offshore drilling machine;false alarms;probability;CVAE;low-speed axial rolling element bearings;lower shaft speeds;autoregressive models;variational autoencoders;health indicator","","11","","55","CCBY","18 Feb 2020","","","IEEE","IEEE Journals"
"Unsupervised Learning of Low Dimensional Satellite Image Representations via Variational Autoencoders","S. Valero; F. Agulló; J. Inglada","CESBIO, CNES/CNRS/INRAE/IRD/UPS, Université de Toulouse, Toulouse, FRANCE; CESBIO, CNES/CNRS/INRAE/IRD/UPS, Université de Toulouse, Toulouse, FRANCE; CESBIO, CNES/CNRS/INRAE/IRD/UPS, Université de Toulouse, Toulouse, FRANCE","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2987","2990","The growing number of images acquired by new satellite missions increases the interest of learning low dimensional image representations without human supervision. Variational AutoEncoders (VAE) are one of the most promising strategies marrying graphical models and deep learning. They are able to learn continuous, structured and probabilistic latent spaces encoding the data. In this work, a VAE architecture is proposed and analyzed for multispectral Sentinel-2 images. The regularized β-VAE is studied and compared with the classical auto-encoder strategy. A classification experiment is carried out to corroborate that generated latent spaces can preserve the salient features of the input data. Classification results show that high accuracies can be obtained by using low dimensional latent representation learned by VAE as input data in a standard classification approach.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554661","ANR-MAESTRIA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554661","Unsupervised learning;Variational Au-toEncoders (VAE);Sentinel-2","Deep learning;Satellites;Graphical models;Geoscience and remote sensing;Image representation;Probabilistic logic;Encoding","deep learning (artificial intelligence);geophysical image processing;image classification;image representation;probability;remote sensing;unsupervised learning","low dimensional satellite image representations;variational autoencoders;satellite missions;graphical models;deep learning;continuous spaces;structured spaces;probabilistic latent spaces;VAE architecture;multispectral Sentinel-2 images;regularized β-VAE;classical auto-encoder strategy;generated latent spaces;low dimensional latent representation;unsupervised learning","","","","4","","12 Oct 2021","","","IEEE","IEEE Conferences"
"Knowing the Uncertainty in Human Behavior Classification via Variational Inference and Autoencoder","H. Du; B. Ge; Y. Dai; T. Jin","College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China","2019 International Radar Conference (RADAR)","27 Apr 2020","2019","","","1","4","Deep learning techniques have been introduced to the radar-based human behavior research in recent years. Different from manual feature engineering methods, deep neural network models can learn features of the raw sensor input automatically, demonstrating competitive performance and scalability. However, most existing deep learning models are deterministic functions. Such models are forced to make a classification at prediction time even when the situation is far different from its training set. In this work, we propose a deep probability model that overly represents the uncertainty of its classification. Specifically, we extract the features of micro-Doppler spectrograms by the convolutional autoencoder and then introduce uncertainty in the weights of the classification module via the variational inference. In this way, all weights in the classifier are represented by probability distributions over possible values, rather than having a single fixed value. The flatter the probability distribution is, the more uncertain the classification result is. Therefore, we can know the uncertainty of the classification results and choose to whether believe its decision or not.","2640-7736","978-1-7281-2660-9","10.1109/RADAR41533.2019.171328","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9079005","micro-Doppler effect;machine learning;variational inference","Feature extraction;Radar;Training;Uncertainty;Spectrogram;Computational modeling;Probability distribution","Doppler radar;feature extraction;gesture recognition;image classification;learning (artificial intelligence);neural nets;probability","microDoppler spectrograms;convolutional autoencoder;classification module;variational inference;probability distribution;human behavior classification;deep learning techniques;radar-based human behavior research;manual feature engineering methods;deep neural network models;raw sensor input;deep probability model;feature extraction","","","","13","","27 Apr 2020","","","IEEE","IEEE Conferences"
"A Data Reconstruction Method based on Adversarial Conditional Variational Autoencoder","Y. Ren; J. Liu; J. Zhang; L. Jiang; Y. Luo","School of Information Science and Engineering, Northeastern University, Shenyang, P. R. China; School of Information Science and Engineering, Northeastern University, Shenyang, P. R. China; School of Information Science and Engineering, Northeastern University, Shenyang, P. R. China; School of Information Science and Engineering, Northeastern University, Shenyang, P. R. China; School of Information Science and Engineering, Northeastern University, Shenyang, P. R. China","2020 IEEE 9th Data Driven Control and Learning Systems Conference (DDCLS)","7 Dec 2020","2020","","","622","626","Aiming at the problem of sample missing for magnetic flux leakage (MFL), a data reconstruction method based on conditional autoencoder (CVAE) and generative adversarial networks (GAN) is proposed. This method combines the advantages of CVAE and GAN, and generates high-quality samples steadily. The proposed CVAE-GAN method can not only reconstruct the missing MFL samples, but also generate a large amount of real and diverse defect sample, which solves the problem of low accuracy of the defect detection model due to insufficient samples and lack of diversity of samples. The defect sample are collected from the domestic in-service oil pipelines in experiments. The experimental results illustrate that the proposed method can effectively generate high-quality samples.","","978-1-7281-5922-5","10.1109/DDCLS49620.2020.9275168","National Natural Science Foundation of China; Natural Science Foundation of Liaoning Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9275168","Magnetic Flux Leakage;Data Reconstructing;Generative Adversarial Networks;Conditional AutoEncoder","Image reconstruction;Data models;Generators;Generative adversarial networks;Gallium nitride;Training;Pipelines","magnetic flux;magnetic leakage;mechanical engineering computing;neural nets;nondestructive testing;pipelines","CVAE-GAN method;generative adversarial networks;conditional autoencoder;magnetic flux leakage;adversarial conditional variational autoencoder;data reconstruction method;high-quality samples;insufficient samples;defect detection model;diverse defect sample;missing MFL samples","","1","","13","","7 Dec 2020","","","IEEE","IEEE Conferences"
"Infrared Image Colorization Network using Variational AutoEncoder","H. Kim; J. Kim; J. Kim","Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, Sounth Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, Sounth Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, Sounth Korea","2021 36th International Technical Conference on Circuits/Systems, Computers and Communications (ITC-CSCC)","11 Nov 2021","2021","","","1","4","This paper presents a novel method for colorizing the near-infrared (NIR) images. Recent deep learning based approaches for NIR colorization utilized an auto-encoder structure to map a single channel to the color domain. However, these methods only provide latent codes of a NIR image using an encoder structure, which simply vectorizes an input image to a latent vector. In this vectorization, all semantic information is mutually considered although each latent code represents independent information. To tackle this issue, we propose a NIR colorization network using variational auto-encoder. This network encodes a NIR image into latent codes with probabilistic distributions. Moreover, we embed a novel correlation module to interactively consider luminance and chrominance features. It facilitates the proposed network to generate better textures and color information. Our model achieves comparable performances on the large-scale dataset: video surveillance in a day (VSIAD).","","978-1-6654-3553-6","10.1109/ITC-CSCC52171.2021.9605698","National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9605698","NIR-to-RGB;Colorization;Variational Auto-Encoder","Deep learning;Computers;Codes;Correlation;Image color analysis;Semantics;Color","feature extraction;image classification;image colour analysis;image representation;infrared imaging;learning (artificial intelligence);neural nets;video surveillance","NIR image;input image;latent vector;vectorization;semantic information;latent code;independent information;NIR colorization network;variational auto-encoder;color information;image colorization network;variational AutoEncoder;near-infrared images;recent deep learning;auto-encoder structure;single channel;color domain","","1","","17","","11 Nov 2021","","","IEEE","IEEE Conferences"
"Insider Threat Detection using Deep Autoencoder and Variational Autoencoder Neural Networks","E. Pantelidis; G. Bendiab; S. Shiaeles; N. Kolokotronis","Faculty of Science and Applied Sciences, Open University of Cyprus (OUC), Nicosia, Cyprus; Cyber Security Research Group, University of Portsmouth, Portsmouth, UK; Cyber Security Research Group, University of Portsmouth, Portsmouth, UK; Department of Informatics and Telecommunications, University of Peloponnese, Tripolis, Greece","2021 IEEE International Conference on Cyber Security and Resilience (CSR)","6 Sep 2021","2021","","","129","134","Internal attacks are one of the biggest cybersecurity issues to companies and businesses. Despite the implemented perimeter security systems, the risk of adversely affecting the security and privacy of the organization’s information remains very high. Actually, the detection of such a threat is known to be a very complicated problem, presenting many challenges to the research community. In this paper, we investigate the effectiveness and usefulness of using Autoencoder and Variational Autoencoder deep learning algorithms to automatically defend against insider threats, without human intervention. The performance evaluation of the proposed models is done on the public CERT dataset (CERT r4.2) that contains both benign and malicious activities generated from 1000 simulated users. The comparison results with other models show that the Variational Autoencoder neural network provides the best overall performance with a higher detection accuracy and a reasonable false positive rate.","","978-1-6654-0285-9","10.1109/CSR51186.2021.9527925","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9527925","Deep Learning;Insider Threat;Network Security;Anomaly Detection","Deep learning;Performance evaluation;Privacy;Costs;Neural networks;Data models;Planning","data privacy;deep learning (artificial intelligence);security of data","insider threat detection;deep autoencoder;variational autoencoder neural networks;internal attacks;cybersecurity issues;perimeter security systems;privacy;organization information;variational autoencoder deep learning algorithms;public CERT dataset","","","","29","IEEE","6 Sep 2021","","","IEEE","IEEE Conferences"
"Fraud detection via deep neural variational autoencoder oblique random forest","N. T. N. Anh; T. Q. Khanh; N. Q. Dat; E. Amouroux; V. K. Solanki","SAMI, Hanoi University of Science and Technolog CIST, CMC Corporation, Hanoi, Vietnam; SAMI, Hanoi University of Science and Technology, Hanoi, Vietnam; SAMI, Hanoi University of Science and Technology, Hanoi, Vietnam; School of Science and Technology, RMIT University Vietnam, Ho Chi Minh, Vietnam; Dept of Computer Science and Engineering, CMR Institute of Technology, Hyderabad, TS, India","2020 IEEE-HYDCON","3 Nov 2020","2020","","","1","6","Fraud detection is critical problem of many financial company that has been researched both in academy organizes and industry. The objective of this paper is fraud detection for transaction level in credit card and e-commerce. The new machine learning model for fraud detection is proposed that deep neural variational autoencoder oblique random forest. Variational autoencoder is strong by regarding the distribution of latent variables and by the most optimal connecting weights between latent variables and visual variables are successful by maximizing log likelihood of observed variables. The proposed method is combined the advantage of variational autoencoder and oblique random forest for fraud detection problem. The proposed method is applied for two data sets being credit card data set and e-commerce data set. The experimental results show that the proposed method attains the better performance than the single or the other methods which used the same data sets.","","978-1-7281-4994-3","10.1109/HYDCON48903.2020.9242753","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9242753","Fraud detection;variational autoencoder;oblique random forest;classification;Deep neural","Industries;Visualization;Companies;Credit cards;Random forests","credit transactions;electronic commerce;fraud;learning (artificial intelligence);maximum likelihood estimation;neural nets;pattern classification","deep neural variational autoencoder oblique random forest;latent variables;fraud detection problem;transaction level;credit card;e-commerce;machine learning model;ptimal connecting weights;visual variables;variational autoencoder","","","","15","","3 Nov 2020","","","IEEE","IEEE Conferences"
"Recent Research and Applications in Variational Autoencoders for Industrial Prognosis and Health Management: A Survey","R. Zemouri; M. Lévesque; É. Boucher; M. Kirouac; F. Lafleur; S. Bernier; A. Merkhouf","Centre de Recherche d’Hydro-Québec (CRHQ), Varennes, Canada; Centre de Recherche d’Hydro-Québec (CRHQ), Varennes, Canada; Université de Montréal-MILA; Centre de Recherche d’Hydro-Québec (CRHQ), Varennes, Canada; Centre de Recherche d’Hydro-Québec (CRHQ), Varennes, Canada; Centre de Recherche d’Hydro-Québec (CRHQ), Varennes, Canada; Centre de Recherche d’Hydro-Québec (CRHQ), Varennes, Canada","2022 Prognostics and Health Management Conference (PHM-2022 London)","1 Jul 2022","2022","","","193","203","Whether in the industrial, medical, or real-world domains, more and more data are being collected. The common particularity of all these application domains is that a great part of this data is mostly unlabeled. Thus, designing a learning model with a minimum of labeled data represents a major challenge in the coming years. A particular emphasis has recently been put on unsupervised learning methods based on the idea of autoencoding. The objective of these methods is twofold: to reduce the dimensionality of the input space and to reconstruct the original observation from this lower dimensional representation space. The variational form of these autoencoders, called the Variational Autoencoders (VAEs), is particularly successful in almost all application areas. This enthusiasm comes from the fact that VAEs allow to take advantage of the theoretical foundations of the Variational Bayesian methods and the learning capabilities of artificial neural networks. This review paper gives to the PHM community a synthesis of the latest publications in the PHM domain using the VAEs related to four topics: 1) Data-Driven Soft Sensors for missing values and data outliers, 2) reconstruction error for fault detection, 3) resampling approach for imbalanced data generation and minority class and 4) the variational embedding as PHM preprocessing pipelines and data transformations. After a review of the theoretical foundations and some practical tricks to succeed the implementation of the VAEs in industrial applications, the four main topics used to exploit the VAEs in the PHM domain are detailed. Finally, a global view of the research done at the research institute of Hydro-Québec regarding the diagnosis and failure detection of hydro-generators with VAEs are presented.","2166-5656","978-1-6654-7954-7","10.1109/PHM2022-London52454.2022.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9808794","Variational Autoencoders;Deep learning;Prognosis and Health Management","Soft sensors;Fault detection;Pipelines;Learning (artificial intelligence);Artificial neural networks;Data models;Bayes methods","Bayes methods;fault diagnosis;learning (artificial intelligence);neural nets;unsupervised learning","Variational Autoencoders;industrial prognosis;health management;industrial world domains;medical, world domains;real-world domains;common particularity;great part;learning model;unsupervised learning methods;original observation;lower dimensional representation space;variational form;VAEs;Variational Bayesian methods;learning capabilities;artificial neural networks;PHM community;PHM domain;imbalanced data generation;minority class;variational embedding;PHM preprocessing pipelines;industrial applications;research institute","","1","","70","IEEE","1 Jul 2022","","","IEEE","IEEE Conferences"
"Conservative Policy Construction Using Variational Autoencoders for Logged Data With Missing Values","M. Abroshan; K. H. Yip; C. Tekin; M. van der Schaar","Alan Turing Institute, London NW1 2DB, U.K. (e-mail: mabroshan@turing.ac.uk); University College London, London WC1E 6BT, U.K..; Department of Electrical and Electronics Engineering, Bilkent University, 06800 Ankara, Turkey.; Department of Applied Mathematics and Theoretical Physics, University of Cambridge, Cambridge CB2 1TN, U.K., also with the Alan Turing Institute, London NW1 2DB, U.K., and also with the University of California, Los Angeles, CA 90095 USA.","IEEE Transactions on Neural Networks and Learning Systems","","2022","PP","99","1","11","In high-stakes applications of data-driven decision-making such as healthcare, it is of paramount importance to learn a policy that maximizes the reward while avoiding potentially dangerous actions when there is uncertainty. There are two main challenges usually associated with this problem. First, learning through online exploration is not possible due to the critical nature of such applications. Therefore, we need to resort to observational datasets with no counterfactuals. Second, such datasets are usually imperfect, additionally cursed with missing values in the attributes of features. In this article, we consider the problem of constructing personalized policies using logged data when there are missing values in the attributes of features in both training and test data. The goal is to recommend an action (treatment) when ~X, a degraded version of Xwith missing values, is observed. We consider three strategies for dealing with missingness. In particular, we introduce the conservative strategy where the policy is designed to safely handle the uncertainty due to missingness. In order to implement this strategy, we need to estimate posterior distribution p(X|~X) and use a variational autoencoder to achieve this. In particular, our method is based on partial variational autoencoders (PVAEs) that are designed to capture the underlying structure of features with missing values.","2162-2388","","10.1109/TNNLS.2021.3136385","Wave 1 of the UK Research and Innovation UKRI Strategic Priorities Fund(grant numbers:EPSRC Grant EP/T001569/1,EP/W006022/1, particularly the ``Health'' and ``Criminal Justice System'' themes within those grants); Alan Turing Institute; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9675815","Missing values;observational data;policy construction;variational autoencoder","Uncertainty;Estimation;Task analysis;IP networks;Noise measurement;Tuning;Training data","","","","","","","IEEE","10 Jan 2022","","","IEEE","IEEE Early Access Articles"
"A Deep-Learning Method for Device Activity Detection in mMTC Under Imperfect CSI Based on Variational-Autoencoder","T. Zhao; F. Li; P. Tian","School of Information and Communications Engineering, Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; School of Information and Communications Engineering, Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; School of Information and Communications Engineering, Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China","IEEE Transactions on Vehicular Technology","15 Jul 2020","2020","69","7","7981","7986","Large-scale deployment of massive device connectivity is a crucial communication challenge for Internet of Things (IoT) networks, which consist of a huge number of devices with sporadic traffic. In massive Machine Communication Scenario (mMTC), it is very important for the serving base-station (BS) to identify the active devices in each coherence block. This paper proposes a deep neural network (DNN) based on variational autoencoder (VAE) for device activity detection in mMTC under imperfect channel state information (CSI). A framework of variational optimization is constructed and the learning network structure is also designed. The derivation on the loss function for network training is presented and numerical results are provided to illustrate the accuracy of our method. The performance demonstrates the merits of the proposed method by comparison with the traditional compressed sensing algorithms, which are widely applied in multi-user detection.","1939-9359","","10.1109/TVT.2020.2992080","Fundamental Research Funds for the Central Universities(grant numbers:xzy012019047); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9085960","Activity detection;deep neural network;massive machine communication scenario;variational-autoencoder","Compressed sensing;Channel estimation;Neural networks;Coherence;Channel state information;Deep learning;Partial transmit sequences","compressed sensing;Internet of Things;learning (artificial intelligence);multiuser detection;neural nets;telecommunication network planning","large-scale deployment;massive device connectivity;Internet of Things networks;sporadic traffic;mMTC;serving base-station;active devices;deep neural network;variational autoencoder;device activity detection;imperfect channel state information;variational optimization;learning network structure;network training;multiuser detection;imperfect CSI;variational-autoencoder;massive machine communication scenario;compressed sensing algorithms","","9","","23","IEEE","4 May 2020","","","IEEE","IEEE Journals"
"Parallel Interaction Spatiotemporal Constrained Variational Autoencoder for Soft Sensor Modeling","X. Zhu; S. K. Damarla; K. Hao; B. Huang","Engineering Research Center of Digitized Textile and Apparel Technology, Donghua University, Shanghai, China; Department of Chemical and Materials Engineering, University of Alberta, Edmonton, AB, Canada; Engineering Research Center of Digitized Textile and Apparel Technology, Donghua University, Shanghai, China; Department of Chemical and Materials Engineering, University of Alberta, Edmonton, AB, Canada","IEEE Transactions on Industrial Informatics","10 May 2022","2022","18","8","5190","5198","Data-driven soft sensors have been widely used in industrial processes for over two decades. Industrial processes often exhibit nonlinear and time-varying behavior due to complex physical and chemical mechanisms, feedback control, and dynamic noise. Lately, variational autoencoder (VAE) has arisen as one of the most prevalent methods for unsupervised learning of intricate distributions. Despite being successful in deep feature extraction and uncertain data modeling, it still suffers from instability and reconstruction error due to random sampling in the latent subspace representation of original input space. In this article, to deal with those limitations, constrained VAE (CVAE) is proposed by utilizing input sample information. Enthused by parallel interaction mechanism between the ventral and dorsal stream of the human brain in object recognition, parallel interaction spatial-temporal CVAE (PIST-CVAE) is proposed to extract spatial and temporal features from input samples. Lower dimensional nonlinear features extracted from PIST-CVAE are used to build the soft sensor. The effectiveness of CVAE and PIST-CVAE is demonstrated in an industrial case study, a polyester polymerization process. The obtained results demonstrate that CVAE is able to reconstruct inputs with higher accuracy and the proposed PIST-CVAE-based soft sensor yields more accurate estimations for the melt viscosity index of the polymerization process.","1941-0050","","10.1109/TII.2021.3110197","Ministry of Science and Technology(grant numbers:2016YFB0302701); Fundamental Research Funds for the Central Universities(grant numbers:2232021A-10,2232021D-36); Natural Science Foundation of Shanghai(grant numbers:19ZR1402300); Donghua University(grant numbers:CUSF-DH-D-2020078); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9529025","Convolutional neural network (CNN);constrained variational autoencoder (VAE);long short-term memory (LSTM);parallel interaction mechanism;polyester polymerization process;variational autoencoder","Feature extraction;Convolution;Logic gates;Informatics;Polymers;Mathematical model;Kernel","feature extraction;image coding;learning (artificial intelligence);neural nets;object recognition;polymerisation;production engineering computing;soft sensors;spatiotemporal phenomena;statistical analysis;unsupervised learning;viscosity","parallel interaction spatiotemporal constrained variational autoencoder;soft sensor modeling;data-driven soft sensors;industrial processes;time-varying behavior;complex physical mechanisms;chemical mechanisms;feedback control;dynamic noise;unsupervised learning;deep feature extraction;uncertain data;reconstruction error;random sampling;latent subspace representation;constrained VAE;ventral stream;dorsal stream;parallel interaction spatial-temporal CVAE;lower dimensional nonlinear features;polyester polymerization process;PIST-CVAE-based soft sensor","","","","25","IEEE","3 Sep 2021","","","IEEE","IEEE Journals"
"A Recurrent Variational Autoencoder for Speech Enhancement","S. Leglaive; X. Alameda-Pineda; L. Girin; R. Horaud","CentraleSupélec, IETR, France; Inria Grenoble Rhône-Alpes, France; Inria Grenoble Rhône-Alpes, France; Inria Grenoble Rhône-Alpes, France","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","371","375","This paper presents a generative approach to speech enhancement based on a recurrent variational autoencoder (RVAE). The deep generative speech model is trained using clean speech signals only, and it is combined with a nonnegative matrix factorization noise model for speech enhancement. We propose a variational expectation-maximization algorithm where the encoder of the RVAE is finetuned at test time, to approximate the distribution of the latent variables given the noisy speech observations. Compared with previous approaches based on feed-forward fully-connected architectures, the proposed recurrent deep generative speech model induces a posterior temporal dynamic over the latent variables, which is shown to improve the speech enhancement results.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9053164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9053164","Speech enhancement;recurrent variational autoencoders;nonnegative matrix factorization;variational inference","Heuristic algorithms;Signal processing algorithms;Speech enhancement;Signal processing;Markov processes;Approximation algorithms;Noise measurement","expectation-maximisation algorithm;feedforward neural nets;matrix decomposition;recurrent neural nets;speech enhancement","nonnegative matrix factorization noise model;variational expectation-maximization algorithm;RVAE;noisy speech observations;recurrent deep generative speech model;speech enhancement results;recurrent variational autoencoder;generative approach","","12","","40","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Variational and Hierarchical Recurrent Autoencoder","J. -T. Chien; C. -W. Wang","Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","3202","3206","Despite a great success in learning representation for image data, it is challenging to learn the stochastic latent features from natural language based on variational inference. The difficulty in stochastic sequential learning is due to the posterior collapse caused by an autoregressive decoder which is prone to be too strong to learn sufficient latent information during optimization. To compensate this weakness in learning procedure, a sophisticated latent structure is required to assure good convergence so that random features are sufficiently captured for sequential decoding. This study presents a new variational recurrent autoencoder (VRAE) for sequence reconstruction. There are two complementary encoders consisting of a long short-term memory (LSTM) and a pyramid bidirectional LSTM which are merged to discover the global and local dependencies in a hierarchical latent variable model, respectively. Experiments on Penn Treebank and Yelp 2013 demonstrate that the proposed hierarchical VRAE is able to learn the complementary representation as well as tackle the posterior collapse in stochastic sequential learning. The performance of recurrent autoencoder is substantially improved in terms of perplexity.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683771","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683771","Sequence generation;recurrent neural network;variational autoencoder;hierarchical model","","image representation;learning (artificial intelligence);natural language processing;recurrent neural nets;stochastic processes","stochastic latent features;natural language;variational inference;stochastic sequential learning;autoregressive decoder;sequential decoding;variational recurrent autoencoder;hierarchical latent variable model;hierarchical VRAE;hierarchical recurrent autoencoder;long short-term memory;pyramid bidirectional LSTM","","15","","31","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Traffic Identification of Mobile Apps Based on Variational Autoencoder Network","D. Li; Y. Zhu; W. Lin","Information Engineering University, Zhengzhou, China; Information Engineering University, Zhengzhou, China; Information Engineering University, Zhengzhou, China","2017 13th International Conference on Computational Intelligence and Security (CIS)","12 Feb 2018","2017","","","287","291","Traffic identification is a fundamental issue in network security. Traditional methods, such as depth packet inspection (DPI) and flow-based classifiers, have difficulties in labeling massive samples and extracting features manually. Motivated by the achievements in computer vision, we focus on mobile app traffic, proposing a deep learning model based on variational autoencoder network (VEAN). Our contributions are two-fold. First, we propose a novel method of transforming mobile app traffic flows into vision-meaningful images, and thus enable the machine to identify the traffic in a human way. Then, based on the transformation method, we create an open dataset named IMTD17. Second, an improved network model is proposed, where variational autoencoder (VAE) algorithm is introduced into a two-stage learning. The model realizes the learning from massive unlabeled data, and the feasibility of the replacement for manual feature extraction is illustrated by the visualization analysis of the latent features. The experimental results show that the identification accuracy can reach 99.6%, which satisfies the practical requirement.","","978-1-5386-4822-3","10.1109/CIS.2017.00069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8288491","traffic identification;mobile app;latent feature;variational autoencoder","Handheld computers;Computational intelligence;Security;Mobile communication;Data mining;Feature extraction;Visualization","computer network security;computer vision;feature extraction;learning (artificial intelligence);mobile computing;neural nets;telecommunication traffic","traffic identification;mobile apps;variational autoencoder network;network security;depth packet inspection;computer vision;mobile app traffic;deep learning model;vision-meaningful images;transformation method;improved network model;variational autoencoder algorithm;manual feature extraction;identification accuracy;feature extraction","","10","","17","","12 Feb 2018","","","IEEE","IEEE Conferences"
"Condition-transforming Variational Autoencoder for Conversation Response Generation","Y. -P. Ruan; Z. -H. Ling; Q. Liu; Z. Chen; N. Indurkhya","National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China, Hefei, P.R.China; National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China, Hefei, P.R.China; iFLYTEK Research, Hefei, P.R. China; iFLYTEK Research, Hefei, P.R. China; National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China, Hefei, P.R.China","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","7215","7219","This paper proposes a new model, called condition-transforming variational autoencoder (CTVAE), to improve the performance of conversation response generation using conditional variational autoencoders (CVAEs). In conventional CVAEs , the prior distribution of latent variable z follows a multivariate Gaussian distribution with mean and variance modulated by the input conditions. Previous work found that this distribution tends to become condition-independent in practical application. In our proposed CTVAE model, the latent variable z is sampled by performing a non-linear transformation on the combination of the input conditions and the samples from a condition-independent prior distribution N(0,I). In our objective evaluations, the CTVAE model outperforms the CVAE model on fluency metrics and surpasses a sequence-to-sequence (Seq2Seq) model on diversity metrics. In subjective preference tests, our proposed CTVAE model performs significantly better than CVAE and Seq2Seq models on generating fluency, informative and topic relevant responses.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683853","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683853","variational;autoencoders;conversation;text generation","Decoding;Training;Gaussian distribution;Measurement;Task analysis;Testing","Gaussian distribution;neural nets","CTVAE model;sequence-to-sequence model;conversation response generation;conditional variational autoencoders;multivariate Gaussian distribution;input conditions;nonlinear transformation;condition-transforming variational autoencoder;condition-independent prior distribution","","2","","25","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Radar Image Reconstruction from Raw ADC Data using Parametric Variational Autoencoder with Domain Adaptation","M. Stephan; T. Stadelmayer; A. Santra; G. Fischer; R. Weigel; F. Lurz","Infineon Technologies AG, Neubiberg, Germany; Infineon Technologies AG, Neubiberg, Germany; Infineon Technologies AG, Neubiberg, Germany; Friedrich-Alexander-University Erlangen-Nuremberg, Erlangen, Germany; Friedrich-Alexander-University Erlangen-Nuremberg, Erlangen, Germany; Friedrich-Alexander-University Erlangen-Nuremberg, Erlangen, Germany","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","9529","9536","This paper presents a parametric variational autoencoder-based human target detection and localization framework working directly with the raw analog-to-digital converter data from the frequency modulated continuous wave radar. We propose a parametrically constrained variational autoencoder, with residual and skip connections, capable of generating the clustered and localized target detections on the range-angle image. Furthermore, to circumvent the problem of training the proposed neural network on all possible scenarios using real radar data, we propose domain adaptation strategies whereby we first train the neural network using ray tracing based model data and then adapt the network to work on real sensor data. This strategy ensures better generalization and scalability of the proposed neural network even though it is trained with limited radar data. We demonstrate the superior detection and localization performance of our proposed solution compared to the conventional signal processing pipeline and earlier state-of-art deep U-Net architecture with range-doppler images as inputs.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9412858","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9412858","Detection and Localization;Parametric Deep Neural Network;Variational Autoencoder;Domain Adaptation","Location awareness;Training;Adaptation models;Computational modeling;Neural networks;Radar;Object detection","analogue-digital conversion;CW radar;FM radar;image reconstruction;learning (artificial intelligence);neural nets;object detection;radar computing;radar imaging;ray tracing;target tracking","range-doppler images;radar image reconstruction;raw ADC data;parametric variational autoencoder-based human target detection;localization framework;analog-to-digital converter data;parametrically constrained variational autoencoder;residual connections;skip connections;clustered localized target detections;range-angle image;neural network;radar data;domain adaptation strategies;based model data;sensor data;superior detection;localization performance","","2","","20","","5 May 2021","","","IEEE","IEEE Conferences"
"Establishing Convolutional Neural Network Kalman Recurrent Variational Autoencoder Using Infrared Imaging for Process Monitoring: An Application in Spinning Disk Processes","Y. Zhang; Y. S. Lee; H. Lin; J. Chen","Department of Chemical Engineering, Chung Yuan Christian University, Taoyuan, Taiwan; Department of Chemical Engineering, Chung Yuan Christian University, Taoyuan, Taiwan; Department of Chemical Engineering, National Taiwan University, Taipei, Taiwan; Department of Chemical Engineering, Chung Yuan Christian University, Taoyuan, Taiwan","IEEE Transactions on Instrumentation and Measurement","23 Feb 2022","2022","71","","1","12","The measurements for thermal changes are commonly mounted only at the fixed location in the operating process. In this article, to comprehensively understand the thermal inhomogeneity and the sampling variances, the nondestructive evaluation of infrared measurement is used to record real-time thermal changes. With the thermal image data, a data-driven deep dynamic latent variable model named the convolutional neural network-Kalman recurrent variational autoencoder (CNN-KRVAE) is proposed. It is constructed based on image data instead of sensor-measured data. The convolutional neural network is used to extract the important spatial thermal distribution features in the image data. Furthermore, the dynamic characteristics of the thermal information are represented by the Markov state-space relationship between the latent variables in the latent space. Moreover, the probabilistic model, variational autoencoder (VAE), is embedded in the model to describe the uncertainty in the process. Consequently, the probability density estimates instead of the point estimates are established to form the distribution-based monitoring indices in the latent and residual spaces. To verify the modeling and monitoring performance of the proposed model, CNN-KRVAE is used for an experiment of the spinning disk process.","1557-9662","","10.1109/TIM.2021.3126381","Ministry of Science and Technology, Taiwan(grant numbers:MOST 109-2221-E-033-013-MY3,MOST 110-2221-E-007-014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9606679","Infrared imaging;process monitoring;recurrent convolutional neural network (RCNN);spinning disk process (SDP);variational autoencoder (VAE)","Convolutional neural networks;Temperature measurement;Spinning;Solid modeling;Imaging;Process monitoring;Heat transfer","computerised instrumentation;convolutional neural nets;estimation theory;infrared imaging;Kalman filters;Markov processes;probability;process monitoring;state-space methods","convolutional neural network Kalman recurrent variational autoencoder;infrared imaging;process monitoring;disk processes;operating process;thermal inhomogeneity;infrared measurement;real-time thermal changes;thermal image data;data-driven deep dynamic latent variable model;convolutional neural network-Kalman recurrent variational autoencoder;sensor-measured data;important spatial thermal distribution features;thermal information;spinning disk process","","1","","34","IEEE","8 Nov 2021","","","IEEE","IEEE Journals"
"Reference-based Image Super-Resolution by Dual-Variational AutoEncoder","M. Yang; J. Qi","China Aerospace Academy of Systems Science and Engineering, Beijing, 100037, China; China Aerospace Academy of Systems Science and Engineering, Beijing, 100037, China","2021 International Conference on Communications, Computing, Cybersecurity, and Informatics (CCCI)","27 Oct 2021","2021","","","1","5","Due to severe information loss of low-resolution images, the development of single-image super-resolution methods is limited. Recently, the reference-based image super-resolution methods, which super-resolve the low-resolution inputs with the guidance of high-resolution reference images are emerging. In this paper, we design a Dual-Variational AutoEncoder (DVAE) for reference-based image super-resolution task, which can learn the high-frequency information and latent distribution of the high-resolution reference images as priors to improve the restoration quality of image super-resolution. Moreover, a hierarchical variational autoencoder strategy is exploited to further study latent space. Complementary to a quantitative evaluation, we demonstrate the effectiveness of the proposed approach.","","978-1-6654-3208-5","10.1109/CCCI52664.2021.9583193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9583193","Variational AutoEncoder;Reference-based Image Super-Resolution;CNN;Residual Learning","Superresolution;Telecommunication computing;Image restoration;Task analysis;Informatics;Computer security","image resolution;learning (artificial intelligence)","severe information loss;low-resolution images;single-image super-resolution methods;reference-based image super-resolution methods;low-resolution inputs;high-resolution reference images;hierarchical variational autoencoder strategy;dual-variational autoencoder;DVAE;high-frequency information learning","","","","23","IEEE","27 Oct 2021","","","IEEE","IEEE Conferences"
"Deep convolution variational autoencoder network based transfer learning strategy for fault diagnosis","B. She; H. Zhang; J. Wang","Department of Weaponry Engineering, Naval University of Engineering, Wuhan, China; Department of Weaponry Engineering, Naval University of Engineering, Wuhan, China; Department of Weaponry Engineering, Naval University of Engineering, Wuhan, China","2021 International Conference on Digital Society and Intelligent Systems (DSInS)","10 Jan 2022","2021","","","378","384","The successful application of traditional machine learning to mechanical fault diagnosis relies on two conditions: the same probability distribution of training data and testing data, and the data containing fault information has labels. However, it is difficult to obtain massive labeled data, and the change of mechanical operation conditions also results in inconsistent distribution of source domain data and target domain data, which makes the labeled data for training model possibly fail in classifying unlabeled data acquired under other conditions. Aiming at solving the above problems, a deep convolution variational autoencoder network is introduced, the pseudo-label information of small samples in target domain is predicted by using label propagation and data fusion methods, combining with the domain adaptability advantages of transfer learning theory, a novel diagnosis method based on transfer learning with deep convolution variational autoencoder (TL-DCVAEN) is presented. In addition, the spectrum data is used as the input of the model to reduce the dependence on artificial feature design and engineering experience. The experimental results indicate that the proposed diagnosis method is suitable for rolling bearing fault diagnosis under variable working conditions, and has better diagnostic performance and generalization.","","978-1-6654-0630-7","10.1109/DSInS54396.2021.9670578","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9670578","convolution;variational autoencoder;transfer learning;label propagation;bearing;fault diagnosis","Fault diagnosis;Training;Employee welfare;Adaptation models;Convolution;Transfer learning;Training data","deep learning (artificial intelligence);fault diagnosis;mechanical engineering computing;rolling bearings;sensor fusion;signal classification;statistical distributions","traditional machine learning;mechanical fault diagnosis;probability distribution;mechanical operation conditions;source domain data;target domain data;deep convolution variational autoencoder network;pseudolabel information;label propagation;rolling bearing fault diagnosis;deep convolution variational autoencoder network based transfer learning strategy;data fusion method;TL-DCVAEN;artificial feature design","","","","20","IEEE","10 Jan 2022","","","IEEE","IEEE Conferences"
"Discriminative Mixture Variational Autoencoder for Semisupervised Classification","J. Chen; L. Du; L. Liao","National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China","IEEE Transactions on Cybernetics","19 May 2022","2022","52","5","3032","3046","In this article, a deep probability model, called the discriminative mixture variational autoencoder (DMVAE), is developed for the feature extraction in semisupervised learning. The DMVAE consists of three parts: 1) the encoding; 2) decoding; and 3) classification modules. In the encoding module, the encoder projects the observation to the latent space, and then the latent representation is fed to the decoding part, which depicts the generative process from the hidden variable to data. In particular, the decoding module in our DMVAE partitions the observed dataset into some clusters via multiple decoders whose number is automatically determined via the Dirichlet process (DP) and learns a probability distribution for each cluster. Compared to the standard variational autoencoder (VAE) describing all data with a single probability function, the DMVAE has the capacity to give a more accurate description for observations, thus improving the characterization ability of the extracted features, especially for the data with complex distribution. Moreover, to obtain a discriminative latent space, the class labels of labeled data are introduced to restrict the feature learning via a softmax classifier, with which the minimum entropy of the predicted labels for the features from unlabeled data can also be guaranteed. Finally, the joint optimization of the marginal likelihood, label, and entropy constraints makes the DMVAE have higher classification confidence for unlabeled data while accurately classifying the labeled data, ultimately leading to better performance. Experiments on several benchmark datasets and the measured radar echo dataset show the advantages of our DMVAE-based semisupervised classification over other related methods.","2168-2275","","10.1109/TCYB.2020.3023019","National Science Foundation of China(grant numbers:61771362); Higher Education Discipline Innovation Project(grant numbers:B18039); Shaanxi Innovation Team Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9216561","Dirichlet process (DP) mixture;discriminative representation;semisupervised learning;variational autoencoder~(VAE)","Decoding;Data models;Probabilistic logic;Feature extraction;Entropy;Radar;Task analysis","entropy;feature extraction;learning (artificial intelligence);pattern classification;probability;statistical distributions","discriminative mixture variational autoencoder;deep probability model;feature extraction;semisupervised learning;encoding module;encoder;latent representation;decoding part;generative process;decoding module;DMVAE partitions;observed dataset;multiple decoders whose number;Dirichlet process;probability distribution;standard variational autoencoder;single probability function;discriminative latent space;unlabeled data;classification confidence;DMVAE-based semisupervised classification","Supervised Machine Learning","","","41","IEEE","7 Oct 2020","","","IEEE","IEEE Journals"
"Sequential Learning and Regularization in Variational Recurrent Autoencoder","J. -T. Chien; C. -J. Tsai","Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan","2020 28th European Signal Processing Conference (EUSIPCO)","18 Dec 2020","2021","","","1613","1617","Latent variable model based on variational autoen-coder (VAE) is influential in machine learning for signal processing. VAE basically suffers from the issue of posterior collapse in sequential learning procedure where the variational posterior easily collapses to a prior as standard Gaussian. Latent semantics are then neglected in optimization process. The recurrent decoder therefore generates noninformative or repeated sequence data. To capture sufficient latent semantics from sequence data, this study simultaneously fulfills an amortized regularization for encoder, extends a Gaussian mixture prior for latent variable, and runs a skip connection for decoder. The noise robust prior, learned from the amortized encoder, is likely aware of temporal features. A variational prior based on the amortized mixture density is formulated in implementation of variational recurrent autoencoder for sequence reconstruction and representation. Owing to skip connection, the sequence samples are continuously predicted in decoder with contextual precision at each time step. Experiments on language model and sentiment classification show that the proposed method mitigates the issue of posterior collapse and learns the meaningful latent features to improve the inference and generation for semantic representation.","2076-1465","978-9-0827-9705-3","10.23919/Eusipco47968.2020.9287616","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287616","sequential learning;Bayesian learning;recurrent neural network;variational autoencoder;language model","Smoothing methods;Semantics;Signal processing;Decoding;Task analysis;Standards;Optimization","approximation theory;Bayes methods;expectation-maximisation algorithm;Gaussian processes;learning (artificial intelligence);mixture models;neural nets;pattern classification","signal processing;VAE;posterior collapse;sequential learning procedure;standard Gaussian;optimization process;recurrent decoder;repeated sequence data;latent semantics;amortized regularization;Gaussian mixture;amortized encoder;amortized mixture density;variational recurrent autoencoder;sequence reconstruction;sequence samples;language model;latent features;semantic representation;latent variable model;machine learning;variational autoencoder;sentiment classification","","1","","34","","18 Dec 2020","","","IEEE","IEEE Conferences"
"Community Detection Based on Multiobjective Particle Swarm Optimization and Graph Attention Variational Autoencoder","K. Guo; Z. Chen; X. Lin; L. Wu; Z. -H. Zhan; Y. Chen; W. Guo","College of Computer and Data Science, Fuzhou University, 12423 Fuzhou, Fujian, China; College of Computer and Data Science, Fuzhou University, 12423 Fuzhou, Fujian, China; College of Computer and Data Science, Fuzhou University, 12423 Fuzhou, Fujian, China; College of Computer and Data Science, Fuzhou University, 12423 Fuzhou, Fujian, China; School of Computer Science and Engineering, South China University of Technology, 26467 Guangzhou, Guangdong, China, 510006; College of Computer and Data Science, Fuzhou University, 12423 Fuzhou, Fujian, China; College of Computer and Data Science, Fuzhou University, 12423 Fuzhou, Fujian, China","IEEE Transactions on Big Data","","2022","PP","99","1","1","Community detection is an important research direction in complex network analysis that can help us discover valuable network structures. The community detection algorithms based on multiobjective particle swarm optimization encode community membership of nodes in particles and employ evolutionary strategies to search for the optimal community division. Existing algorithms face two challenges: (1) they are inapplicable to large networks because the evolution process is time-consuming; (2) they are easy to fall into local optima. In this paper, we propose a novel algorithm that combines a multiobjective particle swarm optimization algorithm based on label propagation with a graph attention variational autoencoder to realize community detection. On the one hand, the label propagation strategy is involved in the update of a swarm's particles to speed up its evolution. The optimal solutions found by the particle swarm optimization algorithm are embedded into the objective of the autoencoder to improve the embedding vectors quality. On the other hand, the embedding vectors are used to improve the solutions of the particle swarm optimization algorithm to avoid its early convergence. The experiments on artificial and real-world networks demonstrate the feasibility and effectiveness of our algorithm compared with the state-of-the-art algorithms.","2332-7790","","10.1109/TBDATA.2022.3164916","the Major Science and Technology Project of Fujian Province(grant numbers:No.2021HZ022007); National Key Research and Development Plan of China(grant numbers:No.2021YFB3600503); Fujian Collaborative Innovation Center for Big Data Applications in Governments; National Natural Science Foundation of China(grant numbers:No. 62002063,No.U21A20472); Department of Education, Fujian Province(grant numbers:No.JAT190026); Natural Science Foundation of Fujian Province(grant numbers:No.2020J05112); Haixi Government Big Data Application Cooperative Innovation Center; Fujian Industry-Academy Cooperation Project(grant numbers:No. 2017H6008,No. 2018H6010); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9749841","community detection;label propagation;multiobjective particle swarm optimization;graph attention variational autoencoder","Optimization;Particle swarm optimization;Convergence;Search problems;Prediction algorithms;Detection algorithms;Big Data","","","","","","","IEEE","5 Apr 2022","","","IEEE","IEEE Early Access Articles"
"A VARIANCE MODELING FRAMEWORK BASED ON VARIATIONAL AUTOENCODERS FOR SPEECH ENHANCEMENT","S. Leglaive; L. Girin; R. Horaud","Inria Grenoble Rhône-Alpes, France; Inria Grenoble Rhône-Alpes, France; Inria Grenoble Rhône-Alpes, France","2018 IEEE 28th International Workshop on Machine Learning for Signal Processing (MLSP)","1 Nov 2018","2018","","","1","6","In this paper we address the problem of enhancing speech signals in noisy mixtures using a source separation approach. We explore the use of neural networks as an alternative to a popular speech variance model based on supervised non-negative matrix factorization (NMF). More precisely, we use a variational autoencoder as a speaker-independent supervised generative speech model, highlighting the conceptual similarities that this approach shares with its NMF-based counterpart. In order to be free of generalization issues regarding the noisy recording environments, we follow the approach of having a supervised model only for the target speech signal, the noise model being based on unsupervised NMF. We develop a Monte Carlo expectation-maximization algorithm for inferring the latent variables in the variational autoencoder and estimating the unsupervised model parameters. Experiments show that the proposed method outperforms a semi-supervised NMF baseline and a state-of-the-art fully supervised deep learning approach.","1551-2541","978-1-5386-5477-4","10.1109/MLSP.2018.8516711","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516711","Audio source separation;speech enhancement;variational autoencoders;non-negative matrix factorization;Monte Carlo expectation-maximization","Speech enhancement;Noise measurement;Monte Carlo methods;Time-frequency analysis;Source separation;Neural networks","encoding;expectation-maximisation algorithm;learning (artificial intelligence);matrix decomposition;Monte Carlo methods;optimisation;source separation;speech enhancement;variational techniques","NMF-based counterpart;noisy recording environments;noise model;unsupervised NMF;Monte Carlo expectation-maximization algorithm;variational autoencoder;unsupervised model parameters;semisupervised NMF baseline;variance modeling framework;noisy mixtures;source separation approach;neural networks;speaker-independent supervised generative speech model;conceptual similarities;supervised deep learning approach;supervised nonnegative matrix factorization;speech variance model;speech signal enhancement;latent variables","","28","","28","","1 Nov 2018","","","IEEE","IEEE Conferences"
"Combining an Autoencoder and a Variational Autoencoder for Explaining the Machine Learning Model Predictions","L. Utkin; P. Drobintsev; M. Kovalev; A. Konstantinov","Peter the Great St.Petersburg Polytechnic University, St.Petersburg, Russia; Peter the Great St.Petersburg Polytechnic University, St.Petersburg, Russia; Peter the Great St.Petersburg Polytechnic University, St.Petersburg, Russia; Peter the Great St.Petersburg Polytechnic University, St.Petersburg, Russia","2021 28th Conference of Open Innovations Association (FRUCT)","11 Feb 2021","2021","","","489","494","A method for explaining a deep learning model prediction is proposed. It uses a combination of the standard autoencoder and the variational autoencoder. The standard autoencoder is exploited to reconstruct original images and to produce hidden representation vectors. The variational autoencoder is trained to transform the deep learning model outputs (embedding vectors) into the hidden representation vectors of the standard autoencoder. In explaining or testing phase, the variational autoencoder produces a set of vectors based on the explained image embedding. Then the trained decoder part of the standard autoencoder reconstructs a set of images which form a heatmap explaining the original explained image. In fact, the variational autoencoder plays a role of the perturbation technique of images. Numerical experiments with the well-known datasets MNIST and CIFAR10 illustrate the propose method.","2305-7254","978-9-5269-2444-1","10.23919/FRUCT50888.2021.9347612","RFBR(grant numbers:19-29-01004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9347612","","Training;Deep learning;Transforms;Predictive models;Numerical models;Standards;Image reconstruction","deep learning (artificial intelligence);image representation;vectors","variational autoencoder;hidden representation vectors;explained image embedding;standard autoencoder;deep learning model prediction;embedding vectors;image reconstruction;heatmap;perturbation technique;CIFAR10;MNIST","","1","","55","","11 Feb 2021","","","IEEE","IEEE Conferences"
"Sub-band Vector Quantized Variational AutoEncoder for Spectral Envelope Quantization","T. Srikotr; K. Mano","Division of Funtional Control Systems, Shibaura Institute of Technology, Japan; Division of Funtional Control Systems, Shibaura Institute of Technology, Japan","TENCON 2019 - 2019 IEEE Region 10 Conference (TENCON)","12 Dec 2019","2019","","","296","300","Recently, a lot of deep learning model successful in taking over conventional methods in speech processing fields. Vector quantization is a popular technique to reduce the amount of speech data before transmitting. The conventional vector quantization method is based on the mathematical model. Last few years, the Vector Quantized Variational AutoEncoder has been proposed for an end-to-end vector quantization based on deep learning techniques. In this paper, we investigate the sub-band quantization in the Vector Quantized Variational AutoEncoder. This model can concentrate on specific frequency bands to assign more bits and leave the unnecessary band with few bits. Experimental results show the efficiency of the proposed quantization method for the spectral envelope parameters of the high-quality vocoder that operates at 48 kHz sampling frequency named WORLD vocoder. At the same four target bit rates, the sub-band Vector Quantized Variational AutoEncoder can reduce the Log Spectral Distortion around 0.93 dB in average.","2159-3450","978-1-7281-1895-6","10.1109/TENCON.2019.8929436","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8929436","vector quantization;autoencoder;vector quantized variational autoencoder;sub-band coding","Convolution;Vocoders;Shape;Decoding;Quantization (signal);Speech processing;Mathematical model","learning (artificial intelligence);spectral analysis;speech coding;vector quantisation;vocoders","log spectral distortion;target bit rates;WORLD vocoder;high-quality vocoder;specific frequency bands;mathematical model;speech data;speech processing fields;sub-band vector quantized variational autoencoder;end-to-end vector quantization;conventional vector quantization method;deep learning model;Spectral envelope quantization;frequency 48.0 kHz","","","","29","","12 Dec 2019","","","IEEE","IEEE Conferences"
"Variational Autoencoder-Based Vehicle Trajectory Prediction with an Interpretable Latent Space","M. Neumeier; M. Botsch; A. Tollkühn; T. Berberich","Technische Hochschule Ingolstadt, CARISSMA Institute of Automated Driving (C-IAD), Ingolstadt; Technische Hochschule Ingolstadt, CARISSMA Institute of Automated Driving (C-IAD), Ingolstadt; AUDI AG, Ingolstadt; AUDI AG, Ingolstadt","2021 IEEE International Intelligent Transportation Systems Conference (ITSC)","25 Oct 2021","2021","","","820","827","This paper introduces the Descriptive Variational Autoencoder (DVAE), an unsupervised and end-to-end trainable neural network for predicting vehicle trajectories that provides partial interpretability. The novel approach is based on the architecture and objective of common variational autoencoders. By introducing expert knowledge within the decoder part of the autoencoder, the encoder learns to extract latent parameters that provide a graspable meaning in human terms. Such an interpretable latent space enables the validation by expert defined rule sets. The evaluation of the DVAE is performed using the publicly available highD dataset for highway traffic scenarios. In comparison to a conventional variational autoencoder with equivalent complexity, the proposed model provides a similar prediction accuracy but with the great advantage of having an interpretable latent space. For crucial decision making and assessing trustworthiness of a prediction this property is highly desirable.","","978-1-7281-9142-3","10.1109/ITSC48978.2021.9565120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9565120","","Training;Space vehicles;Road transportation;Systematics;Neural networks;Predictive models;Trajectory","decision making;learning (artificial intelligence);neural nets;parameter estimation","Variational Autoencoder-based vehicle trajectory prediction;interpretable latent space;Descriptive Variational Autoencoder;DVAE;unsupervised end-to-end trainable neural network;vehicle trajectories;partial interpretability;common variational autoencoders;latent parameters;expert defined rule sets;conventional variational autoencoder;similar prediction accuracy;prediction this property","","1","","24","IEEE","25 Oct 2021","","","IEEE","IEEE Conferences"
"Evaluating Variational Autoencoder as a Private Data Release Mechanism for Tabular Data","S. -C. Li; B. -C. Tai; Y. Huang","Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan","2019 IEEE 24th Pacific Rim International Symposium on Dependable Computing (PRDC)","9 Jan 2020","2019","","","198","1988","Multi-market businesses can collect data from different business entities and aggregate data from various sources to create value. However, due to the restriction of privacy regulation, it could be illegal to exchange data between business entities of the same parent company, unless the users have opted-in to allow it. Regulations such as the EU's GDPR allows data exchange if data is anonymized appropriately. In this study, we use variational autoencoder as a mechanism to generate synthetic data. The privacy and utility of the generated data sets are measured. And its performance is compared with the performance of the plain autoencoder. The primary findings of this study are 1) variational autoencoder can be an option for data exchange with good accuracy even when the number of latent dimensions is low 2) plain autoencoder still provides better accuracy when the number of hidden nodes is high 3) variational autoencoder, as a generative model, can be given to a data user to generate his version of data that closely mimic the original data set.","2473-3105","978-1-7281-4961-5","10.1109/PRDC47002.2019.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952131","variational autoencoder, private data release, k anonymity, k Level","","business data processing;data privacy;electronic data interchange","tabular data;private data release mechanism;data user;plain autoencoder;generated data sets;synthetic data;variational autoencoder;data exchange;privacy regulation;aggregate data;business entities;multimarket businesses","","1","","22","","9 Jan 2020","","","IEEE","IEEE Conferences"
"Gaussian Process Modeling of Approximate Inference Errors for Variational Autoencoders","M. Kim","Samsung AI Center Cambridge, UK","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","244","253","Variational autoencoder (VAE) is a very successful generative model whose key element is the so-called amortized inference network, which can perform test time inference using a single feed forward pass. Unfortunately, this comes at the cost of degraded accuracy in posterior approximation, often underperforming the instance-wise variational optimization. Although the latest semi-amortized approaches mitigate the issue by performing a few variational optimization updates starting from the VAE's amortized inference output, they inherently suffer from computational overhead for inference at test time. In this paper, we address the problem in a completely different way by considering a random inference model, where we model the mean and variance functions of the variational posterior as random Gaussian processes (GP). The motivation is that the deviation of the VAE's amortized posterior distribution from the true posterior can be regarded as random noise, which allows us to view the approximation error as uncertainty in posterior approximation that can be dealt with in a principled GP manner. In particular, our model can quantify the difficulty in posterior approximation by a Gaussian variational density. Inference in our GP model is done by a single feed forward pass through the network, significantly faster than semi-amortized methods. We show that our approach attains higher test data likelihood than the state-of-the-arts on several benchmark datasets.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879639","Machine learning; Optimization methods; Statistical methods","Uncertainty;Costs;Computational modeling;Gaussian processes;Network architecture;Benchmark testing;Approximation error","approximation theory;feedforward neural nets;Gaussian processes;inference mechanisms;optimisation;random noise;random processes;statistical distributions;variational techniques","approximate inference errors;variational autoencoder;generative model;amortized inference network;test time inference;posterior approximation;instance-wise variational optimization;variational optimization updates;random inference model;random Gaussian processes;random noise;approximation error;Gaussian variational density;GP model;Gaussian process modeling;VAE;amortized posterior distribution;test data likelihood;single feed forward pass;variance functions;variational posterior","","","","39","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"VAGA: Towards Accurate and Interpretable Outlier Detection Based on Variational Auto-Encoder and Genetic Algorithm for High-Dimensional Data","J. Li; J. Zhang; J. Wang; Y. Zhu; M. J. Bah; G. Yang; Y. Gan","Nanjing University of Aeronautics and Astronautics, China; Zhejiang Lab, China; Nanjing University of Aeronautics and Astronautics, China; Nanjing University of Aeronautics and Astronautics, China; Zhejiang Lab, China; Anhui University of Science and Technology, China; Xi’an University of Posts and Telecommunications, China","2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","5956","5958","The curse of dimensionality in high-dimensional data makes it difficult to capture the abnormality of data points in full data space. To deal with this problem, we propose an outlier detection model based on Variational Autoencoder and Genetic Algorithm for subspace outlier analysis of high-dimensional data (VAGA). The proposed VAGA model constructs a variational autoencoder (VAE) to preliminarily detect outliers. Then the genetic algorithm (GA) is used to search the abnormal subspace of the outliers obtained by the VAE layer to provide a basis for subspace outlier analysis. The subsequent clustering of the abnormal subspaces help filter out the false positives which are fed back to the VAE layer to adjust network weights. The comparative experiments performed on three public benchmark datasets show that the outlier detection results of the proposed VAGA model are highly interpretable and have better accuracy performance than the state-of-the-art outlier detection methods.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671744","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671744","outlier detection;variational autoencoder;genetic algorithm","Dimensionality reduction;Analytical models;Conferences;Big Data;Benchmark testing;Filtering algorithms;Data models","data analysis;data mining;genetic algorithms;learning (artificial intelligence);pattern clustering","interpretable outlier detection;Variational auto-encoder;genetic algorithm;high-dimensional data;data points;data space;outlier detection model;variational autoencoder;subspace outlier analysis;VAGA model constructs;abnormal subspace;VAE layer;outlier detection results;state-of-the-art outlier detection methods","","","","11","IEEE","13 Jan 2022","","","IEEE","IEEE Conferences"
"Lifelong Mixture of Variational Autoencoders","F. Ye; A. G. Bors","Department of Computer Science, University of York, York YO10 5GH, U.K..; Department of Computer Science, University of York, York YO10 5GH, U.K. (e-mail: adrian.bors@york.ac.uk).","IEEE Transactions on Neural Networks and Learning Systems","","2021","PP","99","1","14","In this article, we propose an end-to-end lifelong learning mixture of experts. Each expert is implemented by a variational autoencoder (VAE). The experts in the mixture system are jointly trained by maximizing a mixture of individual component evidence lower bounds (MELBO) on the log-likelihood of the given training samples. The mixing coefficients in the mixture model control the contributions of each expert in the global representation. These are sampled from a Dirichlet distribution whose parameters are determined through nonparametric estimation during lifelong learning. The model can learn new tasks fast when these are similar to those previously learned. The proposed lifelong mixture of VAE (L-MVAE) expands its architecture with new components when learning a completely new task. After the training, our model can automatically determine the relevant expert to be used when fed with new data samples. This mechanism benefits both the memory efficiency and the required computational cost as only one expert is used during the inference. The L-MVAE inference model is able to perform interpolations in the joint latent space across the data domains associated with different tasks and is shown to be efficient for disentangled learning representation.","2162-2388","","10.1109/TNNLS.2021.3096457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9509343","Disentangled representations;lifelong learning;mixture of evidence lower bounds (ELBOs);mixture of variational autoencoders (VAEs);multitask learning.","Task analysis;Training;Data models;Databases;Computer architecture;Probability;Mixture models","","","","1","","","IEEE","9 Aug 2021","","","IEEE","IEEE Early Access Articles"
"Emotion-Regularized Conditional Variational Autoencoder for Emotional Response Generation","Y. -P. Ruan; Z. Ling","College of Electronic Engineering, National University of Defense Technology, Hefei, Anhui, China, (e-mail: ypruan@mail.ustc.edu.cn); Dept. EEIS, University of Science and Technology of China, 12652 Hefei, Anhui, China, 230027 (e-mail: zhling@ustc.edu.cn)","IEEE Transactions on Affective Computing","","2021","PP","99","1","1","This paper presents an emotion-regularized conditional variational autoencoder (Emo-CVAE) model for generating emotional conversation responses. In conventional CVAE-based emotional response generation, emotion labels are simply used as additional conditions in prior, posterior and decoder networks. Considering that emotion styles are naturally entangled with semantic contents in the language space, the Emo-CVAE model utilizes emotion labels to regularize the CVAE latent space by introducing an extra emotion prediction network. In the training stage, the estimated latent variables are required to predict the emotion labels and token sequences of the input responses simultaneously. Experimental results show that our Emo-CVAE model can learn a more informative and structured latent space than a conventional CVAE model and output responses with better content and emotion performance than baseline CVAE and sequence-to-sequence (Seq2Seq) models.","1949-3045","","10.1109/TAFFC.2021.3073809","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9406340","Emotional Response Generation;Latent Variables;Variational Autoencoder","Training;Emotional responses;Testing;Decoding;Earth Observing System;Bit error rate;Semantics","","","","1","","","IEEE","16 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Co-VAE: Drug-target binding affinity prediction by co-regularized variational autoencoders","T. Li; X. Zhao; L. Li","School of Mathematics and Statistics, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi, China, (e-mail: litj468@stu.xjtu.edu.cn); ISTBI, Fudan University, 12478 Shanghai, Shanghai, China, 200433 (e-mail: xmzhao@fudan.edu.cn); School of Mathematics and Statistics, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi, China, (e-mail: liminli@mail.xjtu.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2021","PP","99","1","1","Identifying drug-target interactions has been a key step in drug discovery. Many computational methods have been proposed to directly determine whether drugs and targets can interact or not. Drug-target binding affinity is another type of data which could show the strength of the binding interaction between a drug and a target. However, it is more challenging to predict drug-target binding affinity, and thus a very few studies follow this line. In our work, we propose a novel co-regularized variational autoencoders (Co-VAE) to predict drug-target binding affinity based on drug structures and target sequences. The Co-VAE model consists of two VAEs for generating drug SMILES strings and target sequences, respectively, and a co-regularization part for generating the binding affinities. We theoretically prove that the Co-VAE model is to maximize the lower bound of the joint likelihood of drug, protein and their affinity. The Co-VAE could predict drug-target affinity and generate new drugs which share similar targets with the input drugs. The experimental results on two datasets show that the Co-VAE could predict drug-target affinity better than existing affinity prediction methods such as DeepDTA and DeepAffinity, and could generate more new valid drugs than existing methods such as GAN and VAE.","1939-3539","","10.1109/TPAMI.2021.3120428","National Natural Science Foundation of China(grant numbers:11631012,61772368,61932008); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9576631","Variational autoencoders;Co-regularized VAE;Drug-target binding affinity;!","Drugs;Predictive models;Feature extraction;Computational modeling;Mathematical models;Proteins;Probabilistic logic","","","","","","","IEEE","15 Oct 2021","","","IEEE","IEEE Early Access Articles"
"Towards Evaluating the Representation Learned by Variational AutoEncoders","T. Ueda; D. V. Vargas","Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan","2021 60th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE)","8 Oct 2021","2021","","","591","594","At the heart of a deep neural network is representation learning with complex latent variables. This representation learning has been improved by disentangled representations and the idea of regularization terms. However, adversarial samples show that tasks with DNNs can easily fail due to slight perturbations or transformations of the input. Variational AutoEncoder (VAE) learns $P(z\vert x)$, the distribution of the latent variable $z$, rather than $P(y\vert x)$, the distribution of the output $y$ for the input x. Therefore, VAE is considered to be a good model for learning representations from input data. In other words, the mapping of $x$ is not directly to $y$, but to the latent variable $z$. In this paper, we propose an evaluation method to characterize the latent variables that VAE learns. Specifically, latent variables extracted from VAEs trained by two well-known data sets are analyzed by the k-nearest neighbor method(kNN). In doing so, we propose an interpretation of what kind of representation the VAE learns, and share clues about the hyperdimensional space to which the latent variables are mapped.","","978-4-9077-6473-9","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555183","variational autoencoder;representation learning;deep neural network","Heart;Deep learning;Perturbation methods;Instruments;Neural networks;Data models;Data mining","","","","","","7","","8 Oct 2021","","","IEEE","IEEE Conferences"
"Geometry-Based Molecular Generation With Deep Constrained Variational Autoencoder","C. Li; J. Yao; W. Wei; Z. Niu; X. Zeng; J. Li; J. Wang","School of Informatics, Xiamen University, Xiamen 361005, China, and also with the School of Mathematics and Computer Sciences, Yunnan Minzu University, Kunming 650500, China.; Institute of Artificial Intelligence and the School of Film, Xiamen University, Xiamen 361005, China; School of Computer Science and Engineering, Xi'an University of Technology, Xi'an 710048, China; MindRank AI Ltd., Hangzhou, Zhejiang 311113, China.; College of Computer Science and Electronic Engineering, Hunan University, Changsha 410082, China.; School of Software, Yunnan University, Kunming 650091, China.; Integrative Biotechnology & Translational Medicine, Yonsei University, Incheon 21983, Republic of Korea.","IEEE Transactions on Neural Networks and Learning Systems","","2022","PP","99","1","10","Finding target molecules with specific chemical properties plays a decisive role in drug development. We proposed GEOM-CVAE, a constrained variational autoencoder based on geometric representation for molecular generation with specific properties, which is protein-context-dependent. In terms of machine learning, it includes continuous feature embedding encoder and molecular generation decoder. Our key contribution is to propose an efficient geometric embedding method, including the spatial structure representations of drug molecule (converting the 3-D coordinates into image) and the geometric graph representations of protein target (modeling the protein surface as a mesh). The 3-D geometric information is vital to successful molecular generation, which is different from previous molecular generative methods based on 1-D or 2-D. Our model framework generates specific molecules in two phases, by first generating special image with molecular 3-D information to learn latent representations and generating molecules with constrained condition based on geometric graph convolution for specific protein and then inputting the generated structural molecules into a parser network for obtaining Simplified Molecular Input Line Entry System (SMILES) strings. Our model achieves competitive performance that implies its potential effectiveness to enable the exploration of the vast chemical space for drug discovery.","2162-2388","","10.1109/TNNLS.2022.3147790","National Natural Science Foundation of China(grant numbers:62072388,62122025,61872309,61972138,62102140); Collaborative Project Fund of Fuzhou-Xiamen-Quanzhou Innovation Zone(grant numbers:3502ZCQXT202001); Industry Guidance Project Foundation of Science Technology Bureau of Fujian Province(grant numbers:2020H0047); Natural Science Foundation of Science Technology Bureau of Fujian Province(grant numbers:2019J01601); Creation Fund Project of Science Technology Bureau of Fujian Province(grant numbers:2019C0021); Hunan Provincial Natural Science Foundation(grant numbers:2020JJ4215,2021JJ10020); Fundamental Research Project of Yunnan Province(grant numbers:202001BB050052); Scientific Research Fund of Yunnan Provincial Department of Education(grant numbers:2022J0450); Fujian Sunshine Charity Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9714718","Coordinate;geometry;graph convolutional network;mesh;molecular generation;variational autoencoder (VAE).","Proteins;Solid modeling;Drugs;Visualization;Computational modeling;Feature extraction;Decoding","","","","","","","IEEE","16 Feb 2022","","","IEEE","IEEE Early Access Articles"
"Unsupervised Clustering through Gaussian Mixture Variational AutoEncoder with Non-Reparameterized Variational Inference and Std Annealing","Z. Li; Y. Zhao; H. Xu; W. Chen; S. Xu; Y. Li; D. Pei","Tsinghua University, Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China; Tsinghua University, Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China; Tsinghua University, Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China; Tsinghua University, Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China; Tsinghua University, Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China; Tsinghua University, Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China; Tsinghua University, Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","8","Clustering has long been an important research topic in machine learning, and is highly valuable in many application tasks. In recent years, many methods have achieved high clustering performance by applying deep generative models. In this paper, we point out that directly using q(z|y, x) instead of resorting to the mean-field approximation (as is adopted in previous works) in Gaussian Mixture Variational Auto-Encoder can benefit the unsupervised clustering task. We improve the performance of Gaussian Mixture VAE, by optimizing it with a Monte Carlo objective (including the q(z|y, x) term), with non-reparameterized Variational Inference for Monte Carlo Objectives (VIMCO) method. In addition, we propose std annealing to stabilize the training process and empirically show its effects on forming well-separated embeddings with different variational inference methods. Experimental results on five benchmark datasets show that our proposed algorithm NVISA outperforms several baseline algorithms as well as the previous clustering methods based on Gaussian Mixture VAE.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9207493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207493","Unsupervised Clustering;Gaussian Mixture Variational Auto-Encoder;Std Annealing","Training;Annealing;Task analysis;Monte Carlo methods;Inference algorithms;Clustering methods;Neural networks","Gaussian processes;inference mechanisms;mixture models;Monte Carlo methods;neural nets;pattern clustering;simulated annealing;unsupervised learning","deep generative models;mean-field approximation;unsupervised clustering;Gaussian mixture VAE;Monte Carlo objective;Gaussian mixture variational autoencoder;machine learning;Std annealing;nonreparameterized variational inference","","1","","30","","28 Sep 2020","","","IEEE","IEEE Conferences"
"Overdispersed variational autoencoders","H. Shah; D. Barber; A. Botev","Department of Computer Science, University College, London; Department of Computer Science, University College, London; Department of Computer Science, University College, London","2017 International Joint Conference on Neural Networks (IJCNN)","3 Jul 2017","2017","","","1109","1116","The ability to fit complex generative probabilistic models to data is a key challenge in AI. Currently, variational methods are popular, but remain difficult to train due to high variance of the sampling methods employed. We introduce the overdispersed variational autoencoder and overdispersed importance weighted autoencoder, which combine overdispersed black box variational inference with the variational autoencoder and importance weighted autoencoder respectively. We use the log likelihood lower bounds and reparametrisation trick from the variational and importance weighted autoencoders, but rather than drawing samples from the variational distribution itself, we use importance sampling to draw samples from an overdispersed (i.e. heavier-tailed) proposal in the same family as the variational distribution. We run experiments on two different datasets, and show that this technique produces a lower variance estimate of the gradients, and reaches a higher bound on the log likelihood of the observed data.","2161-4407","978-1-5090-6182-2","10.1109/IJCNN.2017.7965976","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7965976","","Proposals;Monte Carlo methods;Data models;Dispersion;Computational modeling;Inference algorithms;Stochastic processes","encoding;inference mechanisms;probability;sampling methods","overdispersed variational autoencoders;complex generative probabilistic models;AI;sampling methods;overdispersed importance weighted autoencoder;overdispersed black box variational inference;importance weighted autoencoder;log likelihood lower bounds;reparametrisation trick;variational distribution","","","","18","","3 Jul 2017","","","IEEE","IEEE Conferences"
"Learning Weighted Submanifolds With Variational Autoencoders and Riemannian Variational Autoencoders","N. Miolane; S. Holmes",Stanford University; Stanford University,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","14491","14499","Manifold-valued data naturally arises in medical imaging. In cognitive neuroscience for instance, brain connectomes base the analysis of coactivation patterns between different brain regions on the analysis of the correlations of their functional Magnetic Resonance Imaging (fMRI) time series - an object thus constrained by construction to belong to the manifold of symmetric positive definite matrices. One of the challenges that naturally arises in these studies consists in finding a lower-dimensional subspace for representing such manifold-valued and typically high-dimensional data. Traditional techniques, like principal component analysis, are ill-adapted to tackle non-Euclidean spaces and may fail to achieve a lower-dimensional representation of the data - thus potentially pointing to the absence of lower-dimensional representation of the data. However, these techniques are restricted in that: (i) they do not leverage the assumption that the connectomes belong on a pre-specified manifold, therefore discarding information; (ii) they can only fit a linear subspace to the data. In this paper, we are interested in variants to learn potentially highly curved submanifolds of manifold-valued data. Motivated by the brain connectomes example, we investigate a latent variable generative model, which has the added benefit of providing us with uncertainty estimates - a crucial quantity in the medical applications we are considering. While latent variable models have been proposed to learn linear and nonlinear spaces for Euclidean data, or geodesic subspaces for manifold data, no intrinsic latent variable model exists to learn non-geodesic subspaces for manifold data. This paper fills this gap and formulates a Riemannian variational autoencoder with an intrinsic generative model of manifold-valued data. We evaluate its performances on synthetic and real datasets, by introducing the formalism of weighted Riemannian submanifolds.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.01451","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157379","","Manifolds;Data models;Principal component analysis;Task analysis;Probabilistic logic;Biomedical imaging;Uncertainty","biomedical MRI;brain;differential geometry;geometry;learning (artificial intelligence);matrix algebra;medical image processing;neurophysiology;principal component analysis;time series","manifold data;Riemannian variational autoencoder;manifold-valued data;weighted Riemannian submanifolds;medical imaging;brain connectomes;different brain regions;functional Magnetic Resonance Imaging time series;symmetric positive definite matrices;lower-dimensional subspace;high-dimensional data;principal component analysis;lower-dimensional representation;pre-specified manifold;Euclidean data","","3","","29","","5 Aug 2020","","","IEEE","IEEE Conferences"
"Intrusion Detection Toward Feature Reconstruction using Huber Conditional Variational AutoEncoder","R. F. Lova; R. M. Fifaliana; W. P. De Silva","School of Information Engineering, Wuhan University of Technology, Wuhan, China; NA; Technical Lead, Boroughmarkets, Sydney, Australia","2022 International Conference on Information Networking (ICOIN)","26 Jan 2022","2022","","","13","17","Autoencoder is recently one of the widely used machine learning approaches where the network is trained to learn the data representation. This paper considers Autoencoder for Feature Reconstruction in Intrusion Detection System. Two networks are used to form an autoencoder; the left part, an Encoder network used to learn and compress data in order to reduce feature dimension, and the right part Decoder network, which can be used to reconstruct content into its original format instead of categorizing the data. However, the ability to approximate data reconstructed to the original one in an accurate manner is still a challenging process. Thus, we propose a Conditional Variational Autoencoder with an adaptive loss function named Adaptive Huber CVAE (AH-CVAE). We replace the classical reconstruction loss function with a flexible loss function in order to minimize reconstruction error. Then, this approach is proposed to make an optimal estimation of Intrusion Detection data and achieve an accurate approximation. We conduct our experiment on two datasets, NSL-KDD and UNSW-NB15 Dataset, and compare results with other existing approaches. AH-CVAE can better approximate the original and the reconstructed feature in the intrusion detection dataset.","1976-7684","978-1-6654-1332-9","10.1109/ICOIN53446.2022.9687135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9687135","Feature Reconstruction;Dimensionality reduction;Autoencoder;Conditional Variational Autoencoder;Intrusion Detection.","Intrusion detection;Estimation;Machine learning;Feature extraction;Decoding;Proposals","data compression;data structures;feature extraction;learning (artificial intelligence);neural nets;security of data","adaptive loss function;AH-CVAE;reconstruction error;intrusion detection dataset;feature reconstruction;machine learning;data representation;intrusion detection system;feature dimension;decoder network;encoder network;Huber conditional variational autoencoder;adaptive Huber CVAE;data compression;UNSW-NB15 dataset;NSL-KDD dataset","","","","15","IEEE","26 Jan 2022","","","IEEE","IEEE Conferences"
"Variational Clustering: Leveraging Variational Autoencoders for Image Clustering","V. Prasad; D. Das; B. Bhowmick","Technical University of Darmstadt, Germany; Embedded Systems and Robotics TCS Research & Innovation, Kolkata, India; Embedded Systems and Robotics TCS Research & Innovation, Kolkata, India","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","10","Recent advances in deep learning have shown their ability to learn strong feature representations for images. The task of image clustering naturally requires good feature representations to capture the distribution of the data and subsequently differentiate data points from one another. Often these two aspects are dealt with independently and thus traditional feature learning alone does not suffice in partitioning the data meaningfully. Variational Autoencoders (VAEs) naturally lend themselves to learning data distributions in a latent space. Since we wish to efficiently discriminate between different clusters in the data, we propose a method based on VAEs where we use a Gaussian Mixture prior to help cluster the images accurately. We jointly learn the parameters of both the prior and the posterior distributions. Our method represents a true Gaussian Mixture VAE. This way, our method simultaneously learns a prior that captures the latent distribution of the images and a posterior to help discriminate well between data points. We also propose a novel reparametrization of the latent space consisting of a mixture of discrete and continuous variables. One key takeaway is that our method generalizes better across different datasets without using any pre-training or learnt models, unlike existing methods, allowing it to be trained from scratch in an end-to-end manner. We verify our efficacy and generalizability experimentally by achieving state-of-the-art results among unsupervised methods on a variety of datasets. To the best of our knowledge, we are the first to pursue image clustering using VAEs in a purely unsupervised manner on real image datasets.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9207523","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207523","Unsupervised Learning;Clustering;Variational Inference","Training;Technological innovation;Task analysis;Clustering algorithms;Neural networks;Predictive models;Embedded systems","feature extraction;Gaussian processes;image representation;learning (artificial intelligence);neural nets;pattern clustering;unsupervised learning","VAEs;data distributions;latent space;posterior distributions;Gaussian mixture VAE;latent distribution;image clustering;image datasets;variational clustering;deep learning;feature representations;variational autoencoders;feature learning;unsupervised methods","","2","","43","","28 Sep 2020","","","IEEE","IEEE Conferences"
"Fault Detection Based on Variational Autoencoders for Complex Nonlinear Processes","K. Wang; J. Chen; Z. Song","State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China; Department of Chemical Engineering, Chung-Yuan Christian University, Taoyuan, Taiwan; State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China","2019 12th Asian Control Conference (ASCC)","18 Jul 2019","2019","","","1352","1357","Deep learning models have been proved to outperform shallow methods for industrial process fault detection because of their high capacity for complex nonlinearity. However, typical deep models applied to monitoring processes are conducted in a deterministic manner. They are unable to provide a confidence level for each decision. Also, most deep learning methods often need to integrate prior conditions, such as orthogonal latent variables, constraints, and some given distributions. The consequences of these issues cause lots of trials and errors as conventional deep models are built based on experiences. In this paper, a variational auto-encoder is used to set up a framework to tackle these problems. The learned latent variables, which would be orthogonal to each other, are constrained under the specified and optimized objective. Simultaneously, considering uncertainty in data, probability density estimates of latent variables and residuals instead of point estimates are given to design distribution based monitoring indices. A numerical example validates the effectiveness of the proposed method.","","978-4-88898-300-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8764937","Fault detection;Variational Bayes;Variational autoencoder;Nonlinear systems","Monitoring;Principal component analysis;Kernel;Decoding;Fault detection;Aerospace electronics;Stochastic processes","fault diagnosis;learning (artificial intelligence);optimisation;probability","variational autoencoders;complex nonlinear processes;deep learning models;shallow methods;industrial process fault detection;complex nonlinearity;typical deep models;monitoring processes;deterministic manner;confidence level;deep learning methods;prior conditions;orthogonal latent variables;given distributions;trials;errors;conventional deep models;variational auto-encoder;learned latent variables;specified objective;optimized objective;residuals;design distribution based monitoring indices","","","","17","","18 Jul 2019","","","IEEE","IEEE Conferences"
"Fault Detection of Sensor Data in Semiconductor Processing with Variational Autoencoder Neural Network","W. Yong; C. Xu; W. Zhengying","Shanghai Huali Microelectronics Corporation, Shanghai, China; Shanghai Huali Microelectronics Corporation, Shanghai, China; Shanghai Huali Microelectronics Corporation, Shanghai, China","2020 China Semiconductor Technology International Conference (CSTIC)","21 Dec 2020","2020","","","1","3","Tremendous amounts of equipment parameters and sensor values were generated during modern semiconductor wafer manufacturing. These process data were utilized for early diagnosis of anomalies to prevent subsequent yield loss. However, process data from different steps and machines were highly customized that it is of great difficulties for traditional fault detection and classification (FDC) analysis to find a universal model to identify process excursions. In this paper, we present a neural network method with deep convolutional variational autoencoder structures which used reconstruction error as abnormal scores. This method exhibited a more reliable detection precision than FDC method and traditional anomaly detection algorithms. Furthermore, the reconstruction error of different sensors could be used to identify the root cause of abnormal processes. It was found that similarly structured networks could be applied to different processing steps, which enable this method to be accepted as a standard method to process data.","","978-1-7281-6558-5","10.1109/CSTIC49141.2020.9282417","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9282417","","Semiconductor device modeling;Fault diagnosis;Fault detection;Neural networks;Semiconductor process modeling;Manufacturing;Standards","fault diagnosis;neural nets;semiconductor device manufacture","different processing steps;similarly structured networks;abnormal processes;traditional anomaly detection algorithms;FDC method;reliable detection precision;reconstruction error;deep convolutional variational autoencoder structures;neural network method;process excursions;classification analysis;traditional fault detection;subsequent yield loss;process data;modern semiconductor wafer manufacturing;sensor values;equipment parameters;tremendous amounts;variational autoencoder neural network;semiconductor processing;sensor data","","1","","6","","21 Dec 2020","","","IEEE","IEEE Conferences"
"Complementary Set Variational Autoencoder for Supervised Anomaly Detection","Y. Kawachi; Y. Koizumi; N. Harada","NTT Media Intelligence Laboratories, Tokyo, Japan; NTT Media Intelligence Laboratories, Tokyo, Japan; NTT Media Intelligence Laboratories, Tokyo, Japan","2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 Sep 2018","2018","","","2366","2370","Anomalies have broad patterns corresponding to their causes. In industry, anomalies are typically observed as equipment failures. Anomaly detection aims to detect such failures as anomalies. Although this is usually a binary classification task, the potential existence of unseen (unknown) failures makes this task difficult. Conventional supervised approaches are suitable for detecting seen anomalies but not for unseen anomalies. Although, unsupervised neural networks for anomaly detection now detect unseen anomalies well, they cannot utilize anomalous data for detecting seen anomalies even if some data have been made available. Thus, providing an anomaly detector that finds both seen and unseen anomalies well is still a tough problem. In this paper, we introduce a novel probabilistic representation of anomalies to solve this problem. The proposed model defines the normal and anomaly distributions using the analogy between a set and the complementary set. We applied these distributions to an unsupervised variational autoencoder (VAE)-based method and turned it into a supervised VAE-based method. We tested the proposed method with well-known data and real industrial data to show that the proposed method detects seen anomalies better than the conventional unsupervised method without degrading the detection performance for unseen anomalies.","2379-190X","978-1-5386-4658-8","10.1109/ICASSP.2018.8462181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8462181","Anomaly detection;variational autoencoder (VAE);neural network","Anomaly detection;Task analysis;Training;Probabilistic logic;Gaussian distribution;Neural networks;Decoding","neural nets;pattern classification;probability;security of data;unsupervised learning","supervised anomaly detection;unseen anomalies;normal distributions;anomaly distributions;complementary set variational autoencoder;binary classification task;conventional supervised approaches;unsupervised neural networks;probabilistic representation;unsupervised variational autoencoder-based method;supervised VAE-based method;unsupervised VAE-based method","","37","","28","","13 Sep 2018","","","IEEE","IEEE Conferences"
"ACVAE-VC: Non-Parallel Voice Conversion With Auxiliary Classifier Variational Autoencoder","H. Kameoka; T. Kaneko; K. Tanaka; N. Hojo","NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation, Atsugi, Japan; NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation, Atsugi, Japan; NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation, Atsugi, Japan; NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation, Atsugi, Japan","IEEE/ACM Transactions on Audio, Speech, and Language Processing","24 Jun 2019","2019","27","9","1432","1443","This paper proposes a non-parallel voice conversion (VC) method using a variant of the conditional variational autoencoder (VAE) called an auxiliary classifier VAE. The proposed method has two key features. First, it adopts fully convolutional architectures to construct the encoder and decoder networks so that the networks can learn conversion rules that capture the time dependencies in the acoustic feature sequences of source and target speech. Second, it uses information-theoretic regularization for the model training to ensure that the information in the attribute class label will not be lost in the conversion process. With regular conditional VAEs, the encoder and decoder are free to ignore the attribute class label input. This can be problematic since in such a situation, the attribute class label will have little effect on controlling the voice characteristics of input speech at test time. Such situations can be avoided by introducing an auxiliary classifier and training the encoder and decoder so that the attribute classes of the decoder outputs are correctly predicted by the classifier. We also present several ways to convert the feature sequence of input speech using the trained encoder and decoder and compare them in terms of audio quality through objective and subjective evaluations. We confirmed experimentally that the proposed method outperformed baseline non-parallel VC systems and performed comparably to an open-source parallel VC system trained using a parallel corpus in a speaker identity conversion task.","2329-9304","","10.1109/TASLP.2019.2917232","JSPS KAKENHI(grant numbers:17H01763); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8718381","Voice conversion (VC);variational autoencoder (VAE);non-parallel VC;auxiliary classifier VAE (ACVAE);fully convolutional network","Decoding;Acoustics;Training;Speech recognition;Gallium nitride;Generators;Artificial neural networks","decoding;learning (artificial intelligence);speech coding","trained encoder;nonparallel VC systems;open-source parallel VC system;speaker identity conversion task;ACVAE-VC;auxiliary classifier variational autoencoder;conditional variational autoencoder;auxiliary classifier VAE;convolutional architectures;acoustic feature sequences;information-theoretic regularization;attribute class label input;regular conditional VAE;decoder output networks;nonparallel voice conversion process","","29","","66","IEEE","20 May 2019","","","IEEE","IEEE Journals"
"PuVAE: A Variational Autoencoder to Purify Adversarial Examples","U. Hwang; J. Park; H. Jang; S. Yoon; N. I. Cho","Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, INMC, Seoul National University, Seoul, South Korea; Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, INMC, Seoul National University, Seoul, South Korea","IEEE Access","13 Sep 2019","2019","7","","126582","126593","Deep neural networks are widely used and exhibit excellent performance in many areas. However, they are vulnerable to adversarial attacks that compromise networks at inference time by applying elaborately designed perturbations to input data. Although several defense methods have been proposed to address specific attacks, other types of attacks can circumvent these defense mechanisms. Therefore, we propose Purifying Variational AutoEncoder (PuVAE), a method to purify adversarial examples. The proposed method eliminates an adversarial perturbation by projecting an adversarial example on the manifold of each class and determining the closest projection as a purified sample. We experimentally illustrate the robustness of PuVAE against various attack methods without any prior knowledge about the attacks. In our experiments, the proposed method exhibits performances that are competitive with state-of-the-art defense methods, and the inference time is approximately 130 times faster than that of Defense-GAN which is a state-of-the art purifier method.","2169-3536","","10.1109/ACCESS.2019.2939352","Korean National Police Agency; Ministry of Science, ICT and Future Planning(grant numbers:PA-C000001); National Research Foundation of Korea; National Research Foundation of Korea(grant numbers:2018R1A2B3001628); Samsung; Brain Korea 21 Plus Project in 2019; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8824108","Adversarial attack;variational autoencoder;deep learning","Perturbation methods;Training;Linear programming;Biological neural networks;Gallium nitride;Training data;Law enforcement","learning (artificial intelligence);neural nets;security of data","PuVAE;Variational autoencoder;adversarial example;deep neural networks;adversarial attacks;compromise networks;inference time;defense mechanisms;purified sample;attack methods;Defense-GAN;state-of-the art purifier method;purifying variational autoencoder","","18","1","39","CCBY","4 Sep 2019","","","IEEE","IEEE Journals"
"Transfer Learning in Brain-Computer Interfaces with Adversarial Variational Autoencoders","O. Özdenizci; Y. Wang; T. Koike-Akino; D. Erdoğmuş","Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA","2019 9th International IEEE/EMBS Conference on Neural Engineering (NER)","20 May 2019","2019","","","207","210","We introduce adversarial neural networks for representation learning as a novel approach to transfer learning in brain-computer interfaces (BCIs). The proposed approach aims to learn subject-invariant representations by simultaneously training a conditional variational autoencoder (cVAE) and an adversarial network. We use shallow convolutional architectures to realize the cVAE, and the learned encoder is transferred to extract subject-invariant features from unseen BCI users’ data for decoding. We demonstrate a proof-of-concept of our approach based on analyses of electroencephalographic (EEG) data recorded during a motor imagery BCI experiment.","1948-3554","978-1-5386-7921-0","10.1109/NER.2019.8716897","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8716897","representation learning;transfer learning;adversarial networks;variational autoencoders;convolutional neural networks;EEG;brain-computer interfaces","Decoding;Electroencephalography;Training;Training data;Brain modeling;Brain-computer interfaces;Feature extraction","brain-computer interfaces;electroencephalography;learning (artificial intelligence);medical signal processing","learned encoder;subject-invariant features;transfer learning;brain-computer interfaces;adversarial variational autoencoders;adversarial neural networks;representation learning;subject-invariant representations;conditional variational autoencoder;cVAE;adversarial network;shallow convolutional architectures","","17","","26","IEEE","20 May 2019","","","IEEE","IEEE Conferences"
"Network Embedding via Community Based Variational Autoencoder","W. Shi; L. Huang; C. -D. Wang; J. -H. Li; Y. Tang; C. Fu","School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Computer Science, South China Normal University, Guangzhou, China; School of Computer Science, South China Normal University, Guangzhou, China","IEEE Access","7 Mar 2019","2019","7","","25323","25333","In recent years, network embedding has attracted more and more attention due to its effectiveness and convenience to compress the network structured data. In this paper, we propose a community-based variational autoencoder (ComVAE) model to learn network embedding, which consists of a community detection module and a deep learning module. In the proposed model, both community information and deep learning techniques are utilized to learn low-dimensional vertex representations. First, community information reveals an implicit relationship between vertices from a global view, which can be a supplement to local information and help to improve the embedding quality. To obtain the community information, community detection algorithms are utilized as a module and the modularization design makes the model more flexible. Second, deep learning techniques can not only integrate and preserve the information from both local and global views efficiently but also strengthen the robustness of vertex representations. To demonstrate the performance of our model, extensive experiments are conducted in four downstream tasks, namely, network reconstruction, node classification, link prediction, and visualization. The experimental results show that our model outperforms the state-of-the-art approaches to real-world datasets.","2169-3536","","10.1109/ACCESS.2019.2900662","National Natural Science Foundation of China(grant numbers:61876193,U181120009,61772211); Guangdong Natural Science Funds for the Distinguished Young Scholar(grant numbers:2016A030306014); Tip-top Scientific and Technical Innovative Youth Talents of the Guangdong Special Support Program(grant numbers:2016TQ03X542); Science and Technology Planning Project of Guangzhou Municipal Colleges and Universities(grant numbers:2012A164); Guangzhou Innovative Entrepreneurship Project(grant numbers:2019PT204); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648335","Network embedding;community detection;variational autoencoder","Deep learning;Computational modeling;Detection algorithms;Task analysis;Data mining;Neural networks;Computer science","learning (artificial intelligence);pattern classification","visualization;link prediction;node classification;ComVAE;network reconstruction;community detection algorithms;embedding quality;low-dimensional vertex representations;deep learning techniques;community information;deep learning module;community detection module;community-based variational autoencoder model;network structured data;community based variational autoencoder;network embedding","","13","","46","OAPA","21 Feb 2019","","","IEEE","IEEE Journals"
"Learning Community Structure with Variational Autoencoder","J. J. Choong; X. Liu; T. Murata","Department of Computer Science, Tokyo Institute of Technology, Tokyo, Japan; Industrial Science and Technology, National Institute of Advanced, Tokyo, japan; Department of Computer Science, Tokyo Institute of Technology, Tokyo, Japan","2018 IEEE International Conference on Data Mining (ICDM)","30 Dec 2018","2018","","","69","78","Discovering community structure in networks remains a fundamentally challenging task. From scientific domains such as biology, chemistry and physics to social networks the challenge of identifying community structures in different kinds of network is challenging since there is no universal definition of community structure. Furthermore, with the surge of social networks, content information has played a pivotal role in defining community structure, demanding techniques beyond its traditional approach. Recently, network representation learning have shown tremendous promise. Leveraging on recent advances in deep learning, one can exploit deep learning's superiority to a network problem. Most predominantly, successes in supervised and semi-supervised task has shown promising results in network representation learning tasks such as link prediction and graph classification. However, much has yet to be explored in the literature of community detection which is an unsupervised learning task. This paper proposes a deep generative model for community detection and network generation. Empowered with Bayesian deep learning, deep generative models are capable of exploiting non-linearities while giving insights in terms of uncertainty. Hence, this paper proposes Variational Graph Autoencoder for Community Detection (VGAECD). Extensive experiment shows that it is capable of outperforming existing state-of-the-art methods. The generalization of the proposed model also allows the model to be considered as a graph generator. Additionally, unlike traditional methods, the proposed model does not require a predefined community structure definition. Instead, it assumes the existence of latent similarity between nodes and allows the model to find these similarities through an automatic model selection process. Optionally, it is capable of exploiting feature-rich information of a network such as node content, further increasing its performance.","2374-8486","978-1-5386-9159-5","10.1109/ICDM.2018.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594831","community detection;variational autoencoder;generative model","Conferences;Data mining","complex networks;network theory (graphs);pattern classification;social networking (online);unsupervised learning","social networks;network problem;network representation learning tasks;community detection;unsupervised learning task;deep generative model;network generation;Bayesian deep learning;learning community structure;variational autoencoder;variational graph autoencoder for community detection;VGAECD;graph classification","","9","","41","","30 Dec 2018","","","IEEE","IEEE Conferences"
"Fast Mesh Denoising With Data Driven Normal Filtering Using Deep Variational Autoencoders","S. Nousias; G. Arvanitis; A. S. Lalos; K. Moustakas","Department of Electrical and Computer Engineering, University of Patras, Rion Patras, Greece; Department of Electrical and Computer Engineering, University of Patras, Rion Patras, Greece; Industrial Systems Institute, Athena Research Center, Marousi, Greece; Department of Electrical and Computer Engineering, University of Patras, Rion Patras, Greece","IEEE Transactions on Industrial Informatics","19 Nov 2020","2021","17","2","980","990","Recent advances in 3-D scanning technology have enabled the deployment of 3-D models in various industrial applications such as digital twins, remote inspection, and reverse engineering. Despite their evolving performance, 3-D scanners still introduce noise and artifacts in the acquired dense models. In this article, we propose a fast and robust denoising method for the dense 3-D scanned industrial models. The proposed approach employs conditional variational autoencoders to effectively filter face normals. Training and inference are performed in a sliding patch setup reducing the size of the required training data and execution times. We conducted extensive evaluation studies using 3-D scanned and CAD models. The results verify plausible denoising outcomes, demonstrating similar or higher reconstruction accuracy, compared to other state-of-the-art approaches. Specifically, for 3-D models with more than 1e4 faces, the presented pipeline is twice as fast as methods with equivalent reconstruction error.","1941-0050","","10.1109/TII.2020.3000491","European Union Horizon 2020 Research and innovation program; WARMEST; Marie Sklodowska(grant numbers:777981); European Union Horizon 2020 Research and Innovation Program Ageing@Work(grant numbers:826299); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9110709","3-D mesh denoising;data driven normal filtering;variational autoencoders","Three-dimensional displays;Noise reduction;Face;Solid modeling;Training;Tensors;Decoding","automatic optical inspection;CAD;image denoising;image filtering;image reconstruction;learning (artificial intelligence);neural nets;production engineering computing;reverse engineering","reverse engineering;higher reconstruction accuracy;similar reconstruction accuracy;CAD models;conditional variational autoencoders;remote inspection;digital twins;industrial applications;3-D scanning technology;deep variational autoencoders;data driven normal filtering;fast mesh denoising","","6","","35","CCBY","8 Jun 2020","","","IEEE","IEEE Journals"
"3D High-Resolution Cardiac Segmentation Reconstruction From 2D Views Using Conditional Variational Autoencoders","C. Biffi; J. J. Cerrolaza; G. Tarroni; A. de Marvao; S. A. Cook; D. P. O’Regan; D. Rueckert","Imperial College London, MRC London Institute of Medical Sciences, UK; Biomedical Image Analysis Group, Imperial College London, UK; Biomedical Image Analysis Group, Imperial College London, UK; Imperial College London, MRC London Institute of Medical Sciences, UK; Imperial College London, MRC London Institute of Medical Sciences, UK; Imperial College London, MRC London Institute of Medical Sciences, UK; Biomedical Image Analysis Group, Imperial College London, UK","2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)","11 Jul 2019","2019","","","1643","1646","Accurate segmentation of heart structures imaged by cardiac MR is key for the quantitative analysis of pathology. High-resolution 3D MR sequences enable whole-heart structural imaging but are time-consuming, expensive to acquire and they often require long breath holds that are not suitable for patients. Consequently, multiplanar breath-hold 2D cines sequences are standard practice but are disadvantaged by lack of whole-heart coverage and low through-plane resolution. To address this, we propose a conditional variational autoencoder architecture able to learn a generative model of 3D high-resolution left ventricular (LV) segmentations which is conditioned on three 2D LV segmentations of one short-axis and two long-axis images. By only employing these three 2D segmentations, our model can efficiently reconstruct the 3D high-resolution LV segmentation of a subject. When evaluated on 400 unseen healthy volunteers, our model yielded an average Dice score of 87.92 ± 0.15 and outperformed competing architectures (TL-net, Dice score = 82.60 ± 0.23, p = 2.2 · 10-16).","1945-8452","978-1-5386-3641-1","10.1109/ISBI.2019.8759328","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759328","Cardiac MR;Variational Autoencoder;3D Segmentation Reconstruction;Deep Learning","Three-dimensional displays;Two dimensional displays;Image segmentation;Image reconstruction;Image resolution;Solid modeling;Training","biomedical MRI;cardiology;image reconstruction;image segmentation;image sequences;medical image processing;pneumodynamics","long breath;multiplanar breath-hold 2D cines sequences;standard practice;whole-heart coverage;low through-plane resolution;conditional variational autoencoder architecture;generative model;3D high-resolution left ventricular segmentations;long-axis images;3D high-resolution LV segmentation;high-resolution cardiac segmentation reconstruction;2D views;conditional variational autoencoders;accurate segmentation;heart structures;high-resolution 3D MR sequences;whole-heart structural imaging","","5","","8","","11 Jul 2019","","","IEEE","IEEE Conferences"
"A Quaternion-Valued Variational Autoencoder","E. Grassucci; D. Comminiello; A. Uncini","Dept. Information Engineering, Electronics and Telecommunications (DIET), Sapienza University of Rome, Rome, Italy; Dept. Information Engineering, Electronics and Telecommunications (DIET), Sapienza University of Rome, Rome, Italy; Dept. Information Engineering, Electronics and Telecommunications (DIET), Sapienza University of Rome, Rome, Italy","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","3310","3314","Deep probabilistic generative models have achieved incredible success in many fields of application. Among such models, variational autoencoders (VAEs) have proved their ability in modeling a generative process by learning a latent representation of the input. In this paper, we propose a novel VAE defined in the quaternion domain, which exploits the properties of quaternion algebra to improve performance while significantly reducing the number of parameters required by the network. The success of the proposed quaternion VAE with respect to traditional VAEs relies on the ability to leverage the internal relations between quaternion-valued input features and on the properties of second-order statistics which allow to define the latent variables in the augmented quaternion domain. In order to show the advantages due to such properties, we define a plain convolutional VAE in the quaternion domain and we evaluate its performance with respect to its real-valued counterpart on the CelebA face dataset.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9413859","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9413859","Variational Autoencoder;Quaternion Neural Networks;Quaternion Properness;Generative Models;Quaternion Random Vectors","Convolution;Algebra;Quaternions;Conferences;Probabilistic logic;Acoustics;Decoding","deep learning (artificial intelligence);feature extraction;probability","quaternion-valued variational autoencoder;probabilistic generative models;incredible success;variational autoencoders;generative process;latent representation;quaternion algebra;quaternion VAE;quaternion-valued input features;latent variables;augmented quaternion domain;plain convolutional VAE","","2","","29","IEEE","13 May 2021","","","IEEE","IEEE Conferences"
"Variational Autoencoders for Hyperspectral Unmixing with Endmember Variability","S. Shi; M. Zhao; L. Zhang; J. Chen","School of Marine Science and Technology, Center of Intelligent Acoustics and Immersive Communications (CIAIC), Northwestern Polytechnical University, China; School of Marine Science and Technology, Center of Intelligent Acoustics and Immersive Communications (CIAIC), Northwestern Polytechnical University, China; School of Marine Science and Technology, Center of Intelligent Acoustics and Immersive Communications (CIAIC), Northwestern Polytechnical University, China; School of Marine Science and Technology, Center of Intelligent Acoustics and Immersive Communications (CIAIC), Northwestern Polytechnical University, China","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","1875","1879","Spectral signatures are usually affected by variations in environmental conditions. The spectral variability is thus one of the most important and challenging problems to be addressed in hyperspectral unmixing. Generally, it is a non-trivial task to model the endmember variability, and existing spectral unmixing methods that address the spectral variability have different limitations. This paper presents a variational autoencoder (VAE) framework for hyperspectral unmixing accounting for the endmember variability. The endmembers are generated using the posterior distributions of the latent variables to describe their variability in the image. Compared with other existing distribution based methods, the proposed method is able to fit an arbitrary distribution of endmembers for each material through the representation capacity of deep neural networks. Evaluated with both synthetic and real datasets, the proposed method shows superior unmixing results compared with other state-of-the-art unmixing methods.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414940","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414940","Hyperspectral imaging;spectral unmixing;endmember variability;variational autoencoders","Conferences;Neural networks;Estimation;Color;Signal processing;Probability distribution;Task analysis","geophysical image processing;hyperspectral imaging;image classification;image processing;neural nets;remote sensing;spectral analysis","spectral signatures;spectral variability;important problems;nontrivial task;endmember variability;spectral unmixing methods;variational autoencoder framework;hyperspectral unmixing accounting;endmembers;latent variables;existing distribution based methods;superior unmixing results;state-of-the-art unmixing methods;variational autoencoders","","2","","20","","13 May 2021","","","IEEE","IEEE Conferences"
"Improved Variational Autoencoder Anomaly Detection in Time Series Data","U. Yokkampon; S. Chumkamon; A. Mowshowitz; R. Fujisawa; E. Hayashi","Department of Computer Science and Systems Engineering, Kyushu Institute of Technology, Fukuoka, Japan; Department of Computer Science and Systems Engineering, Kyushu Institute of Technology, Fukuoka, Japan; Department of Computer Science, The City College of New York, New York, USA; Department of Computer Science and Systems Engineering, Kyushu Institute of Technology, Fukuoka, Japan; Department of Computer Science and Systems Engineering, Kyushu Institute of Technology, Fukuoka, Japan","2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","14 Dec 2020","2020","","","82","87","Uncertainty in observations about the state of affairs is unavoidable, and generally undesirable, so we are motivated to try to minimize its effect on data analysis. Detection of anomalies in data has become an important research area. In this paper, we propose a novel approach to anomaly detection based on the Variational Autoencoder method with a Mish activation function and a Negative Log-Likelihood loss function. The proposed method is validated with ten standard datasets, comparing performance on each of the various activation functions and loss functions. Experimental results show that our proposed method offers an improvement over existing methods. Statistical properties (i.e., F1 score, AUC, and ROC) of the method are also examined in light of the experimental results.","2577-1655","978-1-7281-8526-2","10.1109/SMC42975.2020.9283010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283010","Anomaly Detection;Variational Autoencoder;Time Series Data;Activation Functions;Loss Functions","Measurement;Uncertainty;Data analysis;Time series analysis;Anomaly detection;Standards;Cybernetics","data analysis;learning (artificial intelligence);maximum likelihood estimation;neural nets;pattern classification;time series","time series data;data analysis;variational autoencoder method;Mish activation function;negative log-likelihood loss function;variational autoencoder anomaly detection;statistical properties","","1","","14","","14 Dec 2020","","","IEEE","IEEE Conferences"
"Autoregressive Variational Autoencoder with a Hidden Semi-Markov Model-Based Structured Attention for Speech Synthesis","T. Fujimoto; K. Hashimoto; Y. Nankaku; K. Tokuda","Nagoya Institute of Technology, Japan; Nagoya Institute of Technology, Japan; Nagoya Institute of Technology, Japan; Nagoya Institute of Technology, Japan","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","7462","7466","This paper proposes an autoregressive speech synthesis model based on the variational autoencoder incorporating latent sequence representation for acoustic and linguistic features and the structure of a hidden semi-Markov model (HSMM). Although autoregressive models can provide efficient and accurate modeling of acoustic features, they have exposure bias, i.e., the mismatch between training (teacher-forcing) and inference (free-running). To overcome this problem, we introduce an autoregressive latent variable sequence, rather than using autoregressive generation of observations. Latent representation of alignment using HSMM-based structured attention mechanism enables the use of a completely consistent training algorithm for acoustic modeling with explicit duration models. Experimental results indicate that the proposed model outperformed baselines in subjective naturalness.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746158","speech synthesis;variational autoencoder;autoregressive model;attention mechanism;hidden semi-Markov model","Training;Conferences;Signal processing algorithms;Signal processing;Linguistics;Acoustics;Inference algorithms","autoregressive processes;hidden Markov models;learning (artificial intelligence);Markov processes;speech synthesis","hidden semiMarkov model-based structured attention;autoregressive speech synthesis model;variational autoencoder incorporating latent sequence representation;acoustic features;linguistic features;autoregressive models;efficient modeling;inference;autoregressive latent variable sequence;HSMM-based;acoustic modeling;explicit duration models;autoregressive variational autoencoder","","1","","35","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Website Recommendation with Side Information Aided Variational Autoencoder","P. Wang; W. Li; Z. Yu; B. Lu; S. Lu","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Sino-German Institutes of Social Computing, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Nanjing Research Institute of Electronics and Engineering, Nanjing, China; Sino-German Institutes of Social Computing, Nanjing University, Nanjing, China","2020 IEEE 39th International Performance Computing and Communications Conference (IPCCC)","5 Apr 2021","2020","","","1","6","Recommender systems had been proposed to help people to find the interested items, such as recommending products to a buyer; identifying movies or music that a user will find interest, etc. However, the existing recommendation approaches mainly focus on capturing user-item interaction patterns for prediction, and ignore the user's side information such as visit frequency and duration. In this paper, we study the side information aided website recommendation problem that using the browsing history of a set of users and their side information to predict the websites that will be of interest to a certain user. We propose a novel recommendation approach called SI-VAE that incorporates side information with the variational autoencoders (VAEs) model for top-k recommendation. The proposed method takes both user-website interaction information and side information as input, and adopts an encoder/decoder model to generate user's interested websites from partial observations. The model of SI-VAE is implemented as a neural network, and trained with a multinomial likelihood objective function to form the ranking of user-website interaction probabilities. We conduct extensive experiments on two real-world datasets, which show that the proposed model outperforms the baselines in a number of performance metrics in website recommendation.","2374-9628","978-1-7281-9829-3","10.1109/IPCCC50635.2020.9391524","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9391524","Variational autoencoder;website recommendation;side information;collaborative filtering","Measurement;Computational modeling;Neural networks;Predictive models;Motion pictures;Linear programming;Recommender systems","probability;recommender systems;Web sites","variational autoencoder;recommender systems;interested items;identifying movies;music;existing recommendation approaches;user-item interaction patterns;visit frequency;website recommendation problem;recommendation approach;SI-VAE;variational autoencoders model;user-website interaction information;interested websites;user-website interaction probabilities","","1","","19","","5 Apr 2021","","","IEEE","IEEE Conferences"
"Learning to Synthesize Cortical Morphological Changes using Graph Conditional Variational Autoencoder","Y. Chai; M. Liu; B. A. Duffy; H. Kim","Stevens Neuroimaging and Informatics Institute Keck School of Medicine University of Southern, California, Los Angeles, CA, United States; Stevens Neuroimaging and Informatics Institute Keck School of Medicine University of Southern, California, Los Angeles, CA, United States; Stevens Neuroimaging and Informatics Institute Keck School of Medicine University of Southern, California, Los Angeles, CA, United States; Stevens Neuroimaging and Informatics Institute Keck School of Medicine University of Southern, California, Los Angeles, CA, United States","2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)","25 May 2021","2021","","","1495","1499","Changes in brain morphology, such as cortical thinning are of great value for understanding the trajectory of brain aging and various neurodegenerative diseases. In this work, we employed a generative neural network variational autoencoder (VAE) that is conditional on age and is able to generate cortical thickness maps at various ages given an input cortical thickness map. To take into account the mesh topology in the model, we proposed a loss function based on weighted adjacency to integrate the surface topography defined as edge connections with the cortical thickness mapped as vertices. Compared to traditional conditional VAE that did not use the surface topological information, our method better predicted “future” cortical thickness maps, especially when the age gap became wider. Our model has the potential to predict the distinctive temporo-spatial pattern of individual cortical morphology in relation to aging and neurodegenerative diseases.","1945-8452","978-1-6654-1246-9","10.1109/ISBI48211.2021.9433837","National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9433837","Cortical thickness;variational autoencoders;deep neural network;graph;brain aging","Network topology;Surface morphology;Morphology;Aging;Predictive models;Surface topography;Trajectory","biomedical MRI;brain;diseases;graph theory;medical image processing;neural nets;neurophysiology;spatiotemporal phenomena","individual cortical morphology;age gap;future cortical thickness maps;surface topological information;traditional conditional VAE;edge connections;surface topography;weighted adjacency;loss function;mesh topology;input cortical thickness map;generative neural network variational autoencoder;neurodegenerative diseases;brain aging;cortical thinning;brain morphology;graph conditional variational autoencoder;cortical morphological changes","","1","","20","IEEE","25 May 2021","","","IEEE","IEEE Conferences"
"Singing Fundamental Frequency Contour Generation Using Generalized Command-Response Model and Score-Conditional Variational Autoencoder","S. Seki; H. Taga; T. Toda","NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation; Graduate School of Informatics; Information Technology Center, Nagoya University","2021 IEEE 31st International Workshop on Machine Learning for Signal Processing (MLSP)","15 Nov 2021","2021","","","1","3","This paper proposes a method for achieving physically motivated and interpretable control of fundamental frequency (F0) contour generation in singing aid systems for laryngectomees. Recently proposed variational autoencoder (VAE)-based method, VAE-SPACE, has successfully generated singing F0 contours from musical scores. However, VAE-SPACE can generate physically deviated F0 contours. Moreover, to represent fluctuations in F0 contours, VAE-SPACE requires manual adjustment of noise components used as the input with musical scores. To address these issues, the proposed method 1) introduces a generalized command-response (GCR) model to represent an F0 contour as an approximation of a physical F0 production mechanism, and 2) employs a conditional VAE (CVAE) to treat musical scores and the noise components separately. The experimental results reveal that the proposed method achieves comparable performance as VAE-SPACE without the manual adjustment of noise components and makes it possible to control F0 contours more intuitively by using the trained GCR model.","1551-2541","978-1-7281-6338-3","10.1109/MLSP52302.2021.9596428","CREST(grant numbers:JP-MJCR19A3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9596428","Singing aid system;F0 contour generation;Generalized command-response model;Conditional variational autoencoder","Fluctuations;Conferences;Music;Manuals;Production;Machine learning;Signal processing","approximation theory;music;neural nets;speech synthesis","musical scores;generalized command-response model;physical F0 production mechanism;conditional VAE;VAE-SPACE;fundamental frequency contour generation;score-conditional variational autoencoder;variational autoencoder-based method;GCR model;CVAE;laryngectomees;singing aid systems;speech synthesis","","","","23","IEEE","15 Nov 2021","","","IEEE","IEEE Conferences"
"Large Dimension Parameterization with Convolutional Variational Autoencoder: An Application in the History Matching of Channelized Geological Facies Models","J. Potratz; S. W. A. Canchumuni; J. D. Bermudez Castro; A. A. Emerick; M. A. C. Pacheco","Dept. of Electrical Engineering, Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro, Brazil; Dept. of Electrical Engineering, Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro, Brazil; Dept. of Electrical Engineering, Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro, Brazil; Petrobras Research and Development Center Petrobras, Rio de Janeiro, Brazil; Dept. of Electrical Engineering, Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro, Brazil","2020 20th International Conference on Computational Science and Its Applications (ICCSA)","18 Nov 2020","2020","","","23","32","History matching is the problem of assimilating dynamic data in numerical models of oil and gas reservoirs. Among the methods available in the literature, the iterative ensemble smothers are often used in practice. However, these methods assume that all variables are Gaussian, which limits their application in a problem where the objective is to update the distribution of rock types (facies) in the model. In fact, updating models of geological facies using dynamic data is still an open issue in the oil industry. The problem relies on the development of a parametrical model able to preserve the geological realism of the models. In this context, parameterization techniques based on deep learning, such as convolutional variational autoencoders network (CVAE), have shown promising results in this area when combined with ensemble smothers. Nevertheless, these types of networks present difficulties of scalability for large-sized reservoir models, because as the input dimension increases, the number of network parameters increases exponentially. This work addresses this problem by introducing two new CVAE-based network architectures that can be used for modeling large-scale reservoir models. The first proposed network incorporates the “depthwise separable convolution” in its design, while the second introduces the “inception module”. Results show a considerable reduction of trainable parameters for the first network, while, for the second one, the number becomes invariant to the input dimension.","","978-1-7281-9260-4","10.1109/ICCSA50381.2020.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9257505","convolutional variational autoencoders;history matching;parameterization;large-scale","Reservoirs;Two dimensional displays;Convolution;Deep learning;Numerical models;Computer architecture;History","convolution;data assimilation;geology;geophysical prospecting;hydrocarbon reservoirs;iterative methods;petroleum industry;rocks;statistical analysis","large-scale reservoir models;depthwise separable convolution;input dimension;dimension parameterization;convolutional variational autoencoder;history matching;channelized geological facies models;dynamic data;numerical models;gas reservoirs;iterative ensemble smothers;rock types;oil industry;parametrical model;geological realism;parameterization techniques;convolutional variational autoencoders network;large-sized reservoir models;network parameters;CVAE-based network architectures","","","","23","","18 Nov 2020","","","IEEE","IEEE Conferences"
"Deep image hashing based on twin-bottleneck hashing with variational autoencoders","M. Verwilst; N. Žižakić; L. Gu; A. Pižurica","Group for Artificial Intelligence and Sparse Modelling (GAIM), TELIN, Ghent University, Ghent, Belgium; Group for Artificial Intelligence and Sparse Modelling (GAIM), TELIN, Ghent University, Ghent, Belgium; Group for Artificial Intelligence and Sparse Modelling (GAIM), TELIN, Ghent University, Ghent, Belgium; Group for Artificial Intelligence and Sparse Modelling (GAIM), TELIN, Ghent University, Ghent, Belgium","2021 IEEE 23rd International Workshop on Multimedia Signal Processing (MMSP)","16 Mar 2022","2021","","","1","6","With the ever-increasing availability of data, the need for efficient and accurate image retrieval methods has become larger and larger. Deep hashing has proven to be a promising solution, by defining a hash function to convert the data into a manageable lower-dimensional representation. In this paper, we apply recent insights from the field of variational autoencoders to the field of deep image hashing, thus achieving an improvement over the current state of the art as shown by experimental evaluation. The code used in this paper is open-source and available on GitHub (https://github.com/maximverwilst/deepimagehashing-VAE).","2473-3628","978-1-6654-3288-7","10.1109/MMSP53017.2021.9733464","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9733464","Image hashing;deep hashing;content-based image retrieval;variational autoencoders;unsupervised deep learning","Hash functions;Deep learning;Adaptation models;Codes;Conferences;Image retrieval;Signal processing","computer vision;cryptography;file organisation;image retrieval;neural nets","deep image hashing;twin-bottleneck hashing;variational autoencoders;hash function;lower-dimensional representation;image retrieval methods;variational autoencoder","","","","50","IEEE","16 Mar 2022","","","IEEE","IEEE Conferences"
"Variational Autoencoders for Localized Mesh Deformation Component Analysis","Q. Tan; L. -X. Zhang; J. Yang; Y. -K. Lai; L. Gao","University of Maryland, College Park, MD, USA; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; School of Computer Science & Informatics, Cardiff University, Cardiff, U.K.; University of Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","14 Sep 2022","2022","44","10","6297","6310","Spatially localized deformation components are very useful for shape analysis and synthesis in 3D geometry processing. Several methods have recently been developed, with an aim to extract intuitive and interpretable deformation components. However, these techniques suffer from fundamental limitations especially for meshes with noise or large-scale nonlinear deformations, and may not always be able to identify important deformation components. In this paper we propose a mesh-based variational autoencoder architecture that is able to cope with meshes with irregular connectivity and nonlinear deformations, assuming that the analyzed dataset contains meshes with the same vertex connectivity, which is common for deformation analysis. To help localize deformations, we introduce sparse regularization in this framework, along with spectral graph convolutional operations. Through modifying the regularization formulation and allowing dynamic change of sparsity ranges, we improve the visual quality and reconstruction ability of the extracted deformation components. Our system also provides a nonlinear approach to reconstruction of meshes using the extracted basis, which is more effective than the current linear combination approach. As an important application of localized deformation components and a novel approach on its own, we further develop a neural shape editing method, achieving shape editing and deformation component extraction in a unified framework, and ensuring plausibility of the edited shapes. Extensive experiments show that our method outperforms state-of-the-art methods in both qualitative and quantitative evaluations. We also demonstrate the effectiveness of our method for neural shape editing.","1939-3539","","10.1109/TPAMI.2021.3085887","Youth Innovation Promotion Association of the Chinese Academy of Sciences(grant numbers:2019108); National Natural Science Foundation of China(grant numbers:61872440,62061136007); Natural Science Foundation of Beijing Municipality(grant numbers:L182016); Tencent AI Lab Rhino-Bird Focused Research Program(grant numbers:JR202024); Newton Advanced Fellowship from the Royal Society(grant numbers:NAF\R2\192151); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9444875","3D meshes;variational autoencoder;graph convolution;sparsity regularization","Strain;Shape;Three-dimensional displays;Principal component analysis;Geometry;Convolution;Solid modeling","approximation theory;computational geometry;deformation;feature extraction;graph theory;image reconstruction;image representation;iterative methods;medical image processing;mesh generation;solid modelling","extracted deformation components;localized deformation components;neural shape editing method;deformation component extraction;variational autoencoders;localized mesh deformation component;shape analysis;intuitive deformation components;interpretable deformation components;important deformation components;mesh-based variational autoencoder architecture;nonlinear deformations;deformation analysis;regularization formulation;allowing dynamic change","","","","58","IEEE","1 Jun 2021","","","IEEE","IEEE Journals"
"Preservation of Anomalous Subgroups On Variational Autoencoder Transformed Data","S. C. Maina; R. E. Bryant; W. O. Ogallo; K. R. Varshney; S. Speakman; C. Cintas; A. Walcott-Bryant; R. -F. Samoilescu; K. Weldemariam","IBM Research, Nairobi, Kenya; IBM Research, Nairobi, Kenya; IBM Research, Nairobi, Kenya; IBM Research, Nairobi, Kenya; IBM Research, Nairobi, Kenya; IBM Research, Nairobi, Kenya; IBM Research, Nairobi, Kenya; IBM Research, Nairobi, Kenya; IBM Research, Nairobi, Kenya","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","3627","3631","We investigate the effect of variational autoencoder (VAE) based data anonymization and its ability to preserve anomalous subgroup properties. We present a Utility Guaranteed Deep Privacy (UGDP) system which casts existing anomalous pattern detection methods as a new utility measure for data synthesis. UGDP's approach shows that properties of an anomalous subset of records, identified in the original data set, are preserved through the anonymization of a VAE. This is despite the newly generated records being completely synthetic. More specifically, the Bias-Scan algorithm identifies a subgroup of records that are consistently over- (or under-) risked by a black-box classifier as an area of 'poor fit'. This scanning process is applied on both pre- and post- VAE synthesized data. The areas of poor fit (i.e. anomalous records) persist in both settings. We evaluate our approach using publicly available datasets from the financial industry. Our evaluation confirmed that the approach is able to produce synthetic datasets that preserved a high level of subgroup differentiation as identified initially in the original dataset. Such a distinction was maintained while having distinctly different records between the synthetic and original dataset.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9054495","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054495","privacy;bias;anonymization;variational autoencoder","Data privacy;Conferences;Signal processing algorithms;Signal processing;Classification algorithms;Speech processing;Financial industry","data analysis;data mining;data privacy;learning (artificial intelligence);pattern classification;security of data","anomalous subgroups;variational autoencoder transformed data;variational autoencoder based data anonymization;anomalous subgroup properties;utility guaranteed deep privacy system;anomalous pattern detection methods;utility measure;data synthesis;black-box classifier;scanning process;post- VAE synthesized data;synthetic datasets;subgroup differentiation;different records;UGDP approach;bias-scan algorithm","","","","32","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Jointly Trained Variational Autoencoder for Multi-Modal Sensor Fusion","T. Korthals; M. Hesse; J. Leitner; A. Melnik; U. Rückert","Bielefeld University, Cognitronics & Sensor Systems, Bielefeld, Germany; Bielefeld University, Cognitronics & Sensor Systems, Bielefeld, Germany; Australian Centre for Robotic Vision, Queensland University of Technology, Brisbane, Australia; Bielefeld University, Cognitronics & Sensor Systems, Bielefeld, Germany; Bielefeld University, Cognitronics & Sensor Systems, Bielefeld, Germany","2019 22th International Conference on Information Fusion (FUSION)","27 Feb 2020","2019","","","1","8","This work presents the novel multi-modal Variational Autoencoder approach $\mathbf{M}^{\mathbf{2}}\mathbf{VAE}$ which is derived from the complete marginal joint log-likelihood. This allows the end-to-end training of Bayesian information fusion on raw data for all subsets of a sensor setup. Furthermore, we introduce the concept of in-place fusion – applicable to distributed sensing - where latent embeddings of observations need to be fused with new data. To facilitate in-place fusion even on raw data, we introduced the concept of a re-encoding loss that stabilizes the decoding and makes visualization of latent statistics possible. We also show that the $\mathbf{M}^{\mathbf{2}}\mathbf{VAE}$ finds a coherent latent embedding, such that a single naïve Bayes classifier performs equally well on all permutations of a bi-modal Mixture-of-Gaussians signal. Finally, we show that our approach outperforms current VAE approaches on a bi-modal MNIST & fashion-MNIST data set and works sufficiently well as a preprocessing on a tri-modal simulated camera & LiDAR data set from the Gazebo simulator.","","978-0-9964527-8-6","10.23919/FUSION43075.2019.9011314","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9011314","Multi-Modal Fusion;Deep Generative Model;Variational Autoencoder","Biological system modeling;Encoding;Robot sensing systems;Sensor fusion;Training;Decoding;Laser radar","Bayes methods;belief networks;cameras;decoding;encoding;optical radar;sensor fusion;signal classification","in-place fusion;distributed sensing;latent statistics;M2VAE;coherent latent embedding;jointly trained Variational Autoencoder;multimodal sensor fusion;multimodal variational autoencoder;complete marginal joint log-likelihood;end-to-end training;Bayesian information fusion;trimodal simulated camera;LiDAR data;bimodal MNIST;fashion-MNIST data;bimodal mixture-of-Gaussians signal;single Naive-Bayes classifier;Gazebo simulator;reencoding loss","","","","28","","27 Feb 2020","","","IEEE","IEEE Conferences"
"Using Deconvolutional Variational Autoencoder for Answer Selection in Community Question Answering","G. A. Boroujeni; H. Faili","School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Tehran, Iran; School of Electrical and Computer Engineering, College of Engineering, University of Tehran, Tehran, Iran","2020 11th International Conference on Information and Knowledge Technology (IKT)","10 Feb 2021","2020","","","35","39","Answer selection in community question answering is a challenging task in natural language processing. The main problem is that there is no evaluation for the answers given by the users and one should go through all possible answers for assessing them, which is exhausting and time consuming. In this paper we propose a latent-variable model for learning the representations of the question and answer, by jointly optimizing generative and discriminative objectives. This model uses variational autoencoders (VAE) in a multi-task learning process with a classifier to produces a representation for each answer by which the classifier could classify it's relation with correspond question with a high performance. The experimental results on two public datasets, SemEval 2015 and SemEval 2017, recognize the significance of the proposed framework, especially for the semi-supervised setting. The results showed that the proposed model outperformed F1 of state-of-the-art method up to about 8% for SemEval 2015 and about 5% for SemEva1 2017.","","978-1-6654-0441-9","10.1109/IKT51791.2020.9345624","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9345624","community question answering;answer selection;convolutional-deconvolutional;variational autoencoder","Semantics;Tagging;Knowledge discovery;Natural language processing;Task analysis","learning (artificial intelligence);natural language processing;question answering (information retrieval);text analysis;unsupervised learning","correspond question;classifier;multitask learning process;variational autoencoders;latent-variable model;possible answers;natural language processing;community question answering;answer selection;deconvolutional variational autoencoder;SemEval 2017;SemEval 2015","","","","22","","10 Feb 2021","","","IEEE","IEEE Conferences"
"EndoVAE: Generating Endoscopic Images with a Variational Autoencoder","D. E. Diamantis; P. Gatoula; D. K. Iakovidis","Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, Greece; Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, Greece; Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, Greece","2022 IEEE 14th Image, Video, and Multidimensional Signal Processing Workshop (IVMSP)","11 Jul 2022","2022","","","1","5","The generalization performance of deep learning models is closely associated with the number and diversity of data available upon training. While in many applications there is a large number of data available in public, in domains such as medical image analysis, the data availability is limited. This can be largely attributed to data privacy legislations, including the General Data Protection Regulation (GDPR), and the cost of data annotation by experts. Aiming to address this issue, data augmentation approaches employing deep generative models have emerged. Existing augmentation techniques are primarily based on Generative Adversarial Networks (GANs). However, ill-posed training issues of GANs such as nonconvergence, mode collapse and instability in conjunction with their demand for large scale training datasets, complicate their use in medical imaging modalities. Motivated by these issues, this paper investigates the performance of alternative generative models i.e., Variational Autoencoders (VAEs) in endoscopic image synthesis tasks. Contrary to the conventional GAN-based approaches that aiming at augmenting the existing endoscopic datasets the proposed methodology constitutes feasible the complete substitution of medical imaging datasets from real individuals with artificially generated ones. The experimental results obtained validate the effectiveness of the proposed methodology over the state-of-art.","","978-1-6654-7822-9","10.1109/IVMSP54334.2022.9816329","European Regional Development Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9816329","Wireless Capsule Endoscopy;Variational Autoencoders;Medical Image Synthesis","Training;Wireless communication;Solid modeling;Image synthesis;Generative adversarial networks;Data models;Task analysis","data privacy;data protection;endoscopes;learning (artificial intelligence);legislation;medical image processing;security of data","EndoVAE;generating endoscopic images;Variational autoencoder;generalization performance;deep learning models;medical image analysis;data availability;data privacy legislations;General Data Protection Regulation;data annotation;data augmentation;deep generative models;augmentation techniques;Generative Adversarial Networks;GANs;ill-posed training issues;mode collapse;instability;scale training datasets;medical imaging modalities;alternative generative models i.e;Variational Autoencoders;endoscopic image synthesis tasks;conventional GAN-based approaches;existing endoscopic datasets;medical imaging datasets;artificially generated ones","","","","24","IEEE","11 Jul 2022","","","IEEE","IEEE Conferences"
"Fault Diagnosis of Machines Using Deep Convolutional Beta-Variational Autoencoder","G. Dewangan; S. Maurya","Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India; Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India","IEEE Transactions on Artificial Intelligence","24 Mar 2022","2022","3","2","287","296","Industries are using fault diagnosis methods to prevent any downtime, which eventually led them to make profits and take necessary steps beforehand to avoid any mishaps. In recent years, deep learning methods have shown extraordinary performance in massive data applications with advancement in computing power. In this article, a novel intelligent fault diagnosis scheme based on deep convolutional variable-beta variational autoencoder (VAE) is proposed to extract discriminative features. A new min–max algorithm for data points reduction and a random sampling technique to get 2-D data has been proposed. The proposed fault diagnosis combines all intermediate steps (from preprocessing to classification) in a single framework, and an end-to-end training has been performed. The proposed training method with variable beta uses VAE as a feature extractor and classifier rather than just being a probabilistic generative model, which further improved the performance of the overall model. The proposed scheme reduces the needs of domain/expertise knowledge on time-series data. The proposed method has also been validated in the presence of noise. The proposed approach is validated through two case studies by utilizing rotating machinery datasets: First, on the case western reserve university vibration dataset (VD), and second, on the air compressor acoustic dataset (AD). Highest accuracies obtained are 99.93% and 99.91% on case western reserve university VD and air compressor AD, respectively, using the proposed scheme. Finally, a comparative study has been presented.","2691-4581","","10.1109/TAI.2021.3110835","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9536242","Convolution neural network (CNN);fault diagnosis;variable-beta;variational autoencoder (VAE)","Fault diagnosis;Feature extraction;Convolution;Convolutional neural networks;Machinery;Vibrations;Data models","fault diagnosis;feature extraction;learning (artificial intelligence);machinery;vibrations","intermediate steps;end-to-end training;training method;variable beta;VAE;feature extractor;classifier;probabilistic generative model;time-series data;case western reserve university vibration dataset;case western reserve university VD;deep convolutional beta-variational autoencoder;fault diagnosis methods;deep learning methods;extraordinary performance;massive data applications;computing power;novel intelligent fault diagnosis scheme;variable-beta variational autoencoder;discriminative features;min-max algorithm;data points reduction;random sampling technique","","","","51","IEEE","13 Sep 2021","","","IEEE","IEEE Journals"
"An Anomaly Detection Model for ADS-B Systems Using a LSTM-based Variational Autoencoder","X. Guo; C. Zhu; J. Yang; Y. Xiao","Key Laboratory of Grain Information Processing and Control (Henan University of Technology), Ministry of Education College of Information Science and Engineering, Henan University of Technology, Zhengzhou, China; Key Laboratory of Grain Information Processing and Control (Henan University of Technology), Ministry of Education College of Information Science and Engineering, Henan University of Technology, Zhengzhou, China; Key Laboratory of Grain Information Processing and Control (Henan University of Technology), Ministry of Education College of Information Science and Engineering, Henan University of Technology, Zhengzhou, China; Zhengzhou Locaris Technology Co., Ltd, Zhengzhou, China","2021 IEEE 3rd International Conference on Civil Aviation Safety and Information Technology (ICCASIT)","10 Dec 2021","2021","","","1005","1009","Automatic Dependent Surveillance-Broadcast (ADS-B) is an important part of the next generation air transportation system, but its protocol does not provide relevant authentication and data encryption, so it is extremely vulnerable to various spoofing attacks. Therefore, it is necessary to develop a set of ADS-B data anomaly detection models. According to the strong temporal dependence and fast update rate of ADS-B data, we initiatively introduce a novel anomaly detection model based on variational autoencoder and long short-term memory networks (VAE-LSTM). In the model, we focus on reconstructing the expected distribution of ADS-B data, which is called reconstruction probability. At the same time, to model ADS-B data with the temporal dependence, we use the LSTM networks as the main architecture of the model, which is able to make use of long-term temporal dependence and avoid the vanishing gradient problem during training. Experiments show that the proposed model has a higher area under the receiver operating characteristic curve and the precision-recall curve than the other baseline methods from the literature, and reveal that the model has better performance of anomaly detection of ADS-B data.","","978-1-6654-2518-6","10.1109/ICCASIT53235.2021.9633677","National Natural Science Foundation of China; Henan University; Henan University; Henan University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9633677","anomaly detection;deep learning;variational autoencoder networks;long short-term memory networks;ADS-B","Training;Protocols;Training data;Detectors;Receivers;Data models;Safety","cryptography;learning (artificial intelligence);recurrent neural nets;telecommunication security;video surveillance","ADS-B systems;LSTM-based variational autoencoder;automatic dependent surveillance-broadcast;next generation air transportation system;relevant authentication;data encryption;ADS-B data anomaly detection models;strong temporal dependence;long short-term memory networks;VAE-LSTM;LSTM networks;long-term temporal dependence;variational autoencoder;reconstruction probability;receiver operating characteristic curve;precision-recall curve","","","","13","IEEE","10 Dec 2021","","","IEEE","IEEE Conferences"
"Spatiotemporal Fusion Network for Land Surface Temperature Based on a Conditional Variational Autoencoder","Y. Chen; Y. Yang; X. Pan; X. Meng; J. Hu","School of Earth Sciences and Engineering, Hohai University, Nanjing, China; School of Earth Sciences and Engineering, Hohai University, Nanjing, China; School of Earth Sciences and Engineering, Hohai University, Nanjing, China; School of Earth Sciences and Engineering, Hohai University, Nanjing, China; School of Earth Sciences and Engineering, Hohai University, Nanjing, China","IEEE Transactions on Geoscience and Remote Sensing","28 Jun 2022","2022","60","","1","13","High spatiotemporal resolution land surface temperature (LST) data are essential for dynamic monitoring and prediction in climate change research. Due to the limitations of remote sensing instruments, the current platforms have difficulty in achieving a compromise between high spatial and temporal resolutions for LST products. In this study, we propose a spatiotemporal fusion network for LST based on a conditional variational autoencoder (CVAE-LSTFM). First, an improved network is designed based on the CVAE by reconstructing an encoder and a decoder. To generate fine LST images based on dense time series, a variational inference model is formulated to integrate coarse and fine LST image pairs in variational autoencoded latent space. In addition, a new compound loss function for the proposed training method is designed to reduce the effects of noise and outliers. Then, a pretraining mechanism is adopted to optimize the network training process, and the parameters can be transferred to the training network of the CVAE to accelerate network convergence. Finally, a novel weighting strategy that considers spatiotemporal variations in LST (LST consistency weighting) is employed to solve the spatiotemporal heterogeneity problem caused by the rapid changes in LST. The method is quantitatively tested and evaluated in the Heihe River Basin using FY-4A LST and MODIS LST from September 2019. Compared with two traditional models and two deep learning-based models, CVAE-LSTFM yields lower root-mean-square error (RMSE) (average < 1.26 K) and learning perceptual image patch similarity (LPIPS, average < 0.13) values and higher structural similarity (SSIM, average  $>0.96$ ). In practice, CVAE-LSTFM can generate high spatiotemporal resolution LST values (hourly LST with a 1-km spatial resolution) with high accuracy, quality, and robustness.","1558-0644","","10.1109/TGRS.2022.3183114","General Programs of the National Natural Science Foundation of China(grant numbers:42071346); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9795341","Conditional variational autoencoder (CVAE);convolutional neural network (CNN);land surface temperature (LST);pretraining;spatiotemporal fusion","Spatiotemporal phenomena;Land surface temperature;Spatial resolution;Climate change;Data models;Temperature sensors;Biological system modeling","geophysical image processing;geophysical techniques;image classification;image resolution;land surface temperature;learning (artificial intelligence);mean square error methods;remote sensing;rivers;spatiotemporal phenomena;statistical analysis;time series","deep learning-based models;CVAE-LSTFM yields lower root-mean-square error;high spatiotemporal resolution LST values;hourly LST;spatiotemporal fusion network;conditional variational autoencoder;high spatiotemporal resolution land surface temperature data;high spatial resolutions;temporal resolutions;LST products;improved network;fine LST images;variational inference model;coarse image pairs;fine LST image pairs;variational autoencoded latent space;network training process;training network;network convergence;spatiotemporal variations;LST consistency weighting;spatiotemporal heterogeneity problem","","","","53","IEEE","14 Jun 2022","","","IEEE","IEEE Journals"
"Using Variational Autoencoders to Increase the Performance of Malware Classification","T. Taylor; A. Eleyan","Department of Computing and Mathematics, Manchester Metropolitan University, Manchester, United Kingdom; Department of Computing and Mathematics, Manchester Metropolitan University, Manchester, United Kingdom","2021 International Symposium on Networks, Computers and Communications (ISNCC)","25 Nov 2021","2021","","","1","6","Often complex datasets will have a large number of features for each of its samples. Sometimes, this can have a negative effect on the performance of models trained on the raw data. By reducing the number of features this problem can be avoided. However, this may cause a loss of information. One method to mitigate this is by using a type of unsupervised neural network structure called autoencoders. Autoencoders can be used to generate a reduced feature space which the models can then be trained on. This paper uses Convolutional Variational Autoencoders in order to create these latent features and then determines their effectiveness of improving performance of machine learning classifier models.","","978-1-6654-0304-7","10.1109/ISNCC52172.2021.9615643","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9615643","Machine Learning;Neural Networks;Autoencoders;Variational Autoencoders;Cybersecurity;Malware;Malware Classification","Computers;Computational modeling;Neural networks;Machine learning;Malware;Data models;Bayes methods","invasive software;learning (artificial intelligence);neural nets;pattern classification","malware classification;complex datasets;raw data;unsupervised neural network structure;reduced feature space;Convolutional Variational Autoencoders;latent features;machine learning classifier models","","","","25","IEEE","25 Nov 2021","","","IEEE","IEEE Conferences"
"Anomaly based Resilient Network Intrusion Detection using Inferential Autoencoders","A. Hannan; C. Gruhl; B. Sick","Intelligent Embedded Systems, Universität Kassel Kassel, Germany; Intelligent Embedded Systems, Universität Kassel Kassel, Germany; Intelligent Embedded Systems, Universität Kassel Kassel, Germany","2021 IEEE International Conference on Cyber Security and Resilience (CSR)","6 Sep 2021","2021","","","1","7","This article focuses on the application of conditional variational autoencoders as anomaly detectors to identify emerging threats in computer networks. Autoencoders are machine learning techniques that are used to find lower-dimensional representations, i.e. an encoding in latent space, from input space. With variational Autoencoders (VAE) this representation is not a single code word or vector but a probability distribution – greatly improving the robustness of the coding scheme. In contrast to VAE, we present a conditional variational autoencoder (CVAE), which uses the latent representation to encode regular and malicious network traffic into a bimodal distribution. While regular autoencoders are unsupervised, we require some labeled data to tune the bimodal representations, thus turning the learning problem into a semi-supervised classification task. However, unknown threats (i.e. those not contained in labeled training data) can be detected as well. In our presented case study, based on available computer network datasets (KDD99 and CIC-IDS2017), we could improve the detection of unknown threats compared to conventional approaches. Our experiments are publicly available.","","978-1-6654-0285-9","10.1109/CSR51186.2021.9527980","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9527980","Cyber Security;Anomaly Detection;Resilience;Artificial Intelligence;Network Intrusion Detection;Autoencoders;Variational Autoencoders","Training data;Telecommunication traffic;Turning;Encoding;Computer networks;Robustness;Probability distribution","computer network security;feature extraction;neural nets;pattern classification;probability;supervised learning;unsupervised learning","inferential autoencoders;conditional variational autoencoder;computer network threats;machine learning;probability distribution;malicious network traffic;bimodal distribution;bimodal representations;anomaly based resilient network intrusion detection;unsupervised autoencoders;semi-supervised classification","","","","18","","6 Sep 2021","","","IEEE","IEEE Conferences"
"CVA2E: A Conditional Variational Autoencoder With an Adversarial Training Process for Hyperspectral Imagery Classification","X. Wang; K. Tan; Q. Du; Y. Chen; P. Du","Key Laboratory for Land Environment and Disaster Monitoring of National Administration of Surveying and Geoinformation (NASG), China University of Mining and Technology, Xuzhou, China; Key Laboratory for Land Environment and Disaster Monitoring of National Administration of Surveying and Geoinformation (NASG), China University of Mining and Technology, Xuzhou, China; Department of Electrical and Computer Engineering, Mississippi State University, Mississippi State, USA; Key Laboratory for Land Environment and Disaster Monitoring of National Administration of Surveying and Geoinformation (NASG), China University of Mining and Technology, Xuzhou, China; Key Laboratory for Satellite Mapping Technology and Applications of National Administration of Surveying and Geoinformation (NASG), Nanjing University, Nanjing, China","IEEE Transactions on Geoscience and Remote Sensing","21 Jul 2020","2020","58","8","5676","5692","Deep generative models such as the generative adversarial network (GAN) and the variational autoencoder (VAE) have obtained increasing attention in a wide variety of applications. Nevertheless, the existing methods cannot fully consider the inherent features of the spectral information, which leads to the applications being of low practical performance. In this article, in order to better handle this problem, a novel generative model named the conditional variational autoencoder with an adversarial training process (CVA2E) is proposed for hyperspectral imagery classification by combining variational inference and an adversarial training process in the spectral sample generation. Moreover, two penalty terms are added to promote the diversity and optimize the spectral shape features of the generated samples. The performance on three different real hyperspectral data sets confirms the superiority of the proposed method.","1558-0644","","10.1109/TGRS.2020.2968304","National Natural Science Foundation of China(grant numbers:41871337); Priority Academic Program Development of Jiangsu Higher Education Institutions; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8989966","Generative adversarial network (GAN);hyperspectral image (HSI) classification;variational autoencoder (VAE)","Gallium nitride;Generative adversarial networks;Training;Hyperspectral imaging;Data models;Generators","convolutional neural nets;feature extraction;hyperspectral imaging;image classification;learning (artificial intelligence)","spectral shape features;spectral sample generation;variational inference;generative model;generative adversarial network;deep generative models;hyperspectral imagery classification;adversarial training process;conditional variational autoencoder","","18","","29","IEEE","10 Feb 2020","","","IEEE","IEEE Journals"
"A Multimodal Anomaly Detector for Robot-Assisted Feeding Using an LSTM-Based Variational Autoencoder","D. Park; Y. Hoshi; C. C. Kemp","Healthcare Robotics Lab, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Healthcare Robotics Lab, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Healthcare Robotics Lab, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Robotics and Automation Letters","23 Feb 2018","2018","3","3","1544","1551","The detection of anomalous executions is valuable for reducing potential hazards in assistive manipulation. Multimodal sensory signals can be helpful for detecting a wide range of anomalies. However, the fusion of high-dimensional and heterogeneous modalities is a challenging problem for model-based anomaly detection. We introduce a long short-term memory-based variational autoencoder (LSTM-VAE) that fuses signals and reconstructs their expected distribution by introducing a progress-based varying prior. Our LSTM-VAE-based detector reports an anomaly when a reconstruction-based anomaly score is higher than a state-based threshold. For evaluations with 1555 robot-assisted feeding executions, including 12 representative types of anomalies, our detector had a higher area under the receiver operating characteristic curve of 0.8710 than 5 other baseline detectors from the literature. We also show the variational autoencoding and state-based thresholding are effective in detecting anomalies from 17 raw sensory signals without significant feature engineering effort.","2377-3766","","10.1109/LRA.2018.2801475","NSF(grant numbers:IIS-1150157); NIDILRR(grant numbers:90RE5016-01-00); Google Faculty Research Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8279425","Failure detection and recovery;deep learning in robotics and automation;assistive robots","Robot sensing systems;Anomaly detection;Hidden Markov models;Detectors;Decoding;Gaussian distribution","assisted living;handicapped aids;learning (artificial intelligence);manipulators;medical robotics;neural nets;sensor fusion;service robots;signal representation;variational techniques","anomalous executions;potential hazards;assistive manipulation;multimodal sensory signals;high-dimensional modalities;heterogeneous modalities;anomaly detection;short-term memory;variational autoencoder;LSTM-VAE;anomaly score;feeding executions;variational autoencoding;multimodal anomaly detector;signal fusion;baseline detectors;raw sensory signals;long short-term memory-based variational autoencoder;1555 robot-assisted feeding execution;receiver operating characteristic curve;state-based thresholding","","155","","36","IEEE","2 Feb 2018","","","IEEE","IEEE Journals"
"Scalable Variational Quantum Circuits for Autoencoder-based Drug Discovery","J. Li; S. Ghosh","Department of Computer Science and Engineering, The Pennsylvania State University; Department of Computer Science and Engineering, The Pennsylvania State University","2022 Design, Automation & Test in Europe Conference & Exhibition (DATE)","19 May 2022","2022","","","340","345","The de novo design of drug molecules is recognized as a time-consuming and costly process, and computational approaches have been applied in each stage of the drug discovery pipeline. Variational autoencoder is one of the computer-aided design methods which explores the chemical space based on an existing molecular dataset. Quantum machine learning has emerged as an atypical learning method that may speed up some classical learning tasks because of its strong expressive power. However, near-term quantum computers suffer from limited num-ber of qubits which hinders the representation learning in high dimensional spaces. We present a scalable quantum generative autoencoder (SQ-VAE) for simultaneously reconstructing and sampling drug molecules, and a corresponding vanilla variant (SQ-AE) for better reconstruction. The architectural strategies in hybrid quantum classical networks such as, adjustable quantum layer depth, heterogeneous learning rates, and patched quantum circuits are proposed to learn high dimensional dataset such as, ligand-targeted drugs. Extensive experimental results are reported for different dimensions including 8x8 and 32x32 after choosing suitable architectural strategies. The performance of quantum generative autoencoder is compared with the corre-sponding classical counterpart throughout all experiments. The results show that quantum computing advantages can be achieved for normalized low-dimension molecules, and that high-dimension molecules generated from quantum generative autoencoders have better drug properties within the same learning period.","1558-1101","978-3-9819263-6-1","10.23919/DATE54114.2022.9774564","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9774564","Quantum Machine Learning;Variational Autoen-coder;Drug Discovery","Drugs;Representation learning;Learning systems;Image synthesis;Qubit;Pipelines;Space exploration","chemistry computing;drugs;learning (artificial intelligence);medical computing;molecular biophysics;neural nets;quantum computing","scalable variational quantum circuits;autoencoder-based drug discovery;drug molecules;drug discovery pipeline;variational autoencoder;computer-aided design methods;chemical space;molecular dataset;quantum machine learning;atypical learning method;near-term quantum computers;representation learning;scalable quantum generative autoencoder;hybrid quantum classical networks;adjustable quantum layer depth;heterogeneous learning rates;patched quantum circuits;ligand-targeted drugs;architectural strategy;quantum computing;low-dimension molecules;high-dimension molecules;drug properties;SQ-VAE;vanilla variant;high dimensional dataset learning","","","","23","","19 May 2022","","","IEEE","IEEE Conferences"
"Deep Convolutional Variational Autoencoder as a 2D-Visualization Tool for Partial Discharge Source Classification in Hydrogenerators","R. Zemouri; M. Lévesque; N. Amyot; C. Hudon; O. Kokoko; S. A. Tahan","École de Technologie Supérieure, Montréal, Canada; Institut de Recherche d’Hydro-Québec (IREQ), Varennes, Canada; Institut de Recherche d’Hydro-Québec (IREQ), Varennes, Canada; Institut de Recherche d’Hydro-Québec (IREQ), Varennes, Canada; Institut de Recherche d’Hydro-Québec (IREQ), Varennes, Canada; École de Technologie Supérieure, Montréal, Canada","IEEE Access","10 Jan 2020","2020","8","","5438","5454","Hydrogenerators are strategic assets for power utilities. Their reliability and availability can lead to significant benefits. For decades, monitoring and diagnosis of hydrogenerators have been at the core of maintenance strategies. A significant part of generator diagnosis relies on Partial Discharge (PD) measurements, because the main cause of hydrogenerator breakdown comes from failure of its high voltage stator, which is a major component of hydrogenerators. A study of all stator failure mechanisms reveals that more than 85% of them involve the presence of PD activity. PD signal can be detected from the lead of the hydrogenerator while it is running, thus allowing for on-line diagnosis. Hydro-Québec has been collecting more than 33 000 unlabeled PD measurement files over the last decades. Up to now, this diagnostic technique has been quantified based on global PD amplitudes and integrated PD energy irrespective of the source of the PD signal. Several PD sources exist and they all have different relative risk, but in order to recognize the nature of the PD, or its source, the judgement of experts is required. In this paper, we propose a new method based on visual data analysis to build a PD source classifier with a minimum of labeled data. A convolutional variational autoencoder has been used to help experts to visually select the best training data set in order to improve the performances of the PD source classifier.","2169-3536","","10.1109/ACCESS.2019.2962775","Institut de Recherche d’Hydro-Québec (IREQ); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944065","Hydrogenerators;diagnosis;partial discharges;deep neural networks;convolutional variational autoencoder;data visualization;feature extraction;model interpretation;generative model","Partial discharges;Training data;Tools;Training;Visualization;Maintenance engineering;Data visualization","convolutional neural nets;data analysis;data visualisation;failure (mechanical);hydroelectric generators;maintenance engineering;mechanical engineering computing;partial discharges;reliability;signal classification;signal detection;stators;variational techniques","deep convolutional variational autoencoder;partial discharge source classification;generator diagnosis;hydrogenerator breakdown;stator failure;PD signal detection;PD source classifier;2D-visualization tool;power utilities;maintenance strategies;Hydro-Québec;visual data analysis;hydrogenerator reliability","","21","","50","CCBY","27 Dec 2019","","","IEEE","IEEE Journals"
"A Multi-Scale Electricity Consumption Prediction Algorithm Based on Time-Frequency Variational Autoencoder","K. Zheng; P. Li; S. Zhou; W. Zhang; S. Li; L. Zeng; Y. Zhang","China Southern Power Grid, Digital Grid Research Institute, Guangzhou, China; China Southern Power Grid, Digital Grid Research Institute, Guangzhou, China; China Southern Power Grid, Digital Grid Research Institute, Guangzhou, China; China Southern Power Grid, Digital Grid Research Institute, Guangzhou, China; China Southern Power Grid, Digital Grid Research Institute, Guangzhou, China; China Southern Power Grid, Digital Grid Research Institute, Guangzhou, China; China Southern Power Grid, Digital Grid Research Institute, Guangzhou, China","IEEE Access","29 Jun 2021","2021","9","","90937","90946","Accurate electricity consumption forecasting can be treated as a reliable guidance for power production. However, traditional electricity forecasting models suffer from simultaneously capturing the periodicity and the volatility of sequential electricity consumption data, while the periodicity and the volatility are important for electricity forecasting. In order to effectively model this sequential data and predict electricity consumption accurately, we propose a multi-scale prediction (Long Short Term Memory, LSTM) algorithm based on Time-Frequency Variational Autoencoder (TFVAE-LSTM). The proposed algorithm treats the sequential data as a superposition of data in different frequencies, it defines an encoder in frequency domain to extract frequency features to model the periodicity and volatility, and defines a decoder in time domain to capture the sequential features of data. Based on the extracted Time-Frequency features in a TFVAE, a multi-scale LSTM model is defined to further extract sequential features from different scales to predict electricity consumption. Experiments show the effectiveness of the proposed TFVAE-LSTM for electricity consumption forecasting tasks.","2169-3536","","10.1109/ACCESS.2021.3071452","China Southern Power Grid Company Ltd.; Digital Grid Research Institute, China Southern Power Grid; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9398679","Time-frequency variational autoencoder;electricity consumption forecasting;neural network","Feature extraction;Time-frequency analysis;Predictive models;Data models;Forecasting;Data mining;Prediction algorithms","feature extraction;load forecasting;power consumption;power engineering computing;recurrent neural nets;time-frequency analysis;variational techniques","frequency domain;periodicity;volatility;time domain;sequential features;time-frequency feature extraction;multiscale LSTM model;TFVAE-LSTM;electricity consumption forecasting tasks;multiscale electricity consumption prediction algorithm;sequential electricity consumption data;sequential data;multiscale prediction;time-frequency variational autoencoder","","2","","26","CCBY","7 Apr 2021","","","IEEE","IEEE Journals"
"Recurrent Variational Autoencoders for Learning Nonlinear Generative Models in the Presence of Outliers","Y. Wang; B. Dai; G. Hua; J. Aston; D. Wipf","University of Cambridge, Cambridge, Cambridgeshire, GB; Tsinghua University, Beijing, Beijing, CN; Microsoft Research, Redmond, WA, US; University of Cambridge, Cambridge, Cambridgeshire, GB; Microsoft Research, Redmond, WA, US","IEEE Journal of Selected Topics in Signal Processing","18 Dec 2018","2018","12","6","1615","1627","This paper explores two useful modifications of the recent variational autoencoder (VAE), a popular deep generative modeling framework that dresses traditional autoencoders with probabilistic attire. The first involves a specially-tailored form of conditioning that allows us to simplify the VAE decoder structure while simultaneously introducing robustness to outliers. In a related vein, a second, complementary alteration is proposed to further build invariance to contaminated or dirty samples via a data augmentation process that amounts to recycling. In brief, to the extent that the VAE is legitimately a representative generative model, then each output from the decoder should closely resemble an authentic sample, which can then be resubmitted as a novel input ad infinitum. Moreover, this can be accomplished via special recurrent connections without the need for additional parameters to be trained. We evaluate these proposals on multiple practical outlier-removal and generative modeling tasks involving nonlinear low-dimensional manifolds, demonstrating considerable improvements over existing algorithms.","1941-0484","","10.1109/JSTSP.2018.2876995","EPSRC Centre for Mathematical Imaging in Healthcare(grant numbers:EP/N014588/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8500175","Deep generative models;variational autoencoder;robust PCA;outlier removal;variational Bayesian model;deep learning","Principal component analysis;Computational modeling;Bayes methods;Deep learning;Upper bound;Probabilistic logic","learning (artificial intelligence)","data augmentation process;representative generative model;multiple practical outlier-removal;generative modeling tasks;nonlinear low-dimensional manifolds;recurrent variational autoencoders;nonlinear generative models;probabilistic attire;VAE decoder structure;deep generative modeling framework","","8","","32","IEEE","19 Oct 2018","","","IEEE","IEEE Journals"
"Guided Variational Autoencoder for Speech Enhancement with a Supervised Classifier","G. Carbajal; J. Richter; T. Gerkmann","Signal Processing (SP), Universität Hamburg, Germany; Signal Processing (SP), Universität Hamburg, Germany; Signal Processing (SP), Universität Hamburg, Germany","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","681","685","Recently, variational autoencoders have been successfully used to learn a probabilistic prior over speech signals, which is then used to perform speech enhancement. However, variational autoencoders are trained on clean speech only, which results in a limited ability of extracting the speech signal from noisy speech compared to supervised approaches. In this paper, we propose to guide the variational autoencoder with a supervised classifier separately trained on noisy speech. The estimated label is a high-level categorical variable describing the speech signal (e.g. speech activity) allowing for a more informed latent distribution compared to the standard variational autoencoder. We evaluate our method with different types of labels on real recordings of different noisy environments. Provided that the label better informs the latent distribution and that the classifier achieves good performance, the proposed approach outperforms the standard variational autoencoder and a conventional neural network- based supervised approach.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414363","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414363","Speech enhancement;deep generative model;variational autoencoder;semi-supervised learning","Visualization;Wiener filters;Conferences;Speech enhancement;Signal processing;Probabilistic logic;Acoustics","estimation theory;feature extraction;learning (artificial intelligence);neural nets;signal classification;speech enhancement;statistical distributions","speech enhancement;supervised classifier;speech signal;variational autoencoder;latent distribution;label estimation","","4","","23","","13 May 2021","","","IEEE","IEEE Conferences"
"An Evolutionary Approach to Variational Autoencoders","J. Hajewski; S. Oliveira","Department of Computer Science, University of Iowa, Iowa City, IA, USA; Department of Computer Science, University of Iowa, Iowa City, IA, USA","2020 10th Annual Computing and Communication Workshop and Conference (CCWC)","12 Mar 2020","2020","","","0071","0077","Variational autoencoders are an important tool in the domain of generative data models and yet they remain difficult to design due to a lack of intuition as to how to best design the corresponding encoder and decoder neural networks in addition to determining the size of the latent dimension. Furthermore, there is no definitive guidance on how one should structure these networks. Designing an effective variational autoencoder typically requires fine-tuning and experimenting with different neural network architectures and latent dimensions, which, for large datasets, can be costly both in time and money. In this work we present an approach for designing variational autoencoders based on evolutionary neural architecture search. Our technique is efficient, avoiding redundant computation, and scalable. We explore how the number of epochs used during the neural architecture search affects the properties of the resulting variational autoencoders as well as study the characteristics of the learned latent manifolds. We find that evolutionary search is able to find highly performant network even when the networks are evaluated after only two epochs of training. Using this insight we are able to dramatically reduce the overall computational requirements of our neural architecture search system applied to variational autoencoders.","","978-1-7281-3783-4","10.1109/CCWC47524.2020.9031239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9031239","variational autoencoder;neural architecture search;evolutionary algorithm;distributed system","Computer architecture;Neural networks;Evolutionary computation;Graphics processing units;Training;Decoding;Task analysis","evolutionary computation;learning (artificial intelligence);neural nets;search problems","generative data models;decoder neural networks;neural network architectures;evolutionary neural architecture search;variational autoencoder;encoder neural networks","","1","","31","","12 Mar 2020","","","IEEE","IEEE Conferences"
"The Feature Representation Ability of Variational AutoEncoder","C. Dong; T. Xue; C. Wang","Key Laboratory of Trustworthy Distributed Computing and Service (BUPT), Ministry of Education, Beijing, China; Key Laboratory of Trustworthy Distributed Computing and Service (BUPT), Ministry of Education, Beijing, China; Key Laboratory of Trustworthy Distributed Computing and Service (BUPT), Ministry of Education, Beijing, China","2018 IEEE Third International Conference on Data Science in Cyberspace (DSC)","19 Jul 2018","2018","","","680","684","As an important generation model, variational autoencoder plays an important role in image feature extraction, text generation, and text compression. In this paper, from the perspective of feature expression, we mainly study the representation ability and stability of variational autoencoder for image features. We extract the features from the original pixels and the normalized pixels of the image respectively. Through the performance of the image classification task, we evaluate the representation ability of the variational autoencoder and compared with the traditional methods of dimensionality reduction principal components analysis, autoencoder. The experiments on multiple datasets prove that variational autoencoder is a new non-linear dimensionality reduction method, which can represent the data effectively and stably.","","978-1-5386-4210-8","10.1109/DSC.2018.00108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8411929","Variational Autoencoder, Feature Representation, Dimensionality Reduction","Feature extraction;Principal component analysis;Task analysis;Dimensionality reduction;Data mining;Gaussian distribution;Stability analysis","feature extraction;image classification;image representation;principal component analysis","image feature extraction;text generation;feature expression;variational autoencoder;image features;image classification task;feature representation ability;principal components analysis","","7","1","23","","19 Jul 2018","","","IEEE","IEEE Conferences"
"Crank: An Open-Source Software for Nonparallel Voice Conversion Based on Vector-Quantized Variational Autoencoder","K. Kobayashi; W. -C. Huang; Y. -C. Wu; P. L. Tobing; T. Hayashi; T. Toda","TARVO, Inc., Japan; Nagoya University, Japan; Nagoya University, Japan; TARVO, Inc., Japan; TARVO, Inc., Japan; Nagoya University, Japan","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","5934","5938","In this paper, we present an open-source software for developing a nonparallel voice conversion (VC) system named crank. Although we have released an open-source VC software based on the Gaussian mixture model named sprocket in the last VC Challenge, it is not straightforward to apply any speech corpus because it is necessary to prepare parallel utterances of source and target speakers to model a statistical conversion function. To address this issue, in this study, we developed a new open-source VC software that enables users to model the conversion function by using only a nonparallel speech corpus. For implementing the VC software, we used a vector-quantized variational autoencoder (VQVAE). To rapidly examine the effectiveness of recent technologies developed in this research field, crank also supports several representative works for autoencoder-based VC methods such as the use of hierarchical architectures, cyclic architectures, generative adversarial networks, speaker adversarial training, and neural vocoders. Moreover, it is possible to automatically estimate objective measures such as mel-cepstrum distortion and pseudo mean opinion score based on MOSNet. In this paper, we describe representative functions developed in crank and make brief comparisons by objective evaluations.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9413959","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9413959","voice conversion;open-source software;vector-quantized variational autoencoder;nonparallel;neural vocoder","Training;Acoustic distortion;Vocoders;Conferences;Computer architecture;Generative adversarial networks;Distortion measurement","Gaussian processes;speaker recognition;speech processing;speech synthesis;vocoders","open-source software;vector-quantized variational autoencoder;nonparallel voice conversion system named crank;open-source VC software;Gaussian mixture model;VC Challenge;target speakers;statistical conversion function;nonparallel speech corpus;autoencoder-based VC methods","","2","","35","IEEE","13 May 2021","","","IEEE","IEEE Conferences"
"Joint Distribution Learning in the Framework of Variational Autoencoders for Far-Field Speech Enhancement","M. K. Chelimilla; S. Kumar; S. P. Rath","Samsung Research Institute India, Bangalore; Samsung Research Institute India, Bangalore; Samsung Research Institute India, Bangalore","2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)","20 Feb 2020","2019","","","245","251","Far-field speech recognition is a challenging task as speech recognizers trained on close-talk speech do not generalize well to far-field speech. In order to handle such issues, neural network based speech enhancement is typically applied using denoising autoencoder (DA). Recently generative models have become more popular particularly in the field of image generation and translation. One of the popular techniques in this generative framework is variational autoencoder (VAE). In this paper we consider VAE for speech enhancement task in the context of automatic speech recognition (ASR). We propose a novel modification in the conventional VAE to model joint distribution of the far-field and close-talk features for a common latent space representation, which we refer to as joint-VAE. Unlike conventional VAE, joint-VAE involves one encoder network that projects the far-field features onto a latent space and two decoder networks that generate close-talk and far-field features separately. Experiments conducted on the AMI corpus show that it gives a relative WER improvement of 9% compared to conventional DA and a relative improvement of 19.2% compared to mismatched train and test scenario.","","978-1-7281-0306-8","10.1109/ASRU46091.2019.9004024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9004024","Variational autoencoders;speech enhancement;far-field speech;close-talking speech","Speech enhancement;Speech recognition;Decoding;Noise reduction;Task analysis;Neural networks;Computational modeling","learning (artificial intelligence);neural nets;signal denoising;speech enhancement;speech recognition","speech recognizers;close-talk speech;neural network based speech enhancement;denoising autoencoder;automatic speech recognition;common latent space representation;joint-VAE;joint distribution learning;far-field speech enhancement;far-field speech recognition;variational autoencoders;generative models","","","","40","","20 Feb 2020","","","IEEE","IEEE Conferences"
"The Variational InfoMax AutoEncoder","V. Crescimanna; B. Graham","Department of Computer Science, University of Stirling, Stirling, UK; Department of Computer Science, University of Stirling, Stirling, UK","2020 International Joint Conference on Neural Networks (IJCNN)","19 Nov 2020","2020","","","1","8","The Variational AutoEncoder (VAE) learns simultaneously an inference and a generative model, but only one of these models can be learned at optimum, this behaviour is associated to the ELBO learning objective, that is optimised by a non-informative generator. In order to solve such an issue, we provide a learning objective, learning a maximal informative generator while maintaining bounded the network capacity: the Variational InfoMax (VIM). The contribution of the VIM derivation is twofold: an objective learning both an optimal inference and generative model and the explicit definition of the network capacity, an estimation of the network robustness.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9207048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207048","","Generators;Entropy;Mutual information;Robustness;Task analysis;Encoding;Data models","inference mechanisms;learning (artificial intelligence);neural nets;variational techniques","generative adversarial network;machine learning;ELBO learning;variational autoencoder learning;variational infomax autoencoder;generative model;inference model;maximal informative generator;noninformative generator","","1","","33","","19 Nov 2020","","","IEEE","IEEE Conferences"
"A Closer Look at Autoencoders for Unsupervised Anomaly Detection","O. K. Oyedotun; D. Aouada","Interdisciplinary Centre for Security, Reliability and Trust (Snt), University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (Snt), University of Luxembourg, Luxembourg","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","3793","3797","Unsupervised anomaly detection is a challenging problem, where the aim is to detect irregular data instances. Interestingly, generative models can learn data distribution, and thus have been proposed for anomaly detection. In this direction, the variational autoencoder (VAE) is popular, as it enforces an explicit probabilistic interpretation of the latent space. We note that there are other generative autoencoders (AEs) such as the denoising AE (DAE) and contractive AE (CAE), which also model data generation process without enforcing an explicit probabilistic latent space interpretation. While it is intuitively straightforward to see the benefit of a latent space with explicit probabilistic interpretation for generative tasks, it is unclear how this can be crucial for anomaly detection problems. Consequently, our exposition in this paper is to investigate the extent to which different latent space attributes of AEs impact their performances for anomaly detection tasks. We take the conventional and deterministic AE that we refer to as plain AE (PAE) as the baseline for performance comparison. Our results obtained using five different datasets reveal that an explicit probabilistic latent space is not necessary for good performance. The best results on most of the datasets are obtained using CAE, which enjoys stable latent representations.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746898","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746898","Anomaly detection;autoencoder;variational autoencoder;latent representations","Conferences;Noise reduction;Signal processing;Probabilistic logic;Data models;Acoustics;Task analysis","data handling;learning (artificial intelligence);neural nets","unsupervised anomaly detection;irregular data instances;generative models;data distribution;variational autoencoder;explicit probabilistic interpretation;generative autoencoders;model data generation process;explicit probabilistic latent space interpretation;generative tasks;anomaly detection problems;different latent space attributes;anomaly detection tasks;stable latent representations;VAE;AEs;DAE;CAE;PAE;denoising autoencoder;contractive autoencoder","","","","28","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Unsupervised Anomaly Detection in Energy Time Series Data Using Variational Recurrent Autoencoders with Attention","J. Pereira; M. Silveira","Instituto Superior Técnico, University of Lisbon, Lisbon, Portugal; Institute for Systems and Robotics, University of Lisbon, Lisbon, Portugal","2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)","17 Jan 2019","2018","","","1275","1282","In the age of big data, time series are being generated in massive amounts. In the energy field, smart grids are enabling a unprecedented data acquisition with the integration of sensors and smart devices. In the context of renewable energies, there has been an increasing interest in solar photovoltaic energy generation. These installations are often integrated with smart sensors that measure the energy production. Such amount of data collected makes the quest for developing smart monitoring systems that can detect anomalous behaviour in these systems, trigger alerts and enable maintenance operations. In this paper, we propose a generic, unsupervised and scalable framework for anomaly detection in time series data, based on a variational recurrent autoencoder. Furthermore, we introduce attention in the model, by means of a variational self-attention mechanism (VSAM), to improve the performance of the encoding-decoding process. Afterwards, we perform anomaly detection based on the probabilistic reconstruction scores provided by our model. Our results on solar energy generation time series show the ability of the proposed approach to detect anomalous behaviour in time series data, while providing structured and expressive representations. Since it does not need labels to be trained, our methodology enables new applications for anomaly detection in energy time series data and beyond.","","978-1-5386-6805-4","10.1109/ICMLA.2018.00207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8614232","Anomaly Detection, Variational Recurrent Autoencoder, Attention, Solar Photovoltaic Energy","Time series analysis;Anomaly detection;Decoding;Training;Data models;Logic gates;Computational modeling","Big Data;data acquisition;electric power generation;photovoltaic power systems;power engineering computing;power system measurement;power system security;probability;security of data;smart power grids;solar power;time series","variational recurrent autoencoder;energy field;smart grids;smart devices;renewable energies;solar photovoltaic energy generation;smart sensors;energy production;smart monitoring systems;anomalous behaviour;variational self-attention mechanism;solar energy generation time series;energy time series data;unsupervised anomaly detection;Big Data;data acquisition;encoding-decoding process;probabilistic reconstruction scores","","35","","31","","17 Jan 2019","","","IEEE","IEEE Conferences"
"Multispectral Image Reconstruction From Color Images Using Enhanced Variational Autoencoder and Generative Adversarial Network","X. Liu; A. Gherbi; Z. Wei; W. Li; M. Cheriet","Synchromedia Laboratory, École de Technologie Supérieure (ÉTS), University of Québec, Montreal, QC, Canada; Synchromedia Laboratory, École de Technologie Supérieure (ÉTS), University of Québec, Montreal, QC, Canada; Department of Electrical and Computer Engineering, McGill University, Montreal, QC, Canada; Ericsson Research, Montreal, QC, Canada; Synchromedia Laboratory, École de Technologie Supérieure (ÉTS), University of Québec, Montreal, QC, Canada","IEEE Access","5 Jan 2021","2021","9","","1666","1679","Since multispectral images (MSIs) have much more sufficient spectral information than RGB images (RGBs), reconstructing MS images from RGB images is a severely underconstrained problem. We have to generate colossally different information between the two scopes. Almost all previous approaches are based on static and dependent neural networks, which fail to explain how to supplement the massive lost information. This paper presents a low-cost and high-efficiency approach, “VAE-GAN”, based on stochastic neural networks to directly reconstruct high-quality MSIs from RGBs. Our approach combines the advantages of the Generative Adversarial Network (GAN) and the Variational Autoencoder (VAE). The VAE undertakes the generation of the lost variational MS distributions by reparameterizing the latent space vector with sampling from Gaussian distribution. The GAN is responsible for regulating the generator to produce MSI-like images. In this way, our approach can create huge missed information and make the outputs look real, which also solves the previous problem. Moreover, we use several qualitative and quantitative methods to evaluate our approach and obtain excellent results. In particular, with much less training data than the previous approaches, we obtained comparable results on the CAVE dataset and surpassed state-of-the-art results on the ICVL dataset.","2169-3536","","10.1109/ACCESS.2020.3047074","Natural Sciences and Engineering Research Council of Canada (NSERC); Canada Research Chair in Sustainable Smart Eco-Cloud; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9306822","Generative adversarial network (GAN);variational autoencoder (VAE);VAE-GAN;normal distribution;stochastic neural network;multispectral image;RGB image;image processing;color vision;spectral reconstruction","Image reconstruction;Neural networks;Gallium nitride;Hyperspectral imaging;Image color analysis;Generators;Generative adversarial networks","computer vision;Gaussian distribution;geophysical image processing;image classification;image colour analysis;image motion analysis;image reconstruction;image resolution;learning (artificial intelligence);neural nets;stochastic processes","previous problem;huge missed information;MSI-like images;lost variational MS distributions;VAE;GAN;high-quality MSIs;stochastic neural networks;high-efficiency approach;massive lost information;dependent neural networks;static networks;colossally different information;severely underconstrained problem;MS images;RGBs;RGB images;sufficient spectral information;multispectral images;generative adversarial network;enhanced variational autoencoder;color images;multispectral image reconstruction","","6","","29","CCBYNCND","24 Dec 2020","","","IEEE","IEEE Journals"
"Semi-Supervised Neural Chord Estimation Based on a Variational Autoencoder With Latent Chord Labels and Features","Y. Wu; T. Carsault; E. Nakamura; K. Yoshii","Graduate School of Informatics, Kyoto University, Kyoto, Japan; Représentations Musicales, IRCAM, Paris, France; Hakubi Center for Advanced Research, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan","IEEE/ACM Transactions on Audio, Speech, and Language Processing","12 Nov 2020","2020","28","","2956","2966","This paper describes a statistically-principled semi-supervised method of automatic chord estimation (ACE) that can make effective use of music signals regardless of the availability of chord annotations. The typical approach to ACE is to train a deep classification model (neural chord estimator) in a supervised manner by using only annotated music signals. In this discriminative approach, prior knowledge about chord label sequences (model output) has scarcely been taken into account. In contrast, we propose a unified generative and discriminative approach in the framework of amortized variational inference. More specifically, we formulate a deep generative model that represents the generative process of chroma vectors (observed variables) from discrete labels and continuous features (latent variables), which are assumed to follow a Markov model favoring self-transitions and a standard Gaussian distribution, respectively. Given chroma vectors as observed data, the posterior distributions of the latent labels and features are computed approximately by using deep classification and recognition models, respectively. These three models form a variational autoencoder and can be trained jointly in a semi-supervised manner. The experimental results show that the regularization of the classification model based on the Markov prior of chord labels and the generative model of chroma vectors improved the performance of ACE even under the supervised condition. The semi-supervised learning using additional non-annotated data can further improve the performance.","2329-9304","","10.1109/TASLP.2020.3035001","JST ACCEL(grant numbers:JPMJAC1602); JSPS KAKENHI(grant numbers:20K21813,19H04137,19K20340,16H01744); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9246301","Automatic chord estimation;semi-supervised learning;variational autoencoder","Hidden Markov models;Music;Multiple signal classification;Markov processes;Computational modeling;Estimation","audio signal processing;Gaussian distribution;Markov processes;music;neural nets;signal classification;supervised learning","Gaussian distribution;chroma vectors;Markov model;continuous features;discrete labels;deep generative model;amortized variational inference;unified generative approach;chord label sequences;discriminative approach;annotated music signals;neural chord estimator;deep classification model;chord annotations;automatic chord estimation;statistically-principled semisupervised method;latent chord labels;variational autoencoder;semisupervised neural chord estimation;semisupervised learning;supervised condition","","2","","45","IEEE","30 Oct 2020","","","IEEE","IEEE Journals"
"Designing Multi-Task Convolutional Variational Autoencoder for Radio Tomographic Imaging","H. Wu; X. Ma; S. Liu","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Mechatronic Engineering, China University of Mining and Technology, Xuzhou, China","IEEE Transactions on Circuits and Systems II: Express Briefs","4 Jan 2022","2022","69","1","219","223","Radio tomographic imaging (RTI) emerges to model the environment and detect the passive targets by a wireless network. In this work, the received signal strength (RSS) measurements are collected from an uncalibrated network, and a multi-task convolutional variational autoencoder model is proposed to realize RTI. The presented model is trained end-to-end to denoise the RSS measurements, reconstruct the static tomographic images, estimate the parameters of the wireless network, and classify the measurement noise level, simultaneously. The multi-task variational learning strategy is able to improve the generalization of the model. Numerical experiments demonstrate the efficacy of our RTI method.","1558-3791","","10.1109/TCSII.2021.3081997","China Scholarship Council(grant numbers:201806420061); Priority Academic Program Development of Jiangsu Higher Education Institutions (PAPD); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9435803","Radio tomographic imaging;variational autoencoder;convolutional neural network;multi-task learning","Wireless networks;Image reconstruction;Noise level;Convolution;Calibration;Attenuation;Tomography","computerised tomography;convolutional neural nets;image reconstruction;RSSI","RTI method;multitask variational learning strategy;measurement noise level;static tomographic images;RSS measurements;multitask convolutional variational autoencoder model;received signal strength measurements;wireless network;passive targets;radio tomographic imaging","","2","","14","IEEE","19 May 2021","","","IEEE","IEEE Journals"
"Mixtures of Variational Autoencoders","F. Ye; A. G. Bors","Department of Computer Science, University of York, York, UK; Department of Computer Science, University of York, York, UK","2020 Tenth International Conference on Image Processing Theory, Tools and Applications (IPTA)","14 Dec 2020","2020","","","1","6","In this paper, we develop a new deep mixture learning framework, aiming to learn underlying complex data structures. Each component in the mixture model is implemented using a Variational Autoencoder (VAE). VAE is a well known deep learning model which models a latent space data representation on a variational manifold. The mixing parameters are estimated from a Dirichlet distribution modelled by each encoder. In order to train this mixture model, named M-VAE, we derive a mixture evidence lower bound on the sample log-likelihood, which is optimized in order to jointly estimate all mixture components. We further propose to use the d-variables Hilbert-Schmidt Independence Criterion (dHSIC) as a regularization criterion in order to enforce the independence among the encoders' distributions. This criterion encourages the proposed mixture components to learn different data distributions and represent them in the latent space. During the experiments with the proposed M-VAE model we observe that it can be used for discovering disentangled data representations which can not be achieved with a single VAE.","2154-512X","978-1-7281-8750-1","10.1109/IPTA50016.2020.9286619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286619","Mixture models;Variational autoencoder;Hilbert-Schmidt Independence Criterion","Deep learning;Training;Manifolds;Mixture models;Tools;Data models;Task analysis","data analysis;data structures;deep learning (artificial intelligence);Hilbert spaces;mixture models","deep mixture learning framework;complex data structures;mixture model;latent space data representation;variational manifold;Dirichlet distribution;d-variables Hilbert-Schmidt Independence Criterion;data distributions;M-VAE model;disentangled data representations;variational autoencoders;dHSIC","","2","","27","","14 Dec 2020","","","IEEE","IEEE Conferences"
"AutoVAE: Mismatched Variational Autoencoder with Irregular Posterior-Prior Pairing","T. Koike-Akino; Y. Wang","Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA","2022 IEEE International Symposium on Information Theory (ISIT)","3 Aug 2022","2022","","","1689","1694","The variational autoencoder (VAE) has been used in a myriad of applications, e.g., dimensionality reduction and generative modeling. VAE uses a specific model for stochastic sampling in latent space. The normal distribution is the most commonly used one because it allows a straightforward sampling, a reparameterization trick, and a differentiable expression of the Kullback–Leibler divergence. Although various other distributions such as Laplace were studied in literature, the effect of heterogeneous use of different distributions for posterior-prior pair is less known to date. In this paper, we investigate numerous possibilities of such a mismatched VAE, e.g., where the uniform distribution is used as a posterior belief at the encoder while the Cauchy distribution is used as a prior belief at the decoder. To design the mismatched VAE, the total number of potential combinations to explore grows rapidly with the number of latent nodes when allowing different distributions across latent nodes. We propose a novel framework called AutoVAE, which searches for better pairing set of posterior-prior beliefs in the context of automated machine learning for hyperparameter optimization. We demonstrate that the proposed irregular pairing offers a potential gain in the variational Rényi bound. In addition, we analyze a variety of likelihood beliefs and divergence order.","2157-8117","978-1-6654-2159-1","10.1109/ISIT50566.2022.9834769","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9834769","Deep learning;variational Bayes;autoencoder","Dimensionality reduction;Stochastic processes;Gaussian distribution;Decoding;Standards;Optimization","approximation theory;Bayes methods;learning (artificial intelligence);sampling methods;statistical distributions;stochastic processes","prior belief;mismatched VAE;latent nodes;AutoVAE;pairing set;posterior-prior beliefs;irregular pairing;variational Rényi;likelihood beliefs;mismatched variational autoencoder;irregular posterior-prior;dimensionality reduction;generative modeling;stochastic sampling;latent space;normal distribution;straightforward sampling;reparameterization trick;differentiable expression;Kullback-Leibler divergence;posterior-prior pair;uniform distribution;posterior belief;Cauchy distribution","","","","17","IEEE","3 Aug 2022","","","IEEE","IEEE Conferences"
"Unsupervised Image Categorization Based on Variational Autoencoder and Student’s-T Mixture Model","Y. Zhang; W. Fan; N. Bouguila","Department of Computer Science and Technology, Huaqiao University, Xiamen, China; Department of Computer Science and Technology, Huaqiao University, Xiamen, China; Concordia Institute for Information Systems Engineering, Concordia University, Montreal, Canada","2019 IEEE Symposium Series on Computational Intelligence (SSCI)","20 Feb 2020","2019","","","2403","2409","In this work, a novel generative robust image catego-rization approach is developed based on variational autoencoder (VAE) and Student's-T Mixture Model (STMM). The network structure composed of VAE, STMM and Convolutional Neural Network (CNN) generates data. More specifically, first, a cluster is chosen using the STMM. Then, a latent representation is extracted from the selected cluster through a CNN encoder. After that, an observation is generated based on another CNN through a decoding process. The proposed model is learned through variational inference where the Evidence Lower Bound is optimized according to Stochastic Gradient Descent(SGD) and the reparameterization trick. Based on our experimental results, the proposed generative clustering approach is able to outperform classical clustering approaches (e.g. K-means, Gaussian Mixture Models) and other related generative clustering approaches. Furthermore, we show that our generative model is able to generate highly realistic samples without using any supervised information during training.","","978-1-7281-2485-8","10.1109/SSCI44817.2019.9002714","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9002714","image categorization;clustering;Student’s-T mixture model;variational autoencoder;convolutional ceural network.","Feature extraction;Mixture models;Decoding;Robustness;Stochastic processes;Clustering algorithms;Neural networks","convolutional neural nets;Gaussian processes;gradient methods;image classification;pattern clustering;unsupervised learning","students-T mixture model;generative robust image categorization approach;Gaussian mixture models;generative clustering approach;variational inference;CNN encoder;convolutional neural network;network structure;STMM;VAE;variational autoencoder;unsupervised image categorization","","","","21","","20 Feb 2020","","","IEEE","IEEE Conferences"
"Adversarial Dual-Channel Variational Graph Autoencoder for Synthetic Lethality Prediction in Human Cancers","W. Li; H. Zhang; Q. Zhao; J. Liu; Y. Yin","College of Artificial Intelligence, Nankai University, Tianjin, China; College of Artificial Intelligence, Nankai University, Tianjin, China; College of Artificial Intelligence, Nankai University, Tianjin, China; College of Computer Science, Nankai University, Tianjin, China; Department of Food Science and Technology, University of Nebraska - Lincoln, Lincoln, NE, USA","2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","14 Jan 2022","2021","","","444","449","Synthetic Lethality (SL) is a type of vital gene interaction that can lead to various human diseases including cancers. Therefore, SL gene pair prediction can aid in the prevention and treatment of cancer. A number of computational approaches, especially Graph Neural Network (GNN) based methods, have been proposed for this link prediction problem on the graph. However, these GNN-based methods only consider embedding as deterministic vectors and do not take data distribution into account. Here we propose an Adversarial Dual-Channel Variational Graph Autoencoder based on semi-implicit variational inference for SL prediction in human cancers. We consider node embedding as a random variable that has an explicit Gaussian distribution. Then we design a dual-channel GCN encoder to inject stochasticity into the distribution parameters and allow latent embedding to exceed the Gaussian distribution. This hierarchical scheme leads to a more flexible posterior of latent embedding and enhances the model representation capacity. To further obtain a robust and stable representation, an adversarial module is devised for variance regularization. Experimental results compared with other state-of-the-art methods confirm the effectiveness of our proposed method. Moreover, we conduct a case study to demonstrate that our model can be very useful to predict novel SL pairs.","","978-1-6654-0126-5","10.1109/BIBM52615.2021.9669763","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669763","Synthetic Lethality;Human Cancers;DualChannel Graph Autoencoder;Semi-Implicit Variational Inference;Adversarial Regularization","Conferences;Biological system modeling;Gaussian distribution;Predictive models;Graph neural networks;Random variables;Bioinformatics","bioinformatics;cancer;cellular biophysics;data analysis;diseases;Gaussian distribution;genetics;graph theory;molecular biophysics;neural nets;patient treatment;stochastic processes","human cancers;Gaussian distribution;dual-channel GCN encoder;latent embedding;synthetic Lethality prediction;vital gene interaction;human diseases;SL gene pair prediction;graph neural network based methods;link prediction problem;GNN-based methods;semiimplicit variational inference;adversarial dual-channel variational graph autoencoder","","","","32","IEEE","14 Jan 2022","","","IEEE","IEEE Conferences"
"CSI Clustering with Variational Autoencoding","M. Baur; M. Würth; M. Koller; V. -C. Andrei; W. Utschick","Department of Electrical and Computer Engineering, Technical University of Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Germany","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","5278","5282","The model order of a wireless channel plays an important role for a variety of applications in communications engineering, e.g., it represents the number of resolvable incident wave-fronts with non-negligible power incident from a transmitter to a receiver. Areas such as direction of arrival estimation leverage the model order to analyze the multipath components of channel state information. In this work, we propose to use a variational autoencoder to group unlabeled channel state information with respect to the model order in the variational autoencoder latent space in an unsupervised manner. We validate our approach with simulated 3GPP channel data. Our results suggest that, in order to learn an appropriate clustering, it is crucial to use a more flexible likelihood model for the variational autoencoder decoder than it is usually the case in standard applications.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9747682","Ministry of Economic Affairs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747682","Variational autoencoder;generative modeling;latent space;vector channels;clustering","Antenna measurements;Wireless communication;Analytical models;Transmitters;Acoustic measurements;Data models;Decoding","3G mobile communication;codecs;direction-of-arrival estimation;multipath channels;telecommunication computing;unsupervised learning;wireless channels","unlabeled channel state information;variational autoencoder latent space;flexible likelihood model;variational autoencoder decoder;CSI clustering;variational autoencoding;wireless channel;resolvable incident wave-fronts;nonnegligible power incident;direction of arrival estimation;3GPP channel data;communications engineering;multipath components","","","","18","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Anomaly-Based Intrusion Detection From Network Flow Features Using Variational Autoencoder","S. Zavrak; M. İskefiyeli","Department of Computer Engineering, Düzce University, Düzce, Turkey; Department of Computer Engineering, Sakarya University, Turkey","IEEE Access","17 Jun 2020","2020","8","","108346","108358","The rapid increase in network traffic has recently led to the importance of flow-based intrusion detection systems processing a small amount of traffic data. Furthermore, anomaly-based methods, which can identify unknown attacks are also integrated into these systems. In this study, the focus is concentrated on the detection of anomalous network traffic (or intrusions) from flow-based data using unsupervised deep learning methods with semi-supervised learning approach. More specifically, Autoencoder and Variational Autoencoder methods were employed to identify unknown attacks using flow features. In the experiments carried out, the flow-based features extracted out of network traffic data, including typical and different types of attacks, were used. The Receiver Operating Characteristics (ROC) and the area under ROC curve, resulting from these methods were calculated and compared with One-Class Support Vector Machine. The ROC curves were examined in detail to analyze the performance of the methods in various threshold values. The experimental results show that Variational Autoencoder performs, for the most part, better than Autoencoder and One-Class Support Vector Machine.","2169-3536","","10.1109/ACCESS.2020.3001350","Scientific and Technological Research Council of Turkey (TUBITAK) through the 2211/C Ph.D. Scholarship Programme for Priority Areas; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9113298","Flow anomaly detection;intrusion detection;deep learning;variational autoencoder;semi-supervised learning","Intrusion detection;Feature extraction;Telecommunication traffic;Deep learning;Support vector machines;Anomaly detection;Computer hacking","computer network security;feature extraction;neural nets;support vector machines;telecommunication traffic;unsupervised learning","unsupervised deep learning methods;Variational Autoencoder methods;flow-based features;network traffic data;ROC curve;One-Class Support Vector Machine;anomaly-based intrusion detection;network flow features;flow-based intrusion detection systems;anomaly-based methods;anomalous network traffic;flow-based data;e receiver operating characteristics","","51","","74","CCBY","10 Jun 2020","","","IEEE","IEEE Journals"
"Anytime 3D Object Reconstruction Using Multi-Modal Variational Autoencoder","H. Yu; J. Oh","Postdoctoral Fellow at the Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA","IEEE Robotics and Automation Letters","24 Jan 2022","2022","7","2","2162","2169","For effective human-robot teaming, it is important for the robots to be able to share their visual perception with the human operators. In a harsh remote collaboration setting, data compression techniques such as autoencoder can be utilized to obtain and transmit the data in terms of latent variables in a compact form. In addition, to ensure real-time runtime performance even under unstable environments, an anytime estimation approach is desired that can reconstruct the full contents from incomplete information. In this context, we propose a method for imputation of latent variables whose elements are partially lost. To achieve the anytime property with only a few dimensions of variables, exploiting prior information of the category-level is essential. A prior distribution used in variational autoencoders is simply assumed to be isotropic Gaussian regardless of the labels of each training datapoint. This type of flattened prior makes it difficult to perform imputation from the category-level distributions. We overcome this limitation by exploiting a category-specific multi-modal prior distribution in the latent space. The missing elements of the partially transferred data can be sampled, by finding a specific modal according to the remaining elements. Since the method is designed to use partial elements for anytime estimation, it can also be applied for data over-compression. Based on the experiments on the ModelNet and Pascal3D datasets, the proposed approach shows consistently superior performance over autoencoder and variational autoencoder up to 70% data loss. The software is open source and is available from our repository1.","2377-3766","","10.1109/LRA.2022.3142439","AI-Assisted Detection and Threat Recognition Program; US ARMY ACC-APG-RTP(grant numbers:W911NF1820218); Air Force Office of Scientific Research(grant numbers:FA2386-17-1-4660); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9681277","3D object reconstruction;multi-modal variational autoencoder;anytime algorithm;data imputation","Three-dimensional displays;Decoding;Shape;Training;Estimation;Visualization;Real-time systems","Bayes methods;data compression;human-robot interaction;image coding;image reconstruction;image representation;learning (artificial intelligence);multi-robot systems;object detection;pose estimation;service robots;solid modelling","anytime 3D object reconstruction;multimodal variational autoencoder;effective human-robot teaming;visual perception;human operators;harsh remote collaboration setting;data compression techniques;latent variables;compact form;real-time runtime performance;unstable environments;anytime estimation approach;imputation;anytime property;isotropic Gaussian regardless;training datapoint;category-level distributions;category-specific multimodal prior distribution;latent space;missing elements;partially transferred data;specific modal;remaining elements;partial elements;consistently superior performance;70% data loss","","","","37","IEEE","13 Jan 2022","","","IEEE","IEEE Journals"
"DVAEGMM: Dual Variational Autoencoder With Gaussian Mixture Model for Anomaly Detection on Attributed Networks","W. Khan; M. Haroon; A. N. Khan; M. K. Hasan; A. Khan; U. A. Mokhtar; S. Islam","Department of Computer Application, Integral University, Lucknow, India; Department of Computer Science and Engineering, Integral University, Lucknow, India; Department of Computer Application, Integral University, Lucknow, India; Center for Cyber Security, Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia (UKM), Bangi, Malaysia; Department of Computer Application, Integral University, Lucknow, India; Center for Cyber Security, Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia (UKM), Bangi, Malaysia; Institute of Computer Science and Digital Innovations, UCSI University, Kuala Lumpur, Malaysia","IEEE Access","5 Sep 2022","2022","10","","91160","91176","A significant aspect of today’s digital information is attributed networks, which combine multiple node attributes with the basic network topology to extract knowledge. Anomaly Detection on attributed networks has recently drawn significant attention from researchers and is widely used in several high-impact areas. Most current approaches focus on shallow learning methods such as community analysis, ego network or selection of subspace method. These approaches have network sparsity and data nonlinearity problems, and they do not even capture the intricate relationships between various information sources. Deep learning approaches like graph autoencoders are utilized to perform anomaly detection through obtaining node embeddings while dealing with the network nonlinearity and sparsity issues. However, they suffer from the problem of ignoring the latent codes’ embedding distribution, which results in poor representation in many instances. In this paper, we propose a new framework called DVAEGMM to detect anomalies on attributed networks. First, our framework utilizes a dual variational autoencoder for capturing the complex cross-modality relationships between node attributes and network structure, like vanilla autoencoders, but it also considers the potential data distribution and makes use of a generative adversarial network (GAN) for an adversarial regularization approach. An adversarial mechanism makes the encoder make more accurate estimates of how potential features might be distributed. As a result, decoders can make graphs that are more like the original graph. Each input data point is represented by a low-dimensional representation and a probability of reconstruction by the algorithm. Lastly, the Gaussian Mixture Model, a distinct estimation network, is used to approximate the latent vector density, resulting in the detection of anomalies from measuring sample energy. They are trained jointly as an end-to-end framework. DVAEGMM helps in the simultaneous optimization of the mixture model, generative adversarial network, and variational autoencoder parameters. The joint optimization balances the reconstruction probability, the latent representation density approximation, and regularization. Extensive experiments on attributed networks prove that DVAEGMM significantly beats the existing methods, proving the efficiency of the presented approach. The AUC scores of our proposed framework for the BlogCatalog, Flickr, Enron, and Amazon datasets are 0.89380, 0.87130, 0.72480, and 0.75102, respectively.","2169-3536","","10.1109/ACCESS.2022.3201332","Universiti Kebangsaan Malaysia(grant numbers:GUP-2019-061,FRGS/1/2020/ICT03/UKM/02/6); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9866699","Anomaly detection;attributed networks;deep learning;dual variational autoencoder;Gaussian mixture model;graph convolution network;unsupervised learning;generative adversarial network","Anomaly detection;Social networking (online);Generative adversarial networks;Network topology;Gaussian mixture model;Deep learning;Data models","Gaussian processes;graph theory;neural nets;probability","DVAEGMM;anomaly detection;basic network topology;node attributes;network structure;generative adversarial network;attributed networks;dual variational autoencoder with Gaussian mixture model;complex cross-modality relationships;simultaneous optimization;reconstruction probability;latent representation density approximation","","","","71","CCBY","24 Aug 2022","","","IEEE","IEEE Journals"
"Scalable Graph Convolutional Variational Autoencoders","D. Unyi; B. Gyires-Tóth","Department of Telecommunications and Media Informatics, Budapest University of Technology and Economics, Budapest, Hungary; Department of Telecommunications and Media Informatics, Budapest University of Technology and Economics, Budapest, Hungary","2021 IEEE 15th International Symposium on Applied Computational Intelligence and Informatics (SACI)","30 Jun 2021","2021","","","467","472","Autoencoders are widely used for self-supervised representation learning. Variational autoencoders (VAEs), a special type of autoencoders, are proven to be effective in estimating the underlying probability distribution of the training data. Even though VAEs are well explored in many application domains, their utilization for graph-structured data is still under extensive research. Graph variational autoencoders achieved competitive results on various graph-related modeling tasks (e.g. link prediction and node clustering) by incorporating node features. However, current graph VAEs are unable to scale efficiently for larger graphs.In this paper, we propose a novel method that adapts the stochastic multiple partitions (SMP) algorithm to improve on scalability. We also introduce novel graph convolutional layers with general graph filters, which significantly improve the predictive performance of the neural network. The proposed method is evaluated on two popular large-graph datasets. According to the results, the proposed filters outperform the baseline filter in link prediction and node clustering for both datasets.","","978-1-7281-9544-5","10.1109/SACI51354.2021.9465579","Ministry for Innovation and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9465579","Artificial Neural Networks;Unsupervised Learning;Graph Neural Networks;Variational Autoencoders","Adaptation models;Smoothing methods;Social networking (online);Switched mode power supplies;Clustering algorithms;Training data;Stochastic processes","graph theory;neural nets;pattern clustering;statistical distributions;stochastic processes;supervised learning","large-graph datasets;node clustering;scalable graph convolutional variational autoencoders;self-supervised representation learning;probability distribution;training data;application domains;graph-structured data;graph-related modeling tasks;link prediction;node features;graph VAE;stochastic multiple partitions algorithm;general graph filters;SMP algorithm;graph convolutional layers;neural network predictive performance;large-graph dataset;baseline filter","","","","32","","30 Jun 2021","","","IEEE","IEEE Conferences"
"A Transformer-Based Variational Autoencoder for Sentence Generation","D. Liu; G. Liu","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","2019 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2019","2019","","","1","7","The variational autoencoder(VAE) has been proved to be a most efficient generative model, but its applications in natural language tasks have not been fully developed. A novel variational autoencoder for natural texts generation is presented in this paper. Compared to the previously introduced variational autoencoder for natural text where both the encoder and decoder are RNN-based, we propose a new transformer-based architecture and augment the decoder with an LSTM language model layer to fully exploit information of latent variables. We also propose some methods to deal with problems during training time, such as KL divergency collapsing and model degradation. In the experiment, we use random sampling and linear interpolation to test our model. Results show that the generated sentences by our approach are more meaningful and the semantics are more coherent in the latent space.","2161-4407","978-1-7281-1985-4","10.1109/IJCNN.2019.8852155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852155","variational autoencoder;text generation;self-attention;transformer","Decoding;Training;Task analysis;Neural networks;Gaussian distribution;Computer architecture;Natural languages","interpolation;natural language processing;recurrent neural nets;text analysis","transformer-based variational autoencoder;sentence generation;natural language tasks;natural texts generation;natural text;decoder;transformer-based architecture;LSTM language model layer;generated sentences;generative model;RNN","","13","","29","","30 Sep 2019","","","IEEE","IEEE Conferences"
"A Unified Unsupervised Gaussian Mixture Variational Autoencoder for High Dimensional Outlier Detection","W. Liao; Y. Guo; X. Chen; P. Li","Department of Computer and Information Sciences, Towson University, Towson, MD; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, OH","2018 IEEE International Conference on Big Data (Big Data)","24 Jan 2019","2018","","","1208","1217","Paradigm-shifting systems such as cyber-physical systems, collect data of high- or ultrahigh- dimensionality tremendously. Detecting outliers in this type of systems provides indicative understanding in wide-ranging domains such as system health monitoring, information security, etc. Previous dimensionality reduction based outlier detection methods suffer from the incapability of well preserving the critical information in the low-dimensional latent space, mainly because they generally assume an isotropic Gaussian distribution as prior and fail to mine the intrinsic multimodality in high dimensional data. Moreover, most of the schemes decouple the model learning process, resulting in suboptimal performance. To tackle these challenges, in this paper, we propose a unified Unsupervised Gaussian Mixture Variational Autoencoder for outlier detection. Specifically, a variational autoencoder firstly trains a generative distribution and extracts reconstruction based features. Then we adopt a deep brief network to estimate the component mixture probabilities by the latent distribution and extracted features, which is further used by the Gaussian mixture model to estimate sample densities with the Expectation-Maximization (EM) algorithm. The inference model is optimized jointly with the variational autoencoder, the deep brief network, and the Gaussian mixture model. Afterwards, the proposed detector identifies outliers when the estimated sample density exceeds a learned threshold. Extensive simulations on six public benchmark datasets show that the proposed framework outperforms state-of-the-art outlier detection schemes and achieves, on average, 27% improvements in F1 score.","","978-1-5386-5035-6","10.1109/BigData.2018.8622120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8622120","Outlier detection;Gaussian mixture model;variational autoencoder.","Anomaly detection;Gaussian mixture model;Gaussian distribution;Feature extraction;Training;Data models","expectation-maximisation algorithm;feature extraction;Gaussian distribution;Gaussian processes;probability;unsupervised learning","high dimensional outlier detection;paradigm-shifting systems;cyber-physical systems;system health monitoring;previous dimensionality reduction;detection methods;low-dimensional latent space;isotropic Gaussian distribution;high dimensional data;model learning process;deep brief network;component mixture probabilities;latent distribution;Gaussian mixture model;state-of-the-art outlier detection schemes;unified unsupervised Gaussian mixture variational autoencoder","","8","","37","","24 Jan 2019","","","IEEE","IEEE Conferences"
"From Symbols to Signals: Symbolic Variational Autoencoders","C. Devaraj; A. Chowdhury; A. Jain; J. R. Kubricht; P. Tu; A. Santamaria-Pang","Artificial Intelligence, GE Research, Niskayuna, USA; Artificial Intelligence, GE Research, Niskayuna, USA; Artificial Intelligence, GE Research, Niskayuna, USA; Artificial Intelligence, GE Research, Niskayuna, USA; Artificial Intelligence, GE Research, Niskayuna, USA; Artificial Intelligence, GE Research, Niskayuna, USA","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","3317","3321","We introduce Symbolic Variational Autoencoders which generate images from symbols that represent semantic concepts. Unlike generic Variational Autoencoders (VAEs) or Generative Adversarial Networks (GANs), the latent distribution from the Symbolic Variational Autoencoder is discrete. The symbols are learned in a completely unsupervised manner by reconstructing images from symbolic encodings. We demonstrate the efficacy of our symbolic approach on the MNIST and FashionMNIST datasets. Results indicate that symbolic encodings naturally form a grammar, where unique strings of symbols map to different semantic concepts. We further explore how changing these symbols affects the final image that is generated.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9054016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054016","Emergent languages;Variational Autoencoders;Explainability","Image coding;Semantics;Footwear;Transforms;Encoding;Grammar;Image reconstruction","encoding;grammars;image reconstruction;neural nets;unsupervised learning","unsupervised manner;signals;grammar;MNIST dataset;FashionMNIST dataset;GANs;generative adversarial networks;symbolic variational autoencoder;image reconstruction;symbolic encodings","","2","","18","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Variational Autoencoder Based Fault Detection and Location Method for Power Distribution Network","X. Wang; P. Cui; Y. Du; Y. Yang","Department of Automation, The Ministry of Education Key Laboratory of System control and information processing, Shanghai Jiao Tong University, Shanghai, China; Department of Electrical Engineering, State Energy Smart Grid R&D Center, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, The Ministry of Education Key Laboratory of System control and information processing, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, The Ministry of Education Key Laboratory of System control and information processing, Shanghai Jiao Tong University, Shanghai, China","2020 8th International Conference on Condition Monitoring and Diagnosis (CMD)","16 Dec 2020","2020","","","282","285","With the rapid development of the world economy and the continuous improvement of people's living standards, users put forward higher requirements for the quality and reliability of the power system. As a representative of deep learning, variational autoencoders play an important role in processing high-dimensional big data. In this paper, a novel variational autoencoder based distribution network abnormal monitoring and positioning method is proposed. Through an indepth study of the variational autoencoder, we utilize the real-time dynamic distribution network status information provided by the wide-area measurement system, combined with the abilities of feature extracting and data reconstruction. Finally, the IEEE-33 simulation model was built in Matlab software and the experimental results were used to verify the correctness of this method. The results show that this method can quickly and accurately achieve the fault detection and location for the distribution network with strong robustness.","2644-271X","978-1-7281-5931-7","10.1109/CMD48350.2020.9287286","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287286","Anomaly detetion;Distribution systems;Fault location;Variational autoencoder","Fault detection;Distribution networks;Feature extraction;Electrical fault detection;Software;Wide area measurements;Standards","Big Data;deep learning (artificial intelligence);fault location;feature extraction;power distribution faults;power distribution reliability;power engineering computing;power supply quality;power system measurement","power distribution network;world economy;high-dimensional big data processing;positioning method;real-time dynamic distribution network status information;wide-area measurement system;data reconstruction;fault detection;variational autoencoder;power system reliability;power system quality;deep learning;IEEE-33 simulation model;Matlab software;feature extraction;fault location method","","2","","12","","16 Dec 2020","","","IEEE","IEEE Conferences"
"VAE-BRIDGE: Variational Autoencoder Filter for Bayesian Ridge Imputation of Missing Data","R. C. Pereira; P. H. Abreu; P. P. Rodrigues","Dept. of Informatics Engineering, Centre for Informatics and Systems of the University of Coimbra, Coimbra, Portugal; Dept. of Informatics Engineering, Centre for Informatics and Systems of the University of Coimbra, Coimbra, Portugal; Center for Health Technology and Services Research, University of Porto, Porto, Portugal","2020 International Joint Conference on Neural Networks (IJCNN)","29 Sep 2020","2020","","","1","7","The missing data issue is often found in real-world datasets and it is usually handled with imputation strategies that replace the missing values with new data. Recently, generative models such as Variational Autoencoders have been applied for this imputation task. However, they were always used to perform the entire imputation, which has presented limited results when comparing to other state-of-the-art methods. In this work, a new approach called Variational Autoencoder Filter for Bayesian Ridge Imputation is introduced. It uses a Variational Autoencoder at the beginning of the imputation pipeline to filter the instances that are later fitted to a Bayesian ridge regression used to predict the new values. The approach was compared to four state-of-the-art imputation methods using 10 datasets from the healthcare context covering clinical trials, all injected with missing values under different rates. The proposed approach significantly outperformed the remaining methods in all settings, achieving an overall improvement between 26% and 67%.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9206615","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206615","missing data;variational autoencoder;bayesian ridge;data imputation;healthcare data","Bayes methods;Mathematical model;Gaussian distribution;Medical services;Standards;Informatics;Data models","Bayes methods;data handling;data mining;Gaussian processes;health care;learning (artificial intelligence);neural nets;regression analysis","Variational Autoencoder Filter;Bayesian Ridge Imputation;imputation pipeline;Bayesian ridge regression;imputation methods;VAE-BRIDGE;missing data issue;imputation strategies;imputation task","","1","","18","","29 Sep 2020","","","IEEE","IEEE Conferences"
"Anomaly Detection using Variational Autoencoder with Spectrum Analysis for Time Series Data","U. Yokkampon; S. Chumkamon; A. Mowshowitz; E. Hayashi","Graduate School of Computer Science and Systems Engineering, Kyushu Institute of Technology, Fukuoka, Japan; Graduate School of Computer Science and Systems Engineering, Kyushu Institute of Technology, Fukuoka, Japan; Department of Computer Science, The City College of New York, New York, USA; Graduate School of Computer Science and Systems Engineering, Kyushu Institute of Technology, Fukuoka, Japan","2020 Joint 9th International Conference on Informatics, Electronics & Vision (ICIEV) and 2020 4th International Conference on Imaging, Vision & Pattern Recognition (icIVPR)","7 Jan 2021","2020","","","1","6","Uncertainty is an ever present challenge in life. To meet this challenge in data analysis, we propose a method for detecting anomalies in data. This method, based in part on Variational Autoencoder, identifies spiking raw data by means of spectrum analysis. Time series data are examined in the frequency domain to enhance the detection of anomalies. In this paper, we have used the standard data sets to validate the proposed method. Experimental results show that the comparison of the frequency domain with the original data for anomaly detection can improve validity and accuracy on all criteria. Therefore, analysis of time series data by combining Variational Autoencoder and frequency domain spectrum methods can effectively detect anomalies. Contribution- We have proposed an anomaly detection method based on the time series data analysis by combining Variational Autoencoder and Spectrum analysis, and have benchmarked the method with reference to recent related research.","","978-1-7281-9331-1","10.1109/ICIEVicIVPR48672.2020.9306570","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9306570","Anomaly Detection;Variational Autoencoder;Time Series Data","Time-frequency analysis;Data analysis;Uncertainty;Time series analysis;Anomaly detection;Spectral analysis;Standards","frequency-domain analysis;image coding;time series","standard data sets;frequency domain spectrum methods;anomaly detection method;time series data analysis;spectrum analysis;raw data;variational autoencoder","","","","12","","7 Jan 2021","","","IEEE","IEEE Conferences"
"Behavioral Cloning in Atari Games Using a Combined Variational Autoencoder and Predictor Model","B. Chen; S. Tandon; D. Gorsich; A. Gorodetsky; S. Veerapaneni","Department of Mathematics, University of Michigan, Ann Arbor, USA; Department of Aerospace Engineering, University of Michigan, Ann Arbor, USA; Ground Vehicle Systems Center U.S. Army DEVCOM, Warren, USA; Department of Aerospace Engineering, University of Michigan, Ann Arbor, USA; Department of Mathematics, University of Michigan, Ann Arbor, USA","2021 IEEE Congress on Evolutionary Computation (CEC)","9 Aug 2021","2021","","","2077","2084","We explore an approach to behavioral cloning in video games. We are motivated to pursue a learning architecture that is data efficient and provides opportunity for interpreting player strategies and replicating player actions in unseen situations. To this end, we have developed a generative model that learns latent features of a game that can be used for training an action predictor. Specifically, our architecture combines a Variational Autoencoder with a discriminator mapping the latent space to action predictions (predictor). We compare our model performance to two different behavior cloning architectures: a discriminative model (a Convolutional Neural Network) mapping game states directly to actions, and a Variational Autoencoder with a predictor trained separately. Finally, we demonstrate how we can use the advantage of generative modeling to sample new states from the latent space of the Variational Autoencoder to analyze player actions and provide meaning to certain latent features.","","978-1-7281-8393-0","10.1109/CEC45853.2021.9505001","Automotive Research Center; U.S. Army; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9505001","Behavior Cloning;Variational Autoencoder;Predictive Models;Video Games","Training;Computational modeling;Cloning;Games;Evolutionary computation;Computer architecture;Predictive models","computer games;convolutional neural nets;learning (artificial intelligence);prediction theory","generative modeling;behavioral cloning;Atari games;predictor model;video games;learning architecture;player strategies;latent feature learning;action predictor;discriminator mapping;discriminative model mapping game states;combined variational autoencoder;player action replication;behavior cloning architectures;convolutional neural network","","","","18","IEEE","9 Aug 2021","","","IEEE","IEEE Conferences"
"Adversarial Residual Variational Graph Autoencoder with Batch Normalization","Q. Liao; X. Wu; X. Xie; J. Wu; L. Qiu; L. Sun","School of Cyberspace Security, BUPT, Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications Library, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, BUPT, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science (National Pilot Software Engineering School), BUPT, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science (National Pilot Software Engineering School), BUPT, Beijing University of Posts and Telecommunications, Beijing, China; School of Economics and Management, BUPT, Beijing University of Posts and Telecommunications, Beijing, China","2021 IEEE Sixth International Conference on Data Science in Cyberspace (DSC)","11 Apr 2022","2021","","","40","46","The variational graph autoencoder (VGAE), a framework for unsupervised learning on graph-structured data, has captured more attention recently in graph embedding area. However, it has been faced up with the challenge of KL vanishing, which will converge to local optimum and make the graph embedding unavailable for downstream tasks like link prediction. This paper proposes a novel variational graph autoencoder framework to achieve more effective graph embedding. Firstly, we introduce batch normalization to make sure the KL distribution consistent with the whole dataset by keeping its expectation positive, thus avoiding posteriori collapse. In addition, we invite residual connection and adversarial network to simultaneously embed the topology information and content information into graph representation stably, enhancing the expressive ability of latent vector. Finally, link prediction experiments on three citation datasets demonstrate that the AUC scores of our algorithm are higher than 92% and the average accuracies are higher than 93%, which is competitive comparing with the state-of-the-art variational graph autoencoders.","","978-1-6654-1815-7","10.1109/DSC53577.2021.00013","Beijing Municipal Commission of Education(grant numbers:700300184); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9750486","variational graph autoencoder;KullbackLeibler divergence;batch normalization;residual network;adversarial network","Network topology;Conferences;Cyberspace;Data science;Prediction algorithms;Topology;Task analysis","graph theory;neural nets;unsupervised learning","graph representation;link prediction experiments;adversarial residual variational graph autoencoder;batch normalization;unsupervised learning;graph-structured data;graph embedding area;KL vanishing;KL distribution;residual connection;adversarial network;topology information;content information;AUC scores;citation datasets","","","","24","IEEE","11 Apr 2022","","","IEEE","IEEE Conferences"
"Human Emotion Estimation Using Multi-Modal Variational AutoEncoder with Time Changes","Y. Moroto; K. Maeda; T. Ogawa; M. Haseyama","Graduate School of Information Science and Technology, Hokkaido University, Japan; Office of Institutional Research, Hokkaido University, Japan; Faculty of Information Science and Technology, Hokkaido University, Japan; Faculty of Information Science and Technology, Hokkaido University, Japan","2021 IEEE 3rd Global Conference on Life Sciences and Technologies (LifeTech)","8 Apr 2021","2021","","","67","68","A human emotion estimation method via feature integration using multi-modal variational autoencoder (MVAE) with time changes is presented in this paper. To utilize multi-modal information such as gaze and brain activity data including some noises, the proposed method newly introduces MVAE into the human emotion estimation. Furthermore, the proposed MVAE can consider the changes in bio-signals with time and reduce the effect of noises caused in bio-signals by using the probabilistic variation. Experimental results with that of some state-of-the-art methods indicate that the proposed method is effective.","","978-1-6654-1875-1","10.1109/LifeTech52111.2021.9391939","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9391939","","Brain;Conferences;Estimation;Probabilistic logic;Life sciences;Noise measurement","brain;emotion recognition;feature extraction;human computer interaction;neurophysiology","MVAE;bio-signals;probabilistic variation;multimodal variational autoencoder;time changes;human emotion estimation method;multimodal information;brain activity data","","1","","11","","8 Apr 2021","","","IEEE","IEEE Conferences"
"Quantitative Evaluation of Synthesized Brain PET Using a Variational Autoencoder","R. John; J. Penning; H. Chandler; P. Fielding; C. Marshall; R. Smith","Wales Research and Diagnostic PET Imaging Centre (PETIC), Cardiff University, Cardiff, UK; Wales Research and Diagnostic PET Imaging Centre (PETIC), Cardiff University, Cardiff, UK; Cardiff Universities Brain Research Imaging Centre (CUBRIC); Wales Research and Diagnostic PET Imaging Centre (PETIC), Cardiff University, Cardiff, UK; Wales Research and Diagnostic PET Imaging Centre (PETIC), Cardiff University, Cardiff, UK; Wales Research and Diagnostic PET Imaging Centre (PETIC), Cardiff University, Cardiff, UK","2021 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC)","9 Sep 2022","2021","","","1","4","Alzheimer’s disease (AD) accounts for 50-70% of dementia cases, making it the most common type of dementia. Positron Emission Tomography (PET) has demonstrated the ability to diagnose dementia to an equivalent ability as a cognitive exam. Advances in computational power and deep learning have revolutionized quantitative analysis of medical images. A variational autoencoder (VAE) has previously been proposed for the identification of PET brain abnormalities by examining divergence of the reconstruction error from a normal dataset. Little work has examined the utility of training a multiclass VAE and its ability to faithfully reconstruct quantitatively acceptable images across the AD class range; in effect exploring the inclusiveness of the learned latent state representation across different disease states. We construct a VAE that is trained on a dataset containing scans of 94 patients with varying degrees / classes of neurode-generation. A ’leave one group out’ approach to model training allows the classes with the most pertinent features to be probed across the dataset. Metrics used to assess VAE performance were the peak signal-to-noise ratio (PSNR) and structured similarity index (SSIM) if the VAE reconstructed imags versus the ground truth. A decreased average PSNR, 0.82%, and SSIM, 3.97%, demonstrates poorer performance when the cognitively normal (CN) data is removed from the training dataset, suggesting the CN group feature representations aid in the faithful reconstruction of subsequent disease groups. Furthermore, it was observed that inclusion of the late mild cognitively impairment (LMCI) group reduces reconstructed quantitative accuracy across all classes. Removal of this class during training increases PSNR and SSIM across all groups, with increases of 0.19% and 0.42% respectively. This suggests that the LMCI group does not follow the posterior Gaussian distribution.","2577-0829","978-1-6654-2113-3","10.1109/NSS/MIC44867.2021.9875443","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9875443","","Training;Measurement;PSNR;Image synthesis;Statistical analysis;Positron emission tomography;Alzheimer's disease","brain;cognition;deep learning (artificial intelligence);diseases;Gaussian distribution;image reconstruction;medical image processing;neurophysiology;positron emission tomography","medical images;variational autoencoder;PET brain abnormalities;reconstruction error;normal dataset;multiclass VAE;learned latent state representation;disease states;neurode-generation;peak signal-noise ratio;cognitively normal data;training dataset;subsequent disease groups;late mild cognitively impairment group;Alzheimer's disease;dementia cases;Positron Emission Tomography;cognitive exam;computational power;deep learning;leave one group out approach;CN group feature representations;VAE reconstructed image;posterior Gaussian distribution","","","","11","IEEE","9 Sep 2022","","","IEEE","IEEE Conferences"
"Multi-View Variational Autoencoder for Robust Classification against Irrelevant Data","D. Nishikawa; R. Harakawa; M. Iwahashi","Department of Electrical, Electronics and Information Engineering, Nagaoka University of Technology, Niigata, Japan; Department of Electrical, Electronics and Information Engineering, Nagaoka University of Technology, Niigata, Japan; Department of Electrical, Electronics and Information Engineering, Nagaoka University of Technology, Niigata, Japan","2021 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","3 Feb 2022","2021","","","1703","1707","Multi-view variational autoencoders (MVAEs) can extract latent variables with high discriminative power for classification by considering correlations among multi-view data, i.e., multiple kinds of data. However, if we input irrelevant data, i.e., multiple kinds of data that capture the different object, to MVAEs, discriminative power is reduced. To solve this problem, we propose an MVAE including a novel objective function. Our proposed MVAE reconstructs multi-view data without the negative effect of irrelevant data. Specifically, we derive an objective function that focuses on latent variables of relevant data, i.e., multiple kinds of data that capture the same object. Experimental results show that the proposed method improved the discriminative power of latent variables even if irrelevant data are input.","2640-0103","978-988-14768-9-0","","JSPS KAKENHI(grant numbers:JP21K11934); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9689345","","Training;Correlation;Information processing;Linear programming;Data mining","feature extraction;image reconstruction;pattern classification","objective function;MVAE;latent variables;multiview variational autoencoder;robust classification;high discriminative power","","","","24","","3 Feb 2022","","","IEEE","IEEE Conferences"
"Dual Autoencoder Network for Retinex-Based Low-Light Image Enhancement","S. Park; S. Yu; M. Kim; K. Park; J. Paik","Department of Image Graduate School of Advanced Imaging Science, Multimedia and Film, Chung-Ang University, Seoul, South Korea; Department of Image Graduate School of Advanced Imaging Science, Multimedia and Film, Chung-Ang University, Seoul, South Korea; Department of Image Graduate School of Advanced Imaging Science, Multimedia and Film, Chung-Ang University, Seoul, South Korea; Department of Image Graduate School of Advanced Imaging Science, Multimedia and Film, Chung-Ang University, Seoul, South Korea; Department of Image Graduate School of Advanced Imaging Science, Multimedia and Film, Chung-Ang University, Seoul, South Korea","IEEE Access","9 May 2018","2018","6","","22084","22093","This paper presents a dual autoencoder network model based on the retinex theory to perform the low-light enhancement and noise reduction by combining the stacked and convolutional autoencoders. The proposed method first estimates the spatially smooth illumination component which is brighter than an input low-light image using a stacked autoencoder with a small number of hidden units. Next, we use a convolutional autoencoder which deals with 2-D image information to reduce the amplified noise in the brightness enhancement process. We analyzed and compared roles of the stacked and convolutional autoencoders with the constraint terms of the variational retinex model. In the experiments, we demonstrate the performance of the proposed algorithm by comparing with the state-of-the-art existing low-light and contrast enhancement methods.","2169-3536","","10.1109/ACCESS.2018.2812809","Institute for Information & Communications Technology Promotion grant through the Korea government(grant numbers:2017-0-00250); Intelligent Defense Boundary Surveillance Technology Using Collaborative Reinforced Learning of Embedded Edge Camera and Image Analysis; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307190","Autoencoder;image processing;image enhancement;neural networks;variational retinex model;unsupervised learning","Lighting;Image enhancement;Brightness;Image reconstruction;Noise reduction;Convolution;Image edge detection","convolutional codes;image coding;image enhancement;lighting","low-light image enhancement;dual autoencoder network model;retinex theory;low-light enhancement;noise reduction;stacked autoencoders;convolutional autoencoders;spatially smooth illumination component;stacked autoencoder;convolutional autoencoder;2-D image information;amplified noise;brightness enhancement process;variational retinex model","","61","","26","OAPA","6 Mar 2018","","","IEEE","IEEE Journals"
"Supervised Variational Autoencoders for Soft Sensor Modeling With Missing Data","R. Xie; N. M. Jan; K. Hao; L. Chen; B. Huang","Engineering Research Center of Digitized Textile and Apparel Technology, Donghua University, Shanghai, China; Department of Chemical Engineering, Indian Institute of Technology Tirupati, Tirupati, India; Engineering Research Center of Digitized Textile and Apparel Technology, Donghua University, Shanghai, China; Engineering Research Center of Digitized Textile and Apparel Technology, Donghua University, Shanghai, China; Department of Chemical and Materials Engineering, University of Alberta, Edmonton, Canada","IEEE Transactions on Industrial Informatics","22 Jan 2020","2020","16","4","2820","2828","Autoencoder (AE) is a deep neural network that has been widely utilized in process industry owing to its superior abilities of feature extraction and data reconstruction. Recently, assuming the latent variables to be random variables, a probabilistic variant of it called variational autoencoder (VAE) has achieved a major success in different applications. In this article, we develop two novel submodels based on deep VAEs (DVAE), which are further utilized to establish a soft sensor framework. By the use of our first submodel known as supervised DVAE (SDVAE), the distribution information of latent features can be obtained. This is used as a prior of the second submodel known as the modified unsupervised DVAE (MUDVAE). Then, a new soft sensor framework can be constructed by combing the encoder of SDVAE with the decoder of MUDVAE. Since our designed VAE has superior ability in data reconstruction, it also works well under the missing data situation which is common in process industries due to sensor failures. Thus, we extend the proposed soft sensor framework to handle the missing data situation. The effectiveness of our proposed soft sensor frameworks is finally demonstrated via an industrial polymerization dataset.","1941-0050","","10.1109/TII.2019.2951622","Ministry of Science and Technology(grant numbers:2016YFB0302701); Natural Science Foundation of Shanghai(grant numbers:19ZR1402300); National Natural Science Foundation of China(grant numbers:61603090); Donghua University(grant numbers:CUSF-DH-D-2018099); Natural Sciences and Engineering Research Council of Canada(grant numbers:RGPIN-2017-03833); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891716","Melt viscosity index (MVI);missing data;modified unsupervised DVAE (MUDVAE);soft sensor frameworks;supervised deep VAE (SDVAE);variationan autoencoder (VAE)","Neural networks;Probabilistic logic;Decoding;Data models;Standards;Industries;Process control","data analysis;feature extraction;neural nets;probability;sensors;unsupervised learning","data situation;supervised variational autoencoders;soft sensor modeling;deep neural network;data reconstruction;random variables;variational autoencoder;deep VAEs;supervised DVAE;modified unsupervised DVAE;sensor failures;industrial polymerization dataset;MUDVAE;feature extraction;probabilistic variant","","36","","31","IEEE","5 Nov 2019","","","IEEE","IEEE Journals"
"Variational Autoencoders and Wasserstein Generative Adversarial Networks for Improving the Anti-Money Laundering Process","Z. Chen; W. M. Soliman; A. Nazir; M. Shorfuzzaman","School of Computer Science, University of Nottingham Malaysia, Semenyih, Malaysia; School of Computer Science, University of Nottingham Malaysia, Semenyih, Malaysia; Department of Information Systems, College of Technological Innovation, Zayed University, Abu Dhabi, United Arab Emirates; Department of Computer Science, College of Computers and Information Technology, Taif University, Ta’if, Saudi Arabia","IEEE Access","14 Jun 2021","2021","9","","83762","83785","There has been much recent work on fraud and Anti Money Laundering (AML) detection using machine learning techniques. However, most algorithms are based on supervised techniques. Studies show that supervised techniques often have the limitation of not adapting well to new irregular fraud patterns when the dataset is highly imbalanced. Instead, unsupervised learning can have a better capability to find anomalous and irregular patterns in new transaction. Despite this, unsupervised techniques also have the disadvantage of not being able to give state-of-the-art detection results. We propose a suite of unsupervised and deep learning techniques to implement an anti-money laundering and fraud detection system to resolve this limitation. The system leverages three deep learning models: autoencoder (AE), variational autoencoder (VAE), and a generative adversarial network. We preprocess the given dataset to separate the Transaction Date attribute into its base components to capture time-related fraud patterns. Also, Wasserstein Generative Adversarial Network (WGAN) is used to generate fraud transactions, which are then mixed with the base dataset to form a more balanced mixed dataset. These two datasets are used to train the AE and VAE models. We built two versions of the AE model (single-loss and multi-loss) besides a novel method of calculating the anomaly score threshold, called Recall-First Threshold (RFT), which helps enhance the model's performance. Experimental results demonstrated that the False Positive Rate (FPR) drops down to as low as 7% in the proposed multi-loss AE model. In comparison, we achieved an accuracy of 93%, with 100% of the fraud transactions recalled successfully.","2169-3536","","10.1109/ACCESS.2021.3086359","Taif University, Ta’if, Saudi Arabia(grant numbers:TURSP-2020/79); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9446893","Anti-money laundering (AML);autoencoders;anomaly detection;deep learning;fraud detection;GANs;unsupervised learning","Support vector machines;Clustering algorithms;Deep learning;Generative adversarial networks;Unsupervised learning;Radio frequency;Decision trees","fraud;learning (artificial intelligence);pattern classification;security of data;unsupervised learning","fraud transactions;variational autoencoders;Wasserstein Generative Adversarial networks;Anti-Money Laundering process;Anti Money Laundering detection;machine learning techniques;supervised techniques;irregular fraud patterns;anomalous patterns;irregular patterns;unsupervised techniques;state-of-the-art detection results;unsupervised learning techniques;deep learning techniques;fraud detection system;deep learning models;variational autoencoder;Transaction Date;base components;time-related fraud patterns;Wasserstein Generative Adversarial Network;base dataset;balanced mixed dataset;single-loss;multiloss AE model","","","","52","CCBY","4 Jun 2021","","","IEEE","IEEE Journals"
"Hierarchical and Self-Attended Sequence Autoencoder","J. -T. Chien; C. -W. Wang","Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan","IEEE Transactions on Pattern Analysis and Machine Intelligence","4 Aug 2022","2022","44","9","4975","4986","It is important and challenging to infer stochastic latent semantics for natural language applications. The difficulty in stochastic sequential learning is caused by the posterior collapse in variational inference. The input sequence is disregarded in the estimated latent variables. This paper proposes three components to tackle this difficulty and build the variational sequence autoencoder (VSAE) where sufficient latent information is learned for sophisticated sequence representation. First, the complementary encoders based on a long short-term memory (LSTM) and a pyramid bidirectional LSTM are merged to characterize global and structural dependencies of an input sequence, respectively. Second, a stochastic self attention mechanism is incorporated in a recurrent decoder. The latent information is attended to encourage the interaction between inference and generation in an encoder-decoder training procedure. Third, an autoregressive Gaussian prior of latent variable is used to preserve the information bound. Different variants of VSAE are proposed to mitigate the posterior collapse in sequence modeling. A series of experiments are conducted to demonstrate that the proposed individual and hybrid sequence autoencoders substantially improve the performance for variational sequential learning in language modeling and semantic understanding for document classification and summarization.","1939-3539","","10.1109/TPAMI.2021.3068187","Ministry of Science and Technology, Taiwan(grant numbers:MOST 110-2634-F-009-016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9384306","Sequence generation;recurrent neural network;variational autoencoder;hierarchical model;self attention","Decoding;Stochastic processes;Training;Semantics;Recurrent neural networks;Natural languages;Data models","Bayes methods;Gaussian processes;inference mechanisms;learning (artificial intelligence);natural language processing;recurrent neural nets;sequences;stochastic processes","sequence modeling;hybrid sequence autoencoders;variational sequential learning;language modeling;stochastic latent semantics;natural language applications;stochastic sequential learning;posterior collapse;variational inference;estimated latent variables;variational sequence autoencoder;VSAE;latent information;sophisticated sequence representation;complementary encoders;long short-term memory;pyramid bidirectional LSTM;global dependencies;structural dependencies;stochastic self attention mechanism;recurrent decoder;encoder-decoder training procedure","Algorithms;Learning;Neural Networks, Computer;Normal Distribution;Semantics","1","","37","IEEE","23 Mar 2021","","","IEEE","IEEE Journals"
"GLSR-VAE: Geodesic latent space regularization for variational autoencoder architectures","G. Hadjeres; F. Nielsen; F. Pachet","Sony CSL, Paris; Ecole Polytechnique, France; Sony CSL, Paris","2017 IEEE Symposium Series on Computational Intelligence (SSCI)","5 Feb 2018","2017","","","1","7","VAEs (Variational AutoEncoders) have proved to be powerful in the context of density modeling and have been used in a variety of contexts for creative purposes. In many settings, the data we model possesses continuous attributes that we would like to take into account at generation time. We propose in this paper GLSR-VAE, a Geodesic Latent Space Regularization for the Variational AutoEncoder architecture and its generalizations which allows a fine control on the embedding of the data into the latent space. When augmenting the VAE loss with this regularization, changes in the learned latent space reflects changes of the attributes of the data. This deeper understanding of the VAE latent space structure offers the possibility to modulate the attributes of the generated data in a continuous way. We demonstrate its efficiency on a monophonic music generation task where we manage to generate variations of discrete sequences in an intended and playful way.","","978-1-5386-2726-6","10.1109/SSCI.2017.8280895","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8280895","","Manifolds;Aerospace electronics;Decoding;Data models;Training;Interpolation;Stochastic processes","data visualisation;image coding;learning (artificial intelligence);music","geodesic latent space regularization;variational autoencoder architectures;VAEs;Variational AutoEncoders;density modeling;model possesses continuous attributes;Variational AutoEncoder architecture;VAE loss;VAE latent space structure;GLSR-VAE;data model;monophonic music generation;image generation","","11","","30","","5 Feb 2018","","","IEEE","IEEE Conferences"
"Information Theoretic-Learning auto-encoder","E. Santana; M. Emigh; J. C. Principe",University of Florida; University of Florida; University of Florida,"2016 International Joint Conference on Neural Networks (IJCNN)","3 Nov 2016","2016","","","3296","3301","We propose Information Theoretic-Learning (ITL) divergence measures for variational regularization of neural networks. We also explore ITL-regularized autoencoders as an alternative to variational autoencoding bayes, adversarial autoencoders and generative adversarial networks for randomly generating sample data without explicitly defining a paritition function. This paper also formalizes, generative moment matching networks under the ITL framework.","2161-4407","978-1-5090-0620-5","10.1109/IJCNN.2016.7727620","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727620","Information-theoretic Learning;deep learning;autoencoder;variational regularization","Decoding;Irrigation;Tin","Bayes methods;encoding;neural nets;variational techniques","information theoretic-learning;ITL;neural networks;variational autoencoding bayes;adversarial autoencoders;generative adversarial networks;generative moment matching networks","","8","","19","","3 Nov 2016","","","IEEE","IEEE Conferences"
"FastGMVAE: Underdetermined Source Separation Based on Multichannel Variational Auto-Encoder","L. Pi; X. Zheng; X. Wu","College of Communications Engineering, Army Engineering University of PLA, Nanjing, China; College of Communications Engineering, Army Engineering University of PLA, Nanjing, China; College of Communications Engineering, Army Engineering University of PLA, Nanjing, China","2021 4th International Conference on Information Communication and Signal Processing (ICICSP)","25 Nov 2021","2021","","","124","129","In this paper, Fast Generalized Multichannel Variational Auto-Encoder (FastGMVAE) is proposed by combining advantages of multichannel nonnegative matrix factorization and multichannel variational autoencoder to address underdetermined multichannel blind source separation problems. The proposed algorithm uses conditional variational autoencoder instead of the nonnegative matrix factorization model as a generative model that the power spectral density of each source signal, therefore the algorithm can separate the source signal from the mixture signals even if the source signal does not follow the nonnegative matrix factorization. Besides, the proposed algorithm constrains the spatial covariance matrix as a full rank diagonal matrix through jointly diagonalizable, the repeated heavy operations (e.g., inversion) of the spatial covariance matrix can be reduced. Comparing the simulation results of this algorithm with the baseline method, FastGMVAecan outperform the baseline method in terms of reduced computational complexity and separation performance.","","978-1-6654-0757-1","10.1109/ICICSP54369.2021.9611905","National Natural Science Foundation of China(grant numbers:61702543); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9611905","underdetermined source separation;variational autoencoder;spatial covariance matrix;power spectral density","Simulation;Computational modeling;Signal processing algorithms;Blind source separation;Computational efficiency;Covariance matrices;Task analysis","blind source separation;computational complexity;covariance matrices;matrix decomposition;neural nets","FastGMVAE;underdetermined source separation;Fast Generalized Multichannel Variational Auto-Encoder;multichannel nonnegative matrix factorization;multichannel variational autoencoder;underdetermined multichannel blind source separation problems;conditional variational autoencoder;nonnegative matrix factorization model;source signal;mixture signals;spatial covariance matrix;reduced computational complexity;separation performance;full rank diagonal matrix","","","","11","IEEE","25 Nov 2021","","","IEEE","IEEE Conferences"
"A Novel Vehicle Destination Prediction Model With Expandable Features Using Attention Mechanism and Variational Autoencoder","X. Wu; W. Zhu; Z. Liu; Z. Zhang","School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China","IEEE Transactions on Intelligent Transportation Systems","14 Sep 2022","2022","23","9","16548","16557","The daily passage of vehicles generates a huge amount of location-aware social data, which provides a rich source of data for analyzing vehicle travel behavior. Being able to accurately predict the future destinations of vehicle travel has great economic value and social impact. The presence of larger sparsity, fewer features and error information in the real dataset led to difficulties in convergence of previous models. Therefore, we propose a Novel Vehicle Destination Prediction Model with Expandable Features Using Attention Mechanism and Variational Autoencoder (EFAMVA). The EFAMVA model combines the autoencoder model and the attention mechanism has overcome the above mentioned problems. The variational autoencoder model obtains the hidden features conforming to the characteristics of the data from the structured vehicle driving data. And the attention mechanism can learn the appropriate combination of weight parameters. The comprehensive experimental results with other comparison models show that the EFAMVA model achieved the best index score, with the MSE value of 0.750, the RMSE value of 1.215, and the MAE value of 0.955. Therefore, it can be shown that the EFAMVA model has a better predictive effect on the future destination of the vehicle.","1558-0016","","10.1109/TITS.2021.3137168","National Natural Science Foundation of China(grant numbers:61972122); Zhejiang Provincial Natural Science Foundation of China(grant numbers:LZ22F020015); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678132","Variational autoencoder;vehicle driving data;vehicle travel destination prediction;attentional mechanisms","Predictive models;Data models;Vehicle driving;Trajectory;Feature extraction;Mathematical models;Load modeling","learning (artificial intelligence);mean square error methods;mobile computing;prediction theory;social networking (online);traffic engineering computing","analyzing vehicle travel behavior;future destination;great economic value;social impact;fewer features;Novel Vehicle Destination Prediction Model;Expandable Features;attention mechanism;EFAMVA model;variational autoencoder model;hidden features;structured vehicle driving data;comparison models;location-aware social data","","","","40","IEEE","11 Jan 2022","","","IEEE","IEEE Journals"
"Anomaly Detection with Conditional Variational Autoencoders","A. A. Pol; V. Berger; C. Germain; G. Cerminara; M. Pierini","Laboratoire de Recherche en Informatique (LRI), Université Paris-Saclay, Orsay, France; Laboratoire de Recherche en Informatique (LRI), Université Paris-Saclay, Orsay, France; Laboratoire de Recherche en Informatique (LRI), Université Paris-Saclay, Orsay, France; European Organization for Nuclear Research (CERN), Meyrin, Switzerland; European Organization for Nuclear Research (CERN), Meyrin, Switzerland","2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)","17 Feb 2020","2019","","","1651","1657","Exploiting the rapid advances in probabilistic inference, in particular variational Bayes and variational autoencoders (VAEs), for anomaly detection (AD) tasks remains an open research question. Previous works argued that training VAE models only with inliers is insufficient and the framework should be significantly modified in order to discriminate the anomalous instances. In this work, we exploit the deep conditional variational autoencoder (CVAE) and we define an original loss function together with a metric that targets hierarchically structured data AD. Our motivating application is a real world problem: monitoring the trigger system which is a basic component of many particle physics experiments at the CERN Large Hadron Collider (LHC). In the experiments we show the superior performance of this method for classical machine learning (ML) benchmarks and for our application.","","978-1-7281-4550-1","10.1109/ICMLA.2019.00270","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8999265","Anomaly Detection;Machine Learning;Variational Autoencoders;Large Hadron Collider","Computational modeling;Measurement;Data models;Anomaly detection;Image reconstruction;Computer architecture;Task analysis","Bayes methods;high energy physics instrumentation computing;inference mechanisms;learning (artificial intelligence)","original loss function;probabilistic inference;anomaly detection tasks;open research question;training VAE models;anomalous instances;AD;classical machine learning benchmarks;ML;LHC;CVAE;CERN large hadron collider;deep conditional variational autoencoder","","16","","31","","17 Feb 2020","","","IEEE","IEEE Conferences"
"Variational Autoencoder With Optimizing Gaussian Mixture Model Priors","C. Guo; J. Zhou; H. Chen; N. Ying; J. Zhang; D. Zhou","Hangzhou Dianzi University, Hangzhou, China; Hangzhou Dianzi University, Hangzhou, China; Hangzhou Dianzi University, Hangzhou, China; Hangzhou Dianzi University, Hangzhou, China; Hangzhou Dianzi University, Hangzhou, China; Zhejiang Uniview Technologies Company, Ltd., Hangzhou, China","IEEE Access","10 Mar 2020","2020","8","","43992","44005","The latent variable prior of the variational autoencoder (VAE) often utilizes a standard Gaussian distribution because of the convenience in calculation, but has an underfitting problem. This paper proposes a variational autoencoder with optimizing Gaussian mixture model priors. This method utilizes a Gaussian mixture model to construct prior distribution, and utilizes the Kullback-Leibler (KL) distance between posterior and prior distribution to implement an iterative optimization of the prior distribution based on the data. The greedy algorithm is used to solve the KL distance for defining the approximate variational lower bound solution of the loss function, and for realizing the VAE with optimizing Gaussian mixture model priors. Compared with the standard VAE method, the proposed method obtains state-of-the-art results on MNIST, Omniglot, and Frey Face datasets, which shows that the VAE with optimizing Gaussian mixture model priors can learn a better model.","2169-3536","","10.1109/ACCESS.2020.2977671","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9020116","Variational autoencoder;Gaussian mixture model;Kullback-Leibler distance","Gaussian mixture model;Gaussian distribution;Training;Standards;Neural networks;Aggregates","Gaussian distribution;Gaussian processes;greedy algorithms;iterative methods;mixture models;optimisation","optimizing Gaussian mixture model priors;variational autoencoder;standard Gaussian distribution;Kullback-Leibler distance","","8","","46","CCBY","2 Mar 2020","","","IEEE","IEEE Journals"
"Denoising Convolutional Variational Autoencoders-Based Feature Learning for Automatic Detection of Plant Diseases","V. Zilvan; A. Ramdan; E. Suryawati; R. B. S. Kusumo; D. Krisnandi; H. F. Pardede","Research Center for Informatics, Indonesian Institute of Sciences (LIPI), Bandung, Indonesia; Research Center for Informatics, Indonesian Institute of Sciences (LIPI), Bandung, Indonesia; Research Center for Informatics, Indonesian Institute of Sciences (LIPI), Bandung, Indonesia; Research Center for Informatics, Indonesian Institute of Sciences (LIPI), Bandung, Indonesia; Research Center for Informatics, Indonesian Institute of Sciences (LIPI), Bandung, Indonesia; Research Center for Informatics, Indonesian Institute of Sciences (LIPI), Bandung, Indonesia","2019 3rd International Conference on Informatics and Computational Sciences (ICICoS)","6 Feb 2020","2019","","","1","6","Early detection is critical for maintaining quantity and quality of farming commodity. Currently, detection of plant diseases still requires human expertise and/or need microscopic identification such as spectroscopic technique and molecular biological. So, it would be very costly and time consuming, and hence unattainable for small-holder farmers. The rapid development of intelligent agriculture using machine learning has led the widespread use of computer or smart-phones to solve this problem. So, early detection of plant disease can be performed with minimal support from human experts and microscopic identification is no longer needed. However, conventional machine-learning techniques are limited in their ability to process raw data directly. So it require some efforts and domain expertise to design feature extractor to support it. Moreover, impulse noise such as salt-pepper noise may present on the images and it arises another challenge to provide a robust system. In this paper, we present denoising convolutional variational autoencoders as automatic unsupervised feature extractor and automatic denoiser to learn and to extract good features directly from the raw data. Here, we use the output of denoising convolutional variational auto encoders as inputs to fully connected networks classifiers for automatic detection of plant diseases. Our experiments show the average accuracies of our method is better than denoising variational autoencoders which is built using fully deep connected networks architectures. We also found that our proposed method is more robust against noisy test data.","","978-1-7281-4610-2","10.1109/ICICoS48119.2019.8982494","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8982494","Denoising convolutional variational autoencoders;feature learning;plant diseases detection;deep learning;autoen-coders","","agriculture;convolution;convolutional neural nets;feature extraction;image denoising;pattern classification;plant diseases;product quality;smart phones;unsupervised learning","plant disease detection;microscopic identification;spectroscopic technique;machine-learning techniques;automatic unsupervised feature extractor;automatic denoiser;denoising convolutional variational autoencoders-based feature learning","","7","","19","","6 Feb 2020","","","IEEE","IEEE Conferences"
"A Discriminative Cross-Aligned Variational Autoencoder for Zero-Shot Learning","Y. Liu; X. Gao; J. Han; L. Shao","State Key Laboratory of Integrated Services Networks, Xidian University, Xi'an 710071, China, also with the Key Laboratory of Artificial Intelligence, Ministry of Education, Shanghai Jiao Tong University, Shanghai 200240, China, also with the Key Laboratory of Cryptologic Technology and Information Security, Ministry of Education, Shandong University, Jinan 250100, China, and also with the Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, Nanjing 211189, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing 400065, China, and also with the State Key Laboratory of Integrated Services Networks, Xidian University, Xi'an 710071, China.; Department of Computer Science, Aberystwyth University, Aberystwyth SY23 3DB, U.K..; Inception Institute of Artificial Intelligence, Abu Dhabi, UAE.","IEEE Transactions on Cybernetics","","2022","PP","99","1","12","Zero-shot learning (ZSL) aims to classify unseen samples based on the relationship between the learned visual features and semantic features. Traditional ZSL methods typically capture the underlying multimodal data structures by learning an embedding function between the visual space and the semantic space with the Euclidean metric. However, these models suffer from the hubness problem and domain bias problem, which leads to unsatisfactory performance, especially in the generalized ZSL (GZSL) task. To tackle such a problem, we formulate a discriminative cross-aligned variational autoencoder (DCA-VAE) for ZSL. The proposed model effectively utilizes a modified cross-modal-alignment variational autoencoder (VAE) to transform both visual features and semantic features obtained by the discriminative cosine metric into latent features. The key to our method is that we collect principal discriminative information from visual and semantic features to construct latent features which contain the discriminative multimodal information associated with unseen samples. Finally, the proposed model DCA-VAE is validated on six benchmarks including the large dataset ImageNet, and several experimental results demonstrate the superiority of DCA-VAE over most existing embedding or generative ZSL models on the standard ZSL and the more realistic GZSL tasks.","2168-2275","","10.1109/TCYB.2022.3164142","National Natural Science Foundation of China(grant numbers:61906141,62036007,62176195,U21A20514); China Postdoctoral Science Foundation(grant numbers:2019M653564); Open Project Program of the State Key Laboratory of CAD and CG Zhejiang University(grant numbers:A2223); Open Project Program of State Key Laboratory of Virtual Reality Technology and Systems Beihang University(grant numbers:VRLAB2021B02); Open Project Program from Key Laboratory of Artificial Intelligence Ministry of Education Shanghai Jiao Tong University; Open Project Program from Key Laboratory of Cryptologic Technology and Information Security Ministry of Education Shandong University; CCF-Tencent Open Fund; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9762888","Autoencoder;cosine;discriminative;latent;zero-shot learning (ZSL)","Visualization;Semantics;Task analysis;Training;Solid modeling;Prototypes;Generative adversarial networks","","","","","","","IEEE","25 Apr 2022","","","IEEE","IEEE Early Access Articles"
"Graph Regularized Variational Ladder Networks for Semi-Supervised Learning","C. Hu; X. -N. Song","Fujian Provincial Key Laboratory of Information Processing and Intelligent Control, Minjiang University, Fuzhou, China; Jiangsu Provincial Engineering Laboratory of Pattern Recognition and Computational Intelligence, Jiangnan University, Wuxi, China","IEEE Access","23 Nov 2020","2020","8","","206280","206288","To tackle the problem of semi-supervised learning (SSL), we propose a new autoencoder-based deep model. Ladder networks (LN) is an autoencoder-based method for representation learning which has been successfully applied on unsupervised learning and semi-supervised learning. However, It ignores the manifold information of high-dimensional data and usually achieves unmeaning features which are very difficult to use in the subsequent tasks, such as prediction and recognition. To these issues, we proposed Graph Regularized Variational Ladder Networks (GRVLN), which explicitly and implicitly employs the manifold structure of data. Our contributions can be summarized as two folds: (1) Graph regularization is used to build all decoder layers, which explicitly promotes the manifold learning via graph laplacian matrixs; (2) Variational autoencoder is used as the backbone instead of traditional autoencoder in the encoder layers for implicitly learning the manifold structure of data distribution. Compared with ladder networks and other autoencoder-based methods, GRVLN achieves superior performance in semi-supervised classification tasks. Experimental results show that our method also has a comparable performance with state-of-the-art methods on several benchmark data sets.","2169-3536","","10.1109/ACCESS.2020.3038276","National Natural Science Foundation of China(grant numbers:62006097,61876072,61902153,61772273); National Key Research and Development Program of China(grant numbers:2017YFC1601800); Open Fund Project of Fujian Provincial Key Laboratory of Information Processing and Intelligent Control, Minjiang University(grant numbers:MJUKF-IPIC202002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9260146","Semi-supervised learning;ladder network;manifold regularization;graph laplacian;variational autoencoder","Semisupervised learning;Decoding;Manifolds;Deep learning;Data models;Encoding;Training","data analysis;data structures;graph theory;matrix algebra;neural nets;pattern classification;supervised learning;unsupervised learning","semisupervised classification;semisupervised learning;representation learning;unsupervised learning;autoencoder based deep model;graph regularized variational ladder networks;data structure;manifold learning;graph Laplacian matrix;variational autoencoder;deep learning;labeled data","","","","51","CCBY","16 Nov 2020","","","IEEE","IEEE Journals"
"Variational Deep Clustering of Wafer Map Patterns","J. Hwang; H. Kim","Department of Industrial and Systems Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Industrial and Systems Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Transactions on Semiconductor Manufacturing","5 Aug 2020","2020","33","3","466","475","In semiconductor manufacturing, several measurement data called wafer maps are obtained in the metrology steps, and the variations in the process are detected by analyzing the wafer map data. Hidden processes or equipment affecting the process quality variations can be found by comparing the process tracking history and clustered groups of similar wafer maps; thus, clustering analysis is very important to reduce the process quality variations. Currently, clustering wafer maps are becoming more difficult as the wafer maps are formed into more complex patterns along with high-dimensional data. For more effective clustering of complex and high-dimensional wafer maps, we implement a Gaussian mixture model to a variational autoencoder framework to extract features that are more suitable to the clustering environment, and a Dirichlet process is further applied in the variational autoencoder mixture framework for automated one-step clustering. The proposed method is validated using a real dataset from a global semiconductor manufacturing company, and we demonstrate that it is more effective than other competitive methods in determining the number of clusters and clustering wafer map patterns.","1558-2345","","10.1109/TSM.2020.3004483","National Research Foundation of Korea Grant; Korea Government (MSIT)(grant numbers:2018R1C1B6004511); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9123439","Bayesian nonparametrics;clustering;deep neural network;Dirichlet process;Gaussian mixture model;semiconductor manufacturing;variational autoencoder","Feature extraction;Semiconductor device manufacture;Gaussian mixture model;Clustering methods","neural nets;pattern clustering;production engineering computing;semiconductor device manufacture;semiconductor device reliability","process quality variations;high-dimensional data;high-dimensional wafer maps;variational autoencoder framework;clustering environment;Dirichlet process;variational autoencoder mixture framework;one-step clustering;clustering wafer map patterns;variational deep clustering;measurement data;wafer map data;clustering analysis","","16","","35","IEEE","23 Jun 2020","","","IEEE","IEEE Journals"
"Toward Effective Intrusion Detection Using Log-Cosh Conditional Variational Autoencoder","X. Xu; J. Li; Y. Yang; F. Shen","Center for Future Multimedia and the School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Future Multimedia and the School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Future Multimedia and the School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Future Multimedia and the School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Internet of Things Journal","7 Apr 2021","2021","8","8","6187","6196","Intrusion detection is an important technique that can provide solid protection for the network equipment against the security attacks. However, the attacks are usually unbalanced in different types and the attacks of unknown classes may also occur with the growth of Internet construction. In this case, the traditional machine learning-based intrusion detection methods usually have inferior detection accuracy and high false-positive rates. To tackle this problem, in this article, we propose a novel deep learning-based intrusion detection method named log-cosh conditional variational autoencoder (LCVAE). It inherits the capability of the conditional variational autoencoder (CVAE) that can capture the complex distribution of observed data and generate new data with prespecified classes. Different from the traditional CVAE, to better model the discrete property in the intrusion data, we design an effective loss term using the log hyperbolic cosine (log-cosh) function in the proposed LCVAE method. It can well balance the generation and reconstruction procedures and is more effective to generate diverse intrusion data for the imbalanced classes. To improve the detection accuracy, we utilize the classification based on convolutional neural network to perform feature extraction and classification based on the observed and generated intrusion data. We conduct extensive experiments on the challenging data set NSL-KDD with large-scale intrusion data. The results show that the superior detection performance of the proposed LCVAE method comparing with several state-of-the-art intrusion detection methods, and also demonstrate the potentiality of generating new intrusion data with promising diversity.","2327-4662","","10.1109/JIOT.2020.3034621","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9244068","Deep neural networks (DNNs);generative model;intrusion detection;variational autoencoder (VAE)","Intrusion detection;Feature extraction;Internet of Things;Data models;Decoding;Security;Generators","convolutional neural nets;deep learning (artificial intelligence);feature extraction;Internet;pattern classification;security of data","Internet;convolutional neural network;NSL-KDD;log-cosh conditional variational autoencoder;LCVAE method;log hyperbolic cosine function;deep learning;machine learning;security attacks;intrusion detection;large-scale intrusion data","","16","","55","IEEE","29 Oct 2020","","","IEEE","IEEE Journals"
"Balancing Reconstruction Error and Kullback-Leibler Divergence in Variational Autoencoders","A. Asperti; M. Trentin","Department of Informatics, Science, and Engineering (DISI), University of Bologna, Bologna, Italy; Department of Informatics, Science, and Engineering (DISI), University of Bologna, Bologna, Italy","IEEE Access","9 Nov 2020","2020","8","","199440","199448","Likelihood-based generative frameworks are receiving increasing attention in the deep learning community, mostly on account of their strong probabilistic foundation. Among them, Variational Autoencoders (VAEs) are reputed for their fast and tractable sampling and relatively stable training, but if not properly tuned they may easily produce poor generative performances. The loss function of Variational Autoencoders is the sum of two components, with somehow contrasting effects: the reconstruction loss, improving the quality of the resulting images, and the Kullback-Leibler divergence, acting as a regularizer of the latent space. Correctly balancing these two components is a delicate issue, and one of the major problems of VAEs. Recent techniques address the problem by allowing the network to learn the balancing factor during training, according to a suitable loss function. In this article, we show that learning can be replaced by a simple deterministic computation, expressing the balancing factor in terms of a running average of the reconstruction error over the last minibatches. As a result, we keep a constant balance between the two components along training: as reconstruction improves, we proportionally decrease KL-divergence in order to prevent its prevalence, that would forbid further improvements of the quality of reconstructions. Our technique is simple and effective: it clarifies the learning objective for the balancing factor, and it produces faster and more accurate behaviours. On typical datasets such as Cifar10 and CelebA, our technique sensibly outperforms all previous VAE architectures with comparable parameter capacity.","2169-3536","","10.1109/ACCESS.2020.3034828","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9244048","Generative models;likelilhood-based frameworks;Kullback-Leibler divergence;two-stage generation;variational autoencoders","Image reconstruction;Training;Gaussian distribution;Shape;Mathematical model;Probabilistic logic;Data models","image reconstruction;learning (artificial intelligence);neural nets;probability;sampling methods;statistical distributions","deep learning community;reconstruction loss;Kullback-Leibler divergence;balancing factor;KL-divergence;balancing reconstruction error;likelihood-based generative frameworks;variational autoencoders;VAE;image quality;probabilistic distribution","","13","","26","CCBY","29 Oct 2020","","","IEEE","IEEE Journals"
"Variational Autoencoder Bidirectional Long and Short-Term Memory Neural Network Soft-Sensor Model Based on Batch Training Strategy","W. Xie; J. Wang; C. Xing; S. Guo; M. Guo; L. Zhu","School of Electronic and Information Engineering, University of Science and Technology Liaoning, Anshan, China; School of Electronic and Information Engineering, University of Science and Technology Liaoning, Anshan, China; School of Electronic and Information Engineering, University of Science and Technology Liaoning, Anshan, China; School of Electronic and Information Engineering, University of Science and Technology Liaoning, Anshan, China; School of Electronic and Information Engineering, University of Science and Technology Liaoning, Anshan, China; School of Electronic and Information Engineering, University of Science and Technology Liaoning, Anshan, China","IEEE Transactions on Industrial Informatics","4 May 2021","2021","17","8","5325","5334","Long and short-term memory (LSTM) has been used in soft-sensor modeling of industrial processes in recent years. However, LSTM still has many defects for soft-sensor. This article proposes a variational autoencoder bidirectional LSTM soft-sensor modeling method based on batch training (Bt-VAEBiLSTM). First, the training samples are divided into multiple batches according to the time series, in order to reduce the influence of abnormal points and noise, the variational autoencoder is then used to reconstruct the training samples in each batch in order to solve the problem of the global LSTM model discarding critical data information during training; this article proposes a batch training method that is to say the reconstructed samples are trained in batches according to the time series. After the training of a batch samples is completed, the structural parameters of the previous local bidirectional LSTM (BiLSTM) model are shared with the next local BiLSTM model as the initial parameters to retain important state information. At the same time, in order to prevent the Bt-VAEBiLSTM model from overfitting, the L2 regularization term is introduced in the loss function. The effectiveness of the proposed method is verified by simulation experiments on the grinding and classifying process.","1941-0050","","10.1109/TII.2020.3025204","Institution of Higher Learning of Liaoning Province(grant numbers:2017FWDF10); National Natural Science Foundation of China(grant numbers:20180550700); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9200687","Batch training;bidirectional long- and short-term memory neural network;L2 regularization;soft-sensor;variational autoencoder (VAE)","Training;Logic gates;Neural networks;Feature extraction;Data models;Time series analysis;Informatics","batch processing (industrial);learning (artificial intelligence);production engineering computing;recurrent neural nets;time series","L2 regularization term;variational autoencoder bidirectional long and short-term memory neural network soft-sensor model;multiple batches;batch training strategy;Bt-VAEBiLSTM model;batch samples;batch training method;global LSTM model;training samples;time series","","11","","15","IEEE","18 Sep 2020","","","IEEE","IEEE Journals"
"Photo-Realistic Image Super-Resolution via Variational Autoencoders","Z. -S. Liu; W. -C. Siu; Y. -L. Chan","Department of Electronic and Information Engineering (EIE), Center for Multimedia Signal Processing, The Hong Kong Polytechnic University, Hong Kong; Department of Electronic and Information Engineering (EIE), Center for Multimedia Signal Processing, The Hong Kong Polytechnic University, Hong Kong; Department of Electronic and Information Engineering (EIE), Center for Multimedia Signal Processing, The Hong Kong Polytechnic University, Hong Kong","IEEE Transactions on Circuits and Systems for Video Technology","2 Apr 2021","2021","31","4","1351","1365","There is a great leap in objective accuracy on image super-resolution, which recently brings a new challenge on image super-resolution with larger up-scaling (e.g. 4×) using pixel based distortion for measurement. This causes over-smooth effect which cannot grasp well the perceptual similarity. The advent of generative adversarial networks makes it possible super-resolve a low-resolution image to generate photo-realistic images sharing distribution with the high-resolution images. However, generative networks suffer from problems of mode-collapse and unrealistic sample generation. We propose to perform Image Super-Resolution via Variational AutoEncoders (SR-VAE) learning according to the conditional distribution of the high-resolution images induced by the low-resolution images. Given that the Conditional Variational Autoencoders tend to generate blur images, we add the conditional sampling mechanism to narrow down the latent subspace for reconstruction. To evaluate the model generalization, we use KL loss to measure the divergence between latent vectors and standard Gaussian distribution. Eventually, in order to balance the trade-off between super-resolution distortion and perception, not only that we use pixel based loss, we also use the modified deep feature loss between SR and HR images to estimate the reconstruction. In experiments, we evaluated a large number of datasets to make comparison with other state-of-the-art super-resolution approaches. Results on both objective and subjective measurements show that our proposed SR-VAE can achieve good photo-realistic perceptual quality closer to the natural image manifold while maintain low distortion.","1558-2205","","10.1109/TCSVT.2020.3003832","Centre for Signal Processing, Department of Electronic and Information Engineering, The Hong Kong Polytechnic University(grant numbers:1-BBA2,G-YBKG); Research Grants Council of the Hong Kong Special Administrative Region, China(grant numbers:PolyU 5243/13E); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121327","Image super-resolution;variational autoencoders;distortion;divergence","Gallium nitride;Generative adversarial networks;Distortion;Image reconstruction;Feature extraction;Distortion measurement;Generators","Gaussian distribution;image reconstruction;image resolution;image sampling;learning (artificial intelligence);neural nets;realistic images","super-resolution distortion;generative adversarial networks;low-resolution image;high-resolution images;conditional variational autoencoders;blur images;photorealistic image super-resolution;natural image manifold;pixel based distortion;over-smooth effect;unrealistic sample generation;mode-collapse;SR-VAE learning;conditional sampling mechanism;KL loss;standard Gaussian distribution;latent vectors;modified deep feature loss;HR images","","7","","55","IEEE","19 Jun 2020","","","IEEE","IEEE Journals"
"Multimodal Disentangled Variational Autoencoder With Game Theoretic Interpretability for Glioma Grading","J. Cheng; M. Gao; J. Liu; H. Yue; H. Kuang; J. Liu; J. Wang","Institute of Guizhou Aerospace Measuring and Testing Technology, Guiyang, China; Department of Radiology Quality Control Center, Changsha, China; Hunan Provincial Key Lab on Bioinformatics, School of Computer Science and Engineering, Central South University, Changsha, China; Hunan Provincial Key Lab on Bioinformatics, School of Computer Science and Engineering, Central South University, Changsha, China; Hunan Provincial Key Lab on Bioinformatics, School of Computer Science and Engineering, Central South University, Changsha, China; Department of Radiology Quality Control Center, Changsha, China; Hunan Provincial Key Lab on Bioinformatics, School of Computer Science and Engineering, Central South University, Changsha, China","IEEE Journal of Biomedical and Health Informatics","4 Feb 2022","2022","26","2","673","684","Effective fusion of multimodal magnetic resonance imaging (MRI) is of great significance to boost the accuracy of glioma grading thanks to the complementary information provided by different imaging modalities. However, how to extract the common and distinctive information from MRI to achieve complementarity is still an open problem in information fusion research. In this study, we propose a deep neural network model termed as multimodal disentangled variational autoencoder (MMD-VAE) for glioma grading based on radiomics features extracted from preoperative multimodal MRI images. Specifically, the radiomics features are quantized and extracted from the region of interest for each modality. Then, the latent representations of variational autoencoder for these features are disentangled into common and distinctive representations to obtain the shared and complementary data among modalities. Afterwards, cross-modality reconstruction loss and common-distinctive loss are designed to ensure the effectiveness of the disentangled representations. Finally, the disentangled common and distinctive representations are fused to predict the glioma grades, and SHapley Additive exPlanations (SHAP) is adopted to quantitatively interpret and analyze the contribution of the important features to grading. Experimental results on two benchmark datasets demonstrate that the proposed MMD-VAE model achieves encouraging predictive performance (AUC:0.9939) on a public dataset, and good generalization performance (AUC:0.9611) on a cross-institutional private dataset. These quantitative results and interpretations may help radiologists understand gliomas better and make better treatment decisions for improving clinical outcomes.","2168-2208","","10.1109/JBHI.2021.3095476","National Natural Science Foundation of China(grant numbers:61802442,61877059); Natural Science Foundation of Hunan Province(grant numbers:2019JJ50775); Higher Education Discipline Innovation Project(grant numbers:B18059); Hunan Provincial Science and Technology Program(grant numbers:2018WK4001,2020GK2019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9478224","Glioma grading;variational autoencoder;disentangled representation;SHAP","Feature extraction;Magnetic resonance imaging;Tumors;Solid modeling;Radiomics;Bioinformatics;Imaging","biomedical MRI;brain;deep learning (artificial intelligence);feature extraction;image classification;medical image processing;tumours","cross-modality reconstruction loss;disentangled representations;glioma grades;MMD-VAE model;game theoretic interpretability;multimodal magnetic resonance imaging;glioma grading thanks;distinctive information;information fusion research;deep neural network model;multimodal disentangled variational autoencoder;radiomics features;preoperative multimodal MRI images;latent representations","Glioma;Humans;Magnetic Resonance Imaging;Neoplasm Grading;Neural Networks, Computer","6","","54","IEEE","8 Jul 2021","","","IEEE","IEEE Journals"
"EnsVAE: Ensemble Variational Autoencoders for Recommendations","A. Drif; H. E. Zerrad; H. Cherifi","Networks and Distributed System Laboratory, Faculty of Science, Ferhat Abbas University, Setif, Algeria; Computer Science Department, Ferhat Abbas University, Setif, Algeria; LIB, University of Burgundy, Dijon, France","IEEE Access","22 Oct 2020","2020","8","","188335","188351","Recommender systems are information software that retrieves relevant items for users from massive sources of data. The variational autoencoder (VAE) has proven to be a promising approach for recommendation systems, as it can explore high-level user-item relations and extract contingencies from the input effectively. However, the previous variants of VAE have so far seen limited application to domain-specific recommendations that require additional side information. Hence, The Ensemble Variational Autoencoder framework for recommendations (EnsVAE) is proposed. This architecture specifies a procedure to transform sub-recommenders' predicted utility matrix into interest probabilities that allow the VAE to represent the variation in their aggregation. To evaluate the performance of EnsVAE, an instance - called the “Ensemblist GRU/GLOVE model” - is developed. It is based on two innovative recommender systems: 1-) a new “GloVe content-based filtering recommender” (GloVe-CBF) that exploits the strengths of embedding-based representations and stacking ensemble learning techniques to extract features from the item-based side information. 2-) a variant of neural collaborative filtering recommender, named “Gate Recurrent Unit-based Matrix Factorization recommender” (GRU-MF). It models a high level of non-linearities and exhibits interactions between users and items in latent embeddings, reducing user biases towards items that are rated frequently by users. The developed instance speeds up the reconstruction of the utility matrix with increased accuracy. Additionally, it can switch between one of its sub-recommenders according to the context of their use. Our findings reveal that EnsVAE instances retain as much information as possible during the reconstruction of the utility matrix. Furthermore, the trained VAE's generative trait tackles the cold-start problem by accurately estimating the interest probabilities of newly-introduced users and resources. The empirical study on real-world datasets proves that EnsVAE significantly outperforms the state-of-the-art methods in terms of recommendation performances.","2169-3536","","10.1109/ACCESS.2020.3030693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9224132","Hybrid recommender systems;neural recommender models;collaborative filtering;content-based filtering;variational autoencoders","Recommender systems;Collaboration;Stacking;Logic gates;Predictive models;Feature extraction","collaborative filtering;learning (artificial intelligence);matrix decomposition;recommender systems","information software;relevant items;recommendation systems;high-level user-item relations;domain-specific recommendations;Ensemble Variational Autoencoder framework;sub-recommenders;interest probabilities;innovative recommender systems;GloVe-CBF;embedding-based representations;stacking ensemble learning techniques;neural collaborative filtering recommender;Gate Recurrent Unit-based Matrix Factorization recommender;user biases;utility matrix;EnsVAE instances;recommendation performances;item-based side information","","5","","68","CCBY","14 Oct 2020","","","IEEE","IEEE Journals"
"Generating In-Between Images Through Learned Latent Space Representation Using Variational Autoencoders","P. Cristovao; H. Nakada; Y. Tanimura; H. Asoh","National Institute of Advanced Industrial Science and Technology, Tsukuba, Japan; National Institute of Advanced Industrial Science and Technology, Tsukuba, Japan; National Institute of Advanced Industrial Science and Technology, Tsukuba, Japan; National Institute of Advanced Industrial Science and Technology, Tsukuba, Japan","IEEE Access","20 Aug 2020","2020","8","","149456","149467","Image interpolation is often implemented using one of two methods: optical flow or convolutional neural networks. These methods are typically pixel-based; they do not work well on objects between images far apart. Because they either rely on a simple frame average or pixel motion, they do not have the required knowledge of the semantic structure of the data. In this paper, we propose a method for image interpolation based on latent representations. We use a simple network structure based on a variational autoencoder and an adjustable hyperparameter that imposes the latent space distribution to generate accurate interpolation. To visualize the effects of the proposed approach, we evaluate a synthetic dataset. We demonstrate that our method outperforms both pixel-based methods and a conventional variational autoencoder, with particular improvements in nonsuccessive images.","2169-3536","","10.1109/ACCESS.2020.3016313","Japan Society for the Promotion of Science (JSPS) KAKENHI(grant numbers:19K11994); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9166477","Image interpolation;latent variables;representation learning;variational autoencoder","Interpolation;Optical imaging;Optical computing;Semantics;Optical noise;Aerospace electronics;Task analysis","image motion analysis;image representation;image sequences;interpolation;learning (artificial intelligence);neural nets","convolutional neural networks;pixel motion;semantic structure;image interpolation;latent space distribution;nonsuccessive images;latent space representation;optical flow;in-between images;variational autoencoders","","3","","60","CCBY","13 Aug 2020","","","IEEE","IEEE Journals"
"Implicit Discriminator in Variational Autoencoder","P. Munjal; A. Paul; N. C. Krishnan","Indian Institute of Technology Ropar, India; Indian Institute of Technology Ropar, India; Indian Institute of Technology Ropar, India","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","8","Recently generative models have focused on combining the advantages of variational autoencoders (VAE) and generative adversarial networks (GAN) for good reconstruction and generative abilities. In this work we introduce a novel hybrid architecture, Implicit Discriminator in Variational Autoencoder (IDVAE), that combines a VAE and a GAN, which does not need an explicit discriminator network. The fundamental premise of the IDVAE architecture is that the encoder of a VAE and the discriminator of a GAN utilize common features and therefore can be trained as a shared network, while the decoder of the VAE and the generator of the GAN can be combined to learn a single network. This results in a simple two-tier architecture that has the properties of both a VAE and a GAN. The qualitative and quantitative experiments on real-world benchmark datasets demonstrate that IDVAE performs better than the state of the art hybrid approaches. We experimentally validate that IDVAE can be easily extended to work in a conditional setting and demonstrate its performance on complex datasets.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9207307","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207307","Variational Autoencoders;Generative Adversarial Networks","Gallium nitride;Decoding;Generative adversarial networks;Generators;Training;Image reconstruction;Games","learning (artificial intelligence);neural nets","IDVAE architecture;GAN;shared network;two-tier architecture;generative adversarial networks;hybrid architecture;explicit discriminator network;generative models;implicit discriminator in variational autoencoder;single network","","2","","28","","28 Sep 2020","","","IEEE","IEEE Conferences"
"Estimation of Distribution using Population Queue based Variational Autoencoders","S. Bhattacharjee; R. Gras","School of Computer Science, University of Windsor, Windsor, Canada; School of Computer Science, Department of Biological Sciences Great Lakes Institute for Environmental Research, University of Windsor, Windsor, Canada","2019 IEEE Congress on Evolutionary Computation (CEC)","8 Aug 2019","2019","","","1406","1414","We present a new Estimation of Distribution algorithms (EDA) based on two novel Variational Autoencoders generative model building algorithms. The first method, Variational Autoencoder with Population Queue (VAE-EDA-Q), employs a queue of historical populations, which is updated at each iteration of EDA in order to smooth the data generation process. The second method uses Adaptive Variance Scaling (AVS) with VAE-EDA-Q to dynamically update the variance at which the probabilistic model is sampled. The results obtained prove our methods to be significantly more computationally efficient than state-of-the-art algorithms and perform significantly less number of fitness evaluations when tested on benchmark problems such as Trap-k and NK Landscapes. Moreover, we report results of applying our approach successfully to highly complex problems such as Trap 11, Trap 13, and NK Landscapes with neighborhood size K = 8 and K = 10.","","978-1-7281-2153-6","10.1109/CEC.2019.8790077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8790077","Estimation of Distribution Algorithms;Variational Autoencoders;Machine Learning;Combinatorial Opti-mization","Sociology;Statistics;Computational modeling;Adaptation models;Probabilistic logic;Noise reduction;Mathematical model","learning (artificial intelligence);probability;queueing theory;stochastic programming","historical populations;data generation process;VAE-EDA-Q;probabilistic model;adaptive variance scaling;population queue;estimation of distribution algorithms;variational autoencoders generative model;fitness evaluations","","1","","33","","8 Aug 2019","","","IEEE","IEEE Conferences"
"Integration of Variational Autoencoder and Spatial Clustering for Adaptive Multi-Channel Neural Speech Separation","K. Zmolikova; M. Delcroix; L. Burget; T. Nakatani; J. H. Černocky","Faculty of IT, IT4I Centre of Excellence, Brno University of Technology; NTT Communication Science Laboratories, NTT Corporation, Kyoto, Japan; Faculty of IT, IT4I Centre of Excellence, Brno University of Technology; NTT Communication Science Laboratories, NTT Corporation, Kyoto, Japan; Faculty of IT, IT4I Centre of Excellence, Brno University of Technology","2021 IEEE Spoken Language Technology Workshop (SLT)","25 Mar 2021","2021","","","889","896","In this paper, we propose a method combining variational autoencoder model of speech with a spatial clustering approach for multi-channel speech separation. The advantage of integrating spatial clustering with a spectral model was shown in several works. As the spectral model, previous works used either factorial generative models of the mixed speech or discriminative neural networks. In our work, we combine the strengths of both approaches, by building a factorial model based on a generative neural network, a variational autoencoder. By doing so, we can exploit the modeling power of neural networks, but at the same time, keep a structured model. Such a model can be advantageous when adapting to new noise conditions as only the noise part of the model needs to be modified. We show experimentally, that our model significantly outperforms previous factorial model based on Gaussian mixture model (DOLPHIN), performs comparably to integration of permutation invariant training with spatial clustering, and enables us to easily adapt to new noise conditions.","","978-1-7281-7066-4","10.1109/SLT48900.2021.9383612","National Science Foundation; Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9383612","Multi-channel speech separation;variational autoencoder;spatial clustering;DOLPHIN","Training;Adaptation models;Speech coding;Neural networks;Noise measurement;Dolphins;Software development management","adaptive signal processing;Gaussian processes;mixture models;neural nets;pattern clustering;signal denoising;source separation;speech processing","adaptive multichannel neural speech separation;spatial clustering;multichannel speech separation;spectral model;factorial generative models;mixed speech;discriminative neural networks;generative neural network;noise conditions;Gaussian mixture model;variational autoencoder","","1","","40","","25 Mar 2021","","","IEEE","IEEE Conferences"
"Yarn-Dyed Shirt cut Pieces Defect Detection Using Attention Vector Quantized-Variational Autoencoder","H. Zhang; S. Liu; Z. Ge; P. Li","Zhejiang University, state key laboratory of industrial control technology, Hangzhou, ZheJiang, China; Xi'an Polytechnic University, Institute of Machine Vision and Intelligent Detection, Xi'an, ShaanXi, China; Zhejiang University, state key laboratory of industrial control technology, Hangzhou, ZheJiang, China; Xi'an Polytechnic University, Institute of Machine Vision and Intelligent Detection, Xi'an, ShaanXi, China","2021 IEEE 10th Data Driven Control and Learning Systems Conference (DDCLS)","25 Jun 2021","2021","","","1356","1361","For yarn-dyed shirt cut defects detection problems in production process, this paper proposes a yarn-dyed shirt cut defects detection method based on attention vector-quantized variational autoencoder reconstructed model and residual analysis. To solve the actual problem that the defect sample quantity scarce, defect categories imbalances, high cost and poor generalization ability of artificial design defect features. Firstly, for a certain yarn-dyed shirt cut, salt and pepper noise is artificially added to the defect-free samples to construct a training data set, and then a reconstruction model based on the attention vector quantized variational autoencoder is established and trained. Secondly, a residual map between the original image and the correspondingly reconstructed image is calculated. Finally, the defective area could be detected and located by thresholding and opening operation processing. Experimental results on several yarn-dyed shirt cut pieces data sets show that the proposed method can effectively reconstruct the yarn-dyed shirt cut pieces, detect and locate the defect area of yarn-dyed shirt cut pieces quickly.","2767-9861","978-1-6654-2423-3","10.1109/DDCLS52934.2021.9455583","National Natural Science Foundation of China(grant numbers:61803292); Key Research and Development Program of Shaanxi Province(grant numbers:2019ZDLGY01-08); Shaanxi Provincial Science and Technology Department(grant numbers:2019JM-263); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9455583","Fabric defect detection;Unsupervised learning;Variational autoencoder;Attention model","Training;Computational modeling;Training data;Morphology;Production;Inspection;Fabrics","clothing;design engineering;feature extraction;image denoising;image reconstruction;image segmentation;neural nets;production engineering computing;yarn","defect detection;artificial design defect features;yarn dyed shirt;residual analysis;salt and pepper noise;attention vector quantized variational autoencoder training;image reconstruction;thresholding;production process","","","","17","","25 Jun 2021","","","IEEE","IEEE Conferences"
"Automatic Mask Detecion using Convolutional Neural Networks and Variational Autoencoder","M. Silabela; B. Bogdandy; Z. Toth","Faculty of Informatics, Eszterhazy Karoly University, Eger, Hungary; Faculty of Informatics, Eszterhazy Karoly University, Eger, Hungary; Faculty of Informatics, Eszterhazy Karoly University, Eger, Hungary","2021 IEEE 15th International Symposium on Applied Computational Intelligence and Informatics (SACI)","30 Jun 2021","2021","","","461","466","The importance of proper hygienical behaivour is essential in today's word especially during an ongoing pandemic. Wearing mask became mandatory in many countries during the COVID-19 Pandemic. Recognizing whether people are wearing masks is complicated image recognition task which could be facilitated and automated with machine learning techniques. Camera streams are widely available in indoor environments which can be used for object detection and image processing. Convolutional Neural Networks have been successfully applied in image classification and object recognition task in various application areas. There are already trained and openly available general purpose convolutional neural networks which can be used as an initial version for specific applications. A number of different image datasets are also available for research and industrial purposes. The InceptionV3 Neural Network architecture was used to tailored to determine whether a mask is being worn or not using transfer learning techniques, and convolutional neural networks. A variational autoencoder has also been trained to normalize the dataset with respect to skin colour, angle of the head and among other parameters. This paper describes the implementation of a mask recognition software using transfer learning, a convolutional neural network and a variational autoencoder.","","978-1-7281-9544-5","10.1109/SACI51354.2021.9465587","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9465587","Machine Learning;Feedforward neural networks;Variational Autoencoder;Image Recognition;Deep learning","COVID-19;Deep learning;Image recognition;Pandemics;Face recognition;Transfer learning;Government","convolutional neural nets;diseases;epidemics;feature extraction;health care;hygiene;image classification;learning (artificial intelligence);microorganisms;object detection;object recognition","automatic mask detecion;variational autoencoder;COVID-19 pandemic;image recognition task;convolutional neural networks;image datasets;mask recognition software;InceptionV3 neural network architecture;transfer learning;hygienical behaviour","","","","25","","30 Jun 2021","","","IEEE","IEEE Conferences"
"Hyperspectral Anomaly Detection Based on Graph Regularized Variational Autoencoder","J. Wei; J. Zhang; Y. Xu; L. Xu; Z. Wu; Z. Wei","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Jiangsu Key Laboratory of Spectral Imaging and Intelligent Sense, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Jiangsu High Technology Research Key Laboratory for Wireless Sensor Networks, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Geoscience and Remote Sensing Letters","25 Aug 2022","2022","19","","1","5","Nowadays, deep learning can play an important role in addressing the issue of hyperspectral anomaly detection (HAD). To further use the spatial information in hyperspectral images (HSIs), an anomaly detection (AD) method for HSIs is presented based on graph regularized variational autoencoder (GRVAE). First, the proposed method uses the superpixel segmentation algorithm to segment the HSI and constructs an adjacency matrix to evaluate the similarity between pixels. Second, a variational autoencoder is used to reconstruct the spectral vector of the HSI, and meanwhile, the spatial similarity of the image is shared in the feature space through the graph regularization term. Finally, the reconstructed background and the original input are used to obtain the spectral error map, and then attribute filtering is used to further refine the detection results. Performed on four datasets of abnormal target data with different shapes and different background complexity, the experiments show that the method has promising AD performance.","1558-0571","","10.1109/LGRS.2022.3198403","National Natural Science Foundation of China(grant numbers:62071233,61971223,61976117); Jiangsu Provincial Natural Science Foundation of China(grant numbers:BK20211570,BK20180018,BK20191409); Fundamental Research Funds for the Central Universities(grant numbers:30917015104,30919011103,30919011402,30921011209); Key Projects of University Natural Science Fund of Jiangsu Province(grant numbers:19KJA360001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9855514","Graph regularization;hyperspectral anomaly detection (HAD);variational autoencoder (VAE)","Image reconstruction;Hyperspectral imaging;Anomaly detection;Numerical analysis;Mathematical models;Image segmentation;Gaussian distribution","data handling;deep learning (artificial intelligence);feature extraction;geophysical image processing;graph theory;hyperspectral imaging;image reconstruction;image segmentation;matrix algebra","feature space;spectral vector reconstruction;adjacency matrix;GRVAE;spatial similarity;superpixel segmentation algorithm;HSI;hyperspectral images;spatial information;deep learning;graph regularized variational autoencoder;hyperspectral anomaly detection","","","","23","IEEE","11 Aug 2022","","","IEEE","IEEE Journals"
"Machinery New Emerge Fault Diagnosis Based on Deep Convolution Variational Autoencoder and Adaptive Label Propagation","B. She; X. Wang","Department of Weaponry Engineering, Naval University of Engineering, Wuhan, China; Department of Weaponry Engineering, Naval University of Engineering, Wuhan, China","IEEE Access","24 Feb 2022","2022","10","","19365","19378","In the research field of mechanical equipment fault diagnosis, usually only the existing fault types are identified, and the new emerge class of the fault is ignored, however, the new emerge fault class may also occur actually. In order to solve the problem, a novel fault diagnosis model based on deep convolution variational autoencoder network and adaptive label propagation (DCVAN-ALP) is proposed. Firstly, the initial high dimensional features are constructed by using the double tree complex wavelet packet method as the input of the model. Secondly, the convolutional neural network architecture is applied to construct the variational autoencoder, and the local and non-local characteristics of samples are embedded into the loss function for training, which is considered to improve the identification of hidden layer features of the neural network. Finally, t-SNE and the improved label propagation algorithm are adopted to process the hidden features of the neural network, which can achieve the purpose of diagnosing the existing fault class and especially new emerge fault class. Experimental results show that the proposed model can effectively extract the fault characteristics of the vibration signal, and it also has a significantly higher recognition accuracy rate than other typical deep learning methods and traditional classifiers in diagnosing new emerge fault class.","2169-3536","","10.1109/ACCESS.2022.3151799","Natural Science Foundation of Hubei Province(grant numbers:2019CFB362); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9714422","Convolution;variational autoencoder;label propagation;new emerge class;fault diagnosis","Feature extraction;Convolution;Vibrations;Labeling;Mathematical models;Manifolds;Fault diagnosis","convolutional neural nets;deep learning (artificial intelligence);fault diagnosis;feature extraction;machinery","machinery new emerge fault diagnosis;adaptive label propagation;mechanical equipment fault diagnosis;existing fault types;emerge fault class;fault diagnosis model;deep convolution variational autoencoder network;traditional classifiers;typical deep learning methods;vibration signal;neural network;hidden layer features;double tree complex wavelet packet method;fault characteristics;fault class;improved label propagation algorithm;convolutional neural network architecture;initial high dimensional features","","","","35","CCBY","15 Feb 2022","","","IEEE","IEEE Journals"
"Robust Unsupervised Anomaly Detection With Variational Autoencoder in Multivariate Time Series Data","U. Yokkampon; A. Mowshowitz; S. Chumkamon; E. Hayashi","Graduate School of Computer Science and Systems Engineering, Kyushu Institute of Technology, Fukuoka, Japan; Department of Computer Science, The City College of New York, New York, NY, USA; Graduate School of Computer Science and Systems Engineering, Kyushu Institute of Technology, Fukuoka, Japan; Graduate School of Computer Science and Systems Engineering, Kyushu Institute of Technology, Fukuoka, Japan","IEEE Access","7 Jun 2022","2022","10","","57835","57849","Accurate detection of anomalies in multivariate time series data has attracted much attention due to its importance in a wide range of applications. Since it is difficult to obtain accurately labeled data, many unsupervised anomaly detection algorithms for multivariate time series data have been developed. However, building such a system is challenging since it requires capturing temporal dependencies in each time series and must also encode the inter-correlations between different pairs of time series. To meet this challenge, we propose a Multi Scale Convolutional Variational Autoencoder (MSCVAE) to detect anomalies in multivariate time series data. Firstly, multi scale attribute matrices are constructed from multivariate time series to characterize multiple levels of the system states at different time steps. Then, given the attribute matrices, a convolutional variational autoencoder is employed to generate reconstructed attribute matrices, and also an attention-based ConvLSTM network is used to capture the temporal patterns. In addition, a new ERR-based threshold setting strategy is developed to optimize anomaly detection performance instead of relying on the traditional ROC-based threshold setting strategy with an imbalanced dataset. Finally, the proposed framework is assessed by means of experiments on four datasets. The experimental results show that our proposed framework is superior to competing algorithms in terms of model performance and robustness, demonstrating that our model is effective in detecting anomalies in multivariate time series.","2169-3536","","10.1109/ACCESS.2022.3178592","Japanese Government for the Establishment of Regional Universities and Industries; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9783083","Anomaly detection;multivariate time series;convolutional variational autoencoder;threshold setting strategy","Time series analysis;Anomaly detection;Data models;Stochastic processes;Robustness;Principal component analysis;Generative adversarial networks","convolutional neural nets;feature extraction;image classification;matrix algebra;time series;unsupervised learning","multivariate time series data;unsupervised anomaly detection algorithms;multiscale convolutional variational autoencoder;attention-based ConvLSTM network;temporal patterns;attribute matrices;ROC-based threshold setting strategy;ERR-based threshold setting strategy","","","","58","CCBY","27 May 2022","","","IEEE","IEEE Journals"
"Novel Multimode Process Soft Sensing Methods Based on the Dynamic Mixture Variational Autoencoder Regression Model","L. Cui; L. Yao; Z. Ge; Z. Song","State Key Laboratory of Industrial Control Technology, Institute of Industrial Process Control, College of Control Science and Engineering, Zhejiang University, Hangzhou, P. R. China; State Key Laboratory of Industrial Control Technology, Institute of Industrial Process Control, College of Control Science and Engineering, Zhejiang University, Hangzhou, P. R. China; State Key Laboratory of Industrial Control Technology, Institute of Industrial Process Control, College of Control Science and Engineering, Zhejiang University, Hangzhou, P. R. China; State Key Laboratory of Industrial Control Technology, Institute of Industrial Process Control, College of Control Science and Engineering, Zhejiang University, Hangzhou, P. R. China","2022 IEEE 11th Data Driven Control and Learning Systems Conference (DDCLS)","26 Aug 2022","2022","","","543","548","Modern industrial processes with increasing complexity not only contain nonlinear and multi-mode characteristics, but also are commonly the dynamic processes, which brought challenging problems to soft sensor modeling. In order to solve these problems, a dynamic mixture variational autoencoder regression (DMVAER) model is proposed for the nonlinear multi-mode modeling, which is suitable for industrial process quality prediction with multiple complex process characteristics. Furthermore, in order to deal with the problem of semi-supervised data with a large number of unlabeled samples, a semi-supervised dynamic mixture variational autoencoder regression (ssDMVAER) model is proposed, and the corresponding semi-supervised data sequence division method is adopted to make full use of the information in both labeled data and unlabeled data. Finally, in order to verify the feasibility and effectiveness of the proposed methods, the two models are applied to an actual industrial process of methanation furnace. The results show that the proposed methods have superior soft sensing performance than existing methods.","2767-9861","978-1-6654-9675-9","10.1109/DDCLS55054.2022.9858375","National Natural Science Foundation of China(grant numbers:62003300,62103362,92167106); China Postdoctoral Science Foundation(grant numbers:2021T140597,2019M662050); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9858375","Dynamic model;Mixture Variational Autoencoder;soft sensor;multimode process modeling;deep learning","Learning systems;Soft sensors;Furnaces;Process control;Predictive models;Control systems;Data models","furnaces;production engineering computing;quality control;regression analysis","superior soft sensing performance;novel multimode process soft sensing methods;modern industrial processes;dynamic processes;soft sensor modeling;nonlinear multimode modeling;industrial process quality prediction;multiple complex process characteristics;semisupervised dynamic mixture variational autoencoder regression model;corresponding semisupervised data sequence division method;ssDMVAER model;methanation furnace","","","","18","IEEE","26 Aug 2022","","","IEEE","IEEE Conferences"
"Using Variational Autoencoder to augment Sparse Time series Datasets","M. Goubeaud; P. Joußen; N. Gmyrek; F. Ghorban; L. Schelkes; A. Kummert","School of Electrical, Information and Media Engineering, University of Wuppertal, Wuppertal, Germany; School of Electrical, Information and Media Engineering, University of Wuppertal, Wuppertal, Germany; School of Electrical, Information and Media Engineering, University of Wuppertal, Wuppertal, Germany; School of Electrical, Information and Media Engineering, University of Wuppertal, Wuppertal, Germany; School of Electrical, Information and Media Engineering, University of Wuppertal, Wuppertal, Germany; School of Electrical, Information and Media Engineering, University of Wuppertal, Wuppertal, Germany","2021 7th International Conference on Optimization and Applications (ICOA)","31 May 2021","2021","","","1","6","In machine learning, data augmentation is called the process of generating synthetic samples in order to augment sparse training datasets. Reducing the error-rate of classifiers is the main motivation. In this paper, we generate synthetic training samples of time series data using a simple implementation of the Variational Autoencoder, to test whether classification performance increases when augmenting the original training sets with manifolds of generated samples. We demonstrate the effectiveness of data augmentation using the Variational Autoencoder as a generative model, by conducting experiments with different standard classifiers evaluated on nine datasets from the UCR Time Series Classification Archive. We show that our method is beneficial in most cases, as we observed an increase of accuracy and F1-Score on all datasets.","","978-1-6654-4103-2","10.1109/ICOA51614.2021.9442619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442619","data augmentation;time series;variational autoencoder","Training;Support vector machines;Measurement;Manifolds;Time series analysis;Training data;Benchmark testing","learning (artificial intelligence);neural nets;pattern classification;time series","generative model;machine learning;data augmentation;classification performance;variational autoencoder;sparse time series datasets;UCR time series classification","","","","13","IEEE","31 May 2021","","","IEEE","IEEE Conferences"
"Linear Variational Autoencoder for Top-N Recommendation","Z. Pan; W. Liu; Z. Meng; J. Yin","Guangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou, P.R.China; Guangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou, P.R.China; School of Computing Science, University of Glasgow, Glasgow, Scotland; Guangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou, P.R.China","2022 7th International Conference on Big Data Analytics (ICBDA)","21 Apr 2022","2022","","","296","303","Top-N recommendation is significant in various service-based platforms. Variational Autoencoders (VAEs) have been used in top-N recommendation in recent years for its effectiveness in collaborative filtering. Mult-VAE is such a variant that achieves great success, by adopting the multinomial likelihood, and an additional hyperparameter β on the KL divergence term of ELBO of VAE. However, Mult-VAE uses non-linear neural networks as encoder and decoder, to encode and reconstruct the user-item interaction data, which we prove unnecessary in sparse datasets because it will degrade the prediction accuracy in our experiments. Moreover, most variants of VAE-based collaborative filtering methods use the unnormalized user-item interaction data to make recommendations, which will hinder the learning process of the interaction data. In this paper, we propose Linear Variational Autoencoder (LVA), a linear version of Mult-VAE, considering additional normalization on user-item interaction data, for collaborative filtering under the implicit feedback setting. We verify its effectiveness in the experiments and prove that LVA achieves better or competitive performance over current state-of-the-art collaborative filtering methods, e.g, LightGCN, on four public real-world datasets.","","978-1-6654-7938-7","10.1109/ICBDA55095.2022.9760352","National Natural Science Foundation of China; National Science Foundation; Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9760352","Recommendation;Variational Autoencoders;Log-Linear Model","Analytical models;Collaborative filtering;Neural networks;Big Data;Data models;Decoding;Sparse matrices","Bayes methods;collaborative filtering;learning (artificial intelligence);neural nets;recommender systems","top-N recommendation;service-based platforms;Mult-VAE;additional hyperparameter;nonlinear neural networks;encoder;decoder;VAE-based collaborative filtering methods;unnormalized user-item interaction data;linear version;linear variational autoencoder","","","","23","IEEE","21 Apr 2022","","","IEEE","IEEE Conferences"
"Adversarial Variational Autoencoder for Top-N Recommender Systems","G. Zhang; Y. Liu; X. Jin","Beijing Advanced Innovation Center for Future Internet Technology, Beijing University of Technology, Beijing, China; Beijing Advanced Innovation Center for Future Internet Technology, Beijing University of Technology, Beijing, China; Beijing Advanced Innovation Center for Future Internet Technology, Beijing University of Technology, Beijing, China","2018 IEEE 9th International Conference on Software Engineering and Service Science (ICSESS)","10 Mar 2019","2018","","","853","856","Recommender systems play an important role in the age of mass information. They allow users to discover items that match their tastes. In this paper, we propose a novel method, called adversarial variational autoencoder, for top-N recommendation. We use generative adversarial networks to regularize variational autoencoder by imposing an arbitrary prior on the latent representation of VAE, which makes the recommendation model. We define a joint objective function as a minimization problem. Our experiments on three datasets show that the proposed model achieves high recommendation accuracy compared to other state-of-the-art models.","2327-0594","978-1-5386-6565-7","10.1109/ICSESS.2018.8663730","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8663730","variational autoencoder;generative adversarial networks;recommender system;collaborative filtering","Recommender systems;Gallium nitride;Data models;Collaboration;Computational modeling;Matrix decomposition","neural nets;recommender systems","adversarial variational autoencoder;recommendation accuracy;joint objective function;recommendation model;generative adversarial networks;top-N recommendation;mass information;top-N recommender systems","","","","15","","10 Mar 2019","","","IEEE","IEEE Conferences"
"Partial Multiple Imputation With Variational Autoencoders: Tackling Not at Randomness in Healthcare Data","R. C. Pereira; P. H. Abreu; P. P. Rodrigues","Department of Informatics Engineering, University of Coimbra, Centre for Informatics and Systems of the University of Coimbra, Coimbra, Portugal; Department of Informatics Engineering, University of Coimbra, Centre for Informatics and Systems of the University of Coimbra, Coimbra, Portugal; Center for Health Technology and Services Research, Faculty of Medicine (MEDCIDS), University of Porto, Porto, Portugal","IEEE Journal of Biomedical and Health Informatics","11 Aug 2022","2022","26","8","4218","4227","Missing data can pose severe consequences in critical contexts, such as clinical research based on routinely collected healthcare data. This issue is usually handled with imputation strategies, but these tend to produce poor and biased results under the Missing Not At Random (MNAR) mechanism. A recent trend that has been showing promising results for MNAR is the use of generative models, particularly Variational Autoencoders. However, they have a limitation: the imputed values are the result of a single sample, which can be biased. To tackle it, an extension to the Variational Autoencoder that uses a partial multiple imputation procedure is introduced in this work. The proposed method was compared to 8 state-of-the-art imputation strategies, in an experimental setup with 34 datasets from the medical context, injected with the MNAR mechanism (10% to 80% rates). The results were evaluated through the Mean Absolute Error, with the new method being the overall best in 71% of the datasets, significantly outperforming the remaining ones, particularly for high missing rates. Finally, a case study of a classification task with heart failure data was also conducted, where this method induced improvements in 50% of the classifiers.","2168-2208","","10.1109/JBHI.2022.3172656","Foundation for Science and Technology(grant numbers:SFRH/BD/149 018/2019,UID/ CEC/00326/2020); European Social Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9769986","Healthcare data;missing data;missing not at random;partial multiple imputation;variational autoencoder","Medical services;Task analysis;Data models;Principal component analysis;Neural networks;Mathematical models;Mice","cardiology;data analysis;data mining;health care;neural nets;pattern classification","Variational Autoencoder;imputed values;partial multiple imputation procedure;imputation strategies;medical context;MNAR mechanism;high missing rates;critical contexts;clinical research;healthcare data;generative models;Missing Not At Random mechanism","Data Interpretation, Statistical;Delivery of Health Care;Humans;Research Design","","","40","IEEE","5 May 2022","","","IEEE","IEEE Journals"
"A Robust Speaker Clustering Method Based on Discrete Tied Variational Autoencoder","C. Feng; J. Wang; T. Li; J. Peng; J. Xiao","Ping An Technology (Shenzhen) Co., Ltd; Ping An Technology (Shenzhen) Co., Ltd; Ping An Technology (Shenzhen) Co., Ltd; Ping An Technology (Shenzhen) Co., Ltd; Ping An Technology (Shenzhen) Co., Ltd","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","6024","6028","Recently, the speaker clustering model based on aggregation hierarchy cluster (AHC) is a common method to solve two main problems: no preset category number clustering and fix category number clustering. In general, model takes features like i-vectors as input of probability and linear discriminant analysis model (PLDA) aims to form the distance matric in long voice application scenario, and then clustering results are obtained through the clustering model. However, traditional speaker clustering method based on AHC has the shortcomings of long-time running and remains sensitive to environment noise. In this paper, we propose a novel speaker clustering method based on Mutual Information (MI) and a non-linear model with discrete variable, which under the enlightenment of Tied Variational Autoencoder (TVAE), to enhance the robustness against noise. The proposed method named Discrete Tied Variational Autoencoder (DTVAE) which shortens the elapsed time substantially. With experience results, it outperforms the general model and yields a relative Accuracy (ACC) improvement and significant time reduction.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9053488","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9053488","speaker clustering;tied variational autoencoder;mutual information;aggregation hierarchy cluster","Analytical models;Clustering methods;Task analysis;Speech processing;Mutual information;Digital TV;Strain","linear discriminant analysis;neural nets;pattern clustering;probability;speaker recognition","robust speaker clustering method;aggregation hierarchy cluster;AHC;linear discriminant analysis model;long voice application scenario;nonlinear model;discrete tied variational autoencoder;DTVAE;mutual information;MI;probability;distance matric","","","","23","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Pulsar Identification Based on Variational Autoencoder and Residual Network","G. Liu; Y. Li; Z. Bao; Q. Yin; P. Guo","School of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Systems Science, Beijing Normal University, Beijing, China","2021 11th International Conference on Intelligent Control and Information Processing (ICICIP)","16 Dec 2021","2021","","","188","194","In modern astronomy, pulsar identification is a vital task to help researchers discovering new pulsars. With the great progress of modern radio telescopes improves, the amount of pulsar data collected increases exponentially, which causes the traditional pulsar identification approaches to be not enough to tackle such a large dataset. At present, many pulsar identification methods achieve promising performance based on deep neural networks. However, those neural-network-based methods still face the sample imbalance problem, which limits their performance. To be specific, the pulsar sample imbalance problem is that only an extremely limited number of real pulsar samples exist in dataset. To alleviate the problem and enhance the pulsar identification performance, we present a novel method under the framework of synergetic learning systems which includes the variational autoencoder and residual network. In this work, the variational autoencoder is used to generate some high-quality pulsar samples for training procedure to mitigate the pulsar sample imbalance problem, and then we present a residual-network-based model to promote pulsar candidate identification performance. Extensive experiments on two pulsar datasets demonstrate that our framework not only alleviates the imbalance problem, but also improves the accuracy of pulsar identification.","","978-1-6654-2515-5","10.1109/ICICIP53388.2021.9642198","National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9642198","pulsar;variational autoencoder;residual network;synergetic learning systems","Training;Learning systems;Radio astronomy;Image synthesis;Neural networks;Fitting;Information processing","learning (artificial intelligence);neural nets;pulsars;radiotelescopes","modern radio telescopes;pulsar data;traditional pulsar identification;pulsar identification methods;deep neural networks;neural-network-based methods;pulsar sample imbalance problem;pulsar identification performance;variational autoencoder;residual network;high-quality pulsar samples;residual-network-based model;pulsar candidate identification performance;pulsar datasets","","","","29","IEEE","16 Dec 2021","","","IEEE","IEEE Conferences"
"3DVAE-ERSG: 3D Variational Autoencoder for Extremely Rare Signal Generation","T. Chalongvorachai; K. Woraratpanya","Faculty of Information Technology, King Mongkut&#x0027;s Institute of Technology Ladkrabang, Bangkok, Thailand; Faculty of Information Technology, King Mongkut&#x0027;s Institute of Technology Ladkrabang, Bangkok, Thailand","2021 13th International Conference on Information Technology and Electrical Engineering (ICITEE)","25 Nov 2021","2021","","","177","182","Data generation is not data augmentation. Our data generation is a new technique that can synthesize a dataset from a very small number of samples and ensure the quality of its outputs. Recently, this concept has been proposed and applied in a framework called Data Generation Framework for Extremely Rare Case Signals (DGERS) to solve a problem of a limited number of anomaly signals. With the power of DGERS consisting of principal components, including various data augmentation techniques on diverse domains, Signal Fragment Assembler (SFA), Variational Autoencoder (VAE), Data Picker (DP), and Quality Classifier (QC), the generated dataset had the good quality, when evaluated with a performance tester. Nevertheless, the DGERS has not used the full potential of VAE yet. The previous framework used the VAE latent space in only two dimensions. To use a higher potential of VAE, this paper proposed a 3D Variational Autoencoder for Extremely Rare Signal Generation (3DVAE-ERSG). This method increases the dimension of the latent space from 2D to 3D. We also proposed the 3D Data Picker for data exploration. To test this hypothesis, we experimented with the same datasets that the DGERS method was tested before. The results show that our 3DVAE-ERSG can outperform the baseline in most cases.","","978-1-6654-4306-7","10.1109/ICITEE53064.2021.9611955","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9611955","Anomaly detection;Deep learning;Data Generation;Variational Autoencoder;Data Augmentation;Latent Space;Imbalanced Dataset","Electrical engineering;Three-dimensional displays;Robustness;Information technology","data handling;deep learning (artificial intelligence);neural nets;signal processing","3DVAE-ERSG;Variational Autoencoder;DGERS;data augmentation techniques;quality classifier;VAE latent space;data exploration;data picker;signal fragment assembler;extremely rare signal generation;data generation framework for extremely rare case signals;latent space","","","","23","IEEE","25 Nov 2021","","","IEEE","IEEE Conferences"
"Modeling I/O Performance Variability Using Conditional Variational Autoencoders","S. Madireddy; P. Balaprakash; P. Carns; R. Latham; R. Ross; S. Snyder; S. Wild","Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL; Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL; Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL; Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL; Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL; Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL; Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL","2018 IEEE International Conference on Cluster Computing (CLUSTER)","1 Nov 2018","2018","","","109","113","Storage system performance modeling is crucial for efficient use of heterogeneous shared resources on leadership-class computers. Variability in application performance, particularly variability arising from concurrent applications sharing I/O resources, is a major hurdle in the development of accurate performance models. We adopt a deep learning approach based on conditional variational auto encoders (CVAE) for I/O performance modeling, and use it to quantify performance variability. We illustrate our approach using the data collected on Edison, a production supercomputing system at the National Energy Research Scientific Computing Center (NERSC). The CVAE approach is investigated by comparing it to a previously proposed sensitivity-based Gaussian process (GP) model. We find that the CVAE model performs slightly better than the GP model in cases where training and testing data come from different applications, since CVAE can inherently leverage the whole data from multiple applications whereas GP partitions the data and builds separate models for each partition. Hence, the CVAE offers an alternative modeling approach that does not need pre-processing; it has enough flexibility to handle data from a wide variety of applications without changing the inference approach.","2168-9253","978-1-5386-8319-4","10.1109/CLUSTER.2018.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8514864","I/O performance variability, parallel filesystems, probabilistic machine learning, variational autoencoders","Predictive models;Data models;Measurement;Computational modeling;Training;Decoding;Testing","data handling;Gaussian processes;input-output programs;learning (artificial intelligence);multiprocessing systems;parallel machines;performance evaluation","national energy research scientific computing center;I-O performance modeling;NERSC;heterogeneous shared resources;storage system performance modeling;conditional variational autoencoders;alternative modeling approach;multiple applications;testing data;GP model;CVAE model;sensitivity-based Gaussian process model;CVAE approach;production supercomputing system;performance variability;conditional variational auto encoders;deep learning approach;accurate performance models;concurrent applications;leadership-class computers","","6","","22","","1 Nov 2018","","","IEEE","IEEE Conferences"
"Modality Conversion of Handwritten Patterns by Cross Variational Autoencoders","T. Sumi; B. K. Iwana; H. Hayashi; S. Uchida","Advanced Information Technology, Kyushu University, Japan; Advanced Information Technology, Kyushu University, Japan; Advanced Information Technology, Kyushu University, Japan; Advanced Information Technology, Kyushu University, Japan","2019 International Conference on Document Analysis and Recognition (ICDAR)","3 Feb 2020","2019","","","407","412","This research attempts to construct a network that can convert online and offline handwritten characters to each other. The proposed network consists of two Variational Auto-Encoders (VAEs) with a shared latent space. The VAEs are trained to generate online and offline handwritten Latin characters simultaneously. In this way, we create a cross-modal VAE (Cross-VAE). During training, the proposed Cross-VAE is trained to minimize the reconstruction loss of the two modalities, the distribution loss of the two VAEs, and a novel third loss called the space sharing loss. This third, space sharing loss is used to encourage the modalities to share the same latent space by calculating the distance between the latent variables. Through the proposed method mutual conversion of online and offline handwritten characters is possible. In this paper, we demonstrate the performance of the Cross-VAE through qualitative and quantitative analysis.","2379-2140","978-1-7281-3014-9","10.1109/ICDAR.2019.00072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8978197","variational autoencoder;handwritten character recognition;modality conversion","Decoding;Trajectory;Time series analysis;Image reconstruction;Character recognition;Gallium nitride;Training","handwritten character recognition;neural nets","modality conversion;handwritten patterns;Cross Variational autoencoders;offline handwritten characters;Variational Auto-Encoders;VAEs;shared latent space;offline handwritten Latin characters;cross-modal VAE;reconstruction loss;distribution loss;space sharing loss","","4","","28","","3 Feb 2020","","","IEEE","IEEE Conferences"
"Speech Prediction in Silent Videos Using Variational Autoencoders","R. Yadav; A. Sardana; V. P. Namboodiri; R. M. Hegde","Indian Institute of Technology Kanpur, India; NVIDIA; University of Bath, UK; Indian Institute of Technology Kanpur, India","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","7048","7052","Understanding the relationship between the auditory and visual signals is crucial for many different applications ranging from computer-generated imagery (CGI) and video editing automation to assisting people with hearing or visual impairments. However, this is challenging since the distribution of both audio and visual modality is inherently multi-modal. Therefore, most of the existing methods ignore the multimodal aspect and assume that there only exists a deterministic one-to-one mapping between the two modalities. It can lead to low-quality predictions as the model collapses to optimizing the average behavior rather than learning the full data distributions. In this paper, we present a stochastic model for generating speech in a silent video. The proposed model combines recurrent neural networks and variational deep generative models to learn the auditory signal’s conditional distribution given the visual signal. We demonstrate the performance of our model on the GRID dataset based on standard benchmarks.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414040","Bayesian models;cross-modal generation;speech prediction;variational autoencoders","Visualization;Recurrent neural networks;Conferences;Stochastic processes;Predictive models;Signal processing;Distance measurement","feature extraction;handicapped aids;learning (artificial intelligence);neural nets;recurrent neural nets;speech processing;stochastic processes","speech prediction;silent video;variational autoencoders;visual signal;CGI;video editing automation;hearing;visual impairments;audio modality;visual modality;multimodal aspect;low-quality predictions;average behavior;data distributions;stochastic model;variational deep generative models;auditory signal","","2","","19","","13 May 2021","","","IEEE","IEEE Conferences"
"A Comparative Study on Variational Autoencoders and Generative Adversarial Networks","M. Sami; I. Mobin","Computer Science & Engineering, BRAC University, Dhaka, Bangladesh; Computer Science & Engineering, BRAC University, Dhaka, Bangladesh","2019 International Conference of Artificial Intelligence and Information Technology (ICAIIT)","12 Sep 2019","2019","","","1","5","Generative Adversarial Networks (GAN) have been remarkable at generating artificial data, especially realistic looking images. This learning framework has proven itself to be effective in synthetic image generation, semantic image hole filling, semantic image editing, style transfer and many more. On the other hand, variational auto-encoders (VAE) have also been quite effective, so much so that mathematically it is often more accurate at generating images resembling to its original dataset. Nevertheless, images generated by VAE suffer from blurriness and are generally less realistic looking from human perception. In this paper we take a broad view on both systems and propose a theoretical approach to combine them and bring out the best of both.","","978-1-5386-8448-1","10.1109/ICAIIT.2019.8834544","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8834544","GAN;Autoencoders;Variational Inference","Generators;Data models;Training;Generative adversarial networks;Computational modeling;Decoding;Gallium nitride","image classification;image segmentation;learning (artificial intelligence);neural nets","variational autoencoders;artificial data;realistic looking images;synthetic image generation;semantic image hole;semantic image editing;variational auto-encoders;generative adversarial networks","","2","","23","IEEE","12 Sep 2019","","","IEEE","IEEE Conferences"
"Laser Variational Autoencoder for Map Construction and Self-Localization","S. Wakita; T. Nakamura; H. Hachiya","Faculty of Systems Engineering, Wakayama University, Wakayama, Japan; Faculty of Systems Engineering, Wakayama University, Wakayama, Japan; Faculty of Systems Engineering, Wakayama University, Wakayama, Japan","2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","17 Jan 2019","2018","","","3993","3998","For accurate global self-localization with small memory usage, researches for the compression of the laser-scan data have been actively conducted. Main approaches to the compression are to design feature extractor based on human knowledge regarding the specific environment, e.g., office and hallway. However, in real robot navigation tasks such as a security patrol robot, the robot would be applied to a variety of environments and it is expensive if the users need to tune the design at every environment. To alleviate such problem, we propose to extend the state-of-the-art variational auto-encoder (VAE) by introducing the step-edge detector, which detects non-continuous transition emerged frequently at the laser scan data due to the limitation of distance measurement. With our proposed method, called ""laserVAE"", the feature extractor of the laser scan is automatically tuned given unknown environments. Through experiments with a real self-localization with 2D laser scan, we demonstrate the effectiveness of the proposed method.","2577-1655","978-1-5386-6650-0","10.1109/SMC.2018.00677","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8616674","Feature description of scan data;Variational autoencoder;Scan matching;Global self-localization","Decoding;Feature extraction;Two dimensional displays;Mobile robots;Laser tuning;Measurement by laser beam","distance measurement;feature extraction;mobile robots;navigation","laser variational autoencoder;map construction;memory usage;laser-scan data;robot navigation tasks;security patrol robot;step-edge detector;noncontinuous transition;laser scan data;feature extractor;variational auto-encoder;global self-localization","","1","","12","","17 Jan 2019","","","IEEE","IEEE Conferences"
"Sensitivity analysis of latent variables in Variational Autoencoders for Dermoscopic Image Analysis","P. Casti; A. Mencattini; S. Cardarelli; G. Antonelli; J. Filippi; M. D'Orazio; E. Martinelli","Dept. of Electronic Engineering, Univ. of Rome Tor Vergata, Rome, Italy; Dept. of Electronic Engineering, Univ. of Rome Tor Vergata, Rome, Italy; Dept. of Electronic Engineering, Univ. of Rome Tor Vergata, Rome, Italy; Dept. of Electronic Engineering, Univ. of Rome Tor Vergata, Rome, Italy; Dept. of Electronic Engineering, Univ. of Rome Tor Vergata, Rome, Italy; Dept. of Electronic Engineering, Univ. of Rome Tor Vergata, Rome, Italy; Dept. of Electronic Engineering, Univ. of Rome Tor Vergata, Rome, Italy","2022 IEEE International Symposium on Medical Measurements and Applications (MeMeA)","22 Aug 2022","2022","","","1","6","The advances in the deep learning field have paved the way to novel strategies to represent digital image data in the form of synthetic descriptors. Variational Auto-Encoders (VAE) architectures are generative powerful tools not only to reconstruct input images but also to extract meaningful information for the task of pattern classification. The first part of the VAE network, called encoder, aims to condense the image information into a reduced set of low-level descriptors, called latent variables. The second part, called decoder, aims to use the latent variable in a reverse process that reconstructs the original image in output. In this work, we exploited the VAE-based latent representation of colour normalized dermoscopic images for the discrimination of malignant and benign skin lesions. In particular, we investigated the sensitivity to the effect of skin colour variations over the final reconstruction error and on the discrimination capability of the VAE latent variables in terms of individual Area Under the roC curve (AUC). By exploiting and adapting state-of-the art skin colour variation models we obtained a performance worsening of about 10% either in the reconstruction error and in the discrimination capability of the latent variables. The achieved preliminary results demonstrate that, with suitable VAE adaptation, latent descriptors could be used in automatic skin lesions classification frameworks.","","978-1-6654-8299-8","10.1109/MeMeA54994.2022.9856459","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9856459","sensitivity analysis;dermoscopy;skin lesions;variational autoencoders;skin colour model","Analytical models;Adaptation models;Image color analysis;Sensitivity analysis;Stochastic processes;Skin;Lesions","biomedical optical imaging;cancer;feature extraction;image classification;image colour analysis;image reconstruction;image representation;image segmentation;learning (artificial intelligence);medical image processing;pattern classification;sensitivity analysis;skin","latent descriptors;automatic skin lesions classification frameworks;sensitivity analysis;variational autoencoders;dermoscopic image;deep learning field;digital image data;synthetic descriptors;Variational Auto-Encoders architectures;generative powerful tools;input images;pattern classification;VAE network;called encoder;image information;low-level descriptors;called latent variables;called decoder;VAE-based latent representation;colour normalized dermoscopic images;malignant skin lesions;benign skin lesions;skin colour variations;final reconstruction error;discrimination capability;VAE latent variables;state-of-the art skin colour variation models;suitable VAE adaptation","","","","37","IEEE","22 Aug 2022","","","IEEE","IEEE Conferences"
"Semi-supervised Variational Autoencoder for WiFi Indoor Localization","B. Chidlovskii; L. Antsfeld","Naver Labs Europe, Meylan, France; Naver Labs Europe, Meylan, France","2019 International Conference on Indoor Positioning and Indoor Navigation (IPIN)","28 Nov 2019","2019","","","1","8","We address the problem of indoor localization based on WiFi signal strengths. We develop a semi-supervised deep learning method able to train a prediction model from a small set of annotated WiFi observations and a massive set of non-annotated ones. Our method is based on the variational autoencoder deep network. We complement the network with an additional component of structural projection able to further improve the localization accuracy in a complex, multi-building and multi-floor environment. We consider several different network compositions which combine the classification and regression sub-tasks to achieve optimal performance. We evaluate our method on the public UJI-IndoorLoc dataset and show that the proposed method allows to maintain the state of the art localization accuracy with a very limited amount of annotated data.","2471-917X","978-1-7281-1788-1","10.1109/IPIN.2019.8911825","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911825","WiFi based indoor localization;semi-supervised learning;variational auto-encoder;UJI-IndoorLoc dataset","Wireless fidelity;Buildings;Task analysis;Deep learning;Semisupervised learning;Data collection;Predictive models","indoor radio;learning (artificial intelligence);telecommunication computing;wireless LAN","semisupervised variational autoencoder;WiFi indoor localization;WiFi signal strengths;semisupervised deep learning method;prediction model;annotated WiFi observations;variational autoencoder deep network;structural projection;multifloor environment;network compositions;regression sub-tasks;annotated data;nonannotated set;optimal performance","","15","1","22","","28 Nov 2019","","","IEEE","IEEE Conferences"
"Underdetermined Source Separation Based on Generalized Multichannel Variational Autoencoder","S. Seki; H. Kameoka; L. Li; T. Toda; K. Takeda","Graduate School of Informatics, Nagoya University, Nagoya, Japan; Nippon Telegraph and Telephone Corporation, Atsugi, Japan; Graduate School of Systems and Information Engineering, University of Tsukuba, Tsukuba, Japan; Information Technology Center, Nagoya University, Nagoya, Japan; Institutes of Innovation for Future Society, Nagoya University, Nagoya, Japan","IEEE Access","27 Nov 2019","2019","7","","168104","168115","This paper deals with a multichannel audio source separation problem under underdetermined conditions. Multichannel non-negative matrix factorization (MNMF) is a powerful method for underdetermined audio source separation, which adopts the NMF concept to model and estimate the power spectrograms of the sound sources in a mixture signal. This concept is also used in independent low-rank matrix analysis (ILRMA), a special class of the MNMF formulated under determined conditions. While these methods work reasonably well for particular types of sound sources, one limitation is that they can fail to work for sources with spectrograms that do not comply with the NMF model. To address this limitation, an extension of ILRMA called the multichannel variational autoencoder (MVAE) method was recently proposed, where a conditional VAE (CVAE) is used instead of the NMF model for expressing source power spectrograms. This approach has performed impressively in determined source separation tasks thanks to the representation power of deep neural networks. While the original MVAE method was formulated under determined mixing conditions, this paper proposes a generalized version of it by combining the ideas of MNMF and MVAE so that it can also deal with underdetermined cases. We call this method the generalized MVAE (GMVAE) method. In underdetermined source separation and speech enhancement experiments, the proposed method performed better than baseline methods.","2169-3536","","10.1109/ACCESS.2019.2954120","Japan Society for the Promotion of Science(grant numbers:JP17H01763); JST CREST Japan(grant numbers:JPMJCR19A3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8906095","Underdetermined source separation;variational audoencoder;non-negative matrix factorization","Source separation;Spectrogram;Task analysis;Mathematical model;Covariance matrices;Neural networks;Speech enhancement","audio coding;matrix decomposition;neural nets;signal representation;source separation;speech coding;speech enhancement","GMVAE method;conditional VAE method;multichannel nonnegative matrix factorization;MNMF concept;baseline methods;generalized MVAE method;determined mixing conditions;source power spectrograms;multichannel variational autoencoder method;ILRMA;independent low-rank matrix analysis;sound sources;NMF concept;underdetermined audio source separation;nonnegative matrix factorization;multichannel audio source separation problem;generalized multichannel variational autoencoder","","13","","32","CCBY","19 Nov 2019","","","IEEE","IEEE Journals"
"Matrix Completion with Variational Graph Autoencoders: Application in Hyperlocal Air Quality Inference","T. H. Do; D. Minh Nguyen; E. Tsiligianni; A. L. Aguirre; V. Panzica La Manna; F. Pasveer; W. Philips; N. Deligiannis","imec, Leuven, Belgium; imec, Leuven, Belgium; imec, Leuven, Belgium; IPI Ghent University, Ghent, Belgium; Holst Center, imec, AE Eindhoven, The Netherlands; Holst Center, imec, AE Eindhoven, The Netherlands; IPI Ghent University, Ghent, Belgium; imec, Leuven, Belgium","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","7535","7539","Inferring air quality from a limited number of observations is an essential task for monitoring and controlling air pollution. Existing inference methods typically use low spatial resolution data collected by fixed monitoring stations and infer the concentration of air pollutants using additional types of data, e.g., meteorological and traffic information. In this work, we focus on street-level air quality inference by utilizing data collected by mobile stations. We formulate air quality inference in this setting as a graph-based matrix completion problem and propose a novel variational model based on graph convolutional autoencoders. Our model captures effectively the spatio-temporal correlation of the measurements and does not depend on the availability of additional information apart from the street-network topology. Experiments on a real air quality dataset, collected with mobile stations, shows that the proposed model outperforms state-of-the-art approaches.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683787","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683787","air quality inference;variational graph autoen-coder;graph-based matrix completion;deep learning","Atmospheric modeling;Atmospheric measurements;Pollution measurement;Air pollution;Monitoring;Data models","air pollution control;air quality;control engineering computing;convolution;data analysis;environmental science computing;graph theory;inference mechanisms;learning (artificial intelligence);neural nets","variational graph autoencoders;hyperlocal air quality inference;inference methods;air pollutants;street-level air quality inference;mobile stations;graph-based matrix completion problem;variational model;graph convolutional autoencoders;air quality dataset;air pollution monitoring;air pollution controlling;deep learning","","10","","32","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Generalized Multichannel Variational Autoencoder for Underdetermined Source Separation","S. Seki; H. Kameoka; L. Li; T. Toda; K. Takeda","Nagoya University, Nagoya, Japan; NTT Communication Science Laboratories, Atsugi, Japan; University of Tsukuba, Tsukuba, Japan; Nagoya University, Nagoya, Japan; Nagoya University, Nagoya, Japan","2019 27th European Signal Processing Conference (EUSIPCO)","18 Nov 2019","2019","","","1","5","This paper deals with a multichannel audio source separation problem under underdetermined conditions. Multi-channel Non-negative Matrix Factorization (MNMF) is one of the powerful approaches, which adopts the NMF concept for source power spectrogram modeling. It works reasonably well for particular types of sound sources, however, one limitation is that it can fail to work for sources with spectrograms that do not comply with the NMF model. To address this limitation, a novel technique called the Multichannel Variational Autoencoder (MVAE) method was recently proposed, where a Conditional VAE (CVAE) is used instead of the NMF model for source power spectrogram modeling. This approach has shown to perform impressively in determined source separation tasks thanks to the representation power of DNNs. This paper generalizes MVAE originally formulated under determined mixing conditions so that it can also deal with underdetermined cases. The proposed method was evaluated on an underdetermined source separation task of separating out three sources from two microphone inputs. Experimental results revealed that the generalized MVAE method achieved better performance than the conventional MNMF method.","2076-1465","978-9-0827-9703-9","10.23919/EUSIPCO.2019.8903054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903054","Underdetermined source separation;Variational audoencoder;Non-negative matrix factorization","Spectrogram;Source separation;Decoding;Task analysis;Microphones;Time-frequency analysis;Mathematical model","audio signal processing;blind source separation;matrix decomposition;microphones;neural nets;source separation","NMF model;Multichannel Variational Autoencoder method;source power spectrogram modeling;determined source separation tasks thanks;determined mixing conditions;underdetermined cases;underdetermined source separation task;generalized MVAE method;generalized Multichannel Variational Autoencoder;multichannel audio source separation problem;underdetermined conditions;Multichannel Nonnegative Matrix Factorization;powerful approaches;NMF concept;sound sources","","5","","22","","18 Nov 2019","","","IEEE","IEEE Conferences"
"Multiview Variational Graph Autoencoders for Canonical Correlation Analysis","Y. Kaloga; P. Borgnat; S. P. Chepuri; P. Abry; A. Habrard","Univ Lyon, Ens de Lyon, Laboratoire de Physique, Univ. Claude Bernard, CNRS, Lyon, France; Univ Lyon, Ens de Lyon, Laboratoire de Physique, Univ. Claude Bernard, CNRS, Lyon, France; Department of Electrical and Communication Engineering, Indian Institute of Science, Bangalore, India; Univ Lyon, Ens de Lyon, Laboratoire de Physique, Univ. Claude Bernard, CNRS, Lyon, France; UJM-Saint-Etienne, CNRS, Laboratoire Hubert Curien, University of Lyon, France","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","5320","5324","We present a novel multiview canonical correlation analysis model based on a variational approach. This is the first nonlinear model that takes into account the available graph-based geometric constraints while being scalable for processing large scale datasets with multiple views. It is based on an autoencoder architecture with graph convolutional neural network layers. We experiment with our approach on classification, clustering, and recommendation tasks on real datasets. The algorithm is competitive with state-of-the-art multiview representation learning techniques.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414466","EMI; BP; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414466","Canonical correlation analysis;dimensionality reduction;multiview;graph neurals networks;variational inference","Analytical models;Correlation;Signal processing algorithms;Signal processing;Predictive models;Probabilistic logic;Inference algorithms","convolutional neural nets;data handling;graph theory;learning (artificial intelligence)","available graph based geometric constraints;variational approach;multiview canonical correlation analysis model;variational graph autoencoders;state-of-the-art multiview representation learning techniques;graph convolutional neural network layers;autoencoder architecture;nonlinear model","","","","24","","13 May 2021","","","IEEE","IEEE Conferences"
"Information Bottlenecked Variational Autoencoder for Disentangled 3D Facial Expression Modelling","H. Sun; N. Pears; Y. Gu","Department of Computer Science, University of York, UK; Department of Computer Science, University of York, UK; Department of Computer Science, University of York, UK","2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)","15 Feb 2022","2022","","","2334","2343","Learning a disentangled representation is essential to build 3D face models that accurately capture identity and expression. We propose a novel variational autoencoder (VAE) framework to disentangle identity and expression from 3D input faces that have a wide variety of expressions. Specifically, we design a system that has two decoders: one for neutral-expression faces (i.e. identity-only faces) and one for the original (expressive) input faces respectively. Crucially, we have an additional mutual-information regulariser applied on the identity part to solve the issue of imbalanced information over the expressive input faces and the reconstructed neutral faces. Our evaluations on two public datasets (CoMA and BU-3DFE) show that this model achieves competitive results on the 3D face reconstruction task and state-of-the-art results on identity-expression disentanglement. We also show that by updating to a conditional VAE, we have a system that generates different levels of expressions from semantically meaningful variables.","2642-9381","978-1-6654-0915-5","10.1109/WACV51458.2022.00239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9706771","3D Computer Vision Biometrics -> Face Processing; Deep Learning -> Neural Generative Models; Autoencoders; GANs; Explainable AI; Fairness; Accountability; Privacy and Ethics in Vision","Training;Solid modeling;Computer vision;Three-dimensional displays;Genetic expression;Computer architecture;Decoding","face recognition;image reconstruction;learning (artificial intelligence)","information bottlenecked variational autoencoder;disentangled 3D facial expression modelling;disentangled representation;3D face models;accurately capture identity;novel variational autoencoder framework;disentangle identity;3D input faces;neutral-expression faces;identity-only faces;original input faces;additional mutual-information regulariser;identity part;imbalanced information;expressive input faces;reconstructed neutral faces;BU-3DFE;3D face reconstruction task;identity-expression disentanglement","","2","","41","IEEE","15 Feb 2022","","","IEEE","IEEE Conferences"
"Variational Autoencoder-Based Hybrid Recommendation With Poisson Factorization for Modeling Implicit Feedback","I. Tanuma; T. Matsui","Department of Statistical Science, School of Multidisciplinary Sciences, The Graduate University for Advanced Studies, Tokyo, Japan; Department of Statistical Modeling, The Institute of Statistical Mathematics, Tokyo, Japan","IEEE Access","13 Jun 2022","2022","10","","60696","60706","Hybrid recommendation, which is based on collaborative filtering and supplemented with auxiliary content information, is being actively researched due to its ability to overcome the cold-start problem. Many proposed hybrid methods make recommendations using Gaussian distribution-based collaborative filtering even though they handle variables that tend to be non-Gaussian, such as the number of interactions. We present a method that uses a hybrid recommendation framework based on collaborative filtering that models the number of interactions as a Poisson-distributed and variational autoencoder-based content information generation process that shares latent variables with collaborative filtering. As a prior for the shared latent variables, we use a gamma distribution, which is a conjugate prior of a Poisson distribution. An implicit-derivative-based reparameterization trick enables the use of a gamma distribution in a variational autoencoder. The latent variables in the generative model are inferred using the stochastic gradient variational Bayes approach, taking the number of interactions corresponding to users and items and content information as input. In accordance with the inference, unobserved interactions between users and items are predicted for recommendation. The use of a neural-network-based generative model for content information enables the framework to handle various types of content information. Experimental results show that the proposed method utilizes content information effectively for predicting the number of interactions and that it should aid in overcoming the cold-start problem.","2169-3536","","10.1109/ACCESS.2022.3180051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9787494","Collaborative filtering;implicit feedback;matrix factorization;neural networks;recommendation system","Gamma distribution;Collaborative filtering;Matrix decomposition;Recommender systems;Neural networks;Collaboration","Bayes methods;collaborative filtering;gamma distribution;Gaussian distribution;neural nets;Poisson distribution;recommender systems;stochastic processes","Gaussian distribution-based collaborative filtering;variational autoencoder-based content information generation process;shared latent variables;gamma distribution;stochastic gradient variational Bayes approach;neural-network-based generative model;variational autoencoder-based hybrid recommendation;Poisson factorization;implicit feedback;Poisson-distributed process;implicit-derivative-based reparameterization","","","","50","CCBY","3 Jun 2022","","","IEEE","IEEE Journals"
"Variational Sequential Modeling, Learning and Understanding","J. -T. Chien; C. -J. Tsai","Dept of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Taiwan; Dept of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Taiwan","2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)","3 Feb 2022","2021","","","480","486","Normalizing flow comprises of a series of invertible transformations. With careful design in transformations, it can generate images or speeches with fast sampling speed. Inference can also be efficient in maximum likelihood manner. In addition to generating scenes or human faces, it can be used to transform probability distributions. On the other hand, learning latent structures of sentences in a global manner is always challenging. Variational autoencoder (VAE) is haunted by the issue of posterior collapse, where the latent space is poorly learned. To improve inference and generation of VAE in learning sequence data, we propose the amortized flow posterior variational recurrent autoencoder (AFP-VRAE). Variational recurrent autoencoder (VRAE) has RNN based encoder and decoder and learns global representations of sentences. To learn latent space that well preserves the semantic information of data, we use the normalizing flow to generate flexible variational distributions. Furthermore, we adopt the amortized regularization to encode similar embeddings to neighboring latent representations, and we use the skip connections to reinforce the representations to predict every output directly. The benefits can be shown in the experiments as we evaluate the models for language modeling, sentiment analysis and document summarization. AFP-VRAE reports good results on variational modeling for sequence data.","","978-1-6654-3739-4","10.1109/ASRU51503.2021.9687925","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9687925","Sequential learning;language modeling;variational inference;document summarization","Analytical models;Sentiment analysis;Text analysis;Semantics;Stochastic processes;Transforms;Probability distribution","data mining;learning (artificial intelligence);maximum likelihood estimation;probability;recurrent neural nets","invertible transformations;fast sampling speed;inference;maximum likelihood manner;probability distributions;variational autoencoder;posterior collapse;latent space;sequence data;amortized flow posterior variational recurrent autoencoder;AFP-VRAE;RNN based encoder;global representations;flexible variational distributions;amortized regularization;latent representations;language modeling;variational modeling","","","","35","IEEE","3 Feb 2022","","","IEEE","IEEE Conferences"
"DAEN: Deep Autoencoder Networks for Hyperspectral Unmixing","Y. Su; J. Li; A. Plaza; A. Marinoni; P. Gamba; S. Chakravortty","Guangdong Provincial Key Laboratory of Urbanization and Geo-Simulation, Center of Integrated Geographic Information Analysis, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Key Laboratory of Visual Perception and Artificial Intelligence of Hunan Province, Changsha, China; Hyperspectral Computing Laboratory, Escuela Politécnica, University of Extremadura, Cáceres, Spain; Earth Observation Group, Centre for Integrated Remote Sensing and Forecasting for Arctic Operations, UiT–The Arctic University of Norway, Tromsø, Norway; Telecommunications and Remote Sensing Laboratory, University of Pavia, Pavia, Italy; Department of Information Technology, Maulana Abul Kalam Azad University of Technology, Kolkata, India","IEEE Transactions on Geoscience and Remote Sensing","24 Jun 2019","2019","57","7","4309","4321","Spectral unmixing is a technique for remotely sensed image interpretation that expresses each (possibly mixed) pixel as a combination of pure spectral signatures (endmembers) and their fractional abundances. In this paper, we develop a new technique for unsupervised unmixing which is based on a deep autoencoder network (DAEN). Our newly developed DAEN consists of two parts. The first part of the network adopts stacked autoencoders (SAEs) to learn spectral signatures, so as to generate a good initialization for the unmixing process. In the second part of the network, a variational autoencoder (VAE) is employed to perform blind source separation, aimed at obtaining the endmember signatures and abundance fractions simultaneously. By taking advantage from the SAEs, the robustness of the proposed approach is remarkable as it can unmix data sets with outliers and low signal-to-noise ratio. Moreover, the multihidden layers of the VAE ensure the required constraints (nonnegativity and sum-to-one) when estimating the abundances. The effectiveness of the proposed method is evaluated using both synthetic and real hyperspectral data. When compared with other unmixing methods, the proposed approach demonstrates very competitive performance.","1558-0644","","10.1109/TGRS.2018.2890633","National Natural Science Foundation of China(grant numbers:61771496); Natural Science Foundation of Guangdong Province(grant numbers:2016A030313254); National Key Research and Development Program of China(grant numbers:2017YFB0502900); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8628241","Deep autoencoder network (DAEN);deep learning;endmember identification;hyperspectral unmixing;variational autoencoder (VAE)","Hyperspectral imaging;Estimation;Computers;Training;Noise reduction","geophysical image processing;hyperspectral imaging;remote sensing;spectral analysis","deep autoencoder network;hyperspectral unmixing;remotely sensed image interpretation;pure spectral signatures;fractional abundances;unsupervised unmixing;newly developed DAEN;unmixing process;variational autoencoder;endmember signatures;synthetic data;real hyperspectral data;unmixing methods","","103","","55","IEEE","27 Jan 2019","","","IEEE","IEEE Journals"
"Empirical Comparison between Autoencoders and Traditional Dimensionality Reduction Methods","Q. Fournier; D. Aloise","Ecole Polytechnique Montreal Montreal, Quebec; Ecole Polytechnique Montreal Montreal, Quebec","2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)","8 Aug 2019","2019","","","211","214","In order to process efficiently ever-higher dimensional data such as images, sentences, or audio recordings, one needs to find a proper way to reduce the dimensionality of such data. In this regard, SVD-based methods including PCA and Isomap have been extensively used. Recently, a neural network alternative called autoencoder has been proposed and is often preferred for its higher flexibility. This work aims to show that PCA is still a relevant technique for dimensionality reduction in the context of classification. To this purpose, we evaluated the performance of PCA compared to Isomap, a deep autoencoder, and a variational autoencoder. Experiments were conducted on three commonly used image datasets: MNIST, Fashion-MNIST, and CIFAR-10. The four different dimensionality reduction techniques were separately employed on each dataset to project data into a low-dimensional space. Then a k-NN classifier was trained on each projection with a cross-validated random search over the number of neighbours. Interestingly, our experiments revealed that k-NN achieved comparable accuracy on PCA and both autoencoders projections provided a big enough dimension. However, PCA computation time was two orders of magnitude faster than its neural network counterparts.","","978-1-7281-1488-0","10.1109/AIKE.2019.00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8791727","Machine learning;performance;classification;dimensionality reduction;PCA;autoencoder;k-NN","Principal component analysis;Training;Neural networks;Dimensionality reduction;Decoding;Standards;Audio recording","nearest neighbour methods;neural nets;pattern classification;principal component analysis;singular value decomposition","cross-validated random search;SVD-based methods;Isomap;deep autoencoder;variational autoencoder;Fashion-MNIST;low-dimensional space;k-NN;dimensionality reduction methods;neural network;image datasets;dimensional data processing;PCA;CIFAR-10","","3","","11","","8 Aug 2019","","","IEEE","IEEE Conferences"
"Recognizing Fall Actions from Videos Using Reconstruction Error of Variational Autoencoder","J. Zhou; T. Komuro","Saitama University, Saitama, Japan; Saitama University, Saitama, Japan","2019 IEEE International Conference on Image Processing (ICIP)","26 Aug 2019","2019","","","3372","3376","In this paper, we propose a method for detecting fall actions using a variational auto-encoder (VAE) with 3D-convolutional residual blocks. The VAE learns a distribution of Activity of Daily Life (ADL) data, and the reconstruction error is used to detect fall actions. The proposed method is a kind of unsupervised learning method with weakly labeled data for solving the problem of imbalance between the amount of fall data and that of ADL data. Furthermore, we propose extracting a human region from an entire image using skeleton information and aligning motions using the same joint point so that the neural network can focus on learning human motions, which can enhance the accuracy of fall detection. The results of experiments showed that our method achieved a competitive level of accuracy and better generalization ability compared to supervised learning with well-labeled data.","2381-8549","978-1-5386-6249-6","10.1109/ICIP.2019.8803671","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8803671","Image sequence analysis;Video surveillance","Neural networks;Training;Image reconstruction;Unsupervised learning;Videos;Supervised learning;Feature extraction","image motion analysis;image reconstruction;neural nets;unsupervised learning","fall actions;reconstruction error;variational autoencoder;VAE;3D-convolutional residual blocks;unsupervised learning method;fall data;ADL data;fall detection;human motions learning;daily life data;neural network;skeleton information","","5","","16","","26 Aug 2019","","","IEEE","IEEE Conferences"
"Anomaly Detection Through Latent Space Restoration Using Vector Quantized Variational Autoencoders","S. N. Marimont; G. Tarroni","Department of Computer Science City, Cit-AI, University of London; Department of Computing, BioMedIA, Imperial College London","2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)","25 May 2021","2021","","","1764","1767","We propose an out-of-distribution detection method that combines density and restoration-based approaches using Vector-Quantized Variational Auto-Encoders (VQ-VAEs). The VQ-VAE model learns to encode images in a categorical latent space. The prior distribution of latent codes is then modelled using an Auto-Regressive (AR) model. We found that the prior probability estimated by the AR model can be useful for unsupervised anomaly detection and enables the estimation of both sample and pixel-wise anomaly scores. The sample-wise score is defined as the negative log-likelihood of the latent variables above a threshold selecting highly unlikely codes. Additionally, out-of-distribution images are restored into in-distribution images by replacing unlikely latent codes with samples from the prior model and decoding to pixel space. The average L1 distance between generated restorations and original image is used as pixel-wise anomaly score. We tested our approach on the MOOD challenge datasets, and report higher accuracies compared to a standard reconstruction-based approach with VAEs.","1945-8452","978-1-6654-1246-9","10.1109/ISBI48211.2021.9433778","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9433778","Unsupervised anomaly detection;out-of-distribution;VAE;Vector Quantized-VAE","Location awareness;Mood;Estimation;Robustness;Image restoration;Decoding;Anomaly detection","autoregressive processes;image coding;image reconstruction;image restoration;probability;unsupervised learning;vector quantisation","latent space restoration;vector quantized variational autoencoders;out-of-distribution detection method;unsupervised anomaly detection;sample-wise score;in-distribution images;pixel-wise anomaly score;VQ-VAE;latent codes;autoregressive model;pixel-wise anomaly scores;negative log-likelihood;MOOD challenge datasets","","2","","9","","25 May 2021","","","IEEE","IEEE Conferences"
"A Novel Unsupervised Autoencoder-Based HFOs Detector in Intracranial EEG Signals","W. Li; L. Zhong; W. Xiang; T. Kang; D. Lai","University of Electronic Science and Technology of China (UESTC), Chengdu, China; University of Electronic Science and Technology of China (UESTC), Chengdu, China; University of Electronic Science and Technology of China (UESTC), Chengdu, China; University of Electronic Science and Technology of China (UESTC), Chengdu, China; University of Electronic Science and Technology of China (UESTC), Chengdu, China","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","1426","1430","High frequency oscillations (HFOs) have demonstrated their potency acting as an effective biomarker in epilepsy. However, most of the existing HFOs detectors are based on manual feature extraction and supervised learning, which incur laborious feature selection and time-consuming labeling process. In order to tackle these issues, we propose an automatic unsupervised HFOs detector based on convolutional variational autoencoder (CVAE). First, each selected HFO candidate (via an initial detection method) is converted into a 2-D time-frequency map (TFM) using continuous wavelet transform (CWT). Then, CVAE is trained on the red channel of the TFM (R-TFM) dataset so as to achieve the goal of dimensionality reduction and reconstruction of input feature. The reconstructed R-TFM dataset is later classified by K-means algorithm. Experimental results show that the proposed method outperforms four existing detectors, and achieve 92.85% in accuracy, 93.91% in sensitivity, and 92.14% in specificity.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746014","High frequency oscillation;time-frequency analysis;convolutional variational autoencoder;unsupervised detector","Time-frequency analysis;Continuous wavelet transforms;Sensitivity;Supervised learning;Signal processing algorithms;Detectors;Hafnium oxide","bioelectric potentials;convolutional neural nets;electroencephalography;feature extraction;medical disorders;medical signal detection;medical signal processing;neurophysiology;unsupervised learning;variational techniques;wavelet transforms","intracranial EEG signals;high frequency oscillations;convolutional variational autoencoder;R-TFM dataset;2D time-frequency map;unsupervised autoencoder-based HFO detector;feature reconstruction;K-means algorithm;continuous wavelet transform","","","","23","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Motor Fault Detection and Feature Extraction Using RNN-Based Variational Autoencoder","Y. Huang; C. -H. Chen; C. -J. Huang","Institute of Information Management, National Chiao Tung University, Hsinchu, Taiwan; Department of Mechanical Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Mechanical Engineering, National Chiao Tung University, Hsinchu, Taiwan","IEEE Access","2 Oct 2019","2019","7","","139086","139096","In most of the fault detection methods, the time domain signals collected from the mechanical equipment usually need to be transformed into frequency domain or other high-level data, highly relying on professional knowledge such as signal processing and fault pattern recognition. Contrary to those existing approaches, we proposed a two-stage machine learning analysis architecture which can accurately predict the motor fault modes only by using motor vibration time-domain signals without any complicated preprocessing. In the first stage, the method RNN-based VAE was proposed which is highly suitable for dimension reduction of time series data. In addition to reducing the dimension of sequential data from 150*3 to 25 dimensions, our method furthermore improves the prediction accuracy evaluated by several classification algorithms. While other dimension reduction methods such as Autoencoder and Variational Autoencoder cannot improve the classification accuracy effectively or even decreased. It indicates that the sequential data after dimension reduction via the RNN-based VAE still can maintain the high-dimensional data information. Furthermore, the experimental results demonstrate that it can be well applied to time series data dimension reduction and shows a significant improvement of the prediction performance, even with a simple double-layer Neural Network can reach over 99% of accuracy. In the second stage, Principal Components Analysis (PCA) and Linear Discriminant Analysis (LDA) are used to further perform the second dimension reduction, such that the different or unknown fault modes can be clearly visualized and detected.","2169-3536","","10.1109/ACCESS.2019.2940769","Ministry of Science and Technology, Taiwan(grant numbers:MOST 107-2622-8-009-020,MOST 108-2221-E-009-059-MY2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8835037","Motor fault detection;feature extraction;recurrent neural network;variational autoencoder","Feature extraction;Fault detection;Dimensionality reduction;Vibrations;Data models;Fault diagnosis;Time-domain analysis","condition monitoring;fault diagnosis;feature extraction;learning (artificial intelligence);mechanical engineering computing;pattern classification;pattern recognition;principal component analysis;recurrent neural nets;signal processing;time series;turbomachinery;vibrations","mechanical equipment;frequency domain;high-level data;professional knowledge;signal processing;fault pattern recognition;two-stage machine;motor fault modes;motor vibration time-domain signals;method RNN-based VAE;sequential data;prediction accuracy;classification algorithms;dimension reduction methods;classification accuracy;high-dimensional data information;time series data dimension reduction;prediction performance;unknown fault modes;motor fault detection;feature extraction;fault detection methods;time domain signals;RNN-based variational autoencoder","","40","","38","CCBY","12 Sep 2019","","","IEEE","IEEE Journals"
"Adversarial Attention-Based Variational Graph Autoencoder","Z. Weng; W. Zhang; W. Dou","School of Computer Science and Technology, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; School of Computer Science and Technology, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; School of Computer Science and Technology, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China","IEEE Access","27 Aug 2020","2020","8","","152637","152645","Autoencoders have been successfully used for graph embedding, and many variants have been proven to effectively express graph data and conduct graph analysis in low-dimensional space. However, previous methods ignore the structure and properties of the reconstructed graph, or they do not consider the potential data distribution in the graph, which typically leads to unsatisfactory graph embedding performance. In this paper, we propose the adversarial attention variational graph autoencoder (AAVGA), which is a novel framework that incorporates attention networks into the encoder part and uses an adversarial mechanism in embedded training. The encoder involves node neighbors in the representation of nodes by stacking attention layers, which can further improve the graph embedding performance of the encoder. At the same time, due to the adversarial mechanism, the distribution of the potential features that are generated by the encoder are closer to the actual distribution of the original graph data; thus, the decoder generates a graph that is closer to the original graph. Experimental results prove that AAVGA performs competitively with state-of-the-art popular graph encoders on three citation datasets.","2169-3536","","10.1109/ACCESS.2020.3018033","National Key Research and Development Project(grant numbers:2018YFC704); National Natural Science Foundation of China(grant numbers:61502259); Natural Science Foundation of Shandong Province(grant numbers:ZR2017MF056); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9171337","Attention layers;adversarial mechanism;variational graph autoencoder","Convolution;Matrix decomposition;Training;Neural networks;Correlation;Image reconstruction;Matrix converters","citation analysis;graph theory;neural nets","attention networks;embedded training;attention layers;adversarial attention-based variational graph autoencoder;graph analysis;low-dimensional space;reconstructed graph;data distribution;graph embedding performance;graph data;AAVGA;citation dataset","","4","","36","CCBY","19 Aug 2020","","","IEEE","IEEE Journals"
"Deep Variational Autoencoder for Mapping Functional Brain Networks","N. Qiang; Q. Dong; F. Ge; H. Liang; B. Ge; S. Zhang; Y. Sun; J. Gao; T. Liu","School of Physics and Information Technology, Shaanxi Normal University, Xi’an, China; Department of Computer Science and Bioimaging Research Center, Cortical Architecture Imaging and Discovery Lab, University of Georgia, Athens, GA, USA; Department of Computer Science and Bioimaging Research Center, Cortical Architecture Imaging and Discovery Lab, University of Georgia, Athens, GA, USA; School of Physics and Information Technology, Shaanxi Normal University, Xi’an, China; School of Physics and Information Technology, Shaanxi Normal University, Xi’an, China; School of Computer Science, Northwestern Polyteachnical university, Xi’an, China; School of Physics and Information Technology, Shaanxi Normal University, Xi’an, China; School of Physics and Information Technology, Shaanxi Normal University, Xi’an, China; Department of Computer Science and Bioimaging Research Center, Cortical Architecture Imaging and Discovery Lab, University of Georgia, Athens, GA, USA","IEEE Transactions on Cognitive and Developmental Systems","10 Dec 2021","2021","13","4","841","852","In the neuroimaging and brain mapping communities, researchers have proposed a variety of computational methods to map functional brain networks (FBNs). Recently, it has been proven that deep learning (DL) can be applied on functional magnetic resonance image (fMRI) data with superb representation power over the traditional machine learning methods. However, due to the lack of labeled data and the high dimension of fMRI volume images, DL suffers from overfitting in both supervised and unsupervised training processes. In this work, we proposed a novel generative model: deep variational autoencoder (DVAE) to tackle the challenge of insufficient data and incomplete supervision. The experimental results showed that the representations learned by DVAE are interpretable and meaningful compared to those learned from well-known sparse dictionary learning (SDL). Besides, the organization of some FBN patterns derived from different layers in DVAE was observed in a hierarchical fashion. Furthermore, we showed that DVAE has better performance on small dataset over autoencoder (AE). By using attention deficit hyperactivity disorder (ADHD)-200 dataset as our test bed, we constructed a DVAE-based modeling and classification pipeline in which all subjects’ functional connectivities estimated by FBNs were taken as input features to train a classifier. Finally, the results achieved by our pipeline reached state-of-the-art classification accuracies on three ADHD-200 sites compared with other fMRI-based methods.","2379-8939","","10.1109/TCDS.2020.3025137","Fundamental Research Founds for the Central Universities; National Natural Science Foundation of China; Fundamental Research Founds for the Central Universities(grant numbers:GK202003016); Natural Science Foundation of Shaanxi(grant numbers:2019JQ-026); Fundamental Research Founds for Central Universities(grant numbers:GK201903016); National Natural Science Foundation of China(grant numbers:61976131); National Natural Science Foundation of China(grant numbers:61703256); Fundamental Research Founds for the Central Universities(grant numbers:GK201803023); National Institutes of Health(grant numbers:AG042599); National Science Foundation(grant numbers:DBI-1564736); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9204760","Attention deficit hyperactivity disorder (ADHD);deep learning (DL);generative learning;resting-state functional magnetic resonance image (rfMRI);unsupervised learning;variational autoencoder (VAE)","Functional magnetic resonance imaging;Data models;Brain modeling;Feature extraction;Deep learning;Unsupervised learning;Biological system modeling;Magnetic resonance imaging","biomedical MRI;brain;image classification;medical disorders;medical image processing;neurophysiology;unsupervised learning","deep variational autoencoder;mapping functional brain networks;neuroimaging;brain mapping communities;computational methods;map functional brain networks;deep learning;functional magnetic resonance image data;representation power;traditional machine learning methods;fMRI volume images;supervised training processes;unsupervised training processes;sparse dictionary learning;attention deficit hyperactivity disorder-200 dataset;DVAE-based modeling","","1","","60","IEEE","23 Sep 2020","","","IEEE","IEEE Journals"
"Robust Unsupervised Audio-Visual Speech Enhancement Using a Mixture of Variational Autoencoders","M. Sadeghi; X. Alameda-Pineda","Inria Grenoble Rhône-Alpes, France; Inria Grenoble Rhône-Alpes, France","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","7534","7538","Recently, an audio-visual speech generative model based on variational autoencoder (VAE) has been proposed, which is combined with a nonnegative matrix factorization (NMF) model for noise variance to perform unsupervised speech enhancement. When visual data is clean, speech enhancement with audio-visual VAE shows a better performance than with audio-only VAE, which is trained on audio-only data. However, audio-visual VAE is not robust against noisy visual data, e.g., when for some video frames, speaker face is not frontal or lips region is occluded. In this paper, we propose a robust unsupervised audio-visual speech enhancement method based on a per-frame VAE mixture model. This mixture model consists of a trained audio-only VAE and a trained audio-visual VAE. The motivation is to skip noisy visual frames by switching to the audio-only VAE model. We present a variational expectation-maximization method to estimate the parameters of the model. Experiments show the promising performance of the proposed method.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9053730","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9053730","Robust audio-visual speech enhancement;generative models;variational auto-encoder;mixture mode;variational expectation-maximization","Visualization;Lips;Switches;Mixture models;Speech enhancement;Signal processing;Noise measurement","audio signal processing;expectation-maximisation algorithm;feature extraction;matrix decomposition;neural nets;speech enhancement;unsupervised learning","audio-only data;audio-visual VAE;audio-visual speech enhancement method;per-frame VAE mixture model;trained audio-only;noisy visual frames;robust unsupervised audio-visual speech enhancement;variational autoencoder;audio-visual speech generative model;nonnegative matrix factorization model;unsupervised speech enhancement;visual data","","6","","20","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Semisupervised Text Classification by Variational Autoencoder","W. Xu; Y. Tan","Department of Machine Intelligence, Key Laboratory of Machine Perception, Ministry of Education, School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Department of Machine Intelligence, Key Laboratory of Machine Perception, Ministry of Education, School of Electronics Engineering and Computer Science, Peking University, Beijing, China","IEEE Transactions on Neural Networks and Learning Systems","3 Jan 2020","2020","31","1","295","308","Semisupervised text classification has attracted much attention from the research community. In this paper, a novel model, the semisupervised sequential variational autoencoder (SSVAE), is proposed to tackle this problem. By treating the categorical label of unlabeled data as a discrete latent variable, the proposed model maximizes the variational evidence lower bound of the data likelihood, which implicitly derives the underlying label distribution for the unlabeled data. Analytical work indicates that the autoregressive nature of the sequential model is the crucial issue that renders the vanilla model ineffective. To remedy this, two types of decoders are investigated in the SSVAE model and verified. In addition, a reweighting approach is proposed to circumvent the credit assignment problem that occurs during the reconstruction procedure, which can further improve performance for sparse text data. Experimental results show that our method significantly improves the classification accuracy compared with other modern methods.","2162-2388","","10.1109/TNNLS.2019.2900734","National Natural Science Foundation of China(grant numbers:61673025,61375119); Natural Science Foundation of Beijing Municipality(grant numbers:4162029); National Basic Research Program of China (973 Program)(grant numbers:2015CB352302); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8672806","Generative models;semisupervised learning;text classification;variational autoencoder (VAE)","Data models;Decoding;Task analysis;Training;Semisupervised learning;Predictive models;Feature extraction","data analysis;neural nets;pattern classification;supervised learning;text analysis","sparse text data;credit assignment problem;SSVAE model;vanilla model;sequential model;data likelihood;semisupervised sequential variational autoencoder;semisupervised text classification","","17","","62","IEEE","22 Mar 2019","","","IEEE","IEEE Journals"
"Constructing Dynamic Topic Models Based on Variational Autoencoder and Factor Graph","Z. Gou; L. Han; L. Sun; J. Zhu; H. Yan","College of Computer and Information, Hohai University, Nanjing, China; College of Computer and Information, Hohai University, Nanjing, China; College of Computer and Information, Hohai University, Nanjing, China; College of Computer Science, Nanjing University of Science and Technology Zijin College, Nanjing, China; Department of Electronic Engineering, City University of Hong Kong, Hong Kong","IEEE Access","11 Oct 2018","2018","6","","53102","53111","Topic models are widely used in various fields of machine learning and statistics. Among them, the dynamic topic model (DTM) is the most popular time-series topic model for the dynamic representations of text corpora. A major challenge is that the posterior distribution of DTM requires a complex reasoning process with the high cost of computing time in modeling, and even a tiny change of model requires restructuring. For these reasons, the variability and generality of DTM is so poor that DTM is difficult to be carried out. In this paper, we introduce a new method for constructing DTM based on variational autoencoder and factor graphs. This model uses re-parameterization of the variational lower bound to generate a lower bound estimator which is optimized by standard stochastic gradient descent method directly. At the same time, the optimization process is simplified by integrating the dynamic factor graph in the state space to achieve a better model. The experimental dataset uses a journal paper corpus that mainly focuses on natural language processing and spans twenty-five years (1984-2009) from DBLP. Experiment results indicate that the proposed method is effective and feasible by comparing several state-of-the-art baselines.","2169-3536","","10.1109/ACCESS.2018.2869838","Postgraduate Research & Practice Innovation Program of Jiangsu Province of China(grant numbers:KYCX17_0486); Fundamental Research Funds for the Central Universities(grant numbers:2017B708X14); Hong Kong Research Grants Council(grant numbers:C1007-15G); 2018 Qing Lan Project of Jiangsu Province of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8464062","Dynamic topic model;variational autoencoder;factor graph;2-layer neural network","Computational modeling;Optimization;Heuristic algorithms;Inference algorithms;Bayes methods;Cognition;Probabilistic logic","gradient methods;graph theory;inference mechanisms;learning (artificial intelligence);natural language processing;optimisation;stochastic processes;text analysis;time series","variational autoencoder;statistics;DTM;dynamic representations;complex reasoning process;dynamic factor graph;machine learning;dynamic topic models;time-series topic model;stochastic gradient descent method;natural language processing;optimization process","","2","","31","OAPA","12 Sep 2018","","","IEEE","IEEE Journals"
"A Bayesian Permutation Training Deep Representation Learning Method for Speech Enhancement with Variational Autoencoder","Y. Xiang; J. L. Højvang; M. H. Rasmussen; M. G. Christensen","Capturi A/S, Aarhus, Denmark; Capturi A/S, Aarhus, Denmark; Capturi A/S, Aarhus, Denmark; Audio Analysis Lab, CREATE, Aalborg University, Aalbory, Denmark","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","381","385","Recently, variational autoencoder (VAE), a deep representation learning (DRL) model, has been used to perform speech enhancement (SE). However, to the best of our knowledge, current VAE-based SE methods only apply VAE to model speech signal, while noise is modeled using the traditional non-negative matrix factorization (NMF) model. One of the most important reasons for using NMF is that these VAE-based methods cannot disentangle the speech and noise latent variables from the observed signal. Based on Bayesian theory, this paper derives a novel variational lower bound for VAE, which ensures that VAE can be trained in supervision, and can disentangle speech and noise latent variables from the observed signal. This means that the proposed method can apply the VAE to model both speech and noise signals, which is totally different from the previous VAE-based SE works. More specifically, the proposed DRL method can learn to impose speech and noise signal priors to different sets of latent variables for SE. The experimental results show that the proposed method can not only disentangle speech and noise latent variables from the observed signal, but also obtain a higher scale-invariant signal-to-distortion ratio and speech quality score than the similar deep neural network-based (DNN) SE method.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9747036","Innovation Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747036","Deep representation learning;speech enhancement;Bayesian permutation training;variational autoencoder","Training;Representation learning;Conferences;Signal processing algorithms;Speech enhancement;Signal processing;Acoustics","Bayes methods;deep learning (artificial intelligence);matrix decomposition;neural nets;speech enhancement","Bayesian permutation training deep representation learning method;speech enhancement;variational autoencoder;deep representation learning model;speech signal;nonnegative matrix factorization model;NMF;DRL method;latent variables;scale-invariant signal-to-distortion ratio;speech quality score;deep neural network-based SE method;VAE-based SE methods;noise latent variables;speech latent variables","","","","30","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Model-based Variational Autoencoders with Autoregressive Flows","A. J. Almalki; M. Alsofyani; A. Alghuried; P. Wocjan; L. Wang","Department of Computer Science, University of Central Florida, Orlando, Florida, United States; Department of Computer Science, University of Central Florida, Orlando, Florida, United States; Department of Computer Science, Prince Sattam Bin Abdulaziz University, Saudi Arabia; Department of Computer Science, University of Central Florida, Orlando, Florida, United States; Department of Computer Science, University of Central Florida, Orlando, Florida, United States","2021 Fifth World Conference on Smart Trends in Systems Security and Sustainability (WorldS4)","19 Aug 2021","2021","","","322","327","Variational autoencoders are employed to provide a framework for learning deep latent state representation. Inverse autoregressive flow is a type of normalizing flow that is employed to provide strategies for flexible variational inferences of posteriors over latent variables. The study aimed to prove that the agent can find a solution faster and at a lower cost. The proposed architecture comprises three basic methods, whereby the first one initiates the parameters and other layers of the TensorFlow framework; the second one is the build method that develops a layer using the Kera Library, and the last method, transform, determines the next sequence in the chain and changes the input. The model was then tested on a car racing simulator from OpenAI Gym. It was concluded that the proposed model is fast because it achieved a score of 928 ± 14 over 100 random trials, which is the best in the tested environment.","","978-1-6654-0096-1","10.1109/WorldS451998.2021.9514021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9514021","Machine Learning;Reinforcement Learning;Variational Autoencoders;Autoregressive Flows;and Recurrent Neural Network","Recurrent neural networks;Transforms;Market research;Libraries;Security;Automobiles;Sustainable development","autoregressive processes;computer games;computer simulation;inference mechanisms;learning (artificial intelligence);neural nets","model-based variational autoencoders;autoregressive flows;deep latent state representation;inverse autoregressive flow;normalizing flow;latent variables;TensorFlow framework;build method;Kera Library;OpenAI Gym;random trials","","","","14","","19 Aug 2021","","","IEEE","IEEE Conferences"
"Synthetic Aperture Radar Image Compression Based on a Variational Autoencoder","Q. Xu; Y. Xiang; Z. Di; Y. Fan; Q. Feng; Q. Wu; J. Shi","School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; State Key Laboratory of ASIC and System, Fudan University, Shanghai, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Microelectronics, Xidian University, Xi’an, China","IEEE Geoscience and Remote Sensing Letters","29 Dec 2021","2022","19","","1","5","Given the uniqueness of synthetic aperture radar (SAR) images, traditional optical image compression algorithms cannot fully exploit their redundant information. To improve SAR image compression in terms of rate–distortion performance and visual perception, an end-to-end SAR image compression convolutional neural network (CNN) model based on a variational autoencoder is proposed. The proposed CNN model consists of a main autoencoder and a hyper autoencoder. To reduce dependencies in latent space, a joint transform of linear CNN and nonlinear generalized divisive normalization (GDN) activation is applied in the main autoencoder. Moreover, residual blocks are combined with the transforms to boost the efficiency of feature learning and make use of subpixels to improve the quality of reconstructed images. Instead of a fixed entropy model, a conditioned entropy model that works with a hyperprior network is used to learn the distribution of latents, which helps to further improve the compression quality. During training, the model is optimized by evaluating the rate–distortion performance. The experimental results show that the proposed method can achieve better distortion performance than JPEG, JPEG2000, and the available CNN-based method in terms of objective evaluation criteria and human vision perception quality.","1558-0571","","10.1109/LGRS.2021.3097154","National Natural Science Foundation of China(grant numbers:61504110,62090012); Sichuan Science and Technology Program(grant numbers:2019YFG0092,2020YFG0452); State Key Laboratory of ASIC and System Open Research Project Fund(grant numbers:2021KF013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9494440","Autoencoder;convolutional neural network (CNN);image compression;subpixel;synthetic aperture radar (SAR)","Image coding;Entropy;Radar polarimetry;Decoding;Synthetic aperture radar;Transform coding;Training","convolutional neural nets;data compression;entropy;image coding;image reconstruction;radar computing;radar imaging;synthetic aperture radar;visual perception","CNN model;hyper autoencoder;reconstructed images;fixed entropy model;conditioned entropy model;compression quality;rate-distortion performance;synthetic aperture radar image compression;variational autoencoder;end-to-end SAR image compression convolutional neural network model;nonlinear generalized divisive normalization activation;GDN activation;residual blocks;feature learning;hyperprior network;objective evaluation criteria;human vision perception quality;visual perception;linear CNN","","1","","19","IEEE","26 Jul 2021","","","IEEE","IEEE Journals"
"Classification of Motor Imagery EEG Signals Based on Deep Autoencoder and Convolutional Neural Network Approach","J. F. Hwaidi; T. M. Chen","Department of Electrical and Electronic Engineering, City, University of London, London, U.K.; Department of Electrical and Electronic Engineering, City, University of London, London, U.K.","IEEE Access","9 May 2022","2022","10","","48071","48081","The technology of the brain-computer interface (BCI) employs electroencephalogram (EEG) signals to establish direct interaction between the human body and its surroundings with promising applications in medical rehabilitative services and cognitive science. Deep learning approaches, particularly the detection and analysis of motor imagery signals using convolutional neural network (CNN) frameworks have produced outstanding results in the BCI system in recent years. The complex process of data representation, on the other hand, limits practical applications, and the end-to-end approach reduces the accuracy of recognition. Moreover, since noise and other signal sources can interfere with brain electrical capacitance, EEG classifiers are difficult to improve and have limited generalisation ability. To address these issues, this paper proposes a new approach for EEG motor imagery signal classification by using a variational autoencoder to remove noise from the signals, followed by a combination of deep autoencoder (DAE) and a CNN architecture to classify EEG motor imagery signals which is capable of training a deep neural network to replicate its input to output using encoding and decoding operations. Experimental results show that the proposed approach for motor imagery EEG signal classification is feasible and that it outperforms current CNN-based approaches and several traditional machine learning approaches.","2169-3536","","10.1109/ACCESS.2022.3171906","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9766103","Electroencephalography;deep autoencoder;convolutional neural network;variational autoencoder;motor imagery","Electroencephalography;Feature extraction;Convolutional neural networks;Deep learning;Support vector machines;Training;Brain modeling","brain-computer interfaces;cognition;electroencephalography;learning (artificial intelligence);medical signal processing;neural nets;patient rehabilitation;signal classification","deep autoencoder;convolutional neural network approach;brain-computer interface;human body;medical rehabilitative services;cognitive science;convolutional neural network frameworks;outstanding results;BCI system;complex process;data representation;end-to-end approach;signal sources;brain electrical capacitance;motor imagery signal classification;variational autoencoder;CNN architecture;EEG motor imagery signals;deep neural network;motor imagery EEG signal classification;current CNN-based approaches;traditional machine learning approaches","","","","58","CCBY","2 May 2022","","","IEEE","IEEE Journals"
"A Novel Collaborative Filtering Framework Based on Variational Self-Attention GAN","W. Sun; S. Yu; J. Yang; B. Dong","School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; JD.com America Technologies Corporation, Mountain View, CA, USA; Montclair State University, Montclair, NJ, USA","GLOBECOM 2020 - 2020 IEEE Global Communications Conference","25 Jan 2021","2020","","","1","6","It is difficult for users to find the required information promptly in the massive data. The collaborative filtering is an effective way to help users get the proper information. To achieve better performance, an improved framework based on variational Generative Adversarial Networks with self-attention (VGCF) is proposed. In VGCF, self-attention mechanism and Variational Autoencoders are combined to form self-attention variational encoder, which improves the ability of acquiring explicit and implicit features of sparse data and obtains the personal preference and the correlation between users. By utilizing Generative Adversarial Networks for prediction, the generative model uses the compression matrix obtained by self-attention variational encoder to generate the predicted user-items interaction matrix. The discriminative model provides a better approximation for the posterior and maximum-likelihood assignment, which makes the generated result closer to the real data distribution. Finally, we show that the performance of VGCF is significantly better than the state-of-the-art recommendation methods on several real-world datasets.","2576-6813","978-1-7281-8298-8","10.1109/GLOBECOM42002.2020.9322300","National Key R&D Program of China(grant numbers:2018YFB1700100); Fundamental Research Funds for the Central Universities(grant numbers:DUT18JC28,DUT19ZD103); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9322300","collaborative filtering;generative adversarial networks;variational autoencoders;self-attention","Gallium nitride;Data models;Generative adversarial networks;Predictive models;Collaborative filtering;Training;Sparse matrices","collaborative filtering;matrix algebra;neural nets;recommender systems","collaborative filtering framework;variational generative adversarial networks;VGCF;self-attention mechanism;self-attention variational encoder;explicit features;implicit features;sparse data;generative model;data distribution;variational self-attention GAN;variational autoencoders;compression matrix;user-items interaction matrix;maximum-likelihood assignment;recommendation method","","","","14","","25 Jan 2021","","","IEEE","IEEE Conferences"
"Blind Equalization and Channel Estimation in Coherent Optical Communications Using Variational Autoencoders","V. Lauinger; F. Buchali; L. Schmalen","Communications Engineering Laboratory (CEL), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Nokia, Stuttgart, Germany; Communications Engineering Laboratory (CEL), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany","IEEE Journal on Selected Areas in Communications","19 Aug 2022","2022","40","9","2529","2539","We investigate the potential of adaptive blind equalizers based on variational inference for carrier recovery in optical communications. These equalizers are based on a low-complexity approximation of maximum likelihood channel estimation. We generalize the concept of variational autoencoder (VAE) equalizers to higher order modulation formats encompassing probabilistic constellation shaping (PCS), ubiquitous in optical communications, oversampling at the receiver, and dual-polarization transmission. Besides black-box equalizers based on convolutional neural networks, we propose a model-based equalizer based on a linear butterfly filter and train the filter coefficients using the variational inference paradigm. As a byproduct, the VAE also provides a reliable channel estimation. We analyze the VAE in terms of performance and flexibility over a classical additive white Gaussian noise (AWGN) channel with inter-symbol interference (ISI) and over a dispersive linear optical dual-polarization channel. We show that it can extend the application range of blind adaptive equalizers by outperforming the state-of-the-art constant-modulus algorithm (CMA) for PCS for both fixed but also time-varying channels. The evaluation is accompanied with a hyperparameter analysis.","1558-0008","","10.1109/JSAC.2022.3191346","framework of the CELTIC-NEXT project AI-NET-ANTILLAS (C2019/3-3); German Federal Ministry of Education and Research (BMBF)(grant numbers:16KIS1316); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9831780","Blind equalizers;channel estimation;variational inference;optical fiber communication","Blind equalizers;Optical fiber communication;Symbols;Phase shift keying;Optical polarization;Nonlinear optics;Complexity theory","adaptive equalisers;AWGN;AWGN channels;blind equalisers;channel estimation;equalisers;intersymbol interference;learning (artificial intelligence);maximum likelihood estimation;optical communication;time-varying channels","blind equalization;coherent optical communications;variational autoencoder;adaptive blind equalizers;carrier recovery;low-complexity approximation;maximum likelihood channel estimation;VAE;higher order modulation formats;probabilistic constellation;PCS;dual-polarization transmission;black-box equalizers;convolutional neural networks;model-based equalizer;linear butterfly filter;filter coefficients;variational inference paradigm;reliable channel estimation;classical additive white Gaussian noise channel;dual-polarization channel;blind adaptive equalizers;time-varying channels","","","","38","CCBY","18 Jul 2022","","","IEEE","IEEE Journals"
"An Adversarial Variational Autoencoder Approach Toward Transfer Learning for mTBI Identification","S. Salsabilian; L. Najafizadeh","Department of Electrical and Computer Engineering, Integrated Systems and NeuroImaging Laboratory, Rutgers University, Piscataway, NJ, USA; Department of Electrical and Computer Engineering, Integrated Systems and NeuroImaging Laboratory, Rutgers University, Piscataway, NJ, USA","2021 10th International IEEE/EMBS Conference on Neural Engineering (NER)","2 Jun 2021","2021","","","408","411","Subject variability in mild traumatic brain injury (mTBI) data has often been an obstacle in accurate injury-related feature extraction and biomarker identification for successful mTBI diagnosis. To address this issue, we propose an adversarial variational autoencoder model as a novel regularization approach to extract subject-invariant representations for transfer learning in mTBI identification. The proposed method consists of a variational autoencoder with an attached adversarial network. The autoencoder attempts to learn the latent space mappings from neural activity, while the adversary network is used in a discriminative setting to detach the subject individuality from the representations. The trained encoder is then transferred to extract the representations from new subject's data. Several classifiers are utilized to classify the extracted representations into two categories of normal and mTBI. To evaluate the performance of the proposed method, recorded cortical activity of GCaMP6s transgenic calcium reporter mice before and after inducing an injury is used. Experimental results on cross-subject transfer learning exhibit the efficiency of the proposed framework by achieving 89.7% classification accuracy, suggesting the feasibility of the proposed method in learning invariant representations in mTBI data.","1948-3554","978-1-7281-4337-8","10.1109/NER49283.2021.9441372","NSF(grant numbers:1605646); NJCBIR(grant numbers:CBIR16IRG032); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9441372","","Calcium;Biological system modeling;Transfer learning;Neural activity;Neural engineering;Feature extraction;Brain modeling","biomedical optical imaging;brain;feature extraction;injuries;learning (artificial intelligence);medical image processing;medical signal processing;neural nets;neurophysiology","adversarial variational autoencoder approach;mTBI identification;subject variability;mild traumatic brain injury data;accurate injury-related feature extraction;successful mTBI diagnosis;adversarial variational autoencoder model;novel regularization approach;subject-invariant representations;attached adversarial network;latent space mappings;neural activity;adversary network;subject individuality;extracted representations;recorded cortical activity;cross-subject transfer learning;mTBI data","","1","","16","","2 Jun 2021","","","IEEE","IEEE Conferences"
"A Variational Graph Autoencoder for Manipulation Action Recognition and Prediction","G. Akyol; S. Sariel; E. E. Aksoy","Faculty of Computer and Informatics Engineering, Artificial Intelligence and Robotics Laboratory, Istanbul Technical University, Maslak, Turkey; Faculty of Computer and Informatics Engineering, Artificial Intelligence and Robotics Laboratory, Istanbul Technical University, Maslak, Turkey; School of Information Technology, Center for Applied Intelligent Systems Research, Halmstad University, Halmstad, Sweden","2021 20th International Conference on Advanced Robotics (ICAR)","5 Jan 2022","2021","","","968","973","Despite decades of research, understanding human manipulation activities is, and has always been, one of the most attractive and challenging research topics in computer vision and robotics. Recognition and prediction of observed human manipulation actions have their roots in the applications related to, for instance, human-robot interaction and robot learning from demonstration. The current research trend heavily relies on advanced convolutional neural networks to process the structured Euclidean data, such as RGB camera images. These networks, however, come with immense computational complexity to be able to process high dimensional raw data. Different from the related works, we here introduce a deep graph autoencoder to jointly learn recognition and prediction of manipulation tasks from symbolic scene graphs, instead of relying on the structured Euclidean data. Our network has a variational autoencoder structure with two branches: one for identifying the input graph type and one for predicting the future graphs. The input of the proposed network is a set of semantic graphs which store the spatial relations between subjects and objects in the scene. The network output is a label set representing the detected and predicted class types. We benchmark our new model against different state-of-the-art methods on two different datasets, MANIAC and MSRC-9, and show that our proposed model can achieve better performance. We also release our source code https://github.com/gamzeakyol/GNet.","","978-1-6654-3684-7","10.1109/ICAR53236.2021.9659385","Scientific and Technological Research Council of Turkey(grant numbers:119E-436); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9659385","","Computer vision;Semantics;Robot vision systems;Human-robot interaction;Predictive models;Benchmark testing;Market research","computational complexity;graph theory;human-robot interaction;image classification;image colour analysis;image segmentation;image sensors;learning (artificial intelligence);neural nets;robot vision","challenging research topics;computer vision;robotics;observed human manipulation actions;human-robot interaction;robot learning;current research trend;advanced convolutional neural networks;structured Euclidean data;RGB camera images;immense computational complexity;high dimensional raw data;deep graph autoencoder;manipulation tasks;symbolic scene graphs;variational autoencoder structure;input graph type;future graphs;semantic graphs;spatial relations;network output;detected predicted class types;different state-of-the-art methods;variational graph autoencoder;manipulation action recognition;human manipulation activities;attractive research topics","","","","41","IEEE","5 Jan 2022","","","IEEE","IEEE Conferences"
"Statistical Speech Enhancement Based on Probabilistic Integration of Variational Autoencoder and Non-Negative Matrix Factorization","Y. Bando; M. Mimura; K. Itoyama; K. Yoshii; T. Kawahara","Graduate School of Informatics, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan","2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 Sep 2018","2018","","","716","720","This paper presents a statistical method of single-channel speech enhancement that uses a variational autoencoder (VAE) as a prior distribution on clean speech. A standard approach to speech enhancement is to train a deep neural network (DNN) to take noisy speech as input and output clean speech. Although this supervised approach requires a very large amount of pair data for training, it is not robust against unknown environments. Another approach is to use non-negative matrix factorization (NMF) based on basis spectra trained on clean speech in advance and those adapted to noise on the fly. This semi-supervised approach, however, causes considerable signal distortion in enhanced speech due to the unrealistic assumption that speech spectrograms are linear combinations of the basis spectra. Replacing the poor linear generative model of clean speech in NMF with a VAE-a powerful nonlinear deep generative model-trained on clean speech, we formulate a unified probabilistic generative model of noisy speech. Given noisy speech as observed data, we can sample clean speech from its posterior distribution. The proposed method outperformed the conventional DNN-based method in unseen noisy environments.","2379-190X","978-1-5386-4658-8","10.1109/ICASSP.2018.8461530","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8461530","Single-channel speech enhancement;variational autoencoder;Bayesian signal processing","Spectrogram;Speech enhancement;Noise measurement;Gaussian distribution;Bayes methods;Data models;Training","learning (artificial intelligence);matrix decomposition;neural nets;speech enhancement;statistical analysis","noisy speech;probabilistic integration;deep neural network;signal distortion;linear combinations;linear generative model;nonlinear deep generative model;unified probabilistic generative model;DNN-based method;VAE;NMF;speech spectrograms;semisupervised approach;single-channel speech enhancement;nonnegative matrix factorization;variational autoencoder;statistical speech enhancement;sample clean speech","","48","","32","","13 Sep 2018","","","IEEE","IEEE Conferences"
"Unsupervised domain adaptation for robust speech recognition via variational autoencoder-based data augmentation","W. -N. Hsu; Y. Zhang; J. Glass","Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; Massachusetts Institute of Technology, Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA","2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)","25 Jan 2018","2017","","","16","23","Domain mismatch between training and testing can lead to significant degradation in performance in many machine learning scenarios. Unfortunately, this is not a rare situation for automatic speech recognition deployments in real-world applications. Research on robust speech recognition can be regarded as trying to overcome this domain mismatch issue. In this paper, we address the unsupervised domain adaptation problem for robust speech recognition, where both source and target domain speech are available, but word transcripts are only available for the source domain speech. We present novel augmentation-based methods that transform speech in a way that does not change the transcripts. Specifically, we first train a variational autoencoder on both source and target domain data (without supervision) to learn a latent representation of speech. We then transform nuisance attributes of speech that are irrelevant to recognition by modifying the latent representations, in order to augment labeled training data with additional data whose distribution is more similar to the target domain. The proposed method is evaluated on the CHiME-4 dataset and reduces the absolute word error rate (WER) by as much as 35% compared to the non-adapted baseline.","","978-1-5090-4788-8","10.1109/ASRU.2017.8268911","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268911","unsupervised domain adaptation;robust speech recognition;variational autoencoder;data augmentation","Speech;Speech recognition;Adaptation models;Robustness;Pragmatics;Decoding;Noise measurement","learning (artificial intelligence);speech recognition;word processing","robust speech recognition;domain mismatch issue;variational autoencoder;labeled training data;automatic speech recognition;unsupervised domain adaptation;data augmentation;machine learning;word transcripts;speech representation","","40","","35","","25 Jan 2018","","","IEEE","IEEE Conferences"
"Remaining Useful Life Prediction of Lithium-Ion Batteries Based on Conditional Variational Autoencoders-Particle Filter","R. Jiao; K. Peng; J. Dong","Key Laboratory of Knowledge Automation for Industrial Processes of Ministry of Education, School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, China; Institute of Artificial Intelligence, University of Science and Technology Beijing, Beijing, China; Key Laboratory of Knowledge Automation for Industrial Processes of Ministry of Education, School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, China","IEEE Transactions on Instrumentation and Measurement","8 Oct 2020","2020","69","11","8831","8843","Accurate prediction of remaining useful life (RUL) is of great significance to the safety and reliability of lithium-ion batteries, which is able to provide useful reference information for maintenance. Particle filter (PF)-based prognostic methods have been widely used in the RUL prediction of batteries. However, due to the degeneracy of particles, the prediction accuracy of the traditional PF is not high. In this article, a novel PF framework based on conditional variational autoencoder (CVAE) and a reweighting strategy is proposed to predict the RUL of batteries. First, the CVAE algorithm is described in detail and embedded into the PF framework to substitute the traditional prior distribution so as to alleviate particle degradation. Furthermore, a reweighting strategy is introduced during particle resampling to prevent the loss of particle diversity. Afterward, the state-space model of battery capacity is established on the basis of data analysis. In the end, the proposed CVAE-PF is employed to predict the degradation of the battery capacity, and the RUL can be obtained when the capacity drops to a predefined failure threshold. From the experimental results it can be concluded that the new method is able to achieve better prediction performance compared with some traditional methods.","1557-9662","","10.1109/TIM.2020.2996004","Natural Science Foundation of China (NSFC)(grant numbers:61873024,61773053); Fundamental Research Funds for the China Central Universities of USTB(grant numbers:FRF-TP-19-049A1Z); National Key Research and Development Program of China(grant numbers:2017YFB0306403); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097256","Conditional variational autoencoder (CVAE);lithium-ion batteries (LIBs);particle filter (PF);remaining useful life (RUL);resampling method","Batteries;Predictive models;Degradation;Estimation;Reliability;Data models;Mathematical model","data analysis;lithium compounds;particle filtering (numerical methods);remaining life assessment;secondary cells","battery capacity;CVAE-PF;lithium-ion batteries;particle filter-based prognostic methods;prediction accuracy;conditional variational autoencoder;reweighting strategy;CVAE algorithm;particle degradation;particle resampling;particle diversity;remaining useful life prediction;state-space model;data analysis","","32","","34","IEEE","20 May 2020","","","IEEE","IEEE Journals"
"Semi-supervised Multichannel Speech Enhancement with Variational Autoencoders and Non-negative Matrix Factorization","S. Leglaive; L. Girin; R. Horaud","Inria Grenoble Rhône-Alpes, France; Inria Grenoble Rhône-Alpes, France; Inria Grenoble Rhône-Alpes, France","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","101","105","In this paper we address speaker-independent multichannel speech enhancement in unknown noisy environments. Our work is based on a well-established multichannel local Gaussian modeling framework. We propose to use a neural network for modeling the speech spectro-temporal content. The parameters of this supervised model are learned using the framework of variational autoencoders. The noisy recording environment is supposed to be unknown, so the noise spectro-temporal modeling remains unsupervised and is based on non-negative matrix factorization (NMF). We develop a Monte Carlo expectation-maximization algorithm and we experimentally show that the proposed approach outperforms its NMF-based counterpart, where speech is modeled using supervised NMF.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683704","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683704","Multichannel speech enhancement;local Gaussian modeling;variational autoencoders;non-negative matrix factorization;Monte Carlo expectation-maximization","","expectation-maximisation algorithm;Gaussian processes;matrix decomposition;Monte Carlo methods;neural nets;speech enhancement","nonnegative matrix factorization;Monte Carlo expectation-maximization algorithm;supervised NMF;semisupervised multichannel speech enhancement;variational autoencoders;multichannel local Gaussian modeling framework;neural network;speech spectro-temporal content;noisy recording environment;noise spectro-temporal modeling;speaker-independent multichannel speech enhancement","","28","","32","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Unsupervised Anomaly Detection of Industrial Robots Using Sliding-Window Convolutional Variational Autoencoder","T. Chen; X. Liu; B. Xia; W. Wang; Y. Lai","Graduate School at Shenzhen, Tsinghua University, Shenzhen, China; Graduate School at Shenzhen, Tsinghua University, Shenzhen, China; Graduate School at Shenzhen, Tsinghua University, Shenzhen, China; Sunwoda Electronic Company, Ltd., Shenzhen, China; Sunwoda Electronic Company, Ltd., Shenzhen, China","IEEE Access","13 Mar 2020","2020","8","","47072","47081","With growing dependence of industrial robots, a failure of an industrial robot may interrupt current operation or even overall manufacturing workflows in the entire production line, which can cause significant economic losses. Hence, it is very essential to maintain industrial robots to ensure high-level performance. It is widely desired to have a real-time technique to constantly monitor robots by collecting time series data from robots, which can automatically detect incipient failures before robots totally shut down. Model-based methods are typically used in anomaly detection for robots, yet explicit domain knowledge and accurate mathematical models are required. Data-driven techniques can overcome these limitations. However, a major difficulty for them is the lack of sufficient fault data of industrial robots. Besides, the used technique for anomaly detection of robots should be required to not only capture the temporal dependency in collected time series data, but also the inter-correlations between different metrics. In this paper, we introduce an unsupervised anomaly detection for industrial robots, sliding-window convolutional variational autoencoder (SWCVAE), which can realize real-time anomaly detection spatially and temporally by coping with multivariate time series data. This method has been verified by a KUKA KR6R 900SIXX industrial robot, and the results prove that the proposed model can successfully detect anomaly in the robot. Thus, this work presents a promising tool for condition-based maintenance of industrial robots.","2169-3536","","10.1109/ACCESS.2020.2977892","Shenzhen Economic, Trade and Information Commission of Shenzhen; Municipality Strategic Emerging Industries and Future Industrial Development ???Innovation Chain + Industrial. Chain??? Project (2017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9023488","Anomaly detection;industrial robots;sliding window;variational autoencoder;convolutional neural network","Service robots;Anomaly detection;Time series analysis;Mathematical model;Real-time systems;Robot sensing systems","computerised monitoring;condition monitoring;convolutional neural nets;data mining;failure analysis;fault diagnosis;industrial robots;maintenance engineering;mobile robots;time series","unsupervised anomaly detection;sliding-window convolutional variational autoencoder;KUKA KR6R 900SIXX industrial robot;production line;failure detection;real-time technique;shut down;multivariate time series data;model-based methods;mathematical models;data-driven techniques;fault data;condition-based maintenance","","25","","31","CCBY","3 Mar 2020","","","IEEE","IEEE Journals"
"Semi-Supervised Bearing Fault Diagnosis and Classification Using Variational Autoencoder-Based Deep Generative Models","S. Zhang; F. Ye; B. Wang; T. G. Habetler","Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; California PATH, University of California at Berkeley, Berkeley, CA, USA; Mitsubishi Electric Research Laboratories, Cambridge, MA, USA; Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Sensors Journal","4 Feb 2021","2021","21","5","6476","6486","Many industries are evaluating the use of the Internet of Things (IoT) technology to perform remote monitoring and predictive maintenance on their mission-critical assets and equipment, for which mechanical bearings are their indispensable components. Although many data-driven methods have been applied to bearing fault diagnosis, most of them belong to the supervised learning paradigm that requires a large amount of labeled training data to be collected in advance. In practical applications, however, obtaining labeled data that accurately reflect real-time bearing conditions can be more challenging than collecting large amounts of unlabeled data. In this paper, we thus propose a semi-supervised learning scheme for bearing fault diagnosis using variational autoencoder (VAE)-based deep generative models, which can effectively leverage a dataset when only a small subset of data have labels. Finally, a series of experiments were conducted using the University of Cincinnati Intelligent Maintenance System (IMS) Center dataset and the Case Western Reserve University (CWRU) bearing dataset. The experimental results demonstrate that the proposed semi-supervised learning schemes outperformed some mainstream supervised and semi-supervised benchmarks with the same percentage of labeled data samples. Additionally, the proposed methods can mitigate the label inaccuracy issue when identifying naturally-evolved bearing defects.","1558-1748","","10.1109/JSEN.2020.3040696","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9270010","Bearing fault;generative model;semi-supervised learning;variational autoencoders","Data models;Fault diagnosis;Sensors;Semisupervised learning;Decoding;Supervised learning;Training","condition monitoring;data analysis;fault diagnosis;Internet of Things;machine bearings;maintenance engineering;mechanical engineering computing;neural nets;supervised learning","data-driven methods;supervised learning paradigm;real-time bearing conditions;variational autoencoder-based deep generative models;Cincinnati Intelligent Maintenance System Center dataset;Case Western Reserve University;labeled data samples;semisupervised bearing fault diagnosis;Internet of Things;remote monitoring;predictive maintenance;mission-critical assets;mechanical bearings;IoT;VAE;IMS","","18","","34","IEEE","25 Nov 2020","","","IEEE","IEEE Journals"
"Abnormal Event Detection From Videos Using a Two-Stream Recurrent Variational Autoencoder","S. Yan; J. S. Smith; W. Lu; B. Zhang","Department of Computer Science and Software Engineering, Xi’an Jiaotong-Liverpool University, Suzhou, China; Department of Electrical Engineering and Electronics, University of Liverpool, Liverpool, U.K.; Department of Computer Science and Software Engineering, Xi’an Jiaotong-Liverpool University, Suzhou, China; Department of Computer Science and Software Engineering, Xi’an Jiaotong-Liverpool University, Suzhou, China","IEEE Transactions on Cognitive and Developmental Systems","11 Mar 2020","2020","12","1","30","42","With the massive deployment of distributed video surveillance systems, the automatic detection of abnormal events in video streams has become an urgent need. An abnormal event can be considered as a deviation from the regular scene; however, the distribution of normal and abnormal events is severely imbalanced, since the abnormal events do not frequently occur. To make use of a large number of video surveillance videos of regular scenes, we propose a semi-supervised learning scheme, which only uses the data that contains the ordinary scenes. The proposed model has a two-stream structure that is composed of the appearance and motion streams. For each stream, a recurrent variational autoencoder can model the probabilistic distribution of the normal data in a semi-supervised learning scheme. The appearance and motion features from the two streams can provide complementary information to describe this probabilistic distribution. Comprehensive experiments validate the effectiveness of our proposed scheme on several public benchmark data sets which include the Avenue, the Ped1, the Ped2, the Subway-entry, and the Subway-exit.","2379-8939","","10.1109/TCDS.2018.2883368","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543857","Abnormal event detection;convolutional long-short term memory (LSTM);reconstruction error probability;two-stream fusion;variational autoencoder (VAE)","Event detection;Videos;Feature extraction;Hidden Markov models;Image reconstruction;Neural networks;Task analysis","feature extraction;image motion analysis;recurrent neural nets;statistical distributions;supervised learning;video signal processing;video streaming;video surveillance","appearance feature;video streams;distributed video surveillance systems;two-stream recurrent variational autoencoder;abnormal event detection;probabilistic distribution;motion streams;semisupervised learning scheme","","17","","79","IEEE","25 Nov 2018","","","IEEE","IEEE Journals"
"Integrated Multi-omics Analysis Using Variational Autoencoders: Application to Pan-cancer Classification","X. Zhang; J. Zhang; K. Sun; X. Yang; C. Dai; Y. Guo","Data Science Institute, Imperial College London, London, UK; Data Science Institute, Imperial College London, London, UK; Data Science Institute, Imperial College London, London, UK; Data Science Institute, Imperial College London, London, UK; Data Science Institute, Imperial College London, London, UK; Data Science Institute, Imperial College London, London, UK","2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","6 Feb 2020","2019","","","765","769","Omics data are normally high dimensional with large number of molecular features and relatively small number of available samples with clinical labels. The “curse of dimensionality” makes it challenging to train a machine learning model using high dimensional omics data like DNA methylation and gene expression profiles. Here we propose an end-to-end deep learning model called OmiVAE to extract low dimensional features and classify samples from multi-omics data. OmiVAE combines the basic structure of variational autoencoders with a classifier to achieve task-oriented feature extraction and multi-class classification. The training procedure of OmiVAE is comprised of an unsupervised phase and a supervised phase. During the unsupervised phase, a hierarchical cluster structure of samples can be automatically formed without the need for labels. And in the supervised phase, OmiVAE achieved an average accuracy of 97.49% after 10-fold cross-validation among 33 tumour types and normal samples, which shows better performance than existing methods. The integrated model learned from multi-omics datasets outperformed those using only one type of omics data, which indicates that the complementary information from different omics datatypes provides useful insights for biomedical tasks like cancer classification.","","978-1-7281-1867-3","10.1109/BIBM47256.2019.8983228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8983228","deep learning;variational autoencoders;multi-omics analysis;DNA methylation;gene expression;cancer","","cancer;DNA;feature extraction;genetics;genomics;learning (artificial intelligence);medical computing;pattern classification;pattern clustering;proteomics;tumours","cancer classification;biomedical tasks;tumour types;hierarchical cluster structure;multiclass classification;classifier;DNA methylation;machine learning;curse of dimensionality;omics datatypes;multiomics datasets;task-oriented feature extraction;multiomics data;low dimensional features;OmiVAE;end-to-end deep learning model;gene expression profiles;high dimensional omics data;clinical labels;molecular features;pan-cancer classification;variational autoencoders;integrated multiomics analysis","","16","","15","","6 Feb 2020","","","IEEE","IEEE Conferences"
"Speech Enhancement with Variational Autoencoders and Alpha-stable Distributions","S. Leglaive; U. Şimşekli; A. Liutkus; L. Girin; R. Horaud","Inria Grenoble Rhône-Alpes, France; LTCI, Télécom ParisTech, Université Paris-Saclay, France; Inria and LIRMM, France; Inria Grenoble Rhône-Alpes, France; Inria Grenoble Rhône-Alpes, France","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","541","545","This paper focuses on single-channel semi-supervised speech enhancement. We learn a speaker-independent deep generative speech model using the framework of variational autoencoders. The noise model remains unsupervised because we do not assume prior knowledge of the noisy recording environment. In this context, our contribution is to propose a noise model based on alpha-stable distributions, instead of the more conventional Gaussian non-negative matrix factorization approach found in previous studies. We develop a Monte Carlo expectation-maximization algorithm for estimating the model parameters at test time. Experimental results show the superiority of the proposed approach both in terms of perceptual quality and intelligibility of the enhanced speech signal.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682546","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682546","Speech enhancement;variational autoencoders;alpha-stable distribution;Monte Carlo expectation-maximization","Speech enhancement;Time-frequency analysis;Noise measurement;Monte Carlo methods;Deep learning;Context modeling;Expectation-maximization algorithms","expectation-maximisation algorithm;learning (artificial intelligence);matrix decomposition;Monte Carlo methods;speech enhancement","variational autoencoders;alpha-stable distributions;single-channel semisupervised speech enhancement;speaker-independent deep generative speech model;noise model;noisy recording environment;conventional Gaussian nonnegative matrix factorization approach;Monte Carlo expectation-maximization algorithm;model parameters;enhanced speech signal","","15","","38","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Unsupervised Detection of Apnea Using Commodity RFID Tags With a Recurrent Variational Autoencoder","C. Yang; X. Wang; S. Mao","Department of Electrical and Computer Engineering, Auburn University, Auburn, AL, USA; Department of Computer Science, California State University, Sacramento, CA, USA; Department of Electrical and Computer Engineering, Auburn University, Auburn, AL, USA","IEEE Access","4 Jun 2019","2019","7","","67526","67538","With the rapid development of intelligent health sensing in the Internet of Things (IoT), vital sign monitoring (e.g., respiration) and abnormal respiration detection have attracted increasing attention. Considering the challenging and the cost of collecting labeled training data from patients with breathing related diseases, we develop the AutoTag system, an unsupervised recurrent variational autoencoder-based method for respiration rate estimation and abnormal breathing detection with off-the-shelf RFID tags. Moreover, for real-time breath monitoring, a novel method is proposed to cancel the distortion on measured phase values caused by channel hopping for FCC-complaint RFID systems. The efficacy of the proposed system is demonstrated by the extensive experiments conducted in two indoor environments, while the impact of various design and environmental factors is also evaluated.","2169-3536","","10.1109/ACCESS.2019.2918292","National Science Foundation(grant numbers:CNS-1702957); Auburn University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8720147","Apnea;deep learning;radio-frequency identification (RFID);recurrent variational autoencoder;respiration monitoring","Monitoring;Wireless fidelity;Doppler radar;RFID tags","diseases;medical signal processing;patient diagnosis;patient monitoring;pneumodynamics;radiofrequency identification","commodity RFID tags;intelligent health sensing;IoT;vital sign;labeled training data;related diseases;AutoTag system;unsupervised recurrent variational autoencoder-based method;respiration rate estimation;abnormal breathing detection;off-the-shelf RFID tags;real-time breath monitoring;measured phase values;FCC-complaint RFID systems","","14","1","34","OAPA","22 May 2019","","","IEEE","IEEE Journals"
"Unsupervised Wafermap Patterns Clustering via Variational Autoencoders","P. Tulala; H. Mahyar; E. Ghalebi; R. Grosu","Institute of Computer Engineering, Vienna University of Technology (TU Wien); Institute of Computer Engineering, Vienna University of Technology (TU Wien); Institute of Computer Engineering, Vienna University of Technology (TU Wien); Institute of Computer Engineering, Vienna University of Technology (TU Wien)","2018 International Joint Conference on Neural Networks (IJCNN)","14 Oct 2018","2018","","","1","8","Semiconductor manufacturing processes are prone to process deviations or other production issues. Quality assurance of every processing step and measuring wafer test values is crucial for finding possible root causes of these problems. Automated visual inspection and recognition of patterns in wafermap data obtained during different processing steps has a potential to signifficantly improve the efficiency of finding early production issues and even help with adjustment of the production parameters to automatically resolve them. In this paper, we present a machine learning approach for unsupervised clustering of spatial patterns in wafermap measurement data. Measured test values are first pre-processed using some computer vision techniques, followed by a feature extraction based on variational autoencoders to decompose high-dimensional wafermaps into a low-dimensional latent representation. Final step is to detect the structure of this latent space and assign individual wafers into clusters. We experimentally evaluate the performance of the proposed method over a real dataset.","2161-4407","978-1-5090-6014-6","10.1109/IJCNN.2018.8489422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489422","Wafer test data;Image processing;Semiconductor manufacturing;Pattern recognition;Variational Autoencoder;Clustering","Feature extraction;Semiconductor device measurement;Pattern recognition;Manufacturing;Neural networks;Task analysis","automatic optical inspection;computer vision;feature extraction;inspection;learning (artificial intelligence);pattern clustering;production engineering computing;semiconductor device manufacture","measured test values;variational autoencoders;high-dimensional wafermaps;low-dimensional latent representation;latent space;unsupervised wafermap patterns clustering;semiconductor manufacturing processes;quality assurance;wafermap data;production parameters;machine learning approach;unsupervised clustering;spatial patterns;wafermap measurement data;wafer test values","","13","1","25","","14 Oct 2018","","","IEEE","IEEE Conferences"
"EEG-Based Adaptive Driver-Vehicle Interface Using Variational Autoencoder and PI-TSVM","L. Bi; J. Zhang; J. Lian","School of Mechanical Engineering, Beijing Institute of Technology, Beijing, China; School of Mechanical Engineering, Beijing Institute of Technology, Beijing, China; School of Mechanical Engineering, Beijing Institute of Technology, Beijing, China","IEEE Transactions on Neural Systems and Rehabilitation Engineering","17 Oct 2019","2019","27","10","2025","2033","Event-related potential (ERP)-based driver-vehicle interfaces (DVIs) have been developed to provide a communication channel for people with disabilities to drive a vehicle. However, they require a tedious and time-consuming training procedure to build the decoding model, which can translate EEG signals into commands. In this paper, to address this problem, we propose an adaptive DVI by using a new semi-supervised algorithm. The decoding model of the proposed DVI is first built with a small labeled training set, and then gradually improved by updating the proposed semi-supervised decoding model with new collected unlabeled EEG signals. In our semi-supervised algorithm, independent component analysis (ICA) and Kalman smoother are first used to improve the signal-to-noise ratio (SNR). After that, variational autoencoder is applied to provide a robust feature representation of EEG signals. Finally, a prior information-based transductive support vector machine (PI-TSVM) classifier is developed to translate these features into commands. Experimental results show that the proposed DVI can significantly reduce the training effort. After a short updating, its performance can be close to that of the supervised DVI requiring a lengthy training procedure. This work is vital for advancing the application of these DVIs.","1558-0210","","10.1109/TNSRE.2019.2940046","National Natural Science Foundation of China(grant numbers:51575048,51975052); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827606","Brain-controlled vehicle;EEG;semi-supervised learning;variational autoencoder;transductive support vector machine","Electroencephalography;Decoding;Brain modeling;Training;Adaptation models;Kalman filters;Integrated circuits","electroencephalography;feature extraction;independent component analysis;medical signal processing;signal classification;signal representation;support vector machines","prior information-based transductive support vector machine classifier;robust feature representation;SNR;Kalman smoother;ICA;independent component analysis;unlabeled EEG signals;communication channel;EEG-based adaptive driver-vehicle interface;supervised DVI;signal-to-noise ratio;semisupervised decoding model;labeled training set;semisupervised algorithm;adaptive DVI;EEG signals;tedious time-consuming training procedure;event-related potential-based driver-vehicle interfaces;PI-TSVM;variational autoencoder","Adult;Algorithms;Automobile Driving;Brain-Computer Interfaces;Electroencephalography;Female;Healthy Volunteers;Humans;Male;Pattern Recognition, Automated;Principal Component Analysis;Psychomotor Performance;Signal-To-Noise Ratio;Support Vector Machine;Young Adult","13","","34","IEEE","9 Sep 2019","","","IEEE","IEEE Journals"
"Squeezed Convolutional Variational AutoEncoder for unsupervised anomaly detection in edge device industrial Internet of Things","D. Kim; H. Yang; M. Chung; S. Cho; H. Kim; M. Kim; K. Kim; E. Kim","Department of Industrial Engineering, Seoul National University, Seoul, Republic of Korea; Department of Industrial Engineering, Seoul National University, Seoul, Republic of Korea; Department of Industrial Engineering, Seoul National University, Seoul, Republic of Korea; Department of Industrial Engineering, Seoul National University, Seoul, Republic of Korea; Data Analytics Lab, Samsung Electronics Co. Ltd., Seoul, Republic of Korea; Data Analytics Lab, Samsung Electronics Co. Ltd., Seoul, Republic of Korea; Data Analytics Lab, Samsung Electronics Co. Ltd., Seoul, Republic of Korea; Data Analytics Lab, Samsung Electronics Co. Ltd., Seoul, Republic of Korea","2018 International Conference on Information and Computer Technologies (ICICT)","10 May 2018","2018","","","67","71","In this paper, we propose Squeezed Convolutional Variational AutoEncoder (SCVAE) for anomaly detection in time series data for Edge Computing in Industrial Internet of Things (IIoT). The proposed model is applied to labeled time series data from UCI datasets for exact performance evaluation, and applied to real world data for indirect model performance comparison. In addition, by comparing the models before and after applying Fire Modules from SqueezeNet, we show that model size and inference times are reduced while similar levels of performance is maintained.","","978-1-5386-5384-5","10.1109/INFOCT.2018.8356842","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356842","edge computing;IIoT;unsupervised;anomaly Detection;manufacturing;variational autoencoder;VAE;convolutional neural network;CNN;squeezenet","Computational modeling;Anomaly detection;Time series analysis;Fires;Performance evaluation;Decoding;Data models","distributed processing;inference mechanisms;Internet of Things;neural nets;production engineering computing;time series;unsupervised learning","inference times;unsupervised anomaly detection;labeled time series data;manufacturing processes;SqueezeNet;Fire Modules;UCI datasets;IIoT;edge computing;SCVAE;edge device industrial Internet of Things;squeezed convolutional variational autoencoder","","13","1","18","","10 May 2018","","","IEEE","IEEE Conferences"
"Joint Separation and Dereverberation of Reverberant Mixtures with Multichannel Variational Autoencoder","S. Inoue; H. Kameoka; L. Li; S. Seki; S. Makino","University of Tsukuba, Japan; NTT Communication Science Laboratories, NTT Corporation, Japan; University of Tsukuba, Japan; University of Nagoya, Japan; University of Tsukuba, Japan","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","96","100","In this paper, we deal with a multichannel source separation problem under a highly reverberant condition. The multichannel variational autoencoder (MVAE) is a recently proposed source separation method that employs the decoder distribution of a conditional VAE (CVAE) as the generative model for the complex spectrograms of the underlying source signals. Although MVAE is notable in that it can significantly improve the source separation performance compared with conventional methods, its capability to separate highly reverberant mixtures is still limited since MVAE uses an instantaneous mixture model. To overcome this limitation, in this paper we propose extending MVAE to simultaneously solve source separation and dereverberation problems by formulating the separation system as a frequency-domain convolutive mixture model. A convergence-guaranteed algorithm based on the coordinate descent method is derived for the optimiza- tion. Experimental results revealed that the proposed method outperformed the conventional methods in terms of all the source separation criteria in highly reverberant environments.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683497","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683497","Blind source separation;blind derever- beration;multichannel audio signal processing;multichannel variational autoencoder (MVAE)","","convolution;frequency-domain analysis;mixture models;reverberation;source separation","conditional VAE;generative model;complex spectrograms;MVAE;source separation performance;dereverberation;separation system;frequency-domain convolutive mixture model;coordinate descent method;source separation criteria;highly reverberant environments;reverberant mixtures;multichannel variational autoencoder;multichannel source separation problem;source separation method;convergence-guaranteed algorithm;instantaneous mixture model;highly reverberant mixtures;decoder distribution","","12","","17","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Fast MVAE: Joint Separation and Classification of Mixed Sources Based on Multichannel Variational Autoencoder with Auxiliary Classifier","L. Li; H. Kameoka; S. Makino","University of Tsukuba, Japan; NTT Communication Science Laboratories, NTT Corporation, Japan; University of Tsukuba, Japan","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","546","550","This paper proposes an alternative algorithm for the multi-channel variational autoencoder (MVAE), a recently proposed multichannel source separation approach. While MVAE is notable for its impressive source separation performance, its convergence-guaranteed optimization algorithm and the fact that it allows us to estimate source-class labels simultaneously with source separation, there are still two major drawbacks, namely, the high computational complexity and the unsatisfactory source classification accuracy. To overcome these drawbacks, the proposed method employs an auxiliary classifier VAE, which is an information-theoretic extension of the conditional VAE, for learning the generative model of the source spectrograms. Furthermore, with the trained auxiliary classifier, we introduce a novel algorithm for the optimization that can both reduce the computational time and improve the source classification performance. We call the proposed method ""fast MVAE (fMVAE) "". Experimental evaluations revealed that fMVAE achieved source separation performance comparable to that of MVAE and a source classification accu-racy rate of about 80% while reducing computational time by about 93%.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682623","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682623","Multichannel source separation;multi-channel variational autoencoder;auxiliary classifier;source classification","Spectrogram;Decoding;Source separation;Training;Optimization;Backpropagation;Computational modeling","iterative methods;learning (artificial intelligence);neural nets;optimisation;signal classification;source separation","fast MVAE;mixed sources;multichannel variational autoencoder;impressive source separation performance;convergence-guaranteed optimization algorithm;source-class labels;high computational complexity;unsatisfactory source classification accuracy;auxiliary classifier VAE;information-theoretic extension;source spectrograms;trained auxiliary classifier;source classification performance;multichannel source separation approach;source separation performance","","12","","21","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Singing Voice Conversion with Disentangled Representations of Singer and Vocal Technique Using Variational Autoencoders","Y. -J. Luo; C. -C. Hsu; K. Agres; D. Herremans","Singapore University of Technology and Design; University of Southern California, Los Angeles, United States; Institute of High Performance Computing, A*STAR, Singapore; Singapore University of Technology and Design","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","3277","3281","We propose a flexible framework that deals with both singer conversion and singers vocal technique conversion. The proposed model is trained on non-parallel corpora, accommodates many-to-many conversion, and leverages recent advances of variational autoencoders. It employs separate encoders to learn disentangled latent representations of singer identity and vocal technique separately, with a joint decoder for reconstruction. Conversion is carried out by simple vector arithmetic in the learned latent spaces. Both a quantitative analysis as well as a visualization of the converted spectrograms show that our model is able to disentangle singer identity and vocal technique and successfully perform conversion of these attributes. To the best of our knowledge, this is the first work to jointly tackle conversion of singer identity and vocal technique based on a deep learning approach.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9054582","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054582","singing voice conversion;vocal technique;variational autoencoders;disentangled representations","Deep learning;Visualization;Statistical analysis;Conferences;Decoding;Speech processing;Spectrogram","decoding;learning (artificial intelligence);speech coding","variational autoencoders;nonparallel corpora;disentangled latent representations;latent space learning;vocal technique conversion;deep learning approach","","10","","21","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"Unsupervised Representation Disentanglement Using Cross Domain Features and Adversarial Learning in Variational Autoencoder Based Voice Conversion","W. -C. Huang; H. Luo; H. -T. Hwang; C. -C. Lo; Y. -H. Peng; Y. Tsao; H. -M. Wang","Graduate School of Informatics, Nagoya University, Nagoya, Japan; Institute of Information Science, Academia Sinica, Taipei, Taiwan; Institute of Information Science, Academia Sinica, Taipei, Taiwan; Institute of Information Science, Academia Sinica, Taipei, Taiwan; Institute of Information Science, Academia Sinica, Taipei, Taiwan; Research Center of Information Technology Institute of Information Science, Academia Sinica, Taipei, Taiwan; Institute of Information Science, Academia Sinica, Taipei, Taiwan","IEEE Transactions on Emerging Topics in Computational Intelligence","21 Jul 2020","2020","4","4","468","479","An effective approach for voice conversion (VC) is to disentangle linguistic content from other components in the speech signal. The effectiveness of variational autoencoder (VAE) based VC (VAE-VC), for instance, strongly relies on this principle. In our prior work, we proposed a cross-domain VAE-VC (CDVAE-VC) framework, which utilized acoustic features of different properties, to improve the performance of VAE-VC. We believed that the success came from more disentangled latent representations. In this article, we extend the CDVAE-VC framework by incorporating the concept of adversarial learning, in order to further increase the degree of disentanglement, thereby improving the quality and similarity of converted speech. More specifically, we first investigate the effectiveness of incorporating the generative adversarial networks (GANs) with CDVAE-VC. Then, we consider the concept of domain adversarial training and add an explicit constraint to the latent representation, realized by a speaker classifier, to explicitly eliminate the speaker information that resides in the latent code. Experimental results confirm that the degree of disentanglement of the learned latent representation can be enhanced by both GANs and the speaker classifier. Meanwhile, subjective evaluation results in terms of quality and similarity scores demonstrate the effectiveness of our proposed methods.","2471-285X","","10.1109/TETCI.2020.2977678","MOST-Taiwan(grant numbers:MOST 107-2221-E-001-008-MY3,MOST 108-2634-F-001-004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9057379","Voice conversion;unsupervised learning;disentangled representation;variational autoencoder;adversarial learning;cross domain features","Training;Gallium nitride;Decoding;Measurement;Speech processing;Vocoders;Task analysis","learning (artificial intelligence);neural nets;speaker recognition;speech processing","speaker classifier;linguistic content;generative adversarial networks;CDVAE-VC framework;disentangled latent representations;acoustic features;cross-domain VAE-VC framework;speech signal;voice conversion;variational autoencoder;adversarial learning;cross domain features;unsupervised representation disentanglement;learned latent representation;domain adversarial training","","9","","76","CCBY","6 Apr 2020","","","IEEE","IEEE Journals"
"Audio Source Separation Using Variational Autoencoders and Weak Class Supervision","E. Karamatlı; A. T. Cemgil; S. Kırbız","Department of Computer Engineering, Boğaziçi University, İstanbul, Turkey; Department of Computer Engineering, Boğaziçi University, İstanbul, Turkey; Department of Electrical and Electronics Engineering, MEF University, İstanbul, Turkey","IEEE Signal Processing Letters","5 Aug 2019","2019","26","9","1349","1353","In this letter, we propose a source separation method that is trained by observing the mixtures and the class labels of the sources present in the mixture without any access to isolated sources. Since our method does not require source class labels for every time-frequency bin but only a single label for each source constituting the mixture signal, we call this scenario as weak class supervision. We associate a variational autoencoder (VAE) with each source class within a nonnegative (compositional) model. Each VAE provides a prior model to identify the signal from its associated class in a sound mixture. After training the model on mixtures, we obtain a generative model for each source class and demonstrate our method on one-second mixtures of utterances of digits from 0 to 9. We show that the separation performance obtained by source class supervision is as good as the performance obtained by source signal supervision.","1558-2361","","10.1109/LSP.2019.2929440","Scientific and Technological Research Council of Turkey (TÜBİTAK)(grant numbers:215E076); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8769885","Weak Supervision;Source Separation;Variational Autoencoders","Source separation;Training;Spectrogram;Decoding;Time-frequency analysis;Instruments;Convolution","audio signal processing;neural nets;source separation","weak class supervision;source separation method;isolated sources;source class labels;time-frequency bin;single label;mixture signal;variational autoencoder;nonnegative model;associated class;sound mixture;separation performance;source class supervision;source signal supervision;audio source separation","","9","","20","IEEE","23 Jul 2019","","","IEEE","IEEE Journals"
"Dataset Recommendation via Variational Graph Autoencoder","B. Altaf; U. Akujuobi; L. Yu; X. Zhang","King Abdullah University of Science and Technology (KAUST), Saudi Arabia; King Abdullah University of Science and Technology (KAUST), Saudi Arabia; King Abdullah University of Science and Technology (KAUST), Saudi Arabia; King Abdullah University of Science and Technology (KAUST), Saudi Arabia","2019 IEEE International Conference on Data Mining (ICDM)","30 Jan 2020","2019","","","11","20","This paper targets on designing a query-based dataset recommendation system, which accepts a query denoting a user's research interest as a set of research papers and returns a list of recommended datasets that are ranked by the potential usefulness for the user's research need. The motivation of building such a system is to save users from spending time on heavy literature review work to find usable datasets.We start by constructing a two-layer network: one layer of citation network, and the other layer of datasets, connected to the firstlayer papers in which they were used. A query highlights a set of papers in the citation layer. However, answering the query as a naive retrieval of datasets linked with these highlighted papers excludes other semantically relevant datasets, which widely exist several hops away from the queried papers. We propose to learn representations of research papers and datasets in the two-layer network using heterogeneous variational graph autoencoder, and then compute the relevance of the query to the dataset candidates based on the learned representations. Our ranked datasets shown in extensive evaluation results are validated to be more truly relevant than those obtained by naive retrieval methods and adoptions of existing related solutions.","2374-8486","978-1-7281-4604-1","10.1109/ICDM.2019.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8970775","dataset-recommendation;query-based-recommendation;heterogeneous-variational-graph-autoencoder","","citation analysis;data mining;graph theory;learning (artificial intelligence);neural nets;query processing;recommender systems","two-layer network;citation network;citation layer;heterogeneous variational graph autoencoder;dataset candidates;query-based dataset recommendation system","","9","","42","","30 Jan 2020","","","IEEE","IEEE Conferences"
"Recent Advances in Variational Autoencoders With Representation Learning for Biomedical Informatics: A Survey","R. Wei; A. Mahmood","Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, USA; Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, USA","IEEE Access","11 Jan 2021","2021","9","","4939","4956","Variational autoencoders (VAEs) are deep latent space generative models that have been immensely successful in multiple exciting applications in biomedical informatics such as molecular design, protein design, medical image classification and segmentation, integrated multi-omics data analyses, and large-scale biological sequence analyses, among others. The fundamental idea in VAEs is to learn the distribution of data in such a way that new meaningful data with more intra-class variations can be generated from the encoded distribution. The ability of VAEs to synthesize new data with more representation variance at state-of-art levels provides hope that the chronic scarcity of labeled data in the biomedical field can be resolved. Furthermore, VAEs have made nonlinear latent variable models tractable for modeling complex distributions. This has allowed for efficient extraction of relevant biomedical information from learned features for biological data sets, referred to as unsupervised feature representation learning. In this article, we review the various recent advancements in the development and application of VAEs for biomedical informatics. We discuss challenges and future opportunities for biomedical research with respect to VAEs.","2169-3536","","10.1109/ACCESS.2020.3048309","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311619","Deep learning;variational autoencoders (VAEs);data representation;generative models;unsupervised learning;representation learning;latent space;biomedical informatics","Bioinformatics;Biological system modeling;Data models;Training;Mathematical model;Deep learning;Decoding","bioinformatics;data analysis;feature extraction;genomics;learning (artificial intelligence);proteins","variational autoencoders;biomedical informatics;deep latent space generative models;molecular design;protein design;medical image classification;medical image segmentation;integrated multiomics data analyses;large-scale biological sequence analyses;meaningful data;intra-class variations;encoded distribution;representation variance;biomedical field;nonlinear latent variable models;complex distributions;relevant biomedical information;biological data sets;unsupervised feature representation learning;biomedical research;VAE;data distribution","","8","","145","CCBY","31 Dec 2020","","","IEEE","IEEE Journals"
"Spatial Revising Variational Autoencoder-Based Feature Extraction Method for Hyperspectral Images","W. Yu; M. Zhang; Y. Shen","Department of Control Science and Engineering, Harbin Institute of Technology, Harbin, China; Department of Control Science and Engineering, Harbin Institute of Technology, Harbin, China; Department of Control Science and Engineering, Harbin Institute of Technology, Harbin, China","IEEE Transactions on Geoscience and Remote Sensing","20 Jan 2021","2021","59","2","1410","1423","Hyperspectral image with high dimensionality always increases the computational consumption, which challenges image processing. Deep learning models have achieved extraordinary success in various image processing domains, which are effective to improve classification performance. There remain considerable challenges in fully extracting abundant spectral information, such as the combination of spatial and spectral information. In this article, a novel unsupervised hyperspectral feature extraction architecture based on spatial revising variational autoencoder (AE) (UHfeSRVAE) is proposed. The core concept of this method is extracting spatial features via designed networks from multiple aspects for the revision of the obtained spectral features. Multilayer encoder extracts spectral features, and then, latent space vectors are generated from the obtained means and standard deviations. Spatial features based on local sensing and sequential sensing are extracted using multilayer convolutional neural networks and long short-term memory networks, respectively, which can revise the obtained mean vectors. Besides, the proposed loss function guarantees the consistency of the probability distributions of various latent spatial features, which obtained from the same neighbor region. Several experiments are conducted on three publicly available hyperspectral data sets, and the experimental results show that UHfeSRVAE achieves better classification results compared with comparison methods. The combination of spatial feature extraction models and deep AE models is designed based on the unique characteristics of hyperspectral images, which contributes to the performance of this method.","1558-0644","","10.1109/TGRS.2020.2997835","National Natural Science Foundation of China(grant numbers:61876054); Postdoctoral Scientific Research Developmental Fund of Heilongjiang Province(grant numbers:LBH-Q17078); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9109663","Convolutional neural network (CNN);deep learning;feature extraction;hyperspectral image;variational autoencoder (VAE)","Feature extraction;Hyperspectral imaging;Data mining;Standards;Data models;Sensors","convolutional neural nets;feature extraction;image classification;learning (artificial intelligence);neural nets","spatial revising variational autoencoder-based feature extraction method;hyperspectral image;deep learning models;image processing domains;abundant spectral information;spatial information;hyperspectral feature extraction architecture;hfe SRVAE;multilayer convolutional neural networks;short-term memory networks;latent spatial features;publicly available hyperspectral data sets;spatial feature extraction models","","8","","48","IEEE","5 Jun 2020","","","IEEE","IEEE Journals"
"Continual Learning for Anomaly Detection with Variational Autoencoder","F. Wiewel; B. Yang","Institute of Signal Processing and System Theory, University of Stuttgart, Germany; Institute of Signal Processing and System Theory, University of Stuttgart, Germany","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","3837","3841","Detecting anomalies using a variational autoencoder (VAE) suffers from catastrophic forgetting when trained on a continually growing set of normal data where only the most recently added data is available. Solving this problem would allow the use of the VAE for anomaly detection in settings where it is difficult or even impossible to retain all normal data at the same time. We propose an efficient extension of a method for continual learning which alleviates catastrophic forgetting for anomaly detection using a VAE. We show on some anomaly detection problems that the definition of normal data can be continually expanded without requiring all previously seen data.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682702","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682702","Continual Learning;Anomaly Detection;Variational Autoencoder;Generative Replay","Task analysis;Training;Anomaly detection;Decoding;Neural networks;Generators;Generative adversarial networks","learning (artificial intelligence);neural nets;security of data","VAE;continual learning;catastrophic forgetting;anomaly detection problems;variational autoencoder","","8","","20","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Unsupervised Health Indicator Construction by a Novel Degradation-Trend-Constrained Variational Autoencoder and Its Applications","Y. Qin; J. Zhou; D. Chen","State Key Laboratory of Mechanical Transmission, Chongqing University, Chongqing, China; State Key Laboratory of Mechanical Transmission, Chongqing University, Chongqing, China; State Key Laboratory of Mechanical Transmission, Chongqing University, Chongqing, China","IEEE/ASME Transactions on Mechatronics","15 Jun 2022","2022","27","3","1447","1456","Health indicator (HI) affects the accuracy and reliability of the remaining useful life (RUL) prediction model. The hidden variables of variational autoencoder (VAE) can represent the HI values for a life-cycle dataset with obvious degradation trend. However, for an irregular dataset of a rotary machine, it is still a great challenge to construct the HI that can effectively represent the machinery degradation tendency. Therefore, this article proposes a novel degradation-trend-constrained VAE (DTC-VAE) to construct the HI vector with the distinct degradation trend. First, the multidimensional time-domain and frequency-domain characteristics are calculated via the collected vibration samples. Second, a new degradation-constraint loss term is proposed and introduced into VAE for constructing DTC-VAE. Third, with the multidimensional features and DTC-VAE, various HIs can be generated without supervision. The proposed method is applied to construct the HI vectors of bearing life-cycle datasets and gear fatigue datasets, and then macroscopic-microscopic-attention-based long short term memory (MMALSTM) is used to predict the corresponding RULs with the constructed HIs. Via several contrast experiments, the results prove that the proposed unsupervised HI construction approach is superior to other typical methods, and the obtained HI vectors are more suitable for the RUL prediction.","1941-014X","","10.1109/TMECH.2021.3098737","National Natural Science Foundation of China(grant numbers:52175075,62033001,91748116); Graduate Scientific and Innovation Foundation of Chongqing(grant numbers:CYS21009); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9492834","Health indicator (HI);multidimensional features;nonsupervision;remaining useful life (RUL);variational autoencoder (VAE)","Degradation;Market research;Feature extraction;Mechatronics;IEEE transactions;Vibrations;Gears","condition monitoring;fatigue;gears;machine bearings;mechanical engineering computing;recurrent neural nets;remaining life assessment;vibrations","rotary machine;machinery degradation tendency;DTC-VAE;HI vector;frequency-domain characteristics;collected vibration samples;degradation-constraint loss term;life-cycle dataset;unsupervised HI construction approach;RUL prediction;unsupervised health indicator construction;reliability;remaining useful life prediction model;HI values;degradation-trend-constrained variational autoencoder;gear fatigue datasets;degradation-trend-constrained VAE;macroscopic-microscopic-attention-based long short term memory;MMALSTM","","7","","36","IEEE","21 Jul 2021","","","IEEE","IEEE Journals"
"Desertification Detection Using an Improved Variational Autoencoder-Based Approach Through ETM-Landsat Satellite Data","Y. Zerrouki; F. Harrou; N. Zerrouki; A. Dairi; Y. Sun","Conservatoire National des Formations à l'Environnement, Bab El Oued, Algeria; Computer, Electrical and Mathematical Sciences and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Center for Development of Advanced Technologies, Baba Hassen, Algeria; Department of Computer Science, SIMPA Laboratory, University of Science and Technology of Oran–Mohamed Boudiaf, Bir El Djir, Algeria; Computer, Electrical and Mathematical Sciences and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","7 Jan 2021","2021","14","","202","213","The accurate land cover change detection is critical to improve the landscape dynamics analysis and mitigate desertification problems efficiently. Desertification detection is a challenging problem because of the high degree of similarity between some desertification cases and like-desertification phenomena, such as deforestation. This article provides an effective approach to detect deserted regions based on Landsat imagery and variational autoencoder (VAE). The VAE model, as a deep learning-based model, has gained special attention in features extraction and modeling due to its distribution-free assumptions and superior nonlinear approximation. Here, a VAE approach is applied to spectral signatures for detecting pixels affected by the land cover change. The considered features are extracted from multitemporal images and include multispectral information, and no prior image segmentation is required. The proposed method was evaluated on the publicly available remote sensing data using multitemporal Landsat optical images taken from the freely available Landsat program. The arid region around Biskra in Algeria is selected as a study area since it is well-known that desertification phenomena strongly influence this region. The VAE model was evaluated and compared with restricted Boltzmann machines, deep learning model, and binary clustering algorithms, including Agglomerative, BIRCH, expected maximization, k-mean clustering algorithms, and one-class support vector machine. The comparative results showed that the VAE consistently outperformed the other models for detecting changes to the land cover, mainly deserted regions. This study also showed that VAE outperformed the state-of-the-art algorithms.","2151-1535","","10.1109/JSTARS.2020.3042760","King Abdullah University of Science and Technology; Office of Sponsored Research(grant numbers:OSR-2019-CRG7-3800); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9285171","Desertification detection;feature extraction;Landsat sensors;variational autoencoder (VAE) classification","Remote sensing;Feature extraction;Deep learning;Earth;Artificial satellites;Vegetation mapping;Indexes","feature extraction;geomorphology;geophysical image processing;image classification;image segmentation;learning (artificial intelligence);support vector machines;terrain mapping;vegetation mapping","desertification detection;variational autoencoder-based approach;ETM-Landsat satellite data;land cover change detection;landscape dynamics analysis;desertification problems;desertification cases;like-desertification phenomena;deserted regions;VAE model;deep learning-based model;features extraction;distribution-free assumptions;superior nonlinear approximation;multitemporal images;image segmentation;publicly available remote sensing data;multitemporal Landsat optical images;deep learning model;Landsat program","","7","","33","CCBY","7 Dec 2020","","","IEEE","IEEE Journals"
"Refined WaveNet Vocoder for Variational Autoencoder Based Voice Conversion","W. -C. Huang; Y. -C. Wu; H. -T. Hwang; P. L. Tobing; T. Hayashi; K. Kobayashi; T. Toda; Y. Tsao; H. -M. Wang","Academia Sinica, Taiwan; Nagoya University, Japan; Academia Sinica, Taiwan; Nagoya University, Japan; Nagoya University, Japan; Nagoya University, Japan; Nagoya University, Japan; Academia Sinica, Taiwan; Academia Sinica, Taiwan","2019 27th European Signal Processing Conference (EUSIPCO)","18 Nov 2019","2019","","","1","5","This paper presents a refinement framework of WaveNet vocoders for variational autoencoder (VAE) based voice conversion (VC), which reduces the quality distortion caused by the mismatch between the training data and testing data. Conventional WaveNet vocoders are trained with natural acoustic features but conditioned on the converted features in the conversion stage for VC, and such a mismatch often causes significant quality and similarity degradation. In this work, we take advantage of the particular structure of VAEs to refine WaveNet vocoders with the self-reconstructed features generated by VAE, which are of similar characteristics with the converted features while having the same temporal structure with the target natural features. We analyze these features and show that the self-reconstructed features are similar to the converted features. Objective and subjective experimental results demonstrate the effectiveness of our proposed framework.","2076-1465","978-9-0827-9703-9","10.23919/EUSIPCO.2019.8902651","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902651","voice conversion;variational autoencoder;WaveNet vocoder;speaker adaptation","Vocoders;Training;Training data;Feature extraction;Europe;Signal processing;Acoustics","feature extraction;learning (artificial intelligence);speech coding;vocoders","WaveNet vocoder;self-reconstructed features;VAE;converted features;target natural features;refinement framework;variational autoencoder based voice conversion;quality distortion;training data;testing data;conventional WaveNet vocoders;natural acoustic features;conversion stage;significant quality;similarity degradation","","7","","27","","18 Nov 2019","","","IEEE","IEEE Conferences"
"An Integrated Framework Based on Latent Variational Autoencoder for Providing Early Warning of At-Risk Students","X. Du; J. Yang; J. -L. Hung","National Engineering Research Center for E-Learning, Central China Normal University, Wuhan, China; National Engineering Research Center for E-Learning, Central China Normal University, Wuhan, China; National Engineering Laboratory for Educational Big Data, Central China Normal University, Wuhan, China","IEEE Access","16 Jan 2020","2020","8","","10110","10122","The rapid development of learning technologies has enabled online learning paradigm to gain great popularity in both high education and K-12, which makes the prediction of student performance become one of the most popular research topics in education. However, the traditional prediction algorithms are originally designed for balanced dataset, while the educational dataset typically belongs to highly imbalanced dataset, which makes it more difficult to accurately identify the at-risk students. In order to solve this dilemma, this study proposes an integrated framework (LVAEPre) based on latent variational autoencoder (LVAE) with deep neural network (DNN) to alleviate the imbalanced distribution of educational dataset and further to provide early warning of at-risk students. Specifically, with the characteristics of educational data in mind, LVAE mainly aims to learn latent distribution of at-risk students and to generate at-risk samples for the purpose of obtaining a balanced dataset. DNN is to perform final performance prediction. Extensive experiments based on the collected K-12 dataset show that LVAEPre can effectively handle the imbalanced education dataset and provide much better and more stable prediction results than baseline methods in terms of accuracy and F1.5 score. The comparison of t-SNE visualization results further confirms the advantage of LVAE in dealing with imbalanced issue in educational dataset. Finally, through the identification of the significant predictors of LVAEPre in the experimental dataset, some suggestions for designing pedagogical interventions are put forward.","2169-3536","","10.1109/ACCESS.2020.2964845","National Natural Science Foundation of China(grant numbers:61877027); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952699","Performance prediction;early warning prediction;latent variational autoencoder;resampling methods;deep neural network;t-SNE","Education;Predictive models;Gallium nitride;Time-frequency analysis;Neural networks;Data models;Biological system modeling","data mining;data visualisation;educational administrative data processing;learning (artificial intelligence);neural nets;pattern classification","LVAE;latent distribution;at-risk students;at-risk samples;balanced dataset;final performance prediction;LVAEPre;imbalanced education dataset;stable prediction results;educational dataset;experimental dataset;integrated framework;latent variational autoencoder;learning technologies;great popularity;high education;student performance;popular research topics;traditional prediction algorithms;highly imbalanced dataset;imbalanced distribution;educational data","","6","","65","CCBY","8 Jan 2020","","","IEEE","IEEE Journals"
"Latent Space Expanded Variational Autoencoder for Sentence Generation","T. Song; J. Sun; B. Chen; W. Peng; J. Song","College of Information Science and Technology, Beijing Normal University, Beijing, China; College of Information Science and Technology, Beijing Normal University, Beijing, China; College of Information Science and Technology, Beijing Normal University, Beijing, China; College of Information Science and Technology, Beijing Normal University, Beijing, China; College of Information Science and Technology, Beijing Normal University, Beijing, China","IEEE Access","14 Oct 2019","2019","7","","144618","144627","Sentence generation is a key task in many natural language processing systems. Models based on a variational autoencoder (VAE) can generate plausible sentences from a continuous latent space. However, the VAE forces the latent distribution of each input sentence to match the same prior, which results in a large overlap among the latent subspaces of different sentences and a limited informative latent space. Therefore, the sentences generated by sampling from a subspace may have little correlation with the corresponding input, and the latent space cannot capture rich useful information from the input sentences, which leads to the failure of the model to generate diverse sentences from the latent space. Additionally, the Kullback-Leibler (KL) divergence collapse problem makes the VAE notoriously difficult to train. In this paper, a latent space expanded VAE (LSE-VAE) model is presented for sentence generation. The model maps each sentence to a continuous latent subspace under the constraint of its own prior distribution, and constrains nearby sentences to map to nearby subspaces. Sentences are dispersed to a large continuous latent space according to sentence similarity, where the latent subspaces of different sentences may be relatively far away from each other and arranged in an orderly manner. The experimental results show that the LSE-VAE improves the reconstruction ability of the VAE, generates plausible and more diverse sentences, and learns a larger informative latent space than the VAE with the properties of continuity and smoothness. The LSE-VAE does not suffer from the KL collapse problem, and it is robust to hyperparameters and much easier to train.","2169-3536","","10.1109/ACCESS.2019.2944630","National Natural Science Foundation of China(grant numbers:61877004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8853312","Latent space;natural language processing;sentence generation;variational autoencoder","Decoding;Task analysis;Generative adversarial networks;Gallium nitride;Natural language processing;Solid modeling;Interpolation","natural language processing;text analysis","latent space expanded variational autoencoder;sentence generation;plausible sentences;continuous latent space;VAE forces;latent distribution;input sentence;diverse sentences;VAE model;LSE-VAE;sentence similarity;informative latent space;continuous latent subspaces","","5","","45","CCBY","30 Sep 2019","","","IEEE","IEEE Journals"
"Speech Source Separation Using Variational Autoencoder and Bandpass Filter","H. D. Do; S. T. Tran; D. T. Chau","AI Lab, OLLI Technology JSC, Ho Chi Minh City, Vietnam; Office of Education and Training, University of Science, Ho Chi Minh City, Vietnam; Viet Nam National University, Ho Chi Minh City, Vietnam","IEEE Access","2 Sep 2020","2020","8","","156219","156231","Speech source separation is essential for speech-related applications because this process enhances the input speech signal for the main processing model. Most of the current approaches for this task focus on separating the speech of commonly high-frequency noises or a particular background sound. They cannot clear the signals which intersect with the human speech in its frequency range. To deal with this problem, we propose a hybrid approach combining a variational autoencoder (VAE) and a bandpass filter (BPF). This method can extract and enhance the speech signal in the mixture of many elements such as speech signal, the high-frequency noises, and many kinds of different background sounds which interfere with the speech sound. Experimental results showed that our model can extract effectively the speech signal with 15.02 dB in Signal to Interference Ratio (SIR) and 12.99 dB in Signal to Distortion Ratio (SDR). On the other hand, we can adjust the passband to identify the range of frequency at the output signal to apply for a particular application like gender classification.","2169-3536","","10.1109/ACCESS.2020.3019495","OLLI Technology JSC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9178274","Generative model;variational autoencoder;bandpass filter;speech separation","Speech enhancement;Blind source separation;Band-pass filters;Music;Multiple signal classification","band-pass filters;source separation;speech processing","speech source separation;variational autoencoder;bandpass filter;speech-related applications;input speech signal;processing model;high-frequency noises;background sound;signals which intersect;human speech;speech sound;output signal","","5","","44","CCBY","26 Aug 2020","","","IEEE","IEEE Journals"
"nnSpeech: Speaker-Guided Conditional Variational Autoencoder for Zero-Shot Multi-speaker text-to-speech","B. Zhao; X. Zhang; J. Wang; N. Cheng; J. Xiao","Institute of Science and Technology for Brain-Inspired Intelligence, Fudan University, China; Ping An Technology (Shenzhen) Co., Ltd., China; Ping An Technology (Shenzhen) Co., Ltd., China; Ping An Technology (Shenzhen) Co., Ltd., China; Ping An Technology (Shenzhen) Co., Ltd., China","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","4293","4297","Multi-speaker text-to-speech (TTS) using a few adaption data is a challenge in practical applications. To address that, we propose a zero-shot multi-speaker TTS, named nnSpeech, that could synthesis a new speaker voice without fine-tuning and using only one adaption utterance. Compared with using a speaker representation module to extract the characteristics of new speakers, our method bases on a speaker-guided conditional variational autoencoder and can generate a variable Z, which contains both speaker characteristics and content information. The latent variable Z distribution is approximated by another variable conditioned on reference mel-spectrogram and phoneme. Experiments on the English corpus, Mandarin corpus, and cross-dataset proves that our model could generate natural and similar speech with only one adaption speech.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746875","Research and Development; Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746875","zero-shot;multi-speaker text-to-speech;conditional variational autoencoder","Adaptation models;Analytical models;Conferences;Signal processing;Acoustics;Decoding;Data mining","feature extraction;natural language processing;neural nets;speaker recognition;speech processing;speech synthesis","zero-shot multispeaker TTS;speaker voice;speaker representation module;speaker-guided conditional variational autoencoder;speaker characteristics;adaption speech;zero-shot multispeaker text-to-speech;nnSpeech;adaption utterance;content information;latent variable Z distribution;reference mel-spectrogram;English corpus;Mandarin corpus;natural speech;similar speech","","4","","23","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Advances Toward the Next Generation Fire Detection: Deep LSTM Variational Autoencoder for Improved Sensitivity and Reliability","Z. Xu; Y. Guo; J. H. Saleh","School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Access","24 Feb 2021","2021","9","","30636","30653","Fire detection is a critical component of a building safety monitoring system and remains an important research area with weighty practical relevance. Significant advances have occurred in recent years in building automation, and the operation of buildings has become more complex and requires ever more effective monitoring systems. In this work, we develop a novel fire detection method using deep Long-Short Term Memory (LSTM) neural networks and variational autoencoder (VAE) to meet these increasingly stringent requirements and outperform existing fire detection methods. To evaluate the effectiveness of our method, we develop high-fidelity simulations, and we use datasets from real-world fire and non-fire experiments provided by NIST. We compare and discuss the performance of our proposed fire detection with alternative methods, including the standard LSTM, cumulative sum control chart (CUSUM), exponentially weighted moving average (EWMA), and two currently used fixed-temperature heat detectors. The results using the simulation-based and the real-world experiments are complementary, and they indicate that the LSTM-VAE robustly outperforms the other detection methods with, for example, statistically significant shorter alarm time lags, no missed detection, and no false alarms. The results also identify shortcomings of other detection methods and indicate a clear ranking among them (LSTM-VAE>-EWMA >LSTM>-CUSUM).","2169-3536","","10.1109/ACCESS.2021.3060338","Space Technology Research Institute grant from NASA’s Space Technology Research Grant Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9357405","Fire detection;machine learning;anomaly detection;long short-term memory;variational autoencoder","Anomaly detection;Sensitivity;Reliability;Buildings;Monitoring;Training;Safety","alarm systems;building management systems;condition monitoring;control charts;fires;moving average processes;production engineering computing;recurrent neural nets;reliability;sensitivity","deep LSTM variational autoencoder;building safety monitoring system;building automation;fire detection method;reliability;sensitivity analysis;Long-Short Term Memory neural networks;VAE;cumulative sum control chart;CUSUM;weighted moving average;EWMA;fixed-temperature heat detectors;statistical analysis;alarm systems","","4","","48","CCBY","18 Feb 2021","","","IEEE","IEEE Journals"
"Joint Source-Channel Coding Over Additive Noise Analog Channels Using Mixture of Variational Autoencoders","Y. M. Saidutta; A. Abdi; F. Fekri","Department of Electrical and Computer Engineering, Geogia Institute of Technology, Atlanta, GA, USA; Qualcomm Technologies, Inc., San Diego, CA, USA; Department of Electrical and Computer Engineering, Geogia Institute of Technology, Atlanta, GA, USA","IEEE Journal on Selected Areas in Communications","16 Jun 2021","2021","39","7","2000","2013","In this paper, we present a learning scheme for Joint Source-Channel Coding (JSCC) over analog independent additive noise channels. We formulate the learning problem by showing that the minimization loss function from rate-distortion theory, is upper bounded by the loss function of the Variational Autoencoder (VAE). We show that when the source dimension is greater than the channel dimension, the encoding of two source samples in the neighborhood of each other need not be near each other. Such discontinuous projection needs to be accounted for by using multiple encoders and selecting an encoder to encode samples on a particular side of the discontinuity. We explore two selection methodologies, one based on an intuitive rule and the other where it is posed as a learning task in a Mixture-of-Experts (MoE) setup. We analyze the gradients of these methods and reason why the latter is better at avoiding local optima. We show the efficacy of the proposed methodology by simulating the performance of the system for JSCC of Gaussian sources over AWGN channels and showing that the learned solutions are close to or better than the ones proposed earlier. The proposed methodology is also naturally capable of generalizing to other source distributions which we showcase by simulating for Laplace sources. The learned systems are also robust to changes in channel conditions. Further, a single system can be trained to generalize over a range of channel conditions provided the channel conditions are known at both the transmitter and the receiver. Finally, we evaluate our proposed methodology on three different image datasets and showcase consistent improvement over existing methods due to the VAE formulation.","1558-0008","","10.1109/JSAC.2021.3078489","National Science Foundation(grant numbers:ID MLWiNS-2003002); Intel Company; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9427220","Joint source-channel coding;machine learning;deep learning;Variational Autoencoders","Decoding;Training;AWGN channels;Neural networks;Channel coding;Scalability;Optimization","AWGN channels;combined source-channel coding;learning (artificial intelligence);minimisation;neural nets;rate distortion theory;telecommunication computing","joint source-channel coding;additive noise analog channels;analog independent additive noise channels;learning problem;minimization loss function;source dimension;channel dimension;multiple encoders;Gaussian sources;AWGN channels;Laplace sources;variational autoencoders;rate-distortion theory;discontinuous projection;VAE formulation;mixture-of-experts setup;local optima","","4","","58","IEEE","10 May 2021","","","IEEE","IEEE Journals"
"Multilevel Anomaly Detection Through Variational Autoencoders and Bayesian Models for Self-Aware Embodied Agents","G. Slavic; M. Baydoun; D. Campo; L. Marcenaro; C. Regazzoni","DITEN, University of Genoa Faculty of Engineering, Genova, Italy; DITEN, Universitá degli Studi di Genova, Genova, Italy; DITEN, Universitá degli Studi di Genova, Genova, Italy; DITEN, Universitá degli Studi di Genova, Genova, Italy; DITEN, Universitá degli Studi di Genova, Genova, Italy","IEEE Transactions on Multimedia","29 Mar 2022","2022","24","","1399","1414","Anomaly detection constitutes a fundamental step in developing self-aware autonomous agents capable of continuously learning from new situations, as it enables to distinguish novel experiences from already encountered ones. This paper combines Dynamic Bayesian Networks (DBNs) and Neural Networks (NNs) and proposes a method for detecting anomalies in video data at different abstraction levels. We use a Variational Autoencoder (VAE) to reduce the dimensionality of video frames, and Optical Flows between subsequent images, generating a latent space that captures both visual and dynamical information and that is comparable to low-dimensional sensory data (e.g., positioning, steering angle). An Adapted Markov Jump Particle Filter is employed to predict the following frames and detect anomalies in video data. Our method’s evaluation is executed using different video data from a semi-autonomous vehicle performing different tasks in a closed environment. Tests on benchmark anomaly detection datasets have additionally been conducted.","1941-0077","","10.1109/TMM.2021.3065232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9376891","Anomaly detection;kalman filtering;particle filtering;variational autoencoder","Feature extraction;Anomaly detection;Predictive models;Image reconstruction;Self-aware;Probabilistic logic;Data models","Bayes methods;belief networks;image sequences;Markov processes;mobile robots;multi-agent systems;neural nets;object detection;particle filtering (numerical methods)","video frames;visual information;dynamical information;low-dimensional sensory data;adapted Markov jump particle filter;video data;semiautonomous vehicle;benchmark anomaly detection datasets;self-aware embodied agents;self-aware autonomous agents;abstraction levels;variational autoencoder;Bayesian models;VAE;anomaly detection;optical flows;subsequent images","","4","","70","IEEE","12 Mar 2021","","","IEEE","IEEE Journals"
"Multi-Speaker and Multi-Domain Emotional Voice Conversion Using Factorized Hierarchical Variational Autoencoder","M. Elgaar; J. Park; S. W. Lee",KAIST; KAIST; KAIST,"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","7769","7773","Due to the complexity of emotional features, there has been limited success in emotional voice conversion. One major challenge is that conversion between more than two kinds of emotions often accompanies distortion of voice signal.The factorized hierarchical variational autoencoder (FHVAE) [1] was previously shown to have an ability, called sequence-level regularization, to generate disentangled representations of both sequence-level (such as speaker identity) and segment-level features. This study exploits the FHVAE pipeline to produce disentangled representations of emotion, making it possible to greatly facilitate emotional voice conversion.We propose three versions of algorithms for improving the quality of disentangled representation and audio synthesis. We conducted three mean opinion score (MOS) surveys to assess the performance of our models in terms of 1) speaker’s voice preservation, 2) emotion conversion, and 3) audio naturalness.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9054534","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054534","Emotional Voice Conversion;Variational Autoencoder;Disentangled Representation;Style Transfer","Acoustic distortion;Conferences;Pipelines;Signal processing algorithms;Acoustics;Complexity theory;Speech processing","audio signal processing;emotion recognition;neural nets;speaker recognition","audio naturalness;speaker voice preservation;audio synthesis;sequence-level features;sequence-level regularization;multispeaker emotional voice conversion;multidomain emotional voice conversion;segment-level features;speaker identity;disentangled representation;factorized hierarchical variational autoencoder;voice signal distortion","","3","","25","IEEE","9 Apr 2020","","","IEEE","IEEE Conferences"
"Interpreting Variational Autoencoders with Fuzzy Logic: A step towards interpretable deep learning based fuzzy classifiers","K. Bölat; T. Kumbasar","Department of Control and Automation Engineering, Istanbul Technical University, Istanbul, Turkey; Department of Control and Automation Engineering, Istanbul Technical University, Istanbul, Turkey","2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)","26 Aug 2020","2020","","","1","7","The emerging success of Deep Learning (DL) in various application areas comes also with the questions starting with ""How""s and ""Why""s. These questions can be answered if the DL methods are interpretable and thus provide a certain a degree of explanation. In this paper, we propose a DL framework that leverages the advantages of β-Variational Autoencoder (VAE) and Fuzzy Sets (FSs), which are disentanglement and linguistic representation, for the design of a novel DL based Fuzzy Classifier (FC). We first present a step-by-step design approach to construct the DL-FC which is composed of the encoder layer of β-VAE and a Fuzzy Logic System (FLS) followed by a softmax layer. The β-VAE is trained so that the semantic information of the high dimensional data is captured. The latent space of the β-VAE is clustered to extract FSs. The FSs are then used to define antecedents of the FLS that is trained with DL methods. We present results conducted on the MNIST dataset and showed that DL-FC is quite competitive with its deep neural network counterpart. We then try to provide an interpretation to the antecedents of FLS by examining the FSs, the latent traversals and heat-maps of each latent dimension. The results show that the antecedents of FLS can be defined with linguistic interpretations. Thus, for the first time in the literature, we showed that linguistic interpretations can be defined for the latent space of β-VAE with FSs.","1558-4739","978-1-7281-6932-3","10.1109/FUZZ48607.2020.9177631","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9177631","Variational autoencoder;fuzzy sets;fuzzy cmeans clustering;classification;interpretation","Frequency selective surfaces;Fuzzy logic;Training;Linguistics;Feature extraction;Machine learning;Clustering algorithms","fuzzy logic;fuzzy set theory;learning (artificial intelligence);neural nets","FSs;deep learning;fuzzy classifiers;DL methods;fuzzy classifier;step-by-step design;fuzzy logic system;FLS;latent space;deep neural network;linguistic interpretations;variational autoencoders","","3","","28","","26 Aug 2020","","","IEEE","IEEE Conferences"
"Power Plant Model Parameter Calibration Using Conditional Variational Autoencoder","S. R. Khazeiynasab; J. Zhao; I. Batarseh; B. Tan","Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL, USA; Department of Electrical and Computer Engineering, Mississippi State University, Starkville, MS, USA; Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL, USA; Department of Electrical and Computer Engineering, Mississippi State University, Starkville, MS, USA","IEEE Transactions on Power Systems","7 Mar 2022","2022","37","2","1642","1652","Accurate models of power plants play an important role in maintaining the reliable and secure grid operations. In this paper, we propose a synchrophasor measurement-based generator parameter calibration method by a novel deep learning method with high computational efficiency. An elementary effects-based approach is developed to identify the critical parameters from a nonlinear system with much better performance than the widely used trajectory sensitivity-based method. Then, synchrophasor measurement-based conditional variational autoencoder is developed to estimate the parameters’ posterior distributions even in the presence of a high-dimensional case with eighteen critical parameters to be calibrated. The effectiveness of the proposed method is validated for a hydro generator with a very detailed model. The results show that the proposed approach can accurately and efficiently estimate the generator parameters’ posterior distributions even when the parameters true values are not in support of the prior distribution.","1558-0679","","10.1109/TPWRS.2021.3107515","U.S. Department of Energy Advanced Grid Modernization Program; National Science Foundation(grant numbers:ECCS-1917308); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9525328","Conditional variational autoencoders;deep learning;elementary effects;parameter estimation;power system dynamics;synchrophasor measurements","Generators;Mathematical model;Calibration;Phasor measurement units;Computational modeling;Power system stability;Data models","calibration;condition monitoring;deep learning (artificial intelligence);phasor measurement;power engineering computing;power grids;power plants;sensitivity analysis","power plant model parameter calibration;reliable grid operations;secure grid operations;synchrophasor measurement-based generator parameter calibration method;deep learning method;high computational efficiency;synchrophasor measurement-based conditional variational autoencoder;hydro generator;generator parameters;trajectory sensitivity-based method;nonlinear system;posterior distributions;prior distribution","","3","","42","IEEE","30 Aug 2021","","","IEEE","IEEE Journals"
"FastMVAE: A Fast Optimization Algorithm for the Multichannel Variational Autoencoder Method","L. Li; H. Kameoka; S. Inoue; S. Makino","Graduate School of Systems and Information Engineering, University of Tsukuba, Ibaraki, Japan; NTT Communication Science Laboratories, Kanagawa, Japan; Graduate School of Systems and Information Engineering, University of Tsukuba, Ibaraki, Japan; Graduate School of Systems and Information Engineering, University of Tsukuba, Ibaraki, Japan","IEEE Access","30 Dec 2020","2020","8","","228740","228753","This paper proposes a fast optimization algorithm for the multichannel variational autoencoder (MVAE) method, a recently proposed powerful multichannel source separation technique. The MVAE method can achieve good source separation performance thanks to a convergence-guaranteed optimization algorithm and the idea of jointly performing multi-speaker separation and speaker identification. However, one drawback is the high computational cost of the optimization algorithm. To overcome this drawback, this paper proposes using an auxiliary classifier VAE, an information-theoretic extension of the conditional VAE (CVAE), to train the generative model of the source spectrograms and using it to efficiently update the parameters of the source spectrogram models at each iteration of the source separation algorithm. We call the proposed algorithm “FastMVAE” (or fMVAE for short). Experimental evaluations revealed that the proposed fast algorithm can achieve high source separation performance in both speaker-dependent and speaker-independent scenarios while significantly reducing the computational time compared to the original MVAE method by more than 90% on both GPU and CPU. However, there is still room for improvement of about 3 dB compared to the original MVAE method.","2169-3536","","10.1109/ACCESS.2020.3045704","JSPS KAKENHI(grant numbers:18J20059); JST CREST(grant numbers:JPMJCR19A3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9298772","Multichannel source separation;multichannel variational autoencoder (MVAE) method;FastMVAE algorithm;auxiliary classifier VAE","Source separation;Spectrogram;Decoding;Task analysis;Neural networks;Optimization;Computational modeling","blind source separation;neural nets;optimisation","fast optimization algorithm;multichannel variational autoencoder method;multichannel source separation technique;convergence-guaranteed optimization algorithm;speaker identification;auxiliary classifier VAE;source spectrogram models;source separation algorithm;speaker-dependent scenario;speaker-independent scenarios;FastMVAE","","3","","59","CCBY","18 Dec 2020","","","IEEE","IEEE Journals"
"Evolving Deep Convolutional Variational Autoencoders for Image Classification","X. Chen; Y. Sun; M. Zhang; D. Peng","College of Computer Science, Sichuan University, Chengdu, China; Sichuan Eface Technology Company Ltd., Chengdu, China; School of Engineering and Computer Science, Victoria University of Wellington, Wellington, New Zealand; Chengdu Sobey Digital Technology Company Ltd., Chengdu, China","IEEE Transactions on Evolutionary Computation","30 Sep 2021","2021","25","5","815","829","Variational autoencoders (VAEs) have demonstrated their superiority in unsupervised learning for image processing in recent years. The performance of the VAEs highly depends on their architectures, which are often handcrafted by the human expertise in deep neural networks (DNNs). However, such expertise is not necessarily available to each of the end users interested. In this article, we propose a novel method to automatically design optimal architectures of VAEs for image classification, called evolving deep convolutional VAE (EvoVAE), based on a genetic algorithm (GA). In the proposed EvoVAE algorithm, the traditional VAEs are first generalized to a more generic and asymmetrical one with four different blocks, and then a variable-length gene encoding mechanism of the GA is presented to search for the optimal network depth. Furthermore, an effective genetic operator is designed to adapt to the proposed variable-length gene encoding strategy. To verify the performance of the proposed algorithm, nine variants of AEs and VAEs are chosen as the peer competitors to perform the comparisons on MNIST, street view house numbers, and CIFAR-10 benchmark datasets. The experiments reveal the superiority of the proposed EvoVAE algorithm, which wins 21 times out of the 24 comparisons and outperforms the best competitors by 1.39%, 14.21%, and 13.03% on the three benchmark datasets, respectively.","1941-0026","","10.1109/TEVC.2020.3047220","National Natural Science Foundation of China(grant numbers:61971296,U19A2078,61836011); Sichuan Science and Technology Planning Project(grant numbers:2020YFG0319,2020YFH0186); Fundamental Research Funds for the Central Universities(grant numbers:YJ201934); Chengdu Key Research and Development Support Plan(grant numbers:2019-YF08-00264-GX); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9306892","Convolutional variational autoencoder;evolving deep learning;genetic algorithm (GA);neural architecture search (NAS)","Computer architecture;Encoding;Task analysis;Approximation algorithms;Training;Genetic algorithms;Computer science","convolutional neural nets;deep learning (artificial intelligence);genetic algorithms;image classification;unsupervised learning","GA;optimal network depth;effective genetic operator;variable-length gene encoding strategy;EvoVAE algorithm;evolving deep convolutional variational autoencoders;image classification;unsupervised learning;image processing;human expertise;deep neural networks;optimal architectures;deep convolutional VAE;genetic algorithm;traditional VAE;variable-length gene encoding mechanism","","3","","66","IEEE","24 Dec 2020","","","IEEE","IEEE Journals"
"Deep Variational Autoencoder: An Efficient Tool for PHM Frameworks","R. Zemouri; M. Lévesque; N. Amyot; C. Hudon; O. Kokoko","Cedric-Lab, CNAM, HESAM université, Paris, France; Institut de Recherche d'Hydro-Québec, Varennes, QC, Canada; Institut de Recherche d'Hydro-Québec (IREQ), Varennes, Canada; Institut de Recherche d'Hydro-Québec (IREQ), Varennes, Canada; Institut de Recherche d'Hydro-Québec (IREQ), Varennes, Canada","2020 Prognostics and Health Management Conference (PHM-Besançon)","12 Jun 2020","2020","","","235","240","Deep learning (DL) has been recently used in several applications of machine health monitoring systems. Unfortunately, most of these DL models are considered as black-boxes with low interpretability. In this research, we propose an original PHM framework based on visual data analysis. The most suitable space dimension for the data visualization is the 2D-space, which necessarily involves a significant reduction from a high-dimensional to a low-dimensional data space. To perform the data analysis and the diagnostic interpretation in a PHM framework, a Variational Autoencoder (VAE) is used jointly with a classifier. The proposed model was evaluated to automatically recognize individual Partial Discharge (PD) sources for hydro generators monitoring.","2166-5656","978-1-7281-5675-0","10.1109/PHM-Besancon49106.2020.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9115491","Variational Autoencoder, data visualization, sys tem health management, diagnosis analysis.","Partial discharges;Dimensionality reduction;Deep learning;Visualization;Data analysis;Data visualization;Generators","condition monitoring;data analysis;data visualisation;hydroelectric generators;learning (artificial intelligence);mechanical engineering computing;neural nets","deep variational autoencoder;deep learning;machine health monitoring systems;black-boxes;PHM framework;visual data analysis;data visualization;low-dimensional data space;hydro generators monitoring;partial discharge sources","","2","","16","","12 Jun 2020","","","IEEE","IEEE Conferences"
"Improving Performance in Software Defect Prediction Using Variational Autoencoder","Z. Eivazpour; M. R. Keyvanpour","Department of Computer Engineering and Data mining laboratory, Alzahra University, Tehran, Iran; Department of Computer Engineering and Data mining laboratory, Alzahra University, Tehran, Iran","2019 5th Conference on Knowledge Based Engineering and Innovation (KBEI)","13 Jun 2019","2019","","","644","649","Software defect prediction (SDP) is a beneficial task to save limited resources in the software testing stage for improving software quality. However, the imbalanced distribution in defect datasets could be a challenge for often machine learning algorithms, an effect on the performance of the algorithms. To overcome this issue, oversampling techniques from the minority class has been adopted. In this work, we suggest a new oversampling method, which trained a variational autoencoder (VAE) to generate synthesized samples aimed for output mimicked minority samples that were then combined with training dataset into an augmented training dataset. In the experiments, we explored ten SDP datasets from the PROMISE freely accessible repository. We measured the performance of the proposed method by comparing it with state-of-the-art oversampling techniques including Random Over-Sampling, SMOTE, Borderline-SMOTE, and ADASYN. Based on the investigation results, the proposed method provides better mean performance of SDP models between all examined techniques.","","978-1-7281-0872-8","10.1109/KBEI.2019.8734915","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8734915","Software Defect Prediction;Variational Autoencoder;Class Imbalance;Over-sampling","Training;Machine learning algorithms;Software;Mathematical model;Decoding;Classification algorithms;Neural networks","learning (artificial intelligence);program testing;sampling methods;software quality","software defect prediction;variational autoencoder;software testing stage;software quality;machine learning algorithms;oversampling method;PROMISE freely accessible repository","","2","","31","","13 Jun 2019","","","IEEE","IEEE Conferences"
"IterVM: An Iterative Model for Single-Particle Cryo-EM Image Clustering Based on Variational Autoencoder and Multi-Reference Alignment","G. Ji; Y. Yang; H. -B. Shen","Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Key Laboratory of System Control and Information Processing Ministry of Education of China, Institute of Image Processing and Pattern Recognition Shanghai Jiao Tong University, Shanghai, China","2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","24 Jan 2019","2018","","","999","1002","Cryo-electron microscopy (cryo-EM) is playing a more and more important role in single-particle structure determination. In order to achieve near-atomic resolution, 2D image analysis is the first and critical step. The main task is to cluster and align images into homogenous groups, and yield more clear images by averaging the images in the same group. The quality of the average images directly influences the reconstruction of 3D structures. The main difficulties lie in that the cryo-EM images are extremely noisy, and the orientation is randomly distributed and unknown. Therefore how to improve the clustering accuracy in such a low signal-to-noise-ratio (SNR) scenario is a key issue in cryo-EM data analysis. In this study, we present a new clustering method, named IterVM, which is an iterative model. In each iteration, it uses an unsupervised generative model, i.e. variational autoencoders (VAE), to learn the latent information contained in the images. After training the models, it obtains the decoded images from the training data and then clusters and aligns them as using a k-means based algorithm. From the experimental results, we find that the decoded images effectively reflect the real projection information such as orientation angles and structural heterogeneity. The results demonstrate that clustering on the decoded images produce better performance compared with the state-of-the-art clustering methods for cryo-EM data.","","978-1-5386-5488-0","10.1109/BIBM.2018.8621474","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8621474","Cryo-electron Microscopy;Variational Autoencoders;Multi-Reference Alignment;Clustering","Signal to noise ratio;Noise measurement;Training;Clustering algorithms;Training data;Microscopy;Proteins","biology computing;data analysis;electron microscopy;image reconstruction;iterative methods;pattern clustering","cryo-electron microscopy;single-particle structure determination;2D image analysis;align images;homogenous groups;clear images;average images;clustering accuracy;signal-to-noise-ratio scenario;cryo-EM data analysis;clustering method;iterative model;unsupervised generative model;decoded images;state-of-the-art clustering methods;single-particle cryo-EM image;variational autoencoder;VAE","","2","","15","","24 Jan 2019","","","IEEE","IEEE Conferences"
"Deep Variational Autoencoders for NPC Behaviour Classification","E. S. Soares; V. Bulitko","Department of Computing Science, University of Alberta, Edmonton, Alberta, Canada; Department of Computing Science, University of Alberta, Edmonton, Alberta, Canada","2019 IEEE Conference on Games (CoG)","26 Sep 2019","2019","","","1","4","Procedural content generation (PCG) can create novel, player-specific content in video games, including behaviours of AI-controlled non-playable characters (NPC). Here we present our first results on comparing unsupervised and supervised machine learning for procedurally generated NPC behaviours. Using an artificial life environment as a stand-in for a video game, we run artificial evolution and generate AI agents with various behaviours. We then train deep variational autoencoders on commonly evolved behaviour and measure its efficacy in detecting behaviours unseen during training. As a reference, we use an off-the-shelf deep network trained in a supervised manner to detect behaviours both seen and unseen during its training. Preliminary results demonstrate promising performance that holds even when the training set contains a mixture of several types of behaviours without proper labels.","2325-4289","978-1-7281-1884-0","10.1109/CIG.2019.8848095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848095","procedural content generation;non-playable-characters;video games;unsupervised machine learning;deep learning;variational autoencoders;anomaly detection","Games;Rabbits;Training;Training data;Image reconstruction;Machine learning;Detectors","artificial intelligence;computer games;neural nets;pattern classification;software agents;supervised learning;unsupervised learning","procedural content generation;player-specific content;AI-controlled nonplayable characters;unsupervised machine learning;AI agents;video games;supervised machine learning;NPC behaviour classification;deep variational autoencoder training","","2","","22","","26 Sep 2019","","","IEEE","IEEE Conferences"
"Monitoring of Nonlinear Processes With Multiple Operating Modes Through a Novel Gaussian Mixture Variational Autoencoder Model","P. Tang; K. Peng; J. Dong; K. Zhang; S. Zhao","Key Laboratory of Knowledge Automation for Industrial Processes of Ministry of Education, School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, China; Key Laboratory of Knowledge Automation for Industrial Processes of Ministry of Education, School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, China; Key Laboratory of Knowledge Automation for Industrial Processes of Ministry of Education, School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, China; Key Laboratory of Knowledge Automation for Industrial Processes of Ministry of Education, School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, China; Key Laboratory of Knowledge Automation for Industrial Processes of Ministry of Education, School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, China","IEEE Access","29 Jun 2020","2020","8","","114487","114500","Customized production, quality variation of raw materials and other factors make industrial processes work in multiple operating modes. In general, complex industrial processes have strong nonlinearity under each operating mode. In this paper, a Gaussian mixture variational autoencoder (GMVAE) model, which combines with Gaussian mixture and VAE, is proposed to monitor nonlinear processes with multiple operating modes. Due to the Gaussian mixture distribution limitation in latent variable space, GMVAE can not only automatically extract features of the nonlinear system, but also make these features follow Gaussian mixture distribution. Based on Gaussian mixture distribution in latent variable space and the reconstruction error, two probability monitoring indexes are constructed, whose control limits can be determined by χ2 distribution. TE benchmark data and real hot strip mill process (HSMP) data have been used to verify the effectiveness of the proposed method.","2169-3536","","10.1109/ACCESS.2020.3003095","Natural Science Foundation of China (NSFC)(grant numbers:61873024,61773053); Fundamental Research Funds for the China Central University of Science and Technology Beijing (USTB), China(grant numbers:FRF-TP-19-049A1Z); National Basic Research Program of China (973 Program)(grant numbers:2017YFB0306403); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9119397","Process monitoring;multiple operating modes;Gaussian mixture variational autoencoder;hot strip mill process","Kernel;Principal component analysis;Probabilistic logic;Feature extraction;Bayes methods","feature extraction;Gaussian distribution;principal component analysis;probability;process monitoring;strips","multiple operating modes;industrial processes work;complex industrial processes;Gaussian mixture distribution limitation;latent variable space;nonlinear system;hot strip mill process data;raw material quality variation;Gaussian mixture variational autoencoder model;HSMP;GMVAE;feature extraction;χ2 distribution;industrial process monitoring","","2","","64","CCBY","17 Jun 2020","","","IEEE","IEEE Journals"
"Improving Deep Reinforcement Learning With Transitional Variational Autoencoders: A Healthcare Application","M. Baucum; A. Khojandi; R. Vasudevan","Department of Industrial, and Systems Engineering, University of Tennessee, Knoxville, TN, USA; Department of Industrial, and Systems Engineering, University of Tennessee, Knoxville, TN, USA; Center for Nanophase Materials Sciences, Oak Ridge National Laboratory, Oak Ridge, TN, USA","IEEE Journal of Biomedical and Health Informatics","3 Jun 2021","2021","25","6","2273","2280","Reinforcement learning is a powerful tool for developing personalized treatment regimens from healthcare data. Yet training reinforcement learning agents through direct interactions with patients is often impractical for ethical reasons. One solution is to train reinforcement learning agents using an `environment model,' which is learned from retrospective patient data, and can simulate realistic patient trajectories. In this study, we propose transitional variational autoencoders (tVAE), a generative neural network architecture that learns a direct mapping between distributions over clinical measurements at adjacent time points. Unlike other models, the tVAE requires few distributional assumptions, and benefits from identical training, and testing architectures. This model produces more realistic patient trajectories than state-of-the-art sequential decision-making models, and generative neural networks, and can be used to learn effective treatment policies.","2168-2208","","10.1109/JBHI.2020.3027443","University of Tennessee; Laboratory Directed Research and Development; U.S. Department of Energy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9209034","Reinforcement learning;hidden Markov models;variational autoencoders;generative adversarial networks;long short-term memory networks","Hidden Markov models;Data models;Neural networks;Training;Trajectory;Biomedical measurement","decision making;health care;learning (artificial intelligence);medical computing;neural nets;patient treatment","improving deep reinforcement learning;transitional variational autoencoders;healthcare application;personalized treatment regimens;healthcare data;training reinforcement;reinforcement learning agents;environment model;retrospective patient data;realistic patient trajectories;generative neural network architecture;direct mapping;state-of-the-art sequential decision-making models;generative neural networks","Delivery of Health Care;Humans;Neural Networks, Computer;Retrospective Studies","2","","28","IEEE","29 Sep 2020","","","IEEE","IEEE Journals"
"Developing a Conditional Variational Autoencoder to Guide Spectral Data Augmentation for Calibration Modeling","G. Mu; J. Chen","School of Information and Control Engineering, Qingdao University of Technology, Qingdao, China; Department of Chemical Engineering, Chung Yuan Christian University, Taoyuan, Taiwan","IEEE Transactions on Instrumentation and Measurement","23 Feb 2022","2022","71","","1","8","To deal with the typically insufficiently labeled samples involved in practical spectroscopy measurements, a conditional variational autoencoder (CVAE) is proposed to guide the spectral data augmentation calibration modeling method for in situ measurement. First, the CVAE is designed to generate the virtual spectra such that the augmentation training set is employed to develop the calibration model. To use the generated unlabeled samples for modeling with online measurement purposes, a semi-supervised ladder network (S2-LN)-based regression learning model is developed. The proposed method incorporates all generated virtual unlabeled samples with real labeled samples. An important advantage of this approach is that it ensures that the generated virtual spectra and the real labeled spectra are the same distribution, which in turn ensures the effectiveness of semi-supervised learning. A numerical simulation example and an experimental example of the glucose fermentation process illustrate the effectiveness of the approach.","1557-9662","","10.1109/TIM.2022.3142060","Ministry of Science and Technology, Taiwan(grant numbers:MOST 109-2221-E-033-060-MY3,MOST 110-2221-E-007-014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684333","Calibration model building;conditional variational autoencoder (CVAE);data augmentation;semi-supervised;virtual sample","Data models;Calibration;Training;Task analysis;Spectroscopy;Semisupervised learning;Numerical models","calibration;fermentation;production engineering computing;regression analysis;supervised learning","guide spectral data augmentation;calibration modeling;practical spectroscopy measurements;conditional variational autoencoder;CVAE;spectral data augmentation calibration;in-situ measurement;augmentation training set;calibration model;generated unlabeled samples;online measurement purposes;semisupervised ladder network;generated virtual unlabeled samples;generated virtual spectra;labeled spectra;semisupervised learning;spectral data augmentation;semisupervised ladder network-based regression learning model;glucose fermentation process","","2","","26","IEEE","17 Jan 2022","","","IEEE","IEEE Journals"
"A Variational Autoencoder-Based Secure Transceiver Design Using Deep Learning","C. -H. Lin; C. -C. Wu; K. -F. Chen; T. -S. Lee","Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC, USA; Center for mmWave Smart Radar Systems and Technologies, National Chiao Tung University, Taiwan; Center for mmWave Smart Radar Systems and Technologies, National Chiao Tung University, Taiwan; Center for mmWave Smart Radar Systems and Technologies, National Chiao Tung University, Taiwan","GLOBECOM 2020 - 2020 IEEE Global Communications Conference","12 Feb 2021","2020","","","1","7","To achieve new applications for 5G communications, physical layer security has recently drawn significant attention. In a wiretap channel system, our goal is to minimize information leakage to an eavesdropper while maximizing the performance of transmission to the desired or legitimate receiver. Complicated systems or channel models make it difficult to design secrecy systems based on the information theory. In this paper, we propose a deep learning-based transceiver design for secrecy systems as an alternative. Specifically, we modify the loss function design of a variational autoencoder, which is a special type of neural network, making it possible to provide both robust data transmission and security in an unsupervised fashion. We further investigate the impact of an imperfect channel state information and use simulation results to prove that our approach can outperform the existing learning-based methods.","2576-6813","978-1-7281-8298-8","10.1109/GLOBECOM42002.2020.9348041","Ministry of Education (MOE) of Taiwan; Ministry of Science and Technology (MOST) of Taiwan(grant numbers:MOST 109-2634-F-009-030,MOST 109-2218-E-009-002,MOSTI09-2823-8-009-004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9348041","physical layer security;wiretap channel;deep learning;neural networks;variational autoencoder","Simulation;Channel estimation;Receivers;Signal processing;Transceivers;Robustness;Security","5G mobile communication;deep learning (artificial intelligence);radio transceivers;telecommunication computing;telecommunication security","variational autoencoder-based secure transceiver design;physical layer security;wiretap channel system;information leakage;legitimate receiver;channel models;secrecy systems;information theory;deep learning-based transceiver design;loss function design;robust data transmission;imperfect channel state information;learning-based methods;5G communications","","2","","21","","12 Feb 2021","","","IEEE","IEEE Conferences"
"Deep Variational Autoencoder Classifier for Intelligent Fault Diagnosis Adaptive to Unseen Fault Categories","A. He; X. Jin","Predictive Informatics Research Lab, Northeastern University, Boston, MA, USA; Predictive Informatics Research Lab, Northeastern University, Boston, MA, USA","IEEE Transactions on Reliability","30 Nov 2021","2021","70","4","1581","1595","With the rapid development of artificial intelligence (AI) in recent years, fault diagnostics for industrial applications have leaped toward partially or fully automatic provided by the capability of analyzing massive condition monitoring data from sensors and actuators. Generally, AI-based fault diagnostics can achieve high accuracy when failure types appear in training dataset and testing dataset are the same. These diagnostic methods could be invalidated for applications dealing with unprecedented faults because the pretrained classifier for diagnostics tends to misclassify the novel instances into existing known classes. In order to address these limitations of conventional diagnostic approaches, we propose a unified diagnostics framework that can achieve novel fault detection and known fault classification tasks together. Through jointly training a variational autoencoder and a deep neural networks classifier, we convert the original entangled raw data into latent variables with Gaussian probabilistic distributions in the latent space and utilize the probabilistic latent variables to detect novel samples against known fault classes or classify them into one of the existing fault classes if they are not novel. The effectiveness of our proposed joint-training framework is validated through experimental studies on two different bearing datasets. Compared with the state-of-the-art methods in the literature, our unified framework is able to not only accurately detect the novel fault classes but also achieve high classification accuracy of known fault classes.","1558-1721","","10.1109/TR.2021.3090310","National Science Foundation(grant numbers:1943801); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9469775","Ball bearing;deep learning (DL);deep variational autoencoder (VAE);intelligent fault diagnostics;novelty detection","Deep learning;Anomaly detection;Probabilistic logic;Feature extraction;Fault diagnosis;Computational modeling;Anomaly detection","ball bearings;condition monitoring;deep learning (artificial intelligence);fault diagnosis;Gaussian distribution;mechanical engineering computing;pattern classification","unprecedented faults;pretrained classifier;unified diagnostics framework;fault classification tasks;deep neural networks classifier;probabilistic latent variables;fault classes;joint-training framework;bearing datasets;intelligent fault diagnosis;unseen fault categories;artificial intelligence;industrial applications;AI-based fault diagnostics;training dataset;testing dataset;fault detection;deep variational autoencoder classifier;condition monitoring;Gaussian probabilistic distributions;entangled raw data","","2","","32","IEEE","1 Jul 2021","","","IEEE","IEEE Journals"
"Gaussian Mixture Variational Autoencoder for Semi-Supervised Topic Modeling","C. Zhou; H. Ban; J. Zhang; Q. Li; Y. Zhang","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Information Science and Engineering, Southeast University, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Information Department, Nanjing University of Science and Technology, Nanjing, China; SenseDeal Intelligent Technology Company Ltd., Beijing, China","IEEE Access","16 Jun 2020","2020","8","","106843","106854","Topic models are widely explored for summarizing a corpus of documents. Recent advances in Variational AutoEncoder (VAE) have enabled the development of black-box inference methods for topic modeling in order to alleviate the drawbacks of classical statistical inference. Most existing VAE based approaches assume a unimodal Gaussian distribution for the approximate posterior of latent variables, which limits the flexibility in encoding the latent space. In addition, the unsupervised architecture hinders the incorporation of extra label information, which is ubiquitous in many applications. In this paper, we propose a semi-supervised topic model under the VAE framework. We assume that a document is modeled as a mixture of classes, and a class is modeled as a mixture of latent topics. A multimodal Gaussian mixture model is adopted for latent space. The parameters of the components and the mixing weights are encoded separately. These weights, together with partially labeled data, also contribute to the training of a classifier. The objective is derived under the Gaussian mixture assumption and the semi-supervised VAE framework. Modules of the proposed framework are appropriately designated. Experiments performed on three benchmark datasets demonstrate the effectiveness of our method, comparing to several competitive baselines.","2169-3536","","10.1109/ACCESS.2020.3001184","National Natural Science Foundation of China(grant numbers:61902186,91846104); Natural Science Foundation of Jiangsu Province(grant numbers:BK20180463); 4th Project of the National Key Research and Development Program(grant numbers:2020YFB1804604,2020YFB1804600); Fundamental Research Funds for the Central Universities(grant numbers:30920010008,30918012204); 2020 Industrial Internet Innovation and Development Project from Ministry of Industry and Information Technology of China; 2018 Jiangsu Province Major Technical Research Project; Cooperative Research Project Commissioned by Zhongtian Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9112154","Topic model;variational autoencoder;semi-supervised learning;Gaussian mixture model;deep generative learning","Computational modeling;Gaussian mixture model;Standards;Data models;Gaussian distribution;Training","Gaussian distribution;inference mechanisms;mixture models;neural nets;pattern classification","Gaussian mixture variational autoencoder;semisupervised topic modeling;black-box inference methods;VAE based approaches;unimodal Gaussian distribution;semisupervised topic model;multimodal Gaussian mixture model;semisupervised VAE framework;Gaussian mixture assumption","","2","","47","CCBY","9 Jun 2020","","","IEEE","IEEE Journals"
"Variational Autoencoder for Speech Enhancement with a Noise-Aware Encoder","H. Fang; G. Carbajal; S. Wermter; T. Gerkmann","Knowledge Technology (WTM), Universitat Hamburg, Germany; Signal Processing (SP), Universität Hamburg, Germany; Knowledge Technology (WTM), Universitat Hamburg, Germany; Signal Processing (SP), Universität Hamburg, Germany","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","676","680","Recently, a generative variational autoencoder (VAE) has been proposed for speech enhancement to model speech statistics. However, this approach only uses clean speech in the training phase, making the estimation particularly sensitive to noise presence, especially in low signal-to-noise ratios (SNRs). To increase the robustness of the VAE, we propose to include noise information in the training phase by using a noise-aware encoder trained on noisy-clean speech pairs. We evaluate our approach on real recordings of different noisy environments and acoustic conditions using two different noise datasets. We show that our proposed noise-aware VAE outperforms the standard VAE in terms of overall distortion without increasing the number of model parameters. At the same time, we demonstrate that our model is capable of generalizing to unseen noise conditions better than a supervised feedforward deep neural network (DNN). Furthermore, we demonstrate the robustness of the model performance to a reduction of the noisy-clean speech training data size.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414060","speech enhancement;generative model;variational autoencoder;semi-supervised learning","Training;Nonlinear distortion;Estimation;Training data;Speech enhancement;Robustness;Acoustics","codecs;neural nets;speech enhancement","generative variational autoencoder;speech enhancement;speech statistics;training phase;noise presence;signal-to-noise ratios;noise information;noise-aware encoder;noisy-clean speech pairs;noisy environments;noise-aware VAE;unseen noise conditions;supervised feedforward deep neural network;acoustic conditions","","2","","27","","13 May 2021","","","IEEE","IEEE Conferences"
"Stellar Cluster Detection Using GMM with Deep Variational Autoencoder","A. Karmakar; D. Mishra; A. Tej","Department of Avionics, Indian Institute of Space Science and Technology, Trivandrum; Department of Avionics, Indian Institute of Space Science and Technology, Trivandrum; Department of Earth ans Space Science, Indian Institute of Space Science and Technology, Trivandrum","2018 IEEE Recent Advances in Intelligent Computational Systems (RAICS)","7 Feb 2019","2018","","","122","126","Detecting stellar clusters have always been an important research problem in Astronomy. Although images do not convey very detailed information in detecting stellar density enhancements, we attempt to understand if new machine learning techniques can reveal patterns that would assist in drawing better inferences from the available image data. This paper describes an unsupervised approach in detecting star clusters using Deep Variational Autoencoder combined with a Gaussian Mixture Model. We show that our method works significantly well in comparison with state-of-the-art detection algorithm in recognizing a variety of star clusters even in the presence of noise and distortion.","","978-1-5386-7336-2","10.1109/RAICS.2018.8634903","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8634903","Deep Learning;Variational Autoencoder;Gaussian Mixture Model;Star Cluster;Astronomy","Aerospace electronics;Mathematical model;Astronomy;Clustering algorithms;Decoding;Gaussian mixture model","astronomical image processing;Gaussian processes;learning (artificial intelligence);mixture models;star clusters","machine learning;research problem;astronomy;Gaussian mixture model;deep variational autoencoder;stellar density enhancements;GMM;stellar cluster detection;state-of-the-art detection algorithm;star clusters;unsupervised approach","","2","","23","","7 Feb 2019","","","IEEE","IEEE Conferences"
"Classification of Expert-Novice Level Using Eye Tracking And Motion Data via Conditional Multimodal Variational Autoencoder","Y. Akamatsu; K. Maeda; T. Ogawa; M. Haseyama","Graduate School of Information Science and Technology, Hokkaido University, Japan; Office of Institutional Research, Hokkaido University, Japan; Faculty of Information Science and Technology, Hokkaido University, Japan; Faculty of Information Science and Technology, Hokkaido University, Japan","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","1360","1364","Sensor data from wearable devices have been utilized to analyze differences between experts and novices. Previous studies attempted to classify the expert-novice level from sensor data based on supervised learning methods. However, these approaches need to collect enough training data covering various novices’ sensor patterns. In this paper, we propose a semi-supervised anomaly detection approach that requires only sensor data of experts for training and identifies those of novices as anomalies. Our proposed anomaly detection model named conditional multimodal variational autoencoder (CMVAE) has the following two technical contributions: (i) considering action information of persons and (ii) utilizing multimodal sensor data, i.e., eye tracking data and motion data in this case. The proposed method is evaluated on sensor data measured when expert and novice soccer players were shooting, dribbling, and doing soccer ball juggling. Experimental results show that CMVAE can more accurately classify the expert-novice level than previous supervised learning methods and anomaly detection methods using other VAEs.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414361","Wearable devices;sensor data;expert-novice level;anomaly detection;variational autoencoder","Training;Multimodal sensors;Wearable computers;Supervised learning;Training data;Gaze tracking;Signal processing","gaze tracking;pattern classification;supervised learning","expert-novice level;motion data;conditional multimodal variational autoencoder;training data;anomaly detection approach;multimodal sensor data;eye tracking data;novice soccer players;anomaly detection methods;classification;supervised learning methods","","2","","30","","13 May 2021","","","IEEE","IEEE Conferences"
"Radio Galaxy Morphology Simulation via Residual Conditional Variational Autoencoder","Z. Ma; J. Zhu; Y. Zhu; H. Xu","Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Astrophysics, Shanghai Jiao Tong University, Shanghai, China; Department of Astrophysics, Shanghai Jiao Tong University, Shanghai, China","2019 15th International Conference on Computational Intelligence and Security (CIS)","5 Mar 2020","2019","","","151","155","We propose a radio galaxy morphology simulation approach by using a conditional variational autoencoder composed of residual convolutional blocks namely ResCVAE. It estimates the distribution of the existed morphology-labeled radio galaxy images by mapping them to a latent low-dimension space, and simulates new images according to the obtained distribution. From designed experiments we find that the pixelwise cross-entropy (PCE) loss, as a component of the optimization objective for the ResCVAE, trains the network parameters to obtain lower reconstruction loss and more accurate simulation performance than the mean squared error (MSE) loss function under the same training settings. In addition, the strategies of applying condition and residual convolutional blocks are also evaluated and compared to the other networks, which suggests a domination of our proposed approach.","","978-1-7281-6092-4","10.1109/CIS.2019.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9023752","image simulation, pattern analysis, conditional variational autoencoder, residual","Training;Morphology;Decoding;Loss measurement;Image reconstruction;Optimization;Convolution","astronomical image processing;convolutional neural nets;image reconstruction;image resolution;image segmentation;optimisation;radiogalaxies","reconstruction loss;morphology-labeled radio galaxy images;accurate simulation performance;pixelwise cross-entropy loss;low-dimension space;ResCVAE;radio galaxy morphology simulation approach;residual conditional variational autoencoder;residual convolutional blocks","","1","","22","","5 Mar 2020","","","IEEE","IEEE Conferences"
"Time-varying Item Feature Conditional Variational Autoencoder for Collaborative Filtering","J. Kim","Datamining Laboratory, Industrial Engineering, Seoul National University, Seoul, South Korea","2019 IEEE International Conference on Big Data (Big Data)","24 Feb 2020","2019","","","2309","2316","The factors impacting on what users purchase can be classified as an internal factor which is time-invariant user's unique taste and an external factor which is time-varying item characteristic. However, the current recommendation system has a limitation of making recommendations based only on the user's history without taking into account the item features trends of the time, which prevents precise recommendations. In this paper, the recommendation system that reflects inter-items trends of time-based bin is proposed. We focus on creating a hybrid recommender system that could effectively combine time-varying content data with the users history data. Specifically, we use Conditional Variational Autoencoder (VAE) to add a time dynamic item features to user-item implicit feedback data. In this case, distributed representation of items in the specific period is used as a condition that is added to input and latent variable of VAE respectively. In detail, the distributed representation per time bin can be extracted using LSTM. By applying a condition into VAE, a hybrid recommendation system can be created to reflect the item time-varying features. The proposed model in this paper differs from current studies in that it reflects the changing characteristics inherent of the products and utilizes it for recommendation. The Movielens 1M data and Amazon women's clothing dataset are used for the evaluation of the proposed model.","","978-1-7281-0858-2","10.1109/BigData47090.2019.9006014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9006014","recommender system;conditional variational autoencoder;long short term memory","Recommender systems;Motion pictures;Neural networks;Feature extraction;Collaboration;History;Market research","collaborative filtering;feature extraction;recommender systems;recurrent neural nets","time-varying content data;users history data;VAE;user-item implicit feedback data;hybrid recommendation system;users purchase;time-varying item feature conditional variational autoencoder;LSTM","","1","","20","","24 Feb 2020","","","IEEE","IEEE Conferences"
"ViVA: Semi-Supervised Visualization via Variational Autoencoders","S. An; S. Hong; J. Sun","College of Computing, Georgia Institute of Technology, Atlanta, GA, USA; College of Computing, Georgia Institute of Technology, Atlanta, GA, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, Illinois, USA","2020 IEEE International Conference on Data Mining (ICDM)","9 Feb 2021","2020","","","22","31","Visualizing latent embeddings is a popular approach to explain classification models, including deep neural networks. However, existing visualization methods such as t-distributed Stochastic Neighbor Embedding (t-SNE) and Uniform Manifold Approximation Projection (UMAP) are often used as a post-processing step which is independent of the classification models. The resulting visualization can be misaligned with the classification models. In this paper, we propose ViVA, a novel method for semi-supervised Visualization via Variational Autoencoders. ViVA learns from both unlabeled and labeled data by jointly optimizing both visualization loss and classification loss. As a parameterized model using neural networks, ViVA can easily project new data to the same embedding space. Experiments show that ViVA can achieve better visualization quality as well as classification accuracy on multiple challenging datasets compared to several visualization baselines, including t-SNE and UMAP.","2374-8486","978-1-7281-8316-9","10.1109/ICDM50108.2020.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9338364","semi-supervised learning;variational autoencoder;visualization","Manifolds;Neural networks;Data visualization;Stochastic processes;Tools;Data models;Data mining","approximation theory;data visualisation;deep learning (artificial intelligence);neural nets;pattern classification","classification loss;parameterized model;ViVA;embedding space;visualization quality;classification accuracy;visualization baselines;t-SNE;semisupervised Visualization;Variational Autoencoders;latent embeddings;classification models;deep neural networks;t-distributed Stochastic Neighbor Embedding;Uniform Manifold Approximation Projection;visualization loss","","1","","49","IEEE","9 Feb 2021","","","IEEE","IEEE Conferences"
"Continual Learning Of Predictive Models In Video Sequences Via Variational Autoencoders","D. Campo; G. Slavic; M. Baydoun; L. Marcenaro; C. Regazzoni","DITEN, University of Genova, Italy; DITEN, University of Genova, Italy; DITEN, University of Genova, Italy; DITEN, University of Genova, Italy; DITEN, University of Genova, Italy","2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","753","757","This paper proposes a method for performing continual learning of predictive models that facilitate the inference of future frames in video sequences. For a first given experience, an initial Variational Autoencoder, together with a set of fully connected neural networks are utilized to respectively learn the appearance of video frames and their dynamics at the latent space level. By employing an adapted Markov Jump Particle Filter, the proposed method recognizes new situations and integrates them as predictive models avoiding catastrophic forgetting of previously learned tasks. For evaluating the proposed method, this article uses video sequences from a vehicle that performs different tasks in a controlled environment.","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9190980","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190980","Continual learning;lifelong learning;variational autoencoder;particle filter;kalman filter","Training;Predictive models;Video sequences;Task analysis;Technological innovation;Testing;Artificial neural networks","image sequences;learning (artificial intelligence);Markov processes;neural nets;particle filtering (numerical methods);video signal processing","fully connected neural networks;variational autoencoders;continual learning;video sequences;predictive models;Markov jump particle filter;video frames","","1","","20","","30 Sep 2020","","","IEEE","IEEE Conferences"
"A Variational Autoencoder Mixture Model for Online Behavior Recommendation","M. -D. Nguyen; Y. -S. Cho","Department of Software Convergence, Sejong University, Seoul, South Korea; Department of Data Science, Sejong University, Seoul, South Korea","IEEE Access","28 Jul 2020","2020","8","","132736","132747","Online behavior recommendation is an attractive research topic related to social media mining. This topic focuses on suggesting suitable behaviors for users in online platforms, including music listening, video watching, e-commerce, to name but a few to improve the user experience, an essential factor for the success of online services. A successful online behavior recommendation system should have the ability to predict behaviors that users used to performs and also suggest behaviors that users never performed before. In this paper, we develop a mixture model that contains two components to address this problem. The first component is the user-specific preference component that represents the habits of users based on their behavior history. The second component is the latent group preference component based on variational autoencoder, a deep generative neural network. This component corresponds to the hidden interests of users and allows us to discover the unseen behavior of users. We conduct experiments on various real-world datasets with different characteristics to show the performance of our model in different situations. The result indicates that our proposed model outperforms the previous mixture models for recommendation problem.","2169-3536","","10.1109/ACCESS.2020.3010508","National Research Foundation of Korea (NRF) Grant funded by the Korean Government (MSIT)(grant numbers:2018R1C1B504593113); Institute for Information & Communications Technology Promotion (IITP) Grant funded by the Korean government (MSIP)(grant numbers:20200005120012003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144583","Online behavior recommendation;mixture model;variational autoencoder","Mixture models;History;Probabilistic logic;Data models;Neural networks;Task analysis;Training","behavioural sciences computing;data mining;neural nets;recommender systems;social networking (online)","user experience;online services;user-specific preference component;behavior history;latent group preference component;recommendation problem;variational autoencoder mixture model;social media mining;suitable behaviors;online behavior recommendation system","","1","","44","CCBY","20 Jul 2020","","","IEEE","IEEE Journals"
"Generating Transit Light Curves with Variational Autoencoders","D. Woodward; E. Stevens; E. Linstead","Machine Learning and Assistive Technology Lab, Schmid College of Science and Technology Chapman University, Orange, CA, USA; Machine Learning and Assistive Technology Lab, Schmid College of Science and Technology Chapman University, Orange, CA, USA; Machine Learning and Assistive Technology Lab, Schmid College of Science and Technology Chapman University, Orange, CA, USA","2019 IEEE International Conference on Space Mission Challenges for Information Technology (SMC-IT)","11 Oct 2019","2019","","","24","32","We leverage variational autoencoders to generate transient light curves of distant exoplanets and stars in order to demonstrate the efficacy of deep learning techniques for this class of data. The ability to generate accurate light curves with desirable characteristics becomes more and more necessary with the success of recent astronomical missions and upcoming missions and will be a key enabler of the development of future models and research. The first study of its type to date, our initial results indicate a promising new research direction worthy of further development.","","978-1-7281-1545-0","10.1109/SMC-IT.2019.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863859","machine learning;variational autoencoders;neural networks;satellites;astronomy;extrasolar planets","Extrasolar planets;Deep learning;Data models;Training;Training data;Telescopes;Neural networks","astronomical photometry;extrasolar planetary motion;extrasolar planetary spectra;learning (artificial intelligence);transits","leverage variational autoencoders;transient light curves;distant exoplanets;deep learning techniques;accurate light curves;transit light curves;astronomical missions","","1","","27","","11 Oct 2019","","","IEEE","IEEE Conferences"
"Variational Autoencoder Based Unsupervised Domain Adaptation For Semantic Segmentation","Z. Li; R. Togo; T. Ogawa; M. Haseyama","Graduate School of Information Science and Technology, Hokkaido University; Education and Research Center for Mathematical and Data Science, Hokkaido University; Faculty of Information Science and Technology, Hokkaido University; Faculty of Information Science and Technology, Hokkaido University","2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","2426","2430","Unsupervised domain adaptation, which transfers supervised knowledge from a labeled domain to an unlabeled domain, remains a tough problem in the field of computer vision, especially for semantic segmentation. Some methods inspired by adversarial learning and semi-supervised learning have been developed for unsupervised domain adaptation in semantic segmentation and achieved outstanding performances. In this paper, we propose a novel method for this task. Like adversarial learning-based methods using a discriminator to align the feature distributions from different domains, we employ a variational autoencoder to get to the same destination but in a non-adversarial manner. Since the two approaches are compatible, we also integrate an adversarial loss into our method. By further introducing pseudo labels, our method can achieve state-of-the-art performances on two benchmark adaptation scenarios, GTA5-to-CITYSCAPES and SYNTHIA-to-CITYSCAPES.","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9190973","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190973","Unsupervised domain adaptation;semantic segmentation;variational autoencoder;adversarial learning","Semantics;Task analysis;Adaptation models;Mathematical model;Linear programming;Training;Learning systems","computer vision;image segmentation;unsupervised learning","adversarial learning-based methods;variational autoencoder;unsupervised domain adaptation;semantic segmentation;labeled domain;unlabeled domain;semisupervised learning;supervised knowledge;computer vision;feature distributions;adversarial loss;GTA5-to-CITYSCAPES;SYNTHIA-to-CITYSCAPES","","1","","26","","30 Sep 2020","","","IEEE","IEEE Conferences"
"Toward Unsupervised 3d Point Cloud Anomaly Detection Using Variational Autoencoder","M. Masuda; R. Hachiuma; R. Fujii; H. Saito; Y. Sekikawa","Keio University, Japan; Keio University, Japan; Keio University, Japan; Keio University, Japan; Denso IT Laboratory, Japan","2021 IEEE International Conference on Image Processing (ICIP)","23 Aug 2021","2021","","","3118","3122","In this paper, we present an end-to-end unsupervised anomaly detection framework for 3D point clouds. To the best of our knowledge, this is the first work to tackle the anomaly detection task on a general object represented by a 3D point cloud. We propose a deep variational autoencoder based unsupervised anomaly detection network adapted to the 3D point cloud and an anomaly score specifically for 3D point clouds. To verify the effectiveness of the model, we conducted extensive experiments on ShapeNet dataset. Through quantitative and qualitative evaluation, we demonstrate that the proposed method outperforms the baseline method.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506795","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506795","3D point cloud;anomaly detection;unsupervised learning;variational autoencoder","Adaptation models;Three-dimensional displays;Image processing;Conferences;Task analysis;Anomaly detection","image representation;object recognition;security of data;solid modelling;unsupervised learning","unsupervised 3D point cloud anomaly detection;deep variational autoencoder;anomaly score;ShapeNet dataset;quantitative evaluation;qualitative evaluation","","1","","23","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"Human Initiated Grasp Space Exploration Algorithm for an Underactuated Robot Gripper Using Variational Autoencoder","C. Rolinat; M. Grossard; S. Aloui; C. Godin","CEA, List, Université Paris-Saclay, Palaiseau, France; CEA, List, Université Paris-Saclay, Palaiseau, France; CEA, Leti, Université Grenoble Alpes, Grenoble, France; CEA, Leti, Université Grenoble Alpes, Grenoble, France","2021 IEEE International Conference on Robotics and Automation (ICRA)","18 Oct 2021","2021","","","2598","2604","Grasp planning and most specifically the grasp space exploration is still an open issue in robotics. This article presents an efficient procedure for exploring the grasp space of a multifingered adaptive gripper for generating reliable grasps given a known object pose. This procedure relies on a limited dataset of manually specified expert grasps, and use a mixed analytic and data-driven approach based on the use of a grasp quality metric and variational autoencoders. The performances of this method are assessed by generating grasps in simulation for three different objects. On this grasp planning task, this method reaches a grasp success rate of 99.91% on 7000 trials.","2577-087X","978-1-7281-9077-8","10.1109/ICRA48506.2021.9561765","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9561765","multifingered gripper;grasp space exploration;variational autoencoder;grasp quality metric","Automation;Planning;Reliability;Grippers;Grasping","dexterous manipulators;grippers","human initiated grasp space exploration algorithm;underactuated robot gripper;variational autoencoder;robotics;multifingered adaptive gripper;reliable grasps;manually specified expert grasps;mixed analytic data-driven approach;grasp planning task","","1","","23","IEEE","18 Oct 2021","","","IEEE","IEEE Conferences"
"Non-parallel Voice Conversion with Controllable Speaker Individuality using Variational Autoencoder","T. V. Ho; M. Akagi","Japan Advanced Institute of Science and Technology, Japan; Japan Advanced Institute of Science and Technology, Japan","2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","5 Mar 2020","2019","","","106","111","We propose a flexible non-parallel voice conversion (VC) system that is capable of both performing speaker adaptation and controlling speaker individuality. The proposed VC framework aims to tackle the inability to arbitrarily modify voice characteristics in the converted waveform of conventional VC model. To achieve this goal, we use the speaker embedding realized by a Variational Autoencoder (VAE) instead of one-hot encoded vectors to represent and modify the target voice's characteristics. Neither parallel training data, linguistic label nor time alignment procedure is required to train our system. After training on a multi-speaker speech database, the proposed VC system can adapt an arbitrary source speaker to any target speaker using only one sample from a target speaker. The speaker individuality of converted speech can be controlled by modifying the speaker embedding vectors; resulting in a fictitious speaker individuality. The experimental results showed that our proposed system is similar to conventional non-parallel VAE-based VC and better than the parallel Gaussian Mixture Model (GMM) in both perceived speech naturalness and speaker similarity; even when our system only uses one sample from target speaker. Moreover, our proposed system can convert a source voice to a fictitious target voice with well perceived speech naturalness of 3.1 MOS.","2640-0103","978-1-7281-3248-8","10.1109/APSIPAASC47483.2019.9023264","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9023264","Voice conversion;speaker embedding;voice characteristics control;variational autoencoder;non-parallel data","Acoustics;Training;Linguistics;Adaptation models;Gaussian distribution;Modulation;Training data","Gaussian processes;mixture models;neural nets;speaker recognition;speech processing;speech synthesis","controllable speaker individuality;Variational Autoencoder;nonparallel voice conversion system;speaker adaptation;controlling speaker individuality;VC framework;voice characteristics;conventional VC model;parallel training data;linguistic label nor time alignment procedure;multispeaker speech database;VC system;arbitrary source speaker;fictitious speaker individuality;VAE-based VC;parallel Gaussian Mixture Model;perceived speech naturalness;speaker similarity;source voice;fictitious target voice","","1","","16","","5 Mar 2020","","","IEEE","IEEE Conferences"
"Monophonic Music Generation With a Given Emotion Using Conditional Variational Autoencoder","J. Grekow; T. Dimitrova-Grekow","Faculty of Computer Science, Bialystok University of Technology, Bialystok, Poland; Faculty of Computer Science, Bialystok University of Technology, Bialystok, Poland","IEEE Access","23 Sep 2021","2021","9","","129088","129101","The rapid increase in the importance of human-machine interaction and the accelerating pace of life pose various challenges for the creators of digital environments. Continuous improvement of human-machine interaction requires precise modeling of the physical and emotional state of people. By implementing emotional intelligence in machines, robots are expected not only to recognize and track emotions when interacting with humans, but also to respond and behave appropriately. The machine should match its reaction to the mood of the user as precisely as possible. Music generation with a given emotion can be a good start to fulfilling such a requirement. This article presents the process of building a system generating music content of a specified emotion. As the emotion labels, four basic emotions: happy, angry, sad, relaxed, corresponding to the four quarters of Russell’s model, were used. Conditional variational autoencoder using a recurrent neural network for sequence processing was used as a generative model. The obtained results in the form of the generated music examples with a specific emotion are convincing in their structure and sound. The generated examples were evaluated with two methods, in the first using metrics for comparison with the training set and in the second using expert annotation.","2169-3536","","10.1109/ACCESS.2021.3113829","Ministry of Science and Higher Education through Bialystok University of Technology(grant numbers:WZ/WI-IIT/2/2020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9540852","Generative models;music generation;music emotion;variational autoencoder","Music;Emotion recognition;Man-machine systems;Databases;Training;Buildings;Service robots","emotion recognition;human computer interaction;learning (artificial intelligence);music;recurrent neural nets","emotion labels;Russell's model;conditional variational autoencoder;generative model;generated music examples;specific emotion;generated examples;monophonic music generation;given emotion;human-machine interaction;digital environments;continuous improvement;precise modeling;emotional intelligence;system generating music content;specified emotion","","1","","51","CCBY","17 Sep 2021","","","IEEE","IEEE Journals"
"A Semi-Supervised Approach For Identifying Abnormal Heart Sounds Using Variational Autoencoder","R. Banerjee; A. Ghose","Research and Innovation, Tata Consultancy Services; Research and Innovation, Tata Consultancy Services","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","1249","1253","Abnormal heart sounds may have diverse frequency characteristics depending upon underlying pathological conditions. Designing a binary classifier for predicting normal and abnormal heart sounds using supervised learning requires a lot of training data, covering different types of cardiac abnormalities. In this paper, we propose a semi-supervised approach to solve the problem. A convolutional Variational Autoencoder (VAE) structure is defined for learning the probability distribution of the spectrogram properties of normal heart sounds. The Kullback-Leibler (KL) divergence between the known prior distribution of the VAE and the encoded distribution is taken as an anomaly score for detecting abnormal heart sounds. The proposed approach is evaluated on open access and in-house datasets of Phonocardiogram (PCG) signals, recorded from normal subjects and patients, having cardiovascular diseases, cardiac murmurs and extra heart sounds. Results show that an improved classification performance is achieved in comparison to the existing approaches.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9054632","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054632","Heart sounds;Variational Autoencoder;Semi-supervised learning;Convolutional Neural Network","Heart;Training;Supervised learning;Training data;Speech processing;Phonocardiography;Spectrogram","cardiovascular system;convolutional neural nets;diseases;medical signal detection;medical signal processing;phonocardiography;signal classification","semisupervised approach;supervised learning;cardiac abnormalities;convolutional variational autoencoder structure;abnormal heart sound identification;frequency characteristics;pathological conditions;binary classifier;normal heart sound prediction;Kullback-Leibler divergence;KL divergence;convolutional VAE structure;phonocardiogram signal;PCG signal;cardiovascular disease;cardiac murmurs;classification performance improvement","","1","","20","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Botnet Detection Using Recurrent Variational Autoencoder","J. Kim; A. Sim; J. Kim; K. Wu","Lawrence Berkeley National Laboratory, Berkeley, CA, USA; Lawrence Berkeley National Laboratory, Berkeley, CA, USA; Texas A&M University, Commerce, TX, USA; Lawrence Berkeley National Laboratory, Berkeley, CA, USA","GLOBECOM 2020 - 2020 IEEE Global Communications Conference","11 Feb 2021","2020","","","1","6","Botnet detection is an active research topic as botnets are a source of many malicious activities, including distributed denial-of-service (DDoS), click-fraud, spamming, and crypto-mining attacks. However, it is getting more complicated to identify botnets due to the continuous evolution of botnet software and families that harness new types of devices and attack vectors. Recent studies employing machine learning (ML) showed improved performance to detect botnets to some extent, but they are still limited and ineffective with the lack of sequential pattern analysis, which is a key to detect various classes of botnets. In this paper, we propose a novel botnet detection method, built upon Recurrent Variational Autoencoder (RVAE), that effectively captures sequential characteristics of botnet anomalies. We validate the feasibility of the proposed method with the CTU-13 dataset that have been widely employed for botnet detection studies, and show that our method is at least comparable to existing techniques in terms of detection accuracy. In addition, our experimental results show that the proposed method can detect previously unseen botnets by utilizing sequential patterns of network traffic. We will also show how our method can detect botnets in the streaming mode, which is the essential requirement to perform real-time, on-line detection.","2576-6813","978-1-7281-8298-8","10.1109/GLOBECOM42002.2020.9348169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9348169","botnet detection;anomaly scoring;Recurrent Neural Network;Variational Autoencoder;network security","Training;Systematics;Botnet;Unsolicited e-mail;Telecommunication traffic;Detectors;Anomaly detection","fraud;invasive software;learning (artificial intelligence);recurrent neural nets;unsolicited e-mail","botnet detection method;recurrent variational autoencoder;botnet anomalies;botnet detection studies;unseen botnets;online detection;click-fraud;botnet software;RVAE;CTU-13 dataset;distributed denial-of-service;spamming;crypto-mining attacks;machine learning;DDoS","","1","","26","","11 Feb 2021","","","IEEE","IEEE Conferences"
"Learning utterance-level normalisation using Variational Autoencoders for robust automatic speech recognition","S. Tan; K. C. Sim",National University of Singapore; National University of Singapore,"2016 IEEE Spoken Language Technology Workshop (SLT)","9 Feb 2017","2016","","","43","49","This paper presents a Variational Autoencoder (VAE) based framework for modelling utterances. In this model, a mapping from an utterance to a distribution over the latent space, the VAE-utterance feature, is defined. This is in addition to a frame-level mapping, the VAE-frame feature. Using the Aurora-4 dataset, we train and perform some analysis on these models based on their detection of speaker and utterance variability, and also use combinations of LDA, i-vector, and VAE-frame and utterance features for speech recognition training. We find that it works equally well using VAE-frame + VAE-utterance features alone, and by using an LDA + VAE-frame +VAE-utterance feature combination, we obtain a word-errorrate (WER) of 9.59%, a gain over the 9.72% baseline which uses an LDA + i-vector combination.","","978-1-5090-4903-5","10.1109/SLT.2016.7846243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7846243","Deep neural networks;Speaker adaptation;Variational autoencoders","Training;Feature extraction;Hidden Markov models;Neural networks;Speech recognition;Adaptation models;Transforms","learning (artificial intelligence);neural nets;speaker recognition;statistical analysis;vectors","linear discriminant analysis;LDA + VAE-frame + VAE-utterance feature combination;speaker adaptation;deep neural networks;word-error-rate;i-vector;utterance variability detection;speaker detection;Aurora-4 dataset;frame-level mapping;utterance modelling;robust automatic speech recognition;variational autoencoders;utterance-level normalisation learning","","1","","29","","9 Feb 2017","","","IEEE","IEEE Conferences"
"Discourse-Level Prosody Modeling with a Variational Autoencoder for Non-Autoregressive Expressive Speech Synthesis","N. -Q. Wu; Z. -C. Liu; Z. -H. Ling","National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China, Hefei, P.R.China; National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China, Hefei, P.R.China; National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China, Hefei, P.R.China","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","7592","7596","To address the issue of one-to-many mapping from phoneme sequences to acoustic features in expressive speech synthesis, this paper proposes a method of discourse-level prosody modeling with a variational autoencoder (VAE) based on the non-autoregressive architecture of FastSpeech. In this method, phone-level prosody codes are extracted from prosody features by combining VAE with FastSpeech, and are predicted using discourse-level text features together with BERT embeddings. The continuous wavelet transform (CWT) in FastSpeech2 for F0 representation is not necessary anymore. Experimental results on a Chinese audiobook dataset show that our proposed method can effectively take advantage of discourse-level linguistic information and has outperformed FastSpeech2 on the naturalness and expressiveness of synthetic speech.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746238","Nature; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746238","speech synthesis;prosody modeling;FastSpeech;discourse-level modeling;variational autoencoder","Training;Codes;Continuous wavelet transforms;Bit error rate;Predictive models;Signal processing;Feature extraction","speech processing;speech synthesis;text analysis;wavelet transforms","discourse-level prosody modeling;variational autoencoder;nonautoregressive expressive speech synthesis;acoustic features;VAE;nonautoregressive architecture;phone-level prosody codes;prosody features;discourse-level text features;FastSpeech2;discourse-level linguistic information","","","","25","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Disentangled Speech Representation Learning Based on Factorized Hierarchical Variational Autoencoder with Self-Supervised Objective","Y. Xie; T. Arildsen; Z. -H. Tan","Department of Electronic Systems, Aalborg University; Department of Electronic Systems, Aalborg University; Department of Electronic Systems, Aalborg University","2021 IEEE 31st International Workshop on Machine Learning for Signal Processing (MLSP)","15 Nov 2021","2021","","","1","6","Disentangled representation learning aims to extract explanatory features or factors and retain salient information. Factorized hierarchical variational autoencoder (FHVAE) presents a way to disentangle a speech signal into sequential-level and segmental-level features, which represent speaker identity and speech content information, respectively. As a self-supervised objective, autoregressive predictive coding (APC), on the other hand, has been used in extracting meaningful and transferable speech features for multiple downstream tasks. Inspired by the success of these two representation learning methods, this paper proposes to integrate the APC objective into the FHVAE framework aiming at benefiting from the additional self-supervision target. The main proposed method requires neither more training data nor more computational cost at test time, but obtains improved meaningful representations while maintaining disentanglement. The experiments were conducted on the TIMIT dataset. Results demonstrate that FHVAE equipped with the additional self-supervised objective is able to learn features providing superior performance for tasks including speech recognition and speaker recognition. Furthermore, voice conversion, as one application of disentangled representation learning, has been applied and evaluated. The results show performance similar to baseline of the new framework on voice conversion.","1551-2541","978-1-7281-6338-3","10.1109/MLSP52302.2021.9596320","China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9596320","Disentangled representation learning;variational autoencoder;autoregressive predictive coding","Speech coding;Training data;Speech recognition;Predictive coding;Signal processing;Feature extraction;Speaker recognition","feature extraction;image representation;learning (artificial intelligence);speaker recognition;speech processing;speech recognition","speech representation;factorized hierarchical variational autoencoder;self-supervised objective;explanatory features;salient information;speech signal;sequential-level;segmental-level features;speaker identity;speech content information;autoregressive predictive coding;extracting meaningful speech features;transferable speech features;multiple downstream tasks;representation learning methods;APC objective;FHVAE framework;additional self-supervision target;meaningful representations;disentanglement;speech recognition;speaker recognition;disentangled representation learning","","","","18","","15 Nov 2021","","","IEEE","IEEE Conferences"
"Anomaly Detection of Disconnects Using SSTDR and Variational Autoencoders","A. S. Edun; C. LaFlamme; S. R. Kingston; C. M. Furse; M. A. Scarpulla; J. B. Harley","Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, The University of Utah, Salt Lake City, UT, USA; LiveWire Test Labs, Inc., Salt Lake City, UT, USA; Department of Electrical and Computer Engineering, The University of Utah, Salt Lake City, UT, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA","IEEE Sensors Journal","11 Feb 2022","2022","22","4","3484","3492","This article utilizes variational autoencoder (VAE) and spread spectrum time domain reflectometry (SSTDR) to detect, isolate, and characterize anomalous data (or faults) in a photovoltaic (PV) array. The goal is to learn the distribution of non-faulty input signals, inspect the reconstruction error of test signals, flag anomalies, and then locate or characterize the anomalous data using a predicted baseline rather than a fixed baseline that might be too rigid. The use of VAE handles imbalanced data better than other methods used for classification of PV faults because of its unsupervised nature. We consider only disconnects in this work, and our results show an overall accuracy of 96% for detecting true negatives (non-faulty data), a 99% true positive rate of detecting anomalies, 0.997 area under the ROC curve, 0.99 area under the precision-recall curve, and a maximum percentage absolute relative error of 0.40% in locating the faults on a 5-panel setup with a 59.13 m leader cable.","1558-1748","","10.1109/JSEN.2022.3140922","U.S. Department of Energy’s Office of Energy Efficiency and Renewable Energy (EERE) through the Solar Energy Technologies Office (SETO)(grant numbers:DE-EE0008169); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9672156","Variational autoencoders;reflectometry;SSTDR;disconnects;faults","Circuit faults;Sensors;Correlation;Arrays;Power cables;Dictionaries;Photovoltaic systems","data handling;error analysis;fault diagnosis;fault location;neural nets;pattern classification;photovoltaic power systems;power engineering computing;time-domain reflectometry;unsupervised learning","SSTDR;variational autoencoder;VAE;spread spectrum time domain reflectometry;anomalous data detection;photovoltaic array;PV fault classification;unsupervised nature;disconnect anomaly detection;anomalous data isolation;anomalous data characterization;nonfaulty input signal distribution;test signal reconstruction error;imbalanced data handling","","","","28","IEEE","6 Jan 2022","","","IEEE","IEEE Journals"
"Variational Autoencoder for Data Analytics in Internet of Things Based on Transfer Entropy","S. D. Liang","Department of Computer Science, University of Southern California, Los Angeles, CA, USA","IEEE Internet of Things Journal","6 Oct 2021","2021","8","20","15267","15275","Variational autoencoders (VAEs) are generative models which combine deep learning and Bayesian machine learning. The VAEs are trained via minimizing the loss function, and the most popular loss function in VAEs is the evidence lower bound function in which the Kullback–Leibler divergence has been used. Motivated by the idea that information flow from VAEs input to output should be reflected in the loss function, we propose to incorporate transfer entropy (TE) to loss function to quantify the information flow. Subsequently, we apply our TE-based VAEs to data analytics in Internet of Things, including data compression and generative modeling. Simulation results show that our TE-based VAEs works much better than the Kullback–Leibler divergence-based VAE in terms of reconstruction error and label error. We further analyze the latent space to clarify why our TE-based VAE performs better. We compare our TE-based VAE against compressive sensing and demonstrate that our TE-based VAE could have 30 times stronger compression power than compressive sensing.","2327-4662","","10.1109/JIOT.2021.3052162","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9326416","Data analytics;deep learning;Internet of Things (IoT);transfer entropy (TE);variational autoencoder (VAE)","Internet of Things;Data models;Entropy;Decoding;Data analysis;Analytical models;Loss measurement","Bayes methods;data analysis;data compression;entropy;learning (artificial intelligence)","VAEs input;information flow;data analytics;Internet of Things;generative modeling;Kullback-Leibler divergence-based VAE;variational autoencoder;generative models;popular loss function;evidence lower bound function","","","","29","IEEE","18 Jan 2021","","","IEEE","IEEE Journals"
"Feature-Based Inversion Using Variational Autoencoder for Electrical Impedance Tomography","Z. Lin; R. Guo; K. Zhang; M. Li; F. Yang; S. Xu; D. Liu; A. Abubakar","Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; School of Biomedical Engineering and Suzhou Institute for Advanced Research, University of Science and Technology of China, Suzhou, China; Schlumberger, Houston, TX, USA","IEEE Transactions on Instrumentation and Measurement","29 Jul 2022","2022","71","","1","12","A feature-based inversion method is presented to incorporate structural prior information of the human thorax for absolute imaging in electrical impedance tomography (EIT). A set of EIT images are generated from open-source computed tomography (CT) scans with embedded structural priors of the human thorax. A variational autoencoder (VAE) is applied to learn high-level features of these EIT images and construct a mapping between EIT images and latent codes in a low-dimensional feature space. Then, the parameters of the latent code are served as unknowns to be inverted under a deterministic framework by the Gauss–Newton (GN) method. In this way, the number of unknowns is greatly reduced. Both synthetic and experimental data validate the proposed method. The reconstructed image quality is significantly improved, and the proposed method is relatively robust to measurement noise and modeling errors. This method provides a flexible and effective way to incorporate structural information from CT scans into EIT inversion, which is a potential algorithm for human thorax imaging.","1557-9662","","10.1109/TIM.2022.3192054","National Natural Science Foundation of China(grant numbers:61971263); National Key Research and Development Program of China(grant numbers:2018YFC0603604); Institute for Precision Medicine, Tsinghua University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9832623","Absolute imaging;electrical impedance tomography (EIT);inverse problem;variational autoencoder (VAE)","Electrical impedance tomography;Conductivity;Computed tomography;Lung;Codes;Electrodes;Mathematical models","computerised tomography;electric impedance imaging;image reconstruction;inverse problems;medical image processing;tomography","human thorax imaging;EIT inversion;structural information;reconstructed image quality;Gauss-Newton method;low-dimensional feature space;latent code;high-level features;variational autoencoder;embedded structural priors;open-source computed tomography;EIT images;electrical impedance tomography;absolute imaging;incorporate structural prior information;feature-based inversion method","","","","52","IEEE","18 Jul 2022","","","IEEE","IEEE Journals"
"Explainable Dynamic Multimodal Variational Autoencoder for the Prediction of Patients With Suspected Central Precocious Puberty","Y. Xu; X. Liu; L. Pan; X. Mao; H. Liang; G. Wang; T. Chen","Department of Computer Science and Technology, Institute of Artificial Intelligence & BNRist, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Institute of Artificial Intelligence & BNRist, Tsinghua University, Beijing, China; Institute of Pediatrics, Guangzhou Women and Children’s Medical Center, Guangzhou Medical University, Guangzhou, China; Department of Genetics and Endocrinology, Guangzhou Women and Children’s Medical Center, Guangzhou Medical University, Guangzhou, China; Institute of Pediatrics, Guangzhou Women and Children’s Medical Center, Guangzhou Medical University, Guangzhou, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Department of Computer Science and Technology, Institute of Artificial Intelligence & BNRist, Tsinghua University, Beijing, China","IEEE Journal of Biomedical and Health Informatics","7 Mar 2022","2022","26","3","1362","1373","Central precocious puberty (CPP) is the most common type of precocious puberty and has a significant effect on children. A gonadotropin-releasing hormone (GnRH)-stimulation test is the gold standard for confirming CPP. This test, however, is costly and unpleasant for patients. Therefore, it is critical to developing alternative methods for CPP diagnosis in order to alleviate patient suffering. This study aims to develop an artificial intelligence (AI) diagnostic system for predicting response to the GnRH-stimulation test using data from laboratory tests, electronic health records (EHRs), and pelvic ultrasonography and left-hand radiography reports. The challenges are in integrating these multimodal features into a comprehensive deep learning model in order to achieve an accurate diagnosis while also accounting for the missing or incomplete modalities. To begin, we developed a dynamic multimodal variational autoencoder (DMVAE) that can exploit intrinsic correlations between different modalities to impute features for missing modalities. Next, we combined features from all modalities to predict the outcome of a CPP diagnosis. The experimental results (AUROC 0.9086) demonstrate that our DMVAE model is superior to standard methods. Additionally, we showed that by setting appropriate operating thresholds, clinicians could diagnose about two-thirds of patients with confidence (1.0 specificity). Only about one-third of patients require confirmation of their diagnoses using GnRH (or GnRH analog)-stimulation tests. To interpret the results, we implemented an explainer Shapley additive explanation (SHAP) to analyze the local and global feature attributions.","2168-2208","","10.1109/JBHI.2021.3103271","National Natural Science Foundation of China(grant numbers:61872218,61721003); National Key R&D Program of China(grant numbers:2019YFB1404804); Beijing National Research Center for Information Science and Technology; Tsinghua University; Guoqiang Institute; Tsinghua University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9513560","Central precious puberty;dynamic multimodal variational autoencoder;generative model;deep learning;Shapley additive explanations","Feature extraction;Biochemistry;Breast;Medical diagnostic imaging;Ultrasonography;Diagnostic radiography;Machine learning","biomedical ultrasonics;diagnostic radiography;diseases;genomics;gynaecology;learning (artificial intelligence);medical image processing","central precocious puberty;gonadotropin-releasing hormone-stimulation test;CPP diagnosis;artificial intelligence diagnostic system;GnRH-stimulation test;laboratory tests;electronic health records;pelvic ultrasonography;left-hand radiography reports;multimodal features;deep learning model;DMVAE model;local feature attributions;global feature attributions;dynamic multimodal variational autoencoder","Artificial Intelligence;Child;Follicle Stimulating Hormone;Gonadotropin-Releasing Hormone;Humans;Luteinizing Hormone;Puberty, Precocious","","","58","IEEE","13 Aug 2021","","","IEEE","IEEE Journals"
"Cosmo VAE: Variational Autoencoder for CMB Image Inpainting","K. Yi; Y. Guo; Y. Fan; J. Hamann; Y. G. Wang","School of Mathematics and Statistics, The University of New South Wales, Sydney, Australia; School of Mathematics and Statistics, The University of New South Wales, Sydney, Australia; School of Mathematics and Statistics, The University of New South Wales, Sydney, Australia; School of Physics, The University of New South Wales, Sydney, Australia; School of Mathematics and Statistics, The University of New South Wales, Sydney, Australia","2020 International Joint Conference on Neural Networks (IJCNN)","29 Sep 2020","2020","","","1","7","Cosmic microwave background radiation (CMB) is critical to the understanding of the early universe and precise estimation of cosmological constants. Due to the contamination of thermal dust noise in the galaxy, the CMB map that is an image on the two-dimensional sphere has missing observations, mainly concentrated on the equatorial region. The noise of the CMB map has a significant impact on the estimation precision for cosmological parameters. Inpainting the CMB map can effectively reduce the uncertainty of parametric estimation. In this paper, we propose a deep learning-based variational autoencoder - CosmoVAE, to restoring the missing observations of the CMB map. The input and output of CosmoVAE are square images. To generate training, validation, and test data sets, we segment the full-sky CMB map into many small images by Cartesian projection. CosmoVAE assigns physical quantities to the parameters of the VAE network by using Fourier coefficients, which are sampled by the angular power spectrum of the Gaussian random field as latent variables. CosmoVAE adopts a new loss function to improve the learning performance of the model, which consists of ℓ1 reconstruction loss, Kullback-Leibler divergence between the posterior distribution of encoder network and the prior distribution of latent variables, perceptual loss, and total-variation regularizer. The proposed model achieves state of the art performance for Planck Commander 2018 CMB map inpainting.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9207123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207123","variational autoencoder;cosmic microwave background;inpainting;deep learning;convolutional neural networks;uncertainty quantification;KL-divergence regularization;perceptual loss;total variation;angular power spectrum;VGG-16;ImageNet","Image reconstruction;Decoding;Convolutional neural networks;Australia;Training;Machine learning;Probabilistic logic","astronomical image processing;cosmic acceleration;cosmology;radiofrequency cosmic radiation","CMB image;cosmic microwave background radiation;deep learning-based variational autoencoder;CosmoVAE;full-sky CMB map;Planck Commander 2018 CMB map inpainting;Cartesian projection;Fourier coefficients;Gaussian random field;latent variables","","","","26","","29 Sep 2020","","","IEEE","IEEE Conferences"
"Training Variational Autoencoders with Discrete Latent Variables Using Importance Sampling","A. Bartler; F. Wiewel; L. Mauch; B. Yang","Institute of Signal Processing and System Theory, University of Stuttgart, Stuttgart, Germany; Institute of Signal Processing and System Theory, University of Stuttgart, Stuttgart, Germany; Institute of Signal Processing and System Theory, University of Stuttgart, Stuttgart, Germany; Institute of Signal Processing and System Theory, University of Stuttgart, Stuttgart, Germany","2019 27th European Signal Processing Conference (EUSIPCO)","18 Nov 2019","2019","","","1","5","The Variational Autoencoder (VAE) is a popular generative latent variable model that is often used for representation learning. Standard VAEs assume continuous-valued latent variables and are trained by maximization of the evidence lower bound (ELBO). Conventional methods obtain a differentiable estimate of the ELBO with reparametrized sampling and optimize it with Stochastic Gradient Descend (SGD). However, this is not possible if we want to train VAEs with discrete-valued latent variables, since reparametrized sampling is not possible. In this paper, we propose an easy method to train VAEs with binary or categorically valued latent representations. Therefore, we use a differentiable estimator for the ELBO which is based on importance sampling. In experiments, we verify the approach and train two different VAEs architectures with Bernoulli and categorically distributed latent representations on two different benchmark datasets.","2076-1465","978-9-0827-9703-9","10.23919/EUSIPCO.2019.8902811","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902811","variational autoencoder;discrete latent variables;importance sampling","Decoding;Training;Monte Carlo methods;Signal processing;Europe;Standards;Stochastic processes","approximation theory;Gaussian processes;gradient methods;image coding;importance sampling;learning (artificial intelligence);maximum likelihood estimation;stochastic processes","ELBO;reparametrized sampling;VAE;discrete-valued latent variables;binary valued latent representations;categorically valued latent representations;differentiable estimator;importance sampling;VAE architectures;categorically distributed latent representations;discrete latent variables;generative latent variable model;representation learning;stochastic gradient descend;variational autoencoder training","","","","17","","18 Nov 2019","","","IEEE","IEEE Conferences"
"Generating NLFM Radar Waveforms using Variational Autoencoders","A. Charlish; C. Schwalm","Sensor Data and Information Fusion Department, Fraunhofer FKIE, Wachtberg, Germany; Sensor Data and Information Fusion Department, Fraunhofer FKIE, Wachtberg, Germany","2022 IEEE Radar Conference (RadarConf22)","3 May 2022","2022","","","1","6","The rapid synthesis of radar waveform modulations is key to enabling a radar to react to the environment in order to optimize performance. This paper proposes the use of generative models for radar waveform generation. Specifically, variational autoencoders (VAEs) comprising neural networks that are trained with a novel reconstruction loss are proposed. It is shown for simple classes of non-linear FM waveforms that the decoder from the proposed VAE can generate new radar waveform modulations that possess required ambiguity function characteristics, even though they were not represented in the training data.","","978-1-7281-5368-1","10.1109/RadarConf2248738.2022.9764188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9764188","Waveform diversity;cognitive radar;radar waveform synthesis;generative models;variational autoencoder;neural networks;machine learning;artificial intelligence","Frequency modulation;Navigation;Conferences;Neural networks;Training data;Radar;Radar imaging","FM radar;frequency modulation;neural nets;pulse compression;radar signal processing;waveform generators","generative models;radar waveform generation;variational autoencoders;VAE;nonlinear FM waveforms;radar waveform modulations;generating NLFM radar waveforms","","","","13","IEEE","3 May 2022","","","IEEE","IEEE Conferences"
"Cross-Lingual Voice Conversion With Controllable Speaker Individuality Using Variational Autoencoder and Star Generative Adversarial Network","T. V. Ho; M. Akagi","Graduate School of Advanced Science and Technology, Japan Advanced Institute of Science and Technology (JAIST), Nomi, Japan; Graduate School of Advanced Science and Technology, Japan Advanced Institute of Science and Technology (JAIST), Nomi, Japan","IEEE Access","30 Mar 2021","2021","9","","47503","47515","This paper proposes a non-parallel cross-lingual voice conversion (CLVC) model that can mimic voice while continuously controlling speaker individuality on the basis of the variational autoencoder (VAE) and star generative adversarial network (StarGAN). Most studies on CLVC only focused on mimicking a particular speaker voice without being able to arbitrarily modify the speaker individuality. In practice, the ability to generate speaker individuality may be more useful than just mimicking voice. Therefore, the proposed model reliably extracts the speaker embedding from different languages using a VAE. An F0 injection method is also introduced into our model to enhance the F0 modeling in the cross-lingual setting. To avoid the over-smoothing degradation problem of the conventional VAE, the adversarial training scheme of the StarGAN is adopted to improve the training-objective function of the VAE in a CLVC task. Objective and subjective measurements confirm the effectiveness of the proposed model and F0 injection method. Furthermore, speaker-similarity measurement on fictitious voices reveal a strong linear relationship between speaker individuality and interpolated speaker embedding, which indicates that speaker individuality can be controlled with our proposed model.","2169-3536","","10.1109/ACCESS.2021.3063519","National Institute of Informatics-Center for Robust Intelligence and Social Technology (NII-CRIS), Grant-in-Aid for Scientific Research(grant numbers:20H04207); Japan Society for the Promotion of Science (JSPS)-NSFC Bilateral Joint Research Projects/Seminars(grant numbers:JSJSBP120197416); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9367139","Voice conversion;cross-lingual;controllable speaker individuality;variational autoencoder;generative adversarial network","Training;Linguistics;Generative adversarial networks;Gallium nitride;Acoustics;Decoding;Task analysis","interpolation;neural nets;speaker recognition;speech processing;speech synthesis","training-objective function;adversarial training scheme;StarGAN;nonparallel CLVC model;nonparallel cross-lingual voice conversion model;interpolated speaker embedding;fictitious voices;speaker-similarity measurement;F0 injection method;VAE;star generative adversarial network;variational autoencoder;controllable speaker individuality","","","","33","CCBY","2 Mar 2021","","","IEEE","IEEE Journals"
"Neighborhood Geometric Structure-Preserving Variational Autoencoder for Smooth and Bounded Data Sources","X. Chen; C. Wang; X. Lan; N. Zheng; W. Zeng","Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Microsoft Research Asia, Beijing, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Microsoft Research Asia, Beijing, China","IEEE Transactions on Neural Networks and Learning Systems","3 Aug 2022","2022","33","8","3598","3611","Many data sources, such as human poses, lie on low-dimensional manifolds that are smooth and bounded. Learning low-dimensional representations for such data is an important problem. One typical solution is to utilize encoder–decoder networks. However, due to the lack of effective regularization in latent space, the learned representations usually do not preserve the essential data relations. For example, adjacent video frames in a sequence may be encoded into very different zones across the latent space with holes in between. This is problematic for many tasks such as denoising because slightly perturbed data have the risk of being encoded into very different latent variables, leaving output unpredictable. To resolve this problem, we first propose a neighborhood geometric structure-preserving variational autoencoder (SP-VAE), which not only maximizes the evidence lower bound but also encourages latent variables to preserve their structures as in ambient space. Then, we learn a set of small surfaces to approximately bound the learned manifold to deal with holes in latent space. We extensively validate the properties of our approach by reconstruction, denoising, and random image generation experiments on a number of data sources, including synthetic Swiss roll, human pose sequences, and facial expression images. The experimental results show that our approach learns more smooth manifolds than the baselines. We also apply our approach to the tasks of human pose refinement and facial expression image interpolation where it gets better results than the baselines.","2162-2388","","10.1109/TNNLS.2021.3053591","Trico-Robot Plan of NSFC(grant numbers:91748208); NSFC(grant numbers:61973246,62088102); Shaanxi Project(grant numbers:2018ZDCXLGY0607); Program of the Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350115","Bounded representation;manifold learning;variational autoencoder (VAE)","Task analysis;Manifolds;Principal component analysis;Noise reduction;Interpolation;Image reconstruction;Decoding","approximation theory;face recognition;graph theory;interpolation;learning (artificial intelligence);pose estimation","slightly perturbed data;different latent variables;neighborhood geometric structure-preserving variational autoencoder;ambient space;learned manifold;latent space;human pose sequences;smooth manifolds;bounded data sources;human poses;low-dimensional manifolds;low-dimensional representations;encoder-decoder networks;learned representations;essential data relations;adjacent video frames","","","","53","IEEE","8 Feb 2021","","","IEEE","IEEE Journals"
"Federated Variational Autoencoder for Collaborative Filtering","M. Polato","Department of Mathematics, University of Padova, Padova, Italy","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","8","Recommender Systems (RSs) are valuable technologies that help users in their decision-making process. Generally, RSs are designed with the assumption that a central server stores and manages historical users' behaviors. However, users are nowadays more aware of privacy issues leading to a higher demand for privacy-preserving technologies. To cope with this issue, the Federated Learning (FL) paradigm can provide good performance without harming the users' privacy. Some efforts have been devoted to adapt standard collaborative filtering methods (e.g., matrix factorization) into the FL framework in recent years. In this paper, we present a Federated Variational Autoencoder for Collaborative Filtering (FedVAE), which extends the state-of-the-art MultVAE model. Additionally, we propose an adaptive learning rate schedule to accelerate learning. We also discuss the potential privacy-preserving capabilities of FedVAE. An extensive experimental evaluation on five benchmark data sets shows that our proposal can achieve performance close to MultVAE in a reasonable number of iterations. We also empirically demonstrate that the adaptive learning rate guarantees both accelerated learning and good stability.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533358","federated learning;variational autoencoder;collaborative filtering;recommender systems;top-n item recommendation","Privacy;Adaptive learning;Schedules;Collaborative filtering;Neural networks;Stability analysis;Servers","collaborative filtering;data privacy;decision making;learning (artificial intelligence);neural nets;recommender systems","Federated Variational Autoencoder;FedVAE;MultVAE model;adaptive learning rate;potential privacy-preserving capabilities;accelerated learning;Recommender Systems;RSs;decision-making process;central server;privacy-preserving technologies;federated learning paradigm;standard collaborative filtering methods;matrix factorization;FL framework;historical user behavior management;benchmark data sets","","","","40","","20 Sep 2021","","","IEEE","IEEE Conferences"
"Multimodal Variational Autoencoders for Sensor Fusion and Cross Generation","M. Da Silva–Filarder; A. Ancora; M. Filippone; P. Michiardi","Renault Software Factory Eurecom, France; Renault Software Factory; Eurecom, France; Eurecom, France","2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA)","25 Jan 2022","2021","","","1069","1076","The cognitive system of humans, which allows them to create representations of their surroundings exploiting multiple senses, has inspired several applications to mimic this remarkable property. The key for learning rich representations of data collected by multiple, diverse sensors, is to design generative models that can ingest multimodal inputs, and merge them in a common space. This enables to: i) obtain a coherent generation of samples for all modalities, ii) enable cross-sensor generation, by using available modalities to generate missing ones and iii) exploit synergy across modalities, to increase reconstruction quality. In this work, we study multimodal variational autoencoders, and propose new methods for learning a joint representation that can both improve synergy and enable cross generation of missing sensor data. We evaluate these approaches on well-established datasets as well as on a new dataset that involves multimodal object detection with three modalities. Our results shed light on the role of joint posterior modeling and training objectives, indicating that even simple and efficient heuristics enable both synergy and cross generation properties to coexist.","","978-1-6654-4337-1","10.1109/ICMLA52953.2021.00175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680207","Multimodal;Variational;Autoencoder","Training;Solid modeling;Three-dimensional displays;Shape;Spaceborne radar;Sensor fusion;Data models","Bayes methods;cognitive systems;image fusion;image reconstruction;learning (artificial intelligence);object detection","cross generation;sensor data;multimodal object detection;generation properties;multimodal variational autoencoders;sensor fusion;multiple senses;remarkable property;rich representations;multiple sensors;diverse sensors;generative models;multimodal inputs;common space;cross-sensor generation;available modalities;joint representation","","","","28","IEEE","25 Jan 2022","","","IEEE","IEEE Conferences"
"Semi-Supervised Gaussian Mixture Variational Autoencoder for Pulse Shape Discrimination","A. Abdulaziz; J. Zhou; A. Di Fulvio; Y. Altmann; S. McLaughlin","School of Engineering and Physical Sciences, Heriot-Watt University, Edinburgh, U.K; Department of Nuclear, Plasma, and Radiological Engineering, University of Illinois at Urbana-Champaign, Urbana, U.S.A; Department of Nuclear, Plasma, and Radiological Engineering, University of Illinois at Urbana-Champaign, Urbana, U.S.A; School of Engineering and Physical Sciences, Heriot-Watt University, Edinburgh, U.K; School of Engineering and Physical Sciences, Heriot-Watt University, Edinburgh, U.K","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","3538","3542","We address the problem of pulse shape discrimination (PSD) for radiation sources characterization by leveraging a Gaussian mixture variational autoencoder (GMVAE). When using PSD to characterize radiation sources, the number of emission sources and types of pulses to be classified is usually known. Yet, the creation of labeled data can be challenging for some classes as it requires expensive expert annotation. In this context, GMVAE can learn the distinct features of pulses from only unlabeled data. We show that classification accuracy can be further enhanced by adopting a semi-supervised GMVAE with auxiliary loss functions when labeled data are available. The preliminary results on two datasets with different number of classes suggest superior performance of GMVAE compared to other classifiers such as Gaussian mixture model (GMM) for unsupervised and semi-supervised learning and random forest for supervised learning.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9747313","Royal Academy of Engineering; Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747313","Semi-supervised classification;Gaussian mixture variational autoencoder;pulse shape discrimination","Training;Three-dimensional displays;Shape;Supervised learning;Semisupervised learning;Signal processing;Speech processing","feature extraction;Gaussian processes;mixture models;neural nets;optical pulse shaping;semi-supervised learning (artificial intelligence);signal classification","semisupervised Gaussian mixture variational autoencoder;pulse shape discrimination;PSD;emission sources;unlabeled data;semisupervised GMVAE;Gaussian mixture model;semisupervised learning;radiation source characterization;pulse classification;pulse feature learning;auxiliary loss functions;light pulses","","","","27","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Unsupervised Deep Learning for Fault Detection on Spacecraft Using Improved Variational Autoencoder","G. Xiang; R. Tao; Y. Peng; K. Tian; C. Qu","Beijing Aerospace Automatic Control Institute, National Key Lab on Aerospace Intelligent Control School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Beijing Aerospace Automatic Control Institute, National Key Lab on Aerospace Intelligent Control, Beijing, China; Beijing Aerospace Automatic Control Institute, National Key Lab on Aerospace Intelligent Control, Beijing, China; Beijing Aerospace Automatic Control Institute, National Key Lab on Aerospace Intelligent Control, Beijing, China; Beijing Aerospace Automatic Control Institute, National Key Lab on Aerospace Intelligent Control, Beijing, China","2020 Chinese Automation Congress (CAC)","29 Jan 2021","2020","","","5527","5531","Fault detection is important for improving the reliability of spacecraft, ensuring the long-term stable operation, and reducing the economic loss caused by failure. In order to solve the problems such as the large amount of test data, the scarcity of fault data samples and the real-time requirements in the field of spacecraft fault detection, an improved unsupervised deep learning algorithm based on Variational Autoencoder (VAE) is proposed. The algorithm adopts Gated Recurrent Unit (GRU) based recurrent neural networks as encoder to automatically extract features of input data, and then uses VAE to learn the correlation features of multiple test data. The proposed network, trained only on the normal training dataset, is a typical unsupervised method which could learn features and reconstruct the data on the training set with a small loss. Once the reconstruction loss of the input data is larger than the pre-set threshold, the corresponding input data is considered as fault data. Experiments show that the proposed method is feasible and can effectively detect faults.","2688-0938","978-1-7281-7687-1","10.1109/CAC51589.2020.9327846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9327846","fault detection;gated recurrent unit;Variational Autoencoder;deep learning;spacecraft","Space vehicles;Feature extraction;Fault detection;Aerospace engineering;Aerospace control;Training;Decoding","deep learning (artificial intelligence);fault diagnosis;feature extraction;neural nets;recurrent neural nets;space vehicles;unsupervised learning","improved variational autoencoder;long-term stable operation;economic loss;fault data samples;real-time requirements;spacecraft fault detection;VAE;recurrent unit;recurrent neural networks;correlation features;multiple test data;normal training dataset;unsupervised method;reconstruction loss;unsupervised deep learning algorithm;gated recurrent unit;GRU;automatic feature extraction","","","","16","","29 Jan 2021","","","IEEE","IEEE Conferences"
"Face Expression Neutralisation Using Improved Variational Autoencoder","G. Wiem; D. Ali","University of Sousse,Networked Objects Control and Communication Systems Laboratory, National School of Engineers of Sousse National Engineering School of Monastir, Monastir; University of Sousse,Networked Objects Control and Communication Systems Laboratory, National School of Engineers of Sousse, Sousse","2022 6th International Conference on Advanced Technologies for Signal and Image Processing (ATSIP)","28 Jun 2022","2022","","","1","5","There is a high demand for realistic facial expressions in modern computer graphics and multimedia research. Unfortunately, synthesizing face expressions takes time, effort, and hard labour since high naturalism of face expressions is required. Despite recent advances in synthesizing realistic facial images, current generative models conflict to catch more involved image types, potentially due to their latent space simplified architecture. Furthermore, the union of a Generative Adversarial Network (GAN) with a Variational Autoencoder (VAE) by using usually the Adam optimizer has recently been studied and investigated in cutting-edge research. Hence, at tiem of learning the generator takes a long time and then overfit for a particular time instance. So, in this work, we will suggest integrating the VAE to GAN’s architecture by using the Ranger optimizer into an unsupervised generative model that at once learns to encode, generate and compare dataset samples to bring out various real neutral faces in a reduced and optimal time. Next, we proposed the probability distributions called Kullback-Leibler Divergence (KLD) as an objective weighting scheme that helps us to measure just how much information we lose when we choose an approximation during training. Also, the Mean Square Error (MSE), the most commonly used loss function for regression is used as a metric of evaluation for the experiment tests.","2687-878X","978-1-6654-5116-1","10.1109/ATSIP55956.2022.9805967","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9805967","Variational Autoencoder;Face expression neutralisation;image generation","Weight measurement;Training;Visualization;Computer architecture;Generative adversarial networks;Generators;Probability distribution","face recognition;neural nets;optimisation;probability;unsupervised learning","face expression neutralisation;realistic facial expressions;modern computer graphics;multimedia research;high naturalism;realistic facial images;latent space;generative adversarial network;VAE;Adam optimizer;time instance;GAN architecture;unsupervised generative model;neutral faces;face expression synthesis;ranger optimizer;image types;Kullback-Leibler divergence;KLD;mean square error;MSE;regression loss function;probability distributions;variational autoencoder","","","","33","IEEE","28 Jun 2022","","","IEEE","IEEE Conferences"
"Shedding Light on Variational Autoencoders","J. C. Ruiz Vargas; S. F. Novaes; R. Cóbe; R. Iope; S. L. Stanzani; T. Tomei","São Paulo State University (Unesp), Center for Scientific Computing (NCC), São Paulo; São Paulo State University (Unesp), Center for Scientific Computing (NCC), São Paulo; São Paulo State University (Unesp), Center for Scientific Computing (NCC), São Paulo; São Paulo State University (Unesp), Center for Scientific Computing (NCC), São Paulo; São Paulo State University (Unesp), Center for Scientific Computing (NCC), São Paulo; São Paulo State University (Unesp), Center for Scientific Computing (NCC), São Paulo","2018 XLIV Latin American Computer Conference (CLEI)","5 Aug 2019","2018","","","294","298","Deep neural networks provide the canvas to create models of millions of parameters to fit distributions involving an equally large number of random variables. The contribution of this study is twofold. First, we introduce a diffraction dataset containing computer-based simulations of a Young's interference experiment. Then, we demonstrate the adeptness of variational autoencoders to learn diffraction patterns and extract a latent feature that correlates with the physical wavelength.","","978-1-7281-0437-9","10.1109/CLEI.2018.00043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8786343","Variational Autoencoders, Machine Learning, Tensorflow, Fresnel diffraction","Diffraction;Decoding;Computational modeling;Training;Computer architecture;Correlation","feature extraction;learning (artificial intelligence);light diffraction;neural nets;random processes","shedding light;variational autoencoders;deep neural networks;random variables;diffraction dataset;computer-based simulations;Young's interference experiment;diffraction patterns;latent feature extraction;physical wavelength","","","","21","","5 Aug 2019","","","IEEE","IEEE Conferences"
"On a Possible Quantum Variational Autoencoder Circuit","S. Pramanik; M. G. Chandra","TCS Research, India; TCS Research, India","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","6","Generative Models have always attracted the attention of Machine Learning research community; they are useful and also generally harder than their discriminative counterparts. In these models, we would be looking into learning the probability distribution of the input and sampling from that to generate new data samples. Since quantum computing and algorithms are inherently random, they can facilitate a natural framework in this situation. But, getting a suitable gate circuit to achieve the requisite quantum state which by repeated preparation and measurement leads to the sought-after data samples is not trivial. In this paper, we propose a quantum circuit which has a flavor of Variational Autoencoder with the usual visible and hidden nodes for input data and latent distribution. The encoder portion comprises of a suitably chosen parameterized phase ansatz and Inverse Quantum Fourier Transform blocks. Depending on whether the measurement is carried out on the hidden nodes or not, the decoder circuit, which is just not the inverse of the encoder in our case, is configured. The Kullback-Leibler Divergence is used train the circuit towards the required input distribution. Numerical results presented demonstrate the correct functionality of the approach.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533801","generative model;variational autoencoder;quantum circuit;inverse quantum fourier transform;ansatz;kullback-liebler divergence","Computational modeling;Computer architecture;Logic gates;Quantum state;Data models;Probability distribution;Numerical models","encoding;Fourier transforms;learning (artificial intelligence);probability;quantum gates","discriminative counterparts;probability distribution;data samples;quantum computing;natural framework;suitable gate circuit;quantum circuit;hidden nodes;decoder circuit;inverse quantum Fourier transform blocks;parameterized phase ansatz;quantum state;generative models;quantum variational autoencoder circuit","","","","14","IEEE","20 Sep 2021","","","IEEE","IEEE Conferences"
"Ultrasound Anomaly Detection Based on Variational Autoencoders","F. Milković; B. Filipović; M. Subašić; T. Petković; S. Lončarić; M. Budimir","Faculty of Electrical Engineering and Computing, University of Zagreb; Faculty of Electrical Engineering and Computing, University of Zagreb; Faculty of Electrical Engineering and Computing, University of Zagreb; Faculty of Electrical Engineering and Computing, University of Zagreb; Faculty of Electrical Engineering and Computing, University of Zagreb; Institute for Nuclear Technology Zagreb","2021 12th International Symposium on Image and Signal Processing and Analysis (ISPA)","5 Oct 2021","2021","","","225","229","Analysis of ultrasonic testing (UT) data is a time-consuming assignment. In order to make it less demanding we propose an approach based on a variational autoencoder (VAE) to filter out the scans without anomalies/defects and in doing so, partially automate the procedure. The implemented approach uses an additional encoder network allowing to encode the reconstructed images. The differences in encodings of input and reconstructed images have shown to be good indicators of anomalous data. Anomaly detection results surpass the results of other VAE based anomaly criteria.","1849-2266","978-1-6654-2639-8","10.1109/ISPA52656.2021.9552041","European Union through the European Regional Development Fund(grant numbers:KK.01.2.1.01.0151); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552041","ultrasonic testing;anomaly detection;variational autoencoder;deep learning;computer vision","Ultrasonic imaging;Image coding;Signal processing;Acoustics;Image reconstruction;Anomaly detection;Testing","data analysis;image coding;image filtering;image reconstruction;neural nets;object detection;ultrasonic materials testing","ultrasound anomaly detection;variational autoencoder;UT;image reconstruction;anomalous data;ultrasonic testing data analysis;encoder network;VAE based anomaly criteria","","","","24","","5 Oct 2021","","","IEEE","IEEE Conferences"
"Data Augmentation for Monaural Singing Voice Separation Based on Variational Autoencoder-Generative Adversarial Network","B. He; S. Wang; W. Yuan; J. Wang; M. Unoki","Tianjin Key Laboratory of Autonomous Intelligence Technology and Systems, Tianjin Polytechnic University, China; Tianjin Key Laboratory of Autonomous Intelligence Technology and Systems, Tianjin Polytechnic University, China; Tianjin Key Laboratory of Autonomous Intelligence Technology and Systems, Tianjin Polytechnic University, China; Tianjin Key Laboratory of Autonomous Intelligence Technology and Systems, Tianjin Polytechnic University, China; School of Information Science, Japan Advanced Institute of Science and Technology, Japan","2019 IEEE International Conference on Multimedia and Expo (ICME)","5 Aug 2019","2019","","","1354","1359","Random mixing and circularly shifting for augmenting the training set are used to improve the separation effect of deep neural network (DNN)-based monaural singing voice separation (MSVS). However, these manual methods are based on unrealistic assumptions that two sources in the mixture are independent of each other, which limits the separation effect. This paper proposes a data augmentation method based on variational autoencoder (VAE) and generative adversarial network (GAN), which is called as VAE-GAN. The VAE models the observed spectra of sources (vocal and music) separately and reconstructs new spectra from the latent space. The GAN's discriminator is introduced to measure the correlation between the latent variables of the vocal and music generated by the VAE probability encoder. This adversarial mechanism in VAE's latent space could learn the synthetic likelihood and ultimately decode high quality spectra samples, which further improves the separation effect of general MSVS networks.","1945-788X","978-1-5386-9552-4","10.1109/ICME.2019.00235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8784920","Variational Autoencoder, Generative Adversarial Network, Data Augmentation, Monaural Singing Voice Separation, Deep Neural Network","Gallium nitride;Training;Correlation;Decoding;Neural networks;Generators;Gaussian distribution","audio signal processing;music;neural nets;probability;source separation;speech coding","variational autoencoder-generative adversarial network;deep neural network-based monaural singing voice separation;data augmentation method;VAE-GAN;VAE models;vocal;music;VAE probability encoder;adversarial mechanism;general MSVS networks","","","","18","","5 Aug 2019","","","IEEE","IEEE Conferences"
"Research on Missing Data Imputation Based on Conditional Variational Autoencoder","Y. Xu; Y. Ni","Information Engineering University, Zhengzhou, China; Jiangnan Institute of Computing Technology, Wuxi, China","2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI)","28 Feb 2022","2021","","","726","730","With the development of artificial intelligence technology, data has become an important resource with much attention being attracted. However, in the process of data collection, transmission and storage, data missing happens inevitably due to various reasons. In order to reduce the impact of missing data on data application, this paper proposes a multiple imputation model for missing data based on conditional variational autoencoder. The model is trained on an incomplete dataset, using multiple sampling from the latent space to generate multiple estimates. In the model accuracy of the estimates has been improved, constrained by classification label of the data. Experiments were carried out on open source datasets and evaluated with existing imputation methods.","","978-1-6654-0692-5","10.1109/CISAI54367.2021.00147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9719168","impotation;missing data;conditional variational autoencoder","Interpolation;Information science;Big Data applications;Data models;Artificial intelligence","artificial intelligence;data handling;neural nets;pattern classification;sampling methods","missing data imputation;conditional variational autoencoder;artificial intelligence;data application;multiple sampling;data classification label;data collection;data transmission;data storage","","","","14","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"Variational autoencoder as a generative tool to produce de-novo lead compounds for biological targets","V. Ullanat","Department of Biotechnology, RV College of Engineering, Bengaluru, India","2020 14th International Conference on Innovations in Information Technology (IIT)","25 Dec 2020","2020","","","102","107","A variational autoencoder (VAE) is a generational deep learning model based on encoding a particular observation into a latent space and then decoding it while incorporating some random noise with the intuition of being able to generate slightly different forms of the input observation. Here, I propose a VAE that is able to generate denovo drug compounds by feeding in a known set of drug compounds against a particular biological target. To demonstrate the ability of the proposed VAE as a generative model, known drug molecules belonging to the class of Neuraminidase (NA) inhibitors were taken from the ZINC database and fed into the VAE model as one-hot encoded SMILES strings. Similarly, active NA inhibitors and decoy molecules together were also fed to compare efficiency. The generated molecules were then screened to remove impractical structures. Next, a drug-likeness (QED) score was computed for each candidate molecule and a cutoff of 0.5 was used to extract viable candidates. To ensure that the generated drug compounds were active NA inhibitors, a series of Artificial Neural Networks (ANNs) classifiers based on three different characterization techniques, namely chemical fingerprinting, molecular descriptions and graph convolutions, were developed to identify active NA inhibitors from decoy molecules. The feature candidate data were then fed into the three designed ANNs to obtain the final set of novel, viable and active NA inhibitors. Seventy-one new NA inhibitors were obtained after three runs of the VAE model under different parameterizations. The proposed VAE can hence be used to generate de-novo drug compounds for a wide variety of biological targets.","2325-5498","978-1-7281-8184-4","10.1109/IIT50501.2020.9299078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9299078","Variational Autoencoder;ANNs;ZINC Database;SMILES strings;QED score;Neuraminidase","Inhibitors;Drugs;Compounds;Chemicals;Fingerprint recognition;Decoding;Zinc","biology computing;convolutional neural nets;deep learning (artificial intelligence);drugs;graph theory;lead compounds;molecular biophysics;pattern classification;random noise","graph convolutions;molecular descriptions;chemical fingerprinting;ANN classifiers;QED;ZINC database;decoding;encoding;deep learning;VAE;drug-likeness score;one-hot encoded SMILES strings;Neuraminidase inhibitors;drug molecules;biological target;random noise;latent space;artificial neural networks classifiers;decoy molecules;NA inhibitors;de-novo drug compounds;variational autoencoder;generative tool;de-novo lead compounds","","","","10","","25 Dec 2020","","","IEEE","IEEE Conferences"
"Degradation Prediction of Semiconductor Lasers Using Conditional Variational Autoencoder","K. Abdelli; H. Grießer; C. Neumeyr; R. Hohenleitner; S. Pachnicke","Kiel University (CAU), Chair of Communications, Kiel, Germany; ADVA Optical Networking SE, Munich/ Martinsried, Germany; Vertilas GmbH, Munich, Germany; Vertilas GmbH, Munich, Germany; Kiel University (CAU), Chair of Communications, Kiel, Germany","Journal of Lightwave Technology","2 Sep 2022","2022","40","18","6213","6221","Semiconductor lasers have been rapidly evolving to meet the demands of next-generation optical networks. This imposes much more stringent requirements on the laser reliability, which are dominated by degradation mechanisms (e.g., sudden degradation) limiting the semiconductor laser lifetime. Physics-based approaches are often used to characterize the degradation behavior analytically, yet explicit domain knowledge and accurate mathematical models are required. Building such models can be very challenging due to a lack of a full understanding of the complex physical processes inducing the degradation under various operating conditions. To overcome the aforementioned limitations, we propose a new data-driven approach, extracting useful insights from the operational monitored data to predict the degradation trend without requiring any specific knowledge or using any physical model. The proposed approach is based on an unsupervised technique, a conditional variational autoencoder, and validated using vertical-cavity surface-emitting laser (VCSEL) and tunable edge emitting laser reliability data. The experimental results confirm that our model (i) achieves a good degradation prediction and generalization performance by yielding an F1 score of 95.3%, (ii) outperforms several baseline ML based anomaly detection techniques, and (iii) helps to shorten the aging tests by early predicting the failed devices before the end of the test and thereby saving costs.","1558-2213","","10.1109/JLT.2022.3188831","CELTIC-NEXT; AI-NET-PROTECT Project(grant numbers:C2019/3-4); German Federal Ministry of Education and Research(grant numbers:FKZ16KIS1279K); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815877","Degradation prediction;machine learning;semiconductor laser reliability;semiconductor lasers;variational autoencoder","Degradation;Vertical cavity surface emitting lasers;Decoding;Laser modes;Logic gates;Reliability;Data models","laser reliability;neural nets;semiconductor lasers;surface emitting lasers","semiconductor lasers;conditional variational autoencoder;next-generation optical networks;degradation mechanisms;semiconductor laser lifetime;physics-based approaches;degradation behavior;explicit domain knowledge;mathematical models;complex physical processes;data-driven approach;operational monitored data;degradation trend;physical model;degradation prediction;unsupervised technique;vertical-cavity surface-emitting laser;VCSEL;tunable edge emitting laser reliability data;aging tests","","","","17","IEEE","6 Jul 2022","","","IEEE","IEEE Journals"
"H-VAE: A Hybrid Variational AutoEncoder with Data Augmentation in Predicting CRISPR/Cas9 Off-target","W. Xiang; D. Chen; Y. Cui; S. Peng","College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China","2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","14 Jan 2022","2021","","","550","555","CRISPR/Cas9-based gene editing technology has been widely used in various cells and organisms. However, the off-target effects will bring unpredictable consequences to the organism edited. One of the main obstacles to predict CRISPR/Cas9 off-target is the imbalance of the number of positive and negative samples, which puts forward a challenge for the training of traditional deep learning algorithms. In this paper, we proposed H-VAE, a hybrid variational autoencoder model with data augmentation. This model can extract more abundant sgRNA-DNA base pair matching information, and reduce the risk of overfitting. Moreover, the sample imbalance is resolved. H-VAE can make use of underlying information of training sample, extracted by VAE, to alleviate data-imbalance problem. In view of the weak ability to extract base pair matching information of existing models, a different encoding scheme based on pair encoding is proposed, which enables the model to make full use of sgRNA-DNA base pair matching information. On the Mismatch data set, compared with DeepCRISPR, the ROC-AUC and PR-AUC increased by 0.6% and 41.9%, respectively. In the new Indels data set test scenario, compared with CRISPR-Net, the ROC-AUC and PR-AUC were increased by 1.5% and 133.4% respectively. This proves that H-VAE can improve off-target prediction in various scenarios. The improvement of PR-AUC shows that H-VAE can significantly improve the effect of unbalanced classification. The experimental results demonstrate that H-VAE could achieve a better effect compared with state-of-the-art CRISPR/Cas9 off-target methods on various types of data sets. The code and data can be obtained at https://github.com/weimingxiang/H-VAE.","","978-1-6654-0126-5","10.1109/BIBM52615.2021.9669570","State Key Laboratory of Chemo/Biosensing and Chemometrics; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669570","Variational Autoencoder;CRISPR/Cas9;Off-target Prediction","Training;Deep learning;Codes;Conferences;Prediction algorithms;Organisms;Encoding","DNA;learning (artificial intelligence);molecular biophysics;pattern classification","ROC-AUC;Indels data set test scenario;CRISPR-Net;off-target prediction;PR-AUC shows;data sets;data augmentation;organisms;off-target effects;positive samples;negative samples;traditional deep learning algorithms;hybrid variational autoencoder model;sgRNA-DNA base pair matching information;sample imbalance;underlying information;training sample;data-imbalance problem;pair encoding;Mismatch data set","","","","14","IEEE","14 Jan 2022","","","IEEE","IEEE Conferences"
"Learning Subject-Invariant Representations from Speech-Evoked EEG Using Variational Autoencoders","L. Bollens; T. Francart; H. V. Hamme","Dept. Neurosciences, KU Leuven, ExpORL, Leuven, Belgium; Dept. Neurosciences, KU Leuven, ExpORL, Leuven, Belgium; Dept. of Electrical Engineering (ESAT), KU Leuven, PSI, Leuven, Belgium","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","1256","1260","The electroencephalogram (EEG) is a powerful method to understand how the brain processes speech. Linear models have recently been replaced for this purpose with deep neural networks and yield promising results. In related EEG classification fields, it is shown that explicitly modeling subject-invariant features improves generalization of models across subjects and benefits classification accuracy. In this work, we adapt factorized hierarchical variational autoencoders to exploit parallel EEG recordings of the same stimuli. We model EEG into two disentangled latent spaces. Subject accuracy reaches 98.96% and 1.60% on respectively the subject and content latent space, whereas binary content classification experiments reach an accuracy of 51.51% and 62.91% on respectively the subject and content latent space.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9747297","KU Leuven; European Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747297","factorized hierarchical variational autoencoder;speech decoding;EEG;unsupervised learning;domain generalization","Deep learning;Adaptation models;Conferences;Neural networks;Signal processing;Brain modeling;Electroencephalography","electroencephalography;learning (artificial intelligence);medical signal processing;neural nets;pattern classification;signal classification","respectively the subject space;content latent space;subject-invariant representations;speech-evoked EEG;electroencephalogram;linear models;deep neural networks;yield promising results;related EEG classification fields;subject-invariant features;benefits classification accuracy;hierarchical variational autoencoders;disentangled latent spaces;subject accuracy;binary content classification experiments","","","","23","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"RecGraph: Graph Recovery Attack using Variational Graph Autoencoders","J. Tian; C. Liu; G. Gou; Z. Li; G. Xiong; Y. Guan","School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China","2021 IEEE International Performance, Computing, and Communications Conference (IPCCC)","20 Jan 2022","2021","","","1","7","Graph-structured data contains a lot of sensitive information about individuals. In order to protect users’ privacy, many anonymization mechanisms for graph-structured data are proposed. However, one common drawback of these mechanisms is that they only consider to hide the local characteristics, such as the degree of nodes or their neighbors. They lack the consideration for the nodes’ attribute features and the features of potential global graph structure, which leads to the failure of these mechanisms to provide sufficient security.To address this shortcoming, we propose RecGraph, a framework for graph recovery attack based on variational graph autoencoders. We use RecGraph to perform graph recovery attack on three real social network datasets, and compare it with five existing baselines, to prove the effectiveness of our method. We also evaluate the privacy wastage after performing the graph recovery attack using RecGraph to demonstrate the serious security risks faced by the existing graph anonymization mechanisms.","2374-9628","978-1-6654-4331-9","10.1109/IPCCC51483.2021.9679427","National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679427","Graph-structured data;graph recovery attack;variational graph autoencoders","Privacy;Data privacy;Social networking (online);Perturbation methods;Conferences;Neural networks;Computer architecture","computer crime;data privacy;graph theory;neural nets;social networking (online)","RecGraph;graph recovery attack;variational graph autoencoders;graph-structured data;global graph structure;graph anonymization mechanisms;users privacy;privacy wastage;security risks;social network datasets","","","","24","IEEE","20 Jan 2022","","","IEEE","IEEE Conferences"
"Time-Lag Aware Multi-Modal Variational Autoencoder Using Baseball Videos And Tweets For Prediction Of Important Scenes","K. Hirasawa; K. Maeda; T. Ogawa; M. Haseyama","Graduate School of Information Science and Technology, Hokkaido University; Office of Institutional Research, Hokkaido University; Faculty of Information Science and Technology, Hokkaido University; Faculty of Information Science and Technology, Hokkaido University","2021 IEEE International Conference on Image Processing (ICIP)","23 Aug 2021","2021","","","2678","2682","A novel method based on time-lag aware multi-modal variational autoencoder for prediction of important scenes (TI-MVAE-PIS) using baseball videos and tweets posted on Twitter is presented in this paper. This paper has the following two technical contributions. First, to effectively use heterogeneous data for the prediction of important scenes, we transform textual, visual and audio features obtained from tweets and videos to the latent features. Then TI-MVAE-PIS can flexibly express the relationships between them in the constructed latent space. Second, since there are time-lags between tweets and the corresponding multiple previous events, Tl-MVAE-PIS considers such time-lags in their relationship estimation for successfully deriving their latent features. Therefore, these two contributions enable accurate important scene prediction. Results of experiments using actual baseball videos and their corresponding tweets show the effectiveness of TI-MVAE-PIS.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506496","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506496","Multimodal variational autoencoder;important scene prediction;sports video;time-lag;Twitter","Visualization;Social networking (online);Image processing;Conferences;Blogs;Estimation;Transforms","feature extraction;image motion analysis;social networking (online);sport;video signal processing","time-lag aware multimodal variational autoencoder;TI-MVAE-PIS;textual features;visual features;audio features;latent features;accurate important scene prediction;actual baseball videos;corresponding tweets;important scenes prediction","","","","25","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"Field-aware Variational Autoencoders for Billion-scale User Representation Learning","G. Fan; C. Zhang; J. Chen; B. Li; Z. Xu; Y. Li; L. Peng; Z. Gong","Tencent Inc., Shenzhen, China; Tencent Inc., Shenzhen, China; Shenzhen University, Shenzhen, China; Baidu USA, Sunnyvale, USA; Harbin Institute of Technology (Shenzhen), Shenzhen, China; Tencent Inc., Shenzhen, China; Tencent Inc., Shenzhen, China; University of Macau, Macau, China","2022 IEEE 38th International Conference on Data Engineering (ICDE)","2 Aug 2022","2022","","","3413","3425","User representation learning plays an essential role in Internet applications, such as recommender systems. Though developing a universal embedding for users is demanding, only few previous works are conducted in an unsupervised learning manner. The unsupervised method is however important as most of the user data is collected without specific labels. In this paper, we harness the unsupervised advantages of Variational Autoencoders (VAEs), to learn user representation from large-scale, high-dimensional, and multi-field data. We extend the traditional VAE by developing Field-aware VAE (FVAE) to model each feature field with an independent multinomial distribution. To reduce the complexity in training, we employ dynamic hash tables, a batched softmax function, and a feature sampling strategy to improve the efficiency of our method. We conduct experiments on multiple datasets, showing that the proposed FVAE significantly outperforms baselines on several tasks of data reconstruction and tag prediction. Moreover, we deploy the proposed method in real-world applications and conduct online A/B tests in a look-alike system. Results demonstrate that our method can effectively improve the quality of recommendation. To the best of our knowledge, it is the first time that the VAE-based user representation learning model is applied to real-world recommender systems.","2375-026X","978-1-6654-0883-7","10.1109/ICDE53745.2022.00321","National Natural Science Foundation of China(grant numbers:62102265); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9835571","User Representation Learning;Recommender Systems;Lookalike Systems;Variational Autoencoder","Representation learning;Training;Measurement;Conferences;Data engineering;Data models;Internet","Internet;learning (artificial intelligence);recommender systems;unsupervised learning","traditional VAE;Field-aware VAE;FVAE;feature field;independent multinomial distribution;dynamic hash tables;feature sampling strategy;data reconstruction;tag prediction;real-world applications;look-alike system;VAE-based user representation learning model;real-world recommender systems;Field-aware Variational Autoencoders;billion-scale user representation learning;Internet applications;universal embedding;unsupervised learning manner;unsupervised method;user data;specific labels;unsupervised advantages;VAEs;multifield data","","","","67","IEEE","2 Aug 2022","","","IEEE","IEEE Conferences"
"Prognostics With Variational Autoencoder by Generative Adversarial Learning","Y. Huang; Y. Tang; J. VanZwieten","Department of Computer & Electrical Engineering and Computer Science, Florida Atlantic University, Boca Raton, FL, USA; Department of Computer & Electrical Engineering and Computer Science, Florida Atlantic University, Boca Raton, FL, USA; Department of Civil, Environmental, and Geomatics Engineering, Florida Atlantic University, Boca Raton, FL, USA","IEEE Transactions on Industrial Electronics","4 Oct 2021","2022","69","1","856","867","Prognostics predicts the future performance progression and remaining useful life (RUL) of in-service systems based on historical and contemporary data. One of the challenges in prognostics is the development of methods that are capable of handling real-world uncertainties that typically lead to inaccurate predictions. To alleviate the impacts of uncertainties and to achieve accurate degradation trajectory and RUL predictions, a novel sequence-to-sequence predictive model is proposed based on a variational autoencoder that is trained with generative adversarial networks. A long short-term memory network and a Gaussian mixture model are utilized as building blocks so that the model is capable of providing probabilistic predictions. Correlative and monotonic metrics are applied to identify sensitive features in the degradation progress, in order to reduce the uncertainty induced from raw data. Then, the selected features are concatenated with one-hot health state indicators as training data for the model to learn end of life without the need for prior knowledge of failure thresholds. Performance of the proposed model is validated by health monitoring data collected from real-world aeroengines, wind turbines, and lithium-ion batteries. The results demonstrate that significant performance improvement can be achieved in long-term degradation progress and RUL prediction tasks.","1557-9948","","10.1109/TIE.2021.3053882","National Science Foundation(grant numbers:ECCS-1809164,OAC-2017597); U.S. Department of Energy, Water Power Technologies Office(grant numbers:DE-EE0008955); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9339944","Gaussian mixture model (GMM);generative adversarial learning;long short-term memory (LSTM);prognostics and health management (PHM);remaining useful life (RUL);variational autoencoder (VAE)","Degradation;Predictive models;Prognostics and health management;Generative adversarial networks;Gallium nitride;Feature extraction;Data models","aerospace engines;condition monitoring;Gaussian processes;learning (artificial intelligence);neural nets;probability;remaining life assessment;secondary cells;statistical analysis","variational autoencoder;generative adversarial learning;future performance progression;remaining useful life;in-service systems;historical data;contemporary data;real-world uncertainties;inaccurate predictions;accurate degradation trajectory;novel sequence-to-sequence predictive model;generative adversarial networks;short-term memory network;Gaussian mixture model;building blocks;probabilistic predictions;correlative metrics;monotonic metrics;sensitive features;raw data;one-hot health state indicators;training data;health monitoring data;real-world aeroengines;long-term degradation progress;RUL prediction tasks","","","","37","IEEE","28 Jan 2021","","","IEEE","IEEE Journals"
"Self-supervised Variational Autoencoder for Recommender Systems","J. Wang; G. Liu; J. Wu; C. Jia; Z. Zhang","School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China","2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)","21 Dec 2021","2021","","","831","835","Variational autoencoder (VAE) is considered as an emerging model for ensuring competitive performance in recom-mender systems. However, its performance is severely limited by the amount of training examples and, as a result, existing VAE models may fail to provide satisfactory recommendation results in presence of highly sparse user-item interactions. In this paper, we propose a self-supervised VAE model, SSVAE in short, to improve the generalization ability of VAE model on the sparse interaction datasets. Concretely, we first build multiple views for each user by data augmentation, and then design a pretext task to align the representations learned from different views of each user. Particularly, SSVAE aims to optimize a combined objective of recommendation task and pretext task, making them to rein-force each other during the learning process. Our encouraging experimental results on three real-world benchmarks validate the superiority of our SSVAE model to state-of-the-art VAE style recommendation techniques.","2375-0197","978-1-6654-0898-1","10.1109/ICTAI52525.2021.00132","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9643343","Recommender Systems;Self-supervised Learning;Variational Autoencoder","Training;Conferences;Collaborative filtering;Learning (artificial intelligence);Benchmark testing;Data models;Organ transplantation","collaborative filtering;learning (artificial intelligence);recommender systems","pretext task;encouraging experimental results;SSVAE model;state-of-the-art VAE style recommendation techniques;self-supervised variational autoencoder;recommender systems;emerging model;competitive performance;recom-mender systems;satisfactory recommendation results;highly sparse user-item interactions;self-supervised VAE model;sparse interaction datasets;recommendation task","","","","14","IEEE","21 Dec 2021","","","IEEE","IEEE Conferences"
"Inference-Reconstruction Variational Autoencoder for Light Field Image Reconstruction","K. Han; W. Xiang","La Trobe University, Melbourne, VIC, Australia; School of Computing, Engineering and Mathematical Sciences, La Trobe University, Melbourne, VIC, Australia","IEEE Transactions on Image Processing","30 Aug 2022","2022","31","","5629","5644","Light field cameras can capture the radiance and direction of light rays by a single exposure, providing a new perspective to photography and 3D geometry perception. However, existing sub-aperture based light field cameras are limited by their sensor resolution to obtain high spatial and angular resolution images simultaneously. In this paper, we propose an inference-reconstruction variational autoencoder (IR-VAE) to reconstruct a dense light field image out of four corner reference views in a light field image. The proposed IR-VAE is comprised of one inference network and one reconstruction network, where the inference network infers novel views from existing reference views and viewpoint conditions, and the reconstruction network reconstructs novel views from a latent variable that contains the information of reference views, novel views, and viewpoints. The conditional latent variable in the inference network is regularized by the latent variable in the reconstruction network to facilitate information flow between the conditional latent variable and novel views. We also propose a statistic distance measurement dubbed the mean local maximum mean discrepancy (MLMMD) to enable the measurement of the statistic distance between two distributions with high-resolution latent variables, which can capture richer information than their low-resolution counterparts. Finally, we propose a viewpoint-dependent indirect view synthesis method to synthesize novel views more efficiently by leveraging adaptive convolution. Experimental results show that our proposed methods outperform state-of-the-art methods on different light field datasets.","1941-0042","","10.1109/TIP.2022.3197976","Australian Government; Australian Research Council’s Discovery Projects Funding Scheme(grant numbers:DP220101634); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9864283","Light field image reconstruction;variational autoencoder;statistic distance measurement;indirect view synthesis;adaptive convolution","Image reconstruction;Convolution;Superresolution;Spatial resolution;Feature extraction;Cameras;Training","computational geometry;image reconstruction;image resolution;image sensors;neural nets","inference-reconstruction variational autoencoder;light field image reconstruction;light rays;3D geometry perception;sensor resolution;angular resolution images;IR-VAE;dense light field image;corner reference views;inference network;reconstruction network reconstructs;high-resolution latent variables;light field datasets;subaperture based light field cameras;viewpoint-dependent indirect view synthesis","","","","60","IEEE","22 Aug 2022","","","IEEE","IEEE Journals"
"Learning brain effective connectivity networks via controllable variational autoencoder","A. Zou; J. Ji","Faculty of Information Technology, Beijing Artificial Intelligence Institute, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing Artificial Intelligence Institute, Beijing University of Technology, Beijing, China","2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","14 Jan 2022","2021","","","284","287","Learning brain effective connectivity networks (ECNs) by means of deep learning methods from functional magnetic resonance imaging (fMRI) data is a novel study hot in neuroinformatics in recent years. However, current methods need manually tune and set a lot of model hyper-parameters. Once the parameter setting is unreasonable, it will seriously restrict the performance of algorithms. In this paper, we propose a novel method for learning ECNs based on controllable variational autoencoder (CVAE), named as CVAEEC. It can automatically tune model parameters and learn brain effective connectivity. In detail, the proposed method first adopts an encoder network to obtain the latent variables from the fMRI data of brain regions. And then, based on the latent variables, it utilizes a decoder network to obtain the generated fMRI data of brain regions. Once the generated fMRI data is highly similar to real fMRI data by iteratively training, CVAEEC algorithm can output an optimal brain ECN. The experimental results on a real dataset show that the proposed CVAEEC is able to better learn brain ECN compared to some state-of-the-art methods.","","978-1-6654-0126-5","10.1109/BIBM52615.2021.9669871","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669871","effective connectivity networks (ECNs);functional magnetic resonance imaging (fMRI);controllable variational autoencoder (CVAE);deep learning","Training;Learning systems;Deep learning;Heuristic algorithms;Conferences;Neuroinformatics;Functional magnetic resonance imaging","biomedical MRI;brain;encoding;learning (artificial intelligence);medical image processing;neurophysiology","brain effective connectivity networks;controllable variational autoencoder;ECNs;deep learning methods;functional magnetic resonance imaging data;model hyper-parameters;parameter setting;model parameters;encoder network;latent variables;brain regions;decoder network;generated fMRI data;optimal brain ECN","","","","16","IEEE","14 Jan 2022","","","IEEE","IEEE Conferences"
"Optimally designed Variational Autoencoders for Efficient Wind Characteristics Modelling","S. S. Miriyala; S. Chowdhury; N. K. Pujari; K. Mitra","Department of Chemical Engineering, Indian Institute of Technology, Hyderabad, Hyderabad, India; Department of Electrical Engineering, Indian Institute of Technology, Hyderabad, Hyderabad, India; Department of Chemical Engineering, Indian Institute of Technology, Hyderabad, Hyderabad, India; Department of Chemical Engineering, Indian Institute of Technology, Hyderabad, Hyderabad, India","2020 IEEE Symposium Series on Computational Intelligence (SSCI)","5 Jan 2021","2020","","","2869","2876","Wind energy is increasingly applied as a large scale clean energy generating alternative to fossil fuels. However, limited amount of real wind data results in inaccurate construction of Wind Frequency Maps (WFMs), which model the stochastic nature of wind. The inaccuracies in WFMs may lead to over or under estimation of wind power eventually causing significant losses to wind-farmers. Hence, to resolve this crisis, deep generative models such as convolutional Variational Autoencoders (VAEs) are implemented in this work to enable accurate construction of WFMs from limited amount of real wind characteristics data. However, the heuristics based estimation of hyper-parameters in VAEs decrease their efficiency. Thus, in this work, a novel multi-objective evolutionary neural architecture search (NAS) strategy is devised for simultaneously estimating the optimal number of convolutional and feedforward layers, number of filters/nodes in each layer, filter size, pooling option and nonlinear activation choice in VAEs. The proposed framework is designed to balance the conflicting objectives of generalizability and parsimony in VAEs, thereby reducing the chances of their over-fitting. The optimally designed VAE (with 92% accuracy) is used to generate new wind frequency scenarios for accurate construction of WFM. Additionally, the effect of number of new scenarios required for accurate WFM construction is also studied while performing the comparison with an ideal case. It was found that WFM constructed with original limited data resulted in 9% deficit in energy calculation from a single wind turbine, justifying the need for generative models such as VAEs for accurate wind characteristics modelling.","","978-1-7281-2547-3","10.1109/SSCI47803.2020.9308245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308245","Deep Generative modelling;Neural Architecture Search;multi-objective optimization;evolutionary algorithm;Variational Autoencoder;Wind energy conversion systems;Wind frequency maps.","Wind forecasting;Wind speed;Data models;Optimization;Predictive models;Training;Forecasting","evolutionary computation;neural nets;power system analysis computing;stochastic processes;wind power plants;wind turbines","optimally designed variational autoencoders;nonlinear activation;pooling option;hyper-parameters;heuristics based estimation;stochastic nature;wind energy;single wind turbine;wind frequency;feedforward layers;convolutional layers;optimal number;multiobjective evolutionary neural architecture search strategy;deep generative models;wind-farmers;wind power;WFM;wind frequency maps;fossil fuels;wind characteristics modelling","","","","21","","5 Jan 2021","","","IEEE","IEEE Conferences"
"Variational Autoencoder for Non-Negative Matrix Factorization with Exogenous Inputs Applied to Financial Data Modelling","L. Montesdeoca; S. Squires; M. Niranjan","Electronics and Computer Science, University of Southampton, Southampton, UK; Electronics and Computer Science, University of Southampton, Southampton, UK; Electronics and Computer Science, University of Southampton, Southampton, UK","2019 11th International Symposium on Image and Signal Processing and Analysis (ISPA)","17 Oct 2019","2019","","","312","317","Multi-variate time series that arise in financial data, for example, are likely to be driven by underlying lower dimensional latent variables. Extracting such latent spaces can be useful in representing the data efficiently and as a means of explaining aspects of the system from which they are generated. Here, we study an extension to the Variational Autoencoder model specifically cast in a probabilistic setting to deal with positive valued data to extract a non-negative matrix factorization model (NMF) in a probabilistic setting (PAE-NMF). To model financial data, where information about some underlying macroeconomic system may be observed, we extend the PAE-NMF model to include exogenous variables (PAE-XNMF). We present the learning algorithm for this model and illustrate its operation on financial data of constituents of the FTSE100 index and a set of relevant macroeconomic variables. We show an example of the latent space detecting a sharp transition around the Brexit event that is not readily apparent on any of the individual time series.","1849-2266","978-1-7281-3140-5","10.1109/ISPA.2019.8868930","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868930","Non Negative Matrix Factorization;Variational Autoencoder;Dimensionality Reduction;Deep Learning;Kullback Leibler divergence;Financial Data Analysis","Decoding;Data models;Signal processing;Image reconstruction;Time series analysis;Probabilistic logic;Encoding","financial data processing;learning (artificial intelligence);macroeconomics;matrix decomposition;time series","exogenous inputs;multivariate time series;lower dimensional latent variables;latent space;Variational Autoencoder model;probabilistic setting;positive valued data;nonnegative matrix factorization model;PAE-NMF model;exogenous variables;relevant macroeconomic variables;financial data modelling;FTSE100 index;individual time series","","","","50","","17 Oct 2019","","","IEEE","IEEE Conferences"
"Detection of Dataset Shifts in Learning-Enabled Cyber-Physical Systems using Variational Autoencoder for Regression","F. Cai; A. I. Ozdagli; X. Koutsoukos","Vanderbilt University, Nashville, TN; Vanderbilt University, Nashville, TN; Vanderbilt University, Nashville, TN","2021 4th IEEE International Conference on Industrial Cyber-Physical Systems (ICPS)","5 Jul 2021","2021","","","104","111","Cyber-physical systems (CPSs) use learning-enabled components (LECs) extensively to cope with various complex tasks under high-uncertainty environments. However, the dataset shifts between the training and testing phase may lead the LECs to become ineffective to make large-error predictions, and further, compromise the safety of the overall system. In our paper, we first provide the formal definitions for different types of dataset shifts in learning-enabled CPS. Then, we propose an approach to detect the dataset shifts effectively for regression problems. Our approach is based on the inductive conformal anomaly detection and utilizes a variational autoencoder for regression model which enables the approach to take into consideration both LEC input and output for detecting dataset shifts. Additionally, in order to improve the robustness of detection, layer-wise relevance propagation (LRP) is incorporated into our approach. We demonstrate our approach by using an advanced emergency braking system implemented in an open-source simulator for self-driving cars. The evaluation results show that our approach can detect different types of dataset shifts with a small number of false alarms while the execution time is smaller than the sampling period of the system.","","978-1-7281-6207-2","10.1109/ICPS49255.2021.9468230","National Science Foundation (NSF)(grant numbers:1739328); Defense Advanced Research Projects Agency (DARPA)(grant numbers:FA8750-18-C-0089); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9468230","dataset shift detection;variational autoencoder for regression;layer-wise relevance propagation;self-driving vehicles","Training;Computational modeling;Training data;Cyber-physical systems;Robustness;Real-time systems;Safety","automobiles;braking;cyber-physical systems;learning (artificial intelligence);neural nets;regression analysis;security of data","dataset shifts;learning-enabled CPS;inductive conformal anomaly detection;variational autoencoder;learning-enabled cyber-physical systems;learning-enabled components;regression;false alarms;advanced emergency braking system","","","","32","","5 Jul 2021","","","IEEE","IEEE Conferences"
"Investigation And Comparison of Optimization Methods for Variational Autoencoder-Based Underdetermined Multichannel Source Separation","S. Seki; H. Kameoka; L. Li","NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation, Japan; NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation, Japan; Information Technology Center, Nagoya University, Japan","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","511","515","In this paper, we investigate two algorithms for variational autoencoder (VAE)-based underdetermined multichannel source separation. We previously extended the multichannel VAE (MVAE) method for determined multichannel source separation and proposed the generalized MVAE (GMVAE) method for underdetermined multichannel source separation. The GMVAE method employs a conditional VAE (CVAE) as the source model representing the power spectrograms of the underlying sources present in a mixture. While we developed a convergence-guaranteed parameter estimation algorithm using a majorization-minimization/minorization-maximization (MM) algorithm, an expectation-maximization (EM) algorithm also allows us to design another algorithm with the same property. However, a comparison of the MM-based and EM-based algorithms has not yet been revealed. To elucidate this, we investigate the MM-based and EM-based algorithms for the GMVAE method, using an improved CVAE variant called auxiliary classifier VAE (ACVAE). The experimental results suggest that the EM-based algorithm takes less computational cost, achieving comparable separation performance with the MM-based algorithm.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746980","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746980","Underdetermined multichannel source separation;variational autoencoder;convergence-guaranteed algorithm","Source separation;Parameter estimation;Conferences;Signal processing algorithms;Optimization methods;Inference algorithms;Classification algorithms","audio signal processing;blind source separation;expectation-maximisation algorithm;iterative methods;optimisation;parameter estimation;source separation","determined multichannel source separation;generalized MVAE method;GMVAE method;conditional VAE;source model;underlying sources;convergence-guaranteed parameter estimation algorithm;expectation-maximization algorithm;auxiliary classifier VAE;comparable separation performance;MM-based algorithm;optimization methods;variational autoencoder-based underdetermined multichannel source separation;multichannel VAE method","","","","40","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Upmixing Via Style Transfer: A Variational Autoencoder for Disentangling Spatial Images And Musical Content","H. Yang; S. Wager; S. Russell; M. Luo; M. Kim; W. Kim","Dept. of Intelligent Systems Engineering, Indiana University, Bloomington, IN, USA; Amazon Lab126, Cambridge, MA, USA; Amazon Lab126, Cambridge, MA, USA; Amazon Lab126, Cambridge, MA, USA; Amazon Lab126, Cambridge, MA, USA; Amazon Lab126, Cambridge, MA, USA","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","426","430","In the stereo-to-multichannel upmixing problem for music, one of the main tasks is to set the directionality of the instrument sources in the multichannel rendering results. In this paper, we propose a modified variational autoencoder model that learns a latent space to describe the spatial images in multichannel music. We seek to disentangle the spatial images and music content, so the learned latent variables are invariant to the music. At test time, we use the latent variables to control the panning of sources. We propose two upmixing use cases: transferring the spatial images from one song to another and blind panning based on the generative model. We report objective and subjective evaluation results to empirically show that our model captures spatial images separately from music content and achieves transfer-based interactive panning.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746978","Stereo-to-multichannel upmixing;variational autoencoders;panning;information disentanglement","Instruments;Conferences;Music;Signal processing;Aerospace electronics;Rendering (computer graphics);Multiple signal classification","audio signal processing;learning (artificial intelligence);music;principal component analysis;rendering (computer graphics)","via style transfer;disentangling spatial images;musical content;upmixing problem;multichannel rendering results;modified variational autoencoder model;latent space;multichannel music;music content;learned latent variables;upmixing use cases;transfer-based interactive panning","","","","24","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Movie Recommendation System Using Concurrent Hybrid Variational Autoencoders","M. Krishnathasan","Department of Information Technology, University of Moratuwa, Katubedda, Sri Lanka","2021 21st International Conference on Advances in ICT for Emerging Regions (ICter)","16 May 2022","2021","","","1","5","Movie recommendation is a fundamental user requirement for online movie streaming platforms. This research proposes a robust hybrid pipeline that uses two variational autoencoders which can run parallelly to capture the user’s movie preference and genre preference from past data separately. This research uses a stable 1M Movielens dataset for training and testing. This research further explores the impact of the latent space dimension, the impact of the output layer activation function in movie recommendation tasks, and a suitable prediction matrix based on the activation function we used. Our proposed methodology was evaluated against AutoRec Model and was able to achieve 1.3939 in root mean squared error evaluation.","2472-7598","978-1-6654-6686-8","10.1109/ICter53630.2021.9774813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9774813","Recommendation Systems;variational autoencoders;Hybrid Filtering;MovieLenz","Training;Pipelines;Motion pictures;Information filters;Information and communication technology;Task analysis;Matrix converters","collaborative filtering;learning (artificial intelligence);mean square error methods;neural nets;recommender systems","movie recommendation system;concurrent hybrid variational autoencoders;fundamental user requirement;online movie streaming platforms;robust hybrid pipeline;genre preference;stable 1M Movielens dataset;latent space dimension;output layer activation function;movie recommendation tasks;suitable prediction matrix","","","","28","IEEE","16 May 2022","","","IEEE","IEEE Conferences"
"A Novel Clustering Method Using Variational Autoencoder with Reliable Sample Decision and Balanced K-Means++ for Single-particle Cryo-EM Images","Y. Yan; J. Wu; B. Liu; Q. Zheng; D. Zhang; S. Ge; J. Zhang; N. Xia","School of Public Health, Xiamen University, Xiamen, China; School of Public Health, Xiamen University, Xiamen, China; School of Public Health, Xiamen University, Xiamen, China; School of Public Health, Xiamen University, Xiamen, China; School of Public Health, Xiamen University, Xiamen, China; School of Public Health, Xiamen University, Xiamen, China; School of Public Health, Xiamen University, Xiamen, China; School of Public Health, Xiamen University, Xiamen, China","2021 IEEE 10th Data Driven Control and Learning Systems Conference (DDCLS)","25 Jun 2021","2021","","","213","217","Single-particle cryo-electron microscopy (cryo-EM) is one of the most popular technology in the field of biology molecular structure determination. Clustering for Cryo-EM particle images is very important in the structure reconstruction process, which significantly affected the reconstruction resolution. Because the signal-to-noise-ratio (SNR) of cryo-electron is extremely low, it's a challenge to improve the clustering accuracy. In this paper, we proposed a novel clustering method that combined a variational autoencoder with reliable sample decision (ReVAE) and balanced K-means++ (BK-means++). ReVAE projects cryo-EM images into low-dimensional latent variables, and BK-means++ is applied to cluster latent variables. Training of ReVAE and clustering of latent variables by BK-means++ are performed jointly and iteratively. The experimental results showed that ReVAE with BK-means++ achieved state-of-the-art results compared to traditional cryo-EM particle images clustering methods.","2767-9861","978-1-6654-2423-3","10.1109/DDCLS52934.2021.9455603","National Natural Science Foundation of China(grant numbers:62003284); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9455603","Cryo-EM;Image Clustering;Variational Autoencoder;K-means++","Dimensionality reduction;Training;Clustering methods;Feature extraction;Data models;Reliability;Image reconstruction","biology computing;electron microscopy;image reconstruction;image resolution;medical image processing;neural nets;pattern clustering","variational autoencoder;reliable sample decision;single-particle cryo-electron microscopy;biology molecular structure determination;structure reconstruction process;reconstruction resolution;signal-to-noise-ratio;balanced K-means++;single-particle Cryo-EM image clustering;ReVAE training","","","","17","IEEE","25 Jun 2021","","","IEEE","IEEE Conferences"
"A Semi-Supervised Learning Method for MiRNA-Disease Association Prediction Based on Variational Autoencoder","C. Ji; Y. Wang; Z. Gao; L. Li; J. Ni; C. Zheng","School of Software, Qufu Normal University, Qufu, China; School of Software, Qufu Normal University, Qufu, China; School of Software, Qufu Normal University, Qufu, China; School of Software, Qufu Normal University, Qufu, China; School of Software, Qufu Normal University, Qufu, China; School of Computer Science and Technology, Anhui University, Hefei, China","IEEE/ACM Transactions on Computational Biology and Bioinformatics","8 Aug 2022","2022","19","4","2049","2059","MicroRNAs (miRNAs) are a class of non-coding RNAs that play critical role in many biological processes, such as cell growth, development, differentiation and aging. Increasing studies have revealed that miRNAs are closely involved in many human diseases. Therefore, the prediction of miRNA-disease associations is of great significance to the study of the pathogenesis, diagnosis and intervention of human disease. However, biological experimentally methods are usually expensive in time and money, while computational methods can provide an efficient way to infer the underlying disease-related miRNAs. In this study, we propose a novel method to predict potential miRNA-disease associations, called SVAEMDA. Our method mainly consider the miRNA-disease association prediction as semi-supervised learning problem. SVAEMDA integrates disease semantic similarity, miRNA functional similarity and respective Gaussian interaction profile (GIP) similarities. The integrated similarities are used to learn the representations of diseases and miRNAs. SVAEMDA trains a variational autoencoder based predictor by using known miRNA-disease associations, with the form of concatenated dense vectors. Reconstruction probability of the predictor is used to measure the correlation of the miRNA-disease pairs. Experimental results show that SVAEMDA outperforms other stat-of-the-art methods. AUC values of SVAEMDA of global leave-one-out cross validation (LOOCV) and 5-fold cross validation (5-fold CV) are 0.9464 and 0.9428 respectively. In addition, case studies of three common human diseases indicate that SVAEMDA obtains 100 percent of the top 50 predicted candidates in the benchmark databases. Therefore, SVAEMDA can efficiently and accurately predict the potential associations between diseases and miRNAs.","1557-9964","","10.1109/TCBB.2021.3067338","National Natural Science Foundation of China(grant numbers:U19A2064,61873001,61872220); Natural Science Foundation of Shandong Province(grant numbers:ZR2020KC022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9381658","Semi-supervised learning;representation learning;microRNA-disease association;variational autoencoder","Diseases;Feature extraction;Predictive models;Semantics;Databases;Support vector machines;Computational modeling","bioinformatics;cellular biophysics;diseases;genetics;molecular biophysics;RNA;semi-supervised learning (artificial intelligence)","miRNA-disease association prediction;semisupervised learning problem;SVAEMDA;disease semantic similarity;miRNA functional similarity;Gaussian interaction profile;variational autoencoder based predictor;miRNA-disease pairs;MicroRNAs;human disease;biological experimentally methods;computational methods;LOOCV;5-fold CV;leave-one-out cross validation;5-fold cross validation;RNA;GIP;AUC;efficiency 100.0 percent","Algorithms;Computational Biology;Genetic Predisposition to Disease;Humans;MicroRNAs;Research Design;Supervised Machine Learning","","","57","IEEE","18 Mar 2021","","","IEEE","IEEE Journals"
"Sparse Variational Autoencoder-Based Interpretable Bimodal Word Embeddings","J. Tang; W. Zhong; Q. Cai; G. Lu; Z. Yan; Y. Xue; X. Li","School of Physics and Telecommunication Engineering, South China Normal University, Guangzhou, China; School of Physics and Telecommunication Engineering, South China Normal University, Guangzhou, China; School of Physics and Telecommunication Engineering, South China Normal University, Guangzhou, China; School of Physics and Telecommunication Engineering, South China Normal University, Guangzhou, China; School of Physics and Telecommunication Engineering, South China Normal University, Guangzhou, China; School of Physics and Telecommunication Engineering, South China Normal University, Guangzhou, China; Laboratory of Language Engineering and Computing, Guangdong University of Foreign Studies, Guangzhou, China","2021 International Conference on Machine Learning and Cybernetics (ICMLC)","24 Mar 2022","2021","","","1","6","Word embedding is a basic task in the field of natural language processing, which is widely applied to a variety of tasks. In spite of delivering the semantic information, there is no meaningful explanation for specific dimension of the word embedding. As such, research is ongoing to explore the interpretability of word embeddings and thus improve their performance in downstream tasks. Current interpretable word embedding models, however, merely focus on the textual information of the words instead of the multimodalities. In line with the cognition principle, we establish a sparse variational autoencoder, which exploits both the textual and visual information to generate interpretable word embedding. Experiments are conducted to verify the interpretability of word embeddings together with their performance in downstream tasks. Comparing to the state-of-arts, experimental results indicate that the proposed interpretable word embeddings not only effectively increase the interpretability, but also obtain better result in most downstream tasks.","2160-1348","978-1-6654-6608-0","10.1109/ICMLC54886.2021.9737247","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9737247","Interpretable Word Embedding;Bimodal Word Embedding;Sparse Variational Autoencoder","Visualization;Semantics;Machine learning;Natural language processing;Cognition;Task analysis;Cybernetics","learning (artificial intelligence);natural language processing;text analysis","sparse variational autoencoder-based interpretable bimodal word embeddings;downstream tasks;current interpretable word embedding models","","","","22","IEEE","24 Mar 2022","","","IEEE","IEEE Conferences"
"Variational Denoising Autoencoders and Least-Squares Policy Iteration for Statistical Dialogue Managers","V. Diakoloukas; F. Lygerakis; M. G. Lagoudakis; M. Kotti","School of Electrical and Computer Engineering, Technical University of Crete, Chania, Greece; School of Electrical and Computer Engineering, Technical University of Crete, Chania, Greece; School of Electrical and Computer Engineering, Technical University of Crete, Chania, Greece; Artificial Intelligence, Deloitte, London, U.K.","IEEE Signal Processing Letters","18 Jun 2020","2020","27","","960","964","The use of Reinforcement Learning (RL) approaches for dialogue policy optimization has been the new trend for dialogue management systems. Several methods have been proposed, which are trained on dialogue data to provide optimal system response. However, most of these approaches exhibit performance degradation in the presence of noise, poor scalability to other domains, as well as performance instabilities. To overcome these problems, we propose a novel approach based on the incremental, sample-efficient Least-Squares Policy Iteration (LSPI) algorithm, which is trained on compact, fixed-size dialogue state encodings, obtained from deep Variational Denoising Autoencoders (VDAE). The proposed scheme exhibits stable and noise-robust performance, which significantly outperforms the current state-of-the-art, even in mismatched noise environments.","1558-2361","","10.1109/LSP.2020.2998361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9103219","Variational autoencoders;denoising;dialogue systems;sample-efficient statistical dialogue managers;least-squares policy iteration","Noise reduction;Signal processing algorithms;Encoding;Training;Optimization;Approximation algorithms;Degradation","interactive systems;iterative methods;learning (artificial intelligence);least squares approximations;neural nets;signal denoising;speech processing;statistical analysis","Spoken Dialogue Systems;deep VDAE;sample-efficiency least-squares policy iteration;incremental least-squares policy iteration;noise-robust performance;deep Variational Denoising Autoencoders;fixed-size dialogue state encodings;compact size dialogue state encodings;dialogue management systems;dialogue policy optimization;RL;Reinforcement Learning;statistical dialogue managers","","","","25","IEEE","28 May 2020","","","IEEE","IEEE Journals"
"A Collaborative Filtering Framework Based on Variational Autoencoders and Generative Adversarial Networks","S. Xu; J. Ma","School of Computer Science and Technology, Shandong University, Qingdao, China; School of Computer Science and Technology, Shandong University, Qingdao, China","2020 International Conference on Computer Information and Big Data Applications (CIBDA)","27 Jul 2020","2020","","","193","199","The generation models such as Variational Autoencoders (VAE) and Generative Adversarial Networks (GAN) have been demonstrated to be of high effectiveness in standard collaborative filtering applications. However, the conventional VAE can't capture the data distribution well when the data is sparse or the auxiliary information is added, resulting in low recommendation accuracy. In this paper, we propose a novel VAE-GAN-based collaborative filtering (CF) framework, named CF-VAE-GAN, to provide higher accuracy in recommendation. First, auxiliary information such as user comments and item multimedia features are added to VAE. And then, we use the discriminator of GAN to improve the reconstruction objective of VAE. Finally, we design two CF-VAE-GAN models of users and items, respectively. Empirical results indicate that our method outperforms state-of-the-art methods in terms of Recall and NDCG.","","978-1-7281-9837-8","10.1109/CIBDA50819.2020.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9148225","Variational Autoencoders;Generative Adversarial Networks;Recommendation System;Collaborative Filtering","Collaboration;Filtering;Gallium nitride;Generative adversarial networks;Data models;Generators;Decoding","collaborative filtering;neural nets;recommender systems","data distribution;auxiliary information;CF-VAE-GAN models;generative adversarial networks;generation models;standard collaborative filtering applications;VAE-GAN-based collaborative filtering framework;variational autoencoders;multimedia features","","","","21","","27 Jul 2020","","","IEEE","IEEE Conferences"
"Variational Autoencoders for Medical Image Retrieval","C. Alves; A. J. M. Traina","Institute of Mathematical and Computer Sciences, University of Sao Paulo, São Carlos, Brazil; Institute of Mathematical and Computer Sciences, University of Sao Paulo, São Carlos, Brazil","2022 International Conference on INnovations in Intelligent SysTems and Applications (INISTA)","23 Sep 2022","2022","","","1","6","This paper presents an approach based on Variational Autoencoders (VAEs) for unsupervised learning of deep features for Content-Based Medical Image Retrieval (CBMIR). We show that this unsupervised approach can yield better results than the predominant supervised approach based on classification, and can even be used in combination with the classification approach, resulting in a second, mixed model. Despite the VAEs retrieving images more visually similar, the evaluation methodology usually employed in literature is not able to reveal this advantage, which is important for CBMIR. We then propose a new evaluation method based on hidden classes and show that it reflects the visual similarity of the retrieved images better than the traditional evaluation.","2768-7295","978-1-6654-9810-4","10.1109/INISTA55318.2022.9894251","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9894251","Variational Autoencoder;Deep Learning;Medical image retrieval","Training;Measurement;Visualization;Technological innovation;Image retrieval;Inspection;Labeling","content-based retrieval;feature extraction;image retrieval;medical image processing;unsupervised learning","retrieved images;Variational Autoencoders;VAEs;unsupervised learning;deep features;Content-Based Medical Image Retrieval;CBMIR;unsupervised approach;predominant supervised approach;classification approach;visual similarity","","","","21","IEEE","23 Sep 2022","","","IEEE","IEEE Conferences"
"Monte Carlo Simulation of Naroline Thermal Conductivity Using a Conditional Variational Autoencoder","M. Ding; Y. Chen","Jiangsu Key Laboratory for Design and Fabrication of Micro-Nano Biomedical Instruments, School of Mechanical Engineering, Southeast University, Nanjing, China; Jiangsu Key Laboratory for Design and Fabrication of Micro-Nano Biomedical Instruments, School of Mechanical Engineering, Southeast University, Nanjing, China","2022 2nd International Conference on Computer, Control and Robotics (ICCCR)","14 Jun 2022","2022","","","126","131","The Boltzmann Transport Equation (BTE) for phonons can well describe heat flow in crystalline solids. An alternative approach to solving the BTE is known as Monte Carlo simulation. Under the relaxation time approximation (RTA), different forms of scattering are treated individually. Among them, normal scattering obeys conservation laws of energy and momentum. We propose a conditional variational autoencoder (CVAE) as a generative model to generate candidates of phonons with desired property. It is specialized to control multiple phonon properties (momentum, energy) simultaneously by imposing them on latent space and generate phonons in accordance with the scattering law.","","978-1-6654-6674-5","10.1109/ICCCR54399.2022.9790151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9790151","Monte Carlo simulation;conditional variational autoencoder;thermal conductivity;deep learning","Monte Carlo methods;Scattering;Phonons;Conductivity;Thermal conductivity;Solids;Silicon","Boltzmann equation;Monte Carlo methods;phonons;thermal conductivity","Monte Carlo simulation;naroline thermal conductivity;conditional variational autoencoder;Boltzmann Transport Equation;BTE;heat flow;crystalline solids;relaxation time approximation;normal scattering;scattering law;multiple phonon properties","","","","19","IEEE","14 Jun 2022","","","IEEE","IEEE Conferences"
"Quality metrics of variational autoencoders","M. Leontev; A. Mikheev; K. Sviatov; S. Sukhov","Ulyanovsk Branch, Kotel’nikov Institute of Radio Engineering and Electronics of Russian Academy of Sciences, Ulyanovsk, Russia; Ulyanovsk Regional Center of New Information Technologies, Ulyanovsk State Technical University, Ulyanovsk, Russia; Department of Information Systems and Technologies, Ulyanovsk State Technical University, Ulyanovsk, Russia; Ulyanovsk Branch, Kotel’nikov Institute of Radio Engineering and Electronics of Russian Academy of Sciences, Ulyanovsk, Russia","2020 International Conference on Information Technology and Nanotechnology (ITNT)","12 Nov 2020","2020","","","1","5","Variational autoencoders (VAEs) are popular models for the generation of realistic images. Usually, the quality of generated images is estimated only by visual inspection, as the methods for the quantitative estimation are not fully developed. In this work, we present and test the methods that allow the possibility to evaluate the quality and the diversity of the images generated by a VAE objectively using an auxiliary classifier. The corresponding quality metrics are calculated for several implementations of VAE. The proposed metrics are especially valuable for the problems of preventing catastrophic forgetting during sequential learning. The experiments are performed on publicly available datasets.","","978-1-7281-7041-1","10.1109/ITNT49337.2020.9253310","Russian Foundation for Basic Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9253310","generative neural networks;variational autoencoders;quality metrics","Measurement;Training;Visualization;Estimation;Interference;Iterative methods;Nanotechnology","learning (artificial intelligence);neural nets;realistic images","variational autoencoders;VAE;realistic images;visual inspection;quantitative estimation;auxiliary classifier;quality metrics;sequential learning;catastrophic forgetting;publicly available datasets","","","","31","","12 Nov 2020","","","IEEE","IEEE Conferences"
"Deep Convolutional Variational Autoencoder for Anomalous Sound Detection","M. -H. Nguyen; D. -Q. Nguyen; D. -Q. Nguyen; C. -N. Pham; D. Bui; H. -D. Han",Hanoi University of Science and Technology; Hanoi University of Science and Technology; Hanoi University of Science and Technology; Hanoi University of Science and Technology; Confluent Inc.; Hanoi University of Science and Technology,"2020 IEEE Eighth International Conference on Communications and Electronics (ICCE)","16 Feb 2021","2021","","","313","318","Anomalous sound detection (ASD) is one of the most important fields in industrial facility maintenance. For this task, semi-supervised approaches are preferred thanks to their simplicity and no training data labels required. These methods train an autoencoder (AE) with only normal sound data and detect anomalies based on anomaly scores of actual samples. In this paper, we propose applying the convolutional variational autoencoder (CVAE) to ASD task. Through experiments using machine sound data, the CVAE is proven to be effective in detecting abnormal sound and outperform existing methods.","","978-1-7281-5471-8","10.1109/ICCE48956.2021.9352085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9352085","anomalous sound detection;machine sound monitoring;semi-supervised learning;autoencoder","Convolution;Conferences;Training data;Maintenance engineering;Industrial facilities;Task analysis;Monitoring","acoustic signal processing;condition monitoring;convolutional neural nets;deep learning (artificial intelligence);facilities management;feature extraction;maintenance engineering;production engineering computing","deep convolutional variational autoencoder;anomalous sound detection;industrial facility maintenance;semisupervised approaches;autoencoder training;machine sound data;automated industrial monitoring systems","","1","","20","IEEE","16 Feb 2021","","","IEEE","IEEE Conferences"
"SAR Target Recognition Based On Variational Autoencoder","Y. Xu; G. Zhang; K. Wang; H. Leung","Ministry of Education, Key Lab of Radar Imaging and Microware Photonics, Nanjing, China; Ministry of Education, Key Lab of Radar Imaging and Microware Photonics, Nanjing, China; Ministry of Education, Key Lab of Radar Imaging and Microware Photonics, Nanjing, China; Department of Electrical and Computer Engineering, University of Calgary, Calgary, Canada","2019 IEEE MTT-S International Microwave Biomedical Conference (IMBioC)","29 Jul 2019","2019","1","","1","4","Recently, with the rapid development of machine learning, varieties of new thoughts have flooded into the field of the synthetic aperture radar automatic target recognition. Convolutional neural networks are mostly used in this area. Nonetheless, the features extract from convolutional neural networks learned through back propagation may discard the features helpless for recognition like azimuth. Unlike supervised learning, our model based on probabilistic generative model in an unsupervised way learns the distribution inside the input data. Features of synthetic aperture radar images learned by our model are more fruitful and interpretable, which are more effective than traditional hand-crafted features in SAR image processing. Meanwhile, tested on the MSTAR data set, our model gets high accuracy in classify task under KNN and SVM.","","978-1-5386-7395-9","10.1109/IMBIOC.2019.8777915","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8777915","","","convolutional neural nets;feature extraction;nearest neighbour methods;probability;radar computing;radar imaging;radar target recognition;support vector machines;synthetic aperture radar","SAR target recognition;variational autoencoder;machine learning;synthetic aperture radar automatic target recognition;convolutional neural networks;supervised learning;probabilistic generative model;synthetic aperture radar images;SAR image processing;hand-crafted features;feature extraction;MSTAR data set;KNN;SVM","","2","","10","IEEE","29 Jul 2019","","","IEEE","IEEE Conferences"
"Comparison and extension of autoencoder models for uni- and multivariate signal compression in IIoT","J. Rosenberger; A. Kübel; F. Rothfuß","Bosch Rexroth AG, Lohr am Main, Germany; CODE University of Applied Science, Berlin, Germany; CODE University of Applied Science, Berlin, Germany","2022 Data Compression Conference (DCC)","4 Jul 2022","2022","","","481","481","A convolutional variational autoencoder (AE) CBN-$VAE^{1}$, a recurrent LSTM-$AE^{2}$, and a discrete wavelet transform (DWT) are compared w.r.t compression performance and resource consumption. The existing models for streaming data are slightly adapted to handle both univariate (UTS) and multivariate time-series (MTS). The experiments on two publicly available data sets3 confirm that the machine learning models compress time-series in a more generalized and robust manner than DWT. This is shown by a higher quality score $QS= \frac{\text{compression ratio}(CR)}{\text{reconstruction error}(RE)}$ for both AE models compared to the DWT. The following aspects are observed w.r.t. the AE models:","2375-0359","978-1-6654-7893-9","10.1109/DCC52660.2022.00092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9810724","data compression;machine learning;autoencoder;lstm;restricted boltzmann machine;discrete wavelet transform","Adaptation models;Convolution;Data compression;Machine learning;Data models;Discrete wavelet transforms;Industrial Internet of Things","image coding;industrial engineering;Internet of Things;learning (artificial intelligence);production engineering computing;recurrent neural nets;time series","autoencoder models;univariate signal compression;multivariate signal compression;IIoT;convolutional variational autoencoder;recurrent LSTM-AE;discrete wavelet transform;multivariate time-series;univariate time-series;machine learning model","","","","0","IEEE","4 Jul 2022","","","IEEE","IEEE Conferences"
"Enhanced Variational U-Net for Weather Forecasting","P. H. Kwok; Q. Qi",NA; NA,"2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","5758","5763","This work describes our third-place solution in both the core and transfer learning challenges of Weather4cast – IEEE BigData Cup. The solution builds on our success in Weather4cast - Stage 1 [1], and uses the same Variational U-Net architecture. Building on the lessons learned from Weather4cast - Stage 1, we enhanced the model’s performance through the use of data augmentations and model blending. Furthermore, we explored transfer learning between the two competitions. The code for this solution is available at https://github.com/qiq208/w4c-2021-IEEE","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671346","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671346","weather forecasting;machine learning;convolutional neural networks;variational autoencoder","Training;Codes;Conferences;Transfer learning;Buildings;Weather forecasting;Predictive models","Big Data;convolutional neural nets;geophysics computing;learning (artificial intelligence);weather forecasting","enhanced Variational U-Net;third-place solution;learning challenges;IEEE BigData Cup;Variational U-Net architecture;transfer learning;Weather4cast","","1","","13","IEEE","13 Jan 2022","","","IEEE","IEEE Conferences"
"Multilevel Dual-Direction Modifying Variational Autoencoders for Hyperspectral Feature Extraction","W. Yu; H. Huang; G. Shen","School of Electronics and Information Engineering, Soochow University, Suzhou, China; School of Electronics and Information Engineering, Soochow University, Suzhou, China; School of Electronics and Information Engineering, Soochow University, Suzhou, China","IEEE Geoscience and Remote Sensing Letters","27 Jun 2022","2022","19","","1","5","Hyperspectral images (HSIs) provide abundant high-quality spectral information through an immense number of spectral channels, which can be used to classify on-ground objects for Earth observation accurately. However, these highly correlated channels and complex informative features always limit the application of HSIs. In this letter, we propose a multilevel dual-direction modifying variational autoencoder (MD2MVAE) for hyperspectral feature extraction. Its architecture is inspired by the spectral–spatial coherence in HSIs. Our motivation is to modify spectral sequential features by spatial sequential features in a multilevel dual-direction network. The dual-direction strategy has two implications: 1) the spatial continuity is captured by flattening neighboring samples in dual classic directions and 2) the spectral–spatial continuities are captured in the forward and backward directions. This multilevel dual-direction network provides a feasible way to avoid the loss of spatial information when flattening samples in the spatial domain, without using any convolutional layers. Inspired by our previous work, a variational autoencoder (VAE)-based network is used to enhance the noise immunity of latent features. To preserve the consistency of spectral–spatial sequential features, a combined loss function based on the solid angle on a unit sphere is proposed for parameter optimization. Two typical datasets are selected as benchmarks to show the effectiveness of MD2MVAE, compared with the state-of-the-art methods.","1558-0571","","10.1109/LGRS.2022.3183408","Natural Science Foundation of Jiangsu Province of China(grant numbers:BK20181431); Qing Lan Project of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796592","Deep learning (DL);feature extraction (FE);hyperspectral image (HSI);multilevel dual-direction framework;solid angle","Feature extraction;Iron;Solids;Hyperspectral imaging;Task analysis;Shape;Coherence","deep learning (artificial intelligence);feature extraction;geophysical image processing;hyperspectral imaging;image classification;image sampling;neural nets;object detection;optimisation;spectral analysis","dual-direction modifying variational autoencoder;hyperspectral feature extraction;hyperspectral images;HSI;high-quality spectral information;spectral channels;highly correlated channels;complex informative features;spectral-spatial coherence;spectral sequential features;dual-direction network;spatial continuity;dual classic directions;spectral-spatial continuities;spatial information;spatial domain;variational autoencoder-based network;latent features;spectral-spatial sequential features;on-ground object classification;Earth observation;noise immunity;loss function;parameter optimization;MD2MVAE","","","","18","IEEE","15 Jun 2022","","","IEEE","IEEE Journals"
"Gaussian Mixture Variational Autoencoder with Whitening Score for Multimodal Time Series Anomaly Detection","J. Zhu; F. Deng; J. Zhao; Z. Ye; J. Chen","Department of Automation, Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology Chongqing Innovation Center, Chongqing, China; Department of Automation, Beijing Institute of Technology, Beijing, China; Department of Automation, Beijing Institute of Technology, Beijing, China; Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University, Shanghai, China","2022 IEEE 17th International Conference on Control & Automation (ICCA)","25 Jul 2022","2022","","","480","485","Time series anomaly detection has attracted great attention due to its widespread existence in real life. With the increasing development and advancement of deep learning, many unsupervised deep learning methods have been proposed for time series anomaly detection since labeling time series is prohibitively expensive. In this paper, we propose an unsupervised anomaly detection method: Gaussian Mixture Variational Autoencoder with Whitening Distance Anomaly Score (WGVAE). Concretely, we employ an LSTM-based variational autoencoder to capture the long-term dependence of time series and learn the low-dimensional feature representation and distribution, in which the Gaussian mixture prior are used to characterize multimodal time series. Further, whitening distance anomaly scores are used to make the multidimensional time series independently and identically distributed among each dimension, which combines the distribution characteristics of the samples to measure the degree of outliers. When the anomaly score is below the threshold, the sample is detected as anomalous. Finally, comprehensive experiments are given to verify the effectiveness of our method.","1948-3457","978-1-6654-9572-1","10.1109/ICCA54724.2022.9831885","National Key Research and Development Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9831885","","Deep learning;Automation;Time series analysis;Time measurement;Labeling;Task analysis;Anomaly detection","deep learning (artificial intelligence);Gaussian processes;mixture models;security of data;time series;unsupervised learning","unsupervised deep learning methods;labeling time series;unsupervised anomaly detection method;Gaussian mixture variational autoencoder;LSTM-based variational autoencoder;low-dimensional feature representation;whitening distance anomaly scores;multidimensional time series;multimodal time series anomaly detection;outlier degree;WGVAE method","","","","22","IEEE","25 Jul 2022","","","IEEE","IEEE Conferences"
"NF-VGA: Incorporating Normalizing Flows into Graph Variational Autoencoder for Embedding Attribute Networks","H. Shan; D. Jin; P. Jiao; Z. Liu; B. Li; Y. Huang","College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; Center of Biosafety Research and Strategy, Law School, Tianjin University, Tianjin, China; JD.com; College of Intelligence and Computing, Tianjin University, Tianjin, China; Columbian College of Arts & Sciences, George Washington University","2020 IEEE International Conference on Data Mining (ICDM)","9 Feb 2021","2020","","","1244","1249","Network embedding (NE), aiming to embed a network into a low dimensional latent representation while preserving the inherent structural properties of the network, has attracted considerable attention recently. Variational Autoencoder (VAE) has been widely studied for NE. Existing VAE based methods let the network follow a unimodal distribution, that is, they typically use some fixed distribution as the prior, e.g. Gaussian distribution. However, in reality networks often contain many complicated structural properties [5], [6] (such as the first/second order proximity, the motif or community structures, power-law, etc). The latent representation from unimodal and fixed distribution is not capable of describing such multi-modal characteristic of networks. To address this issue, we develop a new VAE method for NE, named Normalizing Flow Variational Graph Autoencoder (NF-VGA). We design a prior-generative module based on normalizing flows to generate flexible, multi-modal distribution as the prior of the latent representation. To make the generated prior better describe the coupling relationship between nodes, we further utilize network local structures to guide the prior generation. Extensive experiments on some real-world networks show a superior performance of the new approach over some state-of-the-art methods on some popular network embedding tasks.","2374-8486","978-1-7281-8316-9","10.1109/ICDM50108.2020.00157","National Natural Science Foundation of China(grant numbers:61772361,61902278); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9338351","deep learning;network embedding","Couplings;Laplace equations;Conferences;Gaussian distribution;Data mining;Task analysis","Gaussian distribution;graph theory;learning (artificial intelligence);network theory (graphs);optimisation","power-law;fixed distribution;VAE method;NE;named Normalizing Flow Variational Graph Autoencoder;NF-VGA;prior-generative module;multimodal distribution;network local structures;prior generation;real-world networks;popular network embedding tasks;incorporating Normalizing flows;Graph Variational Autoencoder;embedding attribute networks;low dimensional latent representation;inherent structural properties;VAE based methods;unimodal distribution;gaussian distribution;reality networks;complicated structural properties;order proximity;motif","","","","22","","9 Feb 2021","","","IEEE","IEEE Conferences"
"Modeling the behavior of multiple subjects using a Cauchy-Schwarz regularized Partitioned Subspace Variational AutoEncoder (CS-PS-VAE)","D. Yi; S. Saxena","Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA","2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","8 Sep 2022","2022","","","497","503","Effectively modeling and quantifying behavior is essential for our understanding of the brain. Modeling behavior across different subjects in a unified manner remains a significant challenge in the field of behavioral quantification, which necessitates partitioning the behavioral data into features that are common across subjects, and others that are distinct to each subject. We build on a semi-supervised approach to partition the subspace adequately known as a Partitioned Subspace Variational AutoEncoder (PS-VAE), and propose a novel regularization based on the Cauchy-Schwarz divergence to model the distinct features across subjects. Our model, called the Cauchy-Schwarz regularized Partitioned Subspace Variational AutoEncoder (CS-PS-VAE), successfully models continuously varying differences in behavior, and models distinct features of the behavioral videos across subjects in an unsupervised manner. This method is also successful at uncovering the relationships between recorded neural data and the ensuing behavior.","2694-0604","978-1-7281-2782-8","10.1109/EMBC48229.2022.9871466","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9871466","","Biological system modeling;Brain modeling;Data models;Behavioral sciences;Videos","brain;medical image processing;neurophysiology;unsupervised learning;video coding","behavioral quantification;behavioral data;semisupervised approach;Cauchy-Schwarz divergence;CS-PS-VAE;behavioral videos;ensuing behavior;modeling behavior;quantifying behavior;partitioned subspace variational autoencoder;Cauchy-Schwarz regularized partitioned subspace variational autoencoder","","","","12","IEEE","8 Sep 2022","","","IEEE","IEEE Conferences"
"Deep Variation Autoencoder with Topic Information for Text Similarity","Z. Gong; Y. Fu; X. Su; H. Xu","College of Computer Science, Inner Mongolia University, Hohhot, China; College of Computer Science, Inner Mongolia University, Hohhot, China; College of Computer Science, Inner Mongolia University, Hohhot, China; College of Computer Science, Inner Mongolia University, Hohhot, China","2018 3rd International Conference on Computational Intelligence and Applications (ICCIA)","13 May 2019","2018","","","265","269","Representation learning is an essential process in the text similarity task. The methods based on neural variational inference first learn the semantic representation of the texts, then measure the similarity of these texts by calculating the cosine similarity of their representations. However, it is not generally desirable that using the neural network simply to learn semantic representation as it cannot capture the rich semantic information completely. Considering that the similarity of context information reflects the similarity of text pairs in most cases, we integrate the topic information into a stacked variational autoencoder in process of text representation learning. The improved text representations are used in text similarity calculation. Experiment result shows that our approach obtains the state-of-art performance.","","978-1-5386-9571-5","10.1109/ICCIA.2018.00058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8711495","representation learning, semantic similarity, variational autoencoder, deep learning, topic information","Semantics;Task analysis;Computational modeling;Deep learning;Computer science;Stochastic processes;Neural networks","learning (artificial intelligence);neural nets;text analysis","deep variation autoencoder;topic information;essential process;text similarity task;neural variational inference;semantic representation;cosine similarity;neural network;rich semantic information;context information;text pairs;stacked variational autoencoder;text representation learning;improved text representations;text similarity calculation","","","","21","","13 May 2019","","","IEEE","IEEE Conferences"
"Inpainting of Vintage Films Based on Variational Auto-encoder","Y. Li; Y. Ding; B. Yu","Shanghai Film Academy, Shanghai University, Shanghai, China; Shanghai Film Academy, Shanghai University, Shanghai, China; Shanghai Film Academy, Shanghai University, Shanghai, China","2020 5th International Conference on Mechanical, Control and Computer Engineering (ICMCCE)","13 May 2021","2020","","","616","620","There are many existing video restoration frameworks, but there are no professional methods to deal with multiple degradation restorations of vintage films. With the help of the idea of mapping, this paper constructs a model with two variational autoencoders to repair the complex degradation problem. In addition, convolutional LSTM is used for video de-flicker processing to obtain smoother and natural results. The experimental results prove that this method can repair different damages in the vintage films screen at the same time, and achieve good results.","","978-1-6654-2314-4","10.1109/ICMCCE51767.2020.00137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9421468","video inpainting;deep learning;variational auto-encoder;video temporal consistency","Degradation;Convolutional codes;Films;Maintenance engineering;Jitter;Encoding","image restoration;learning (artificial intelligence);recurrent neural nets;video signal processing","complex degradation problem;convolutional LSTM;video de-flicker processing;smoother results;natural results;vintage films screen;inpainting;variational auto-encoder;existing video restoration frameworks;professional methods;multiple degradation restorations;variational autoencoders","","","","19","","13 May 2021","","","IEEE","IEEE Conferences"
"Enhancing Variational Generation Through Self-Decomposition","A. Asperti; L. Bugo; D. Filippini","Department of Informatics: Science and Engineering (DISI), University of Bologna, Bologna, Italy; Department of Informatics: Science and Engineering (DISI), University of Bologna, Bologna, Italy; Department of Informatics: Science and Engineering (DISI), University of Bologna, Bologna, Italy","IEEE Access","30 Jun 2022","2022","10","","67510","67520","In this article we introduce the notion of Split Variational Autoencoder (SVAE), whose output  $\hat {x}$  is obtained as a weighted sum  $\sigma \odot \hat {x_{1}} + (1-\sigma) \odot \hat {x_{2}}$  of two generated images  $\hat {x_{1}},\hat {x_{2}}$ , and  $\sigma $  is a learned compositional map. The composing images  $\hat {x_{1}},\hat {x_{2}}$ , as well as the  $\sigma $ -map are automatically synthesized by the model. The network is trained as a usual Variational Autoencoder with a negative loglikelihood loss between training and reconstructed images. No additional loss is required for  $\hat {x_{1}},\hat {x_{2}}$  or  $\sigma $ , neither any form of human tuning. The decomposition is nondeterministic, but follows two main schemes, that we may roughly categorize as either “syntactic” or “semantic.” In the first case, the map tends to exploit the strong correlation between adjacent pixels, splitting the image in two complementary high frequency sub-images. In the second case, the map typically focuses on the contours of objects, splitting the image in interesting variations of its content, with more marked and distinctive features. In this case, according to empirical observations, the Fréchet Inception Distance (FID) of  $\hat {x_{1}}$  and  $\hat {x_{2}}$  is usually lower (hence better) than that of  $\hat {x}$ , that clearly suffers from being the average of the former. In a sense, a SVAE forces the Variational Autoencoder to make choices, in contrast with its intrinsic tendency to average between alternatives with the aim to minimize the reconstruction loss towards a specific sample. According to the FID metric, our technique, tested on typical datasets such as Mnist, Cifar10 and CelebA, allows us to outperform all previous purely variational architectures (not relying on normalization flows).","2169-3536","","10.1109/ACCESS.2022.3185654","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9804716","Deep learning;generative modeling;multi-layer neural networks;representation learning;unsupervised learning;variational autoencoder","Deep learning;Image reconstruction;Decoding;Syntactics;Semantics;Solid modeling;Neural networks;Unsupervised learning;Representation learning;Encoding","image reconstruction;learning (artificial intelligence);neural nets","negative loglikelihood loss;human tuning;adjacent pixels;complementary high frequency sub-images;marked features;Fréchet inception distance;SVAE forces;reconstruction loss;variational generation;compositional map learning;split variational autoencoder;self-decomposition;Mnist;Cifar10;CelebA;image reconstruction","","","","36","CCBY","23 Jun 2022","","","IEEE","IEEE Journals"
"A Variational Autoencoder Based Generative Model of Urban Human Mobility","D. Huang; X. Song; Z. Fan; R. Jiang; R. Shibasaki; Y. Zhang; H. Wang; Y. Kato","Center for Spatial Information Science, The University of Tokyo; Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology; Center for Spatial Information Science, The University of Tokyo; Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology; Center for Spatial Information Science, The University of Tokyo; Department of Computer Science and Engineering, Hong Kong University of Science and Technology; Civil and Construction Engineering, Oregon State University; Transport Consulting Division, NAVITIME JAPAN Co., Ltd","2019 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)","25 Apr 2019","2019","","","425","430","Recently, big and heterogeneous human mobility data inspires many revolutionary ideas of implementing machine learning algorithms for solving some traditional social issues, such as zone regulation, air pollution, and disaster evacuation el at.. However, incomplete datasets were provided owing to both the concerns of violation of privacy and some technique issues in many practical applications, which leads to some limitations of the utility of collected data. Variational Autoencoder (VAE), which uses a well-constructed latent space to capture salient features of the training data, shows a significant excellent performance in not only image processing, but also Natural Language Processing domain. By combining VAE and sequence-to-sequence (seq2seq) model, a Sequential Variational Autoencoder (SVAE) is built for the task of human mobility reconstruction. It is the first time that this kind of SVAE model is implemented for solving the issues about human mobility reconstruction. We use navigation GPS data of selected greater Tokyo area to evaluate the performance of the SVAE model. Experimental results demonstrate that the SVAE model can efficiently capture the salient features of human mobility data and generate more reasonable trajectories.","","978-1-7281-1198-8","10.1109/MIPR.2019.00086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8695407","human mobility;generative model;machine learning","Trajectory;Hidden Markov models;Global Positioning System;Data models;Gaussian distribution;Data privacy","feature extraction;learning (artificial intelligence);natural language processing;variational techniques","generative model;urban human mobility;big mobility data;heterogeneous human mobility data;zone regulation;image processing;sequence-to-sequence model;human mobility reconstruction;SVAE model;navigation GPS data;natural language processing domain;sequential variational autoencoder","","3","","26","","25 Apr 2019","","","IEEE","IEEE Conferences"
"Design of Communication Systems Using Deep Learning: A Variational Inference Perspective","V. Raj; S. Kalyani","Department of Electrical Engineering, Indian Institute of Technology Madras, Chennai, India; Department of Electrical Engineering, Indian Institute of Technology Madras, Chennai, India","IEEE Transactions on Cognitive Communications and Networking","8 Dec 2020","2020","6","4","1320","1334","Recent research in the design of end to end communication system using deep learning has produced models which can outperform traditional communication schemes. Most of these architectures leveraged autoencoders to design the encoder at the transmitter and decoder at the receiver and train them jointly by modeling transmit symbols as latent codes from the encoder. However, in communication systems, the receiver has to work with noise corrupted versions of transmit symbols. Traditional autoencoders are not designed to work with latent codes corrupted with noise. In this work, we provide a framework to design end to end communication systems which accounts for the existence of noise corrupted transmit symbols. The proposed method uses deep neural architecture. An objective function for optimizing these models is derived based on the concepts of variational inference. Further, domain knowledge such as channel type can be systematically integrated into the objective. Through numerical simulation, the proposed method is shown to consistently produce models with better packing density and achieving it faster in multiple popular channel models as compared to the previous works leveraging deep learning models.","2332-7731","","10.1109/TCCN.2020.2985371","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9056790","Physical layer;deep learning;variational inference;autoencoders","Communication systems;Receivers;Machine learning;Transmitters;Noise measurement;Decoding;Graphical models","channel coding;deep learning (artificial intelligence);inference mechanisms;neural net architecture;optimisation;telecommunication computing;variational techniques;wireless channels","optimisation;autoencoders;end to end communication system;variational inference perspective;deep learning models;channel models;deep neural architecture;noise corrupted transmit symbols;latent codes","","11","","32","IEEE","3 Apr 2020","","","IEEE","IEEE Journals"
"Generalisation Techniques Using a Variational CEAE for Classifying Manuka Honey Quality","T. Phillips; W. Abdulla","Electrical, Computer and Software Engineering, University of Auckland, Auckland, New Zealand; Electrical, Computer and Software Engineering, University of Auckland, Auckland, New Zealand","2020 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","31 Dec 2020","2020","","","1631","1640","This paper presents an integrated architecture of the class embodiment autoencoder (CEAE) and variational autoencoder. The aim is to improve the generalisation of the algorithm and accordingly increase the classification accuracy of unseen samples. The proposed variational CEAE is trained by using hyperspectral images of Manuka honey dataset, then evaluated for generalisation performance on unseen brands of honey. We applied well-known generalisation techniques to this structure, and evaluated the effect of these on our dataset. Our experiment results show that the average validation set performance of the new autoencoder technique on unseen brands is 55.4%, while the average benchmark technique is 48.1% for the same unseen brands. The autoencoder structures are performing feature reduction on our data, which has shown to improve the classification accuracy and generalisation performance. We tested the feature reduction techniques in combination with K-nearest-neighbour classifier, linear support vector machine (SVM), and radial basis function SVM. This work develops an important step toward the automatic classification of Manuka honey quality using hyperspectral imaging and machine learning. This is the first work to evaluate generalisation performance in honey classification, which is crucial for a viable real-world solution.","2640-0103","978-988-14768-8-3","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9306291","Autoencoders;Feature Reduction;Generalisation;Hyperspectral Imaging;Support Vector Machines","Training;Hyperspectral imaging;Support vector machines;Standards;Noise reduction;Decoding;Noise measurement","generalisation (artificial intelligence);image classification;learning (artificial intelligence);nearest neighbour methods;radial basis function networks;support vector machines","radial basis function SVM;linear support vector machine;generalisation techniques;Manuka honey quality classification;honey classification;machine learning;hyperspectral imaging;K-nearest-neighbour classifier;feature reduction techniques;autoencoder structures;average benchmark technique;autoencoder technique;average validation set performance;unseen brands;generalisation performance;Manuka honey dataset;hyperspectral images;unseen samples;classification accuracy;variational autoencoder;integrated architecture;variational CEAE","","","","34","","31 Dec 2020","","","IEEE","IEEE Conferences"
"Variations in Variational Autoencoders - A Comparative Evaluation","R. Wei; C. Garcia; A. El-Sayed; V. Peterson; A. Mahmood","Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, USA; Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, USA; Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, USA; Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, USA; Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, USA","IEEE Access","28 Aug 2020","2020","8","","153651","153670","Variational Auto-Encoders (VAEs) are deep latent space generative models which have been immensely successful in many applications such as image generation, image captioning, protein design, mutation prediction, and language models among others. The fundamental idea in VAEs is to learn the distribution of data in such a way that new meaningful data can be generated from the encoded distribution. This concept has led to tremendous research and variations in the design of VAEs in the last few years creating a field of its own, referred to as unsupervised representation learning. This paper provides a much-needed comprehensive evaluation of the variations of the VAEs based on their end goals and resulting architectures. It further provides intuition as well as mathematical formulation and quantitative results of each popular variation, presents a concise comparison of these variations, and concludes with challenges and future opportunities for research in VAEs.","2169-3536","","10.1109/ACCESS.2020.3018151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9171997","Deep learning;variational autoencoders (VAEs);data representation;generative models;unsupervised learning;representation learning;latent space","Decoding;Data models;Computational modeling;Neural networks;Training data;Bayes methods;Probability distribution","neural nets;unsupervised learning","VAEs;deep latent space generative models;image generation;image captioning;protein design;mutation prediction;language models;encoded distribution;unsupervised representation learning;variational autoencoders","","15","","101","CCBY","20 Aug 2020","","","IEEE","IEEE Journals"
"Optimization Algorithm of Time Synchronization Network Monitoring Based on Variational Autoencoder","B. Lv; F. Pan; X. Miao; C. Hu","Institute of Technology and Standards, China Academy of Information and Communication, Beijing, China; Institute of Technology and Standards, China Academy of Information and Communication, Beijing, China; Institute of Technology and Standards, China Academy of Information and Communication, Beijing, China; Institute of Technology and Standards, China Academy of Information and Communication, Beijing, China","2020 5th International Conference on Computational Intelligence and Applications (ICCIA)","27 Aug 2020","2020","","","133","137","In this paper an optimization algorithm for time synchronization in telecommunication network is proposed based on VAE(Variational Auto Encoder)framework. Firstly features are represented in latent space under proposed framework while performance of synchronization network is measured and evaluated. Secondly optimization algorithm is further designed with which feature of abnormal samples and benchmark are adaptively merged for smooth adjustment with low risk in practical network operation. Meanwhile considering the characteristics as domain knowledge of synchronization network, a novel metric is adopted to reduce the fluctuation of adjustment. The simulation results verified that performance of synchronization network is significantly improved by optimization templates reconstructed through decoding part of VAE model. It is implied that prior knowledge of synchronization in latent space is introduced with certain interpret-ability for assessment of monitoring performance while optimization adjustment can be properly operated through novel metric proposed in this algorithm.","","978-1-7281-6042-9","10.1109/ICCIA49625.2020.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9178676","telecommunication;time synchronization;machine learning;variational autoencoder;optimization algorithm","Synchronization;Optimization;Monitoring;Machine learning;Benchmark testing;Machine learning algorithms","computer networks;feature extraction;neural nets;optimisation;synchronisation;telecommunication computing","practical network operation;optimization templates;latent space;optimization algorithm;time synchronization network monitoring;telecommunication network;VAE;variational autoencoder framework","","1","","18","","27 Aug 2020","","","IEEE","IEEE Conferences"
"Synthesis Algorithm of Data in Synchronization Network Based on Modified Variational Autoencoder","B. Lv; Y. Wang; S. Li; X. Miao; G. Zhang; C. Hu","China Academy of Information and Communication, Institute of Technology and Standards, Beijing, China; The State Grid Corporation of China, China Electric Power Research Institute, Beijing, China; China Academy of Information and Communication, Institute of Technology and Standards, Beijing, China; China Academy of Information and Communication, Institute of Technology and Standards, Beijing, China; The State Grid Corporation of China, China Electric Power Research Institute, Beijing, China; China Academy of Information and Communication, Institute of Technology and Standards, Beijing, China","2021 6th International Conference on Computational Intelligence and Applications (ICCIA)","16 Dec 2021","2021","","","36","40","In this paper aiming to generate plentiful testing samples on demand in synchronization network, a synthesis method with machine learning is proposed inspired by generative model and loss function of style transfer. Firstly equivalent relationship between synthesis data and phase response is analyzed, based on which the modified VAE (Variational Auto Encoder) framework is designed where attribute features of phase response for synthesis data are represented in latent space, grafting a style evaluation network for the purpose that the diversity of style for data generation is quantified and evaluated. Secondly synthesis algorithm is implemented with a novel scheme to operate and select attribute feature in latent space under proposed criteria as posterior processing to balance the style diversity and fitness with the category of anchor sample from standard template. Moreover the experimental results verify that the proposed algorithm show some advantages in the aspect of generation speed, richness of samples and accuracy of fitness for objective on demand, comparing to conventional method such as simulated annealing or genetic algorithm. Finally two potential application scenarios adopting this synthesis algorithm are recommended in synchronization network.","","978-1-6654-3933-6","10.1109/ICCIA52886.2021.00015","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9643609","telecommunication;synchronization network;machine learning;variational autoencoder;synthesis algorithm","Simulated annealing;Machine learning;Synchronization;Standards;Testing;Genetic algorithms","genetic algorithms;learning (artificial intelligence);simulated annealing","synchronization network;generative model;style transfer;phase response;modified VAE framework;latent space;style evaluation network;data generation;synthesis algorithm;attribute feature;style diversity;generation speed;genetic algorithm;modified variational autoencoder","","","","15","IEEE","16 Dec 2021","","","IEEE","IEEE Conferences"
"Cross-modal Variational Alignment of Latent Spaces","T. Theodoridis; T. Chatzis; V. Solachidis; K. Dimitropoulos; P. Daras","Information Technologies Institute, Centre for Research and Technology Hellas, Thessaloniki, Greece; Information Technologies Institute, Centre for Research and Technology Hellas, Thessaloniki, Greece; Information Technologies Institute, Centre for Research and Technology Hellas, Thessaloniki, Greece; Information Technologies Institute, Centre for Research and Technology Hellas, Thessaloniki, Greece; Information Technologies Institute, Centre for Research and Technology Hellas, Thessaloniki, Greece","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","4127","4136","In this paper, we propose a novel cross-modal variational alignment method in order to process and relate information across different modalities. The proposed approach consists of two variational autoencoder (VAE) networks which generate and model the latent space of each modality. The first network is a multi modal variational autoencoder that maps directly one modality to the other, while the second one is a single-modal variational autoencoder. In order to associate the two spaces, we apply variational alignment, which acts as a translation mechanism that projects the latent space of the first VAE onto the one of the single-modal VAE through an intermediate distribution. Experimental results on four well-known datasets, covering two different application domains (food image analysis and 3D hand pose estimation), show the generality of the proposed method and its superiority against a number of state-of-the-art approaches.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00488","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150585","","Decoding;Task analysis;Three-dimensional displays;Gallium nitride;Probability distribution;Training;Pose estimation","image processing;neural nets","latent space;novel cross-modal variational alignment method;variational autoencoder networks;multimodal variational autoencoder;single-modal variational autoencoder;single-modal VAE","","5","","40","","28 Jul 2020","","","IEEE","IEEE Conferences"
"Improving Diversity of Image Captioning Through Variational Autoencoders and Adversarial Learning","L. Ren; G. -J. Qi; K. Hua","University of Central Florida; Huawei Cloud, Seattle; University of Central Florida","2019 IEEE Winter Conference on Applications of Computer Vision (WACV)","7 Mar 2019","2019","","","263","272","Learning translation from images to human-readable natural language has become a great challenge in computer vision research in recent years. Existing works explore the semantic correlation between the visual and language domains via encoder-to-decoder learning frameworks based on classifying visual features in the language domain. This approach, however, is criticized for its lacking of naturalness and diversity. In this paper, we demonstrate a novel way to learn a semantic connection between visual information and natural language directly based on a Variational Autoencoder (VAE) that is trained in an adversarial routine. Instead of using the classification based discriminator, our method directly learns to estimate the diversity between a hidden vector embedded from a text encoder and an informative feature that is sampled from a learned distribution of the autoencoders. We show that the sentences learned from this matching contains accurate semantic meaning with high diversity in the image captioning task. Our experiments on the popular MSCOCO dataset indicates that our method learns to generate high-quality natural language with competitive scores on both correctness and diversity.","1550-5790","978-1-7281-1975-5","10.1109/WACV.2019.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8659100","","Visualization;Semantics;Gallium nitride;Generative adversarial networks;Training;Generators;Maximum likelihood estimation","computer vision;image classification;image coding;image segmentation;learning (artificial intelligence);natural language processing;recurrent neural nets","adversarial learning;translation;human-readable natural language;computer vision research;semantic correlation;visual language;encoder-to-decoder learning frameworks;visual features;language domain;naturalness;semantic connection;visual information;adversarial routine;classification based discriminator;text encoder;informative feature;learned distribution;image captioning task;high-quality natural language;MSCOCO dataset;variational autoencoders;variational autoencoder","","2","","64","","7 Mar 2019","","","IEEE","IEEE Conferences"
"Conditional Introspective Variational Autoencoder for Image Synthesis","K. Zheng; Y. Cheng; X. Kang; H. Yao; T. Tian","School of Geography and Information Engineering, China University of Geosciences, Wuhan, China; School of Computer Science, China University of Geosciences, Wuhan, China; School of Computer Science, China University of Geosciences, Wuhan, China; School of Computer Science, China University of Geosciences, Wuhan, China; School of Computer Science, China University of Geosciences, Wuhan, China","IEEE Access","28 Aug 2020","2020","8","","153905","153913","We present a variational autoencoder (VAE) learning framework with introspective training for conditional image synthesis, and explore conditional capsule encoder by class-wise mask label insertion for this framework. Our model only consists of encoder (E), generator (G) and classifier (C), where E and G can be adversarially optimized, and C helps to boost conditional generation, improve authenticity and provide generation measures for E and G. Discriminator is not necessary in our framework and its absence makes our model more concise with fewer artifacts and pattern collapse problems. To compensate for the blurry weakness of VAE-like models, feature matching is introduced into loss functions by means of C to offer more reasonable measures between real and synthesized images. Moreover, in consideration of the key role of E in autoencoders as well as the interesting characteristics of capsule structure, conditional capsule encoder is preliminary explored in the image synthesis model. Class labels participate conditional encoding by masking high-level capsules of other categories, and capsule loss for the encoder is added to facilitate conditional synthesis. Experiments on MNIST and Fashion-MNIST data sets show that our model achieves real conditional synthesis performances with better diversity and fewer artifacts. And conditional capsule encoder also reveals interesting synthesis effects.","2169-3536","","10.1109/ACCESS.2020.3018228","National Basic Research Program of China (973 Program)(grant numbers:2018YFB1004600); National Science and Technology Major Project of China(grant numbers:2017ZX05036-001-010); Science and Technology Planning Project of Guangdong Province, China(grant numbers:2018B020207012); National Natural Science Foundation of China(grant numbers:41701417,61972365,61672474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9172064","Image generation;artificial neural networks;image processing","Generators;Image synthesis;Training;Generative adversarial networks;Gallium nitride;Image reconstruction;Task analysis","feature extraction;image classification;image coding;image matching;image representation;learning (artificial intelligence)","Fashion-MNIST data sets;feature matching;pattern collapse problems;synthesis effects;capsule loss;conditional encoding;image synthesis model;VAE-like models;class-wise mask label insertion;conditional capsule encoder;conditional image synthesis;introspective training;variational autoencoder learning framework;conditional introspective variational autoencoder","","2","","31","CCBY","20 Aug 2020","","","IEEE","IEEE Journals"
"Chest X-Rays Image Classification from $\beta{-}$ Variational Autoencoders Latent Features","L. Crespi; D. Loiacono; A. Chiti","Centre for Health Data Human Technopole, Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria Politecnico di Milano, Milan, Italy; IRCCS Humanitas Research Hospital Rozzano, Milan, Italy","2021 IEEE Symposium Series on Computational Intelligence (SSCI)","24 Jan 2022","2021","","","1","8","Chest X-Ray (CXR) is one of the most common diagnostic imaging used in everyday clinical practice. In this work, we present a Deep Learning (DL) approach to extract from CXR images a set of features that would capture as much information as possible. In particular, our aim is to extract highly general features that could be successfully used for a large variety of real-world classification tasks. Accordingly, we trained several $\beta{-}$, Variational Autoencoder $(\beta{-}$ VAE) models on CheXpert, a popular dataset consisting in a very broad and publicly available collection of labeled CXR images; through these models, high level features have been extracted and used to train Machine Learning (ML) classifier (Random Forest, K-Nearest Neighbours, Extremely Randomised Trees, Gradient Boosting), to classify CXR images thanks to the information extracted from the $\beta{-}$ - VAEs; finally, trained classifiers have been combined in ensembles to improve the performances without the need of further training or models engineering. Despite, as expected, our approach does not achieve the same performance of the state-of-the-art models specifically devised for this classification task, our results are promising and show the viability of using the high level features extracted by the Autoencoders for classification tasks.","","978-1-7281-9048-8","10.1109/SSCI50451.2021.9660190","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9660190","machine learning;medical images classification;auto encoders","Training;Feature extraction;Data mining;Task analysis;Usability;X-ray imaging;Random forests","diagnostic radiography;feature extraction;image classification;learning (artificial intelligence);medical image processing;nearest neighbour methods;neural nets;random forests","chest X-rays image classification;common diagnostic imaging;everyday clinical practice;real-world classification tasks;variational autoencoder models;β- VAE;labeled CXR images;high level features;extremely randomised trees;CXR images;trained classifiers;classification task;deep learning approach;β- variational autoencoders latent features;random forest;k-nearest neighbours;gradient boosting","","","","36","IEEE","24 Jan 2022","","","IEEE","IEEE Conferences"
"Prediction of Subsurface NMR T2 Distributions in a Shale Petroleum System Using Variational Autoencoder-Based Neural Networks","H. Li; S. Misra","Mewbourne School of Petroleum and Geological Engineering, University of Oklahoma, Norman, OK, USA; Petroleum and Geological Engineering Department, University of Oklahoma, Norman, OK, USA","IEEE Geoscience and Remote Sensing Letters","4 Dec 2017","2017","14","12","2395","2397","Nuclear magnetic resonance (NMR) is used in geological characterization to investigate the internal structure of geomaterials filled with fluids containing 1H and 13C nuclei. Subsurface NMR measurements are generally acquired as well logs that provide information about fluid mobility and fluid-filled pore size distribution. Acquisition of subsurface NMR log is limited due to operational and instrumentation challenges. We implement a variational autoencoder (VAE) for improved training of a neural network (NN) to generate the NMR-T2 distributions along a 300-ft depth interval in a shale petroleum system at 11000-ft depth below sea level. Subsurface mineral and kerogen volume fractions, fluid saturations, and T2 distributions acquired at 460 discrete depth points were used as the training data set. The trained VAE-NN successfully predicts the T2 distributions for 100 discrete depths at an R2 of 0.75 and normalized root-mean-square deviation of 15%.","1558-0571","","10.1109/LGRS.2017.2766130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8113692","Machine learning;nuclear magnetic resonance (NMR)","Nuclear magnetic resonance;Training;Minerals;Artificial neural networks;Training data;Testing;Petroleum","geophysical prospecting;hydrocarbon reservoirs;neural nets;nuclear magnetic resonance;porosity;production engineering computing;well logging","shale petroleum system;nuclear magnetic resonance;fluid mobility;NMR-T2 distributions;fluid saturations;geomaterials geological characterization;well logs;fluid-filled pore size distribution;normalized root mean square deviation;autoencoder-based neural network","","38","","9","IEEE","16 Nov 2017","","","IEEE","IEEE Journals"
"Conditional Perceptual Adversarial Variational Autoencoder for Age Progression and Regression on Child Face","P. K. Chandaliya; N. Nain","Malaviya National Institute of Technology, Jaipur, India; Malaviya National Institute of Technology, Jaipur, India","2019 International Conference on Biometrics (ICB)","10 Feb 2020","2019","","","1","8","Recent works have shown that Generative Adversarial Networks (GAN) and Variational Auto-Encoder (VAE) can construct synthetic images of remarkable visual fidelity. In this paper, we propose a novel architecture based on GAN and VAE with Perceptual loss termed as Conditional Perceptual Adversarial Variational Autoencoder (CPAVAE), a model for face aging and rejuvenation on children face. CPAVAE performs face aging and rejuvenation by learning manifold constrained with conditions such as age and gender, which allows it to preserve face identity. CPAVAE uses six networks; these networks are an Encoder (E) and Sampling (S) which maps the child face to latent vector, Generator (G) takes the latent vector z as input along with age conditioned vector and tries to reconstruct the input image, a perceptual loss network Φ, a pre-trained very deep convolution network, discriminator on the encoder (Dz) smoothen's the age transformation, discriminator on the image (Dimg) forces the generator to produce human realistic images. Here D and E are based on Variational Auto-encoder (VAE) architecture, VGGNet is used as perceptual loss network (Ploss), Dz and Dimg are convolutional neural networks. We represent child face progression and regression on the Children Longitudinal Face(CLF) dataset containing 10752 faces images in the age group [0 : 20]. This dataset contains 6164 and 4588 images of boys and girls respectively.","2376-4201","978-1-7281-3640-0","10.1109/ICB45273.2019.8987410","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8987410","","","age issues;convolutional neural nets;face recognition;image reconstruction;learning (artificial intelligence);variational techniques","age progression;GAN;CPAVAE;face rejuvenation;children face;gender;face identity;age conditioned vector;perceptual loss network;pre-trained very deep convolution network;age transformation;convolutional neural networks;child face progression;faces images;age group;conditional perceptual adversarial variational autoencoder;generative adversarial networks;child face regression;visual fidelity;face aging;learning manifold;latent vector;image reconstruction;Children Longitudinal Face dataset","","5","","40","","10 Feb 2020","","","IEEE","IEEE Conferences"
"Collaborative Variational Deep Learning for Healthcare Recommendation","X. Deng; F. Huangfu","Business School, Huaqiao University, Quanzhou, China; College of Foreign Languages, Huaqiao University, Quanzhou, China","IEEE Access","6 May 2019","2019","7","","55679","55688","Healthcare recommender system (HRS) has shown the great potential of targeting medical experts or patients, and plays a key role in improving an individual's health by providing insightful recommendations. The HRSs generate recommendations based on a successful and widely applied method known as collaborative filtering (CF). Despite its success, the CF suffers from data sparsity and cold-start problem, which results in the poor quality of recommendations. In particular, it is a great challenge to seeking information relevant to patients' condition, and understanding the medical terms and relationships between them in HRSs. To address these problems, we design a novel collaborative variational deep learning model (CVDL) to exploit multi-sourced information for providing appropriate healthcare recommendations in primary care service. CVDL employs additional variational autoencoder (VAE) to learn deep latent representations for item contents (the description of primary care doctors) in latent space, instead of observation space through an inference network. Meanwhile, the CVDL extracts latent user (patient) features by incorporating user profile in a VAE neural network. Therefore, the CVDL can learn better implicit relationships between items and users from item content, user profile, and rating matrix. In addition, a Stochastic Gradient Variational Bayes (SGVB) approach is proposed to calculate the maximum posterior estimates for learning model parameters. The experiments conducted on three datasets have indicated that our method significantly outperforms the state-of-the-art hybrid CF methods.","2169-3536","","10.1109/ACCESS.2019.2913468","National Natural Science Foundation of China(grant numbers:71401058); Program for New Century Excellent Talents in Fujian Province University (NCETFJ); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8704225","Collaborative topic regression;variational autoencoder;healthcare recommender system;side information;implicit feedback","Medical services;Collaboration;Predictive models;Deep learning;Feature extraction;Recommender systems;Neural networks","Bayes methods;collaborative filtering;health care;learning (artificial intelligence);maximum likelihood estimation;medical information systems;neural nets;recommender systems;stochastic processes","healthcare recommender system;medical experts;HRSs;collaborative filtering;data sparsity;cold-start problem;medical terms;CVDL;multisourced information;primary care service;deep latent representations;item content;primary care doctors;latent user features;user profile;VAE neural network;collaborative variational deep learning model;variational autoencoder;stochastic gradient variational Bayes approach;hybrid CF methods;patients condition;SGVB approach;rating matrix;maximum posterior estimates;learning model parameters","","10","","30","OAPA","1 May 2019","","","IEEE","IEEE Journals"
"Variational Bayesian GAN","J. -T. Chien; C. -L. Kuo","Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan","2019 27th European Signal Processing Conference (EUSIPCO)","18 Nov 2019","2019","","","1","5","Generative adversarial network (GAN) has been successfully developing as a generative model where the artificial data drawn from the generator are misrecognized as real samples by a discriminator. Although GAN achieves the desirable performance, the challenge is that the mode collapse easily happens in the joint optimization of generator and discriminator. This study copes with this challenge by improving the model regularization by means of representing the weight uncertainty in GAN. A new Bayesian GAN is formulated and implemented to learn a regularized model from diverse data where the strong modes are flattened via the marginalization and the issues of model collapse and gradient vanishing are alleviated. In particular, we present a variational GAN (VGAN) where the encoder, generator and discriminator are jointly estimated according to the variational Bayesian inference. The experiments on image generation over two tasks (MNIST and CeleA) demonstrate the superiority of the proposed VGAN to the variational autoencoder, the standard GAN and the Bayesian GAN based on the sampling method. The learning efficiency and generation performance are evaluated.","2076-1465","978-9-0827-9703-9","10.23919/EUSIPCO.2019.8903084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903084","generative adversarial networks;Bayesian learning;variational autoencoder;computer vision","Gallium nitride;Generative adversarial networks;Generators;Bayes methods;Data models;Uncertainty;Training","Bayes methods;belief networks;computer vision;inference mechanisms;learning (artificial intelligence);neural nets;sampling methods","variational Bayesian GAN;generative adversarial network;joint optimization;model regularization;gradient vanishing;variational Bayesian inference;image generation;variational autoencoder;learning efficiency;weight uncertainty;sampling method;VGAN","","5","","24","","18 Nov 2019","","","IEEE","IEEE Conferences"
"Comparing AutoEncoder Variants for Real-Time Denoising of Hyperspectral X-Ray","N. Bonettini; C. A. Gonano; P. Bestagini; M. Marcon; B. Garavelli; S. Tubaro","Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy; Xnext S.p.A., Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy; Xnext S.p.A., Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy","IEEE Sensors Journal","14 Sep 2022","2022","22","18","17997","18007","Hyperspectral X-ray analysis is used in many industrial pipelines, from quality control to detection of low-density contaminants in food. Unfortunately, the signal acquired by X-ray sensors is often affected by a great amount of noise. This hinders the performance of most of the applications building on top of these acquisitions (e.g., detection of food contaminants). Therefore, a good denoising pipeline is necessary. This article proposes a comparison between three different AutoEncoder variants: the Variational AutoEncoder, the Augmented AutoEncoder, and a plain vanilla AutoEncoder. All the networks are trained in an unsupervised fashion to denoise a given noisy spectrum. Focusing on the specific application of recognizing possible food contaminants, we force the latent space of the networks to have just two parameters, as suggested by the physical law of Lambert–Beer. We validate our experiments on a synthetic dataset composed of roughly 15 million spectra. Results suggest that the Augmented AutoEncoder is the best network configuration for this task, showing excellent performance without suffering from the nondeterministic behavior of the Variational AutoEncoder.","1558-1748","","10.1109/JSEN.2022.3195038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9850976","AutoEncoder;denoising;hyperspectral X-ray","Noise reduction;Sensors;X-ray imaging;Hyperspectral imaging;Noise measurement;Photonics;Plastics","contamination;data reduction;feature extraction;image classification;image denoising;learning (artificial intelligence);neural nets;pipelines;quality control;signal denoising","Augmented AutoEncoder;network configuration;Variational AutoEncoder;real-time denoising;hyperspectral X-ray analysis;industrial pipelines;quality control;low-density contaminants;X-ray sensors;applications building;good denoising pipeline;different AutoEncoder variants;plain vanilla AutoEncoder;unsupervised fashion;given noisy spectrum;possible food contaminants","","","","40","IEEE","4 Aug 2022","","","IEEE","IEEE Journals"
"Stochastic Gradient Variational Bayes for deep learning-based ASR","A. Tjandra; S. Sakti; S. Nakamura; M. Adriani","Faculty of Computer Science, Universitas Indonesia, Indonesia; Graduate School of Information Science, Nara Institute of Science and Technology, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Japan; Faculty of Computer Science, Universitas Indonesia, Indonesia","2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)","11 Feb 2016","2015","","","175","180","Many successful methods for training deep neural networks (DNN) rely on an unsupervised pretraining algorithm. It is particularly effective when the number of labeled training samples is not large enough, because pretraining method helps to initialize the parameter values in the appropriate range near a local good minimum, for further discriminative finetuning. However, while the improvement is impressive, training DNN is difficult because the objective function of DNN is highly non-convex function of the parameters. To avoid placing the parameter that generalizes poorly, a robust generative modelling is necessary. This paper explore an alternative of generative modelling for pretraining DNN-based acoustic modelling using Stochastic Gradient Variational Bayes (SGVB) within autoencoder framework called Variational Bayes Autoencoder (VBAE). It performs an efficient approximate inference and learning with directed probabilistic graphical models. During fine-tuning, probabilistic encoder parameters with latent variable components are then used in discriminative training for acoustic model. Here, we investigate the performances of DNN-based acoustic model using the proposed pretrained VBAE in comparison with widely used pretraining algorithms like Restricted Boltzmann Machine (RBM) and Stacked Denoising Autoencoder (SDAE). The results reveal that VBAE pretraining with Gaussian latent variables gave the best performance.","","978-1-4799-7291-3","10.1109/ASRU.2015.7404791","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7404791","acoustic model;deep neural network;variational Bayes;autoencoder","Hidden Markov models;Probabilistic logic;Acoustics;Training;Data models;Decoding;Neural networks","directed graphs;gradient methods;inference mechanisms;learning (artificial intelligence);neural nets;speech recognition;stochastic processes","stochastic gradient variational Bayes model;deep learning-based ASR;automatic speech recognition;deep neural networks;DNN training;unsupervised pretraining algorithm;robust generative modelling;SGVB model;autoencoder framework;inference;directed probabilistic graphical model;latent variable components;pretraining algorithm;restricted Boltzmann machine;RBM algorithm;stacked denoising autoencoder algorithm;SDAE algorithm","","4","","23","","11 Feb 2016","","","IEEE","IEEE Conferences"
"Monitoring of Wastewater Treatment Process Based on Slow Feature Analysis Variational Autoencoder","K. Wang; P. Chang; F. Meng","Faculty of Information Technology, Beijing University of Technology, Beijing, China; Beijing Key Laboratory of Computational Intelligence and Intelligent System, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China","2021 IEEE 10th Data Driven Control and Learning Systems Conference (DDCLS)","25 Jun 2021","2021","","","495","502","The wastewater treatment process (WWTP) is a complex nonlinear, uncertain and dynamic physical and biochemical reaction process. The non-linearity, uncertainty and dynamicity of the WWTP increase the difficulty of extracting data features, and also make it difficult to monitor the faults in this process. Aiming at the problems of non-linearity, uncertainty and dynamicity, a slow feature variational autoencoder (SFAVAE) process monitoring model is proposed. With the dynamicity of WWTP data taken into account, the slow feature analysis algorithm (SFA) is used to extract the slowly changing dynamic features of wastewater data. The variational autoencoder can impose Gaussian distribution restrictions on its hidden layer features, so that it can simultaneously learn nonlinear and certain features that obey the Gaussian distribution to deal with the nonlinearity and uncertainty of data. Finally, the hidden layer space of the variational autoencoder model is used to construct hidden layer feature statistics Z2 to realize process monitoring. Compared with the principal component analysis (PCA), independent component analysis (ICA), kernel principal analysis (KPCA) and variational auto-encoder (VAE) models, the experimental results of the benchmark simulation model 1 (BSM1) model show that the SFAVAE model has higher effectiveness in process monitoring.","2767-9861","978-1-6654-2423-3","10.1109/DDCLS52934.2021.9455562","National Natural Science Foundation of China(grant numbers:61174109); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9455562","non-linearity;uncertainty;dynamics;process monitoring","Process monitoring;Analytical models;Uncertainty;Biological system modeling;Heuristic algorithms;Gaussian distribution;Feature extraction","feature extraction;Gaussian distribution;independent component analysis;neural nets;principal component analysis;process monitoring;production engineering computing;wastewater treatment","wastewater treatment process;dynamic physical reaction process;biochemical reaction process;WWTP;slow feature analysis algorithm;Gaussian distribution;slow feature variational autoencoder process;SFA;process monitoring model;hidden layer feature statistics;principal component analysis;independent component analysis;PCA;ICA;kernel principal analysis;KPCA;VAE;variational auto-encoder models;BSM;benchmark simulation;SFAVAE model","","1","","29","","25 Jun 2021","","","IEEE","IEEE Conferences"
"GAN-VAE: Elevate Generative Ineffective Image Through Variational Autoencoder","J. Chen; W. Song","Automatization Engineering College, Nanjing University of Posts and Telecomunications, Nanjing, China; School of Geographic and Biologic Information, Nanjing University of Posts and Telecomunications, Shanghai, China","2022 5th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)","4 Oct 2022","2022","","","765","770","We present a general learning framework which combine a deep convolutional GANs network with a variational autoencoder network. To begin with, we found a solution which could solve the problem that the images create from generator of GANs are usually unsharp and breezing. In this case, GAN merge with VAE could be a better choice which will avoid to waste the resource of GPU or TPU. We put what we have done on https://github.com/charlesshowup/GAN-AE.","","978-1-6654-9916-3","10.1109/PRAI55851.2022.9904067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9904067","GAN;autoencoder;computer vision;CNN;variational autoencoder;DCGAN","Training;Face recognition;Graphics processing units;Generative adversarial networks;Generators;Artificial intelligence;Testing","","","","","","13","IEEE","4 Oct 2022","","","IEEE","IEEE Conferences"
"Infinite Variational Autoencoder for Semi-Supervised Learning","M. E. Abbasnejad; A. Dick; A. van den Hengel",The University of Adelaide; The University of Adelaide; The University of Adelaide,"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","9 Nov 2017","2017","","","781","790","This paper presents an infinite variational autoencoder (VAE) whose capacity adapts to suit the input data. This is achieved using a mixture model where the mixing coefficients are modeled by a Dirichlet process, allowing us to integrate over the coefficients when performing inference. Critically, this then allows us to automatically vary the number of autoencoders in the mixture based on the data. Experiments show the flexibility of our method, particularly for semi-supervised learning, where only a small number of training samples are available.","1063-6919","978-1-5386-0457-1","10.1109/CVPR.2017.90","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8099573","","Data models;Bayes methods;Mixture models;Semisupervised learning;Training;Supervised learning;Predictive models","image coding;learning (artificial intelligence);mixture models;variational techniques","Dirichlet process;semisupervised learning;VAE;input data;mixture model;mixing coefficients;infinite variational autoencoder","","21","1","47","","9 Nov 2017","","","IEEE","IEEE Conferences"
"Deep Convolutional Stack Autoencoder of Process Adaptive VMD Data With Robust Multikernel RVFLN for Power Quality Events Recognition","M. Sahani; P. K. Dash","Multidisciplinary Research Cell, Siksha ‘O’ Anusandhan (Deemed to be University), Bhubaneswar, India; Multidisciplinary Research Cell, Siksha ‘O’ Anusandhan (Deemed to be University), Bhubaneswar, India","IEEE Transactions on Instrumentation and Measurement","10 Feb 2021","2021","70","","1","12","In this article, an improved particle swarm optimization (PSO)-based variational mode decomposition (VMD) is proposed to compute the most informative band-limited intrinsic mode function (BLIMF) of highly nonstationary single as well as combined power quality events (PQEs). A novel reduced deep convolutional neural network (RDCNN) embedded with stack autoencoder, that is, RDCSAE structure is introduced to extract the most discriminative unsupervised feature data by importing the selected BLIMF of parameter-adaptive VMD (PAVMD) algorithm. A supervised robust multikernel random vector functional link network (RMRVFLN) method is proposed to further train the unsupervised features combined with the deep convoluted Fourier privileged data for the recognition of complex PQEs accurately. Automatic computation of minimum overlapped descriptive features, unified complex feature learning framework, outstanding recognition accuracy, robust antinoise performance, and quick PQEs recognition time prove the superiority of the proposed PAVMD-RDCSAE-RMRVFLN method over RDCNN, PAVMD-RDCNN, PAVMD-RDCSAE, PAVMD-RDCNN-RMRVFLN, and PAVMD-RDCSAE-MRVFLN methods. Finally, the architecture of the proposed method is designed, implemented, and tested in a fast digital field-programmable gate array (FPGA) embedded processor to validate the feasibility, practicability, and performances for the online PQEs monitoring.","1557-9662","","10.1109/TIM.2021.3054673","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9335941","Autoencoder;deep convolutional neural network (DCNN);field programmable gate array;parameter adaptive variational mode decomposition (PAVMD);power quality analysis;random vector functional link network","Feature extraction;Noise measurement;Real-time systems;Harmonic analysis;Convolution;Computational modeling;Transient analysis","convolutional neural nets;deep learning (artificial intelligence);feature extraction;Fourier analysis;particle swarm optimisation;power engineering computing;power supply quality;random processes;supervised learning;unsupervised learning;variational techniques;vectors","PAVMD-RDCSAE-MRVFLN;PAVMD-RDCSAE-RMRVFLN;discriminative unsupervised feature data extraction;PQE recognition;variational mode decomposition;deep convolutional stack autoencoder;deep convoluted Fourier privileged data;unsupervised feature training;supervised robust multikernel random vector functional link network method;parameter-adaptive VMD algorithm;BLIMF;RDCSAE structure;deep convolutional neural network;band-limited intrinsic mode function;particle swarm optimization;power quality events recognition;robust multikernel RVFLN;process adaptive VMD data;PAVMD-RDCNN-RMRVFLN","","4","","32","IEEE","26 Jan 2021","","","IEEE","IEEE Journals"
"Skewed t-Distribution for Hyperspectral Anomaly Detection Based on Autoencoder","K. Kayabol; E. B. Aytekin; S. Arisoy; E. E. Kuruoglu","Electronics Engineering Department, Gebze Technical University, Kocaeli, Turkey; TUBITAK BILGEM Information Technologies Institute, Kocaeli, Turkey; Electronics Engineering Department, Gebze Technical University, Kocaeli, Turkey; ISTI, CNR, Pisa, Italy","IEEE Geoscience and Remote Sensing Letters","10 Jan 2022","2022","19","","1","5","We propose multivariate skewed  ${t}$ -distribution (MVSkt) for hyperspectral anomaly detection (AD). The proposed distribution model is able to increase the detection performance of autoencoder (AE)-based anomaly detectors. In the proposed method, the reconstruction error of a deep AE is modeled with a skewed  ${t}$ -distribution. The deep AE network is trained based on adversarial learning strategy by feeding its input with the hyperspectral data cubes. The parameters of the  ${t}$ -distribution model are estimated using variational Bayesian approach. We define an MVSkt-based detection rule for pixel-wise AD. We compare our proposed method with those based on the multivariate normal (MVN) distribution and the robust MVN variance–mean mixture distributions on real hyperspectral datasets. The experimental results show that the proposed approach outperforms other detectors in the benchmark.","1558-0571","","10.1109/LGRS.2021.3121876","Scientific and Technological Research Council of Turkey (TUBITAK)(grant numbers:118E295); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9583260","Anomaly detection (AD);autoencoder (AE);hyperspectral image (HSI);multivariate skewed t-distribution (MVSkt);variational Bayes","Hyperspectral imaging;Image reconstruction;Anomaly detection;Standards;Parameter estimation;Training;Probability density function","Bayes methods;deep learning (artificial intelligence);geophysical image processing;hyperspectral imaging;image reconstruction;mixture models;normal distribution;object detection;variational techniques","hyperspectral anomaly detection;multivariate skewed t-distribution;autoencoder-based anomaly detectors;deep AE network;hyperspectral data cubes;multivariate normal distribution;hyperspectral datasets;adversarial learning;MVN variance-mean mixture distributions;MVSkt;reconstruction error;variational Bayesian approach;MVSkt-based detection rule;pixel-wise AD","","1","","21","IEEE","21 Oct 2021","","","IEEE","IEEE Journals"
"Variational Open Set Recognition (VOSR)","L. Buquicchio; W. Gerych; A. Alajaji; K. Chandrasekaran; H. Mansoor; T. Hartvigsen; E. Rundensteiner; E. Agu",Worcester Polytechnic Institute; Worcester Polytechnic Institute; Worcester Polytechnic Institute; Worcester Polytechnic Institute; Worcester Polytechnic Institute; Worcester Polytechnic Institute; Worcester Polytechnic Institute; Worcester Polytechnic Institute,"2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","994","1001","Open set recognition models address the real-world scenario where classes of data unobserved during training are encountered in testing after deployment. Closed set classifiers wrongly attempt to classify instances from an unknown class as belonging to one of the known classes from the training set, which reduces the model’s accuracy. Ideally, these unknown instances should be recognized as such, while known instances should continue to be accurately classified. Unfortunately, state-of-the-art open set methods solve this problem by making restrictive assumptions on the variance and/or boundedness of the distributions of known classes. In this paper, we propose a novel method, Variational Open-Set Recognition (VOSR) that eliminates these assumptions. VOSR incorporates a closed set classifier, an unknown detector, and a novel Structured Gaussian Mixture Variational Autoencoder (SGM-VAE) that guarantees separable class distributions with known variances in its la-tent space. Further, by encouraging a large distance between class-specific distributions, VOSR increases the likelihood that instances from unknown classes lie in low-probability regions and thus are more readily identifiable. In rigorous evaluation, we demonstrate that VOSR outperforms state-of-the-art open set classifiers with up to a 14% F1 score increase in identifying instances from unknown classes in multiple image classification and human activity recognition datasets.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671727","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671727","deep learning;novelty detection;mixture models;semi-supervised learning;variational autoencoders;extreme value theory;open set recognition","Training;Conferences;Detectors;Big Data;Activity recognition;Data models;Testing","Gaussian processes;image classification;learning (artificial intelligence);pattern classification;probability","Variational Open Set Recognition;VOSR;recognition models;closed set classifier;unknown class;known classes;training set;unknown instances;known instances;state-of-the-art open set methods;Variational Open-Set Recognition;unknown detector;novel Structured Gaussian Mixture Variational Autoencoder;separable class distributions;known variances;class-specific distributions;state-of-the-art open set classifiers","","","","26","IEEE","13 Jan 2022","","","IEEE","IEEE Conferences"
"Text Generation with Syntax - Enhanced Variational Autoencoder","W. Yuan; L. Ding; K. Meng; G. Liu","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","8","Text generation is one of the essential yet challenging tasks in natural language processing. However, the input text alone is usually hard to provide enough information to generate the desired output. Previous work attempts to incorporate syntactic information into the generative models based on variational autoencoder(VAE). But these methods have difficulty in adequately modeling the tree structure of syntactic data. In this paper, we formulate the syntactic structure as a graph and introduce a syntax encoder based on graph neural network(GNN) to model the syntactic information of sentences. Based on the syntax encoder, we propose a novel syntax-enhanced variational autoencoder(SEVAE) with two variants. The variant SEVAE-m merges sentence information and syntactic information into one latent space to enrich the fine-grained syntactic information of latent representations. And the variant SEVAE-s with two separate latent spaces allows the sentence decoder to dynamically attend to semantic and syntactic information from two latent variables. Experiments on two benchmark datasets show that our methods achieve significant and consistent improvements compared with previous work.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533865","National Natural Science Foundation of China(grant numbers:61772337,U1736207); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533865","text generation;variational auto encoder;syntactic modeling;attention mechanism","Semantics;Neural networks;Syntactics;Benchmark testing;Natural language processing;Data models;Decoding","computational linguistics;graph theory;natural language processing;neural nets;text analysis","fine-grained syntactic information;text generation;natural language processing;generative models;syntactic data;syntactic structure;syntax encoder;variant SEVAE-m merges sentence information;syntax-enhanced variational autoencoder;GNN;graph neural network","","2","","37","","20 Sep 2021","","","IEEE","IEEE Conferences"
"Industrial Process Modeling and Fault Detection with Recurrent Kalman Variational Autoencoder","Z. Zhang; J. Zhu; Y. liu; Z. Ge","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; College of Control Science and Engineering, Zhejiang University, Hangzhou, China","2020 IEEE 9th Data Driven Control and Learning Systems Conference (DDCLS)","7 Dec 2020","2020","","","1370","1376","This article proposes the recurrent Kalman variational autoencoder, an end-to-end trainable framework for process modeling and fault detection. Based on the backbone of variational autoencoder, our research focuses on the dynamic and nonlinear properties that implied in the industrial process. For the dynamics describing, the Kalman filter is integrated to estimate the hidden state uncertainty due to process noise, and hence to identify the time-domain correlation in the hidden space. While for the nonlinear evolution in the hidden mapping, the dynamic parameter network is constructed for recurrent updating, so as to further improve the inference accuracy. Finally, for process monitoring, a fault detection panel is designed in the latent and residual domains generated by the deep model. Through the simulation of the industrial benchmark Tennessee Eastman Process, the superiority of the proposed method is evaluated and discussed.","","978-1-7281-5922-5","10.1109/DDCLS49620.2020.9275274","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9275274","Nonlinear industrial monitoring;Fault detection;Kalman filter;Variational inference;Recurrent","Kalman filters;Probabilistic logic;Uncertainty;Fault detection;Principal component analysis;Process monitoring;Estimation","encoding;fault diagnosis;Kalman filters;learning (artificial intelligence);time-domain analysis","industrial benchmark Tennessee Eastman process;fault detection panel;dynamic parameter network;hidden state uncertainty;Kalman filter;nonlinear properties;end-to-end trainable framework;recurrent Kalman variational autoencoder;industrial process modeling","","2","","10","","7 Dec 2020","","","IEEE","IEEE Conferences"
"Efficient Local Image Descriptors Learned With Autoencoders","N. Žižakić; A. Pižurica","Department of Telecommunications and Information Processing, TELIN–GAIM, Ghent University, Ghent, Belgium; Department of Telecommunications and Information Processing, TELIN–GAIM, Ghent University, Ghent, Belgium","IEEE Access","4 Jan 2022","2022","10","","221","235","Local image descriptors play a crucial role in many image processing tasks, such as object tracking, object recognition, panorama stitching, and image retrieval. In this paper, we focus on learning local image descriptors in an unsupervised way, using autoencoders and variational autoencoders. We perform a thorough comparative analysis of these two approaches along with an in-depth analysis of the most relevant hyperparameters to guide their optimal selection. In addition to this analysis, we give insights into the difficulties and the importance of selecting right evaluation techniques during the unsupervised learning of the local image descriptors. We explore the extent to which a simple perceptual metric during training can predict the performance on tasks such as patch matching, retrieval and verification. Finally, we propose an improvement to the encoder architecture that yields significant savings in memory complexity, especially in single-image tasks. As a proof of concept, we integrate our descriptor into an inpainting algorithm and illustrate its results when applied to the virtual restoration of master paintings. The source code required to reproduce the presented results has been made available as a repository on GitHub (https://github.com/nimpy/local-img-descr-ae).","2169-3536","","10.1109/ACCESS.2021.3138168","Flemish Government (AI Research Program); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9662311","Local image descriptor;autoencoder;variational autoencoder;inpainting;unsupervised deep learning","Encoding;Computer architecture;Benchmark testing;Training data;Deep learning;Object tracking;Neural networks;Unsupervised learning","feature extraction;image classification;image matching;image processing;image representation;image retrieval;image texture;learning (artificial intelligence);object recognition;object tracking;unsupervised learning","efficient local image descriptors;image processing tasks;object tracking;image retrieval;learning local image descriptors;variational autoencoders;comparative analysis;in-depth analysis;unsupervised learning;single-image tasks","","","","57","CCBY","23 Dec 2021","","","IEEE","IEEE Journals"
"High Dimensional Latent Space Variational AutoEncoders for Fake News Detection","S. Sadiq; N. Wagner; M. -L. Shyu; D. Feaster","Department of Electrical and Computer Engineering, University of Miami, Coral Gables, FL, USA; Department of Electrical and Computer Engineering, University of Miami, Coral Gables, FL, USA; Department of Electrical and Computer Engineering, University of Miami, Coral Gables, FL, USA; Department of Public Health Sciences, University of Miami - Miller School of Medicine, Miami, FL, USA","2019 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)","25 Apr 2019","2019","","","437","442","With the advent of social media and cell phones, news is now far more reaching and impactful than ever before. This comes with the exponential increase in fake news that blurs the lines of reality and holds the power to sway public opinion. To counter the impact of fake news, several research groups have developed novel algorithms that could fact check news as a human would do. Unfortunately, natural language processing (NLP) is a complicated task because of the underlying hidden meanings in human communication. In this paper, we propose a novel method that builds a latent representation of natural language to capture its underlying hidden meanings accurately and classify fake news. Our approach connects the high-level semantic concepts in the news content with their low-level deep representations so that the complex news text consisting of satire, sarcasm, and purposeful misleading content can be translated into quantifiable latent spaces. This allows us to achieve very high accuracy, surpassing the scores of all winners of the fake news challenge.","","978-1-7281-1198-8","10.1109/MIPR.2019.00088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8695321","Fake news;latent representation;VAE (Variational AutoEncoder);LSTM (Long Short Term Memory)","Vegetation;Decoding;Social networking (online);Data models;Google;Training","data mining;feature extraction;learning (artificial intelligence);natural language processing;social networking (online);text analysis","news content;complex news text;quantifiable latent spaces;fake news detection;social media;cell phones;natural language processing;high-level semantic concepts;high dimensional latent space variational autoencoders","","3","","32","","25 Apr 2019","","","IEEE","IEEE Conferences"
"The Character Generation in Handwriting Feature Extraction Using Variational AutoEncoder","T. Yamada; M. Hosoe; K. Kato; K. Yamamoto","Faculty of Engineering, Gifu University, Gifu, Japan; Gifu Prefectural Police Headquarters, Forensic SciLab Gifu PrefPolice H.Q., Gifu, Japan; Faculty of Engineering, Gifu University, Gifu, Japan; Faculty of Engineering, Gifu University, Gifu, Japan","2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)","29 Jan 2018","2017","01","","1019","1024","Handwriting identification is a method to identify an unknown writer by comparing a known writer's characters with an unknown writer's characters by using the homeostasis of handwriting in the characters. In handwriting identification, improving the accuracy is important in analyzing a large number of characters of the same class. However, a problem with the accuracy of handwriting identification occurs because of lack of characters of the same class. In order to solve this problem, we propose a method of extracting features of handwritten characters from a character class and generating characters of different character class based on the extracted features. It is difficult to extract handwriting features by scientific numerical analysis method, and to generate characters from extracted handwriting features. In this paper, we tried to construct a learning method using Deep Learning to generate a model of the handwriting feature extraction and the handwriting character data generative model. Using the existing neural network model, we tried to apply the generative model of the data of Japanese characters (Hiragana). Because existing models cannot capture complicated character features like Hiragana, we propose a modified method to improve character generation accuracy by adding a convolution model to the existing neural network model. Improvement of character generation accuracy by adding the convolution model was confirmed by using quantitative evaluation method of generated characters.","2379-2140","978-1-5386-3586-5","10.1109/ICDAR.2017.169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8270100","Variational AutoEncoder;Generative model;Character generation","Feature extraction;Data models;Neural networks;Convolution;Numerical models;Gallium nitride;Mathematical model","feature extraction;handwriting recognition;handwritten character recognition;learning (artificial intelligence);neural nets","handwriting feature extraction;handwriting identification;unknown writer;handwritten characters;scientific numerical analysis method;handwriting character data generative model;Japanese characters;complicated character features;character generation accuracy;convolution model;handwriting features;neural network model;character class;Variational AutoEncoder","","2","","13","","29 Jan 2018","","","IEEE","IEEE Conferences"
"Machine Learning With Variational AutoEncoder for Imbalanced Datasets in Intrusion Detection","Y. -D. Lin; Z. -Q. Liu; R. -H. Hwang; V. -L. Nguyen; P. -C. Lin; Y. -C. Lai","Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu City, Taiwan; Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu City, Taiwan; Department of Computer Science and Information Engineering, National Chung Cheng University, Chiayi County, Taiwan; Department of Information Technology, University of Information and Communication Technology, Thai Nguyen, Vietnam; Department of Computer Science and Information Engineering, National Chung Cheng University, Chiayi County, Taiwan; Department of Information Management, National Taiwan University of Science and Technology, Taipei City, Taiwan","IEEE Access","11 Feb 2022","2022","10","","15247","15260","As a result of the explosion of security attacks and the complexity of modern networks, machine learning (ML) has recently become the favored approach for intrusion detection systems (IDS). However, the ML approach usually faces three challenges: massive attack variants, imbalanced data issues, and appropriate data segmentation. Improper handling of the issues will significantly degrade ML performance, e.g., resulting in high false-negative and low recall rates. Despite many efforts have done in the literature, detecting security attacks in a complicated network environment with imperfect data collection is still an open issue. This work proposes a machine learning framework with a combination of a variational autoencoder and multilayer perceptron model to deal with imbalanced datasets and detect the explosion of attack variants on the Internet. The detection engine also includes an efficient range-based sequential search algorithm to address the segmentation challenge in data pre-processing from multiple sources (network packets, system/statistic logs) effectively. Our work is the first attempt to demonstrate the effect of using an appropriate combination of ML models for boosting IDS detection capability in a heterogeneous environment, where data collection imperfection is common. Experimental results on a public system log dataset (e.g., HDFS) show that our method gains approximately as much as 97% on F1 score and 98% on recall rate, a promising result compared to the same measurement of other solutions. Even better, we found that the proposed treatment of imbalanced datasets can improve up to 35% on the F1 score and 27% on recall rate. The testing results also indicate that our model can detect new attack variants.","2169-3536","","10.1109/ACCESS.2022.3149295","Ministry of Science and Technology (MOST) of Taiwan(grant numbers:110-2811-E-194-501-MY2,MOST 109-2221-E-194-025-MY2,108-2221-E-194-022-MY3,108-2221-E-194-019-MY3); Advanced Institute of Manufacturing with High-Tech Innovations (AIM-HI) through the Featured Areas Research Center Program within the framework of the Higher Education Sprout Project by the Ministry of Education (MOE) in Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9705580","Imbalanced dataset;machine learning;variational autoencoder;intrusion detection","Training;Data models;Intrusion detection;Machine learning;Soft sensors;Predictive models;Explosions","computer network security;data mining;image segmentation;learning (artificial intelligence);multilayer perceptrons;pattern classification","complicated network environment;imperfect data collection;machine learning framework;variational autoencoder;multilayer perceptron model;imbalanced datasets;detection engine;efficient range-based sequential search algorithm;data pre-processing;network packets;ML models;IDS detection capability;data collection imperfection;public system log dataset;recall rate;security attacks;intrusion detection systems;ML approach;massive attack variants;imbalanced data issues;appropriate data segmentation;ML performance;high false-negative recall rates;low recall rates","","1","","42","CCBY","7 Feb 2022","","","IEEE","IEEE Journals"
"Plausible 3D Face Wrinkle Generation Using Variational Autoencoders","Q. Deng; L. Ma; A. Jin; H. Bi; B. H. Le; Z. Deng","Department of Computer Science, University of Houston, Houston, TX, USA; Department of Computer Science, University of Houston, Houston, TX, USA; Department of Computer Science, University of Houston, Houston, TX, USA; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; SEED Lab, Search for Extraordinary Experience Division, Electronic Arts Inc., Ashburn, VA, USA; Department of Computer Science, University of Houston, Houston, TX, USA","IEEE Transactions on Visualization and Computer Graphics","29 Jul 2022","2022","28","9","3113","3125","Realistic 3D facial modeling and animation have been increasingly used in many graphics, animation, and virtual reality applications. However, generating realistic fine-scale wrinkles on 3D faces, in particular, on animated 3D faces, is still a challenging problem that is far away from being resolved. In this article we propose an end-to-end system to automatically augment coarse-scale 3D faces with synthesized fine-scale geometric wrinkles. By formulating the wrinkle generation problem as a supervised generation task, we implicitly model the continuous space of face wrinkles via a compact generative model, such that plausible face wrinkles can be generated through effective sampling and interpolation in the space. We also introduce a complete pipeline to transfer the synthesized wrinkles between faces with different shapes and topologies. Through many experiments, we demonstrate our method can robustly synthesize plausible fine-scale wrinkles on a variety of coarse-scale 3D faces with different shapes and expressions.","1941-0506","","10.1109/TVCG.2021.3051251","National Science Foundation(grant numbers:IIS-1524782,IIS-2005430); National Natural Science Foundation of China(grant numbers:62002345); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321747","Face modeling;wrinkle synthesis;deep generative models;variational autoencoders","Faces;Three-dimensional displays;Solid modeling;Shape;Computational modeling;Pipelines;Data models","computer animation;computer graphics;face recognition;image texture;solid modelling;statistical analysis;virtual reality","plausible 3D face wrinkle generation;variational autoencoders;realistic 3D facial modeling;animation;virtual reality applications;fine-scale wrinkles;end-to-end system;coarse-scale 3D;synthesized fine-scale geometric wrinkles;wrinkle generation problem;supervised generation task;compact generative model;plausible face wrinkles;synthesized wrinkles","","1","","55","IEEE","13 Jan 2021","","","IEEE","IEEE Journals"
"Driving Style-Based Conditional Variational Autoencoder for Prediction of Ego Vehicle Trajectory","D. Kim; H. Shon; N. Kweon; S. Choi; C. Yang; K. Huh","Department of Automotive Engineering, Hanyang University, Seoul, Republic of Korea; Department of Automotive Engineering (Automotive-Computer Convergence), Hanyang University, Seoul, Republic of Korea; Department of Automotive Electronic Control Engineering, Hanyang University, Seoul, Republic of Korea; Department of Automotive Engineering (Automotive-Computer Convergence), Hanyang University, Seoul, Republic of Korea; Department of Automotive Engineering, Hanyang University, Seoul, Republic of Korea; Department of Automotive Engineering, Hanyang University, Seoul, Republic of Korea","IEEE Access","31 Dec 2021","2021","9","","169348","169356","Trajectory prediction of the ego vehicle is essential for advanced driver assistance systems to function properly. By recognizing various driving styles and predicting trajectories reflecting them, the prediction performance is enhanced, and a personalized trajectory can be generated. Therefore, we propose to combine driving style recognition and trajectory prediction tasks using only in-vehicle CAN-bus sensor data for possible application to normal vehicles. The DeepConvLstm network was utilized for driving style recognition, and a generative-based model was used for trajectory prediction. The classified driving style was added as a condition to the network. In addition, the past trajectory of the ego vehicle is estimated and utilized as an additional input for performance improvement. The performance of the proposed method is analyzed in terms of the root mean squared error (RMSE) and mean absolute error (MAE) compared with the case wherein the driving style and the past trajectory are not conditioned or given, respectively. The results demonstrate the effectiveness of the proposed method.","2169-3536","","10.1109/ACCESS.2021.3138502","Ministry of Trade, Industry, and Energy (MOTIE), South Korea, through the Technology Innovation Program (Industrial Strategic Technology Development Program, Development of Test Procedure Standards for V2I Connected Automated Driving Systems)(grant numbers:20014460); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9663155","Driving style recognition;trajectory prediction;conditional variational autoencoder;CAN data;Hardware-in-the-Loop simulation","Trajectory;Feature extraction;Vehicles;Training;Global Positioning System;Data models;Task analysis","convolutional neural nets;deep learning (artificial intelligence);driver information systems;mean square error methods;pattern classification;recurrent neural nets;road vehicles","conditional variational autoencoder;ego vehicle trajectory;advanced driver assistance systems;personalized trajectory;driving style recognition;trajectory prediction tasks;in-vehicle CAN-bus sensor data;generative-based model;classified driving style;mean absolute error;root mean squared error;RMSE;DeepConvLstm network","","1","","20","CCBY","24 Dec 2021","","","IEEE","IEEE Journals"
"Zero-Shot User Intent Detection via Augmented Conditional Variational Autoencoders","F. Wang; J. Shen; D. Zha; L. Wang; J. Xiang","School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","2020 IEEE 3rd International Conference on Information Systems and Computer Aided Education (ICISCAE)","2 Nov 2020","2020","","","632","636","User intent detection plays a critical role in modern information retrieval and dialog question answering systems. It can provide intelligent retrieval results through understanding user query intent and serve as the semantic understanding in the human-machine conversation process. However, intent labeling is a time-consuming and labor-intensive work, and how to handle diverse and novel intentions is becoming an urgent and challenging task. In this paper, we propose a cvae-based architecture for the user intent detection which tries to make the latent vectors of training far away from the most similar misclassified intent labels in order to improve the detection accuracy. The cvae-based architecture includes two parts. Intent-AugCVAE extracts semantic features from utterance and is used to discriminate existing intents, while Intent-AugCVAE-ZSL transfers the learning ability of Intent-AugCVAE to discriminate emerging user intentions. Experimental results show that our method can not only discriminate existing intents, but also be able to discriminate emerging intents effectively when no labeled utterances exist.","","978-1-7281-8304-6","10.1109/ICISCAE51034.2020.9236881","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9236881","zero-shot intent detection;conditional variational autoencoder;augmented CVAE","Training;Visualization;Semantics;Feature extraction;Routing;Task analysis;Man-machine systems","convolutional neural nets;feature extraction;learning (artificial intelligence);question answering (information retrieval);text analysis","cvae-based architecture;Intent-AugCVAE extracts semantic features;existing intents;Intent-AugCVAE-ZSL transfers;emerging user intentions;zero-shot user Intent detection;augmented conditional variational autoencoders;modern information retrieval;dialog question answering systems;intelligent retrieval results;user query intent;semantic understanding;human-machine conversation process;intent labeling;similar misclassified intent labels;detection accuracy","","","","16","","2 Nov 2020","","","IEEE","IEEE Conferences"
"CNC Machining Quality Prediction Using Variational Autoencoder: A Novel Industrial 2 TB Dataset","A. Proteau; R. Zemouri; A. Tahan; M. Thomas; W. Bounouara; S. Agnard","Department of Mechanical Engineering, École de Technologie Supérieure, Montréal, Canada; CEDRIC Laboratory, Conservatoire National des Arts et Métiers (CNAM), Paris, France; Department of Mechanical Engineering, École de Technologie Supérieure, Montréal, Canada; Department of Mechanical Engineering, École de Technologie Supérieure, Montréal, Canada; Department of Mechanical Engineering, École de Technologie Supérieure, Montréal, Canada; APN Inc., Québec, Canada","2022 Prognostics and Health Management Conference (PHM-2022 London)","1 Jul 2022","2022","","","360","367","The purpose of this paper is to present and to describe a novel dataset acquired entirely in an industrial environment during multiple regular scheduled production runs. In the monitoring, prognostic and fault detection literature, researchers are often faced with work based on the same popular datasets; for instance, the milling dataset, the Pronostia Bearing Dataset, the IMS Bearing Dataset or the Turbofan Engine Degradation Simulation Dataset. On the one hand, these datasets are the results of either simulations or acquired in a laboratory under controlled environment. On the other hand, a real industrial context might not be adequately represented within these datasets due to less controlled parameters or increased complexity. Consequently, it becomes critical to have access to a way to test and validate research work on both experimental and industrial data. In that mindset, to accelerate the technological transfer to the industry and to ensure that it can quickly profit from the benefits that the monitoring, diagnostic and prognostic research area can provide them, a new dataset acquired at an industrial partner: a machining company located in Quebec City (Qc, Canada) is presented.","2166-5656","978-1-6654-7954-7","10.1109/PHM2022-London52454.2022.00069","Nature; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9808708","Dataset;Machining;GD&T;Prognostic;Variational Autoencoder","Industries;Geometry;Urban areas;Laboratories;Production;Milling;Complexity theory","computerised numerical control;condition monitoring;fault diagnosis;jet engines;machine bearings;milling;neural nets;production engineering computing;profitability;quality control;technology transfer","CNC machining quality prediction;variational autoencoder;fault detection literature;milling dataset;turbofan engine degradation simulation dataset;prognostic research area;IMS bearing dataset;Pronostia bearing dataset;technological transfer;profitability;condition monitoring;machining company;Quebec City;memory size 2.0 TByte","","","","30","IEEE","1 Jul 2022","","","IEEE","IEEE Conferences"
"NVSRN: A Neural Variational Scaling Reasoning Network for Initiative Response Generation","J. Chang; R. He; H. Xu; K. Han; L. Wang; X. Li; J. Dang","College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; AI Labs, Didi Chuxing, Beijing, China; AI Labs, Didi Chuxing, Beijing, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; AI Labs, Didi Chuxing, Beijing, China; Japan Advanced Institute of Science and Technology, Ishikawa, Japan","2019 IEEE International Conference on Data Mining (ICDM)","30 Jan 2020","2019","","","51","60","Open-domain multi-turn dialogue systems are booming in human-machine interactions, which encourage to chat actively and freely in an intelligent natural way. Previous generative conversational models usually employ a single and deterministic encoder-decoder framework to model the semantic consistency between the context and corresponding response. However, they neglect the various dialog patterns (we denote the regularity of topic shifting as dialog pattern) in the conversations, leading to uninformative, non-initiative yet plausible responses. Although the existing variational methods have improved the response diversity to some extent by introducing a global variability into the generative process, they fail to simulate the transfer between topics with directional information due to the weak interpretability of the Gaussian-distributed latent variables. In this paper, we propose a novel Neural Variational Scaling Reasoning Network (NVSRN) for initiative response generation. To this end, our approach has two core ingredients: neural dialog pattern reasoner (reasoner) and topic scaling mechanism. Specifically, inspired by the advantage of von Mises-Fisher (vMF) distribution modeling the directional data (e.g., the topic transfer state), we employ it as the latent space of the reasoner to explore the regularity of topic shifting, which is then used to reason the topic of response. Based on this, a topic scaling mechanism is designed to control the transfer degree of topic in the response generator. The experimental results on two large dialog datasets demonstrate that the proposed model outperforms state-of-the-art baselines. The human evaluation shows the proposed model can produce more informative and initiative responses actively.","2374-8486","978-1-7281-4604-1","10.1109/ICDM.2019.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8970864","dialogue generation, topic shifting, von Mises Fisher distribution, conditional variational autoencoder, topic scaling mechanism","","decoding;encoding;inference mechanisms;interactive systems;natural language interfaces;neural nets;pattern clustering;variational techniques","NVSRN;initiative response generation;open-domain multiturn dialogue systems;human-machine interactions;single encoder-decoder framework;deterministic encoder-decoder framework;corresponding response;plausible responses;variational methods;response diversity;generative process;Gaussian-distributed latent variables;neural dialog pattern reasoner;topic scaling mechanism;von Mises-Fisher distribution;topic transfer state;response generator;dialog datasets;initiative responses;neural variational scaling reasoning network;generative conversational models","","1","","44","","30 Jan 2020","","","IEEE","IEEE Conferences"
"Generating Adversarial Samples on Multivariate Time Series using Variational Autoencoders","S. Harford; F. Karim; H. Darabi","Department of Mechanical and Industrial Engineering, University of Illinois at Chicago, Chicago, IL, USA; Department of Mechanical and Industrial Engineering, University of Illinois at Chicago, Chicago, IL, USA; Department of Mechanical and Industrial Engineering, University of Illinois at Chicago, Chicago, IL, USA","IEEE/CAA Journal of Automatica Sinica","9 Jul 2021","2021","8","9","1523","1538","Classification models for multivariate time series have drawn the interest of many researchers to the field with the objective of developing accurate and efficient models. However, limited research has been conducted on generating adversarial samples for multivariate time series classification models. Adversarial samples could become a security concern in systems with complex sets of sensors. This study proposes extending the existing gradient adversarial transformation network (GATN) in combination with adversarial autoencoders to attack multivariate time series classification models. The proposed model attacks classification models by utilizing a distilled model to imitate the output of the multivariate time series classification model. In addition, the adversarial generator function is replaced with a variational autoencoder to enhance the adversarial samples. The developed methodology is tested on two multivariate time series classification models: 1-nearest neighbor dynamic time warping (1-NN DTW) and a fully convolutional network (FCN). This study utilizes 30 multivariate time series benchmarks provided by the University of East Anglia (UEA) and University of California Riverside (UCR). The use of adversarial autoencoders shows an increase in the fraction of successful adversaries generated on multivariate time series. To the best of our knowledge, this is the first study to explore adversarial attacks on multivariate time series. Additionally, we recommend future research utilizing the generated latent space from the variational autoencoders.","2329-9274","","10.1109/JAS.2021.1004108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9479867","Adversarial machine learning;deep learning;multivariate time series;perturbation methods","Time series analysis;Benchmark testing;Data models;Sensor systems;Generators;Sensors;Security","pattern classification;set theory;time series","variational autoencoder;generating adversarial samples;multivariate time series classification model;adversarial autoencoders;model attacks classification models;gradient adversarial transformation network;GATN;1-nearest neighbor dynamic time warping;1-NN DTW;University of East Anglia;UEA;University of California Riverside;UCR;fully convolutional network;FCN","","5","","67","","9 Jul 2021","","","IEEE","IEEE Journals"
"Generative Data Augmentation for Learning-based Electrical Impedance Tomography via Variational Autoencoder","Y. Zhan; R. Guan; S. Ren; F. Dong","Tianjin Key Laboratory of Process Measurement and Control, School of Electrical and Information Engineering, Tianjin University, Tianjin, China; Tianjin Key Laboratory of Process Measurement and Control, School of Electrical and Information Engineering, Tianjin University, Tianjin, China; Tianjin Key Laboratory of Process Measurement and Control, School of Electrical and Information Engineering, Tianjin University, Tianjin, China; Tianjin Key Laboratory of Process Measurement and Control, School of Electrical and Information Engineering, Tianjin University, Tianjin, China","2021 IEEE International Instrumentation and Measurement Technology Conference (I2MTC)","29 Jun 2021","2021","","","1","5","Electrical Impedance Tomography (EIT) owns lots of potential industrial and biomedical applications due to its high temporal resolution and non-intrusive advantages. To improve the spatial resolution of EIT, a neural network-based image reconstruction method is proposed. Compared with the traditional neural network-based image reconstruction methods, the proposed method is constructed by the variational auto-encoder. To improve the generalization ability of the proposed network, a data generation strategy is proposed. Artificial conductivity images can be automatically generated following the same manifold of the preset image set. Numerical results proved that the proposed generation model can generate a desirable dataset for significantly improving the accuracy and generalization of the neural network.","2642-2077","978-1-7281-9539-1","10.1109/I2MTC50364.2021.9459861","National Natural Science Foundation of China(grant numbers:61971304,51976137); Natural Science Foundation of Tianjin(grant numbers:19JCZDJC38900); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9459861","Electrical impedance tomography;variational auto-encoder;data generation;neural network;image reconstruction","Training;Electrical impedance tomography;Shape;Stability analysis;Numerical models;Spatial resolution;Task analysis","electric impedance imaging;image reconstruction;learning (artificial intelligence);medical image processing;neural nets","nonintrusive advantages;spatial resolution;EIT;neural network-based image reconstruction method;traditional neural network-based image reconstruction methods;variational auto-encoder;data generation strategy;artificial conductivity images;preset image;generation model;generative data augmentation;learning-based electrical Impedance Tomography;variational autoencoder;potential industrial applications;biomedical applications;high temporal resolution","","1","","19","","29 Jun 2021","","","IEEE","IEEE Conferences"
"Hybrid Quantum Variational Autoencoders for Representation Learning","P. Rivas; L. Zhao; J. Orduz","Dept. of Computer Science, School of Eng. and Computer Science, Baylor University; Marketing Department, St. Ambrose University; Dept. of Computer Science, School of Eng. and Computer Science, Baylor University","2021 International Conference on Computational Science and Computational Intelligence (CSCI)","22 Jun 2022","2021","","","52","57","Representation learning is a standard area that has seen many improvements based on machine learning advances. Quantum machine learning advances are now spreading across different application areas such as representation learning. This paper introduces a novel hybrid quantum machine learning approach to representation learning by using a quantum variational circuit that is trainable with traditional gradient descent techniques. We use marketing data to showcase the learning potential of our model.","","978-1-6654-5841-2","10.1109/CSCI54926.2021.00085","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9799154","quantum machine learning;marketing;quantum variational circuits","Representation learning;Social networking (online);Scientific computing;Feature extraction;Hybrid power systems;Data models;Integrated circuit modeling","gradient methods;learning (artificial intelligence);marketing;neural nets;quantum computing","hybrid quantum variational autoencoders;representation learning;quantum machine learning advances;quantum variational circuit;hybrid quantum machine learning approach;traditional gradient descent technique;marketing data","","","","30","IEEE","22 Jun 2022","","","IEEE","IEEE Conferences"
"Hierarchical Variational Autoencoders For Visual Counterfactuals","N. Vercheval; A. Pižurica","Department of Electronics and Information Systems, Clifford Research Group, Faculty of Engineering and Architecture, Ghent University, Belgium; Department of Telecommunications and Information Processing, TELIN-GAIM, Faculty of Engineering and Architecture, Ghent University, Belgium","2021 IEEE International Conference on Image Processing (ICIP)","23 Aug 2021","2021","","","2513","2517","Conditional Variational Auto Encoders (VAE) are gathering significant attention as an Explainable Artificial Intelligence (XAI) tool. The codes in the latent space provide a theoretically sound way to produce counterfactuals, i.e. alterations resulting from an intervention on a targeted semantic feature. To be applied on real images more complex models are needed, such as Hierarchical CVAE. This comes with a challenge as the naive conditioning is no longer effective. In this paper we show how relaxing the effect of the posterior leads to successful counterfactuals and we introduce VAEX1 an Hierarchical VAE designed for this approach that can visually audit a classifier in applications.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506780","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506780","Hierarchical Variational Auto Encoders;XAI;Counterfactuals","Visualization;Image processing;Conferences;Semantics;Tools;Artificial intelligence;Stress","Bayes methods;image coding;learning (artificial intelligence)","Hierarchical VAE;Hierarchical Variational autoencoders;visual counterfactuals;Conditional Variational Auto Encoders;Explainable Artificial Intelligence tool;XAI;latent space;targeted semantic feature;Hierarchical CVAE","","","","34","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"Object Tracking of Aerial Imaging Device Image Using Variational Autoencoder and External Memory","K. Park; B. Kim; D. Kim; S. -H. Kim; S. -J. Kim; S. Jeong","Korea Electronics Technology Institute, Jeonju-si, Republic of Korea; Korea Electronics Technology Institute, Jeonju-si, Republic of Korea; Korea Electronics Technology Institute, Jeonju-si, Republic of Korea; Korea Electronics Technology Institute, Jeonju-si, Republic of Korea; Korea Electronics Technology Institute, Jeonju-si, Republic of Korea; Korea Electronics Technology Institute, Jeonju-si, Republic of Korea","2022 Thirteenth International Conference on Ubiquitous and Future Networks (ICUFN)","20 Jul 2022","2022","","","473","478","Object tracking is a fundamental problem in the field of computer vision. The object tracking methods proposed so far can be divided into a ‘discriminative correlation filter’ and a ‘deep learning’ based methods with a complex structure and a lot of computation. In this paper, we propose an algorithm for tracking objects with a simple structure while maintaining tracking performance using a convolutional variational auto-encoder, external memory, and a Siamese network. As a result of an experiment with an RT (real-time) data set to measure real-time, the result was a precision of 0.546 and a success rate of 0.527.","2165-8536","978-1-6654-8550-0","10.1109/ICUFN55119.2022.9829672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9829672","deep learning;object tracking;variational auto-encoder;external memory;Siamese network","Performance evaluation;Computer vision;Correlation;Imaging;Filtering algorithms;Real-time systems;Object tracking","computer vision;feature extraction;filtering theory;image classification;image representation;learning (artificial intelligence);object detection;object tracking;tracking","object tracking;aerial imaging device image;variational autoencoder;external memory;fundamental problem;computer vision;discriminative correlation filter;complex structure;tracking performance;convolutional variational auto-encoder","","","","12","IEEE","20 Jul 2022","","","IEEE","IEEE Conferences"
"Amortized Mixture Prior for Variational Sequence Generation","J. -T. Chien; C. -J. Tsai","Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","6","Variational autoencoder (VAE) is a popular latent variable model for data generation. However, in natural language applications, VAE suffers from the posterior collapse in optimization procedure where the model posterior likely collapses to a standard Gaussian prior which disregards latent semantics from sequence data. The recurrent decoder accordingly generates du-plicate or noninformative sequence data. To tackle this issue, this paper adopts the Gaussian mixture prior for latent variable, and simultaneously fulfills the amortized regularization in encoder and skip connection in decoder. The noise robust prior, learned from the amortized encoder, becomes semantically meaningful. The prediction of sequence samples, due to skip connection, becomes contextually precise at each time. The amortized mixture prior (AMP) is then formulated in construction of variational recurrent autoencoder (VRAE) for sequence generation. Experiments on different tasks show that AMP-VRAE can avoid the posterior collapse, learn the meaningful latent features and improve the inference and generation for semantic representation.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9206667","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206667","Sequence generation;recurrent neural network;variational autoencoder;language model","Decoding;Atmospheric modeling;Computational modeling;Data models;Standards;Semantics;Gold","data analysis;Gaussian processes;learning (artificial intelligence);mixture models;natural language processing;optimisation;recurrent neural nets","variational sequence generation;VAE;data generation;natural language applications;optimization procedure;latent semantics;recurrent decoder;noninformative sequence data;Gaussian mixture;sequence samples;variational recurrent autoencoder;latent features;semantic representation;AMP-VRAE","","3","","50","","28 Sep 2020","","","IEEE","IEEE Conferences"
"Factorized Variational Autoencoders for Modeling Audience Reactions to Movies","Z. Deng; R. Navarathna; P. Carr; S. Mandt; Y. Yue; I. Matthews; G. Mori",Simon Fraser University; Disney Research; Disney Research; Disney Research; Caltech; Disney Research; Simon Fraser University,"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","9 Nov 2017","2017","","","6014","6023","Matrix and tensor factorization methods are often used for finding underlying low-dimensional patterns from noisy data. In this paper, we study non-linear tensor factorization methods based on deep variational autoencoders. Our approach is well-suited for settings where the relationship between the latent representation to be learned and the raw data representation is highly complex. We apply our approach to a large dataset of facial expressions of movie-watching audiences (over 16 million faces). Our experiments show that compared to conventional linear factorization methods, our method achieves better reconstruction of the data, and further discovers interpretable latent factors.","1063-6919","978-1-5386-0457-1","10.1109/CVPR.2017.637","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8100120","","Tensile stress;Motion pictures;Data models;Decoding;Machine learning;Probabilistic logic;Neural networks","face recognition;image coding;image representation;learning (artificial intelligence);matrix decomposition;tensors","movie-watching;linear factorization;audience reaction modeling;movies;factorized variational autoencoders;raw data representation;deep variational autoencoders","","14","","54","","9 Nov 2017","","","IEEE","IEEE Conferences"
"Interpretable Variational Autoencoders for Cognitive Models","M. Curi; G. A. Converse; J. Hajewski; S. Oliveira","Dept. of Applied Mathematics and Statistics, University of São Paulo, São Carlos, Brazil; Dept. of Mathematics, The University of Iowa, Iowa City, U.S.A.; Dept. of Computer Science, The University of Iowa, Iowa City, U.S.A.; Dept. of Computer Science, The University of Iowa, Iowa City, U.S.A.","2019 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2019","2019","","","1","8","One of the most used methodologies in the field of education assessment is Item Response Theory (IRT). In this work, we propose the use of a novel Variational Autoencoder (VAE) architecture for a multidimensional IRT model. Our approach combines the advantages of the IRT model while allowing us to model high latent trait dimensions, previously unattainable in prior work. Additionally, it has the advantage of interpretability in the domain of educational assessment.Our experiments show that, given enough data, the new model is competitive with the state-of-the-art methods with respect to predictive power and is much faster in runtime performance. In our experiments, we achieve competitive results on a sample size 20× larger in a runtime that is 40× faster than the state-of-the- art model.","2161-4407","978-1-7281-1985-4","10.1109/IJCNN.2019.8852333","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852333","","Biological system modeling;Computational modeling;Neural networks;Education;Data models;Decoding;Urban areas","Bayes methods;maximum likelihood estimation;principal component analysis;psychology","item response theory;variational autoencoder architecture;high latent trait dimensions;interpretable variational autoencoders;educational assessment;multidimensional IRT model;education assessment;cognitive models","","9","","27","","30 Sep 2019","","","IEEE","IEEE Conferences"
"A Manifold Constrained Multi-Head Self-Attention Variational Autoencoder Method for Hyperspectral Anomaly Detection","H. Jiang","Xidian University, Xi'an, China","2021 International Conference on Electronic Information Technology and Smart Agriculture (ICEITSA)","16 Feb 2022","2021","","","11","17","Hyperspectral anomaly detection is a very important task in the field of remote sensing. Most of the VAE-based methods for hyperspectral anomaly detection ignores the structural characteristics of the hyperspectral data and fails to effectively model the global dependency in the data. Based on the above problems, this paper proposes a manifold constrained multi-head self-attention variational autoencoder (MMS-VAE) method for hyperspectral anomaly detection. First, the manifold learning method is utilized to learn the embedded manifold, and the learned embedding manifold is used to constrain the VAE to learn the latent feature representation to maintain the internal structure of the hyperspectral data. Secondly, the multi-head self-attention mechanism is introduced to learn context-related information in different subspaces, so as to automatically focus on abnormal areas. Finally, the global reconstruction error of the multi-head self-attention network and the local reconstruction error from the latent feature space are considered at the same time to determine whether each pixel is abnormal. The effectiveness of the algorithm proposed in this paper is verified on two different real datasets. The experimental results prove the superiority of the proposed MMS-VAE method.","","978-1-6654-1300-8","10.1109/ICEITSA54226.2021.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9707316","Hyperspectral Anomaly Detection;Manifold Learning;Multi-Head Self-Attention","Manifolds;Focusing;Feature extraction;Data models;Manifold learning;Task analysis;Information technology","geophysical image processing;hyperspectral imaging;learning (artificial intelligence);neural nets;remote sensing","manifold learning;learned embedding manifold;MMS-VAE method;hyperspectral anomaly detection;VAE-based methods;variational autoencoder;manifold constrained multihead self-attention variational autoencoder;latent feature representation;multihead self-attention network;local reconstruction error","","1","","37","IEEE","16 Feb 2022","","","IEEE","IEEE Conferences"
"Improving Synthesizer Programming From Variational Autoencoders Latent Space","G. L. Vaillant; T. Dutoit; S. Dekeyser","Numediart Institute University of Mons, Mons, Belgium; Numediart Institute University of Mons, Mons, Belgium; ISIB HE2B, Brussels, Belgium","2021 24th International Conference on Digital Audio Effects (DAFx)","11 May 2022","2021","","","276","283","Deep neural networks have been recently applied to the task of automatic synthesizer programming, i.e., finding optimal values of sound synthesis parameters in order to reproduce a given input sound. This paper focuses on generative models, which can infer parameters as well as generate new sets of parameters or perform smooth morphing effects between sounds. We introduce new models to ensure scalability and to increase performance by using heterogeneous representations of parameters as numerical and categorical random variables. Moreover, a spectral variational autoencoder architecture with multi-channel input is proposed in order to improve inference of parameters related to the pitch and intensity of input sounds. Model performance was evaluated according to several criteria such as parameters estimation error and audio reconstruction accuracy. Training and evaluation were performed using a 30k presets dataset which is published with this paper. They demonstrate significant improvements in terms of parameter inference and audio accuracy and show that presented models can be used with subsets or full sets of synthesizer parameters.","2413-6689","978-3-200-08378-3","10.23919/DAFx51585.2021.9768218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9768218","","Training;Codes;Synthesizers;Neural networks;Computer architecture;Software;Numerical models","acoustic signal processing;audio signal processing;deep learning (artificial intelligence);parameter estimation","spectral variational autoencoder architecture;multichannel input;input sounds;parameters estimation error;audio reconstruction accuracy;parameter inference;synthesizer parameters;variational autoencoders latent space;deep neural networks;automatic synthesizer programming;sound synthesis parameters;generative models;smooth morphing effects;heterogeneous representations;numerical variables;categorical random variables","","1","","23","","11 May 2022","","","IEEE","IEEE Conferences"
"Combined Generation of Electrocardiogram and Cardiac Anatomy Models Using Multi-Modal Variational Autoencoders","M. Beetz; A. Banerjee; Y. Sang; V. Grau","Department of Engineering Science, Institute of Biomedical Engineering, University of Oxford, UK; Radcliffe Department of Medicine, Division of Cardiovascular Medicine, University of Oxford, UK; Department of Engineering Science, Institute of Biomedical Engineering, University of Oxford, UK; Department of Engineering Science, Institute of Biomedical Engineering, University of Oxford, UK","2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)","26 Apr 2022","2022","","","1","4","Understanding population-wide variability of the human heart is crucial to detect abnormalities and improve the assessment of both cardiac anatomy and function. While many computational modeling approaches have been developed to capture this variability separately for either cardiac anatomy or physiology, their complex interconnections have rarely been explored together. In this work, we propose a novel multi-modal variational autoencoder (VAE) capable of processing combined physiology and bitemporal anatomy information in the form of electrocardiograms (ECG) and 3D biventricular point clouds. Our method achieves high reconstruction accuracy on a UK Biobank dataset with Chamfer distances between predicted and input anatomies below the underlying image resolution and the ECG reconstructions outperforming a state-of-the-art benchmark approach specialized in ECG generation. We also evaluate its generative ability and find comparable populations of generated and gold standard anatomies, ECGs, and combined anatomy-ECG data in terms of common clinical metrics and maximum mean discrepancies.","1945-8452","978-1-6654-2923-8","10.1109/ISBI52829.2022.9761590","Heart Foundation; European Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761590","Multi-Modal VAE;3D Cardiac Anatomy Generation;ECG Synthesis;Combined Anatomy and Electrophysiology Modeling;Geometric Deep Learning","Point cloud compression;Measurement;Three-dimensional displays;Biological system modeling;Sociology;Electrocardiography;Physiology","cardiology;electrocardiography;image reconstruction;image resolution;medical computing;medical image processing;medical signal processing","gold standard anatomies;combined anatomy-ECG data;cardiac anatomy models;multimodal variational autoencoders;understanding population-wide variability;human heart;computational modeling approaches;complex interconnections;novel multimodal variational autoencoder;combined physiology;bitemporal anatomy information;electrocardiograms;3D biventricular point clouds;high reconstruction accuracy;UK Biobank dataset;input anatomies;underlying image resolution;ECG reconstructions;state-of-the-art benchmark approach;ECG generation;generative ability;comparable populations;generated standard anatomies","","","","10","IEEE","26 Apr 2022","","","IEEE","IEEE Conferences"
"Disentangled Representation of Longitudinal Β-Amyloid for AD Via Sequential Graph Variational Autoencoder with Supervision","F. Yang; G. Wu; W. Hwa Kim","University of Texas at Arlington, Arlington, USA; University of North Carolina, Chapel Hill, Chapel Hill, USA; Pohang University of Science and Technology, Pohang, South Korea","2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)","26 Apr 2022","2022","","","1","5","The emergence of Positron Emission Tomography (PET) imaging allows us to quantify the burden of amyloid plaques in-vivo, which is one of the hallmarks of Alzheimer’s disease (AD). However, the invasive exposure to radiation and high imaging cost significantly restrict the application of PET in characterizing the evolution of pathology burden which often requires longitudinal PET image sequences. In this regard, we propose a proof-of-concept solution to generate the complete trajectory of pathological events throughout the brain based on very limited number of PET scans. We present a novel variational autoencoder model to learn a latent population-level representation of neurodegeneration process based on the longitudinal β-amyloid measurements at each brain region and longitudinal diagnostic stages. As the propagation of pathological burdens follow the topology of brain connectome, we further cast our neural network into a supervised sequential graph VAE, where we use the brain network to guide the representation learning. Experiments show that the disentangled representation can capture disease-related dynamics of amyloid and forecast the level of amyloid depositions at future time points.","1945-8452","978-1-6654-2923-8","10.1109/ISBI52829.2022.9761588","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761588","","Representation learning;Pathology;Costs;Network topology;Trajectory;Topology;Image sequences","brain;diseases;image sequences;learning (artificial intelligence);medical image processing;molecular biophysics;neurophysiology;positron emission tomography","disentangled representation;longitudinal b-amyloid;sequential graph variational autoencoder;positron emission tomography imaging;amyloid plaques in-vivo;Alzheimer's disease;invasive exposure;imaging cost;pathology burden;longitudinal PET image sequences;proof-of-concept solution;complete trajectory;pathological events;PET scans;variational autoencoder model;latent population-level representation;neurodegeneration process;longitudinal β-amyloid measurements;brain region;longitudinal diagnostic stages;pathological burdens;brain connectome;supervised sequential graph VAE;brain network;representation learning;disease-related dynamics;amyloid depositions","","","","29","IEEE","26 Apr 2022","","","IEEE","IEEE Conferences"
"Conditional Deep Hierarchical Variational Autoencoder for Voice Conversion","K. Akuzawa; K. Onishi; K. Takiguchi; K. Mametani; K. Mori","University of Tokyo, Tokyo, Japan; The University of Electro-Communications, Tokyo, Japan; DeNA Co., Ltd., Tokyo, Japan; DeNA Co., Ltd., Tokyo, Japan; DeNA Co., Ltd., Tokyo, Japan","2021 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","3 Feb 2022","2021","","","808","813","Variational autoencoder-based voice conversion (VAE-VC) has the advantage of requiring only pairs of speeches and speaker labels for training. Unlike the majority of the research in VAE-VC which focuses on utilizing auxiliary losses or discretizing latent variables, this paper investigates how an increasing model expressiveness has benefits and impacts on the VAE-VC. Specifically, we first analyze VAE-VC from a rate-distortion perspective, and point out that model expressiveness is significant for VAE-VC because rate and distortion reflect similarity and naturalness of converted speeches. Based on the analysis, we propose a novel V C method using a deep hierarchical VAE, which has high model expressiveness as well as having fast conversion speed thanks to its non-autoregressive decoder. Also, our analysis reveals another problem that similarity can be degraded when the latent variable of VAEs has redundant infor-mation. We address the problem by controlling the information contained in the latent variable using $\beta$ - VAE objective. In the experiment using VCTK corpus, the proposed method achieved mean opinion scores higher than 3.5 on both naturalness and similarity in inter-gender settings, which are higher than the scores of existing auto encoder-based VC methods.","2640-0103","978-988-14768-9-0","","JSPS KAKENHI(grant numbers:JP20J11448); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9689369","","Training;Analytical models;Rate-distortion;Rate distortion theory;Information processing;Distortion;Decoding","deep learning (artificial intelligence);speaker recognition;speech coding","conditional deep hierarchical variational autoencoder;variational autoencoder-based voice conversion;VAE-VC;auxiliary losses;latent variables;deep hierarchical VAE;VAE objective;auto encoder-based VC methods","","","","37","","3 Feb 2022","","","IEEE","IEEE Conferences"
"Estimating TOA Reliability With Variational Autoencoders","M. Stahlke; S. Kram; F. Ott; T. Feigl; C. Mutschler","Fraunhofer Institute for Integrated Circuits IIS, Nuremberg, Germany; Institute of Information Technology (Communication Electronics), Friedrich-Alexander-University Erlangen-Nürnberg (FAU), Erlangen, Germany; Fraunhofer Institute for Integrated Circuits IIS, Nuremberg, Germany; Programming Systems Group, Friedrich-Alexander-University Erlangen-Nürnberg (FAU), Erlangen, Germany; Fraunhofer Institute for Integrated Circuits IIS, Nuremberg, Germany","IEEE Sensors Journal","14 Mar 2022","2022","22","6","5133","5140","Radio frequency (RF)-based localization yields centimeter-accurate positions under mild propagation conditions. However, propagation conditions predominant in indoor environments (e.g. industrial production) are often challenging as signal blockage, diffraction and dense multipath lead to errors in the time of flight (TOF) estimation and hence to a degraded localization accuracy. A major topic in high-precision RF-based localization is the identification of such anomalous signals that negatively affect the localization performance, and to mitigate the errors introduced by them. As such signal and error characteristics depend on the environment, data-driven approaches have shown to be promising. However, there is a trade-off to a bad generalization and a need for an extensive and time-consuming recording of training data associated with it. We propose to use generative deep learning models for out-of-distribution detection based on channel impulse responses (CIRs). We use a Variational Autoencoder (VAE) to predict an anomaly score for the channel of a TOF-based Ultra-wideband (UWB) system. Our experiments show that a VAE trained only on line-of-sight (LOS) training data generalizes well to new environments and detects non-line-of-sight CIRs with an accuracy of 85%. We also show that integrating our anomaly score into a TOF-based extended Kalman filter (EKF) improves tracking performance by over 25%.","1558-1748","","10.1109/JSEN.2021.3101933","Bavarian Ministry of Economic Affairs, Infrastructure, Energy and Technology as part of the Bavarian Projects Leistungszentrum Elektroniksysteme (LZE) and the Center for Analytics-Data-Applications (ADA—Center) within the Framework of “BAYERN DIGITAL II.”; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9503384","NLOS identification;NLOS mitigation;channel quality estimation;CIR;UWB;deep learning;VAE","Feature extraction;Location awareness;Sensors;Reliability;Training;Support vector machines;Receivers","distance measurement;indoor radio;Kalman filters;learning (artificial intelligence);least squares approximations;neural nets;nonlinear filters;telecommunication computing;time-of-arrival estimation;transient response;ultra wideband communication","bad generalization;extensive time-consuming recording;generative deep learning models;channel impulse responses;Variational Autoencoder;anomaly score;TOF-based Ultra-wideband system;line-of-sight training data;TOA reliability;Variational autoencoders;radio frequency-based localization yields centimeter;mild propagation conditions;indoor environments;signal blockage;dense multipath lead;flight estimation;degraded localization accuracy;high-precision RF-based localization;anomalous signals;localization performance;error characteristics;data-driven approaches;detects nonline-of-sight CIR","","","","44","CCBY","2 Aug 2021","","","IEEE","IEEE Journals"
"A novel partial discharge pattern recognition for GIS with unbalanced sample based on conditional variational autoencoder","Q. Jing; J. Yan; Y. Wang","State Key Laboratory of Electrical Insulation and Power Equipment, Xi'an Jiaotong University, Xi'an, China; State Key Laboratory of Electrical Insulation and Power Equipment, Xi'an Jiaotong University, Xi'an, China; State Key Laboratory of Electrical Insulation and Power Equipment, Xi'an Jiaotong University, Xi'an, China","18th International Conference on AC and DC Power Transmission (ACDC 2022)","29 Aug 2022","2022","2022","","1314","1319","Deep learning has been widely used in gas insulated switchgear (GIS) partial discharge (PD) pattern recognition with its powerful ability to automatically extract features. As a typical data-driven model, the diagnostic performance of deep learning methods will decrease with the reduction of the training sample size, resulting in lower recognition rates for minority class samples. In actual situation, the probability of failure of various insulation defects in GIS is not the same, so that the samples of various types of defects obtained in practical applications cannot maintain a balanced distribution. To solve the problem of class imbalance among training samples, this paper proposes an improved variational autoencoder (VAE) to augment the minority class fault samples. The PD signal is first converted into a time-spectrogram with high time-frequency resolution by S transform. Then use conditional AE to perform directed augmentation on unbalanced class samples. Finally, the obtained balanced data set is input into convolutional neural network to complete the fault diagnosis of PD. Experiments show that the proposed method achieves excellent recognition results under various unbalanced conditions, indicating that it has strong tolerance and high generalization ability for unbalanced samples.","","978-1-83953-761-5","10.1049/icp.2022.1405","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9868586","","","convolutional neural nets;deep learning (artificial intelligence);feature extraction;gas insulated switchgear;partial discharges;power engineering computing;transforms","conditional variational autoencoder;gas insulated switchgear partial discharge pattern recognition;GIS;data-driven model;diagnostic performance;deep learning methods;insulation defects;class imbalance;improved variational autoencoder;minority class fault samples;PD signal;high time-frequency resolution;unbalanced class samples;unbalanced conditions;partial discharge pattern recognition","","","","","","29 Aug 2022","","","IET","IET Conferences"
"Hyperspectral Anomaly Detection with Multivariate Skewed t Background Model","K. Kayabol; E. B. Aytekin; S. Arisoy; E. E. Kuruoğlu","Elektronik Mühendisliği Bölümü, Gebze Teknik Üniversitesi, Kocaeli, Türkiye; BİLGEM, TÜBİTAK, Kocaeli, Türkiye; Elektronik Mühendisliği Bölümü, Gebze Teknik Üniversitesi, Kocaeli, Türkiye; Data Sci. and Info. Tech. Cen., TBSI, Shenzhen, China","2022 30th Signal Processing and Communications Applications Conference (SIU)","29 Aug 2022","2022","","","1","4","In this paper, autoencoder-based multivariate skewed t-distribution is proposed for hyperspectral anomaly detection. In the proposed method, the reconstruction error between the hyperspectral images reconstructed by the autoencoder and the original hyperspectral images is calculated and is modeled with a multivariate skewed t-distribution. The parameters of the distribution are estimated using the variational Bayes approach, and a distribution-based rule is determined for anomaly detection. The experimental results show that the proposed method has better performance when compared to the RX, LRASR and DAEAD anomaly detection methods.","2165-0608","978-1-6654-5092-8","10.1109/SIU55565.2022.9864954","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9864954","multivariate skewed t-distribution;anomaly detection;hyperspectral image;autoencoder;variational Bayes approach","Signal processing;Anomaly detection;Image reconstruction;Hyperspectral imaging","Bayes methods;geophysical image processing;hyperspectral imaging;image reconstruction;neural nets;object detection","hyperspectral anomaly detection;autoencoder-based multivariate skewed;reconstruction error;hyperspectral images;distribution-based rule;RX;LRASR;DAEAD;variational Bayes approach;multivariate skewed t-distribution;autoencoder","","","","0","IEEE","29 Aug 2022","","","IEEE","IEEE Conferences"
"Autoencoder and Evolutionary Algorithm for Level Generation in Lode Runner","S. Thakkar; C. Cao; L. Wang; T. J. Choi; J. Togelius","New York University, New York, USA; New York University, New York, USA; New York University, New York, USA; New York University, New York, USA; New York University, New York, USA","2019 IEEE Conference on Games (CoG)","26 Sep 2019","2019","","","1","4","Procedural content generation can be used to create arbitrarily large amounts of game levels automatically, but traditionally the PCG algorithms needed to be developed or adapted for each game manually. Procedural Content Generation via Machine Learning (PCGML) harnesses the power of machine learning to semi-automate the development of PCG solutions, training on existing game content so as to create new content from the trained models. One of the machine learning techniques that have been suggested for this purpose is the autoencoder. However, very limited work has been done to explore the potential of autoencoders for PCGML. In this paper, we train autoencoders on levels for the platform game Lode Runner, and use them to generate levels. Compared to previous work, we use a multi-channel approach to represent content in full fidelity, and we compare standard and variational autoencoders. We also evolve the values of the hidden layer of trained autoencoders in order to find levels with desired properties.","2325-4289","978-1-7281-1884-0","10.1109/CIG.2019.8848076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848076","","Games;Encoding;Machine learning;Evolutionary computation;Gold;Markov processes;Decoding","computer games;evolutionary computation;learning (artificial intelligence)","evolutionary algorithm;level Generation;procedural content generation;game levels;PCG algorithms;machine learning;PCGML;PCG solutions;game content;trained models;platform game Lode Runner;standard autoencoders;variational autoencoders;trained autoencoders","","15","","9","","26 Sep 2019","","","IEEE","IEEE Conferences"
"Variational Sentence Augmentation for Masked Language Modeling","M. Ş. Bilici; M. F. Amasyali","Computer Engineering, Yildiz Technical University, Istanbul, Turkey; Computer Engineering, Yildiz Technical University, Istanbul, Turkey","2021 Innovations in Intelligent Systems and Applications Conference (ASYU)","18 Nov 2021","2021","","","1","5","We introduce a variational sentence augmentation method that consists of Variational Autoencoder [1] and Gated Recurrent Unit [2]. The proposed method for data augmentation benefits from its latent space representation, which encodes semantic and syntactic properties of the language. After learning the representation of the language, the model generates sentences from its latent space with the sequential structure of Gated Recurrent Unit. By augmenting existing unstructured corpus, the model improves Masked Language Modeling on pre-training. As a result, it improves fine-tuning as well. In pre-training, our method increases the prediction rate of masked tokens. In fine-tuning, we show that variational sentence augmentation can help semantic tasks and syntactic tasks. We make our experiments and evaluations on a limited dataset containing Turkish sentences, which also stands for a contribution to low resource languages.","","978-1-6654-3405-8","10.1109/ASYU52992.2021.9599089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9599089","Variational Autoencoder;Gated Recurrent Unit;BERT;Natural Language Processing;Masked Language Modeling;Data Augmentation","Technological innovation;Semantics;Bit error rate;Logic gates;Syntactics;Natural language processing;Data models","learning (artificial intelligence);natural language processing;speech recognition","Masked Language Modeling;variational sentence augmentation method;Gated Recurrent Unit;data augmentation benefits;latent space representation;semantic properties;syntactic properties;masked tokens;Turkish sentences;low resource languages;variational autoencoder","","","","25","IEEE","18 Nov 2021","","","IEEE","IEEE Conferences"
"Creativity: Generating Diverse Questions Using Variational Autoencoders","U. Jain; Z. Zhang; A. Schwing",UIUC; Northwestern University; UIUC,"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","9 Nov 2017","2017","","","5415","5424","Generating diverse questions for given images is an important task for computational education, entertainment and AI assistants. Different from many conventional prediction techniques is the need for algorithms to generate a diverse set of plausible questions, which we refer to as creativity. In this paper we propose a creative algorithm for visual question generation which combines the advantages of variational autoencoders with long short-term memory networks. We demonstrate that our framework is able to generate a large set of varying questions given a single input image.","1063-6919","978-1-5386-0457-1","10.1109/CVPR.2017.575","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8100058","","Visualization;Hidden Markov models;Training;Creativity;Artificial intelligence;Transforms","data visualisation;encoding;variational techniques","plausible questions;creativity;creative algorithm;visual question generation;variational autoencoders;diverse questions;long short-term networks","","44","","74","","9 Nov 2017","","","IEEE","IEEE Conferences"
"Blind Channel Equalization Using Variational Autoencoders","A. Caciularu; D. Burshtein","School of Electrical Engineering, Tel-Aviv University, Tel-Aviv, Israel; School of Electrical Engineering, Tel-Aviv University, Tel-Aviv, Israel","2018 IEEE International Conference on Communications Workshops (ICC Workshops)","5 Jul 2018","2018","","","1","6","A new maximum likelihood estimation approach for blind channel equalization, using variational autoencoders (VAEs), is introduced. Significant and consistent improvements in the error rate of the reconstructed symbols, compared to constant modulus equalizers, are demonstrated. In fact, for the channels that were examined, the performance of the new VAE blind channel equalizer was close to the performance of a nonblind adaptive linear minimum mean square error equalizer. The new equalization method enables a significantly lower latency channel acquisition compared to the constant modulus algorithm (CMA). The VAE uses a convolutional neural network with two layers and a very small number of free parameters. Although the computational complexity of the new equalizer is higher compared to CMA, it is still reasonable, and the number of free parameters to estimate is small.","2474-9133","978-1-5386-4328-0","10.1109/ICCW.2018.8403666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8403666","","Blind equalizers;Maximum likelihood estimation;Channel estimation;Machine learning;Neural networks","blind equalisers;computational complexity;feedforward neural nets;maximum likelihood estimation;variational techniques","blind channel equalization;variational autoencoders;maximum likelihood estimation approach;constant modulus equalizers;VAE blind channel equalizer;square error equalizer;equalization method;constant modulus algorithm","","29","","26","","5 Jul 2018","","","IEEE","IEEE Conferences"
"Dynamic movement primitives in latent space of time-dependent variational autoencoders","N. Chen; M. Karl; P. van der Smagt","Faculty for Informatics, Technische Universität München, Germany; Faculty for Informatics, Technische Universität München, Germany; Faculty for Informatics, Technische Universität München, Germany","2016 IEEE-RAS 16th International Conference on Humanoid Robots (Humanoids)","2 Jan 2017","2016","","","629","636","Dynamic movement primitives (DMPs) are powerful for the generalization of movements from demonstration. However, high dimensional movements, as they are found in robotics, make finding efficient DMP representations difficult. Typically, they are either used in configuration or Cartesian space, but both approaches do not generalize well. Additionally, limiting DMPs to single demonstrations restricts their generalization capabilities. In this paper, we explore a method that embeds DMPs into the latent space of a time-dependent variational autoencoder framework. Our method enables the representation of high-dimensional movements in a low-dimensional latent space. Experimental results show that our framework has excellent generalization in the latent space, e.g., switching between movements or changing goals. Also, it generates optimal movements when reproducing the movements.","2164-0580","978-1-5090-4718-5","10.1109/HUMANOIDS.2016.7803340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7803340","","Training;Neural networks;Gaussian distribution;Switches;Trajectory;Decoding;Probabilistic logic","Bayes methods;robots;signal processing;variational techniques","latent space;time-dependent variational autoencoders;dynamic movement primitives;DMP;robotics;Cartesian space","","26","","19","","2 Jan 2017","","","IEEE","IEEE Conferences"
"Guided Variational Autoencoder for Disentanglement Learning","Z. Ding; Y. Xu; W. Xu; G. Parmar; Y. Yang; M. Welling; Z. Tu","UC San Diego; UC San Diego; UC San Diego; UC San Diego; Qualcomm, Inc.; University of Amsterdam; UC San Diego","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","7917","7926","We propose an algorithm, guided variational autoencoder (Guided-VAE), that is able to learn a controllable generative model by performing latent representation disentanglement learning. The learning objective is achieved by providing signal to the latent encoding/embedding in VAE without changing its main backbone architecture, hence retaining the desirable properties of the VAE. We design an unsupervised and a supervised strategy in Guided-VAE and observe enhanced modeling and controlling capability over the vanilla VAE. In the unsupervised strategy, we guide the VAE learning by introducing a lightweight decoder that learns latent geometric transformation and principal components; in the supervised strategy, we use an adversarial excitation and inhibition mechanism to encourage the disentanglement of the latent variables. Guided-VAE enjoys its transparency and simplicity for the general representation learning task, as well as disentanglement learning. On a number of experiments for representation learning, improved synthesis/sampling, better disentanglement for classification, and reduced classification errors in meta learning have been observed.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00794","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156623","","Principal component analysis;Task analysis;Decoding;Training;Gallium nitride;Standards;Image reconstruction","decoding;image representation;unsupervised learning;variational techniques","guided variational autoencoder;Guided-VAE;controllable generative model;latent representation disentanglement learning;supervised strategy;enhanced modeling;controlling capability;vanilla VAE;unsupervised strategy;VAE learning;latent geometric transformation;latent variables;general representation learning task;meta learning","","19","","54","IEEE","5 Aug 2020","","","IEEE","IEEE Conferences"
"Missing Data in Traffic Estimation: A Variational Autoencoder Imputation Method","G. Boquet; J. L. Vicario; A. Morell; J. Serrano","Wireless Information Networking (WIN) Group, Universitat Autònoma de Barcelona (UAB); Wireless Information Networking (WIN) Group, Universitat Autònoma de Barcelona (UAB); Wireless Information Networking (WIN) Group, Universitat Autònoma de Barcelona (UAB); Wireless Information Networking (WIN) Group, Universitat Autònoma de Barcelona (UAB)","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","2882","2886","Road traffic forecasting systems are in scenarios where sensor or system failure occur. In those scenarios, it is known that missing values negatively affect estimation accuracy although it is being often underestimate in current deep neural network approaches. Our assumption is that traffic data can be generated from a latent space. Thus, we propose an online unsupervised data imputation method based on learning the data distribution using a variational autoencoder (VAE). This is used as an independent pre-processing step prior to traffic forecasting which is then evaluated against missing data of a real-world dataset. Compared to other methods, we show that VAE improves post-imputation traffic forecasting performance while allowing for data augmentation, data compression and traffic classification at the same time.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683011","traffic forecasting;deep learning;missing data;imputation method;intelligent transportation systems","","data analysis;data compression;neural nets;pattern classification;road traffic;traffic engineering computing;unsupervised learning;variational techniques","data distribution;VAE;independent pre-processing step;missing data;post-imputation traffic forecasting performance;data augmentation;data compression;traffic classification;traffic estimation;variational autoencoder imputation method;road traffic forecasting systems;traffic data;online unsupervised data imputation method;sensor failure;deep neural network approaches;system failure","","15","","20","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Deep recurrent music writer: Memory-enhanced variational autoencoder-based musical score composition and an objective measure","R. Sabathé; E. Coutinho; B. Schuller","Department of Computing, Imperial College London, London, United Kingdom; Department of Music, University of Liverpool, Liverpool, United Kingdom; Chair of Complex & Intelligent Systems, University of Passau, Passau, Germany","2017 International Joint Conference on Neural Networks (IJCNN)","3 Jul 2017","2017","","","3467","3474","In recent years, there has been an increasing interest in music generation using machine learning techniques typically used for classification or regression tasks. This is a field still in its infancy, and most attempts are still characterized by the imposition of many restrictions to the music composition process in order to favor the creation of “interesting” outputs. Furthermore, and most importantly, none of the past attempts has focused on developing objective measures to evaluate the music composed, which would allow to evaluate the pieces composed against a predetermined standard as well as permitting to fine-tune models for better “performance” and music composition goals. In this work, we intend to advance state-of-the-art in this area by introducing and evaluating a new metric for an objective assessment of the quality of the generated pieces. We will use this measure to evaluate the outputs of a truly generative model based on Variational Autoencoders that we apply here to automated music composition. Using our metric, we demonstrate that our model can generate music pieces that follow general stylistic characteristics of a given composer or musical genre. Additionally, we use this measure to investigate the impact of various parameters and model architectures on the compositional process and output.","2161-4407","978-1-5090-6182-2","10.1109/IJCNN.2017.7966292","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966292","","Music;Measurement;Standards;Data models;Context;Training;Computational modeling","audio coding;learning (artificial intelligence);music;variational techniques","deep recurrent music writer;memory-enhanced variational autoencoder-based musical score composition;music generation;machine learning;classification tasks;regression tasks;automated music composition;music pieces quality;stylistic characteristics;model architectures","","6","","23","","3 Jul 2017","","","IEEE","IEEE Conferences"
"Unsupervised classification of high-dimension and low-sample data with variational autoencoder based dimensionality reduction","M. S. Mahmud; X. Fu","Big Data Institute, College of Computer and Software Engineering, Shenzhen University, China; Faculty of Arts and Sciences, Shenzhen Technology University, China","2019 IEEE 4th International Conference on Advanced Robotics and Mechatronics (ICARM)","12 Sep 2019","2019","","","498","503","In data mining research and development, one of the defining challenges is to perform classification or clustering tasks for relatively limited-samples with high-dimensions data, also known as high-dimensional limited-sample size (HDLSS) problem. Due to the limited-sample-size, there is a lack of enough training data to train classification models. Also, the ‘curse of dimensionality’ aspect is often a restriction on the effectiveness of many methods for solving HDLSS problem. Classification model with limited-sample dataset lead to overfitting and cannot achieve a satisfactory result. Thus, the unsupervised method is a better choice to solve such problems. Due to the emergence of deep learning, their plenty of applications and promising outcome, it is required an extensive analysis of the deep learning technique on HDLSS dataset. This paper aims at evaluating the performance of variational autoencoder (VAE) based dimensionality reduction and unsupervised classification on the HDLSS dataset. The performance of VAE is compared with two existing techniques namely PCA and NMF on fourteen datasets in term of three evaluation metrics namely purity, Rand index, and NMI. The experimental result shows the superiority of VAE over the traditional methods on the HDLSS dataset.","","978-1-7281-0064-7","10.1109/ICARM.2019.8834333","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8834333","HDLSS dataset;dimensionality reduction;variational autoencoder;unsupervised classification","Dimensionality reduction;Principal component analysis;Data models;Deep learning;Data analysis;Decoding;Conferences","bioinformatics;data mining;pattern classification;pattern clustering;principal component analysis;unsupervised learning","classification model;limited-sample dataset lead;unsupervised method;deep learning technique;HDLSS dataset;unsupervised classification;low-sample data;data mining research;high-dimensions data;limited-sample size problem;training data;high-dimension data;autoencoder based dimensionality reduction;HDLSS problem","","4","","25","","12 Sep 2019","","","IEEE","IEEE Conferences"
"Robust Disentangled Variational Speech Representation Learning for Zero-Shot Voice Conversion","J. Lian; C. Zhang; D. Yu","Tencent AI Lab, Bellevue, WA; Tencent AI Lab, Bellevue, WA; Tencent AI Lab, Bellevue, WA","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","6572","6576","Traditional studies on voice conversion (VC) have made progress with parallel training data and known speakers. Good voice conversion quality is obtained by exploring better alignment modules or expressive mapping functions. In this study, we investigate zero-shot VC from a novel perspective of self-supervised disentangled speech representation learning. Specifically, we achieve the disentanglement by balancing the information flow between global speaker representation and time-varying content representation in a sequential variational autoencoder (VAE). A zero-shot voice conversion is performed by feeding an arbitrary speaker embedding and content embeddings to the VAE decoder. Besides that, an on-the-fly data augmentation training strategy is applied to make the learned representation noise invariant. On TIMIT and VCTK datasets, we achieve state-of-the-art performance on both objective evaluation, i.e., speaker verification (SV) on speaker embedding and content embedding, and subjective evaluation, i.e., voice naturalness and similarity, and remains to be robust even with noisy source/target utterances.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9747272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747272","Self-supervised Disentangled representation learning;zero-shot style transfer;voice conversion;variational autoencoder","Training;Representation learning;Vocoders;System performance;Training data;Speech recognition;Acoustics","neural nets;speaker recognition;speech processing;supervised learning;unsupervised learning;voice activity detection","content embedding;voice naturalness;variational speech representation learning;zero-shot voice conversion;traditional studies;parallel training data;good voice conversion quality;expressive mapping functions;zero-shot VC;self-supervised disentangled speech representation learning;global speaker representation;time-varying content representation;sequential variational autoencoder;arbitrary speaker;content embeddings;learned representation noise invariant;speaker verification;speaker embedding;robust disentangled variational speech representation learning;on-the-fly data augmentation;TIMIT datasets;VCTK datasets;noisy source-target utterances","","","","28","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Robust Belief State Space Representation for Statistical Dialogue Managers Using Deep Autoencoders","F. Lygerakis; V. Diakoloulas; M. Lagoudakis; M. Kotti","School of Electrical & Computer Engineering, Technical University of Crete, Greece; School of Electrical & Computer Engineering, Technical University of Crete, Greece; School of Electrical & Computer Engineering, Technical University of Crete, Greece; Speech Technology Group, Toshiba Research Cambridge, UK","2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)","20 Feb 2020","2019","","","1055","1061","Statistical Dialogue Systems (SDS) have proved their humongous potential over the past few years. However, the lack of efficient and robust representations of the belief state (BS) space refrains them from revealing their full potential. There is a great need for automatic BS representations, which will replace the old hand-crafted, variable-length ones. To tackle those problems, we introduce a novel use of Autoencoders (AEs). Our goal is to obtain a low-dimensional, fixed-length, and compact, yet robust representation of the BS space. We investigate the use of dense AE, Denoising AE (DAE) and Variational Denoising AE (VDAE), which we combine with GP-SARSA to learn dialogue policies in the PyDial toolkit. In this framework, the BS is normally represented in a relatively compact, but still redundant summary space which is obtained through a heuristic mapping of the original master space. We show that all the proposed AE-based representations consistently outperform the summary BS representation. Especially, as the Semantic Error Rate (SER) increases, the DAE/VDAE-based representations obtain state-of-the-art and sample efficient performance.","","978-1-7281-0306-8","10.1109/ASRU46091.2019.9003871","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003871","denoising autoencoder;variational autoencoder;statistical dialogue system;dialogue manager;belief state representation","Noise reduction;Feature extraction;Robustness;Training;Semantics;Standards;Decoding","interactive systems;learning (artificial intelligence);Markov processes;natural language processing","original master space;summary BS representation;robust belief state space representation;deep autoencoders;statistical dialogue systems;humongous potential;efficient representations;robust representations;automatic BS representations;old hand-crafted;low-dimensional length;fixed-length;robust representation;BS space;dialogue policies;redundant summary space;variational denoising AE;statistical dialogue managers;AE-based representations;SER;semantic error rate;DAE-VDAE-based representations;GP-SARSA","","1","","33","","20 Feb 2020","","","IEEE","IEEE Conferences"
"Anomaly Detection of Time Series With Smoothness-Inducing Sequential Variational Auto-Encoder","L. Li; J. Yan; H. Wang; Y. Jin","State Key Laboratory of Advanced Optical Communication System and Network, MoE Key Laboratory of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, MoE Key Laboratory of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Advanced Optical Communication System and Network, MoE Key Laboratory of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Advanced Optical Communication System and Network, MoE Key Laboratory of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai, China","IEEE Transactions on Neural Networks and Learning Systems","1 Mar 2021","2021","32","3","1177","1191","Deep generative models have demonstrated their effectiveness in learning latent representation and modeling complex dependencies of time series. In this article, we present a smoothness-inducing sequential variational auto-encoder (VAE) (SISVAE) model for the robust estimation and anomaly detection of multidimensional time series. Our model is based on VAE, and its backbone is fulfilled by a recurrent neural network to capture latent temporal structures of time series for both the generative model and the inference model. Specifically, our model parameterizes mean and variance for each time-stamp with flexible neural networks, resulting in a nonstationary model that can work without the assumption of constant noise as commonly made by existing Markov models. However, such flexibility may cause the model fragile to anomalies. To achieve robust density estimation which can also benefit detection tasks, we propose a smoothness-inducing prior over possible estimations. The proposed prior works as a regularizer that places penalty at nonsmooth reconstructions. Our model is learned efficiently with a novel stochastic gradient variational Bayes estimator. In particular, we study two decision criteria for anomaly detection: reconstruction probability and reconstruction error. We show the effectiveness of our model on both synthetic data sets and public real-world benchmarks.","2162-2388","","10.1109/TNNLS.2020.2980749","China Major State Research Development Program(grant numbers:2018YFC0830400,2018AAA0100704,2016YFB1001003); NSFC(grant numbers:61972250,U19B2035); STCSM(grant numbers:18DZ1112300); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9064715","Anomaly detection;deep generative model;recurrent neural network;time series;variational auto-encoder (VAE)","Time series analysis;Anomaly detection;Data models;Adaptation models;Estimation;Robustness;Recurrent neural networks","Bayes methods;deep learning (artificial intelligence);estimation theory;gradient methods;Markov processes;mathematics computing;recurrent neural nets;time series;variational techniques","robust estimation;anomaly detection;multidimensional time series;recurrent neural network;flexible neural networks;Markov models;stochastic gradient variational Bayes estimator;deep generative models;smoothness inducing sequential variational autoencoder model;nonsmooth reconstructions","","14","","58","IEEE","13 Apr 2020","","","IEEE","IEEE Journals"
"U-ASG: A Universal Method to Perform Adversarial Attack on Autoencoder based Network Anomaly Detection Systems","C. Yang; L. Zhou; H. Wen; Y. Wu","National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, P. R. China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, P. R. China; Department of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, P. R. China; Department of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, P. R. China","IEEE INFOCOM 2020 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)","10 Aug 2020","2020","","","68","73","Semi-supervised machine learning models, especially deep neural networks, have been widely used in network anomaly detection for their capability of capturing patterns in normal data. However, the models face security challenges when an attacker has obtained their full details. In this paper, we propose a universal adversarial sample generator (U-ASG), to perform white-box adversarial attacks on autoencoder-based semi-supervised network anomaly detection (SSNAD) systems. The purpose of adversarial attacks is to generate small adversarial perturbations and add them to targeted anomalous samples to fly under the radar. We model the generation process of adversarial perturbations as an optimization problem, in which we minimize the reconstruction errors of the adversarial samples through the trained autoencoder and approximate it to solve. Furthermore, to improve the attack performance against the variational autoencoder (VAE), which is robust to tiny perturbations through uncertainty modeling, we design a mechanism to weaken its robustness by introducing a variance regularizer to the optimization. Simulation results show that the adversarial attacks generated by our U-ASG can effectively degrade the performance of the autoencoder-based SSNAD systems.","","978-1-7281-8695-5","10.1109/INFOCOMWKSHPS50562.2020.9162699","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9162699","anomaly detection;autoencoder;adversarial perturbation;neural network","Perturbation methods;Anomaly detection;Optimization;Neural networks;Decoding;Data models;Principal component analysis","neural nets;security of data;supervised learning","U-ASG;adversarial attack;semisupervised machine learning models;deep neural networks;universal adversarial sample generator;white-box adversarial attacks;autoencoder-based semisupervised network anomaly detection systems;adversarial perturbations;generation process;trained autoencoder;attack performance;variational autoencoder;uncertainty modeling;autoencoder-based SSNAD systems","","","","19","","10 Aug 2020","","","IEEE","IEEE Conferences"
"A Variational Autoencoder-Based Dimensionality Reduction Technique for Generation Forecasting in Cyber-Physical Smart Grids","D. Kaur; S. N. Islam; M. A. Mahmud","School of Engineering, Deakin University, Australia; School of Engineering, Deakin University, Australia; School of Engineering, Deakin University, Australia","2021 IEEE International Conference on Communications Workshops (ICC Workshops)","9 Jul 2021","2021","","","1","6","Modern energy systems often regarded as smart grid (SG) systems are cyber-physical systems (CPS) equipped with advanced metering and smart sensing devices, leading to a high-dimensional data generation in large volumes. To address this challenge, we propose a new variational autoencoder (VAE)- based dimensionality reduction technique for SG data to enable renewable energy generation forecasting with improved accuracy. The proposed method integrates bidirectional long short-term memory (BiLSTM) deep neural networks with variational inference, to generate an encoded representation of the high-dimensional time-series energy data. The encoded data is further utilized as low- dimensional representation of the original data for the application of energy forecasting, which leads to the reduced computational cost and more accurate forecasting results. The efficacy of the proposed VAE-BiLSTM method is evaluated using python programming and tensorflow library on the data traces taken from the Ausgrid solar generation dataset. Moreover, a comparative analysis of the proposed technique is presented with the benchmark autoencoder (AE) and VAE-based methods. Our result analysis illustrates that the proposed VAE-BiLSTM outperforms VAE-RNN, VAE-LSTM, as well as standard AE- based methods using evaluation metrics such as reconstruction error, pinball score, root-mean square error (RMSE), and mean absolute error (MAE).","2694-2941","978-1-7281-9441-7","10.1109/ICCWorkshops50388.2021.9473748","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9473748","Dimensionality reduction;energy forecasting;deep learning;renewable energy generation;posterior approximation;VAE-BiLSTM","Dimensionality reduction;Renewable energy sources;Conferences;Benchmark testing;Smart grids;Sensors;Solar power generation","cyber-physical systems;load forecasting;power engineering computing;power system measurement;Python;recurrent neural nets;smart meters;smart power grids;tensors;time series","cyber-physical smart grids;smart grid systems;cyber-physical systems;metering device;high-dimensional data generation;SG data;renewable energy generation forecasting;variational inference;encoded representation;high-dimensional time-series energy data;encoded data;energy forecasting;Ausgrid solar generation dataset;variational autoencoder-based dimensionality reduction;smart sensing device;VAE-BiLSTM;bidirectional long short-term memory deep neural networks;Python programming;tensorflow library","","1","","21","","9 Jul 2021","","","IEEE","IEEE Conferences"
"Language Model-Based Paired Variational Autoencoders for Robotic Language Learning","O. Özdemir; M. Kerzel; C. Weber; J. H. Lee; S. Wermter","Department of Informatics, Knowledge Technology Group, University of Hamburg, Hamburg, Germany; Department of Informatics, Knowledge Technology Group, University of Hamburg, Hamburg, Germany; Department of Informatics, Knowledge Technology Group, University of Hamburg, Hamburg, Germany; Department of Informatics, Knowledge Technology Group, University of Hamburg, Hamburg, Germany; Department of Informatics, Knowledge Technology Group, University of Hamburg, Hamburg, Germany","IEEE Transactions on Cognitive and Developmental Systems","","2022","PP","99","1","1","Human infants learn language while interacting with their environment in which their caregivers may describe the objects and actions they perform. Similar to human infants, artificial agents can learn language while interacting with their environment. In this work, first, we present a neural model that bidirectionally binds robot actions and their language descriptions in a simple object manipulation scenario. Building on our previous Paired Variational Autoencoders (PVAE) model, we demonstrate the superiority of the variational autoencoder over standard autoencoders by experimenting with cubes of different colours, and by enabling the production of alternative vocabularies. Additional experiments show that the model’s channel-separated visual feature extraction module can cope with objects of different shapes. Next, we introduce PVAE-BERT, which equips the model with a pretrained large-scale language model, i.e., Bidirectional Encoder Representations from Transformers (BERT), enabling the model to go beyond comprehending only the predefined descriptions that the network has been trained on; the recognition of action descriptions generalises to unconstrained natural language as the model becomes capable of understanding unlimited variations of the same descriptions. Our experiments suggest that using a pretrained language model as the language encoder allows our approach to scale up for real-world scenarios with instructions from human users.","2379-8939","","10.1109/TCDS.2022.3204452","Deutsche Forschungsgemeinschaft(grant numbers:TRR 169); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9878160","language grounding;variational autoencoders;channel separation;pretrained language model;object manipulation","Robots;Visualization;Task analysis;Toy manufacturing industry;Feature extraction;Data models;Bit error rate","","","","","","","CCBY","6 Sep 2022","","","IEEE","IEEE Early Access Articles"
"Optical Flow Prediction in Auto Driving from Single Image via Conditional Variational Auto-Encoder","J. Yan; L. Xu; K. Mei","Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China","2019 IEEE International Conference on Unmanned Systems and Artificial Intelligence (ICUSAI)","25 Jun 2020","2019","","","320","323","In auto-driving tasks, visual prediction is very meaningful and difficult, because the motion of the predicted target has many possible outputs. It is very effective to predict the motion of the target by optical flow, but the output of the previous optical flow models is fixed. In this paper, we proposed an optical flow prediction model via Conditional Variational Auto-Encoder. In experiment, the model can effectively predict a variety of possible optical motions in the real world. A number of experimental results show that our models outperform all prior state-of-the-art on the test of a recent optical flow prediction competition.","","978-1-7281-5859-4","10.1109/ICUSAI47366.2019.9124852","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9124852","Conditional Variational Auto-Encoder;Optical Flow Prediction;Auto-Driving (key words)","","computer vision;image motion analysis;image sequences;intelligent transportation systems;neural nets;object tracking","conditional variational autoencoder;optical flow prediction;visual prediction;target motion;autodriving tasks;optical motions","","","","20","","25 Jun 2020","","","IEEE","IEEE Conferences"
"Game Theoretical Adversarial Deep Learning With Variational Adversaries","A. S. Chivukula; X. Yang; W. Liu; T. Zhu; W. Zhou","Advanced Analytics Institute, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia; Advanced Analytics Institute, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia; Advanced Analytics Institute, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia; Centre for Cyber Security and Privacy, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia; Centre for Cyber Security and Privacy, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia","IEEE Transactions on Knowledge and Data Engineering","6 Oct 2021","2021","33","11","3568","3581","A critical challenge in machine learning is the vulnerability of learning models in defending attacks from malicious adversaries. In this research, we propose game theoretical learning between a variational adversary and a Convolutional Neural Network (CNN), participating in a variable-sum two-player sequential Stackelberg game. Our adversary manipulates the input data distribution to make the CNN misclassify the manipulated data. Our ideal adversarial manipulation is a minimum change to the data which yet is large enough to mislead the CNNs. We propose an optimization procedure to find optimal adversarial manipulations by solving for the Nash equilibrium of the Stackelberg game. Specifically, the adversary's payoff function depends on the data manipulation which is determined by a Variational Autoencoder, while the CNN classifier's payoff functions are evaluated by misclassification errors. The optimization of our adversarial manipulations is defined by Alternating Least Squares and Simulated Annealing. Experimental results demonstrate that our game-theoretic manipulations are able to mislead CNNs that are well trained on the original data as well as on data generated by other models. We then let the CNNs to incorporate our manipulated data which leads to secure classifiers that are empirically the most robust in defending various types of adversarial attacks.","1558-2191","","10.1109/TKDE.2020.2972320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8986751","Adversarial learning;variational autoencoders;convolutional neural networks;game theory;nash equilibrium","Games;Nash equilibrium;Training;Computational modeling;Optimization;Neural networks;Perturbation methods","convolutional neural nets;deep learning (artificial intelligence);game theory;least squares approximations;pattern classification;security of data;simulated annealing","game theoretical adversarial deep learning;variational adversary;machine learning;malicious adversaries;convolutional neural network;input data distribution;optimization procedure;optimal adversarial manipulations;data manipulation;game-theoretic manipulations;adversarial attacks;learning model vulnerability;variable-sum two-player sequential Stackelberg game;Nash equilibrium;adversary payoff function;variational autoencoder;CNN classifier payoff function;alternating least squares;simulated annealing","","3","","40","IEEE","7 Feb 2020","","","IEEE","IEEE Journals"
"Variational Dialogue Generation with Normalizing Flows","T. -C. Luo; J. -T. Chien","Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","7778","7782","Conditional variational autoencoder (cVAE) has shown promising performance in dialogue generation. However, there still exists two issues in dialog cVAE model. The first issue is the Kullback-Leiblier (KL) vanishing problem which results in degenerating cVAE into a simple recurrent neural network. The second issue is the assumption of isotropic Gaussian prior for latent variable which is too simple to assure diversity of the generated responses. To handle these issues, a simple distribution should be transformed into a complex distribution and simultaneously the value of KL divergence should be preserved. This paper presents the dialogue flow VAE (DF-VAE) for variational dialogue generation. In particular, KL vanishing is tackled by a new normalizing flow. An inverse autoregressive flow is proposed to transform isotropic Gaussian prior to a rich distribution. In the experiments, the proposed DF-VAE is significantly better than the other methods in terms of different evaluation metrics. The diversity of generated dialogue responses is enhanced. Ablation study is conducted to illustrate the merit of the proposed flow models.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414586","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414586","Dialogue generation;recurrent neural network;variational autoencoder;normalizing flow","Recurrent neural networks;Conferences;Transforms;Signal processing;Acoustic measurements;Acoustics;Speech processing","autoregressive processes;interactive systems;natural language processing;recurrent neural nets","inverse autoregressive flow;DF-VAE;dialogue flow VAE;KL divergence;isotropic Gaussian;recurrent neural network;Kullback-Leiblier vanishing problem;dialog cVAE model;conditional variational autoencoder;normalizing flow;variational dialogue generation","","1","","32","IEEE","13 May 2021","","","IEEE","IEEE Conferences"
"Learning Disentangled Latent Factors for Individual Treatment Effect Estimation Using Variational Generative Adversarial Nets","Q. Bao; Z. Mao; L. Chen","School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China; Jiangsu Key Laboratory of Big Data Security and Intelligent Processing, Nanjing University of Posts and Telecommunications, Nanjing, China","2022 IEEE 25th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","20 May 2022","2022","","","347","352","Estimating individual treatment effect (ITE) is a challenging task due to the need for individual potential outcomes to be learned from biased data and counterfactuals are inherently unobservable. Some researchers propose to use generative adversarial approaches to infer the counterfactual outcomes based on the distribution of factual outcomes. However, these methods assume that complete confounding factors are observed, and simply treat all observed variables as confounding factors, ignoring identification of possible instrumental factors and adjustment factors, which will bring large deviation to ITE estimation when facing biased data. To address these issues, we propose a novel Variational Generative Adversarial Nets for ITE estimation by designing the collaborative learning strategy with Variational AutoEncoder (VAE) and Generative Adversarial Nets (GAN). Specifically, we employ VAE to infer the latent representations of observed variables to access complete latent factors while using GAN to infer unseen counterfactual outcomes and guide VAE for disentangling these latent factors into three sets corresponding to the instrumental, confounding, and adjustment factors. Then the disentangled latent confounding factors can be used to further control data bias using an adaptive weighting scheme. Extensive experiments on real and synthetic data demonstrate learning disentangled latent factors for ITE estimation is effective, and our method has excellent performance even with high data bias.","","978-1-6654-0527-0","10.1109/CSCWD54268.2022.9776065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9776065","individual treatment effect;biased data;counterfactual outcomes;latent confounding factors;Variational AutoEncoder;Generative Adversarial Nets","Correlation;Instruments;Conferences;Estimation;Collaborative work;Task analysis","data handling;learning (artificial intelligence);neural nets","individual treatment effect estimation;individual potential outcomes;biased data;factual outcomes;complete confounding factors;observed variables;ITE estimation;collaborative learning strategy;variational AutoEncoder;VAE;latent representations;complete latent factors;unseen counterfactual outcomes;instrumental adjustment factors;disentangled latent confounding factors;control data bias;high data bias;variational generative adversarial nets;confounding adjustment factors;GAN;adaptive weighting scheme","","","","29","IEEE","20 May 2022","","","IEEE","IEEE Conferences"
"Keyword-Based Diverse Image Retrieval With Variational Multiple Instance Graph","Y. Zeng; Y. Wang; D. Liao; G. Li; W. Huang; J. Xu; D. Cao; H. Man","Department of WeChat, Tencent Inc., Shenzhen 518063, China.; Department of WeChat, Tencent Inc., Shenzhen 518063, China.; Department of WeChat, Tencent Inc., Shenzhen 518063, China.; Department of WeChat, Tencent Inc., Shenzhen 518063, China.; Department of WeChat, Tencent Inc., Shenzhen 518063, China.; School of Future Technology, South China University of Technology, Guangzhou 510006, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha 410082, China.; Department of Electrical and Computer Engineering, Stevens Institute of Technology, Hoboken, NJ 07030 USA.","IEEE Transactions on Neural Networks and Learning Systems","","2022","PP","99","1","10","The task of cross-modal image retrieval has recently attracted considerable research attention. In real-world scenarios, keyword-based queries issued by users are usually short and have broad semantics. Therefore, semantic diversity is as important as retrieval accuracy in such user-oriented services, which improves user experience. However, most typical cross-modal image retrieval methods based on single point query embedding inevitably result in low semantic diversity, while existing diverse retrieval approaches frequently lead to low accuracy due to a lack of cross-modal understanding. To address this challenge, we introduce an end-to-end solution termed variational multiple instance graph (VMIG), in which a continuous semantic space is learned to capture diverse query semantics, and the retrieval task is formulated as a multiple instance learning problems to connect diverse features across modalities. Specifically, a query-guided variational autoencoder is employed to model the continuous semantic space instead of learning a single-point embedding. Afterward, multiple instances of the image and query are obtained by sampling in the continuous semantic space and applying multihead attention, respectively. Thereafter, an instance graph is constructed to remove noisy instances and align cross-modal semantics. Finally, heterogeneous modalities are robustly fused under multiple losses. Extensive experiments on two real-world datasets have well verified the effectiveness of our proposed solution in both retrieval accuracy and semantic diversity.","2162-2388","","10.1109/TNNLS.2022.3168431","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9764824","Cross-modal retrieval;keyword-based image retrieval;multiple instance graph;variational autoencoder (VAE).","Semantics;Image retrieval;Task analysis;Feature extraction;Learning systems;Generators;Noise measurement","","","","","","","IEEE","28 Apr 2022","","","IEEE","IEEE Early Access Articles"
"Deformable Mri To Transrectal Ultrasound Registration For Prostate Interventions With Shape-Based Deep Variational Auto-Encoders","S. Shakeri; W. Le; C. Ménard; S. Kadoury","MedICAL Laboratory, Polytechnique Montréal, Montréal, Canada; Centre de recherche du CHUM (CRCHUM), Université de Montréal, Canada; Centre de recherche du CHUM (CRCHUM), Université de Montréal, Canada; Centre de recherche du CHUM (CRCHUM), Université de Montréal, Canada","2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)","25 May 2021","2021","","","174","178","Prostate cancer is one of the most prevalent cancers in men, where diagnosis is confirmed through biopsies analyzed with histopathology. A diagnostic T2-w MRI is often registered to intra-operative transrectal ultrasound (TRUS) for effective targeting of suspicious lesions during image-guided biopsy procedures or needle-based therapeutic interventions such as brachytherapy. However, this process remains challenging and time-consuming in an interventional environment. The present work proposes an automated 3D deformable MRI to TRUS registration pipeline that leverages both deep variational auto-encoders with a non-rigid iterative closest point registration approach. A convolutional FC-ResNet segmentation model is first trained from 3D TRUS images to extract prostate boundaries during the procedure. Matched MRI-TRUS 3D segmentations are then used to generate a vector representation of the gland's surface mesh between modalities, used as input to a 10layer dense variational autoencoder model to constrain the predicted deformations based on a latent representation of the deformation modes. At each iteration of the registration process, the warped image is regularized using the autoencoder's reconstruction loss, ensuring plausible anatomical deformations. Based on a 5-fold cross-validation strategy with 45 patients undergoing HDR brachytherapy, the method yields a Dice score of 85.0 ± 2.6 with a target registration error of 3.9 ± 1.4 mm, with the proposed method yielding results outperforming the state-of-the-art, with minimal intra-procedural disruptions.","1945-8452","978-1-6654-1246-9","10.1109/ISBI48211.2021.9434101","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9434101","Prostate cancer;Deep variational auto-encoders;TRUS segmentation;Deformable registration;Non-iterative closest point alignment","Deformable models;Image segmentation;Solid modeling;Three-dimensional displays;Ultrasonic imaging;Magnetic resonance imaging;Tools","biological organs;biomedical MRI;biomedical ultrasonics;cancer;deformation;feature extraction;image reconstruction;image registration;image segmentation;iterative methods;medical image processing","transrectal ultrasound registration;prostate interventions;prostate cancer;prevalent cancers;biopsies;intra-operative transrectal ultrasound;effective targeting;suspicious lesions;image-guided biopsy procedures;needle-based therapeutic interventions;interventional environment;TRUS registration pipeline;nonrigid iterative closest point registration approach;convolutional FC-ResNet segmentation model;prostate boundaries;matched MRI-TRUS 3D segmentations;vector representation;predicted deformations;warped image;plausible anatomical deformations;target registration error;minimal intra-procedural disruptions;dense variational autoencoder model;diagnostic T2-w MRI;shape-based deep variational autoencoders;deformable MRI","","","","14","","25 May 2021","","","IEEE","IEEE Conferences"
"Video Compression With Rate-Distortion Autoencoders","A. Habibian; T. V. Rozendaal; J. Tomczak; T. Cohen","Qualcomm AI Research, Amsterdam, the Netherlands; Qualcomm AI Research, Amsterdam, the Netherlands; Qualcomm AI Research, Amsterdam, Netherlands; Qualcomm AI Research, Amsterdam, Netherlands","2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","7032","7041","In this paper we present a deep generative model for lossy video compression. We employ a model that consists of a 3D autoencoder with a discrete latent space and an autoregressive prior used for entropy coding. Both autoencoder and prior are trained jointly to minimize a ratedistortion loss, which is closely related to the ELBO used in variational autoencoders. Despite its simplicity, we find that our method outperforms the state-of-the-art learned video compression networks based on motion compensation or interpolation. We systematically evaluate various design choices, such as the use offrame-based or spatio-temporal autoencoders, and the type of autoregressive prior. In addition, we present three extensions of the basic method that demonstrate the benefits over classical approaches to compression. First, we introduce semantic compression, where the model is trained to allocate more bits to objects of interest. Second, we study adaptive compression, where the model is adapted to a domain with limited variability, e.g. videos taken from an autonomous car, to achieve superior compression on that domain. Finally, we introduce multimodal compression, where we demonstrate the effectiveness of our model in joint compression of multiple modalities captured by non-standard imaging sensors, such as quad cameras. We believe that this opens up novel video compression applications, which have not been feasible with classical codecs.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.00713","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9008368","","Image coding;Video compression;Distortion;Rate distortion theory;Adaptation models;Rate-distortion;Three-dimensional displays","autoregressive processes;data compression;image capture;image sensors;learning (artificial intelligence);motion compensation;neural nets;stereo image processing;variational techniques;video coding","rate-distortion autoencoders;deep generative model;lossy video compression;discrete latent space;entropy coding;variational autoencoders;motion compensation;adaptive compression;3D autoencoder;autoregressive prior;imaging sensors","","43","1","40","","27 Feb 2020","","","IEEE","IEEE Conferences"
"Towards Enhancing Spectrum Sensing: Signal Classification Using Autoencoders","S. Subray; S. Tschimben; K. Gifford","Computer Science Department, University of Colorado, Boulder, CO, USA; Computer Science Department, University of Colorado, Boulder, CO, USA; Computer Science Department, University of Colorado, Boulder, CO, USA","IEEE Access","14 Jun 2021","2021","9","","82288","82299","The demand for technologies relying on the radio spectrum, such as mobile communications and IoT, has been growing exponentially. As a consequence, providing access to the radio spectrum is becoming increasingly more important. The ever-growing wireless traffic and the increasing scarcity of available spectrum warrants efficient management of the radio spectrum. At the same time, machine learning (ML) is becoming ubiquitous and has found applications in many fields for its ability to identify patterns and assist with decision-making processes. Recently, machine learning algorithms have been used to address challenges in the wireless communications domain, such as radio spectrum sensing, and have shown better performance than traditional sensing methods, such as energy detection. Spectrum sensing, a method for detecting and identifying different wireless signals being transmitted in the same band of the radio spectrum, is crucial for improving dynamic spectrum sharing, which has the potential to enhance sharing and coexistence of different wireless technologies in the same frequency band and ultimately improve spectrum efficiency. To this end, this research evaluates different types of autoencoders, such as deep, variational and Long Short-Term Memory (LSTM) autoencoders, to identify and differentiate between LTE and Wi-Fi transmissions. The goal is to investigate the performance of the different types of autoencoders on an I/Q dataset consisting of LTE and a combination of Wi-Fi signals (IEEE 802.11ax and IEEE 802.11ac) for the classification task in terms of complexity, precision, and recall to identify the best algorithm. Our models have achieved up to 99.9% precision and 88.1% recall for this classification task. Additionally, with a shortest training time of approximately 47 seconds, the models are suitable for online learning and deployment in a dynamic RF environment.","2169-3536","","10.1109/ACCESS.2021.3087113","National Aeronautics and Space Administration (NASA)(grant numbers:NNX17AK79A); National Science Foundation (NSF)(grant numbers:2030233); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9448060","Multiple signal classification;machine learning;artificial neural networks;autoencoder;spectrum sensing;LTE;Wi-Fi","Wireless fidelity;Long Term Evolution;Wireless communication;Wireless sensor networks;Sensors;Modulation;Classification algorithms","decision making;game theory;learning (artificial intelligence);Long Term Evolution;radio spectrum management;recurrent neural nets;signal classification;signal detection;telecommunication network management;telecommunication traffic;wireless LAN","autoencoders;wireless communications domain;radio spectrum sensing;sensing methods;wireless signals;dynamic spectrum sharing;spectrum efficiency;variational autoencoders;long short-term memory autoencoders;LSTM autoencoders;machine learning;LTE transmissions;Wi-Fi transmissions;wireless traffic;decision-making processes","","1","","38","CCBY","7 Jun 2021","","","IEEE","IEEE Journals"
"Training Convolutional Autoencoders with Metric Learning","Y. Onitsuka; W. Ohyama; S. Uchida","Kyushu University, Fukuoka, Japan; Saitama Institute of Technology, Fukaya-shi, Saitama, JAPAN; Kyushu University, Fukuoka-shi, JAPAN","2019 International Conference on Document Analysis and Recognition (ICDAR)","3 Feb 2020","2019","","","86","91","We propose a new Training method that enables an autoencoder to extract more useful features for retrieval or classification tasks with limited-size datasets. Some targets in document analysis and recognition (DAR) including signature verification, historical document analysis, and scene text recognition, involve a common problem in which the size of the dataset available for training is small against the intra-class variety of the target appearance. Recently, several approaches, such as variational autoencoders and deep metric learning, have been proposed to obtain a feature representation that is suitable for the tasks. However, these methods sometimes cause an overfitting problem in which the accuracy of the test data is relatively low, while the performance for the training dataset is quite high. Our proposed method obtains feature representations for such tasks in DAR using convolutional autoencoders with metric learning. The accuracy is evaluated on an image-based retrieval of ancient Japanese signatures.","2379-2140","978-1-7281-3014-9","10.1109/ICDAR.2019.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8977957","convolutional autoencoder;metric learning;feature extraction;histrical document analysis","Measurement;Training;Feature extraction;Task analysis;Text analysis;Dimensionality reduction;Text recognition","convolutional neural nets;feature extraction;handwriting recognition;image classification;image representation;learning (artificial intelligence)","historical document analysis;scene text recognition;intra-class variety;target appearance;variational autoencoders;deep metric learning;feature representation;overfitting problem;training dataset;DAR;image-based retrieval;ancient Japanese signatures;Training convolutional autoencoders;autoencoder;limited-size datasets;convolutional autoencoders;signature verification","","1","","18","","3 Feb 2020","","","IEEE","IEEE Conferences"
"Examining the Size of the Latent Space of Convolutional Variational Autoencoders Trained With Spectral Topographic Maps of EEG Frequency Bands","T. Ahmed; L. Longo","Artificial Intelligence and Cognitive Load Research Laboratory, School of Computer Science, Technological University Dublin, Dublin 7, Ireland; Artificial Intelligence and Cognitive Load Research Laboratory, School of Computer Science, Technological University Dublin, Dublin 7, Ireland","IEEE Access","13 Oct 2022","2022","10","","107575","107586","Dimensionality reduction and the automatic learning of key features from electroencephalographic (EEG) signals have always been challenging tasks. Variational autoencoders (VAEs) have been used for EEG data generation and augmentation, denoising, and automatic feature extraction. However, investigations of the optimal shape of their latent space have been neglected. This research tried to understand the minimal size of the latent space of convolutional VAEs, trained with spectral topographic EEG head maps of different frequency bands, that leads to the maximum reconstruction capacity of the input and maximum utility for classification tasks. Head maps are generated employing a sliding window technique with a 125ms shift. Person-specific convolutional VAEs are trained to learn latent spaces of varying dimensions while a dense neural network is trained to investigate their utility on a classification task. The empirical results suggest that when VAEs are deployed on spectral topographic maps with shape  $32\times 32$ , deployed for 32 electrodes from 2 seconds cerebral activity, they were capable of reducing the input up to almost 99%, with a latent space of 28 means and standard deviations. This did not compromise the salient information, as confirmed by a structural similarity index, and mean squared error between the input and reconstructed maps. Additionally, along the 28 means maximized the utility of latent spaces in the classification task, with an average 0.93% accuracy. This study contributes to the body of knowledge by offering a pipeline for effective dimensionality reduction of EEG data by employing convolutional variational autoencoders.","2169-3536","","10.1109/ACCESS.2022.3212777","Technological University Dublin, Ireland(grant numbers:PB04433); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9913434","Electroencephalography;convolutional variational autoencoder;latent space;deep learning;frequency bands;spectral topographic maps;and neural networks","Electroencephalography;Brain modeling;Convolutional neural networks;Deep learning;Feature extraction;Encoding;Data models;Neural networks;Frequency bands;Terrain mapping","","","","","","44","CCBY","6 Oct 2022","","","IEEE","IEEE Journals"
"Generative neural network based spectrum sharing using linear sum assignment problems","A. B. Zaky; J. Z. Huang; K. Wu; B. M. ElHalawany","Big Data Institute, Shenzhen University, Shenzhen, China; Big Data Institute, Shenzhen University, Shenzhen, China; Guangdong Laboratory of Artificial Intelligence and Digital Economy, Shenzhen University, Shenzhen, China; Guangdong Laboratory of Artificial Intelligence and Digital Economy, Shenzhen University, Shenzhen, China","China Communications","2 Mar 2020","2020","17","2","14","29","Spectrum management and resource allocation (RA) problems are challenging and critical in a vast number of research areas such as wireless communications and computer networks. The traditional approaches for solving such problems usually consume time and memory, especially for large-size problems. Recently different machine learning approaches have been considered as potential promising techniques for combinatorial optimization problems, especially the generative model of the deep neural networks. In this work, we propose a resource allocation deep autoencoder network, as one of the promising generative models, for enabling spectrum sharing in underlay device-to-device (D2D) communication by solving linear sum assignment problems (LSAPs). Specifically, we investigate the performance of three different architectures for the conditional variational autoencoders (CVAE). The three proposed architecture are the convolutional neural network (CVAE-CNN) autoencoder, the feed-forward neural network (CVAE-FNN) autoencoder, and the hybrid (H-CVAE) autoencoder. The simulation results show that the proposed approach could be used as a replacement of the conventional RA techniques, such as the Hungarian algorithm, due to its ability to find solutions of LASPs of different sizes with high accuracy and very fast execution time. Moreover, the simulation results reveal that the accuracy of the proposed hybrid autoencoder architecture outperforms the other proposed architectures and the state-of-the-art DNN techniques.","1673-5447","","10.23919/JCC.2020.02.002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9020294","autoencoder;linear sum assignment problems;generative models;resource allocation","Device-to-device communication;Wireless communication;Resource management;Computer architecture;Neural networks;Optimization;Machine learning","combinatorial mathematics;convolutional neural nets;learning (artificial intelligence);mobile radio;optimisation;radio spectrum management;resource allocation","generative neural network;hybrid autoencoder architecture;RA techniques;feed-forward neural network;convolutional neural network autoencoder;conditional variational autoencoders;device-to-device communication;spectrum sharing;resource allocation deep autoencoder network;deep neural networks;generative model;combinatorial optimization problems;machine learning approaches;computer networks;wireless communications;linear sum assignment problems","","5","","","","2 Mar 2020","","","IEEE","IEEE Magazines"
"Variational Self-attention Network for Sequential Recommendation","J. Zhao; P. Zhao; L. Zhao; Y. Liu; V. S. Sheng; X. Zhou","School of Computer Science and Technology, Soochow University, Suzhou, China; School of Computer Science and Technology, Soochow University, Suzhou, China; School of Computer Science and Technology, Soochow University, Suzhou, China; Rutgers University, New Jersey, USA; Department of Computer Science, Texas Tech University, Lubbock, USA; The Hong Kong University of Science and Technology, Hong Kong SAR, China","2021 IEEE 37th International Conference on Data Engineering (ICDE)","22 Jun 2021","2021","","","1559","1570","Sequential recommendation has become an attractive topic in recommender systems. Existing sequential recommendation methods, including the methods based on the state-of-the-art self-attention mechanism, usually employ deterministic neural networks to represent user preferences as fixed-points in the latent feature spaces. However, the fixed-point vector lacks the ability to capture the uncertainty and dynamics of user preferences that are prevalent in recommender systems. In this paper, we propose a new Variational Self-Attention Network (VSAN), which introduces a variational autoencoder (VAE) into the self-attention network to capture latent user preferences. Specifically, we represent the obtained self-attention vector as density via variational inference, whose variance well characterizes the uncertainty of user preferences. Furthermore, we employ self-attention networks to learn the inference process and generative process of VAE, which well captures long-range and local dependencies. Finally, we evaluate our proposed method VSAN with two public real-world datasets. Our experimental results show the effectiveness of our model compared to the state-of-the-art approaches.","2375-026X","978-1-7281-9184-3","10.1109/ICDE51399.2021.00138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9458633","variational;attention;sequential recommendation","Uncertainty;Conferences;Neural networks;Data engineering;Recommender systems","data mining;learning (artificial intelligence);neural nets;recommender systems","sequential recommendation methods;state-of-the-art self-attention mechanism;deterministic neural networks;fixed-points;latent feature spaces;fixed-point vector;recommender systems;Variational Self-Attention Network;variational autoencoder;latent user preferences;self-attention vector;variational inference;method VSAN;Variational Self-attention Network;attractive topic","","5","","45","IEEE","22 Jun 2021","","","IEEE","IEEE Conferences"
"Systematic Development of a New Variational Autoencoder Model Based on Uncertain Data for Monitoring Nonlinear Processes","K. Wang; M. G. Forbes; B. Gopaluni; J. Chen; Z. Song","State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China; Honeywell Process Solutions, North Vancouver, BC, Canada; Department of Chemical and Biological Engineering, The University of British Columbia, Vancouver, BC, Canada; Department of Chemical Engineering and Research Center for Circular Economy, Chung Yuan Christian University, Taoyuan, Taiwan; State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China","IEEE Access","28 Feb 2019","2019","7","","22554","22565","Deep learning models have been applied to industrial process fault detection because of their ability to approximate the complex nonlinear behavior. They have been proven to outperform the shallow neural network models. However, there are no good guidelines on how to build these deep models. Therefore, a good deep model is often constructed through a trial-and-error exercise. It is not easy to interpret the model because of features that do not have any physical interpretation. In addition, latent variables (or features) in a deep model are not independent. This causes features to overlap with each other, resulting in challenges in evaluating distributions of features and designing suitable monitoring indices. Finally, typical deep learning models in process monitoring are used in a deterministic manner and do not automatically provide confidence levels for each decision. In this paper, a variational autoencoder is utilized to develop a framework for monitoring uncertain nonlinear processes. The learned latent variables are guaranteed to be independent (or orthogonal) of each other under a specific optimization objective with constraints. The proposed method provides the density estimates of latent variables and residuals instead of point estimates. The density functions are used to design appropriate indices for monitoring. A simulation example and an industrial paper machine example are presented to validate the effectiveness of the proposed method.","2169-3536","","10.1109/ACCESS.2019.2894764","National Natural Science Foundation of China(grant numbers:61833014); Ministry of Science and Technology, Taiwan(grant numbers:MOST 106-2221-E-033-060-MY3); China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643825","Fault detection;latent variables;probability;variational auto-encoder","Monitoring;Kernel;Deep learning;Principal component analysis;Fault detection;Probabilistic logic;Correlation","fault diagnosis;learning (artificial intelligence);neural nets;nonlinear control systems;optimisation;process monitoring;production engineering computing","monitoring uncertain nonlinear processes;learned latent variables;systematic development;new variational autoencoder model;uncertain data;monitoring nonlinear processes;industrial process fault detection;approximate the complex nonlinear behavior;shallow neural network models;good guidelines;good deep model;physical interpretation;designing suitable monitoring indices;typical deep learning models;process monitoring","","27","","30","OAPA","18 Feb 2019","","","IEEE","IEEE Journals"
"A Vector Quantized Variational Autoencoder (VQ-VAE) Autoregressive Neural $F_0$ Model for Statistical Parametric Speech Synthesis","X. Wang; S. Takaki; J. Yamagishi; S. King; K. Tokuda","National Institute of Informatics, Tokyo, Japan; Nagoya Institute of Technology, Nagoya, Japan; Centre for Speech Technology Research, The University of Edinburgh, Edinburgh, U.K.; Centre for Speech Technology Research, The University of Edinburgh, Edinburgh, U.K.; Nagoya Institute of Technology, Nagoya, Japan","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20 Dec 2019","2020","28","","157","170","Recurrent neural networks (RNNs) can predict fundamental frequency (F0) for statistical parametric speech synthesis systems, given linguistic features as input. However, these models assume conditional independence between consecutive F0 values, given the RNN state. In a previous study, we proposed autoregressive (AR) neural F0 models to capture the causal dependency of successive F0 values. In subjective evaluations, a deep AR model (DAR) outperformed an RNN. Here, we propose a Vector Quantized Variational Autoencoder (VQ-VAE) neural F0 model that is both more efficient and more interpretable than the DAR. This model has two stages: one uses the VQ-VAE framework to learn a latent code for the F0 contour of each linguistic unit, and other learns to map from linguistic features to latent codes. In contrast to the DAR and RNN, which process the input linguistic features frame-by-frame, the new model converts one linguistic feature vector into one latent code for each linguistic unit. The new model achieves better objective scores than the DAR, has a smaller memory footprint and is computationally faster. Visualization of the latent codes for phones and moras reveals that each latent code represents an F0 shape for a linguistic unit.","2329-9304","","10.1109/TASLP.2019.2950099","JST CREST, Japan,(grant numbers:JPMJCR18A6); MEXT KAKENHI, Japan,(grant numbers:16H06302,16K16096,17H04687,18H04120,18H04112,18KT0051); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8884734","Fundamental frequency;speech synthesis;neural network;variational auto-encoder","Hidden Markov models;Linguistics;Artificial neural networks;Computational modeling;Frequency synthesizers;Feature extraction;Speech processing","learning (artificial intelligence);recurrent neural nets;speech synthesis;statistical analysis","linguistic unit;latent code;DAR;linguistic feature vector;recurrent neural networks;statistical parametric speech synthesis systems;linguistic features;conditional independence;RNN state;VQ-VAE framework;Vector Quantized Variational Autoencoder","","8","","62","IEEE","28 Oct 2019","","","IEEE","IEEE Journals"
"Heterogeneous Hypergraph Variational Autoencoder for Link Prediction","H. Fan; F. Zhang; Y. Wei; Z. Li; C. Zou; Y. Gao; Q. Dai","School of Computer Science and Technology, Harbin University of Science and Technology, Harbin, China; School of Computer Science and Technology, Harbin University of Science and Technology, Harbin, China; School of Software, BRNist, THUICBS, Tsinghua University, Beijing, China; Fujian Provincial Key Laboratory of Information Processing and Intelligent Control, Minjiang University, Fuzhou, China; Sun Yat-sen University, Guangzhou, China; School of Software, BRNist, THUICBS, Tsinghua University, Beijing, China; Department of Automation, BRNist, THUICBS, Tsinghua University, Beijing, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","1 Jul 2022","2022","44","8","4125","4138","Link prediction aims at inferring missing links or predicting future ones based on the currently observed network. This topic is important for many applications such as social media, bioinformatics and recommendation systems. Most existing methods focus on homogeneous settings and consider only low-order pairwise relations while ignoring either the heterogeneity or high-order complex relations among different types of nodes, which tends to lead to a sub-optimal embedding result. This paper presents a method named Heterogeneous Hypergraph Variational Autoencoder (HeteHG-VAE) for link prediction in heterogeneous information networks (HINs). It first maps a conventional HIN to a heterogeneous hypergraph with a certain kind of semantics to capture both the high-order semantics and complex relations among nodes, while preserving the low-order pairwise topology information of the original HIN. Then, deep latent representations of nodes and hyperedges are learned by a Bayesian deep generative framework from the heterogeneous hypergraph in an unsupervised manner. Moreover, a hyperedge attention module is designed to learn the importance of different types of nodes in each hyperedge. The major merit of HeteHG-VAE lies in its ability of modeling multi-level relations in heterogeneous settings. Extensive experiments on real-world datasets demonstrate the effectiveness and efficiency of the proposed method.","1939-3539","","10.1109/TPAMI.2021.3059313","National Natural Science Foundation of China(grant numbers:U1701262,61972187,61172168); Tsinghua University Initiative Scientific Research Program(grant numbers:20197020003); Natural Science Foundation of Fujian Province(grant numbers:2020J02024); Fuzhou Science and Technology Project(grant numbers:2020-RC-186); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354594","Heterogeneous information network;hypergraph;hyperedge attention;link prediction;variational inference","Semantics;Predictive models;Task analysis;Topology;Stochastic processes;Network topology;Fans","bioinformatics;biology computing;graph theory;information networks;learning (artificial intelligence);network theory (graphs);pattern clustering;recommender systems;social networking (online)","bioinformatics;recommendation systems;low-order pairwise relations while ignoring;Heterogeneous Hypergraph Variational Autoencoder;link prediction;heterogeneous information networks;high-order semantics;complex relations;low-order pairwise topology information;multilevel relations;heterogeneous settings;inferring missing links;predicting future ones;currently observed network","","1","","73","IEEE","15 Feb 2021","","","IEEE","IEEE Journals"
"Speech Dereverberation Using Variational Autoencoders","D. Baby; H. Bourlard",Amazon Alexa; Amazon Alexa,"ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","5784","5788","This paper presents a statistical method for single-channel speech dereverberation using a variational autoencoder (VAE) for modelling the speech spectra. One popular approach for modelling speech spectra is to use non-negative matrix factorization (NMF) where learned clean speech spectral bases are used as a linear generative model for speech spectra. This work replaces this linear model with a powerful nonlinear deep generative model based on VAE. Further, this paper formulates a unified probabilistic generative model of reverberant speech based on Gaussian and Poisson distributions. We develop a Monte Carlo expectation-maximization algorithm for inferring the latent variables in the VAE and estimating the room impulse response for both probabilistic models. Evaluation results show the superiority of the proposed VAE-based models over the NMF-based counterparts.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414736","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414736","speech dereverberation;variational au-toencoders;non-negative matrix factorization","Monte Carlo methods;Conferences;Signal processing algorithms;Speech enhancement;Signal processing;Probabilistic logic;Reverberation","expectation-maximisation algorithm;matrix decomposition;Monte Carlo methods;neural nets;Poisson distribution;reverberation;speech processing","variational autoencoder;statistical method;single-channel speech dereverberation;nonnegative matrix factorization;clean speech spectral bases;linear generative model;nonlinear deep generative model;unified probabilistic generative model;VAE-based models;Poisson distributions;Gaussian distributions;Monte Carlo expectation-maximization algorithm","","","","27","","13 May 2021","","","IEEE","IEEE Conferences"
"Generation of 12-Lead Electrocardiogram with Subject-Specific, Image-Derived Characteristics Using a Conditional Variational Autoencoder","Y. Sang; M. Beetz; V. Grau","Department of Engineering Science, Institute of Biomedical Engineering, University of Oxford, UK; Department of Engineering Science, Institute of Biomedical Engineering, University of Oxford, UK; Department of Engineering Science, Institute of Biomedical Engineering, University of Oxford, UK","2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)","26 Apr 2022","2022","","","1","5","Deep learning models have proven their value in the analysis of electrocardiogram (ECG). Among these, deep generative models have shown their ability in ECG generation. In this paper, we propose a conditional variational autoencoder (cVAE) to automatically generate realistic 12-lead ECG signals. Our method differs from previous papers in that (i) it generates complete 12-lead studies and (ii) generated ECGs can be adjusted to correspond to specific subject characteristics, particularly those from images. We demonstrate the ability of the model to adjust to age, sex and Body Mass Index (BMI) values. Our model is the first to incorporate imaging information by including heart position and orientation as input conditions, to analyse anatomical influences on generated ECG morphology. The network shows high accuracy and sensitivity to different conditions. In addition, our method can extract a ten-dimensional latent space containing interpreted features of the 12 ECG leads, which correspond to interpretable ECG features.","1945-8452","978-1-6654-2923-8","10.1109/ISBI52829.2022.9761431","European Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761431","Variational Auto-encoder;ECG Generation;Heart Position and Orientation","Heart;Deep learning;Analytical models;Sensitivity;Biological system modeling;Morphology;Electrocardiography","electrocardiography;feature extraction;medical signal processing","12-lead electrocardiogram;image-derived characteristics;conditional variational autoencoder;deep learning models;deep generative models;ECG generation;12-lead ECG signals;method differs;12-lead studies;generated ECGs;specific subject characteristics;imaging information;including heart position;input conditions;generated ECG morphology;12 ECG leads;interpretable ECG features","","","","12","IEEE","26 Apr 2022","","","IEEE","IEEE Conferences"
"DCNN Augmentation via Synthetic Data from Variational Autoencoders and Generative Adversarial Networks","D. Kornish; S. Ezekiel; M. Cornacchia","Indiana University of Pennsylvania, Indiana, PA; Indiana University of Pennsylvania, Indiana, PA; Air Force Research Lab, Rome, NY","2018 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)","9 May 2019","2018","","","1","6","Deep convolutional neural networks have recently demonstrated incredible capabilities in areas such as image classification and object detection, but they require large datasets of quality pre-labeled data to achieve high levels of performance. Almost all data is not properly labeled when it is captured, and the process of manually labeling large enough datasets for effective learning is impractical in many real-world applications. New studies have shown that synthetic data, generated from a simulated environment, can be effective training data for DCNNs. However, synthetic data is only as effective as the simulation from which it is gathered, and there is often a significant trade-off between designing a simulation that properly models real-world conditions and simply gathering better real-world data. Using generative network architectures, such as Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), it is possible to produce new synthetic samples based on the features of real-world data. This data can be used to augment small datasets to increase DCNN performance, similar to traditional augmentation methods such as scaling, translation, rotation, and adding noise. In this paper, we compare the advantages of synthetic data from GANs and VAEs to traditional data augmentation techniques. Initial results are promising, indicating that using synthetic data for augmentation can improve the accuracy of DCNN classifiers.","2332-5615","978-1-5386-9306-3","10.1109/AIPR.2018.8707390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8707390","Unsupervised Learning;Autoencoder;Stochastic Weighted Averages;Classifier;DCNN Fusion","Data models;Training;Generative adversarial networks;Convolutional neural networks;Machine learning","convolutional neural nets;pattern classification","synthetic data;convolutional neural networks;quality pre-labeled data;generative network architectures;DCNN augmentation;variational autoencoders;deep convolutional neural networks;generative adversarial networks","","2","","20","","9 May 2019","","","IEEE","IEEE Conferences"
"Contrastive Predictive Coding Supported Factorized Variational Autoencoder For Unsupervised Learning Of Disentangled Speech Representations","J. Ebbers; M. Kuhlmann; T. Cord-Landwehr; R. Haeb-Umbach","Department of Communications Engineering, Paderborn University, Paderborn, Germany; Department of Communications Engineering, Paderborn University, Paderborn, Germany; Department of Communications Engineering, Paderborn University, Paderborn, Germany; Department of Communications Engineering, Paderborn University, Paderborn, Germany","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","3860","3864","In this work we address disentanglement of style and content in speech signals. We propose a fully convolutional variational autoencoder employing two encoders: a content encoder and a style encoder. To foster disentanglement, we propose adversarial contrastive predictive coding. This new disentanglement method does neither need parallel data nor any supervision. We show that the proposed technique is capable of separating speaker and content traits into the two different representations and show competitive speaker-content disentanglement performance compared to other unsupervised approaches. We further demonstrate an increased robustness of the content representation against a train-test mismatch compared to spectral features, when used for phone recognition.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414487","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414487","speech disentanglement;unsupervised learning;contrastive learning;autoencoder","Training;Convolutional codes;Speech coding;Convolution;Conferences;Predictive coding;Robustness","feature extraction;learning (artificial intelligence);source separation;speaker recognition;speech processing;speech recognition;speech synthesis;unsupervised learning","unsupervised learning;disentangled speech representations;speech signals;fully convolutional variational autoencoder;encoders;content encoder;style encoder;adversarial contrastive predictive coding;disentanglement method;content traits;competitive speaker-content disentanglement performance;unsupervised approaches;content representation","","2","","26","","13 May 2021","","","IEEE","IEEE Conferences"
"PRVNet: A Novel Partially-Regularized Variational Autoencoders for Massive MIMO CSI Feedback","M. Hussien; K. K. Nguyen; M. Cheriet","Information Technology Department, Assiut University, Egypt; École de technologie supérieure (ÉTS), Univeristy of Québec, Canada; École de technologie supérieure (ÉTS), Univeristy of Québec, Canada","2022 IEEE Wireless Communications and Networking Conference (WCNC)","16 May 2022","2022","","","2286","2291","In a multiple-input multiple-output frequency-division duplexing (MIMO-FDD) system, the user equipment (UE) sends the downlink channel state information (CSI) to the base station to report link status. Due to the complexity of MIMO systems, the overhead incurred in sending this information negatively affects the system bandwidth. Although this problem has been widely considered in the literature, prior work generally assumes an ideal feedback channel. In this paper, we introduce PRVNet, a neural network architecture inspired by variational autoencoders (VAE) to compress the CSI matrix before sending it back to the base station under noisy channel conditions. Moreover, we propose a customized loss function that best suits the special characteristics of the problem being addressed. We also introduce an additional regularization hyperparameter for the learning objective, which is crucial for achieving competitive performance. In addition, we provide an efficient way to tune this hyperparameter using KL-annealing. Experimental results show the proposed model outperforms the benchmark models including two deep learning-based models in a noise-free feedback channel assumption. In addition, the proposed model achieves an outstanding performance under different noise levels for additive white Gaussian noise feedback channels.","1558-2612","978-1-6654-4266-4","10.1109/WCNC51071.2022.9771642","Mitacs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9771642","MIMO-OFDM;CSI Feedback;Autoencoders","Deep learning;Base stations;Conferences;Neural networks;Massive MIMO;Downlink;MIMO","AWGN channels;deep learning (artificial intelligence);feedback;frequency division multiplexing;MIMO communication;telecommunication computing;wireless channels","PRVNet;massive MIMO CSI feedback;multiple-output frequency-division duplexing;MIMO-FDD;user equipment;downlink channel state information;base station;link status;ideal feedback channel;neural network architecture;CSI matrix;noisy channel conditions;customized loss function;regularization hyperparameter;learning objective;deep learning-based models;noise-free feedback channel assumption;additive white Gaussian noise feedback channels;partially-regularized variational autoencoders;KL-annealing","","","","19","IEEE","16 May 2022","","","IEEE","IEEE Conferences"
"Exploiting Linear Interpolation of Variational Autoencoders for Satisfying Preferences in Evolutionary Design Optimization","S. Saha; L. L. Minku; X. Yao; B. Senhoff; S. Menzel","Honda Research Institute Europe GmbH, Offenbach, Germany; School of Computer Science, University of Birmingham, Birmingham, UK; Department of Computer Science and Engineering, SUSTech, China; Honda Research Institute Europe GmbH, Offenbach, Germany; Honda Research Institute Europe GmbH, Offenbach, Germany","2021 IEEE Congress on Evolutionary Computation (CEC)","9 Aug 2021","2021","","","1767","1776","In the early design phase of automotive digital development, one of the key challenges for the designer is to consider multiple-criteria like aerodynamics and structural efficiency besides aesthetic aspects for designing a car shape. In our research, we imagine a cooperative design system in the automotive domain which provides guidance to the designer for finding sets of design options or well-performing designs for preferred search areas. In the present paper, we focus on two perspectives for this multi-criteria decision-making problem: First, a scenario without prior information about design preferences, where the designer aims to explore the search space for a diverse set of design alternatives. Second, a scenario where the designer has a prior intuition on preferred solutions of interest. For both scenarios, we assume that historic 3D car shape data exists, which we can utilize to learn a compact low-dimensional design representation based on a variational autoencoder (VAE). In contrast to evolutionary multi-objective optimization approaches where starting populations are randomly initialized, we propose to seed the population more efficiently by exploiting the advantage of linear interpolation in the latent space of the VAE. In our experiments, we demonstrate that the multi-objective optimization converges faster and achieves a diverse set of solutions. For the second scenario, when specifying design preferences by weights, we improve on the weighted-sum method, which simplifies the multi-objective problem and propose a strategy for efficiently adapting the weights towards the preferred design solution.","","978-1-7281-8393-0","10.1109/CEC45853.2021.9504772","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9504772","multi-objective optimization;preference formulation;autoencoders","Interpolation;Three-dimensional displays;Shape;Sociology;Search problems;Space exploration;Automobiles","aerodynamics;automotive engineering;design engineering;evolutionary computation;optimisation;product development","multicriteria decision-making problem;car shape;compact low-dimensional design representation;variational autoencoder;evolutionary multiobjective optimization;linear interpolation;evolutionary design optimization;design system;design options;automotive digital development","","","","37","IEEE","9 Aug 2021","","","IEEE","IEEE Conferences"
"Variational Autoencoder and Joint Recurrence plot based automated condition monitoring in the context of wire manufacturing in the Philippines","E. Gatmaitan; D. Lagazo; J. De Vera; A. Coronel; J. Jimenez","Department of Information Systems and Computer Science, Ateneo de Manila University, Quezon City, Philippines; Department of Information Systems and Computer Science, Ateneo de Manila University, Quezon City, Philippines; Department of Information Systems and Computer Science, Ateneo de Manila University, Quezon City, Philippines; Department of Information Systems and Computer Science, Ateneo de Manila University, Quezon City, Philippines; Department of Information Systems and Computer Science, Ateneo de Manila University, Quezon City, Philippines","2021 IEEE Western New York Image and Signal Processing Workshop (WNYISPW)","30 Dec 2021","2021","","","1","6","AI and Machine Learning have become ubiquitous in many industries. Automated condition monitoring is a popular application for AI, and has been widely studied in recent years. This study provides a case for the usage of a Variational Autoencoder based approach for automated condition monitoring based on vibration data from accelerometers. We show that when trained in a semi-supervised manner, even with limited data, the VAE latent space is able to distinguish between normal and idle machine activity. We also show that the VAE is able to learn to group data from similar sensors together in latent space, even without a sensor label provided during training. We explore the applicability of Joint Recurrence Plots as a image representation of accelerometer data for fault diagnostic applications.","2471-9242","978-1-6654-3630-4","10.1109/WNYISPW53194.2021.9661283","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9661283","Varational Autoencoder;Automated Condition Monitoring;Anomaly Detection;Joint Recurrence Plot;Vibration","Condition monitoring;Vibrations;Accelerometers;Training;Industries;Wires;Machine learning","accelerometers;condition monitoring;fault diagnosis;image representation;learning (artificial intelligence);neural nets;production engineering computing;vibrations;wires (electric)","condition monitoring;normal machine activity;idle machine activity;joint recurrence plots;AI;machine learning;variational autoencoder;wire manufacturing;Philippines;VAE latent space;image representation;accelerometer data;fault diagnosis;vibration data","","","","19","IEEE","30 Dec 2021","","","IEEE","IEEE Conferences"
"Multi-Decoder RNN Autoencoder Based on Variational Bayes Method","D. Kaji; K. Watanabe; M. Kobayashi","AI R & D Division, Denso Corporation, Tokyo, Japan; Dept. of CSE, Toyohashi University of Technology, Aichi, Japan; Dept. of CSE, Toyohashi University of Technology, Aichi, Japan","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","8","Clustering algorithms have wide applications and play an important role in data analysis fields including time series data analysis. However, in time series analysis, most of the algorithms used signal shape features or the initial value of hidden variable of a neural network. Little has been discussed on the methods based on the generative model of the time series. In this paper, we propose a new clustering algorithm focusing on the generative process of the signal with a recurrent neural network and the variational Bayes method. Our experiments show that the proposed algorithm not only has a robustness against for phase shift, amplitude and signal length variations but also provide a flexible clustering based on the property of the variational Bayes method.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9206686","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206686","Time series analysis;Clustering;Recurrent neural network;Variational Bayes","Time series analysis;Clustering algorithms;Decoding;Feature extraction;Recurrent neural networks;Heuristic algorithms","Bayes methods;data analysis;pattern clustering;recurrent neural nets;time series","multidecoder RNN autoencoder;variational Bayes method;clustering algorithm;time series data analysis;signal shape features;generative model;recurrent neural network;flexible clustering","","1","","32","","28 Sep 2020","","","IEEE","IEEE Conferences"
"Oversampling Highly Imbalanced Indoor Positioning Data using Deep Generative Models","F. Alhomayani; M. H. Mahoor","Department of Electrical and Computer Engineering, University of Denver, Denver, USA; Department of Electrical and Computer Engineering, University of Denver, Denver, USA","2021 IEEE Sensors","17 Dec 2021","2021","","","1","4","The location fingerprinting method, which typically utilizes supervised learning, has been widely adopted as a viable solution for the indoor positioning problem. Many indoor positioning datasets are imbalanced. Models trained on imbalanced datasets may exhibit poor performance on the minority class(es). This problem, also known as the ""curse of imbalanced data,"" becomes more evident when class distributions are highly imbalanced. Motivated by the recent advances in deep generative modeling, this paper proposes using Variational Autoencoders and Conditional Variational Autoencoders as oversampling tools to produce class-balanced fingerprints. Experimental results based on Bluetooth Low Energy fingerprints demonstrate that the proposed method outperforms SMOTE and ADASYN in both minority class precision and overall precision. To promote reproducibility and foster new research efforts, we made all the codes associated with this work publicly available.","2168-9229","978-1-7281-9501-8","10.1109/SENSORS47087.2021.9639241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9639241","ADASYN;Bluetooth Low Energy;Conditional Variational Autoencoders;Imbalanced Data;Indoor Positioning;Location Fingerprints;Oversampling;Recurrence Plots;SMOTE;Variational Autoencoders","Codes;Bluetooth;Supervised learning;Fingerprint recognition;Reproducibility of results;Data models;Sensors","Bluetooth;learning (artificial intelligence);pattern classification;sampling methods","supervised learning;indoor positioning problem;indoor positioning datasets;imbalanced datasets;imbalanced data;class distributions;deep generative modeling;Conditional Variational Autoencoders;oversampling tools;class-balanced fingerprints;Bluetooth Low Energy fingerprints;minority class precision;highly imbalanced indoor positioning data;deep generative models;location fingerprinting method","","","","38","IEEE","17 Dec 2021","","","IEEE","IEEE Conferences"
"An Autoencoder-based Approach for Recognizing Null Class in Activities of Daily Living In-the-wild via Wearable Motion Sensors","A. Akbari; R. Jafari","Department of Biomedical Engineering, Texas A&M University; Department of Electrical and Computer Engineering, Texas A&M University","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","3392","3396","Recognizing activities of daily living (ADL) in-the-wild, while users follow their daily routine, is challenging due to the presence of various activities that do not belong to the set of desired activities in which the system is interested (i.e., NULL class). In this paper, we propose a framework for ADL recognition via wearable motion sensors with the ability to detect NULL class. Existing ADL recognition systems either ignore the NULL class or use some training data to train a model for recognizing it. However, our framework uses only samples of the desired activities in the training phase and learns to detect the NULL samples based on a modified variational autoencoder model that outputs reconstruction probability. Experimental results show that in detecting six ADL with accelerometer data, our system achieves 14% higher F1-score compared to the models that use training samples of NULL activities.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682161","Wearable motion sensor;ADL recognition;variational autoencoder;NULL class detection","Mathematical model;Training;Feature extraction;Training data;Motion detection;Decoding;Data models","accelerometers;motion sensors","daily routine;wearable motion sensors;ADL recognition systems;NULL samples;modified variational autoencoder model;NULL activities;autoencoder-based approach;daily living;NULL class","","4","","19","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Fast mesh denoising with data driven normal filtering using deep autoencoders","S. Nousias; G. Arvanitis; A. S. Lalos; K. Moustakas","Department of Electrical & Computer Engineering, University of Patras, Greece; Department of Electrical & Computer Engineering, University of Patras, Greece; Industrial Systems Institute, Athena Research Center; Department of Electrical & Computer Engineering, University of Patras, Greece","2019 IEEE 17th International Conference on Industrial Informatics (INDIN)","30 Jan 2020","2019","1","","260","263","Through the years, several works have demonstrated high-quality 3D mesh denoising. Despite the high reconstruction quality, there are still challenges that need to be addressed ranging from variations in configuration parameters to high computational complexity. These drawbacks are crucial especially if the reconstructed models have to be used for quality check, inspection or repair in manufacturing environments where we have to deal with large objects resulting in very dense 3D meshes. Recently, deep learning techniques have shown that are able to automatically learn and find more accurate and reliable results, without the need for setting manually parameters. In this work, motivated by the aforementioned requirements, we propose a fast and reliable denoising method that can be effectively applied for reconstructing very dense noisy 3D models. The proposed method applies conditional variational autoencoders on face normals. Extensive evaluation studies carried out using a variety of 3D models verify that the proposed approach achieves plausible reconstruction outputs, very relative or even better of those proposed by the literature, in considerably faster execution times.","2378-363X","978-1-7281-2927-3","10.1109/INDIN41052.2019.8972221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8972221","3D mesh denoising;data driven normal filtering;variational autoencoders.","","image denoising;image filtering;image reconstruction;learning (artificial intelligence);neural nets","deep autoencoders;high-quality 3D mesh denoising;high reconstruction quality;configuration parameters;high computational complexity;reconstructed models;quality check;manufacturing environments;deep learning techniques;reliable denoising method;conditional variational autoencoders;face normals;plausible reconstruction;very dense noisy 3D models;very dense 3D meshes;data driven normal filtering;fast mesh denoising","","2","","32","","30 Jan 2020","","","IEEE","IEEE Conferences"
"Data augmentation and feature extraction using variational autoencoder for acoustic modeling","H. Nishizaki","The Graduate School of Interdisciplinary Research, University of Yamanashi, Kofu, Japan","2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","8 Feb 2018","2017","","","1222","1227","A data augmentation and feature extraction method using a variational autoencoder (VAE) for acoustic modeling is described. A VAE is a generative model based on variational Bayesian learning using a deep learning framework. A VAE can extract latent values its input variables to generate new information. VAEs are widely used to generate pictures and sentences. In this paper, a VAE is applied to speech corpus data augmentation and feature vector extraction from speech for acoustic modeling. First, the size of a speech corpus is doubled by encoding latent variables extracted from original utterances using a VAE framework. The latent variables extracted from speech waveforms have latent ""meanings"" of the waveforms. Therefore, latent variables can be used as acoustic features for automatic speech recognition (ASR). This paper experimentally shows the effectiveness of data augmentation using a VAE framework and that latent variable-based features can be utilized in ASR.","","978-1-5386-1542-3","10.1109/APSIPA.2017.8282225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8282225","","Speech;Acoustics;Decoding;Feature extraction;Training;Image reconstruction;Task analysis","Bayes methods;feature extraction;learning (artificial intelligence);speech recognition","acoustic modeling;feature extraction method;variational autoencoder;variational Bayesian learning;deep learning framework;speech corpus data augmentation;VAE framework;speech waveforms;acoustic features;automatic speech recognition","","21","","23","","8 Feb 2018","","","IEEE","IEEE Conferences"
"Unsupervised Linear and Nonlinear Channel Equalization and Decoding Using Variational Autoencoders","A. Caciularu; D. Burshtein","Department of Computer Science, Bar-Ilan University, Ramat Gan, Israel; School of Electrical Engineering, Tel Aviv University, Tel Aviv, Israel","IEEE Transactions on Cognitive Communications and Networking","9 Sep 2020","2020","6","3","1003","1018","A new approach for blind channel equalization and decoding, variational inference, and variational autoencoders (VAEs) in particular, is introduced. We first consider the reconstruction of uncoded data symbols transmitted over a noisy linear intersymbol interference (ISI) channel, with an unknown impulse response, without using pilot symbols. We derive an approximate maximum likelihood estimate to the channel parameters and reconstruct the transmitted data. We demonstrate significant and consistent improvements in the error rate of the reconstructed symbols, compared to existing blind equalization methods such as constant modulus, thus enabling faster channel acquisition. The VAE equalizer uses a convolutional neural network with a small number of free parameters. These results are extended to blind equalization over a noisy nonlinear ISI channel with unknown parameters. We then consider coded communication using low-density parity-check (LDPC) codes transmitted over a noisy linear or nonlinear ISI channel. The goal is to reconstruct the transmitted message from the channel observations corresponding to a transmitted codeword, without using pilot symbols. We demonstrate improvements compared to the expectation maximization (EM) algorithm using turbo equalization. Furthermore, unlike EM, the computational complexity of our method does not have exponential dependence on the size of the channel impulse response.","2332-7731","","10.1109/TCCN.2020.2990773","Israel Science Foundation(grant numbers:1868/18); Yitzhak and Chaya Weinstein Research Institute for Signal Processing; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9080094","Blind equalizers;maximum likelihood estimation;deep learning;convolutional neural networks;belief propagation","Blind equalizers;Noise measurement;Maximum likelihood decoding;Modulation;Maximum likelihood estimation;Deep learning","blind equalisers;channel estimation;computational complexity;decoding;equalisers;intersymbol interference;maximum likelihood estimation;parity check codes;transient response;turbo codes","channel impulse response;variational inference;variational autoencoders;uncoded data symbols;noisy linear intersymbol interference;unknown impulse response;pilot symbols;approximate maximum likelihood estimate;channel parameters;transmitted data;reconstructed symbols;existing blind equalization methods;faster channel acquisition;VAE equalizer;noisy nonlinear ISI channel;unknown parameters;low-density parity-check codes;transmitted message;channel observations;transmitted codeword;turbo equalization","","16","","60","IEEE","28 Apr 2020","","","IEEE","IEEE Journals"
"Multi-adversarial Variational Autoencoder Networks","A. -A. -Z. Imran; D. Terzopoulos","Computer Science Department, University of California, Los Angeles, USA; Computer Science Department, University of California, Los Angeles, USA","2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)","17 Feb 2020","2019","","","777","782","The unsupervised training of GANs and VAEs has enabled them to generate realistic images mimicking real-world distributions and perform unsupervised clustering or semi-supervised classification of images. Combining the power of these two generative models, we introduce a novel network architecture, Multi-Adversarial Variational autoEncoder Networks (MAVENs), which incorporate an ensemble of discriminators in a combined VAE-GAN network, with simultaneous adversarial learning and variational inference. We apply MAVENs to the generation of synthetic images and propose a new distribution measure to evaluate the quality of the generated images. Our experimental results using the computer vision datasets SVHN and CIFAR-10 demonstrate competitive performance against state-of-the-art semi-supervised models both in image generation and classification tasks.","","978-1-7281-4550-1","10.1109/ICMLA.2019.00137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8999307","Deep-generative-models,-GANs,-VAEs,-semi-supervised-learning,-image-classification,-image-generation","Gallium nitride;Training;Data models;Generators;Image generation;Computational modeling;Supervised learning","computer vision;image classification;inference mechanisms;learning (artificial intelligence);pattern clustering","multiadversarial variational autoencoder networks;unsupervised training;generative models;network architecture;VAE-GAN network;simultaneous adversarial learning;variational inference;image generation","","3","","16","","17 Feb 2020","","","IEEE","IEEE Conferences"
"Patch Variational Autoencoder-based Industrial Defect Detection","Y. Yang; J. Mao; Y. Wang; H. Zhang; X. Zhou; Y. Chen","National Engineering Research Center of Robot Vision Perception and Control Technology, Hunan University, Changsha, China; National Engineering Research Center of Robot Vision Perception and Control Technology, Hunan University, Changsha, China; National Engineering Research Center of Robot Vision Perception and Control Technology, Hunan University, Changsha, China; National Engineering Research Center of Robot Vision Perception and Control Technology, Hunan University, Changsha, China; National Engineering Research Center of Robot Vision Perception and Control Technology, Hunan University, Changsha, China; National Engineering Research Center of Robot Vision Perception and Control Technology, Hunan University, Changsha, China","2022 13th Asian Control Conference (ASCC)","20 Jul 2022","2022","","","674","677","Anomaly detection occupies an important position in the field of industrial automation and manufacturing intelligence. This paper aims to alleviate two of the inherent problems in variational inference-based anomaly analysis. One of the problems is the information obtained from prior latent distribution is limited, and the other one is the feature collapse phenomenon caused by the strong probability distance notion. In this paper, a patch variational autoencoder architecture with jigsaw puzzle solving is proposed, which is able to increase the expressiveness of the latent manifold. And we introduce a sliced-Wasserstein measure to solve the second problem. There is a superior performance on the MVTec AD datasets.","2770-8373","978-89-93215-23-6","10.23919/ASCC56756.2022.9828054","National Natural Science Foundation of China; China Postdoctoral Science Foundation; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9828054","Anomaly detection;Variation inference;Patch Distribution Modelling","Manifolds;Automation;Benchmark testing;Feature extraction;Robustness;Inference algorithms;Data models","computer vision;data handling;factory automation;feature extraction;intelligent manufacturing systems;neural nets;probability;production engineering computing","industrial defect detection;anomaly detection;industrial automation;manufacturing intelligence;variational inference;feature collapse phenomenon;patch variational autoencoder architecture;anomaly analysis;jigsaw puzzle;probability distance notion;sliced-Wasserstein measure;MVTec AD datasets","","","","19","","20 Jul 2022","","","IEEE","IEEE Conferences"
"Rethinking Controllable Variational Autoencoders","H. Shao; Y. Yang; H. Lin; L. Lin; Y. Chen; Q. Yang; H. Zhao",College of Willam and Mary; Zhejiang University; Carnegie Mellon University; Zhejiang University; Zhejiang University; Zhejiang University; University of Illinois at Urbana-Champaign,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","19228","19237","The Controllable Variational Autoencoder (ControlVAE) combines automatic control theory with the basic VAE model to manipulate the KL-divergence for overcoming posterior collapse and learning disentangled representations. It has shown success in a variety of applications, such as image generation, disentangled representation learning, and language modeling. However, when it comes to disentangled representation learning, ControlVAE does not delve into the rationale behind it. The goal of this paper is to develop a deeper understanding of ControlVAE in learning disentangled representations, including the choice of a desired KL-divergence (i.e, set point), and its stability during training. We first fundamentally explain its ability to disentangle latent variables from an information bottleneck perspective. We show that KL-divergence is an upper bound of the variational information bottleneck. By controlling the KL-divergence gradually from a small value to a target value, ControlVAE can disentangle the latent factors one by one. Based on this finding, we propose a new DynamicVAE that leverages a modified incremental PI (proportionalintegral) controller, a variant of the proportional-integralderivative (PID) algorithm, and employs a moving average as well as a hybrid annealing method to evolve the value of KL-divergence smoothly in a tightly controlled fashion. In addition, we analytically derive a lower bound of the set point for disentangling. We then theoretically prove the stability of the proposed approach. Evaluation results on multiple benchmark datasets demonstrate that DynamicVAE achieves a good trade-off between the disentanglement and reconstruction quality. We also discover that it can separate disentangled representation learning and re-construction via manipulating the desired KL-divergence.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01865","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879937","Representation learning; Explainable computer vision; Machine learning","Representation learning;Training;Annealing;Upper bound;PI control;Image synthesis;Stability analysis","control engineering computing;learning (artificial intelligence);PI control;simulated annealing;three-term control","set point;disentangling;disentanglement;reconstruction quality;desired KL-divergence;ControlVAE;automatic control theory;basic VAE model;posterior collapse;disentangled representation learning;language modeling;information bottleneck perspective;variational information bottleneck;modified incremental PI controller;tightly controlled fashion;controllable variational autoencoders","","","","49","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Language/Dialect Recognition Based on Unsupervised Deep Learning","Q. Zhang; J. H. L. Hansen","Center for Robust Speech Systems, Erik Jonsson School of Engineering University of Texas at Dallas, Richardson, TX, USA; Center for Robust Speech Systems, Erik Jonsson School of Engineering University of Texas at Dallas, Richardson, TX, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","15 Mar 2018","2018","26","5","873","882","Over the past decade, bottleneck features within an i-Vector framework have been used for state-of-the-art language/dialect identification (LID/DID). However, traditional bottleneck feature extraction requires additional transcribed speech information. Alternatively, two types of unsupervised deep learning methods are introduced in this study. To address this limitation, an unsupervised bottleneck feature extraction approach is proposed, which is derived from the traditional bottleneck structure but trained with estimated phonetic labels. In addition, based on a generative modeling autoencoder, two types of latent variable learning algorithms are introduced for speech feature processing, which have been previous considered for image processing/reconstruction. Specifically, a variational autoencoder and adversarial autoencoder are utilized on alternative phase of speech processing. To demonstrate the effectiveness of the proposed methods, three corpora are evaluated: 1) a four Chinese dialect dataset, 2) a five Arabic dialect corpus, and 3) multigenre broadcast challenge corpus (MGB-3) for arabic DID. The proposed features are shown to outperform traditional acoustic feature MFCCs consistently across three corpora. Taken collectively, the proposed features achieve up to a relative +58% improvement in Cavg for LID/DID without the need of any secondary speech corpora.","2329-9304","","10.1109/TASLP.2018.2797420","Air Force Research Laboratory(grant numbers:FA8750-15-1-0205); University of Texas at Dallas from the Distinguished University Chair in Telecommunications Engineering held by J. H. L. Hansen; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268099","Language/Dialect recognition;unsupervised learning;variational autoencoder;adversarial autoencoder;bottleneck feature;phonetic label estimation","Feature extraction;Acoustics;Speech;Training;Hidden Markov models;Speech processing;Speech recognition","feature extraction;natural language processing;speech coding;speech recognition;unsupervised learning","additional transcribed speech information;unsupervised deep learning methods;unsupervised bottleneck feature extraction approach;estimated phonetic labels;generative modeling autoencoder;latent variable learning algorithms;speech feature processing;variational autoencoder;adversarial autoencoder;speech processing;Arabic dialect corpus;i-Vector framework;state-of-the-art language/dialect;feature extraction;dialect recognition","","23","","36","IEEE","24 Jan 2018","","","IEEE","IEEE Journals"
"Attentional Adversarial Variational Video Generation via Decomposing Motion and Content","S. Talafha; B. Rekabdar; C. P. Ekenna; C. Mousas","Department of Computer Science, Southern Illinois University, Illinois, USA; Department of Computer Science, Southern Illinois University, Illinois, USA; Department of Computer Science, University at Albany, New York, USA; Department of Computer Graphics Technology, Purdue University, Indiana, USA","2020 IEEE 14th International Conference on Semantic Computing (ICSC)","12 Mar 2020","2020","","","45","52","Predicting future frames sequentially for a video is considered a challenging generative modeling task. Our work is among the few works for complete video generation. A video is about objects (content) performing actions (motion). Based on this, we utilize paired inputs including human skeleton information as motion embedding and a human appearance image as the content information, to generate novel motion frames. Our approach is based on a video prediction model using a combination of the Variational Autoencoder and Generative Adversarial Network (VAE-GAN). On top of that, we applied two attentional mechanisms to obtain the important regions of interest in a video, aimed at improving the visual representation of the human motion in the generated output. To evaluate the performance of the proposed method, we conduct quantitative and qualitative experiments including comparisons with state-of-the-arts. As the result of experiments suggest, the proposed method shows improved performance in comparison with other widely used methods and performs favorably under the metrics PSNR, SSIM, LPIPS, and FVD on Human3.6M dataset.","2325-6516","978-1-7281-6332-1","10.1109/ICSC.2020.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9031476","Deep learning;Generative Adversarial Network (GAN);Variational Autoencoder (VAE);Video Generation;Attention Mechanisms","Gallium nitride;Predictive models;Skeleton;Generative adversarial networks;Visualization;Task analysis;Training","decomposition;image coding;image motion analysis;image representation","FVD;LPIPS;SSIM;PSNR;variational autoencoder and generative adversarial network;VAE-GAN;human motion frame decomposition;human appearance imaging;attentional adversarial variational video generation mechanisms;video prediction model;content information;motion embedding;human skeleton information;generative modeling task;Human3.6M dataset","","2","","34","","12 Mar 2020","","","IEEE","IEEE Conferences"
"Deep Variational Filter Learning Models for Speech Recognition","P. Agrawal; S. Ganapathy","Learning and Extraction of Acoustic Patterns (LEAP) lab, Electrical Engineering, Indian Institute of Science, Bangalore, India; Learning and Extraction of Acoustic Patterns (LEAP) lab, Electrical Engineering, Indian Institute of Science, Bangalore, India","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","5731","5735","We present a novel approach to derive robust speech representations for automatic speech recognition (ASR) systems. The proposed method uses an unsupervised data-driven modulation filter learning approach that preserves the key modulations of speech signal in spectro-temporal domain. This is achieved by a deep generative modeling framework to learn modulation filters using convolutional variational autoencoder (CVAE). A skip connection based CVAE enables the learning of multiple irredundant modulation filters in the time and frequency modulation domain using temporal and spectral trajectories of input spectrograms. The learnt filters are used to process the spectrogram features for ASR training. The ASR experiments are performed on Aurora-4 (additive noise with channel artifact) and CHiME-3 (additive noise with reverberation) databases. The results show significant improvements for the proposed CVAE model over the baseline features as well as other robust front-ends (average relative improvements of 9% in word error rate over baseline features on Aurora-4 database and 23% on CHiME-3 database). In addition, the performance of the proposed features is highly beneficial for semi-supervised training of ASR when reduced amounts of labeled training data are available (average relative improvements of 29% over baseline features on Aurora-4 database with 30% of the labeled training data).","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682520","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682520","Unsupervised filter learning;Convolutional variational autoencoder;skip connections;modulation filtering;robust speech recognition","Modulation;Spectrogram;Convolution;Training;Databases;Kernel;Decoding","feature extraction;filtering theory;learning (artificial intelligence);neural nets;speech recognition;time-frequency analysis","time domain;skip connection based CVAE;deep variational filter learning models;semi-supervised training;labeled training data;CHiME-3 database;Aurora-4 database;robust front-ends;baseline features;CVAE model;additive noise;ASR experiments;ASR training;spectrogram features;learnt filters;input spectrograms;spectral trajectories;temporal trajectories;frequency modulation domain;multiple irredundant modulation filters;convolutional variational autoencoder;deep generative modeling framework;spectro-temporal domain;speech signal;key modulations;unsupervised data-driven modulation filter learning;automatic speech recognition systems;robust speech representations","","2","","24","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Learning Audio-Visual Correlations From Variational Cross-Modal Generation","Y. Zhu; Y. Wu; H. Latapie; Y. Yang; Y. Yan","Illinois Institute of Technology, USA; ReLER, University of Technology Sydney, Australia; Cisco, USA; ReLER, University of Technology Sydney, Australia; Illinois Institute of Technology, USA","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","4300","4304","People can easily imagine the potential sound while seeing an event. This natural synchronization between audio and visual signals reveals their intrinsic correlations. To this end, we propose to learn the audio-visual correlations from the perspective of cross-modal generation in a self-supervised manner, the learned correlations can be then readily applied in multiple downstream tasks such as the audio-visual cross-modal localization and retrieval. We introduce a novel Variational AutoEncoder (VAE) framework that consists of Multiple encoders and a Shared decoder (MS-VAE) with an additional Wasserstein distance constraint to tackle the problem. Extensive experiments demonstrate that the optimized latent representation of the proposed MS-VAE can effectively learn the audio-visual correlations and can be readily applied in multiple audio-visual downstream tasks to achieve competitive performance even without any given label information during training.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414296","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414296","Audio-visual correlations;Variational autoencoder;Cross-modal generation","Training;Location awareness;Visualization;Correlation;Conferences;Signal processing;Decoding","audio signal processing;audio-visual systems;decoding;feature extraction;learning (artificial intelligence)","audio-visual correlations;Variational cross-modal generation;audio signals;visual signals;intrinsic correlations;learned correlations;audio-visual cross-modal localization;novel Variational AutoEncoder framework;MS-VAE;audio-visual downstream tasks","","1","","28","IEEE","13 May 2021","","","IEEE","IEEE Conferences"
"Learning and Adaptation for Millimeter-Wave Beam Tracking and Training: A Dual Timescale Variational Framework","M. Hussain; N. Michelusi","School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA","IEEE Journal on Selected Areas in Communications","17 Dec 2021","2022","40","1","37","53","Millimeter-wave vehicular networks incur enormous beam-training overhead to enable narrow-beam communications. This paper proposes a learning and adaptation framework in which the dynamics of the communication beams are learned and then exploited to design adaptive beam-tracking and training with low overhead: on a long-timescale, a deep recurrent variational autoencoder (DR-VAE) uses noisy beam-training feedback to learn a probabilistic model of beam dynamics and enable predictive beam-tracking; on a short-timescale, an adaptive beam-training procedure is formulated as a partially observable (PO-) Markov decision process (MDP) and optimized via point-based value iteration (PBVI) by leveraging beam-training feedback and a probabilistic prediction of the strongest beam pair provided by the DR-VAE. In turn, beam-training feedback is used to refine the DR-VAE via stochastic gradient ascent in a continuous process of learning and adaptation. The proposed DR-VAE learning framework learns accurate beam dynamics: it reduces the Kullback-Leibler divergence between the ground truth and the learned model of beam dynamics by ~95% over the Baum-Welch algorithm and a naive learning approach that neglects feedback errors. Numerical results on a line-of-sight scenario with multipath and 3D beamforming reveal that the proposed dual timescale approach yields near-optimal spectral efficiency, and improves it by 130% over a policy that scans exhaustively over the dominant beam pairs, and by 20% over a state-of-the-art POMDP policy. Finally, a low-complexity policy is proposed by reducing the POMDP to an error-robust MDP, and is shown to perform well in regimes with infrequent feedback errors.","1558-0008","","10.1109/JSAC.2021.3126086","National Science Foundation(grant numbers:CNS-1642982,CNS-2129015); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9605254","Millimeter-wave (mm-wave);beam alignment;beam tracking;point-based value iteration (PBVI);deep recurrent variational autoencoders (DR-VAEs)","Vehicle dynamics;Array signal processing;Training;Adaptation models;Antenna arrays;Three-dimensional displays;Probabilistic logic","array signal processing;deep learning (artificial intelligence);gradient methods;iterative methods;Markov processes;telecommunication computing","learning adaptation;millimeter-wave beam tracking;dual timescale variational framework;millimeter-wave vehicular networks;enormous beam-training overhead;narrow-beam communications;adaptation framework;communication beams;adaptive beam-tracking;long-timescale;deep recurrent variational autoencoder;noisy beam-training feedback;predictive beam-tracking;short-timescale;adaptive beam-training procedure;leveraging beam-training feedback;probabilistic prediction;strongest beam pair;DR-VAE learning framework;accurate beam dynamics;naive learning approach;dual timescale approach;dominant beam pairs;infrequent feedback errors;near-optimal spectral efficiency;millimeter-wave beam training;Markov decision process;point-based value iteration;beam-training feedback;stochastic gradient ascent;Kullback-Leibler divergence;Baum-Welch algorithm;line-of-sight scenario;3D beamforming;POMDP policy;low-complexity policy;error-robust MDP","","","","36","IEEE","8 Nov 2021","","","IEEE","IEEE Journals"
"Playing Technique Classification Based on Deep Collaborative Learning of Variational Auto-Encoder and Gaussian Process","S. -H. Chen; Y. -S. Lee; M. -C. Hsieh; J. -C. Wang","Dept. of Computer Science and Information Engineering, National Central University, Taiwan; Dept. of Computer Science and Information Engineering, National Central University, Taiwan; Dept. of Computer Science and Information Engineering, National Central University, Taiwan; Dept. of Computer Science and Information Engineering, National Central University, Taiwan","2018 IEEE International Conference on Multimedia and Expo (ICME)","11 Oct 2018","2018","","","1","6","Modeling musical timbre is critical for various music information retrieval (MIR) tasks. This work addresses the task of classifying playing techniques, which involves extremely subtle variations of timbre among different categories. A deep collaborative learning framework is proposed to represent a music with greater discriminative power than previously achieved. Firstly, a novel variational autoencoder (VAE) is developed to eliminate the variation of acoustic features within a class. Secondly, a Gaussian process classifier is jointly learned to distinguish the variations of timbres between classes, which increases the discriminative power of the learned representations. We derive a new lower bound that guides a VAE-based representation. Experiments were conducted on a database of seven classes of guitar playing techniques. The experimental results demonstrated that the proposed method outperforms baselines in terms of the Fl-score and accuracy.","1945-788X","978-1-5386-1737-3","10.1109/ICME.2018.8486467","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8486467","Variational autoencoder;Gaussian process;collaborative learning;playing technique classification","Decoding;Collaborative work;Task analysis;Gaussian processes;Timbre","feature extraction;Gaussian processes;information retrieval;learning (artificial intelligence);music;musical instruments;pattern classification","learned representations;VAE-based representation;guitar playing techniques;technique classification;variational auto-encoder;modeling musical timbre;music information retrieval tasks;MIR;deep collaborative learning framework;greater discriminative power;acoustic features;Gaussian process classifier;variational autoencoder;Fl-score","","","","24","","11 Oct 2018","","","IEEE","IEEE Conferences"
"Variational Autoencoding Dialogue Sub-Structures Using a Novel Hierarchical Annotation Schema","M. Tewari; M. Persiani","Dept. of Computing Science, Umeå University, Umeå, Sweden; Dept. of Computing Science, Umeå University, Umeå, Sweden","2020 6th IEEE Congress on Information Science and Technology (CiSt)","29 Mar 2021","2020","","","334","341","This work presents a novel method to extract sub-structures in dialogues for the following genres: human-human task driven, human-human chit-chat, human-machine task driven, and human-machine chit-chat dialogues. The model consists of a novel semi-supervised annotation schema of syntactic features, communicative functions, dialogue policy, sequence expansion and sender information. These labels are then transformed into tuples of three, four and five segments, the tuples are used as features and modelled to learn sub-structures in above mentioned genres of dialogues with sequence-to-sequence variational autoencoders. The results analyse the latent space of generic sub-structures decomposed by PCA and ICA, showing an increase in silhouette scores for clustering of the latent space.","2327-1884","978-1-7281-6646-9","10.1109/CiSt49399.2021.9357245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9357245","Variational autoencoders;Attention Layer;Dialogue sub-structures;Conversation Analysis;Dialogue control functions;Dialogue Policies;LSTM;Hierarchical Agglomerative Clustering","Information science;Annotations;Aerospace electronics;Syntactics;Task analysis;Man-machine systems;Principal component analysis","human computer interaction;interactive systems;learning (artificial intelligence);man-machine systems;pattern clustering;text analysis","syntactic features;dialogue policy;sequence expansion;tuples;sequence-to-sequence variational autoencoders;novel hierarchical annotation schema;human-human task;human-human chit-chat;human-machine chit-chat dialogues;generic substructures;semisupervised annotation schema;variational autoencoding dialogue substructures","","","","36","","29 Mar 2021","","","IEEE","IEEE Conferences"
"Cognitive Workload Estimation Using Variational Auto Encoder & Attention-based Deep Model","D. D. Chakladar; S. Datta; P. P. Roy; A. P. Vinod",NA; NA; NA; NA,"IEEE Transactions on Cognitive and Developmental Systems","","2022","PP","99","1","1","The estimation of cognitive workload using electroencephalogram (EEG) is an emerging research area. However, due to poor spatial resolution issues, features obtained from EEG signals often lead to poor classification results. As a good generative model, the Variational Autoencoder (VAE) extracts the noise-free robust features from the latent space that lead to better classification performance. The spatial attention-based method (Convolutional Block Attention Module: CBAM) can improve the spatial resolution of EEG signals. In this paper, we propose an effective VAE-CBAM-based deep model for estimating cognitive states from topographical videos. Topographical videos of four different conditions (Baseline: BL, low workload: LW, medium workload: MW, and high workload: HW) of the mental arithmetic task are taken for the experiment. Initially, the VAE extracts localized features from input images (extracted from topographical video), and CBAM infers the spatial-channellevels attention features from those localized features. Finally, the deep CNN-BLSTM model effectively learns those attentionbased spatial features in a timely-distributed manner to classify the cognitive state. For four-class and two-class classification, the proposed model achieves 83.13% and 92.09% classification accuracy, respectively. The proposed model enhances the future research scope of attention-based studies in EEG applications.","2379-8939","","10.1109/TCDS.2022.3163020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745055","Electroencephalogram;Variational Autoencoder;Convolutional Block Attention Module;Convolutional Neural Network;Long Short-Term Memory.","Feature extraction;Brain modeling;Electroencephalography;Task analysis;Videos;Convolution;Arithmetic","","","","","","","IEEE","30 Mar 2022","","","IEEE","IEEE Early Access Articles"
"Deep Clustering With Variational Autoencoder","K. -L. Lim; X. Jiang; C. Yi","Rapid-Rich Object Search Lab, School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore; Rapid-Rich Object Search Lab, School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore; Rapid-Rich Object Search Lab, School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore","IEEE Signal Processing Letters","4 Feb 2020","2020","27","","231","235","An autoencoder that learns a latent space in an unsupervised manner has many applications in signal processing. However, the latent space of an autoencoder does not pursue the same clustering goal as Kmeans or GMM. A recent work proposes to artificially re-align each point in the latent space of an autoencoder to its nearest class neighbors during training (Song et al. 2013). The resulting new latent space is found to be much more suitable for clustering, since clustering information is used. Inspired by previous works (Song et al. 2013), in this letter we propose several extensions to this technique. First, we propose a probabilistic approach to generalize Song's approach, such that Euclidean distance in the latent space is now represented by KL divergence. Second, as a consequence of this generalization we can now use probability distributions as inputs rather than points in the latent space. Third, we propose using Bayesian Gaussian mixture model for clustering in the latent space. We demonstrated our proposed method on digit recognition datasets, MNIST, USPS and SHVN as well as scene datasets, Scene15 and MIT67 with interesting findings.","1558-2361","","10.1109/LSP.2020.2965328","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8957256","","Bayes methods;Gaussian distribution;Optimization;Probabilistic logic;Probability distribution;Random variables;Standards","Bayes methods;Gaussian processes;image classification;image coding;image recognition;pattern clustering;unsupervised learning","Scene15 dataset;scene datasets;SHVN dataset;USPS dataset;MNIST dataset;digit recognition dataset;KL divergence;Euclidean distance;probabilistic approach;variational autoencoder;deep clustering;latent space;autoencoder","","17","","40","IEEE","13 Jan 2020","","","IEEE","IEEE Journals"
"Learning a Sparse Generative Non-Parametric Supervised Autoencoder","M. Barlaud; F. Guyard","Laboratoire I3S CNRS, Cote d’Azur University Sophia Antipolis, France Orange Labs, Sophia Antipolis, France; Laboratoire I3S CNRS, Cote d’Azur University Sophia Antipolis, France Orange Labs, Sophia Antipolis, France","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","3315","3319","This paper concerns the supervised generative non parametric autoencoder. Classical methods are based on variational non supervised autoencoders (VAE). Variational autoencoders encourage the latent space to fit a prior distribution, like a Gaussian. However, they tend to draw stronger assumptions for the data, often leading to higher asymptotic bias when the model is wrong.In this paper, we relax the parametric distribution assumption in the latent space and we propose to learn a non-parametric data distribution of the clusters in the latent space. The network encourages the latent space to fit a distribution learned with the labels instead of the parametric prior assumptions. We have built a network architecture that uses the labels to compute the latent space. Thus we define a global criterion combining classification and reconstruction loss. In addition, we have proposed a ℓ1,1 regularization which has the advantage of sparsifying the network and improving the clustering. Finally we propose a tailored algorithm to minimize the criterion with constraint. We demonstrate the effectiveness of our method using the popular image dataset MNIST and two biological datasets.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414410","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414410","","Biological system modeling;Signal processing algorithms;Clustering algorithms;Lung;Network architecture;Signal processing;Data models","image classification;image reconstruction;Markov processes;Monte Carlo methods;neural nets","latent space;sparse generative nonparametric supervised autoencoder;variational nonsupervised autoencoders;parametric distribution assumption;nonparametric data distribution","","1","","27","","13 May 2021","","","IEEE","IEEE Conferences"
"Efficiency of Reinforcement Learning using Polarized Regime by Variational Autoencoder","M. Nakai; T. Shibuya","Doctoral Program in Intelligent and Mechanical Interaction Systems, University of Tsukuba, Japan; Faculty of Engineering, Information and System, University of Tsukuba, Japan","2022 61st Annual Conference of the Society of Instrument and Control Engineers (SICE)","6 Oct 2022","2022","","","128","134","Reinforcement learning from low-dimensional state expressions extracted as features from images is more efficient than learning directly from high-dimensional images. The autoencoder (AE) is typically used to render an image into a low-dimensional state; reinforcement learning on latent variables encoded by variational autoencoder (VAE) give excellent results. Notably, VAE is known to have a polarized regime and disentanglement among the generated latent variables. However very few studies have attempted to improve the efficiency of reinforcement learning using a polarized regime. This paper demonstrates the capability of a VAE polarized regime to improve the efficiency of reinforcement learning using an interactive driving game. It was found that only some polarized latent variables contribute to image restoration and reinforcement learning. The results show that calculation times can be significantly shortened while maintaining performance by reducing the number of search points of ES (Evolution Strategy) via the selection of only the latent variables that contribute to reinforcement learning using the polarized regime.","","978-4-9077-6478-4","10.23919/SICE56594.2022.9905819","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9905819","Variational autoencoder;polarized regime;reinforcement learning;state representation;latent space;evolution strategy","Instruments;Reinforcement learning;Games;Gaussian distribution;Feature extraction;Image restoration;Standards","","","","","","18","","6 Oct 2022","","","IEEE","IEEE Conferences"
"Multimodal Weibull Variational Autoencoder for Jointly Modeling Image-Text Data","C. Wang; B. Chen; S. Xiao; Z. Wang; H. Zhang; P. Wang; N. Han; M. Zhou","National Lab of Radar Signal Processing, Collaborative Innovation Center of Information Sensing and Understanding, Xidian University, Xi’an, China; National Lab of Radar Signal Processing, Collaborative Innovation Center of Information Sensing and Understanding, Xidian University, Xi’an, China; Security Department, ByteDance, Guangzhou, China; National Lab of Radar Signal Processing, Collaborative Innovation Center of Information Sensing and Understanding, Xidian University, Xi’an, China; Department of Population Health Sciences, Weill Cornell Medicine, Tompkins, NY, USA; National Lab of Radar Signal Processing, Collaborative Innovation Center of Information Sensing and Understanding, Xidian University, Xi’an, China; Research Room 7, Institute of Mechanical Technology, Xi’an, China; McCombs School of Business, The University of Texas at Austin, Austin, TX, USA","IEEE Transactions on Cybernetics","19 Sep 2022","2022","52","10","11156","11171","For multimodal representation learning, traditional black-box approaches often fall short of extracting interpretable multilayer hidden structures, which contribute to visualize the connections between different modalities at multiple semantic levels. To extract interpretable multimodal latent representations and visualize the hierarchial semantic relationships between different modalities, based on deep topic models, we develop a novel multimodal Poisson gamma belief network (mPGBN) that tightly couples the observations of different modalities via imposing sparse connections between their modality-specific hidden layers. To alleviate the time-consuming Gibbs sampler adopted by traditional topic models in the testing stage, we construct a Weibull-based variational inference network (encoder) to directly map the observations to their latent representations, and further combine it with the mPGBN (decoder), resulting in a novel multimodal Weibull variational autoencoder (MWVAE), which is fast in out-of-sample prediction and can handle large-scale multimodal datasets. Qualitative evaluations on bimodal data consisting of image-text pairs show that the developed MWVAE can successfully extract expressive multimodal latent representations for downstream tasks like missing modality imputation and multimodal retrieval. Further extensive quantitative results demonstrate that both MWVAE and its supervised extension sMWVAE achieve state-of-the-art performance on various multimodal benchmarks.","2168-2275","","10.1109/TCYB.2021.3070881","National Natural Science Foundation of China(grant numbers:61771361,61701379); Fund for Foreign Scholars in University Research and Teaching Programs (the 111 Project)(grant numbers:B18039); Thousand Young Talent Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9417864","Bayesian inference;deep topic model;multimodal representation learning;variational autoencoder (VAE)","Semantics;Data models;Probabilistic logic;Task analysis;Computational modeling;Predictive models;Data mining","","","Learning","","","50","IEEE","28 Apr 2021","","","IEEE","IEEE Journals"
"Multiscale Variational Autoencoder Aided Convolutional Neural Network for Pose Estimation of Tunneling Machine Using a Single Monocular Image","H. Wu; S. Liu; C. Cheng; S. Cao; Y. Cui; D. Zhang","School of Mechatronic Engineering, China University of Mining and Technology, Xuzhou, China; School of Mechatronic Engineering, China University of Mining and Technology, Xuzhou, China; School of Mechatronic Engineering, China University of Mining and Technology, Xuzhou, China; School of Mechatronic Engineering, China University of Mining and Technology, Xuzhou, China; School of Mechatronic Engineering, China University of Mining and Technology, Xuzhou, China; School of Mechatronic Engineering, China University of Mining and Technology, Xuzhou, China","IEEE Transactions on Industrial Informatics","10 May 2022","2022","18","8","5161","5170","With the rising demand of underground construction, intelligent tunneling techniques have been increasingly studied to improve the safety and efficiency of construction. The self-positioning technology of tunneling machines is the cornerstone of intelligent tunneling, which is particularly challenging due to the extreme environments of the underground tunnels. In this article, a novel robust and real-time six degrees of freedom (6-DoF) pose estimation strategy is proposed for tunneling machines based on the computer vision and deep learning methods. A monocular camera is attached to the tunneling machine, and employed to capture the images of the artificial feature object that is set far behind the tunneling machine. A novel multiscale variational autoencoder aided convolutional neural network (MSVAE-CNN) model is developed to estimate the current absolute 6-DoF pose of the tunneling machine in an end-to-end manner using a single monocular image, in which the multitask variational learning scheme is able to enhance the generalization and robustness of the model and the multiscale structure can improve the learning ability of the neural network. In our numerical experiments, a motion capture system is utilized to assist the acquisition of training dataset. The experimental results demonstrate the efficacy of the proposed MSVAE-CNN based pose estimation method.","1941-0050","","10.1109/TII.2021.3123546","Excellent Youth Foundation of Jiangsu Scientific Committee(grant numbers:BK20211531); Priority Academic Program Development of Jiangsu Higher Education Institutions; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9591347","Computer vision;convolutional neural network (CNN);pose estimation;tunnelling;variational autoencoder (VAE)","Tunneling;Cameras;Pose estimation;Location awareness;Feature extraction;Deep learning;Convolutional neural networks","cameras;computer vision;feature extraction;learning (artificial intelligence);neural nets;pose estimation;tunnels","tunneling machine;convolutional neural network model;single monocular image;intelligent tunneling techniques;underground tunnels","","","","45","IEEE","27 Oct 2021","","","IEEE","IEEE Journals"
"Depth-Aware Object Tracking With a Conditional Variational Autoencoder","W. Huang; J. Gu; Y. Guo","School of Information Science and Engineering, Shandong Normal University, Jinan, China; Department of Electrical and Computer Engineering, Dalhousie University, Halifax, NS, Canada; School of Information Science and Engineering, Shandong Normal University, Jinan, China","IEEE Access","8 Jul 2021","2021","9","","94537","94547","Object tracking is a fundamental task in computer vision and artificial intelligence. However, state-of-the-art object tracking approaches are still prone to failures and are imprecise when applied to challenging scenarios, and their results are generally confidence agnostic. An imprecise deterministic output with low confidence may lead to disastrous consequences and a lack of proof for subsequent operations and human interventions. Deep network training with ambiguous data or the noise inherent in observations (i.e., data uncertainty or aleatoric uncertainty) will result in inherent uncertainties in predictions. In this paper, we exploit probabilistic depth-aware object tracking with a conditional variational autoencoder (CVAE). First, we build a bridge between the Siamese network and the variational autoencoder conditioned with depth images and propose a novel multimodal Bayesian object tracking method. Second, our proposed method yields a complete probability distribution that enables the production of multiple plausible features. Third, the variational autoencoder conditioned by depth images encodes a low-dimensional latent space that conducts depth-aware tracking, which has obvious advantages for challenging tracking scenarios. Our proposed tracking method outperformed the state-of-the-art trackers on the VOT 2016, VOT 2018, and VOT 2019 datasets.","2169-3536","","10.1109/ACCESS.2021.3092886","Fund of National Nature Science Foundation, China(grant numbers:62003196,61572300,81871508,61773246,62073201,62072289); Fund of Provincial Nature Science Foundation, Shandong, China(grant numbers:ZR2020QF032); Taishan Scholar Program of Shandong Province, China(grant numbers:TSHW201502038); Major Program of Shandong Province Natural Science Foundation, China(grant numbers:ZR2019ZD04,ZR2018ZB0419); Natural Sciences and Engineering Research Council of Canada (NSERC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9466099","Depth awareness;object tracking;Bayesian neural networks","Uncertainty;Object tracking;Probabilistic logic;Training;Target tracking;Deep learning;Feature extraction","Bayes methods;computer vision;learning (artificial intelligence);object detection;object tracking;probability;target tracking","inherent uncertainties;probabilistic depth-aware object tracking;conditional variational autoencoder;Siamese network;depth images;novel multimodal Bayesian object tracking method;low-dimensional latent space;depth-aware tracking;tracking scenarios;computer vision;artificial intelligence;state-of-the-art object tracking;imprecise deterministic output;low confidence;disastrous consequences;subsequent operations;human interventions;deep network training;ambiguous data;noise inherent;data uncertainty","","1","","41","CCBY","28 Jun 2021","","","IEEE","IEEE Journals"
"Convolutional One-Dimensional Variational Autoencoder Based Intrusion detection","K. Wu; M. Cao; P. Wang; Z. Wang","School of Modern Posts, Nanjing University of Posts & Telecommunications, Nanjing, China; School of Modern Posts, Nanjing University of Posts & Telecommunications, Nanjing, China; School of Modern Posts, Nanjing University of Posts & Telecommunications, Nanjing, China; School of Modern Posts, Nanjing University of Posts & Telecommunications, Nanjing, China","2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)","15 Mar 2022","2021","","","488","493","Intrusion detection technology is an important part of network security. It detects various intrusions by collecting and analyzing various information on the network, which is the focus of maintaining network security. With the popularization of the network and the increase of the network rate, the network attack behavior is increasing and the attack methods are constantly updated. The traditional detection technology can not meet the demand of the new network environment for network security. In view of the defects of the existing intrusion detection algorithm model based on deep learning, such as long training time, more hyperparameters and high data demand, it is feasible to detect malicious traffic by learning the characteristics of normal traffic. In this paper, a variational self-encoder (COD-VAE) intrusion detection model based on one-dimensional convolutional neural network is proposed, which can identify malicious traffic more accurately. The intrusion detection algorithm is used to detect the intrusion of the intrusion detection system. Experimental results show that all the indexes of the algorithm are higher than the comparison algorithm, which verifies the effectiveness of the algorithm.","","978-1-6654-2174-4","10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9730421","Intrusion detection;Unsupervised;Machine learning;Deep learning;Variational auto encoder","Training;Deep learning;Intrusion detection;Network security;Big Data;Data models;Convolutional neural networks","computer crime;convolutional neural nets;deep learning (artificial intelligence)","intrusion detection technology;network security;network attack behavior;malicious traffic;intrusion detection system;convolutional one-dimensional variational autoencoder;COD-VAE;deep learning","","","","13","IEEE","15 Mar 2022","","","IEEE","IEEE Conferences"
"Smooth Variational Graph Embeddings for Efficient Neural Architecture Search","J. Lukasik; D. Friede; A. Zela; F. Hutter; M. Keuper",University of Mannheim; University of Mannheim; University of Freiburg; Bosch Center for Artificial Intelligence; University of Mannheim,"2021 International Joint Conference on Neural Networks (IJCNN)","22 Sep 2021","2021","","","1","8","Neural architecture search (NAS) has recently been addressed from various directions, including discrete, sampling-based methods and efficient differentiable approaches. While the former are notoriously expensive, the latter suffer from imposing strong constraints on the search space. Architecture optimization from a learned embedding space for example through graph neural network based variational autoencoders builds a middle ground and leverages advantages from both sides. Such approaches have recently shown good performance on several benchmarks. Yet, their stability and predictive power heavily depends on their capacity to reconstruct networks from the embedding space. In this paper, we propose a two-sided variational graph autoencoder, which allows to smoothly encode and accurately reconstruct neural architectures from various search spaces. We evaluate the proposed approach on neural architectures defined by the ENAS approach, the NAS-Bench-101 and the NAS-Bench-201 search space and show that our smooth embedding space allows to directly extrapolate the performance prediction to architectures outside the seen domain (e.g. with more operations). Thus, it facilitates to predict good network architectures even without expensive Bayesian optimization or reinforcement learning.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9534092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534092","representation learning;neural architecture search;graph neural network;deep learning","Extrapolation;Reinforcement learning;Predictive models;Network architecture;Stability analysis;Graph neural networks;Encoding","graph theory;neural net architecture;sampling methods;search problems;variational techniques","graph neural network;variational graph autoencoder;ENAS approach;NAS-Bench-101 search space;smooth variational graph embeddings;neural architecture search;sampling based methods;learned embedding space;NAS-Bench-201 search space","","1","","55","","22 Sep 2021","","","IEEE","IEEE Conferences"
"F0-Consistent Many-To-Many Non-Parallel Voice Conversion Via Conditional Autoencoder","K. Qian; Z. Jin; M. Hasegawa-Johnson; G. J. Mysore","University of Illinois at Urbana-Champaign, IL, USA; Adobe Research, CA, USA; University of Illinois at Urbana-Champaign, IL, USA; Adobe Research, CA, USA","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","6284","6288","Non-parallel many-to-many voice conversion remains an interesting but challenging speech processing task. Many style-transfer-inspired methods such as generative adversarial networks (GANs) and variational autoencoders (VAEs) have been proposed. Recently, AU-TOVC, a conditional autoencoders (CAEs) based method achieved state-of-the-art results by disentangling the speaker identity and speech content using information-constraining bottlenecks, and it achieves zero-shot conversion by swapping in a different speaker's identity embedding to synthesize a new voice. However, we found that while speaker identity is disentangled from speech content, a significant amount of prosodic information, such as source F0, leaks through the bottleneck, causing target F0 to fluctuate unnaturally. Furthermore, AutoVC has no control of the converted F0 and thus unsuitable for many applications. In the paper, we modified and improved autoencoder-based voice conversion to disentangle content, F0, and speaker identity at the same time. Therefore, we can control the F0 contour, generate speech with F0 consistent with the target speaker, and significantly improve quality and similarity. We support our improvement through quantitative and qualitative analysis.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9054734","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054734","voice-conversion;F0-conversion;autoencoder;WaveNet-vocoder","Conferences;Signal processing;Generative adversarial networks;Acoustics;Speech processing;Task analysis;Tuning","neural nets;speaker recognition;speech processing;speech synthesis","style-transfer-inspired methods;variational autoencoders;AU-TOVC;speech content;information-constraining bottlenecks;zero-shot conversion;autoencoder-based voice conversion;F0-consistent many-to-many nonparallel voice conversion;speech processing task;generative adversarial networks;GANs;VAEs;conditional autoencoders based method;CAEs;speaker identity embedding;F0 contour;qualitative analysis;quantitative analysis","","16","","26","","9 Apr 2020","","","IEEE","IEEE Conferences"
"A tensorflow based feature learning method application in fault detecting of tract motor","W. Huizhong; Q. Linhan; H. Keke","Lanzhou University of Technology, Lanzhou, China; Lanzhou University of Technology, Lanzhou, China; Lanzhou University of Technology, Lanzhou, China","2018 Chinese Control And Decision Conference (CCDC)","9 Jul 2018","2018","","","3248","3252","In purpose of detecting the inner and outer ring faults of tractor motor, one Feature Learning method, Variational AutoEncoder, which based on Tensorflow, was cited to process the motor vibration signal. This method firstly normalized all data sets Next, these data sets were input into the built Variational AutoEncoder model to train the weights and biases as the feature learning is going on. Then, a Softmax Regression model is used for multi-faults diagnosis. The final results showed that this method can be used for finishing multi-faults detecting missions excellently, and for every metric, the results are better than traditional Back Propagation Neura Network, from 87.51% to 93.61%. Hence, this unsupervised feature learning method decreased lots of Machine learning model's dependency on feature engineering. It would be a good guidance of actual projects.","1948-9447","978-1-5386-1244-6","10.1109/CCDC.2018.8407684","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8407684","Tensorflow;Variational AutoEncoder;Softmax Regression;Feature Learning;Fault Detection","","fault diagnosis;feature extraction;regression analysis;unsupervised learning;vibrational signal processing","tract motor;motor vibration signal;Softmax Regression model;multifaults diagnosis;Machine learning model;unsupervised feature learning;tensorflow based feature learning;fault detection;tractor motor ring faults;Variational AutoEncoder model","","","","15","","9 Jul 2018","","","IEEE","IEEE Conferences"
"A VAE Conversion Method for Private Data Linkage","B. -C. Tai; S. -C. Li; Y. Huang","Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Department of Information Communication, Tamkang University, New Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan","2021 IEEE 26th Pacific Rim International Symposium on Dependable Computing (PRDC)","12 Jan 2022","2021","","","161","164","Data linkage plays a crucial role in realizing big data's value but is often regarded as a threat to personal privacy. Regulations like GDPR requires users' consent on each specific use of data, which is not practical for data analyzers. In this study, we propose a way to address the problem by having a trustworthy third party collect data from two or more parties, then use the data to train one or more variational autoencoder (VAE) models to remove privacy and send them to the data providers. Using this model, the users express their consent to share data with a trustworthy party. The third party links data from various datasets together to build a variational autoencoder model that allows all parties to generate datasets with full attributes without revealing sensitive personal data. System architectures and machine learning accuracy of generated data sets are measured in this study.","2473-3105","978-1-6654-2476-9","10.1109/PRDC53464.2021.00029","Ministry of Science and Technology, Taiwan(grant numbers:MOST109-2221-E-001-019-MY3); Academia Sinica(grant numbers:AS-KPQ-109-DSTCP); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9667675","data linkage;synthetic data;variational autoencoder","Couplings;Data privacy;Systems architecture;Machine learning;Big Data;Data models;Regulation","Big Data;data privacy;neural nets","big data;personal privacy;data analyzers;trustworthy third party;variational autoencoder model;party links data;sensitive personal data;VAE conversion method;private data linkage;machine learning;system architectures","","","","7","IEEE","12 Jan 2022","","","IEEE","IEEE Conferences"
"Quantifying The Generative Capabilities Of Variational Autoencoders For 3D Car Point Clouds","S. Saha; S. Menzel; L. L. Minku; X. Yao; B. Sendhoff; P. Wollstadt","Honda Research Institute Europe GmbH, Carl-Legien-Str. 30, Offenbach, Germany; Honda Research Institute Europe GmbH, Carl-Legien-Str. 30, Offenbach, Germany; CERCIA, School of Computer Science, University of Birmingham, Birmingham, UK; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Honda Research Institute Europe GmbH, Carl-Legien-Str. 30, Offenbach, Germany; Honda Research Institute Europe GmbH, Carl-Legien-Str. 30, Offenbach, Germany","2020 IEEE Symposium Series on Computational Intelligence (SSCI)","5 Jan 2021","2020","","","1469","1477","During each cycle of automotive development, large amounts of geometric data are generated as results of design studies and simulation tasks. Discovering hidden knowledge from this data and making it available to the development team strengthens the design process by utilizing historic information when creating novel products. To this end, we propose to use powerful geometric deep learning models that learn lowdimensional representation of the design data in an unsupervised fashion. Trained models allow to efficiently explore the design space, as well as to generate novel designs. One popular class of generative models are variational autoencoders, which have however been rarely applied to geometric data. Hence, we use a variational autoencoder for 3D point clouds (PC-VAE) and explore the model's generative capabilities with a focus on the generation of realistic yet novel 3D shapes. We apply the PC-VAE to point clouds sampled from car shapes from a benchmark data set and employ quantitative measures to show that our PC-VAE generates realistic car shapes, wile returning a richer variety of unseen shapes compared to a baseline autoencoder. Finally, we demonstrate how the PC-VAE can be guided towards generating shapes with desired target properties by optimizing the parameters that maximize the output of a trained classifier for said target properties. We conclude that generative models are a powerful tool that may aid designers in automotive product development.","","978-1-7281-2547-3","10.1109/SSCI47803.2020.9308513","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308513","Representation learning;geometric deep learning;point clouds;generative model;novelty","Shape;Three-dimensional displays;Solid modeling;Data models;Automobiles;Analytical models;Computer architecture","automotive engineering;deep learning (artificial intelligence);image representation;mechanical engineering computing","generative models;variational autoencoder;geometric data;PC-VAE;benchmark data set;automotive product development;3D car point clouds;automotive development;geometric deep learning models;low-dimensional representation","","6","","35","","5 Jan 2021","","","IEEE","IEEE Conferences"
"Revisiting Bayesian Autoencoders With MCMC","R. Chandra; M. Jain; M. Maharana; P. N. Krivitsky","UNSW Data Science Hub, UNSW Sydney, Sydney, NSW, Australia; Department of Computer and Communication, Manipal Institute of Technology, Manipal, Karnataka, India; Department of Computer and Communication, Manipal Institute of Technology, Manipal, Karnataka, India; UNSW Data Science Hub, UNSW Sydney, Sydney, NSW, Australia","IEEE Access","21 Apr 2022","2022","10","","40482","40495","Autoencoders gained popularity in the deep learning revolution given their ability to compress data and provide dimensionality reduction. Although prominent deep learning methods have been used to enhance autoencoders, the need to provide robust uncertainty quantification remains a challenge. This has been addressed with variational autoencoders so far. Bayesian inference via Markov Chain Monte Carlo (MCMC) sampling has faced several limitations for large models; however, recent advances in parallel computing and advanced proposal schemes have opened routes less traveled. This paper presents Bayesian autoencoders powered by MCMC sampling implemented using parallel computing and Langevin-gradient proposal distribution. The results indicate that the proposed Bayesian autoencoder provides similar performance accuracy when compared to related methods in the literature. Furthermore, it provides uncertainty quantification in the reduced data representation. This motivates further applications of the Bayesian autoencoder framework for other deep learning models.","2169-3536","","10.1109/ACCESS.2022.3163270","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745141","Bayesian deep learning;MCMC;Langevin dynamics;autoencoders;parallel tempering;deep learning","Bayes methods;Neural networks;Proposals;Deep learning;Decoding;Data models;Computational modeling","Bayes methods;data structures;deep learning (artificial intelligence);Markov processes;Monte Carlo methods;parallel processing","parallel computing;Bayesian autoencoder;deep learning revolution;robust uncertainty quantification;variational autoencoders;Bayesian inference;Markov chain Monte Carlo sampling;MCMC sampling;reduced data representation","","","","99","CCBY","30 Mar 2022","","","IEEE","IEEE Journals"
"Unsupervised Speech Representation Learning Using WaveNet Autoencoders","J. Chorowski; R. J. Weiss; S. Bengio; A. van den Oord","Institute of Computer Science, University of Wrocław, Wrocław, Poland; Google, Mountain View, CA, USA; Google, Mountain View, CA, USA; DeepMind Technologies, London, U.K.","IEEE/ACM Transactions on Audio, Speech, and Language Processing","11 Sep 2019","2019","27","12","2041","2053","We consider the task of unsupervised extraction of meaningful latent representations of speech by applying autoencoding neural networks to speech waveforms. The goal is to learn a representation able to capture high level semantic content from the signal, e.g. phoneme identities, while being invariant to confounding low level details in the signal such as the underlying pitch contour or background noise. Since the learned representation is tuned to contain only phonetic content, we resort to using a high capacity WaveNet decoder to infer information discarded by the encoder from previous samples. Moreover, the behavior of autoencoder models depends on the kind of constraint that is applied to the latent representation. We compare three variants: a simple dimensionality reduction bottleneck, a Gaussian Variational Autoencoder (VAE), and a discrete Vector Quantized VAE (VQ-VAE). We analyze the quality of learned representations in terms of speaker independence, the ability to predict phonetic content, and the ability to accurately reconstruct individual spectrogram frames. Moreover, for discrete encodings extracted using the VQ-VAE, we measure the ease of mapping them to phonemes. We introduce a regularization scheme that forces the representations to focus on the phonetic content of the utterance and report performance comparable with the top entries in the ZeroSpeech 2017 unsupervised acoustic unit discovery task.","2329-9304","","10.1109/TASLP.2019.2938863","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8822475","Autoencoder;speech representation learning;unsupervised learning;acoustic unit discovery","Decoding;Task analysis;Prototypes;Feature extraction;Neural networks;Phonetics;Speech processing","acoustic signal processing;Gaussian processes;learning (artificial intelligence);neural nets;speech processing;vector quantisation","speech waveforms;high level semantic content;phoneme identities;low level details;phonetic content;high capacity WaveNet decoder;autoencoder models;latent representation;simple dimensionality reduction bottleneck;VQ-VAE;ZeroSpeech 2017 unsupervised acoustic unit discovery task;unsupervised speech representation;WaveNet autoencoders;unsupervised extraction;autoencoding neural networks;Gaussian variational autoencoder;discrete vector quantized VAE;latent representations;pitch contour","","98","","80","IEEE","2 Sep 2019","","","IEEE","IEEE Journals"
"Deep Autoencoder Architectures For Foreground Object Detection In Video Sequences Based On Probabilistic Mixture Models","J. García-Gonzàlez; M. A. Molina-Cabello; R. M. Luque-Baena; J. M. Ortiz-de-Lazcano-Lobato; E. López-Rubio","Department of Computer Languages and Computer Science, University of Màlaga Biomedic Research Institute of Màlaga (IBIMA); Department of Computer Languages and Computer Science, University of Màlaga Biomedic Research Institute of Màlaga (IBIMA); Department of Computer Languages and Computer Science, University of Màlaga Biomedic Research Institute of Màlaga (IBIMA); Department of Computer Languages and Computer Science, University of Màlaga Biomedic Research Institute of Màlaga (IBIMA); Department of Computer Languages and Computer Science, University of Màlaga Biomedic Research Institute of Màlaga (IBIMA)","2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","3199","3203","Foreground object detection algorithms should be insensitive to noise present in the analyzed video sequences. In this work, a study of a type of non-supervised deep learning network, called autoencoder, is performed. They are suited to reduce input dimensionality and capture the most relevant information present in a region or image. Therefore, different types of autoencoders, deterministic and variational, with different architectures, activation functions and number of layers, are analyzed. This neural network is combined with a probabilistic mixture model which attempts to classify each video frame region as background and foreground.","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9190834","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190834","foreground detection;deep autoencoders;video surveillance","Probabilistic logic;Feature extraction;Training;Mixture models;Computer architecture;Object detection;Video sequences","deep learning (artificial intelligence);image classification;image sequences;mixture models;neural net architecture;object detection;probability;video signal processing","input dimensionality;neural network;probabilistic mixture model;deep autoencoder architectures;foreground object detection;video sequences;nonsupervised deep learning network;variational autoencoder;deterministic autoencoder;activation functions;video frame region classification","","","","27","","30 Sep 2020","","","IEEE","IEEE Conferences"
"A generative model of galactic dust emission using variational autoencoders","B. Thorne; L. Knox; K. Prabhu","Department of Physics, University of California, One Shields Avenue, Davis, CA 95616, USA; bn.thorne@gmail.com; Department of Physics, University of California, One Shields Avenue, Davis, CA 95616, USA; Department of Physics, University of California, One Shields Avenue, Davis, CA 95616, USA","Monthly Notices of the Royal Astronomical Society","28 Jun 2021","2021","504","2","2603","2613","Emission from the interstellar medium can be a significant contaminant of measurements of the intensity and polarization of the cosmic microwave background (CMB). For planning CMB observations, and for optimizing foreground-cleaning algorithms, a description of the statistical properties of such emission can be helpful. Here, we examine a machine learning approach to inferring the statistical properties of dust from observational data. In particular, we apply a type of neural network called a variational autoencoder (VAE) to maps of the intensity of emission from interstellar dust as inferred from Planck sky maps and demonstrate its ability to (i) simulate new samples with similar summary statistics as the training set, (ii) provide fits to emission maps withheld from the training set, and (iii) produce constrained realizations. We find VAEs are easier to train than another popular architecture: that of generative adversarial networks, and are better suited for use in Bayesian inference.","1365-2966","","10.1093/mnras/stab1011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9466685","methods: statistical;ISM: general;cosmic background radiation","","","","","","","","","28 Jun 2021","","","OUP","OUP Journals"
"Semantically Disentangled Variational Autoencoder for Modeling 3D Facial Details","J. Ling; Z. Wang; M. Lu; Q. Wang; C. Qian; F. Xu","School of Software, Tsinghua University, 12442 Beijing, Beijing, China, 100084; The Institute of CG&CAD, Tsinghua University, 12442 Beijing, Beijing, China, 100084; VAIL, Intel Labs China, Beijing, Beijing, China; SenseTime Research, SenseTime Group, 602673 Hong Kong, Hong Kong, Hong Kong; Research Deparment, SenseTime Group Limited, Hong Kong, Hong Kong, China; School of Software, CG&CAD, Beijing, Beijing, China","IEEE Transactions on Visualization and Computer Graphics","","2022","PP","99","1","1","Parametric face models, like morphable and blendshape models, have shown great potential in face representation, reconstruction, and animation. However, all these models focus on large-scale facial geometry. Facial details like wrinkles are not parameterized in these models, impeding their accuracy and realism. In this paper, we propose a method to learn a Semantically Disentangled Variational Autoencoder (SDVAE) to parameterize facial details and support independent detail manipulation as an extension of an off-the-shelf large-scale face model. Our method utilizes the non-linear capability of Deep Neural Networks for detail modeling, achieving better accuracy and greater representation power compared with linear models. In order to disentangle the semantic factors of identity, expression and age, we propose to eliminate the correlation between different factors in an adversarial manner. Therefore, wrinkle-level details of various identities, expressions, and ages can be generated and independently controlled by changing latent vectors of our SDVAE. We further leverage our model to reconstruct 3D faces via fitting to facial scans and images. Benefiting from our parametric model, we achieve accurate and robust reconstruction, and the reconstructed details can be easily animated and manipulated. We evaluate our method on practical applications, including scan fitting, image fitting, video tracking, model manipulation, and expression and age animation. Extensive experiments demonstrate that the proposed method can robustly model facial details and achieve better results than alternative methods.","1941-0506","","10.1109/TVCG.2022.3166666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9756299","Detail reconstruction;facial animation;semantic disentanglement","Solid modeling;Three-dimensional displays;Faces;Image reconstruction;Geometry;Principal component analysis;Shape","","","","","","","IEEE","12 Apr 2022","","","IEEE","IEEE Early Access Articles"
"Modulation Filter Learning Using Deep Variational Networks for Robust Speech Recognition","P. Agrawal; S. Ganapathy","Learning and Extraction of Acoustic Patterns Lab, Department of Electrical Engineering, Indian Institute of Science, Bangalore, India; Learning and Extraction of Acoustic Patterns Lab, Department of Electrical Engineering, Indian Institute of Science, Bangalore, India","IEEE Journal of Selected Topics in Signal Processing","17 May 2019","2019","13","2","244","253","The performance of a typical speech recognition system is degraded in the presence of extrinsic sources like noise and due to the recording artifacts like reverberation. The principle of modulation filtering attempts to remove the spectro-temporal modulations of the speech signal that are more susceptible to noise while preserving the key modulations for speech recognition. While traditional approaches use modulation filters that are hand-crafted, we propose a novel method for modulation filter learning using deep variational models in this paper. Specifically, we pose the filter learning problem in a deep unsupervised generative modeling framework where the convolutional filters in the variational autoencoder capture the important speech modulations. The two-dimensional modulation filters, learned using the deep variational networks in the joint spectro-temporal domain, are used to process the spectrogram features for speech recognition task. Several speech recognition experiments are performed on a set of tasks consisting of additive noise with channel artifacts (Aurora-4), reverberation (REVERB Challenge), and additive noise with reverberation (CHiME-3). In these experiments, the proposed modulation filter learning framework shows significant improvements over the baseline features as well as various other noise robust front-ends (average relative improvements of 7.5% and 20% over the baseline features on the Aurora-4 and CHiME-3 databases respectively). Furthermore, the proposed method is also shown to be of considerable benefit for semi-supervised automatic speech recognition applications. For example, on Aurora-4 database we observe an average relative improvement of 25% over the baseline system using 30% labeled training data.","1941-0484","","10.1109/JSTSP.2019.2913965","Department of Science and Technology; Department of Atomic Energy, Government of India; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8703845","Unsupervised filter learning;deep variational autoencoder;modulation filtering;noise robust speech recognition","Modulation;Speech recognition;Decoding;Spectrogram;Reverberation;Convolution;Training","filtering theory;modulation;neural nets;signal denoising;speech recognition;unsupervised learning","deep variational networks;spectro-temporal modulations;speech signal;deep variational models;filter learning problem;deep unsupervised generative modeling framework;convolutional filters;two-dimensional modulation filters;speech recognition task;additive noise;semisupervised automatic speech recognition applications;speech recognition system;speech modulations","","19","","48","IEEE","1 May 2019","","","IEEE","IEEE Journals"
"Collaborative Additional Variational Autoencoder for Top-N Recommender Systems","M. He; Q. Meng; S. Zhang","Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China","IEEE Access","16 Jan 2019","2019","7","","5707","5713","Collaborative filtering (CF) has been generally used in recommender systems when faced some practical problems. Due to the sparsity of the rating matrix, the traditional CF-based approach has a significant decline in recommendation performance. Gradually, a hybrid method, using side information and rating information, has been widely employed and achieves great performance. Together with side information and rating information, the hybrid method can overcome the data sparsity and cold-start problems. However, they seem to fail to take into consideration the fact that the sparsity of single side information. To solve this problem, we take full advantage of the characteristics of deep learning that can learn effective representation and propose a novel deep learning model named additional variational autoencoder that considers both content and tag information of the item. The model learns effective latent representations from additional side information, including content information and tag information in an unsupervised manner. With the help of graphical models, it can extract the implicit relationships between users and items effectively. A large number of experimental results on two actual datasets show that our proposed model is superior to other methods, and the performance improvement is achieved.","2169-3536","","10.1109/ACCESS.2018.2890293","Natural Science Foundation of Beijing Municipality(grant numbers:4192008); Beijing Municipal Commission of Education(grant numbers:KM201710005023); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598869","Collaborative filtering;deep learning;variational autoencoder;side information","Collaboration;Deep learning;Feature extraction;Recommender systems;Data mining;Graphical models;Task analysis","","","","15","","19","OAPA","1 Jan 2019","","","IEEE","IEEE Journals"
"RUL Prediction Using a Fusion of Attention-Based Convolutional Variational AutoEncoder and Ensemble Learning Classifier","I. Remadna; L. S. Terrissa; Z. Al Masry; N. Zerhouni","LINFI Laboratory, Computer Science Department, University of Biskra, Biskra, Algeria; LINFI Laboratory, Computer Science Department, University of Biskra, Biskra, Algeria; FEMTO-ST Institute, Universit&#x00E9; Bourgogne Franche-Comt&#x00E9;, CNRS, ENSMM, Besan&#x00E7;on, France; FEMTO-ST Institute, Universit&#x00E9; Bourgogne Franche-Comt&#x00E9;, CNRS, ENSMM, Besan&#x00E7;on, France","IEEE Transactions on Reliability","","2022","PP","99","1","19","Predicting the remaining useful life (RUL) is a critical step before the decision-making process and developing maintenance strategies. As a result, it is frequently impacted by uncertainty in a practical context and may cause issues. This article proposes a new hybrid deep architecture that predicts when an in-service machine will fail to overcome the latter problem, allowing for an improved data analysis and dimensionality reduction capability providing better spatial distributions of features and increasing interpretability. A deep convolutional variational autoencoder with an attention mechanism (ACVAE) has been developed and tested using the aero-engine C-MAPSS dataset. We defined two adapted threshold settings (<inline-formula><tex-math notation=""LaTeX"">$\alpha 1, \alpha 2$</tex-math></inline-formula>) by analyzing the spatial distribution and minimizing the overlapping area between the degradation classes. To reduce the conflict zone, we used the soft voting classifier. The performance of our visual explainable deep learning model has reached a higher level of accuracy compared with previous existing models.","1558-1721","","10.1109/TR.2022.3190639","General Directorate of Scientific Research and Technological Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9843862","Attention mechanism;data visualization;deep learning;prognostics and health management;variational autoencoder","Feature extraction;Degradation;Computer architecture;Estimation;Decoding;Prognostics and health management;Visualization","","","","","","","IEEE","27 Jul 2022","","","IEEE","IEEE Early Access Articles"
"End-to-End Image Classification and Compression with variational autoencoders","L. D. Chamain; S. Qi; Z. Ding","Department of Electrical and Computer Engineering, University of California, Davis, CA, USA; Department of Electrical and Computer Engineering, University of California, Davis, CA, USA; Department of Electrical and Computer Engineering, University of California, Davis, CA, USA","IEEE Internet of Things Journal","","2022","PP","99","1","1","The past decade has witnessed the rising dominance of deep learning and artificial intelligence in a wide range of applications. In particular, the ocean of wireless smartphones and IoT devices continue to fuel the tremendous growth of edge/cloud-based machine learning (ML) systems including image/speech recognition and classification. To overcome the infrastructural barrier of limited network bandwidth in cloud ML, existing solutions have mainly relied on traditional compression codecs such as JPEG that were historically engineered for human-end users instead of ML algorithms. Traditional codecs do not necessarily preserve features important to ML algorithms under limited bandwidth, leading to potentially inferior performance. This work investigates application-driven optimization of programmable commercial codec settings for networked learning tasks such as image classification. Based on the foundation of variational autoencoders (VAEs), we develop an end-to-end networked learning framework by jointly optimizing the codec and classifier without reconstructing images for given data rate (bandwidth). Compared with standard JPEG codec, the proposed VAE joint compression and classification framework achieves classification accuracy improvement by over 10% and 4%, respectively, for CIFAR-10 and ImageNet-1k data sets at data rate of 0.8 bpp. Our proposed VAE-based models show 65%–99% reductions in encoder size, ×1.5–×13.1 improvements in inference speed and 25%–99% savings in power compared to baseline models. We further show that a simple decoder can reconstruct images with sufficient quality without compromising classification accuracy.","2327-4662","","10.1109/JIOT.2022.3182313","National Science Foundation(grant numbers:2002927,2002937); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794700","Variational autoencoders;End-to-end;Classification;Compression;Reconstruction","Image coding;Image reconstruction;Codecs;Internet of Things;Decoding;Transform coding;Task analysis","","","","","","","IEEE","13 Jun 2022","","","IEEE","IEEE Early Access Articles"
"Anomaly Detection for Large Hydrogenerators Using the Variational Autoencoder Based on Vibration Signals","R. Ibrahim; R. Zemouri; A. Tahan; F. Lafleur; B. Kedjar; A. Merkhouf; K. Al-Haddad","École de Technologie Supérieure, Montréal, QC, Canada; Institut de Recherche d'Hydro-Québec (IREQ), Varennes, QC, Canada; École de Technologie Supérieure, Montréal, QC, Canada; Institut de Recherche d'Hydro-Québec (IREQ), Varennes, QC, Canada; École de Technologie Supérieure, Montréal, QC, Canada; Institut de Recherche d'Hydro-Québec (IREQ), Varennes, QC, Canada; École de Technologie Supérieure, Montréal, QC, Canada","2022 International Conference on Electrical Machines (ICEM)","13 Oct 2022","2022","","","1609","1615","This paper presents the potential and the sensitivity of the Variational Autoencoder (VAE) technique in early detection of a failure mode of large hydrogenerator. Real vibration data collected in situ, acquired from the site for a healthy machine, are used for the training and validation of this technique. Synthetic faulty signals (rotor inter-turn short-circuits faults), in which statistical parameters are calculated, have been used to test the sensitivity of the model in detecting the occurrence of this fault. The faulty signals were created by injecting the fault, based on its frequency pattern, to a set of healthy vibration signals collected in situ. The obtained results prove the prevalence of this technique and its sensitivity in detecting anomalies at early stages based on the variation of the reconstruction error","2381-4802","978-1-6654-1432-6","10.1109/ICEM51905.2022.9910728","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9910728","hydrogenerators;diagnosis;dataset;vibration;inter-turn short-circuits;Variational Autoencoder","Vibrations;Training;Fault diagnosis;Electric potential;Sensitivity;Three-dimensional displays;Rotors","","","","","","21","IEEE","13 Oct 2022","","","IEEE","IEEE Conferences"
"FastMVAE2: On improving and accelerating the fast variational autoencoder-based source separation algorithm for determined mixtures","L. Li; H. Kameoka; S. Makino","Nagoya University, Furo-cho, Chikusa-ku, Nagoya, Japan; NTT Communication Science Laboratories, NTT Corporation, Atsugi-shi, Kanagawa, Japan; University of Tsukuba, Tsukuba, Ibaraki, Japan","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2022","PP","99","1","15","This paper proposes a new source model and training scheme to improve the accuracy and speed of the multichannel variational autoencoder (MVAE) method. The MVAE method is a recently proposed powerful multichannel source separation method. It consists of pretraining a source model represented by a conditional VAE (CVAE) and then estimating separation matrices along with other unknown parameters so that the log-likelihood is non-decreasing given an observed mixture signal. Although the MVAE method has been shown to provide high source separation performance, one drawback is the computational cost of the backpropagation steps in the separation-matrix estimation algorithm. To overcome this drawback, a method called “FastMVAE” was subsequently proposed, which uses an auxiliary classifier VAE (ACVAE) to train the source model. By using the classifier and encoder trained in this way, the optimal parameters of the source model can be inferred efficiently, albeit approximately, in each step of the algorithm. However, the generalization capability of the trained ACVAE source model was not satisfactory, which led to poor performance in situations with unseen data. To improve the generalization capability, this paper proposes a new model architecture (called the “ChimeraACVAE” model) and a training scheme based on knowledge distillation. The experimental results revealed that the proposed source model trained with the proposed loss function achieved better source separation performance with less computation time than FastMVAE. We also confirmed that our methods were able to separate 18 sources with a reasonably good accuracy.","2329-9304","","10.1109/TASLP.2022.3214763","JST CREST(grant numbers:JPMJCR19A3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9919339","Multichannel source separation;multichannel variational autoencoder (MVAE);fast algorithm;auxiliary classifier VAE;knowledge distillation","Source separation;Training;Spectrogram;Classification algorithms;Task analysis;Computational modeling;Backpropagation","","","","","","","IEEE","14 Oct 2022","","","IEEE","IEEE Early Access Articles"
"Disease progression score estimation from multimodal imaging and microRNA data using supervised variational autoencoders","V. Kmetzsch; E. Becker; D. Saracino; D. Rinaldi; A. Camuzat; I. Le Ber; O. Colliot","Sorbonne Université, Institut du Cerveau - Paris Brain Institute - ICM, CNRS, Inria, Inserm, AP-HP, Paris, France; Univ Rennes, Inria, CNRS, IRISA, Rennes, France; Sorbonne Université, Institut du Cerveau - Paris Brain Institute - ICM, CNRS, Inria, Inserm, AP-HP, Paris, France; Sorbonne Université, Institut du Cerveau - Paris Brain Institute - ICM, CNRS, Inserm, AP-HP, Paris, France; Sorbonne Université, Institut du Cerveau - Paris Brain Institute - ICM, CNRS, Inserm, AP-HP, Paris, France; Sorbonne Université, Institut du Cerveau - Paris Brain Institute - ICM, CNRS, Inserm, AP-HP, Hôpital de la Pitié Salpêtrière, Institute of Memory and Alzheimer's Disease (IM2A), Paris, France; Sorbonne Université, Institut du Cerveau - Paris Brain Institute - ICM, CNRS, Inria, Inserm, AP-HP, Paris, France","IEEE Journal of Biomedical and Health Informatics","","2022","PP","99","1","12","Frontotemporal dementia and amyotrophic lateral sclerosis are rare neurodegenerative diseases with no effective treatment. The development of biomarkers allowing an accurate assessment of disease progression is crucial for evaluating new therapies. Concretely, neuroimaging and transcriptomic (microRNA) data have been shown useful in tracking their progression. However, no single biomarker can accurately measure progression in these complex diseases. Additionally, large samples are not available for such rare disorders. It is thus essential to develop methods that can model disease progression by combining multiple biomarkers from small samples. In this paper, we propose a new framework for computing a disease progression score (DPS) from cross-sectional multimodal data. Specifically, we introduce a supervised multimodal variational autoencoder that can infer a meaningful latent space, where latent representations are placed along a disease trajectory. A score is computed by orthogonal projections onto this path. We evaluate our framework with multiple synthetic datasets and with a real dataset containing 14 patients, 40 presymptomatic genetic mutation carriers and 37 controls from the PREV-DEMALS study. There is no ground truth for the DPS in real-world scenarios, therefore we use the area under the ROC curve (AUC) as a proxy metric. Results with the synthetic datasets support this choice, since the higher the AUC, the more accurate the predicted simulated DPS. Experiments with the real dataset demonstrate better performance in comparison with state-of-the-art approaches. The proposed framework thus leverages cross-sectional multimodal datasets with small sample sizes to objectively measure disease progression, with potential application in clinical trials.","2168-2208","","10.1109/JBHI.2022.3208517","French government under management of Agence Nationale de la Recherche(grant numbers:ANR-19-P3IA-0001); (PRAIRIE 3IA Institute)(grant numbers:ANR-10-IAIHU-06); project PREV-DEMALS(grant numbers:ANR-14-CE15-0016-07); Inria Project Lab Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9896928","Disease progression score;Deep learning;MicroRNA;Multimodal data;Neurodegenerative disease;Neuroimaging;Variational autoencoder","Diseases;Biomarkers;Biological system modeling;Computational modeling;Trajectory;Data models;Brain modeling","","","","","","","IEEE","21 Sep 2022","","","IEEE","IEEE Early Access Articles"
"Variational Domain Adversarial Learning With Mutual Information Maximization for Speaker Verification","Y. Tu; M. -W. Mak; J. -T. Chien","Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong SAR; Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong SAR; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu City, Taiwan","IEEE/ACM Transactions on Audio, Speech, and Language Processing","10 Jul 2020","2020","28","","2013","2024","Domain mismatch is a common problem in speaker verification (SV) and often causes performance degradation. For the system relying on the Gaussian PLDA backend to suppress the channel variability, the performance would be further limited if there is no Gaussianity constraint on the learned embeddings. This paper proposes an information-maximized variational domain adversarial neural network (InfoVDANN) that incorporates an InfoVAE into domain adversarial training (DAT) to reduce domain mismatch and simultaneously meet the Gaussianity requirement of the PLDA backend. Specifically, DAT is applied to produce speaker discriminative and domain-invariant features, while the InfoVAE performs variational regularization on the embedded features so that they follow a Gaussian distribution. Another benefit of the InfoVAE is that it avoids posterior collapse in VAEs by preserving the mutual information between the embedded features and the training set so that extra speaker information can be retained in the features. Experiments on both SRE16 and SRE18-CMN2 show that the InfoVDANN outperforms the recent VDANN, which suggests that increasing the mutual information between the embedded features and input features enables the InfoVDANN to extract extra speaker information that is otherwise not possible.","2329-9304","","10.1109/TASLP.2020.3004760","RGC of Hong Kong SAR(grant numbers:PolyU 152137/17E); Taiwan MOST(grant numbers:109-2634-F-009-024); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9124672","Speaker verification (SV);domain adaptation;domain adversarial training;variational autoencoder;mutual information","Training;Feature extraction;Mutual information;Neural networks;Adaptation models;Decoding;Training data","Gaussian distribution;learning (artificial intelligence);neural nets;speaker recognition","variational domain adversarial learning;mutual information maximization;speaker verification;domain mismatch;performance degradation;Gaussian PLDA backend;channel variability;Gaussianity constraint;information-maximized variational domain adversarial neural network;InfoVDANN;InfoVAE;domain adversarial training;DAT;Gaussianity requirement;speaker discriminative;domain-invariant features;variational regularization;embedded features;Gaussian distribution","","14","","60","IEEE","24 Jun 2020","","","IEEE","IEEE Journals"
"Variational Information Diffusion for Probabilistic Cascades Prediction","F. Zhou; X. Xu; K. Zhang; G. Trajcevski; T. Zhong","School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; Robert H. Smith School of Business, University of Maryland, College Park, USA; Department of Electrical and Computer Engineering, Iowa State University, USA; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE INFOCOM 2020 - IEEE Conference on Computer Communications","4 Aug 2020","2020","","","1618","1627","Understanding in-network information diffusion is a fundamental problem in many application domains and one of the primary challenges is to predict the size of the information cascade. Most of the existing models rely either on hypothesized point process (e.g., Poisson and Hawkes process), or simply predict the information propagation via deep neural networks. However, they fail to simultaneously capture the underlying structure of a cascade graph and the propagation of uncertainty in the diffusion, which may result in unsatisfactory prediction performance. To address these, in this work we propose a novel probabilistic cascade prediction framework: Variational Cascade (VaCas) graph learning networks. VaCas allows a non-linear information diffusion inference and models the information diffusion process by learning the latent representation of both the structural and temporal information. It is a pattern-agnostic model leveraging variational inference to learn the node-level and cascade-level latent factors in an unsupervised manner. In addition, VaCas is capable of capturing both the cascade representation uncertainty and node infection uncertainty, while enabling hierarchical pattern learning of information diffusion. Extensive experiments conducted on real-world datasets demonstrate that VaCas significantly improves the prediction accuracy, compared to state-of-the-art approaches, while also enabling interpretability.","2641-9874","978-1-7281-6412-0","10.1109/INFOCOM41043.2020.9155349","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155349","Information cascades;variational autoencoder;graph learning","Uncertainty;Predictive models;Neural networks;Probabilistic logic;Machine learning;Computational modeling;Diffusion processes","graph theory;learning (artificial intelligence);neural nets","Variational information diffusion;probabilistic cascades prediction;in-network information diffusion;fundamental problem;application domains;primary challenges;information cascade;hypothesized point process;information propagation;deep neural networks;unsatisfactory prediction performance;novel probabilistic cascade prediction framework;Variational Cascade graph learning networks;VaCas;information diffusion process;latent representation;structural information;temporal information;pattern-agnostic model;variational inference;cascade-level latent factors;cascade representation uncertainty;infection uncertainty;prediction accuracy","","13","","58","","4 Aug 2020","","","IEEE","IEEE Conferences"
"Information Maximized Variational Domain Adversarial Learning for Speaker Verification","Y. Tu; M. -W. Mak; J. -T. Chien","Dept. of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong SAR; Dept. of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong SAR; Dept. of Electrical and Computer Engineering, National Chiao Tung University, Taiwan","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","6449","6453","Domain mismatch is a common problem in speaker verification. This paper proposes an information-maximized variational domain adversarial neural network (InfoVDANN) to reduce domain mismatch by incorporating an InfoVAE into domain adversarial training (DAT). DAT aims to produce speaker discriminative and domain-invariant features. The InfoVAE has two roles. First, it performs variational regularization on the learned features so that they follow a Gaussian distribution, which is essential for the standard PLDA backend. Second, it preserves mutual information between the features and the training set to extract extra speaker discriminative information. Experiments on both SRE16 and SRE18-CMN2 show that the InfoVDANN outperforms the recent VDANN, which suggests that increasing the mutual information between the latent features and input features enables the InfoVDANN to extract extra speaker information that is otherwise not possible.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9053735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9053735","Speaker verification;domain adaptation;adversarial training;variational autoencoder;mutual information","Training;Neural networks;Gaussian distribution;Feature extraction;Data mining;Mutual information;Standards","feature extraction;Gaussian distribution;Gaussian processes;learning (artificial intelligence);speaker recognition","information maximized variational domain adversarial learning;speaker verification;information-maximized variational domain adversarial neural network;InfoVDANN;InfoVAE;domain adversarial training;DAT;domain-invariant features;variational regularization;mutual information;speaker discriminative information;latent features;speaker information","","5","","41","","9 Apr 2020","","","IEEE","IEEE Conferences"
"An Overview of Unsupervised Deep Feature Representation for Text Categorization","S. Wang; J. Cai; Q. Lin; W. Guo","Fujian Provincial Key Laboratory of Network Computing and Intelligent Information Processing, Fuzhou University, Fuzhou, China; Fujian Provincial Key Laboratory of Network Computing and Intelligent Information Processing, Fuzhou University, Fuzhou, China; Fujian Provincial Key Laboratory of Network Computing and Intelligent Information Processing, Fuzhou University, Fuzhou, China; Fujian Provincial Key Laboratory of Network Computing and Intelligent Information Processing, Fuzhou University, Fuzhou, China","IEEE Transactions on Computational Social Systems","10 Jun 2019","2019","6","3","504","517","High-dimensional features are extensively accessible in machine learning and computer vision areas. How to learn an efficient feature representation for specific learning tasks is invariably a crucial issue. Due to the absence of class label information, unsupervised feature representation is exceedingly challenging. In the last decade, deep learning has captured growing attention from researchers in a broad range of areas. Most of the deep learning methods are supervised, which is required to be fed with a large amount of accurately labeled data points. Nevertheless, acquiring sufficient accurately labeled data is unaffordable in numerous real-world applications, which is suggestive of the needs of unsupervised learning. Toward this end, quite a few unsupervised feature representation approaches based on deep learning have been proposed in recent years. In this paper, we attempt to provide a comprehensive overview of unsupervised deep learning methods and compare their performances in text categorization. Our survey starts with the autoencoder and its representative variants, including sparse autoencoder, stacked autoencoder, contractive autoencoder, denoising autoencoder, variational autoencoder, graph autoencoder, convolutional autoencoder, adversarial autoencoder, and residual autoencoder. Aside from autoencoders, deconvolutional networks, restricted Boltzmann machines, and deep belief nets are introduced. Then, the reviewed unsupervised feature representation methods are compared in terms of text clustering. Extensive experiments in eight publicly available data sets of text documents are conducted to provide a fair test bed for the compared methods.","2329-924X","","10.1109/TCSS.2019.2910599","National Natural Science Foundation of China(grant numbers:U1705262,61672159); Technology Innovation Platform Project of Fujian Province(grant numbers:2014H2005,2009J1007); Fujian Collaborative Innovation Center for Big Data Application in Governments; Fujian Engineering Research Center of Big Data Analysis and Processing; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8700490","Autoencoder;deconvolutional network;deep belief nets;deep learning;feature representation;text categorization;unsupervised learning","Biological neural networks;Deep learning;Decoding;Task analysis;Optimization;Unsupervised learning;Neurons","belief networks;Boltzmann machines;computer vision;feature extraction;text analysis;unsupervised learning","unsupervised deep feature representation;text categorization;high-dimensional features;machine learning;computer vision areas;class label information;accurately labeled data points;unsupervised deep learning methods;sparse autoencoder;stacked autoencoder;contractive autoencoder;variational autoencoder;graph autoencoder;convolutional autoencoder;adversarial autoencoder;residual autoencoder;deep belief nets;reviewed unsupervised feature representation methods;feature representation;restricted Boltzmann machines","","17","","93","IEEE","26 Apr 2019","","","IEEE","IEEE Journals"
"Variational grid setting network","Y. -N. Chuang; Z. -Y. Huang; Y. -L. Tsai","Dept. of Mathematical Sciences, National Chengchi University, Taipei, Taiwan; Institute of Industrial Engineering, National Taiwan University, Taipei, Taiwan; Dept. of Mathematical Sciences, National Chengchi University, Taipei, TW","2017 International Conference on Asian Language Processing (IALP)","22 Feb 2018","2017","","","222","226","We propose a new neural network architecture for automatic generation of missing characters in a Chinese font set. We call the neural network architecture the Variational Grid Setting Network which is based on the variational autoencoder (VAE) with some tweaks. The neural network model is able to generate missing characters relatively large in size (256 × 256 pixels). Moreover, we show that one can use very few samples for training data set, and get a satisfied result.","","978-1-5386-1981-0","10.1109/IALP.2017.8300584","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8300584","deep learning;typography;Chinese character;grid-setting;neural network","Training;Neural networks;Training data;Convolution;Electronic mail;Decoding;Probability distribution","character recognition;character sets;learning (artificial intelligence);neural net architecture","neural network architecture;automatic generation;Chinese font set;Variational Grid Setting Network;variational autoencoder;neural network model;VAE","","","","8","","22 Feb 2018","","","IEEE","IEEE Conferences"
"Cross-modal Variational Auto-encoder for Content-based Micro-video Background Music Recommendation","J. Yi; Y. Zhu; J. Xie; Z. Chen","School of Computer Science, Wuhan University, Wuhan, China, 430072 (e-mail: yijing-v@whu.edu.cn); School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China, 430079 (e-mail: yaochenzhu@whu.edu.cn); School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China, 430079 (e-mail: xjyxie@whu.edu.cn); School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China, 430079 (e-mail: zzchen@ieee.org)","IEEE Transactions on Multimedia","","2021","PP","99","1","1","In this paper, we propose a cross-modal variational auto-encoder (CMVAE) for content-based micro-video background music recommendation. CMVAE is a hierarchical Bayesian generative model that matches relevant background music to a micro-video by projecting these two multimodal inputs into a shared low-dimensional latent space, where the alignment of two corresponding embeddings of a matched video-music pair is achieved by cross-generation. Moreover, the multimodal information is fused by the product-of-experts (PoE) principle, where the semantic information in visual and textual modalities of the micro-video are weighted according to their variance estimations such that the modality with a lower noise level is given more weights. Therefore, the micro-video latent variables contain less irrelevant information that results in a more robust model generalization. Furthermore, we establish a large-scale content-based micro-video background music recommendation dataset, TT-150k, composed of approximately 3,000 different background music clips associated to 150,000 micro-videos from different users. Extensive experiments on the established TT- 150k dataset demonstrate the effectiveness of the proposed method. A qualitative assessment of CMVAE by visualizing some recommendation results is also included.","1941-0077","","10.1109/TMM.2021.3128254","National Natural Science Foundation of China(grant numbers:62036005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616385","Cross-modal matching;Variational autoencoder;Product-of-experts system;Recommendation systems","Videos;Visualization;Recommender systems;Semantics;Mood;Task analysis;Pattern matching","","","","","","","IEEE","16 Nov 2021","","","IEEE","IEEE Early Access Articles"
"Deep Human-guided Conditional Variational Generative Modeling for Automated Urban Planning","D. Wang; K. Liu; P. Johnson; L. Sun; B. Du; Y. Fu","Department of Computer Science, Beihang University, Beijing; Department of Computer Science, Beihang University, Beijing; Department of Computer Science, Beihang University, Beijing; Department of Computer Science, Beihang University, Beijing; Department of Computer Science, Beihang University, Beijing; Department of Computer Science, University of Central Florida, Orlando","2021 IEEE International Conference on Data Mining (ICDM)","24 Jan 2022","2021","","","679","688","Urban planning designs land-use configurations and can benefit building livable, sustainable, safe communities. Inspired by image generation, deep urban planning aims to leverage deep learning to generate land-use configurations. However, urban planning is a complex process. Existing studies usually ignore the need of personalized human guidance in planning, and spatial hierarchical structure in planning generation. Moreover, the lack of large-scale land-use configuration samples poses a data sparsity challenge. This paper studies a novel deep human guided urban planning method to jointly solve the above challenges. Specifically, we formulate the problem into a deep conditional variational autoencoder based framework. In this framework, we exploit the deep encoder-decoder design to generate land-use configurations. To capture the spatial hierarchy structure of land uses, we enforce the decoder to generate both the coarse-grained layer of functional zones, and the fine-grained layer of POI distributions. To integrate human guidance, we allow humans to describe what they need as texts and use these texts as a model condition input. To mitigate training data sparsity and improve model robustness, we introduce a variational Gaussian embedding mechanism. It not just allows us to better approximate the embedding space distribution of training data and sample a larger population to overcome sparsity, but also adds more probabilistic randomness into the urban planning generation to improve embedding diversity so as to improve robustness. Finally, we present extensive experiments to validate the enhanced performances of our method.","2374-8486","978-1-6654-2398-4","10.1109/ICDM51629.2021.00079","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679173","Automated Urban Planning;Conditional Variational Generative Model;Human Guided;Spatial Data Mining","Deep learning;Image synthesis;Urban planning;Sociology;Training data;Probabilistic logic;Robustness","deep learning (artificial intelligence);encoding;Gaussian processes;image reconstruction;land use planning;probability","deep human-guided conditional variational generative modeling;automated urban planning;image generation;personalized human guidance;spatial hierarchical structure;data sparsity challenge;deep conditional variational autoencoder based framework;deep encoder-decoder design;spatial hierarchy structure;training data sparsity;variational Gaussian embedding mechanism;deep learning;land-use configuration samples;functional zone coarse-grained layer;POI distribution fine-grained layer;embedding space distribution;probabilistic randomness","","1","","28","IEEE","24 Jan 2022","","","IEEE","IEEE Conferences"
"Echo-state conditional variational autoencoder for anomaly detection","S. Suh; D. H. Chae; H. -G. Kang; S. Choi","Department of Computer Science and Engineering, Pohang University of Science and Technology, Pohang, Korea; SK Telecom, Access Network Lab, Korea; SK Telecom, Access Network Lab, Korea; Department of Computer Science and Engineering, Pohang University of Science and Technology, Pohang, Korea","2016 International Joint Conference on Neural Networks (IJCNN)","3 Nov 2016","2016","","","1015","1022","Anomaly detection involves identifying the events which do not conform to an expected pattern in data. A common approach to anomaly detection is to identify outliers in a latent space learned from data. For instance, PCA has been successfully used for anomaly detection. Variational autoencoder (VAE) is a recently-developed deep generative model which has established itself as a powerful method for learning representation from data in a nonlinear way. However, the VAE does not take the temporal dependence in data into account, so it limits its applicability to time series. In this paper we combine the echo-state network, which is a simple training method for recurrent networks, with the VAE, in order to learn representation from multivariate time series data. We present an echo-state conditional variational autoencoder (ES-CVAE) and demonstrate its useful behavior in the task of anomaly detection in multivariate time series data.","2161-4407","978-1-5090-0620-5","10.1109/IJCNN.2016.7727309","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727309","","Stochastic processes;History;Data models;Predictive models;Sparse matrices;Time series analysis;Probabilistic logic","learning (artificial intelligence);principal component analysis;security of data;time series","echo-state conditional variational autoencoder;anomaly detection;PCA;latent space;deep generative model;learning representation;training method;recurrent networks;multivariate time series data;ES-CVAE","","31","","19","","3 Nov 2016","","","IEEE","IEEE Conferences"
"AutoTag: Recurrent Variational Autoencoder for Unsupervised Apnea Detection with RFID Tags","C. Yang; X. Wang; S. Mao","Department of Electrical and Computer Engineering, Auburn University, Auburn, USA; Department of Electrical and Computer Engineering, Auburn University, Auburn, USA; Department of Electrical and Computer Engineering, Auburn University, Auburn, USA","2018 IEEE Global Communications Conference (GLOBECOM)","21 Feb 2019","2018","","","1","7","With the growth of smart healthcare in the Internet of Things (IoT), breathing monitoring and apnea detection are of increasing importance. In this paper, we propose AutoTag, a recurrent variational autoencoder model for breathing and apnea detection with commodity RFID Tags. The AutoTag system consists of signal extraction, calibration, and respiration monitoring modules. We propose a novel method to mitigate the frequency hopping offset with realtime calibration for FCC complaint RFID systems, and a new recurrent variational autoencoder method for apnea and breathing detection. Experimental results demonstrate the effectiveness of the proposed AutoTag system in two different environments.","2576-6813","978-1-5386-4727-1","10.1109/GLOCOM.2018.8648073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648073","","Monitoring;Calibration;Data mining;RFID tags;FCC;Biomedical monitoring","biomedical communication;calibration;health care;Internet of Things;medical signal processing;patient monitoring;pneumodynamics;radiofrequency identification","respiration monitoring modules;FCC complaint RFID systems;breathing detection;AutoTag system;unsupervised apnea detection;smart healthcare;IoT;recurrent variational autoencoder model;commodity RFID Tags;signal extraction;Internet of Things","","12","1","22","","21 Feb 2019","","","IEEE","IEEE Conferences"
"Unsupervised Real Image Super-Resolution via Generative Variational AutoEncoder","Z. -S. Liu; W. -C. Siu; L. -W. Wang; C. -T. Li; M. -P. Cani; Y. -L. Chan","The Hong Kong Polytechnic University; The Hong Kong Polytechnic University; The Hong Kong Polytechnic University; The Hong Kong Polytechnic University; LIX, École polytechnique; The Hong Kong Polytechnic University","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","1788","1797","Benefited from the deep learning, image Super-Resolution has been one of the most developing research fields in computer vision. Depending upon whether using a discriminator or not, a deep convolutional neural network can provide an image with high fidelity or better perceptual quality. Due to the lack of ground truth images in real life, people prefer a photo-realistic image with low fidelity to a blurry image with high fidelity. In this paper, we revisit the classic example based image super-resolution approaches and come up with a novel generative model for perceptual image super-resolution. Given that real images contain various noise and artifacts, we propose a joint image denoising and super-resolution model via Variational AutoEncoder. We come up with a conditional variational autoencoder to encode the reference for dense feature vector which can then be transferred to the decoder for target image denoising. With the aid of the discriminator, an additional overhead of super-resolution subnetwork is attached to super-resolve the denoised image with photo-realistic visual quality. We participated the NTIRE2020 Real Image Super-Resolution Challenge [24] . Experimental results show that by using the proposed approach, we can obtain enlarged images with clean and pleasant features compared to other supervised methods. We also compared our approach with state-of-the-art methods on various datasets to demonstrate the efficiency of our proposed unsupervised super-resolution model.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150958","","Noise reduction;Training;Mathematical model;Spatial resolution;Decoding;Distortion","computer vision;feature extraction;image classification;image denoising;image reconstruction;image resolution;learning (artificial intelligence);neural nets;realistic images","ground truth images;photo-realistic image;blurry image;perceptual image super-resolution;super-resolution model;image denoising;generative variational autoencoder;NTIRE2020 Real Image Super-Resolution Challenge","","8","","38","","28 Jul 2020","","","IEEE","IEEE Conferences"
"A New Approach for Smoking Event Detection Using a Variational Autoencoder and Neural Decision Forest","C. Fan; F. Gao","College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China","IEEE Access","9 Jul 2020","2020","8","","120835","120849","Smoking is associated with cancer, cardiovascular disease and premature death and can cause severe fire hazards. To assist with smoking cessation, this paper presents a wireless body area network-based system consisting of two off-the-shelf devices, one smartphone and one smartwatch, to detect smoking events by mining the inertial sensor data from both devices. In the system, an end-to-end trainable unified model is implemented by combining a variational autoencoder with a random forest to classify the collected data into smoking and nonsmoking after data preprocessing. The variational autoencoder is adopted to learn the feature representation and deal with the class imbalance problem, and the stochastic decision forest is adopted to guide the global optimization of the parameter learning process. Extensive validation of our scheme is performed on a large dataset we collected, and our scheme yields quite promising results in terms of accuracy and efficiency.","2169-3536","","10.1109/ACCESS.2020.3006163","National Natural Science Foundation of China(grant numbers:61402410); Zhejiang Provincial Natural Science Foundation of China(grant numbers:LY19F020027); Primary Research and Development Plan of Zhejiang Province(grant numbers:2018C01064); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9129702","Activity recognition;body sensor networks;data acquisition;data preprocessing;event detection;neural networks;ubiquitous computing;wearable sensors","Event detection;Forestry;Wireless communication;Motion detection;Accelerometers;Body area networks","body area networks;body sensor networks;diseases;learning (artificial intelligence);medical computing;neural nets;pattern classification","parameter learning process;wireless body area network-based system;smoking events;smoking cessation;premature death;cardiovascular disease;neural decision forest;smoking event detection;stochastic decision forest;data preprocessing;random forest;variational autoencoder;end-to-end trainable unified model","","7","","29","CCBY","30 Jun 2020","","","IEEE","IEEE Journals"
"Cross-Domain Variational Autoencoder for Recommender Systems","J. Shi; Q. Wang","Department of Information and Computer Science, Beijing University of Technology, Beijing, China; Department of Information Information Center, Beijing University of Technology, Beijing, China","2019 IEEE 11th International Conference on Advanced Infocomm Technology (ICAIT)","19 Dec 2019","2019","","","67","72","Aiming at the problem of sparse data and user cold start in a single domain for collaborative filtering, this paper proposes a cross-domain recommendation model called cross-domain variational autoencoder (CDVAE) based on Bayesian theory. The model uses rating data to construct latent representations of users and items in multiple domains, utilizes overlapping users in different domains, and draws on the idea of variational autoencoder (VAE) to train a user generating networks cross-domains based on user preferences to different domains. Bayesian theory is introduced to ensure the generation ability and robustness of the model. Finally, based on the user’s preference to the source domain, the user’s preference prediction in the target domain is obtained. The generation of the recommendation result is obtained by the user’s preference weighting in the source domain and the target domain, and the user’s multi-source interest preference is considered to improve the accuracy. The experimental results show that CDVAE is able to significantly outperform the state-of-the-art recommendation methods of more robust performance.","","978-1-7281-4778-9","10.1109/ICAIT.2019.8935901","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8935901","collaborative filtering;cold start;cross-domain recommendation","Bayes methods;Matrix decomposition;Motion pictures;Sparse matrices;Mathematical model;Deep learning;Data mining","Bayes methods;collaborative filtering;recommender systems","cross-domain variational autoencoder;recommender systems;cross-domain recommendation model;Bayesian theory;user preferences;collaborative filtering;CDVAE","","2","","14","","19 Dec 2019","","","IEEE","IEEE Conferences"
"High-dimensional Motion Segmentation by Variational Autoencoder and Gaussian Processes","M. Nagano; T. Nakamura; T. Nagai; D. Mochihashi; I. Kobayashi; W. Takano","Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, Chofu-shi, Japan; Department of Mechanical Engineering and Intelligent Systems, The University of Electro-Communications, Chofu-shi, Japan; Department of Systems Innovation, Osaka University, Toyonaka-shi, Japan; Department of Statistical Inference and Mathematics, The Institute of Statistical Mathematics, Tachikawa, Japan; Department of Information Sciences, Ochanomizu University, Bunkyoku, Japan; Department of Systems Innovation, Osaka University, Toyonaka-shi, Japan","2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","28 Jan 2020","2019","","","105","111","Humans perceive continuous high-dimensional information by dividing it into significant segments such as words and units of motion. We believe that such unsupervised segmentation is also important for robots to learn topics such as language and motion. To this end, we previously proposed a hierarchical Dirichlet process-Gaussian process-hidden semi-Markov model (HDP-GP-HSMM). However, an important drawback to this model is that it cannot divide high-dimensional time-series data. Further, low-dimensional features must be extracted in advance. Segmentation largely depends on the design of features, and it is difficult to design effective features, especially in the case of high-dimensional data. To overcome this problem, this paper proposes a hierarchical Dirichlet process-variational autoencoder-Gaussian process-hidden semi-Markov model (HVGH). The parameters of the proposed HVGH are estimated through a mutual learning loop of the variational autoencoder and our previously proposed HDP-GP-HSMM. Hence, HVGH can extract features from high-dimensional time-series data, while simultaneously dividing it into segments in an unsupervised manner. In an experiment, we used various motion-capture data to show that our proposed model estimates the correct number of classes and more accurate segments than baseline methods. Moreover, we show that the proposed method can learn latent space suitable for segmentation.","2153-0866","978-1-7281-4004-9","10.1109/IROS40897.2019.8967987","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8967987","","","feature extraction;Gaussian processes;hidden Markov models;image motion analysis;image segmentation;time series;unsupervised learning","HVGH;HDP-GP-HSMM;high-dimensional time-series data;motion-capture data;high-dimensional motion segmentation;Gaussian processes;high-dimensional information;unsupervised segmentation;hierarchical Dirichlet process;low-dimensional features;hierarchical Dirichlet process-variational autoencoder-Gaussian process-hidden semiMarkov model","","2","","29","","28 Jan 2020","","","IEEE","IEEE Conferences"
"Including Sparse Production Knowledge into Variational Autoencoders to Increase Anomaly Detection Reliability","T. Hammerbacher; M. Lange-Hegermann; G. Platz","Phoenix Contact Electronics GmbH, Bad Pyrmont, Germany; Department of Electrical Engineering and Computer Science, Ostwestfalen-Lippe University of Applied Sciences, Lemgo, Germany; Phoenix Contact Electronics GmbH, Bad Pyrmont, Germany","2021 IEEE 17th International Conference on Automation Science and Engineering (CASE)","5 Oct 2021","2021","","","1262","1267","Digitalization leads to data transparency for production systems that we can benefit from with data-driven analysis methods like neural networks. For example, automated anomaly detection enables saving resources and optimizing the production. We study using rarely occurring information about labeled anomalies into Variational Autoencoder neural network structures to overcome information deficits of supervised and unsupervised approaches. This method outperforms all other models in terms of accuracy, precision, and recall. We evaluate the following methods: Principal Component Analysis, Isolation Forest, Classifying Neural Networks, and Variational Autoencoders on seven time series datasets to find the best performing detection methods. We extend this idea to include more infrequently occurring meta information about production processes. This use of sparse labels, both of anomalies or production data, allows to harness any additional information available for increasing anomaly detection performance.","2161-8089","978-1-6654-1873-7","10.1109/CASE49439.2021.9551636","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9551636","","Training;Neural networks;Transfer learning;Time series analysis;Supervised learning;Training data;Production","data analysis;neural nets;pattern classification;principal component analysis;reliability theory;supervised learning;time series;unsupervised learning","sparse production knowledge;anomaly detection reliability;data transparency;production systems;data-driven analysis methods;labeled anomalies;information deficits;supervised approaches;unsupervised approaches;principal component analysis;time series datasets;performing detection methods;meta information;production processes;sparse labels;production data;harness any additional information;anomaly detection performance;increase anomaly detection reliability;digitalization leads;variational autoencoder neural network structures;isolation forest","","","","21","","5 Oct 2021","","","IEEE","IEEE Conferences"
"Partial Mixture-of-Experts Similarity Variational Autoencoder for Clustering on Single Cell Data","C. Liu; L. Hong; F. Liu","School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China; School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China; School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China","2022 7th International Conference on Intelligent Computing and Signal Processing (ICSP)","24 May 2022","2022","","","615","619","Mixture-of-Experts Similarity Variational Autoencoder (MoE-Sim-VAE) is a novel generative clustering model which can cluster high-dimensional samples well and generalize to multi-modal distributions. However, high-dimensional feature from biological measurement is often incomplete. The common solution is to fill '0's to those missing elements in high-dimensional feature, which may lead to a decrease in accuracy. In this paper, we propose a data optimization strategy which called ‘partial VAE’ to overcome the issue caused by missing value using ‘maxpooling’ operation for partial inference. The improved version of MoE-Sim-VAE is called Partial Mixture-of-Experts Similarity Variational Autoencoder (Partial MoE-Sim-VAE). We evaluate the performance of clustering on public datasets including mouse organ-cell and simulated dataset with different proportions of ‘0’s. The experiments demonstrate that Partial MoE-Sim-VAE outperforms MoE-Sim-VAE.","","978-1-6654-7857-1","10.1109/ICSP54964.2022.9778475","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9778475","VAE;Partial Inference;Single Cell Data;Clustering;Multi-modal Distribution","Biological system modeling;Gaussian noise;Optimization methods;Signal processing;Mice;Data models;Stability analysis","biological organs;data analysis;data mining;optimisation;pattern clustering","Partial Mixture-of-Experts Similarity Variational Autoencoder;single cell data;novel generative clustering model;cluster high-dimensional samples;high-dimensional feature;partial VAE;partial inference;Partial MoE-Sim-VAE","","","","15","IEEE","24 May 2022","","","IEEE","IEEE Conferences"
"The Multilayer Perceptron Vector Quantized Variational AutoEncoder for Spectral Envelope Quantization","T. Srikotr; K. Mano","Division of Functional Control Systems, Graduate School of Engineering and Science, Shibaura Institute of Technology, Japan; Division of Functional Control Systems, Graduate School of Engineering and Science, Shibaura Institute of Technology, Japan","2020 IEEE International Conference on Consumer Electronics (ICCE)","23 Mar 2020","2020","","","1","6","Recently, deep generative learning has been introduced to replace the conventional mathematical models. In speech processing, the vector quantization was the effective compression method to reduce the amount of speech data before transmitting. In this paper, we propose The Multilayer Perceptron Vector Quantized Variational Autoencoder (MLP-VQ-VAE) to manage the flexibility of controlling the number of z-latent vectors to quantize and embedding space size efficiently. The MLP-VQVAE replaces the Convolutional Neural Network (CNN) with Multilayer Perceptron (MLP) in the encoder network and the decoder network of Vector Quantized Variational AutoEncoder (VQ-VAE) to receive the size of the effectively z-latent vectors for quantization and also the ability of dimensional reduction. In the experiments, the MLP-VQ-VAE is applied to quantize spectral envelope parameters from the 48 kHz high-quality vocoder named WORLD. The MLP-VQ-VAE reduces the memory sizes of the representation of z-latent or the length of vectors to quantize and embedding space size or codebook size around 1.6 times compared to the conventional vector quantization and 21.4 times for VQVAE. The proposed method decreases the Log Spectral Distortion around 1.1 dB lower than the conventional VQ and around 2.5 dB than the VQ-VAE.","2158-4001","978-1-7281-5186-1","10.1109/ICCE46568.2020.9043006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9043006","","Vector quantization;Vocoders;Multilayer perceptrons;Aerospace electronics;Distortion;Mathematical models;Decoding","data compression;learning (artificial intelligence);multilayer perceptrons;quantisation (signal);spectral analysis;speech coding;vector quantisation;vocoders","MLP-VQVAE;z-latent vectors;vector quantization;Multilayer Perceptron Vector Quantized Variational AutoEncoder;spectral envelope quantization;deep generative learning;frequency 48.0 kHz","","","","28","","23 Mar 2020","","","IEEE","IEEE Conferences"
"Dynamic Variational Autoencoders for Visual Process Modeling","A. Sagel; H. Shen","fortiss - The Research Institute of the Free State of Bavaria, Munich, Germany; fortiss - The Research Institute of the Free State of Bavaria, Munich, Germany","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","3677","3681","This work studies the problem of modeling visual processes by leveraging deep generative architectures for learning linear, Gaussian representations from observed sequences. We propose a joint learning framework, combining a vector autoregressive model and a Variational Autoencoder. This results in an architecture that allows Variational Autoencoders to simultaneously learn a non-linear observation as well as a linear state model from sequences of frames. We validate our approach on synthesis of artificial sequences and dynamic textures. To this end, we use our architecture to learn a statistical model of each visual process, and generate a new sequence from each learned visual process model.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9053660","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9053660","Neural Networks;Statistical Learning;Video Signal Processing;Unsupervised learning","Visualization;Process modeling;Conferences;Signal processing;Acoustics;Mathematical model;Speech processing","autoregressive processes;Gaussian processes;image sequences;image texture;learning (artificial intelligence);neural nets;statistical analysis","learning linear representations;learned visual process modeling;dynamic variational autoencoders;statistical model;dynamic textures;artificial sequences;linear state model;nonlinear observation;vector autoregressive model;joint learning framework;observed sequences;Gaussian representations;deep generative architectures","","","","23","","9 Apr 2020","","","IEEE","IEEE Conferences"
"A Variational Autoencoder Enhanced Deep Learning Model for Wafer Defect Imbalanced Classification","S. Wang; Z. Zhong; Y. Zhao; L. Zuo","School of Control Engineering, Northeastern University at Qinhuangdao, Qinhuangdao, China; School of Control Engineering, Northeastern University at Qinhuangdao, Qinhuangdao, China; School of Control Engineering, Northeastern University at Qinhuangdao, Qinhuangdao, China; Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA","IEEE Transactions on Components, Packaging and Manufacturing Technology","15 Dec 2021","2021","11","12","2055","2060","In semiconductor foundries, wafer map defect analysis is crucial to prevent yield excursion. However, traditional manual inspection can hardly meet the high-throughput demand. Deep learning-based automatic defect detection shows promising efforts to achieve high accuracy and efficiency, yet the current approaches’ performance is limited by the imbalanced dataset and lack of interpretability. In this article, we propose a variational autoencoder-enhanced deep learning model (VAEDLM) for wafer defect imbalanced classification. It is light-weighted and effective in wafer defect pattern recognition on imbalanced dataset. It used variational autoencoders (VAEs) and decoders to generate similar wafer defect maps and a refined deep convolutional neural network (CNN) for feature learning. We demonstrate the method using an authentic wafer map dataset, WM-811K. The performance is not only significantly improved after data augmentation, but it also beats the state-of-the art methods, reaching 99.19% accuracy, 99.10% recall, 99.23% precision, 99.96% AUC, and 99.16% for F1-score. It clearly demonstrates the method’s efficacy to deal with the imbalanced defect pattern. Our study using saliency map and t-distributed stochastic neighbor embedding (t-SNE) further leads to enhanced interpretability.","2156-3985","","10.1109/TCPMT.2021.3126083","Natural Science Foundation of China(grant numbers:62104034); Fundamental Research Fund from Central University(grant numbers:2023012); Natural Science Foundation of Hebei Province(grant numbers:F2020501033); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9606716","Convolutional neural network (CNN);data augmentation;encoder–decoder;pattern recognition;wafer defect","Integrated circuit manufacture;Feature extraction;Convolutional neural networks;Pattern recognition","convolutional neural nets;deep learning (artificial intelligence);feature extraction;image classification;inspection;learning (artificial intelligence);pattern classification;production engineering computing;semiconductor device manufacture","semiconductor foundries;wafer map defect analysis;yield excursion;deep learning-based automatic defect detection;imbalanced dataset;variational autoencoder-enhanced deep learning model;wafer defect pattern recognition;similar wafer defect maps;refined deep convolutional neural network;feature learning;authentic wafer map dataset;imbalanced defect pattern;saliency map;t-distributed stochastic neighbor;WM-811K dataset","","","","21","IEEE","8 Nov 2021","","","IEEE","IEEE Journals"
"Bridged Variational Autoencoders for Joint Modeling of Images and Attributes","R. Yadav; A. Sardana; V. P. Namboodiri; R. M. Hegde",IIT Kanpur; NVIDIA; IIT Kanpur; IIT Kanpur,"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)","14 May 2020","2020","","","1468","1476","Generative models have recently shown the ability to realistically generate data and model the distribution accurately. However, joint modeling of an image with the attribute that it is labeled with requires learning a cross modal correspondence between image and attribute data. Though the information present in a set of images and its attributes possesses completely different statistical properties altogether, there exists an inherent correspondence that is challenging to capture. Various models have aimed at capturing this correspondence either through joint modeling of a variational autoencoder or through separate encoder networks that are then concatenated. We present an alternative by proposing a bridged variational autoencoder that allows for learning cross-modal correspondence by incorporating cross-modal hallucination losses in the latent space. In comparison to the existing methods, we have found that by using a bridge connection in latent space we not only obtain better generation results, but also obtain highly parameter-efficient model which provide 40% reduction in training parameters for bimodal dataset and nearly 70% reduction for trimodal dataset. We validate the proposed method through comparison with state of the art methods and benchmarking on standard datasets.","2642-9381","978-1-7281-6553-0","10.1109/WACV45572.2020.9093565","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9093565","","Training;Decoding;Computational modeling;Data models;Bridges;Task analysis;Computer architecture","image processing;learning (artificial intelligence);neural nets;statistical analysis","cross-modal correspondence;cross-modal hallucination losses;latent space;attribute data;statistical properties;variational autoencoders;image modeling","","","","26","","14 May 2020","","","IEEE","IEEE Conferences"
"End-to-End Autonomous Driving Controller Using Semantic Segmentation and Variational Autoencoder","M. Azizpour; F. da Roza; N. Bajcinca","Department of Mechanical and Process Engineering, Technische Universitat Kaiserslautern, Kaiserslautern, Germany; Department of Mechanical and Process Engineering, Technische Universitat Kaiserslautern, Kaiserslautern, Germany; Department of Mechanical and Process Engineering, Technische Universitat Kaiserslautern, Kaiserslautern, Germany","2020 7th International Conference on Control, Decision and Information Technologies (CoDIT)","27 Nov 2020","2020","1","","1075","1080","There is a great interest in developing robust and efficient controllers for autonomous cars. A special issue is related with the high energy consumed by the embedded GPUs for tasks like sensory data processing, feature extraction and decision making. In this paper, the benefits of using Semantic-Segmentation and Variational-Autoencoder methods integrated with a camera-based end-to-end controller are shown. With Semantic Segmentation an agent trained using Deep Deterministic Policy Gradient algorithm exhibits a faster convergence, a better performing policy and increased robustness when compared with the alternative raw RGB input. The Variational-Autoencoder, used for dimensionality reduction, represented a significant decrease in the GPU usage and in the neural network processing time.","2576-3555","978-1-7281-5953-9","10.1109/CoDIT49905.2020.9263921","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9263921","","Semantics;Image segmentation;Automobiles;Feature extraction;Data models;Dimensionality reduction;Task analysis","deterministic algorithms;embedded systems;gradient methods;graphics processing units;image segmentation;learning (artificial intelligence);neural nets;road traffic control;robust control;traffic engineering computing","neural network processing time;GPU usage;end-to-end autonomous driving controller;variational autoencoder;semantic segmentation;camera based end-to-end controller;embedded GPU;autonomous cars;robust controllers;deep deterministic policy gradient algorithm","","","","18","","27 Nov 2020","","","IEEE","IEEE Conferences"
"Parallel Variational Autoencoders for Multiple Responses Generation","M. Li; P. Fu; Z. Lin; W. Wang","Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences","2020 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)","4 Jun 2021","2020","","","128","136","Variational autoencoders (VAEs) have been widely adopted in the field of diverse responses generation. The existing VAE-based responses generation models can be roughly divided into two categories: the first is to map multiple responses to a joint variable distribution; the second is to construct an individual variable distribution for each response. Models based on the joint distribution can generate diverse responses to some extent, but the difference among responses is inapparent. On the contrary, models based on the individual distribution can ensure the distinction among responses, while they are not good at modeling the correlation among responses. To combine these two kinds of VAEs and make the best of their respective advantages, we propose a Parallel Variational Autoencoders (PVAE) model that innovatively contains two variable distributions: correlation and distinction. The joint correlation distribution captures the common feature of all responses. Therefore, it can better retain the relevance to the given context. The individual distinction distribution models the unique content of each response, which promotes responses' diversity. In the generation step, keywords are sampled from these two distributions via the improved sampling process, which also enhances the diversity of responses. The experimental results demonstrate that our model achieves state-of-the-art performance on a weibo dataset.","","978-1-6654-1485-2","10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00042","National Natural Science Foundation of China(grant numbers:61906187,61976207); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9443751","Multiple Responses Generation;VAE;Diversity Generation","Correlation;Blogs;Sampling methods","feature extraction;knowledge based systems;social networking (online);speech processing","multiple responses generation;VAEs;diverse responses generation;existing VAE-based responses generation models;map multiple responses;joint variable distribution;individual variable distribution;joint distribution;individual distribution;Parallel Variational Autoencoders model;variable distributions;joint correlation distribution;individual distinction distribution models","","","","32","","4 Jun 2021","","","IEEE","IEEE Conferences"
"Deep Autoencoder-Based Anomaly Detection of Electricity Theft Cyberattacks in Smart Grids","A. Takiddin; M. Ismail; U. Zafar; E. Serpedin","Electrical and Computer Engineering, Texas A&M University, College Station, TX, USA; Department of Computer Science, Tennessee Tech University, Cookeville, TN, USA; Qatar Environment and Energy Research Institute, Hamad Bin Khalifa University, Doha, Qatar; Electrical and Computer Engineering, Texas A&M University, College Station, TX, USA","IEEE Systems Journal","25 Aug 2022","2022","16","3","4106","4117","Designing an electricity theft cyberattack detector for the advanced metering infrastructures (AMIs) is challenging due to the limited availability of electricity theft datasets (i.e., malicious datasets). Anomaly detectors, which are trained solely on honest customers’ energy consumption profiles (i.e., benign datasets), could potentially overcome this challenge. Unfortunately, existing anomaly detectors in AMIs present shallow architectures and are incapable of capturing the temporal correlations as well as the sophisticated patterns present in the electricity consumption data, which impact their detection performance negatively. This article proposes the adoption of deep (stacked) autoencoders with a long-short-term-memory (LSTM)-based sequence-to-sequence (seq2seq) structure. The depth of the autoencoders’ structure helps capture the sophisticated patterns of the data and the seq2seq LSTM model enables exploitation of the time-series nature of data. We investigate the performance of simple autoencoder, variational autoencoder, and autoencoder with attention (AEA), in which improved detection performance is observed when seq2seq structures are adopted compared to fully connected ones. Based on the simulation results, the AEA detector offers an enhancement of $4\!-\!21\%$ and $4\!-\!13\%$ in terms of detection rate and false alarm rate, respectively, compared to existing state-of-the-art detectors","1937-9234","","10.1109/JSYST.2021.3136683","Qatar National Research Fund(grant numbers:NPRP12S-0221-190127); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9674027","Autoencoders;deep machine learning;electricity stealth;hyperparameter optimization;sequence to sequence (seq2seq)","Detectors;Energy consumption;Computer crime;Smart meters;Training;Support vector machines;Anomaly detection","energy consumption;invasive software;learning (artificial intelligence);neural nets;object detection;power consumption;power engineering computing;power system security;smart power grids","deep autoencoder-based anomaly detection;electricity theft cyberattack detector;advanced metering infrastructures;AMIs;electricity theft datasets;malicious datasets;anomaly detectors;benign datasets;sophisticated patterns;electricity consumption data;detection performance;seq2seq LSTM model;variational autoencoder;seq2seq structures;AEA detector;detection rate","","2","","35","IEEE","7 Jan 2022","","","IEEE","IEEE Journals"
"Unsupervised Pre-Training of Imbalanced Data for Identification of Wafer Map Defect Patterns","H. S. Shon; E. Batbaatar; W. -S. Cho; S. G. Choi","Research Institute for Computer and Information Communication, Chungbuk National University, Cheongju, Republic of Korea; School of Electrical Computer Engineering, Chungbuk National University, Cheongju, Republic of Korea; Department of Management Information Systems, Chungbuk National University, Cheongju, Republic of Korea; School of Information and Communication Engineering, Chungbuk National University, Cheongju, Republic of Korea","IEEE Access","8 Apr 2021","2021","9","","52352","52363","Visual defect inspection and classification are significant steps of most manufacturing processes in the semiconductor and electronics industries. Known and unknown defects on wafer maps tend to cluster, and these spatial patterns provide valuable process information for supporting manufacturing in determining the root causes of abnormal processes. In previous studies, data augmentation-based deep learning (DL) techniques were most commonly used for the identification of wafer map defect patterns (WMDP). Data augmentation is an effective technique for improving the accuracy of modern image classifiers. However, current data augmentation implementations were manually designed for the WMDP problem. In this study, we propose a DL-based method with automatic data augmentation for the WMDP task. Basically, it focuses on learning effective discriminative features, from wafer maps, through a deep network structure. The network consists of a convolution-based variational autoencoder (CVAE) sequentially. First, we pre-trained the CVAE on large training data in an unsupervised manner. Second, we fine-tuned the encoder of the CVAE, which was followed by a neural network (NN) classifier, in a supervised manner. Additionally, we describe a simple procedure for automatically searching for improved data augmentation policies. The policy mainly consists of five image processing functions: rotation, flipping, shifting, shearing range, and zooming. The effectiveness of the proposed method was demonstrated through experimental results obtained from a simulation dataset and a real-world wafer map dataset (WM-811K). This study provides guidance for the application of deep learning in semiconductor manufacturing processes to improve product quality and yield.","2169-3536","","10.1109/ACCESS.2021.3068378","Basic Science Research Program through the National Research Foundation of Korea (NRF); Ministry of Education(grant numbers:2020R1A6A1A1204794511); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9385104","Classification;convolutional variational autoencoder;deep learning;imbalanced data;neural network;unsupervised pre-training;variational autoencoder;wafer map defect patterns","Feature extraction;Fabrication;Semiconductor device modeling;Deep learning;Visualization;Convolutional codes;Training","convolutional neural nets;feature extraction;image classification;inspection;learning (artificial intelligence);manufacturing processes;semiconductor technology","semiconductor manufacturing processes;real-world wafer map dataset;image processing functions;improved data augmentation policies;neural network classifier;CVAE;convolution-based variational autoencoder sequentially;deep network structure;automatic data augmentation;current data augmentation implementations;modern image classifiers;data augmentation-based deep learning techniques;wafer maps;wafer map defect patterns;unsupervised pre-training;temperature 811.0 K","","1","","62","CCBY","24 Mar 2021","","","IEEE","IEEE Journals"
"Intrusion Detection System After Data Augmentation Schemes Based on the VAE and CVAE","C. Liu; R. Antypenko; I. Sushko; O. Zakharchenko","Institute of Electronics and Information Engineering, Guangdong Ocean University, Zhanjiang, China; Radio Engineering Faculty, National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute,”, Kyiv, Ukraine; Radio Engineering Faculty, National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute,”, Kyiv, Ukraine; Radio Engineering Faculty, National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute,”, Kyiv, Ukraine","IEEE Transactions on Reliability","2 Jun 2022","2022","71","2","1000","1010","Industrial Internet of Things (IoT) is the most rapidly developing industry in the current IoT industry, and the intrusion detection system (IDS) remains one of the key technologies for industrial IoT security protection. Researchers have considered applying algorithms such as machine learning and deep learning to network IDSs to cope with complex and changing network environments and to automatically extract key features from high-dimensional feature data. However, in the real industrial IoT environment, data imbalance is the main factor that affects the performance of the deep-learning-based IDS. In this article, we study the network intrusion detection model based on data level. Three data-based research schemes are constructed step by step in this article, which are a data augmentation scheme based on the variational autoencoder (VAE), a data-balancing scheme based on the conditional VAE, and a data-balancing scheme based on random undersampling and conditional VAE. The three data-level-based schemes are combined with the deep-learning-based IDS. In this article, we build experiments based on the CSE-CIC-IDS2018 dataset to verify the effectiveness of three data processing schemes. After data enhancement through the third scheme, the Macro-F1-score of the convolutional-neural-network-based IDS model improved by 3.75% and the Macro-F1-score of the gated-recurrent-unit-based IDS model improved by 5.32%.","1558-1721","","10.1109/TR.2022.3164877","Guangdong Province Science and Technology Special Funds(grant numbers:2021A05237); Guangdong Science and Technology Department; overseas famous teachers(grant numbers:2020A1414010380); Enhancing School with Innovation of Guangdong Ocean University(grant numbers:230420023); Scientific Research start-up funds of Guangdong Ocean University(grant numbers:R20065); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761959","Conditional variational autoencoder (CVAE);data imbalance;deep learning;intrusion detection system (IDS);variational autoencoder (VAE)","Feature extraction;Data models;Deep learning;Industrial Internet of Things;Training;Convolutional neural networks;Machine learning algorithms","deep learning (artificial intelligence);Internet of Things;security of data","data augmentation scheme;data-balancing scheme;conditional VAE;data-level-based schemes;CSE-CIC-IDS2018 dataset;data processing schemes;data enhancement;convolutional-neural-network-based IDS model;gated-recurrent-unit-based IDS model;intrusion detection system;IoT industry;industrial IoT security protection;machine learning;deep learning;complex network environments;changing network environments;high-dimensional feature data;industrial IoT environment;data imbalance;network intrusion detection model;data level;data-based research schemes;industrial Internet of Things;variational autoencoder","","","","31","IEEE","22 Apr 2022","","","IEEE","IEEE Journals"
"Relational autoencoder for feature extraction","Q. Meng; D. Catchpoole; D. Skillicom; P. J. Kennedy","Faculty of Engineering and Information Technology, University of Technology Sydney, Sydney, Australia; Children's Cancer Research Unit, The Children's Hospital, Sydney, Australia; School of Computing, Queen's University at Kingston, Ontario, Canada; Faculty of Engineering and Information Technology, University of Technology Sydney, Sydney, Australia","2017 International Joint Conference on Neural Networks (IJCNN)","3 Jul 2017","2017","","","364","371","Feature extraction becomes increasingly important as data grows high dimensional. Autoencoder as a neural network based feature extraction method achieves great success in generating abstract features of high dimensional data. However, it fails to consider the relationships of data samples which may affect experimental results of using original and new features. In this paper, we propose a Relation Autoencoder model considering both data features and their relationships. We also extend it to work with other major autoencoder models including Sparse Autoencoder, Denoising Autoencoder and Variational Autoencoder. The proposed relational autoencoder models are evaluated on a set of benchmark datasets and the experimental results show that considering data relationships can generate more robust features which achieve lower construction loss and then lower error rate in further classification compared to the other variants of autoencoders.","2161-4407","978-1-5090-6182-2","10.1109/IJCNN.2017.7965877","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7965877","","Feature extraction;Data models;Image reconstruction;Training;Decoding;Principal component analysis;Noise reduction","feature extraction;neural nets","relational autoencoder;feature extraction;neural network;sparse autoencoder;denoising autoencoder;variational autoencoder","","46","1","45","","3 Jul 2017","","","IEEE","IEEE Conferences"
"Autoencoders - A Comparative Analysis in the Realm of Anomaly Detection","S. Schneider; D. Antensteiner; D. Soukup; M. Scheutz","Human-Robot Interaction Lab, Tufts University, Medford, MA, USA; Center for Vision, Automation and Control, Austrian Institute of Technology, Vienna, Austria; Center for Vision, Automation and Control, Austrian Institute of Technology, Vienna, Austria; Human-Robot Interaction Lab, Tufts University, Medford, MA, USA","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","23 Aug 2022","2022","","","1985","1991","We applied convolutional versions of a ""standard"" autoencoder (CAE), a variational autoencoder (VAE) and an adversarial autoencoder (AAE) to two different publicly available datasets and compared their anomaly detection performances. We used the MNIST dataset [14] as a simple anomaly detection scenario. The CIFAR10 dataset [13] was used to examine the autoencoders in a more complex anomaly detection task. The anomaly detection performance of our different autoencoder types is compared in a qualitative and quantitative manner. The time needed for training the models is measured to capture their complexity. The simplest model demanding the simplest training, the CAE, computes results which are nearly as accurate and for some cases even better than results achieved by the VAE and AAE. We show that all three autoencoder types computed convincing anomaly detection results for the more simple-structured MNIST scenario. However, none of the autoencoder types proved to capture a good representation of the relevant features of the more complex CIFAR10 dataset, leading to moderately good anomaly detection performances.","2160-7516","978-1-6654-8739-9","10.1109/CVPRW56347.2022.00216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9857253","","Training;Computational modeling;Dogs;Feature extraction;Time measurement;Decoding;Complexity theory","data handling;learning (artificial intelligence);security of data;statistical analysis","anomaly detection performances;comparative analysis;convolutional versions;standard autoencoder;CAE;variational autoencoder;VAE;adversarial autoencoder;AAE;different publicly available datasets;anomaly detection performance;MNIST dataset;simple anomaly detection scenario;complex anomaly detection task;anomaly detection results;simple-structured MNIST scenario;complex CIFAR10 dataset;autoencoder types","","","","23","IEEE","23 Aug 2022","","","IEEE","IEEE Conferences"
"Detecting Microcracks in Photovoltaics Silicon Wafers using Varitional Autoencoder","Z. Liu; F. Oviedo; E. M. Sachs; T. Buonassisi","Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA","2020 47th IEEE Photovoltaic Specialists Conference (PVSC)","5 Jan 2021","2020","","","0139","0142","Microcracks in silicon wafers significantly reduce the wafer fracture strength, reducing yield, and increasing $/W cost. In this study, we demonstrate a high-throughput prototype that relies on an edge-on illumination source of a near-infrared laser, and a high-framerate linescan camera to detect submillimeter cracks near the wafer edges. To fully achieve the automatic micro-crack detection, we use a variational autoencoder using the principle of unsupervised anomaly detection. We evaluate the different error metrics for crack detection. At the optimal selection of the error metric and threshold, our preliminary results demonstrate the detection precision of 0.83 and the detection recall of 0.72.","0160-8371","978-1-7281-6115-0","10.1109/PVSC45281.2020.9300366","U.S. Department of Energy (DOE); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9300366","wafer cracks;machine learning;high throughput;thin silicon wafer","Silicon;Image edge detection;Photovoltaic systems;Cameras;Anomaly detection;Machine learning;Lighting","condition monitoring;crack detection;electronic engineering computing;fracture toughness;microcracks;neural nets;photovoltaic power systems;semiconductor industry;semiconductor technology;silicon","photovoltaics silicon wafers;varitional autoencoder;high-throughput prototype;edge-on illumination source;near-infrared laser;high-framerate linescan camera;submillimeter crack detection;wafer edges;microcrack detection;variational autoencoder;unsupervised anomaly detection;wafer fracture strength reduction","","1","","12","","5 Jan 2021","","","IEEE","IEEE Conferences"
"Generating Healthy Aortic Root Geometries From Ultrasound Images of the Individual Pathological Morphology Using Deep Convolutional Autoencoders","J. Hagenah; M. Mehdi; F. Ernst","Institute for Robotics and Cognitive Systems, University of Luebeck, Germany; Institute for Robotics and Cognitive Systems, University of Luebeck, Germany; Institute for Robotics and Cognitive Systems, University of Luebeck, Germany","2019 Computing in Cardiology (CinC)","24 Feb 2020","2019","","","Page 1","Page 4","In valve-sparing aortic root reconstruction surgery, estimating the individual healthy shape of the aortic root as it was before pathological deformation is a challenging task. However, exactly this estimation is necessary to develop personalized aortic root prostheses. To support the surgeon in this decision making, we present a novel approach to reconstruct the healthy shape of an aortic root based on ultrasound images of its pathologically dilated state using representation learning. The idea is to identify a suitable representation of healthy and pathological aortic root shapes using a supervised variational autoencoder. Then, an image of the dilated root can be encoded, manipulated in the latent space, i.e. shifted towards the distribution of healthy valves, and a synthetic image of this resulting shape can be generated using the decoder. We evaluate our method on an ex-vivo porcine data set and provide a proof-of-concept of our method in a qualitative and quantitative way. Our results indicate the great potential of reducing a complex shape deformation task to a simple and intuitive shifting towards a specific class. Hence, our method could play an important role in the shaping of personalized implants and is, due to its data-driven nature, not limited to cardiovascular applications but also for other organs.","2325-887X","978-1-7281-6936-1","10.23919/CinC49843.2019.9005819","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005819","","Shape;Pathology;Image reconstruction;Surgery;Decoding;Ultrasonic imaging;Valves","biomedical ultrasonics;blood vessels;cardiovascular system;diseases;haemodynamics;learning (artificial intelligence);medical computing;surgery","dilated root;synthetic image;complex shape deformation task;aortic root geometries;ultrasound images;deep convolutional autoencoders;valve-sparing aortic root reconstruction surgery;pathological deformation;personalized aortic root prostheses;pathological aortic root shapes;supervised variational autoencoder","","","","7","","24 Feb 2020","","","IEEE","IEEE Conferences"
"DeepCoder: Semi-Parametric Variational Autoencoders for Automatic Facial Action Coding","D. L. Tran; R. Walecki; O. Rudovic; S. Eleftheriadis; B. Schuller; M. Pantic","Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE; Electromagnetism and Radar Department, ONERA, FRANCE","2017 IEEE International Conference on Computer Vision (ICCV)","25 Dec 2017","2017","","","3209","3218","Human face exhibits an inherent hierarchy in its representations (i.e., holistic facial expressions can be encoded via a set of facial action units (AUs) and their intensity). Variational (deep) auto-encoders (VAE) have shown great results in unsupervised extraction of hierarchical latent representations from large amounts of image data, while being robust to noise and other undesired artifacts. Potentially, this makes VAEs a suitable approach for learning facial features for AU intensity estimation. Yet, most existing VAE-based methods apply classifiers learned separately from the encoded features. By contrast, the non-parametric. (probabilistic) approaches, such as Gaussian Processes (GPs), typically outperform their parametric counterparts, but cannot deal easily with large amounts of data. To this end, we propose a novel VAE semi-parametric modeling framework, named DeepCoder, which combines the modeling power of parametric (convolutional) and non-parametric. (ordinal GPs) VAEs, for joint learning of(l) latent representations at multiple levels in a task hierarchy1, and (2) classification of multiple ordinal outputs. We show on benchmark datasets for AU intensity estimation that the proposed DeepCoder outperforms the state-of-the-art approaches, and related VAEs and deep learning models.","2380-7504","978-1-5386-1032-9","10.1109/ICCV.2017.346","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8237608","","Gold;Estimation;Face;Feature extraction;Encoding;Image reconstruction;Decoding","emotion recognition;face recognition;feature extraction;Gaussian processes;image representation;learning (artificial intelligence)","human face;inherent hierarchy;holistic facial expressions;facial action units;AUs;variational auto-encoders;unsupervised extraction;hierarchical latent representations;image data;VAEs a suitable approach;facial features;AU intensity estimation;existing VAE;encoded features;Gaussian Processes;parametric counterparts;novel VAE semiparametric modeling framework;named DeepCoder;modeling power;joint learning;multiple ordinal outputs;state-of-the-art approaches;related VAEs;deep learning models;semiparametric variational autoencoders;automatic facial action coding","","19","","57","","25 Dec 2017","","","IEEE","IEEE Conferences"
"Mesh Variational Autoencoders with Edge Contraction Pooling","Y. -J. Yuan; Y. -K. Lai; J. Yang; Q. Duan; H. Fu; L. Gao","Institute of Computing Technology, CAS, Beijing Key Laboratory of Mobile Computing and Pervasive Device; School of Computer Science and Informatics, Cardiff University, UK; Institute of Computing Technology, CAS, Beijing Key Laboratory of Mobile Computing and Pervasive Device; SenseTime Research; City University of Hong Kong; Shenzhen Research Institute of Big Data, Shenzhen","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","1105","1112","3D shape analysis is an important research topic in computer vision and graphics. While existing methods have generalized image-based deep learning to meshes using graph-based convolutions, the lack of an effective pooling operation restricts the learning capability of their networks. In this paper, we propose a novel pooling operation for mesh datasets with the same connectivity but different geometry, by building a mesh hierarchy using mesh simplification. For this purpose, we develop a modified mesh simplification method to avoid generating highly irregularly sized triangles. Our pooling operation effectively encodes the correspondence between coarser and finer meshes in the hierarchy. We then present a variational auto-encoder (VAE) structure with the edge contraction pooling and graph-based convolutions, to explore probability latent spaces of 3D surfaces and perform 3D shape generation. Our network requires far fewer parameters than the original mesh VAE and thus can handle denser models thanks to our new pooling operation and convolutional kernels. Our evaluation also shows that our method has better generalization ability and is more reliable in various applications, including shape generation and shape interpolation.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150750","","Three-dimensional displays;Shape;Strain;Interpolation;Neural networks;Machine learning","computational geometry;computer graphics;computer vision;graph theory;interpolation;learning (artificial intelligence);mesh generation;probability;shape recognition;solid modelling","shape interpolation;original mesh VAE;3D shape generation;variational auto-encoder structure;finer meshes;coarser;modified mesh simplification method;mesh hierarchy;mesh datasets;learning capability;effective pooling operation;graph-based convolutions;image-based deep learning;computer vision;3D shape analysis;edge contraction pooling;mesh variational autoencoders","","6","","37","IEEE","28 Jul 2020","","","IEEE","IEEE Conferences"
"Noise-to-Compression Variational Autoencoder for Efficient End-to-End Optimized Image Coding","J. Luo; S. Li; W. Dai; Y. Xu; D. Cheng; G. Li; H. Xiong","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Algorithm Innovation Lab, Huawei Cloud, Xi'an, China; Algorithm Innovation Lab, Huawei Cloud, Xi'an, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","2020 Data Compression Conference (DCC)","2 Jun 2020","2020","","","33","42","Generative model has emerged as a disruptive alternative for lossy compression of natural images, but suffers from the low-fidelity reconstruction. In this paper, we propose a noise-to-compression variational antoencoder (NC-VAE) to achieve efficient rate-distortion optimization (RDO) for end-to-end optimized image compression with a guarantee of fidelity. The proposed NC-VAE improves rate-distortion performance by adaptively adjusting the distribution of latent variables with trainable noise perturbation. Consequently, high-efficiency RDO is developed based on the distribution of latent variables for simplified decoder. Furthermore, robust end-to-end learning is developed over the corrupted inputs to suppress the deformation and color drift in standard VAE based generative models. Experimental results show that NC-VAE outperforms the state-of-the-art lossy image coders and recent end-to-end optimized compression methods in low bit-rate region, i.e., below 0.2 bits per pixel (bpp).","2375-0359","978-1-7281-6457-1","10.1109/DCC47342.2020.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9105715","","","codecs;data compression;image coding;image colour analysis;image reconstruction;learning (artificial intelligence);natural scenes;optimisation;rate distortion theory","color drift;efficient end-to-end optimized image coding;high-efficiency RDO;trainable noise perturbation;end-to-end optimized image compression;rate-distortion optimization;noise-to-compression variational antoencoder;low-fidelity reconstruction;natural images;lossy compression;noise-to-compression variational autoencoder;low bit-rate region;compression methods;state-of-the-art lossy image coders;NC-VAE;standard VAE based generative models;robust end-to-end learning","","1","","21","","2 Jun 2020","","","IEEE","IEEE Conferences"
"A Variational Autoencoder for Joint Chord and Key Estimation from Audio Chromagrams","Y. Wu; E. Nakamura; K. Yoshii","Graduate School of Informatics, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan","2020 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","31 Dec 2020","2020","","","500","506","This paper describes a deep generative approach to jointly estimating chords and keys from music signals. Although deep neural networks have widely been used for estimating various kinds of musical elements, joint estimation of multiple kinds of musical elements has scarcely been investigated so far. Given the mutual dependency between keys and chords, which both describe the harmonic content of music, we propose to use a unified deep classification model for jointly estimating chords and keys. At the heart of our study is the integration of supervised multi-task learning with unsupervised variational autoencoding for achieving improved performance and semi-supervised learning. Specifically, we formulate a deep latent-variable model that represents the generative process of chroma vectors from discrete key classes, chord classes, and continuous latent features. The deep classification model and another deep recognition model are then introduced for inferring keys, chords, and latent features from chroma vectors. These three models are trained jointly in a (semi-)supervised manner, where the generative model acts as a regularizer for the classification model. The experimental results show that the multi-task learning improves the consistency between estimated keys and chords and that the autoencoding-based regularization significantly improves the estimation performance.","2640-0103","978-988-14768-8-3","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9306269","","Music;Estimation;Data models;Hidden Markov models;Training;Multiple signal classification;Training data","audio signal processing;learning (artificial intelligence);music;neural nets","inferring keys;deep recognition model;continuous latent features;chord classes;discrete key classes;latent-variable model;semisupervised learning;unsupervised variational autoencoding;supervised multitask;unified deep classification model;joint estimation;musical elements;deep neural networks;music signals;deep generative approach;key estimation;joint chord;variational autoencoder;estimation performance;estimated keys;multitask learning;generative model;chroma vectors;chords","","","","29","","31 Dec 2020","","","IEEE","IEEE Conferences"
"Domain Mismatch Robust Acoustic Scene Classification Using Channel Information Conversion","S. Mun; S. Shon","Clova AI Research, Naver Corp., Seongnam, South Korea; MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","845","849","In recent acoustic scene classification (ASC) research field, training and test device channel mismatch have become an issue for the real world implementation. To address the issue, this paper proposes a channel domain conversion using factorized hierarchical variational autoencoder. Proposed method adapts both the source and target domain to a pre-defined specific domain. Unlike the conventional approach, the relationship between the target and source domain and information of each domain are not required in the adaptation process. Based on the experimental results using the IEEE Detection and Classification of Acoustic Scenes and Event 2018 task 1-B dataset and the baseline system, it is shown that the proposed approach can mitigate the channel mismatching issue of different recording devices.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683514","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683514","acoustic scene classification;factorized hierarchical variational autoencoder;domain adaptation","","acoustic signal processing;feature extraction;signal classification","channel information conversion;ASC;device channel mismatch;factorized hierarchical variational autoencoder;domain mismatch robust acoustic scene classification","","9","","20","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Late Breaking Results: A Neural Network that Routes ICs","D. Utyamishev; I. Partin-Vaisband","University of Illinois at Chicago, Chicago, IL; University of Illinois at Chicago, Chicago, IL","2020 57th ACM/IEEE Design Automation Conference (DAC)","9 Oct 2020","2020","","","1","2","A global router is proposed that learns from routed circuits and autonomously routes unseen layouts. The uniqueness of this approach is in redefining the global routing as a classical image-to-image processing problem. The imaging problem is efficiently solved with a deep learning system, comprising a variational autoencoder and custom loss function. This fundamentally new routing method provides a natural way for global routing parallelization. The deep router is designed, trained, and tested on an unseen 64×64 ISPD'98 benchmark circuit. The test results yield 3.2% decrease in routability and over 5X speedup in runtime as compared with the state-of-the-art FastRoute router.","0738-100X","978-1-7281-1085-1","10.1109/DAC18072.2020.9218598","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9218598","Global routing;deep learning;variational autoencoder;FastRoute","Routing;Layout;Training;Pins;Graphics processing units;Integrated circuits;Machine learning","electronic engineering computing;image processing;integrated circuit design;learning (artificial intelligence);network routing;neural nets","neural network;global router;routed circuits;deep learning system;variational autoencoder;custom loss function;image-to-image processing problem;ISPD98 benchmark circuit;FastRoute router","","1","","6","","9 Oct 2020","","","IEEE","IEEE Conferences"
"Comparison of Deep Generative Models for the Generation of Handwritten Character Images","Ö. Kırbıyık; E. Simsar; A. T. Cemgil","Bogazici Universitesi, Istanbul, TR; Bogazici Universitesi, Istanbul, TR; Bogazici Universitesi, Istanbul, TR","2019 27th Signal Processing and Communications Applications Conference (SIU)","22 Aug 2019","2019","","","1","4","In this study, we compare deep learning methods for generating images of handwritten characters. This problem can be thought of as a restricted Turing test: A human draws a character from any desired alphabet and the system synthesizes images with similar appearances. The intention here is not to merely duplicate the input image but to add random perturbations to give the impression of being human-produced. For this purpose, the images produced by two different generative models (Generative Adversarial Network and Variational Autoencoder) and the related training method (Reptile) are examined with respect to their visual quality in a subjective manner. Also, the capability of transferring the knowledge that is obtained by the model is challenged by using different datasets for the training and test processes. Using the proposed model and meta-learning method, it is possible to produce not only images similar to the ones in the training set but also novel images that belong to a class which is seen for the first time.","2165-0608","978-1-7281-1904-5","10.1109/SIU.2019.8806416","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8806416","Generative Adversarial Networks;Variational Autoencoders;Generative models;Meta-learning","Training;Generative adversarial networks;Gallium nitride;Information processing;Image synthesis;Stochastic processes;Deep learning","handwritten character recognition;learning (artificial intelligence)","generative models;related training method;Variational Autoencoder;Generative Adversarial Network;random perturbations;input image;restricted Turing test;handwritten characters;deep learning methods;handwritten character images;deep Generative models;meta-learning method;test processes","","","","","","22 Aug 2019","","","IEEE","IEEE Conferences"
"Textile Design Generation Using GANs","R. A. Fayyaz; M. Maqbool; M. Hanif","Department of Computer Science, FAST NUCES, Lahore, Pakistan; Department of Computer Science, FAST NUCES, Lahore, Pakistan; Department of Computer Science, FAST NUCES, Lahore, Pakistan","2020 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)","19 Nov 2020","2020","","","1","5","In this work, we propose a novel method for automated textile design patterns generation using generative models. We first improve the accuracy of state-of-the-art results in classification of textile design patterns by 2% through data cleaning and pseudo labeling. Then a new dataset which is an improvement of existing dataset is also proposed. On this new dataset we compare the performance of image generative models like Wasserstein Generative Adversarial Networks Gradient Penalty (WGANs GP), Deep Convolutional GANs (DCGANs) and Convolutional Variational Autoencoders (CVAEs) for all classes separately and have evaluated the models using the inception score. We further use a style transfer model to combine multiple designs generated by WGANs GP, due to its better results among all three approaches and form more complex and appealing textile designs. Moreover we present results of unsupervised clustering of different patterns in the latent space captured by a CVAE.","2576-7046","978-1-7281-5442-8","10.1109/CCECE47787.2020.9255674","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9255674","generatve adversarial networks;textile pattern generation;variational autoencoders;latent code;clustering","Textiles;Labeling;Image synthesis;Generative adversarial networks;Conferences;Data models;Training","convolutional neural nets;design engineering;gradient methods;image classification;neural nets;pattern clustering;production engineering computing;textile industry;unsupervised learning","latent space;unsupervised clustering;inception score;CVAEs;DCGANs;pseudolabeling;textile design pattern classification;automated textile design pattern generation;complex textile designs;multiple designs;style transfer model;Convolutional Variational Autoencoders;Deep Convolutional GANs;WGANs GP;Wasserstein Generative Adversarial Networks Gradient Penalty;image generative models;data cleaning","","","","20","","19 Nov 2020","","","IEEE","IEEE Conferences"
"Microwave Data Inversion With a Model Compression Scheme Based on Deep Learning","R. Guo; Z. Lin; M. Li; F. Yang; S. Xu; A. Abubakar","Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Institute for Precision Medicine, Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Institute for Precision Medicine, Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Institute for Precision Medicine, Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Institute for Precision Medicine, Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Institute for Precision Medicine, Tsinghua University, Beijing, China; Schlumberger, Houston, TX, USA","2022 IEEE International Symposium on Antennas and Propagation and USNC-URSI Radio Science Meeting (AP-S/URSI)","21 Sep 2022","2022","","","892","893","We present a nonlinear model compression scheme based on deep learning for microwave imaging. Permittivity models are described by the latent parameters of a trained variational autoencoder (VAE) neural network. The latent variables are taken as the unknowns to be inverted through minimizing the data misfit function with the Gauss-Newton method. By decoding the inverted parameters, features extracted from the dataset can be incorporated into the imaging process, which effectively mitigates the ill-posedness of the inverse scattering problem.","1947-1491","978-1-6654-9658-2","10.1109/AP-S/USNC-URSI47032.2022.9886107","National Natural Science Foundation of China; Tsinghua University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9886107","model compression;microwave imaging;deep learning;variational autoencoder;inverse scattering","Deep learning;Inverse problems;Neural networks;Scattering;Microwave theory and techniques;Feature extraction;Data models","data compression;feature extraction;geophysical signal processing;inverse problems;learning (artificial intelligence);microwave imaging;neural nets;Newton method;permittivity","microwave data inversion;deep learning;nonlinear model compression scheme;microwave imaging;permittivity models;latent parameters;trained variational autoencoder neural network;latent variables;data misfit function;Gauss-Newton method;inverted parameters;imaging process;inverse scattering problem","","","","5","IEEE","21 Sep 2022","","","IEEE","IEEE Conferences"
"Anomaly Detection Combining Discriminative and Generative Models","K. Higa; H. Sato; S. Shiraishi; K. Kikuchi; K. Iwamoto","Data Science Research Laboratories, NEC Corporation, Japan; Data Science Research Laboratories, NEC Corporation, Japan; Data Science Research Laboratories, NEC Corporation, Japan; Data Science Research Laboratories, NEC Corporation, Japan; Data Science Research Laboratories, NEC Corporation, Japan","2019 IEEE International Conference on Imaging Systems and Techniques (IST)","27 Feb 2020","2019","","","1","6","This paper proposes a method to accurately detect anomaly from an image by combining features extracted by discriminative and generative models. Automatic anomaly detection is a key factor for reducing operation costs of visual inspection in a wide range of domains. The proposed method consists of three sub-networks. The first sub-network is convolutional neural networks as a discriminative model for extracting features to distinguish between anomaly and normal. The second subnetwork is a variational autoencoder as a generative model to extract features representing normal. The third sub-network is neural networks to discriminate between anomaly and normal on the basis of features from the discriminative and generative models. Experiments were conducted using pseudo anomalous images generated by superimposing anomaly which was manually extracted from real images. Results of the experiments show that the proposed method improves the area under the curve by 0.08-0.33 points compared with that of a conventional method. With high accuracy, automatic visual inspection systems can be implemented for reducing operation costs.","1558-2809","978-1-7281-3868-8","10.1109/IST48021.2019.9010139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010139","anomaly detection;visual inspection;discriminative model;generative model;convolutional neural network;variational autoencoder","Feature extraction;Data models;Computational modeling;Anomaly detection;Neural networks;Inspection;Training","convolutional neural nets;feature extraction;security of data","generative model;automatic anomaly detection;operation cost reduction;convolutional neural networks;discriminative model;pseudoanomalous images;automatic visual inspection systems;feature extraction;variational autoencoder","","","","35","","27 Feb 2020","","","IEEE","IEEE Conferences"
"Generate Xi’an Drum Music Based on Compressed Coding","H. Wang; J. Li; Y. Lin; W. Ru; J. Wu","Computer Science, Vrije Universiteit Amsterdam & Universiteit van Amsterdam, Amsterdam, Netherlands; School of Qianxuesen, Xi’an Jiaotong University, Xi’an, China; School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; School of Humanities and Social Science, Xi’an Jiaotong University, Xi’an, China; School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China","2021 40th Chinese Control Conference (CCC)","6 Oct 2021","2021","","","8679","8683","Xi’an Drum Music is a traditional form of Chinese music and its notes are recorded by Chinese Characters. Because Xi’an Drum Music is composed and translated by the elder musicians, Xi’an Drum Music becomes difficult to be protected. In this article, we use sparse coding and compressed coding to transfer the Chinese Character recording to genre and lyrics of Xi’an Drum Music. Based on our dataset of Xi’an Drum Music, we set up a method to generate Xi’an Drum Music similar to Huffman coding, a model named Xi’an Drum Music Generation via Variational Autoencoder (DMGVAE) and the accuracy of Xi’an Drum Music generation increases to 0.73. Compressed coding on Xi’an Drum Music shows a novel method to generate Xi’an Drum Music by compressed format, making potential application for generating the sparse traditional Chinese Music such as Xi’an Drum Music.","1934-1768","978-9-8815-6380-4","10.23919/CCC52363.2021.9549489","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9549489","Xi’an Drum Music;Compressed Coding;Variational Autoencoder;Deep Learning","Music;Encoding;Huffman coding","Huffman codes;music;neural nets","Xian drum music generation;compressed coding;Chinese music;Chinese character recording;variational autoencoder;DMGVAE;Huffman coding","","","","17","","6 Oct 2021","","","IEEE","IEEE Conferences"
"Generative model based frame generation of volcanic flow video","A. Yamaguchi; M. Cabatuan","Department of Computer and Information Sciences, Tokyo University of Agriculture and Technology, Tokyo, Japan; Electronics and Communications Engineering Department, De La Salle University, Manila, Philippines","2017IEEE 9th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment and Management (HNICEM)","25 Jan 2018","2017","","","1","5","Automatic generation of computer graphics utilizing generative models has been the state of the art recently. The motivation of generating images on a natural phenomenon with a generative model is to simulate it more easily than with conventional methods, which usually propose some mathematical equations for simulation. In this paper, we focus on generating volcanic flow images by utilizing Deep Learning methods, such as Deep Convolutional Generative Adversarial Networks (DCGAN) and Variational Autoencoders (VAE). In order to simulate lava flow, we adopt videos that are uploaded YouTube as input dataset. The experimental results demonstrate that using DCGAN to our problem is inferior to utilizing VAE in terms of time complexity and quality of output images. These results suggest that when input dataset has categories that contain sequential images, it is more effective to utilize VAE rather than to use DCGAN.","","978-1-5386-0912-5","10.1109/HNICEM.2017.8269503","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8269503","Visual Simulation;Deep Learning;Generative Adversarial Networks;Variational Autoencoders;Lava flow image generation","Generators;Computational modeling;Mathematical model;Gallium nitride;Machine learning;Convolutional codes;Computer graphics","computer graphics;learning (artificial intelligence);video signal processing;volcanology","deep learning methods;variational autoencoders;deep convolutional generative model-based frame generation;YouTube;lava flow;VAE;DCGAN;volcanic flow images;computer graphics;automatic generation;volcanic flow video","","","","19","","25 Jan 2018","","","IEEE","IEEE Conferences"
"Data Augmentation for Question Answering Using Transformer-based VAE with Negative Sampling","W. Kano; K. Takeuchi","Graduate School of Natural Science and Technology, Okayama University, Okayama, Japan; Faculty of Natural Science and Technology, Okayama University, Okayama, Japan","2022 12th International Congress on Advanced Applied Informatics (IIAI-AAI)","23 Sep 2022","2022","","","467","470","In this paper, we propose a method to improve the accuracy of extracting appropriate question-answer pairs using generated questions with negative sampling. The base question-answering system that extracts similar questions for input queries is constructed on a Sentence-BERT model to carry out pairwised-ranking between questions of question-answer data and the input queries. The key issue of improving the question answering system is how we can prepare the enough size and variety of training examples. The Sentence-BERT model is trained on positive and negative pairs of extended questions generated by a Transformer-based Variational Autoencoder as well as human. Experimental results show that performance of retrieving appropriate questions for input queries is improved when the Sentence-BERT model is trained with the negative samples that are most similar to the positive examples.","2472-0070","978-1-6654-9755-8","10.1109/IIAIAAI55812.2022.00097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9894634","Sentence-BERT;Question answering system;Negative sampling;Variational Autoencoder","Training;Transformers;Question answering (information retrieval);Data models;Data mining;Informatics","learning (artificial intelligence);neural nets;question answering (information retrieval);sampling methods","data augmentation;Transformer-based VAE;negative sampling;question-answer pairs;Sentence-BERT model;question-answer data;question answering system;transformer-based variational autoencoder","","","","14","IEEE","23 Sep 2022","","","IEEE","IEEE Conferences"
"MBM-IoT: Intelligent Multi-Baseline Modeling of Heterogeneous Device Behaviors against IoT Botnet","J. Wang; J. Pan","University of Missouri-St. Louis, St. Louis, Missouri, USA; University of Missouri-St. Louis, St. Louis, Missouri, USA","2022 IEEE 19th Annual Consumer Communications & Networking Conference (CCNC)","10 Feb 2022","2022","","","711","712","Recent researches have applied various machine learning models to detect IoT botnet attacks. However, the heterogeneity of IoT devices’ normal and attack behaviors was not well addressed, which resulted in high false positive/negative detection rates. To solve this issue, we propose a method that builds individual behavior baselines for different types of devices with a single Conditional Variational Autoencoder model, and then detects attacks with even minor deviations from the baselines. The evaluation results on the public N-BaIoT dataset show that our method outperforms the others with accuracy higher than 99.9% while introducing limited extra computational cost.","2331-9860","978-1-6654-3161-3","10.1109/CCNC49033.2022.9700572","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9700572","IoT security;botnet attack detection;heterogeneous IoT devices;conditional variational autoencoder","Performance evaluation;Costs;Botnet;Computational modeling;Machine learning;Computational efficiency","computer network security;Internet of Things;invasive software;learning (artificial intelligence)","MBM-IoT;intelligent multibaseline modeling;machine learning models;IoT botnet attacks;individual behavior baselines;single conditional variational autoencoder model;heterogeneous device behaviors;public N-BaIoT dataset","","","","6","IEEE","10 Feb 2022","","","IEEE","IEEE Conferences"
"Research on recommendation algorithm combining item social regularization and variational encoder","Y. Fang; N. Ge; J. Ge","College of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, China; College of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, China; College of software engineering, Chongqing University of Posts and Telecommunications, Chongqing, China","2021 IEEE 5th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)","5 Apr 2021","2021","5","","333","338","Variational autoencoder is a very concise and effective unsupervised learning method, which can achieve excellent performance when applied in the field of recommendation systems. At present, most of the research on recommendation algorithms consider the user's social relationship, and rarely consider the social relationship between items. Focused on the problem of how to improve the recommendation accuracy of the recommendation system under the condition of sparse scoring data, a recommendation algorithm (SR-CVAE) for fusion item social relationship regularization and variational encoder are proposed. In this paper, the user-item feedback information, item content information, social relationship between items, and tag information are combined, and integrated into a variational encoder with a hidden variable generation model, and then combing the variational encoder with the discriminant model and applying it to the collaborative filtering recommendation algorithm to improve the accuracy of the algorithm. Experimental results on two CiteULike datasets show that the proposed algorithm has better interpretation and recommendation performance than other models.","2689-6621","978-1-7281-8028-1","10.1109/IAEAC50856.2021.9390988","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9390988","item social regularization;variational encoder;implicit feedback;discriminant model","Collaborative filtering;Scalability;Conferences;Neural networks;Data models;Information technology;Unsupervised learning","collaborative filtering;recommender systems;unsupervised learning","effective unsupervised learning method;recommendation system;fusion item social relationship regularization;variational encoder;user-item feedback information;item content information;collaborative filtering recommendation algorithm;item social regularization;variational autoencoder;concise learning method","","","","14","","5 Apr 2021","","","IEEE","IEEE Conferences"
"Integrated Multiple Directed Attention-Based Deep Learning for Improved Air Pollution Forecasting","A. Dairi; F. Harrou; S. Khadraoui; Y. Sun","Computer Science Department Signal, Image and Speech Laboratory (SIMPA) Laboratory, University of Science and Technology of Oran-Mohamed Boudiaf (USTO-MB), Bir El Djir, Algeria; Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, KAUST, Thuwal, Saudi Arabia; Department of Electrical Engineering, University of Sharjah, Sharjah, United Arab Emirates; Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, KAUST, Thuwal, Saudi Arabia","IEEE Transactions on Instrumentation and Measurement","8 Jul 2021","2021","70","","1","15","In recent years, human health across the world is becoming concerned by a constant threat of air pollution, which causes many chronic diseases and premature mortalities. Poor air quality does not have only serious adverse effects on human health and vegetation but also some major negative political, societal, and economic impacts. Hence, it is essential to invest more effort on accurate forecasting of ambient air pollution to provide practical and relevant solutions, achieve acceptable air quality, and plan for prevention. In this work, we propose a flexible and efficient deep learning-driven model to forecast concentrations of ambient pollutants. This article introduces first the traditional variational autoencoder (VAE) and the attention mechanism to develop the forecasting modeling strategy based on the innovative integrated multiple directed attention (IMDA) deep learning architecture. To assess the performance of the proposed forecasting methodology, experimental validation is then performed using air pollution data from four US states. Six statistical indicators have been used to evaluate the forecasting accuracy. A discussion of the results obtained finally demonstrates the satisfying performance of integrated multiple directed attention variational autoencoder (IMDA-VAE) methods to forecast different pollutants in different locations. Furthermore, results indicate that the proposed IMDA-VAE model can effectively improve air pollution forecasting performance and outperforms the deep learning models, namely VAE, long short-term memory (LSTM), gated recurrent units (GRU), bidirectional LSTM, bidirectional GRU, and ConvLSTM. We also showed that the forecasting results of the proposed model surpass the performance of LSTM and GRU with the attention mechanism.","1557-9662","","10.1109/TIM.2021.3091511","King Abdullah University of Science and Technology (KAUST), Office of Sponsored Research (OSR)(grant numbers:OSR-2019-CRG7-3800); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9466491","Air pollution concentrations forecasting;deep learning;integrated multiple directed attention variational autoencoder (IMDA-VAE);multiple directed attention;time series","Atmospheric modeling;Forecasting;Predictive models;Air pollution;Deep learning;Data models;Time series analysis","air pollution;deep learning (artificial intelligence);diseases;environmental science computing;forecasting theory;health and safety;medical computing;recurrent neural nets","integrated multiple directed attention-based;improved air pollution forecasting;human health;constant threat;chronic diseases;premature mortalities;poor air quality;serious adverse effects;negative political impacts;societal impacts;economic impacts;ambient air pollution;practical solutions;relevant solutions;acceptable air quality;flexible learning-driven model;efficient deep learning-driven model;ambient pollutants;traditional variational autoencoder;attention mechanism;forecasting modeling strategy;innovative integrated multiple;deep learning architecture;forecasting methodology;air pollution data;forecasting accuracy;satisfying performance;attention variational autoencoder methods;pollutants;IMDA-VAE model;air pollution forecasting performance;deep learning models","","15","","65","IEEE","28 Jun 2021","","","IEEE","IEEE Journals"
"A Robust PCA Feature Selection To Assist Deep Clustering Autoencoder-Based Network Anomaly Detection","V. Q. Nguyen; V. H. Nguyen; V. L. Cao; N. . -. A. L. Khac; N. Shone","Le Quy Don Technical University, Viet Nam; Le Quy Don Technical University, Viet Nam; Le Quy Don Technical University, Viet Nam; University College Dublin, Ireland; Liverpool John Moores University, UK","2021 8th NAFOSTED Conference on Information and Computer Science (NICS)","8 Feb 2022","2021","","","335","341","This paper presents a novel method to enhance the performance of Clustering-based Autoencoder models for network anomaly detection. Previous studies have developed regularized variants of Autoencoders to learn the latent representation of normal data in a semi-supervised manner, including Shrink Autoencoder, Dirac Delta Variational Autoencoder and Clustering-based Autoencoder. However, there are concerns regarding the feature selection of the original data, which stronger support Autoencoders models exploring more intrinsic, meaningful and latent features at bottleneck. The method proposed involves combining Principal Component Analysis and Clustering-based Autoencoder. Specifically, PCA is used for the selection of new data representation space, aiming to better assist CAE in learning the latent, prominent features of normal data, which addresses the aforementioned concerns. The proposed method is evaluated using the standard benchmark NSL-KDD data set and four scenarios of the CTU13 datasets. The promising experimental results confirm the improvements offered by the proposed approach, in comparison to existing methods. Therefore, it suggests a strong potential application within modern network anomaly detection systems.","","978-1-6654-1001-4","10.1109/NICS54270.2021.9701456","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9701456","Anomaly Detection;Clustering-based Autoencoders (CAEs);Principal Component Analysis (PCA);Latent Representation;Deep Learning","Computer science;Benchmark testing;Feature extraction;Data models;Anomaly detection;Standards;Principal component analysis","data mining;feature selection;image coding;learning (artificial intelligence);principal component analysis;security of data","robust PCA feature selection;latent representation;normal data;autoencoder models;intrinsic features;meaningful features;latent features;data representation space;standard benchmark NSL-KDD data;network anomaly detection systems;deep clustering autoencoder-based network anomaly detection;shrink autoencoder;CTU13 dataset","","","","28","IEEE","8 Feb 2022","","","IEEE","IEEE Conferences"
"Greedy Hierarchical Variational Autoencoders for Large-Scale Video Prediction","B. Wu; S. Nair; R. Martín-Martín; L. Fei-Fei; C. Finn","Stanford University, Stanford, CA; Stanford University, Stanford, CA; Stanford University, Stanford, CA; Stanford University, Stanford, CA; Stanford University, Stanford, CA","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","2 Nov 2021","2021","","","2318","2328","A video prediction model that generalizes to diverse scenes would enable intelligent agents such as robots to perform a variety of tasks via planning with the model. However, while existing video prediction models have produced promising results on small datasets, they suffer from severe underfitting when trained on large and diverse datasets. To address this underfitting challenge, we first observe that the ability to train larger video prediction models is often bottlenecked by the memory constraints of GPUs or TPUs. In parallel, deep hierarchical latent variable models can produce higher quality predictions by capturing the multi-level stochasticity of future observations, but end-to-end optimization of such models is notably difficult. Our key insight is that greedy and modular optimization of hierarchical autoencoders can simultaneously address both the memory constraints and the optimization challenges of large-scale video prediction. We introduce Greedy Hierarchical Variational Autoencoders (GHVAEs), a method that learns highfidelity video predictions by greedily training each level of a hierarchical autoencoder. In comparison to state- of-the-art models, GHVAEs provide 17-55% gains in prediction performance on four video datasets, a 35–40% higher success rate on real robot tasks, and can improve performance monotonically by simply adding more modules. Visualization and more details are at https://sites.google.com/view/ghvae.","2575-7075","978-1-6654-4509-2","10.1109/CVPR46437.2021.00235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9578715","","Training;Visualization;Memory management;Stacking;Predictive models;Planning;Pattern recognition","feature extraction;greedy algorithms;learning (artificial intelligence);neural nets;optimisation;video signal processing","prediction performance;video datasets;Greedy Hierarchical Variational Autoencoders;large-scale video prediction;video prediction model;diverse datasets;larger video prediction models;memory constraints;deep hierarchical latent variable models;end-to-end optimization;greedy optimization;modular optimization;highfidelity video predictions","","2","","87","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"De Novo Drug Design via Multi-Label Learning and Adversarial Autoencoder","Q. Ye; X. Zhang; X. Lin","Hubei Key Laboratory of Intelligent Information Processing and Real-Time Industrial System, School of Computer Science and Technology, Wuhan University of Science and Technology, Wuhan, China; Hubei Key Laboratory of Intelligent Information Processing and Real-Time Industrial System, School of Computer Science and Technology, Wuhan University of Science and Technology, Wuhan, China; Hubei Key Laboratory of Intelligent Information Processing and Real-Time Industrial System, School of Computer Science and Technology, Wuhan University of Science and Technology, Wuhan, China","2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","14 Jan 2022","2021","","","3456","3463","generating new molecules is very important for drug design. Currently, many deep generative models have been designed, such as variational autoencoder (VAE), adversarial autoencoder (AAE), and reinforcement learning (RL). However, many problems are also existed in these models. Firstly, the information among molecules could be not utilized in optimizing these models. Secondly, some useful molecule information could be not used, such as fingerprint. Thirdly, the information contained in different molecule representations could be not used together. To overcome the above problems, in this paper, a multi-label learning and adversarial autoencoder (MLAAE) based de novo drug design method is designed. MLAAE enhances its learning ability with a new designed multi-label classifier and a new designed double AAEs collaborative optimization framework. These new designs can learn a better latent space whose global distribution is similar with the random distribution, but local distribution contains much information. As a result, the generator can be trained by more information, and the input of generator in testing is similar with that in training. The conducted experiments validate the effectiveness of our MLAAE.","","978-1-6654-0126-5","10.1109/BIBM52615.2021.9669568","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669568","De novo drug design;Adversarial autoencoder;Multi-label learning;Deep learning","Drugs;Training;Measurement;Collaboration;Reinforcement learning;Fingerprint recognition;Generators","deep learning (artificial intelligence);drugs;medical computing;optimisation;pattern classification","de novo drug design;multilabel learning;adversarial autoencoder;deep generative models;reinforcement learning;molecule representations;MLAAE;learning ability;latent space whose global distribution;VAE;variational autoencoder;double AAEs collaborative optimization framework;multilabel classifier","","","","42","IEEE","14 Jan 2022","","","IEEE","IEEE Conferences"
"Exploiting Generative Models for Performance Predictions of 3D Car Designs","S. Saha; T. Rios; L. L. Minku; B. V. Stein; P. Wollstadt; X. Yao; T. Back; B. Sendhoff; S. Menzel","Honda Research Institute Europe GmbH, Offenbach, Germany; Honda Research Institute Europe GmbH, Offenbach, Germany; CERCIA, School of Computer Science, University of Birmingham, Birmingham, UK; Leiden Institute of Advanced Computer Science (LIACS), Leiden, The Netherlands; Honda Research Institute Europe GmbH, Offenbach, Germany; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Leiden Institute of Advanced Computer Science (LIACS), Leiden, The Netherlands; Honda Research Institute Europe GmbH, Offenbach, Germany; Honda Research Institute Europe GmbH, Offenbach, Germany","2021 IEEE Symposium Series on Computational Intelligence (SSCI)","24 Jan 2022","2021","","","1","9","In automotive digital development, engineers utilize multiple virtual prototyping tools to design and assess the performance of 3D shapes. However, accurate performance simulations are computationally expensive and time-consuming, which may be prohibitive for design optimization tasks. To address this challenge, we envision a 3D design assistance system for design exploration with performance assessment in the automotive domain. Recent advances in deep learning methods for learning geometric data are a promising step towards realizing such systems. Deep learning-based (variational) autoencoder models have been used for learning and compressing 3D data allowing engineers to generate low-dimensional representations of 3D designs. Finding representations in a data-driven fashion results in representations that are agnostic to downstream tasks performed on these representations and are believed to capture relevant design features. In this paper, we evaluate whether such data-driven representations contain relevant information about the input data and whether representations are meaningful in performance prediction tasks for the input data. We use machine learning-based surrogate models to predict the performances of car shapes based on the low-dimensional representation learned by 3D point cloud (variational) autoencoders. Furthermore, we exploit the stochastic nature of the representation learned by variational autoencoders to augment the training data for our surrogate models, since the limited amount of data is usually a challenge for surrogate modeling in engineering. We demonstrate that augmenting training with generated shapes improves prediction accuracy. In sum, we find that geometric deep learning approaches offer powerful tools to support the engineering design process.","","978-1-7281-9048-8","10.1109/SSCI50451.2021.9660034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9660034","representation learning;3D point clouds;auto encoder;variational autoencoder;regression analysis","Point cloud compression;Solid modeling;Three-dimensional displays;Shape;Computational modeling;Training data;Predictive models","automobiles;automotive engineering;CAD;data compression;deep learning (artificial intelligence);image representation;neural nets;optimisation;production engineering computing;virtual prototyping","3D data compression;geometric data learning;design exploration;3D design assistance system;design optimization tasks;virtual prototyping tools;automotive digital development;3D car designs;generative models;engineering design process;geometric deep learning approaches;training data;variational autoencoders;3D point cloud autoencoders;car shapes;machine learning-based surrogate models;performance prediction tasks;data-driven representations;downstream tasks;low-dimensional representation;deep learning-based autoencoder models","","1","","23","IEEE","24 Jan 2022","","","IEEE","IEEE Conferences"
"VDGAN: A Collaborative Filtering Framework Based on Variational Denoising with GANs","W. Sun; S. Yu; B. Dong","School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; Montclair State University, Montclair, NJ, USA","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","8","Generative Adversarial Networks (GANs) effectively capture the true posterior distribution. When applied to Collaborative Filtering (CF), GANs can generate a recommendation list through implicit feedback. However, the discriminators in the existing GANs-based CF methods are not utilized fully, and the generators perform poorly on sparse data mining. In this paper, we propose an improved collaborative filtering framework based on variational denoising for GANs (VDGAN). Specifically, VDGAN integrates the variational encoder and the self-attention mechanism into the GANs. By using the positive-negative sampling mechanism to add specific noise to the input data, the variational encoder obtains a robust feature matrix and improves the sparse data processing capability of the generator. In VDGAN, the denoising generator reconstructs the user-items interaction matrix through the feature matrix. And the discriminator is composed of the self-attention mechanism to obtain the explicit features of user preferences, which extends the ability of the discriminator. Furthermore, reinforcement learning replaces the traditional objective function of GANs, which better optimizes the generator and further improves the recommendation accuracy of the model. From our comprehensive experiments on three real-world datasets, we demonstrate that the performance of VDGAN significantly outperforms the state-of-the-art methods based on GANs and Auto-Encoders.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533585","Fundamental Research Funds for the Central Universities(grant numbers:DUT18JC28,DUT19ZD103,DUT21LAB115); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533585","collaborative filtering;generative adversarial networks;variational autoencoders;self-attention;reinforcement learning","Collaborative filtering;Noise reduction;Neural networks;Reinforcement learning;Linear programming;Generative adversarial networks;Data processing","collaborative filtering;data mining;image denoising;information filtering;learning (artificial intelligence);recommender systems","denoising generator reconstructs;self-attention mechanism;VDGAN;collaborative filtering framework;variational denoising;Generative Adversarial Networks;discriminator;existing GANs-based CF methods;generators;sparse data mining;improved collaborative;variational encoder;sparse data processing capability","","","","23","IEEE","20 Sep 2021","","","IEEE","IEEE Conferences"
"Generating robotic emotional body language with variational autoencoders","M. Marmpena; A. Lim; T. S. Dahl; N. Hemion","SoftBank Robotics Europe, Paris, France & University of Plymouth, Plymouth, UK; Simon Fraser University, British Columbia, Canada; InstaDeep, London, UK; dSPACE GmbH, Paderborn, Germany","2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)","9 Dec 2019","2019","","","545","551","Humanoid robots in social environments can become more engaging by using their embodiment to display emotional body language. For such expressions to be effective in long term interaction, they need to be characterized by variation and complexity, so that the robot can sustain the user's interest beyond the novelty effect period. Hand-coded, pose-to-pose robotic animations can be of high quality and interpretability, but the demanding process of creating them results in limited sets; therefore, after a while, the user will realize that the behavior is repetitive. This work proposes the application of deep learning methods, and more specifically the variational autoencoder framework, for generating numerous emotional body language animations for the Pepper robot, after being trained with a few examples of hand-coded animations. Interestingly, the latent space of the model exhibits topological features that can be used to modulate the amplitude of the motion; we propose that this can be potentially useful for generating animations of specific arousal according to the dimensional theory of emotion.","2156-8111","978-1-7281-3888-6","10.1109/ACII.2019.8925459","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8925459","human-robot interaction;social robotics;emotional body language;generative models;variational autoen-coders","Animation;Emotion recognition;Humanoid robots;Pose estimation;Deep learning","computer animation;emotion recognition;humanoid robots;human-robot interaction;learning (artificial intelligence);mobile robots;pose estimation","robotic emotional body language;humanoid robots;social environments;deep learning methods;autoencoder framework;Pepper robot;hand-coded animations;emotional body language animations;pose-to-pose robotic animations","","5","","26","","9 Dec 2019","","","IEEE","IEEE Conferences"
"Protein Binding Pose Prediction via Conditional Variational Autoencoding for Plasmodium Falciparum","T. Tran; C. Ekenna","Department of Computer Science, University at Albany, Albany, New York; Department of Computer Science, University at Albany, Albany, New York","2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","13 Jan 2021","2020","","","2448","2455","Malaria is a disease caused by single-celled blood parasites of the genus Plasmodium. The protozoan Plasmodium Falciparum (PF) inflicts the most damage and is responsible for most malaria-related deaths. The high mutational capacity of the Plasmodium parasite coupled with its changing metabolism makes the development of new effective drug treatments an evolving and open problem. In this work, we propose a machine learning approach to predict the binding pose structure of ligand families for this parasite. Identifying appropriate protein-ligand binding poses is essential in structure-based drug design and important for the evaluation of protein-ligand binding affinity. Specifically, a conditional variational autoencoder is trained to learn the distribution which represents the binding structures conditioned on the given binding sites. Using this well-trained conditional variational autoencoder, our approach generates binding poses for the ligand's receptor for a particular binding site by sampling from this learned distribution. We demonstrate that our model is able to accurately predict the binding structures of multiple binding sites for the PF parasite invasion ligand families in the erythrocyte invasion and compare it with other states of the art methods like HADDOCK, Hdock, and GRAMMX.","","978-1-7281-6215-7","10.1109/BIBM49941.2020.9313491","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9313491","Malaria;protein-ligand interaction;machine learning;autoencoder","Proteins;Computational modeling;Mathematical model;Receptor (biochemistry);Predictive models;Decoding;Protein engineering","blood;cellular biophysics;diseases;drugs;learning (artificial intelligence);medical computing;microorganisms;molecular biophysics;molecular configurations;proteins;variational techniques","conditional variational autoencoding;single-celled blood parasites;malaria-related deaths;Plasmodium parasite;drug treatments;protein-ligand binding poses;structure-based drug design;protein-ligand binding affinity;multiple binding sites;PF parasite invasion ligand families;mutational capacity;Plasmodium falciparum;protozoan;machine learning;binding pose structure;ligand receptor;erythrocyte invasion;malaria","","1","","43","","13 Jan 2021","","","IEEE","IEEE Conferences"
"Anomaly Detection of Heat Energy Usage in District Heating Substations Using LSTM based Variational Autoencoder Combined with Physical Model","F. Zhang; H. Fleyeh","Departments of Energy Technology and Microdata Analysis, Dalarna University, Falun, Sweden; Department of Computer Engineering, Dalarna University, Falun, Sweden","2020 15th IEEE Conference on Industrial Electronics and Applications (ICIEA)","9 Nov 2020","2020","","","153","158","District heating systems that distribute heat through pipelines to residential and commercial buildings have been widely used in Northern Europe. The energy efficiency of district heating systems is of great interest to energy stakeholders. However, it is not uncommon that district heating systems fail to achieve the expected performance due to various faults. Identification of such rare observations that are different significantly from the majority of the meter readings data plays a vital role in system diagnose. In this study, a new hybrid approach is proposed for anomaly detection of a district heating substation, which consists of a simplified physical model and a Long Short Term Memory based Variational Autoencoder (LSTM VAE). A dataset of an anonymous substation in Sweden is used as a case study. The performance of two state of art models, LSTM and long short term memory based autoencoder (LSTM AE) are evaluated and compared with the LSTM VAE. Experimental results show that LSTM VAE outperforms the baseline models in terms of Area under receiver operating characteristic (ROC) curve (AUC) and F1 score when an optimal threshold is applied.","2158-2297","978-1-7281-5169-4","10.1109/ICIEA48937.2020.9248108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9248108","Energy system;neural networks;anomaly detection;computational intelligence;machine learning","Heating systems;Substations;Pipelines;Receivers;Meter reading;Stakeholders;Anomaly detection","district heating;energy conservation;pipelines;power engineering computing;recurrent neural nets;substations","Northern Europe;energy efficiency;Sweden;receiver operating characteristic curve;AUC;pipelines;physical model;variational autoencoder;long short term memory;district heating substation;heat energy usage;anomaly detection;LSTM VAE","","1","","21","","9 Nov 2020","","","IEEE","IEEE Conferences"
"A Log-likelihood Regularized KL Divergence for Video Prediction With a 3D Convolutional Variational Recurrent Network","H. Razali; B. Fernando","A* STAR, Singapore; A* STAR, Singapore","2021 IEEE Winter Conference on Applications of Computer Vision Workshops (WACVW)","21 Apr 2021","2021","","","209","217","The use of latent variable models has shown to be a powerful tool for modeling probability distributions over sequences. In this paper, we introduce a new variational model that extends the recurrent network in two ways for the task of video frame prediction. First, we introduce 3D convolutions inside all modules including the recurrent model for future frame prediction, inputting and outputting a sequence of video frames at each timestep. This enables us to better exploit spatiotemporal information inside the variational recurrent model, allowing us to generate high-quality predictions. Second, we enhance the latent loss of the variational model by introducing a maximum likelihood estimate in addition to the KL divergence that is commonly used in variational models. This simple extension acts as a stronger regularizer in the variational autoencoder loss function and lets us obtain better results and generalizability. Experiments show that our model outperforms existing video prediction methods on several benchmarks while requiring fewer parameters.","2690-621X","978-1-6654-1967-3","10.1109/WACVW52041.2021.00027","National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9407596","","Solid modeling;Three-dimensional displays;Conferences;Stochastic processes;Computer architecture;Predictive models;Tools","convolutional neural nets;image sequences;maximum likelihood estimation;recurrent neural nets;statistical distributions;video signal processing","log-likelihood regularized KL divergence;3D convolutional variational recurrent network;latent variable models;probability distributions;variational model;video frame prediction;frame prediction;variational recurrent model;variational autoencoder loss function","","","","31","","21 Apr 2021","","","IEEE","IEEE Conferences"
"Classification of imbalanced land-use/land-cover data using variational semi-supervised learning","T. W. Cenggoro; S. M. Isa; G. P. Kusuma; B. Pardamean","Bioinformatics and Data Science Research Center, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia; Computer Science Department, Bina Nusantara University, Jakarta, Indonesia","2017 International Conference on Innovative and Creative Information Technology (ICITech)","19 Mar 2018","2017","","","1","6","Classification of Land Use/Land Cover (LULC) data is a typical task in remote-sensing domain. However, because the classes distribution in LULC data is naturally imbalance, it is difficult to do the classification. In this paper, we employ Variational Semi-Supervised Learning (VSSL) to solve imbalance problem in LULC of Jakarta City. This VSSL exploits the use of semi-supervised learning on deep learning model. Therefore, it is suitable for classifying data with abundant unlabeled like LULC. The result shows that VSSL achieves 80.17% of overall accuracy, outperforming other algorithms in comparison.","","978-1-5386-4046-3","10.1109/INNOCIT.2017.8319149","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319149","Variational Autoencoder;Variational Semi-Supervised Learning;Remote Sensing;Imbalanced Learning","Remote sensing;Semisupervised learning;Urban areas;Standards;Training;Testing;Gaussian distribution","geophysics computing;land cover;land use;learning (artificial intelligence);pattern classification;remote sensing","imbalanced data classification;land-use/land-cover data;Jakarta City;deep learning model;VSSL;variational semisupervised learning;LULC data;remote-sensing domain","","16","","23","","19 Mar 2018","","","IEEE","IEEE Conferences"
"Structure-Exploiting variational inference for recurrent switching linear dynamical systems","S. W. Linderman; M. J. Johnson",Columbia University; Google Brain,"2017 IEEE 7th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)","12 Mar 2018","2017","","","1","5","Many natural systems, such as neurons firing in the brain or basketball teams traversing a court, give rise to time series data with complex, nonlinear dynamics. We can gain insight into these systems by decomposing the data into segments that are each explained by simpler dynamic units. This is the motivation underlying the class of recurrent switching linear dynamical systems (rSLDS) [1], which build on the standard SLDS by introducing a model of how discrete transition probabilities depend on observations or continuous latent states. Previous work relied on Markov chain Monte Carlo algorithms and augmentation schemes for inference, but these methods only applied to a limited class of recurrent dependencies. Here we relax these constraints and consider recurrent dependencies specified by arbitrary parametric, nonlinear functions. We derive two structure-exploiting variational inference algorithms for these challenging models. Both leverage the conditionally linear Gaussian and Markovian nature of the models to perform efficient posterior inference.","","978-1-5386-1251-4","10.1109/CAMSAP.2017.8313132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8313132","State space models;recurrent models;switching linear dynamical systems;variational inference;variational autoencoders","Switches;Superluminescent diodes;Inference algorithms;Standards;Heuristic algorithms;Computational modeling;Conferences","Bayes methods;inference mechanisms;Markov processes;Monte Carlo methods;time series","time series data;complex dynamics;nonlinear dynamics;simpler dynamic units;discrete transition probabilities;continuous latent states;Markov chain Monte Carlo algorithms;recurrent dependencies;arbitrary parametric functions;nonlinear functions;structure-exploiting variational inference algorithms;efficient posterior inference;recurrent switching linear dynamical systems;natural systems;brain","","","","17","","12 Mar 2018","","","IEEE","IEEE Conferences"
"Generative Probabilistic Wind Speed Forecasting: A Variational Recurrent Autoencoder Based Method","Z. Zheng; L. Wang; L. Yang; Z. Zhang","School of Data Science, City University of Hong Kong, Kowloon Tong, Hong Kong SAR, China; The Department of Computer Science and Technology, University of Science and Technology Beijing, Beijing, China; School of Data Science, City University of Hong Kong, Kowloon Tong, Hong Kong SAR, China; School of Data Science, City University of Hong Kong, Kowloon Tong, Hong Kong SAR, China","IEEE Transactions on Power Systems","7 Mar 2022","2022","37","2","1386","1398","In this paper, a novel framework for probabilistic wind speed forecasting (PWSF) based on variational recurrent autoencoders (VRAEs) via a generative perspective is proposed. Compared with a traditional optimization objective maximizing the conditional likelihood of the target wind speed directly, a novel optimization objective maximizing the likelihood of the complete wind speed sequence is proposed to better model the temporal relationship within the complete wind speed sequence. As directly maximizing the proposed objective is intractable, we show that it can be alternatively achieved via the help of the VRAE learning principle. The framework of the proposed VRAE based PWSF is composed of two phases, training a VRAE with maximizing the variational lower bound of the likelihood of the complete wind speed sequence and forecasting the target wind speed from the generative perspective through the approximate posterior learned by the VRAE. Computational results demonstrate that the proposed method outperforms other benchmarking deterministic and probabilistic forecasting models in terms of the negative form of continuous ranked probability score (CRPS*). Compared with other benchmarking models for probabilistic forecasting, the proposed method achieves better sharpness and overall quality of prediction intervals (PIs) as well as a comparable reliability. Results verify advantages of the proposed VARE based PWSF method.","1558-0679","","10.1109/TPWRS.2021.3105101","National Natural Science Foundation of China Young Scientist Fund Project(grant numbers:52007160); Hong Kong Research Grants Council General Research Fund Projects(grant numbers:11215418,11204419); CityU Strategic Research(grant numbers:7005537,7005692); Fundamental Research Funds for the Central Universities and the Youth Teacher International Exchange & Growth Program(grant numbers:QNXM20210037); Laboratory for AI-Powered Financial Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9516991","Probabilistic forecasting;wind speed;recurrent neural networks;data-driven models;data mining","Wind speed;Forecasting;Hidden Markov models;Probabilistic logic;Predictive models;Probability density function;Wind forecasting","learning (artificial intelligence);neural nets;optimisation;power engineering computing;power generation planning;power generation reliability;probability;wind power plants","probabilistic wind speed forecasting;optimization objective;VRAE learning principle;variational recurrent autoencoder based method;benchmarking deterministic;continuous ranked probability score;CRPS;prediction intervals;VARE based PWSF method;computational results","","1","","30","IEEE","18 Aug 2021","","","IEEE","IEEE Journals"
"Adversarial Autoencoder Based Feature Learning for Fault Detection in Industrial Processes","K. Jang; S. Hong; M. Kim; J. Na; I. Moon","School of Chemical and Biomolecular Engineering, Yonsei University, Seoul, South Korea; School of Chemical and Biomolecular Engineering, Yonsei University, Seoul, South Korea; School of Chemical and Biomolecular Engineering, Yonsei University, Seoul, South Korea; Department of Chemical Engineering and Materials Science, Graduate Program in System Health Science and Engineering, Ewha Womans University, Seoul, South Korea; School of Chemical and Biomolecular Engineering, Yonsei University, Seoul, South Korea","IEEE Transactions on Industrial Informatics","29 Oct 2021","2022","18","2","827","834","Deep learning has recently emerged as a promising method for nonlinear process monitoring. However, ensuring that the features from process variables have representative information of the high-dimensional process data remains a challenge. In this study, we propose an adversarial autoencoder (AAE) based process monitoring system. AAE which combines the advantages of a variational autoencoder and a generative adversarial network enables the generation of features that follow the designed prior distribution. By employing the AAE model, features that have informative manifolds of the original data are obtained. These features are used for constructing and monitoring statistics and improve the stability and reliability of fault detection. Extracted features help calculate the degree of abnormalities in process variables more robustly and indicate the type of fault information they imply. Finally, our proposed method is testified using the Tennessee Eastman benchmark process in terms of fault detection rate, false alarm rate, and fault detection delays.","1941-0050","","10.1109/TII.2021.3078414","National Research Foundation of Korea; Korean Government(grant numbers:NRF-2021R1C1C1012031); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9426453","Adversarial autoencoder (AAE);data-driven method;dimensionality reduction;fault detection;process monitoring;Tennessee Eastman (TE) process","Feature extraction;Process monitoring;Fault detection;Data models;Informatics;Generative adversarial networks;Data mining","convolutional neural nets;deep learning (artificial intelligence);fault diagnosis;feature extraction;principal component analysis;process monitoring;production engineering computing","fault detection rate;fault detection delays;feature learning;industrial processes;deep learning;nonlinear process monitoring;process variables;high-dimensional process data;adversarial autoencoder based process monitoring system;variational autoencoder;generative adversarial network;AAE model;fault information;Tennessee Eastman benchmark process;false alarm rate","","7","","30","IEEE","7 May 2021","","","IEEE","IEEE Journals"
"Image-based Process Monitoring via Adversarial Autoencoder with Applications to Rolling Defect Detection","H. Yan; H. -M. Yeh; N. Sergin","School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, USA.; School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, USA.; School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, USA.","2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)","19 Sep 2019","2019","","","311","316","Image-based process monitoring has recently attracted increasing attention due to the advancement of the sensing technologies. However, existing process monitoring methods fail to fully utilize the spatial information of images due to their complex characteristics including the high-dimensionality and complex spatial structures. Recent advancements in unsupervised deep models such as generative adversarial networks (GAN) and adversarial autoencoders (AAE) has enabled to learn the complex spatial structures automatically. Inspired by this advancement, we propose an anomaly detection framework based on the AAE for unsupervised anomaly detection for images. AAE combines the power of GAN with the variational autoencoder, which serves as a nonlinear dimension reduction technique. Based on this, we propose a monitoring statistic efficiently capturing the change of the data. The performance of the proposed AAE-based anomaly detection algorithm is validated through a simulation study and real case study for rolling defect detection.","2161-8089","978-1-7281-0356-3","10.1109/COASE.2019.8843313","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8843313","Statistical Process Control;Profile Monitoring;Deep Generative Models;Adversarial Autoencoder","Monitoring;Generative adversarial networks;Principal component analysis;Generators;Anomaly detection;Image reconstruction;Dimensionality reduction","computerised monitoring;neural nets;object detection;process monitoring;production engineering computing;rolling;statistical analysis;unsupervised learning","AAE-based anomaly detection algorithm;rolling defect detection;sensing technologies;process monitoring methods;spatial information;complex characteristics;unsupervised deep models;adversarial autoencoders;anomaly detection framework;unsupervised anomaly detection;variational autoencoder;monitoring statistic;image-based process monitoring;generative adversarial networks;GAN;AAE;complex spatial structure learning;nonlinear dimension reduction technique","","3","","20","","19 Sep 2019","","","IEEE","IEEE Conferences"
"Uncertainty-Autoencoder-Based Privacy and Utility Preserving Data Type Conscious Transformation","B. Mandal; G. Amariucai; S. Wei","Department of Computer Science, Kansas State University, Manhattan, KS, USA; Department of Computer Science, Kansas State University, Manhattan, KS, USA; Division of Electrical & Computer Engineering, Louisiana State University, Baton Rouge, LA, USA","2022 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2022","2022","","","1","8","We propose an adversarial learning framework that deals with the privacy-utility tradeoff problem under two types of conditions: data-type ignorant, and data-type aware. Under data-type aware conditions, the privacy mechanism provides a one-hot encoding of categorical features, representing exactly one class, while under data-type ignorant conditions the categorical variables are represented by a collection of scores, one for each class. We use a neural network architecture consisting of a generator and a discriminator, where the generator consists of an encoder-decoder pair, and the discriminator consists of an adversary and a utility provider. Unlike previous research considering this kind of architecture, which leverages autoencoders (AEs) without introducing any randomness, or variational autoencoders (VAEs) based on learning latent representations which are then forced into a Gaussian assumption, our proposed technique introduces randomness and removes the Gaussian assumption restriction on the latent variables, only focusing on the end-to-end stochastic mapping of the input to privatized data. We test our framework on different datasets: MNIST, FashionMNIST, UCI Adult, and US Census Demographic Data, providing a wide range of possible private and utility attributes. We use multiple adversaries simultaneously to test our privacy mechanism - some trained from the ground truth data and some trained from the perturbed data generated by our privacy mechanism. Through comparative analysis, our results demonstrate better privacy and utility guarantees than the existing works under similar, data-type ignorant conditions, even when the latter are considered under their original restrictive single-adversary model.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9892789","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9892789","data privacy;utility;min-max;optimization;autoencoder;categorical features;data-type-aware privacy","Data privacy;Privacy;Analytical models;Neural networks;Stochastic processes;Focusing;Gaussian distribution","data privacy;learning (artificial intelligence)","uncertainty-autoencoder-based privacy;adversarial learning framework;privacy-utility tradeoff problem;data-type aware conditions;privacy mechanism;one-hot encoding;categorical features;categorical variables;neural network architecture;encoder-decoder pair;variational autoencoders;Gaussian assumption restriction;latent variables;end-to-end stochastic mapping;privatized data;ground truth data;perturbed data;utility guarantees;restrictive single-adversary model;private utility attributes;US Census Demographic Data;MNIST dataset;FashionMNIST dataset;UCI Adult dataset;utility preserving data type conscious transformation","","","","51","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"Discrete Wasserstein Autoencoders for Document Retrieval","Y. Zhang; H. Zhu","Alibaba Group, Hangzhou, Zhejiang; Alibaba Group, Hangzhou, Zhejiang","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","8159","8163","Learning to hash via generative models has became a promising paradigm for fast similarity search in document retrieval. The binary hash codes are treated as Bernoulli latent variables when training a variational autoencoder (VAE). However, the prior of discrete distribution (i.e., Bernoulli distribution) is short of some structure regularization to generate more effi-cient binary codes. In this paper, we present an end-to-end Wasserstein Autoencoder (WAE) for text hashing to avoid in-differentiable operators in the reparameterization trick, where the latent variables can be imposed to any discrete priors we can sample by using adversarial learning. Moreover, we can generate more efficient discrete codes by imposing a structural constraint on priors like the bit balance constraint. Our experiments show that the proposed model is competitive to the state of the art methods on both unsupervised and supervised scenarios.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9053129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9053129","Wasserstein Autoencoder;Documental Retrieval;Learning to Hash","Training;Measurement;Conferences;Binary codes;Signal processing;Acoustics;Speech processing","binary codes;cryptography;file organisation;information retrieval;search problems;text analysis;unsupervised learning","discrete Wasserstein autoencoders;document retrieval;generative models;similarity search;binary hash codes;Bernoulli latent variables;variational autoencoder;discrete distribution;Bernoulli distribution;structure regularization;in-differentiable operators;reparameterization trick;adversarial learning;discrete codes;VAE","","","","19","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Autoencoder Based Dimensionality Reduction of Feature Vectors for Object Recognition","R. K. Keser; B. U. Töreyin","Signal Processing for Computational Intelligence Group, Informatics Institute Istanbul Technical University, Istanbul, Turkey; Signal Processing for Computational Intelligence Group, Istanbul Technical University, Istanbul, Turkey","2019 15th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)","16 Apr 2020","2019","","","577","584","Object recognition can be performed with high accuracy thanks to the robust feature descriptors defining the significant areas in images. However, these features suffer from high dimensional structure, in other words ""curse of dimensionality"" for further processes. Autoencoders (AE) are proposed in this study to solve the dimensionality reduction problem of visual features. To assess the efficacy, object recognition is performed using reduced dimensional visual features. For this purpose, dimensionalities of three well-known feature vectors, namely, HOG, SIFT and SURF, are reduced to half. Moreover, deep learning based features are also reduced. Then, reduced vectors, which are called as AE-HOG, AE-SIFT, AE-SURF and AE-DEEP are fed to object recognition task. Also, dimensionality reduction is implemented by a variant of AE, variational autoencoder (VAE) and PCA, which is the most studied unsupervised method for these features, and the results are compared. Furthermore, all experiments are repeated on noisy images. Results suggest that dimensionality reduction of these feature vectors can be accomplished successfully owing to the proposed method.","","978-1-7281-5686-6","10.1109/SITIS.2019.00097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9067860","dimensionality reduction;autoencoder;HOG;SIFT;SURF","Object recognition;Dimensionality reduction;Feature extraction;Principal component analysis;Visualization;Robustness","feature extraction;image coding;image denoising;image recognition;neural nets;object recognition;principal component analysis;transforms;unsupervised learning","object recognition task;dimensionality reduction problem;deep learning based features;autoencoder based dimensionality reduction;AE-HOG;AE-SIFT;AE-SURF;AE-DEEP;variational autoencoder;VAE;PCA","","","","53","","16 Apr 2020","","","IEEE","IEEE Conferences"
"Subresolution Assist Feature Insertion by Variational Adversarial Active Learning and Clustering with Data Point Retrieval","S. S. -E. Tseng; I. H. -R. Jiang; J. P. Shiely","Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan; Synopsys, Inc., Hillsboro, United States","2021 58th ACM/IEEE Design Automation Conference (DAC)","8 Nov 2021","2021","","","181","186","As the feature size keeps shrinking in the modern semiconductor manufacturing process, subresolution assist feature (SRAF) insertion is one promising resolution enhancement technique that can improve the printability and lithographic process window of target patterns. Model-based SRAF generation achieves a high accuracy but with a high computational cost, while rule-based SRAF insertion may require a huge rule table to handle complex patterns. Thus, state-of-the-art works resort to machine learning to reduce runtime but require abundant training samples to generalize the trained models and achieve high performance. Nevertheless, in advanced lithography, we may have a huge solution space of SRAF insertion but few labeled training samples. Therefore, in this work, we address SRAF insertion from a data efficiency perspective. We separate sample selection from SRAF probability learning and train a variational autoencoder and an adversarial network to discriminate between unlabeled and labeled data effectively. Second, we devise a region-based concentric circle area sampling representation to avoid information loss during feature extraction. Third, we determine the final placement of SRAFs by a novel clustering method based on retrieved data points. Experimental results show that, compared with state-of-the-art works, by using 40% training samples, our framework can achieve comparable or even better process variation bands and edge placement errors.","0738-100X","978-1-6654-3274-0","10.1109/DAC18074.2021.9586238","Synopsys; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9586238","","Training;Semiconductor device modeling;Runtime;Manufacturing processes;Design automation;Computational modeling;Lithography","electronic engineering computing;feature extraction;learning (artificial intelligence);lithography;masks;pattern clustering;probability;variational techniques","data point retrieval;modern semiconductor manufacturing process;resolution enhancement technique;lithographic process window;target patterns;model-based SRAF generation;high computational cost;rule-based SRAF insertion;huge rule table;complex patterns;machine learning;abundant training samples;trained models;data efficiency perspective;separate sample selection;SRAF probability;variational autoencoder;adversarial network;unlabeled labeled data;region-based concentric circle area sampling representation;feature extraction;retrieved data points;process variation bands;subresolution assist feature insertion;variational adversarial active learning","","","","19","IEEE","8 Nov 2021","","","IEEE","IEEE Conferences"
"Variational Image Deraining","Y. Du; J. Xu; Q. Qiu; X. Zhen; L. Zhang","University of Amsterdam, Amsterdam, Netherlands; Inception Institute of Artificial Intelligence, Abu Dhabi, UAE; Duke University, Durham, USA; Inception Institute of Artificial Intelligence, Abu Dhabi, UAE; Guangdong University of Petrochemical Technology, Guangdong, China","2020 IEEE Winter Conference on Applications of Computer Vision (WACV)","14 May 2020","2020","","","2395","2404","Images captured in severe weather such as rain and snow significantly degrade the accuracy of vision systems, e.g., for outdoor video surveillance or autonomous driving. Image deraining is a critical yet highly challenging task, due to the fact that rain density varies across spatial locations, while the distribution patterns simultaneously vary across color channels. In this paper, we propose a variational image deraining (VID) method by formulating image deraining in a conditional variational auto-encoder framework. To achieve adaptive deraining to spatial rain density, we generate a density estimation map for each color channel, which can largely avoid over and under deraining. In addition, to address cross-channel variations, we conduct channel-wise deraining, motivated by our observation that bright pixels do not tend to remain bright after deraining unless their color channels are handled separately. Experimental results show that the proposed deraining method achieves superior performance on both synthesized and real rainy images, surpassing previous state-of-the-art methods by large margins.","2642-9381","978-1-7281-6553-0","10.1109/WACV45572.2020.9093393","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9093393","","Rain;Task analysis;Image color analysis;Estimation;Decoding;Image reconstruction;Monte Carlo methods","computer vision;image capture;image colour analysis;image enhancement;image reconstruction;image segmentation;neural nets;rain;variational techniques","derained image reconstruction;vision system accuracy;image capture;variational image deraining;channel-wise deraining;density estimation;spatial rain density;adaptive deraining;conditional variational autoencoder;color channel;severe weather","","19","","37","","14 May 2020","","","IEEE","IEEE Conferences"
"Unsupervised Variational Video Hashing With 1D-CNN-LSTM Networks","S. Li; Z. Chen; X. Li; J. Lu; J. Zhou","Tsinghua Shenzhen International Graduate School, Shenzhen, China; Department of Automation, State Key Lab of Intelligent Technologies and Systems, Beijing Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Tsinghua Shenzhen International Graduate School, Shenzhen, China; Department of Automation, State Key Lab of Intelligent Technologies and Systems, Beijing Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Automation, State Key Lab of Intelligent Technologies and Systems, Beijing Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China","IEEE Transactions on Multimedia","21 May 2020","2020","22","6","1542","1554","Most existing unsupervised video hashing methods generate binary codes by using RNNs in a deterministic manner, which fails to capture the dominant latent variation of videos. In addition, RNN-based video hashing methods suffer the content forgetting of early input frames due to the sequential processing inherency of RNNs, which is detrimental to global information capturing. In this work, we propose an unsupervised variational video hashing (UVVH) method for scalable video retrieval. Our UVVH method aims to capture the salient and global information in a video. Specifically, we introduce a variational autoencoder to learn a probabilistic latent representation of the salient factors of video variations. To better exploit the global information of videos, we design a 1D-CNN-LSTM model. The 1D-CNN-LSTM model processes long frame sequences in a parallel and hierarchical way, and exploits the correlations between frames to reconstruct the frame-level features. As a consequence, the learned hash functions can produce reliable binary codes for video retrieval. We conduct extensive experiments on three widely used benchmark datasets, FCVID, ActivityNet and YFCC to validate the effectiveness of our proposed approach.","1941-0077","","10.1109/TMM.2019.2946096","National Basic Research Program of China (973 Program)(grant numbers:2017YFA0700802); National Natural Science Foundation of China(grant numbers:41876098,U1813218,61806110,61822603,U1713214,61672306,61572271,61527808); National Postdoctoral Program for Innovative Talents(grant numbers:BX201700137); China Postdoctoral Science Foundation(grant numbers:2018M630159); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861413","hashing;scalable video retrieval;unsupervised;variational","Binary codes;Hash functions;Probabilistic logic;Correlation;Decoding;Convolutional codes;Visualization","binary codes;convolutional neural nets;image reconstruction;image representation;image sequences;probability;recurrent neural nets;unsupervised learning;video coding;video retrieval","RNN-based video;early input frames;sequential processing inherency;RNNs;global information capturing;unsupervised variational video hashing method;scalable video retrieval;UVVH method;variational autoencoder;probabilistic latent representation;video variations;1D-CNN-LSTM model;learned hash functions;reliable binary codes;1D-CNN-LSTM networks","","10","","79","IEEE","7 Oct 2019","","","IEEE","IEEE Journals"
"Combining Reservoir Computing and Variational Inference for Efficient One-Class Learning on Dynamical Systems","D. Cabrera; F. Sancho; F. Tobar","Department of Mechanical Engineering, Universidad Politéecnica Salesiana sede Cuenca, Cuenca, Ecuador; Department of Mechanical Engineering, Universidad Politéecnica Salesiana sede Cuenca, Cuenca, Ecuador; Department of Mechanical Engineering, Universidad Politéecnica Salesiana sede Cuenca, Cuenca, Ecuador","2017 International Conference on Sensing, Diagnostics, Prognostics, and Control (SDPC)","14 Dec 2017","2017","","","57","62","Usually, time series acquired from some measurement in a dynamical system are the main source of information about its internal structure and complex behavior. In this situation, trying to predict a future state or to classify internal features in the system becomes a challenging task that requires adequate conceptual and computational tools as well as appropriate datasets. A specially difficult case can be found in the problems framed under one-class learning. In an attempt to sidestep this issue, we present a machine learning methodology based in Reservoir Computing and Variational Inference. In our setting, the dynamical system generating the time series is modeled by an Echo State Network (ESN), and the parameters of the ESN are defined by an expressive probability distribution which is represented as a Variational Autoencoder. As a proof of its applicability, we show some results obtained in the context of condition-based maintenance in rotating machinery, where vibration signals can be measured from the system, our goal is fault detection in helical gearboxes under realistic operating conditions. The results show that our model is able, after trained only with healthy conditions, to discriminate successfully between healthy and faulty conditions.","","978-1-5090-4020-9","10.1109/SDPC.2017.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8181550","Dynamical System Modeling;Reservoir Computing;Variational Inference","Reservoirs;Time series analysis;Computational modeling;Probability distribution;Mathematical model;Time measurement","fault diagnosis;gears;learning (artificial intelligence);machinery;maintenance engineering;probability;time series;vibrational signal processing","reservoir computing;variational inference;one-class learning;dynamical system;time series;Echo State Network;Variational Autoencoder;fault detection;vibration signals;condition-based maintenance;rotating machinery","","","","11","","14 Dec 2017","","","IEEE","IEEE Conferences"
"Wind Turbine Gearbox Failure Detection Based on SCADA Data: A Deep Learning-Based Approach","L. Yang; Z. Zhang","School of Data Science, City University of Hong Kong, Hong Kong, SAR, China; School of Data Science, City University of Hong Kong, Hong Kong, SAR, China","IEEE Transactions on Instrumentation and Measurement","8 Jan 2021","2021","70","","1","11","Gearbox failure is one of top-ranked factors leading to the unavailability of wind turbines (WTs). Existing data-driven studies of gearbox failure detection (GFD) focus on improving detection accuracies while reducing false alarms has not received sufficient discussions. In this article, we propose a deep joint variational autoencoder (JVAE)-based monitoring method using wind farm supervisory control and data acquisition (SCADA) data to more effectively detect WT gearbox failures. The JVAE-based monitoring method includes two parts. First, a novel JVAE that takes a chunk of multivariate time series derived from collected SCADA data as inputs is developed. The JVAE utilizes two types of predefined parameters, behavior parameters (BPs) and conditional parameters (CPs), to produce reconstruction errors (REs) of the BP, which reflects the gearbox abnormality. Next, a statistical process control chart is developed to monitor REs and raise alarms. To validate advantages of the proposed method in GFD, five methods, the joint latent variational autoencoder (JLVAE)-, the variational autoencoder (VAE)-, full-dimensional VAE (FDVAE)-, recurrent autoencoder (RAE)-, and one-class support vector machine (OCSVM)-based monitoring methods, are considered as benchmarks. SCADA data with field reports of gearbox failure events collected from four commercial wind farms are utilized to demonstrate the effectiveness of the JVAE-based monitoring method on GFD and its stronger ability to resist false alarms.","1557-9662","","10.1109/TIM.2020.3045800","Hong Kong Research Grants Council General Research Fund(grant numbers:11215418,11204419); CityU Strategic Research(grant numbers:7005302,7005537); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9298851","Anomaly detection;autoencoders (AEs);data mining;wind energy;wind turbine (WT) gearbox","Monitoring;Wind farms;Feature extraction;Wind turbines;Support vector machines;Data models;Doubly fed induction generators","condition monitoring;control charts;data acquisition;failure (mechanical);fault diagnosis;gears;learning (artificial intelligence);mechanical engineering computing;recurrent neural nets;SCADA systems;statistical process control;support vector machines;time series;wind power plants;wind turbines","data mining;one-class support vector machine-based monitoring;recurrent autoencoder;full-dimensional VAE;reconstruction errors;behavior parameters;wind turbine GFD;deep joint variational autoencoder-based monitoring;JVAE-based monitoring;gearbox failure events;joint latent variational autoencoder;statistical process control chart;conditional parameters;SCADA data;WT gearbox failures;wind farm supervisory control;deep learning;wind turbine gearbox failure detection","","9","","30","IEEE","18 Dec 2020","","","IEEE","IEEE Journals"
"Semi-Supervised Recurrent Variational Autoencoder Approach for Visual Diagnosis of Atrial Fibrillation","N. Costa; L. Sánchez; I. Couso","Computer Science Department, University of Oviedo, Gijón, Spain; Computer Science Department, University of Oviedo, Gijón, Spain; Statistics Department, University of Oviedo, Gijón, Spain","IEEE Access","15 Mar 2021","2021","9","","40227","40239","In this work we propose a semi-supervised framework to visually assess the progression of time series. To this end, we present a recurrent version of the VAE to exploit the generative properties that lead it to learn in an unsupervised way a continuous compressed representation of the data. We introduce a classifier in the VAE training process to control the regulation of the latent space, allowing the network to learn latent variables that set the basis for creating an explainable evaluation of the data. We use the proposed framework to address the diagnosis of Atrial Fibrillation (AF) first validating it with simulated data with known properties and subsequently testing it with intracardiac data obtained from pacemakers and defibrillator systems.","2169-3536","","10.1109/ACCESS.2021.3064854","Ministry of Economy, Industry and Competitiveness (Ministerio de Economía, Industria y Competitividad) of Spain/FEDER(grant numbers:TIN2017-84804-R,PID2020-112726-RB); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9373315","Graphical Analysis;heart disease;recurrent neural networks;time series;variational autoencoder","Time series analysis;Diseases;Heart beat;Electrocardiography;Data models;Pacemakers;Task analysis","","","","5","","47","CCBY","9 Mar 2021","","","IEEE","IEEE Journals"
"Experimental Evidence that Empowerment May Drive Exploration in Sparse-Reward Environments","F. Massari; M. Biehl; L. Meeden; R. Kanai","Swarthmore College, Swarthmore, USA; Araya Inc., Tokyo, Japan; Department of Computer Science, Swarthmore College, Swarthmore, USA; Araya Inc., Tokyo, Japan","2021 IEEE International Conference on Development and Learning (ICDL)","20 Aug 2021","2021","","","1","6","Reinforcement Learning (RL) is known to be often unsuccessful in environments with sparse extrinsic rewards. A possible countermeasure is to endow RL agents with an intrinsic reward function, or ‘intrinsic motivation’, which rewards the agent based on certain features of the current sensor state. An intrinsic reward function based on the principle of empowerment assigns rewards proportional to the amount of control the agent has over its own sensors. We implemented a variation on a recently proposed intrinsically motivated agent, which we refer to as the ‘curious’ agent, and an empowerment-inspired agent. The former leverages sensor state encoding with a variational autoencoder, while the latter predicts the next sensor state via a variational information bottleneck. We compared the performance of both agents to that of an advantage actor-critic baseline in four sparse reward grid worlds. Both the empowerment agent and its curious competitor seem to benefit to similar extents from their intrinsic rewards. This provides some experimental support to the conjecture that empowerment can be used to drive exploration.","","978-1-7281-6242-3","10.1109/ICDL49984.2021.9515647","Swarthmore College; Templeton World Charity Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9515647","Advantage Actor-Critic;Empowerment;Information Bottleneck;Information Gain;Intrinsic Motivation;Reinforcement Learning;Variational Autoencoder","Conferences;Reinforcement learning;Encoding","learning (artificial intelligence);neural nets;software agents;variational techniques","drive exploration;sparse-reward environments;sparse extrinsic rewards;RL agents;intrinsic reward function;empowerment agent;intrinsic rewards;intrinsically motivated agent;curious agent;variational autoencoder","","","","23","","20 Aug 2021","","","IEEE","IEEE Conferences"
"Generalized Zero- and Few-Shot Learning via Aligned Variational Autoencoders","E. Schönfeld; S. Ebrahimi; S. Sinha; T. Darrell; Z. Akata",Bosch Center for Artificial Intelligence; UC Berkeley; University of Toronto; UC Berkeley; University of Amsterdam,"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","8239","8247","Many approaches in generalized zero-shot learning rely on cross-modal mapping between the image feature space and the class embedding space. As labeled images are expensive, one direction is to augment the dataset by generating either images or image features. However, the former misses fine-grained details and the latter requires learning a mapping associated with class embeddings. In this work, we take feature generation one step further and propose a model where a shared latent space of image features and class embeddings is learned by modality-specific aligned variational autoencoders. This leaves us with the required discriminative information about the image and classes in the latent features, on which we train a softmax classifier. The key to our approach is that we align the distributions learned from images and from side-information to construct latent features that contain the essential multi-modal information associated with unseen classes. We evaluate our learned latent features on several benchmark datasets, i.e. CUB, SUN, AWA1 and AWA2, and establish a new state of the art on generalized zero-shot as well as on few-shot learning. Moreover, our results on ImageNet with various zero-shot splits show that our latent features generalize well in large-scale settings.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.00844","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8953639","Representation Learning;Deep Learning","","feature extraction;image classification;learning (artificial intelligence);neural nets","cross-modal mapping;zero-shot learning;generalized zero;zero-shot splits;few-shot learning;learned latent features;essential multimodal information;required discriminative information;modality-specific aligned variational autoencoders;shared latent space;feature generation;class embeddings;misses fine-grained details;image features;labeled images;class embedding space;image feature space","","170","1","37","","9 Jan 2020","","","IEEE","IEEE Conferences"
"Deep Feature Consistent Variational Autoencoder","X. Hou; L. Shen; K. Sun; G. Qiu","University of Nottingham, Ningbo, China; Shenzhen University, Shenzhen, China; University of Nottingham, Ningbo, China; University of Nottingham, Ningbo, China","2017 IEEE Winter Conference on Applications of Computer Vision (WACV)","15 May 2017","2017","","","1133","1141","We present a novel method for constructing Variational Autoencoder (VAE). Instead of using pixel-by-pixel loss, we enforce deep feature consistency between the input and the output of a VAE, which ensures the VAE's output to preserve the spatial correlation characteristics of the input, thus leading the output to have a more natural visual appearance and better perceptual quality. Based on recent deep learning works such as style transfer, we employ a pre-trained deep convolutional neural network (CNN) and use its hidden features to define a feature perceptual loss for VAE training. Evaluated on the CelebA face dataset, we show that our model produces better results than other methods in the literature. We also show that our method can produce latent vectors that can capture the semantic information of face expressions and can be used to achieve state-of-the-art performance in facial attribute prediction.","","978-1-5090-4822-9","10.1109/WACV.2017.131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7926714","","Loss measurement;Image reconstruction;Training;Decoding;Face;Correlation;Feature extraction","feedforward neural nets;image reconstruction","deep feature consistency;variational autoencoder;spatial correlation characteristics;natural visual appearance;perceptual quality;pretrained deep CNN;convolutional neural network;feature perceptual loss;VAE training;CelebA face dataset;latent vectors;facial attribute prediction;image reconstruction","","108","2","34","","15 May 2017","","","IEEE","IEEE Conferences"
"A Generative Model for Zero Shot Learning Using Conditional Variational Autoencoders","A. Mishra; S. K. Reddy; A. Mittal; H. A. Murthy",Indian Institute of Technology Madras; Indian Institute of Technology Madras; Indian Institute of Technology Madras; Indian Institute of Technology Madras,"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","16 Dec 2018","2018","","","2269","22698","Zero shot learning in Image Classification refers to the setting where images from some novel classes are absent in the training data but other information such as natural language descriptions or attribute vectors of the classes are available. This setting is important in the real world since one may not be able to obtain images of all the possible classes at training. While previous approaches have tried to model the relationship between the class attribute space and the image space via some kind of a transfer function in order to model the image space correspondingly to an unseen class, we take a different approach and try to generate the samples from the given attributes, using a conditional variational autoencoder, and use the generated samples for classification of the unseen classes. By extensive testing on four benchmark datasets, we show that our model outperforms the state of the art, particularly in the more realistic generalized setting, where the training classes can also appear at the test time along with the novel classes.","2160-7516","978-1-5386-6100-0","10.1109/CVPRW.2018.00294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8575465","","Semantics;Training;Image generation;Decoding;Visualization;Data models;Computer vision","image classification;image coding;learning (artificial intelligence);vectors","class attribute space;image space;conditional variational autoencoder;generative model;zero shot learning;Image Classification","","103","","48","","16 Dec 2018","","","IEEE","IEEE Conferences"
"UC-Net: Uncertainty Inspired RGB-D Saliency Detection via Conditional Variational Autoencoders","J. Zhang; D. -P. Fan; Y. Dai; S. Anwar; F. S. Saleh; T. Zhang; N. Barnes","Data61; Inception Institute of Artificial Intelligence (IIAI), Abu Dhabi, UAE; Northwestern Polytechnical University; Data61; ACRV; Australian National University; Australian National University","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","8579","8588","In this paper, we propose the first framework (UCNet) to employ uncertainty for RGB-D saliency detection by learning from the data labeling process. Existing RGB-D saliency detection methods treat the saliency detection task as a point estimation problem, and produce a single saliency map following a deterministic learning pipeline. Inspired by the saliency data labeling process, we propose probabilistic RGB-D saliency detection network via conditional variational autoencoders to model human annotation uncertainty and generate multiple saliency maps for each input image by sampling in the latent space. With the proposed saliency consensus process, we are able to generate an accurate saliency map based on these multiple predictions. Quantitative and qualitative evaluations on six challenging benchmark datasets against 18 competing algorithms demonstrate the effectiveness of our approach in learning the distribution of saliency maps, leading to a new state-of-the-art in RGB-D saliency detection.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156838","","Saliency detection;Labeling;Predictive models;Uncertainty;Pipelines;Probabilistic logic;Training","computer vision;feature extraction;image coding;image colour analysis;image segmentation;learning (artificial intelligence);object detection","qualitative evaluation;quantitative evaluation;saliency consensus process;multiple saliency maps;human annotation uncertainty;probabilistic RGB-D saliency detection network;saliency data labeling process;deterministic learning pipeline;RGB-D saliency detection methods;UCNet;conditional variational autoencoders;uncertainty inspired RGB-D saliency detection","","81","","66","IEEE","5 Aug 2020","","","IEEE","IEEE Conferences"
"Variational Autoencoders for Deforming 3D Mesh Models","Q. Tan; L. Gao; Y. -K. Lai; S. Xia","School of Computer and Control Engineering, University of Chinese Academy of Sciences; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Chinese Academy of Sciences; School of Computer Science & Informatics, Cardiff University; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Chinese Academy of Sciences","2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition","16 Dec 2018","2018","","","5841","5850","3D geometric contents are becoming increasingly popular. In this paper, we study the problem of analyzing deforming 3D meshes using deep neural networks. Deforming 3D meshes are flexible to represent 3D animation sequences as well as collections of objects of the same category, allowing diverse shapes with large-scale non-linear deformations. We propose a novel framework which we call mesh variational autoencoders (mesh VAE), to explore the probabilistic latent space of 3D surfaces. The framework is easy to train, and requires very few training examples. We also propose an extended model which allows flexibly adjusting the significance of different latent variables by altering the prior distribution. Extensive experiments demonstrate that our general framework is able to learn a reasonable representation for a collection of deformable shapes, and produce competitive results for a variety of applications, including shape generation, shape interpolation, shape space embedding and shape exploration, outperforming state-of-the-art methods.","2575-7075","978-1-5386-6420-9","10.1109/CVPR.2018.00612","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8578710","","Shape;Three-dimensional displays;Solid modeling;Two dimensional displays;Deformable models;Analytical models;Geometry","computer animation;image representation;interpolation;learning (artificial intelligence);mesh generation;neural nets;solid modelling","variational autoencoders;3D mesh models;3D geometric contents;deforming 3D meshes;deep neural networks;3D animation sequences;diverse shapes;mesh VAE;probabilistic latent space;training examples;extended model;general framework;deformable shapes;shape generation;shape interpolation;shape space embedding;shape exploration;nonlinear deformations;latent variables","","67","","49","","16 Dec 2018","","","IEEE","IEEE Conferences"
"Non-Parallel Voice Conversion Using Variational Autoencoders Conditioned by Phonetic Posteriorgrams and D-Vectors","Y. Saito; Y. Ijima; K. Nishida; S. Takamichi","Graduate School of Information Science and Technology, The University of Tokyo; NTT Media Intelligence Laboratories, NTT Corporation, Japan; NTT Media Intelligence Laboratories, NTT Corporation, Japan; NTT Media Intelligence Laboratories, NTT Corporation, Japan","2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 Sep 2018","2018","","","5274","5278","This paper proposes novel frameworks for non-parallel voice conversion (VC) using variational autoencoders (VAEs). Although conventional VAE-based VC models can be trained using non-parallel speech corpora with given speaker representations, phonetic contents of the converted speech tend to vanish because of an over-regularization issue often observed in latent variables of the VAEs. To overcome the issue, this paper proposes a VAE-based non-parallel VC conditioned by not only the speaker representations but also phonetic contents of speech represented as phonetic posteriorgrams (PPGs). Since the phonetic contents are given during the training, we can expect that the VC models effectively learn speaker-independent latent features of speech. Focusing on the point, this paper also extends the conventional VAE-based non-parallel VC to many-to-many VC that can convert arbitrary speakers' characteristics into another arbitrary speakers' ones. We investigate two methods to estimate speaker representations for speakers not included in speech corpora used for training VC models: 1) adapting conventional speaker codes, and 2) using d-vectors for the speaker representations. Experimental results demonstrate that 1) PPGs successfully improve both naturalness and speaker similarity of the converted speech, and 2) both speaker codes and d-vectors can be adopted to the VAE-based many-to-many non-parallel VC.","2379-190X","978-1-5386-4658-8","10.1109/ICASSP.2018.8461384","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8461384","VAE-based non-parallel VC;phonetic posteri-orgrams;d-vectors;many-to-many VC","Phonetics;Training;Decoding;Speech coding;Graphical models;Backpropagation algorithms;Focusing","speech processing;speech recognition","conventional speaker codes;converted speech;nonparallel VC;nonparallel voice conversion;phonetic posteriorgrams;phonetic contents;speech corpora;variational autoencoders","","42","","19","","13 Sep 2018","","","IEEE","IEEE Conferences"
"GEE: A Gradient-based Explainable Variational Autoencoder for Network Anomaly Detection","Q. P. Nguyen; K. W. Lim; D. M. Divakaran; K. H. Low; M. C. Chan",National University of Singapore; National University of Singapore; Trustwave; National University of Singapore; National University of Singapore,"2019 IEEE Conference on Communications and Network Security (CNS)","19 Aug 2019","2019","","","91","99","This paper looks into the problem of detecting network anomalies by analyzing NetFlow records. While many previous works have used statistical models and machine learning techniques in a supervised way, such solutions have the limitations that they require large amount of labeled data for training and are unlikely to detect zero-day attacks. Existing anomaly detection solutions also do not provide an easy way to explain or identify attacks in the anomalous traffic. To address these limitations, we develop and present GEE, a framework for detecting and explaining anomalies in network traffic. GEE comprises of two components: (i)Variational Autoencoder (VAE)- an unsupervised deep-learning technique for detecting anomalies, and (ii)a gradient-based fingerprinting technique for explaining anomalies. Evaluation of GEE on the recent UGR dataset demonstrates that our approach is effective in detecting different anomalies as well as identifying fingerprints that are good representations of these various attacks.","","978-1-5386-7117-7","10.1109/CNS.2019.8802833","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802833","Anomaly Detection;NetFlow Records;Gradient-based Fingerprinting","Anomaly detection;Deep learning;Data models;Feature extraction;Security;Principal component analysis","gradient methods;Internet;statistical analysis;unsupervised learning","GEE;statistical models;anomaly detection solutions;gradient-based explainable variational autoencoder;zero-day attack detection;unsupervised deep-learning technique;anomalous network traffic detection;NetFlow recording;machine learning techniques;VAE;gradient-based fingerprinting technique;UGR dataset","","40","","43","","19 Aug 2019","","","IEEE","IEEE Conferences"
"Towards Visually Explaining Variational Autoencoders","W. Liu; R. Li; M. Zheng; S. Karanam; Z. Wu; B. Bhanu; R. J. Radke; O. Camps","Northeastern University, Boston, MA; University of California Riverside, Riverside, CA; Rensselaer Polytechnic Institute, Troy, NY; United Imaging Intelligence, Cambridge, MA; United Imaging Intelligence, Cambridge, MA; University of California Riverside, Riverside, CA; Rensselaer Polytechnic Institute, Troy, NY; Northeastern University, Boston, MA","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","8639","8648","Recent advances in Convolutional Neural Network (CNN) model interpretability have led to impressive progress in visualizing and understanding model predictions. In particular, gradient-based visual attention methods have driven much recent effort in using visual attention maps as a means for visual explanations. A key problem, however, is these methods are designed for classification and categorization tasks, and their extension to explaining generative models, e.g., variational autoencoders (VAE) is not trivial. In this work, we take a step towards bridging this crucial gap, proposing the first technique to visually explain VAEs by means of gradient-based attention. We present methods to generate visual attention from the learned latent space, and also demonstrate such attention explanations serve more than just explaining VAE predictions. We show how these attention maps can be used to localize anomalies in images, demonstrating state-of-the-art performance on the MVTec-AD dataset. We also show how they can be infused into model training, helping bootstrap the VAE into learning improved latent space disentanglement, demonstrated on the Dsprites dataset.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00867","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156323","","Visualization;Image reconstruction;Standards;Task analysis;Computational modeling;Anomaly detection;Predictive models","convolutional neural nets;gradient methods;image classification","categorization tasks;variational autoencoders;gradient-based attention;learned latent space;attention explanations;VAE predictions;convolutional neural network;visual attention maps;visual explanations;classification;gradient-based visual attention;classification task;MVTec-AD dataset;latent space disentanglement;Dsprites dataset","","33","","50","","5 Aug 2020","","","IEEE","IEEE Conferences"
"Long Short-Term Memory and Variational Autoencoder With Convolutional Neural Networks for Generating NMR T2 Distributions","H. Li; S. Misra","Mewbourne School of Petroleum and Geological Engineering, The University of Oklahoma, Norman, OK, USA; Mewbourne School of Petroleum and Geological Engineering, The University of Oklahoma, Norman, OK, USA","IEEE Geoscience and Remote Sensing Letters","21 Jan 2019","2019","16","2","192","195","Downhole nuclear magnetic resonance (NMR) logs acquired in the borehole environment are valuable for subsurface characterization because they contain information about the pore size distribution, fluid composition, fluid saturation, fluid mobility, formation permeability, and porosity. NMR log acquisition can be challenging due to operational and financial constraints. Recently, NMR T2 distributions of the subsurface were generated by processing conventional well logs using deeplearning neural-network (NN) models. This improves the accessibility to subsurface pore size distributions. We implement two neural-network models, variational autoencoder-based NN with convolutional layers and long short-term memory (LSTM), to generate NMR T2 distributions from formation mineral content and fluid saturation logs. Prediction performance is evaluated for the entire NMR T2 spectrum ranging from 0.3 to 3000 ms as well as for T2 spectra within four bins obtained by dividing the entire spectrum into four equal parts. Each bin represents a specific pore size range. In terms of R2, both the models have prediction performances above R2 of 0.75 for the entire spectrum. The best prediction performance is achieved for the bin of size ranging from 2.7 to 28 ms, representing pore diameters from 10 to 100 nm. The performance of this bin in terms of R2 is 0.78. The LSTM model is highly sensitive to noise in T2 distribution used during the training, and both the models are robust to noise in the conventional input logs.","1558-0571","","10.1109/LGRS.2018.2872356","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489895","Machine learning;nuclear magnetic resonance (NMR)","Nuclear magnetic resonance;Artificial neural networks;Training;Feature extraction;Testing;Data models;Distance measurement","hydrocarbon reservoirs;neural nets;nuclear magnetic resonance;permeability;porosity;porous materials;rocks;well logging","entire spectrum;specific pore size range;prediction performance;size ranging;conventional input logs;long short-term memory;convolutional neural networks;generating NMR;T2 Distributions;downhole nuclear magnetic resonance;subsurface characterization;pore size distribution;fluid composition;fluid saturation;fluid mobility;deeplearning neural-network models;subsurface pore size distributions;variational autoencoder-based NN;entire NMR;T2 spectrum;time 2.7 ms to 28.0 ms;size 10.0 nm to 100.0 nm;time 0.3 as to 3000.0 as","","26","","13","IEEE","11 Oct 2018","","","IEEE","IEEE Journals"
"Deep Clustering by Gaussian Mixture Variational Autoencoders With Graph Embedding","L. Yang; N. -M. Cheung; J. Li; J. Fang",University of Electronic Science and Technology of China; Singapore University of Technology and Design (SUTD); Singapore University of Technology and Design (SUTD); University of Electronic Science and Technology of China,"2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","6439","6448","We propose DGG: {\textbf D}eep clustering via a {\textbf G}aussian-mixture variational autoencoder (VAE) with {\textbf G}raph embedding. To facilitate clustering, we apply Gaussian mixture model (GMM) as the prior in VAE. To handle data with complex spread, we apply graph embedding. Our idea is that graph information which captures local data structures is an excellent complement to deep GMM. Combining them facilitates the network to learn powerful representations that follow global model and local structural constraints. Therefore, our method unifies model-based and similarity-based approaches for clustering. To combine graph embedding with probabilistic deep GMM, we propose a novel stochastic extension of graph embedding: we treat samples as nodes on a graph and minimize the weighted distance between their posterior distributions. We apply Jenson-Shannon divergence as the distance. We combine the divergence minimization with the log-likelihood maximization of the deep GMM. We derive formulations to obtain an unified objective that enables simultaneous deep representation learning and clustering. Our experimental results show that our proposed DGG outperforms recent deep Gaussian mixture methods (model-based) and deep spectral clustering (similarity-based). Our results highlight advantages of combining model-based and similarity-based clustering as proposed in this work. Our code is published here: https://github.com/dodoyang0929/DGG.git","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.00654","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010011","","Training;Data models;Neural networks;Clustering methods;Machine learning;Gaussian mixture model","data structures;feature extraction;Gaussian processes;graph theory;learning (artificial intelligence);minimisation;mixture models;pattern clustering","graph embedding;probabilistic deep GMM;simultaneous deep representation learning;deep spectral clustering;Gaussian-mixture variational autoencoder;Gaussian mixture model;graph information;local data structures;global model;local structural constraints;model-based clustering;similarity-based clustering;weighted distance;posterior distributions;Jenson-Shannon divergence;divergence minimization;log-likelihood maximization","","25","","42","IEEE","27 Feb 2020","","","IEEE","IEEE Conferences"
"Variational autoencoder based synthetic data generation for imbalanced learning","Z. Wan; Y. Zhang; H. He","Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, Kingston, RI, USA; Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, Kingston, RI, USA; Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, Kingston, RI, USA","2017 IEEE Symposium Series on Computational Intelligence (SSCI)","8 Feb 2018","2017","","","1","7","Discovering pattern from imbalanced data plays an important role in numerous applications, such as health service, cyber security, and financial engineering. However, the imbalanced data greatly compromise the performance of most learning algorithms. Recently, various synthetic sampling methods have been proposed to balance the dataset. Although these methods have achieved great success in many datasets, they are less effective for high-dimensional data, such as the image. In this paper, we propose a variational autoencoder (VAE) based synthetic data generation method for imbalanced learning. VAE can produce new samples which are similar to those in the original dataset, but not exactly the same. We evaluate and compare our proposed method with the traditional synthetic sampling methods on various datasets under five evaluation metrics. The experimental results demonstrate the effectiveness of the proposed method.","","978-1-5386-2726-6","10.1109/SSCI.2017.8285168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8285168","","Sampling methods;Training;Decoding;Computer architecture;Euclidean distance;Data models","data mining;learning (artificial intelligence);pattern classification;sampling methods","synthetic sampling methods;original dataset;synthetic data generation method;VAE;high-dimensional data;learning algorithms;financial engineering;cyber security;health service;numerous applications;imbalanced data;imbalanced learning;variational autoencoder","","22","","25","","8 Feb 2018","","","IEEE","IEEE Conferences"
"OC-FakeDect: Classifying Deepfakes Using One-class Variational Autoencoder","H. Khalid; S. S. Woo","Computer Science and Engineering Department, Sungkyunkwan University, South Korea; Computer Science and Engineering Department, Sungkyunkwan University, South Korea","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","2794","2803","An image forgery method called Deepfakes can cause security and privacy issues by changing the identity of a person in a photo through the replacement of his/her face with a computer-generated image or another person's face. Therefore, a new challenge of detecting Deepfakes arises to protect individuals from potential misuses. Many researchers have proposed various binary-classification based detection approaches to detect deepfakes. However, binary-classification based methods generally require a large amount of both real and fake face images for training, and it is challenging to collect sufficient fake images data in advance. Besides, when new deepfakes generation methods are introduced, little deepfakes data will be available, and the detection performance may be mediocre. To overcome these data scarcity limitations, we formulate deepfakes detection as a one-class anomaly detection problem. We propose OC-FakeDect, which uses a one-class Variational Autoencoder (VAE) to train only on real face images and detects non-real images such as deepfakes by treating them as anomalies. Our preliminary result shows that our one class-based approach can be promising when detecting Deepfakes, achieving a 97.5% accuracy on the NeuralTextures data of the well-known FaceForensics++ benchmark dataset without using any fake images for the training process.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00336","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150876","","Face;Training;Image reconstruction;Forensics;Streaming media;Anomaly detection;Benchmark testing","data privacy;face recognition;feature extraction;image classification;learning (artificial intelligence);object detection;pattern clustering;support vector machines","class-based approach;detects nonreal images;one-class anomaly detection problem;deepfakes detection;data scarcity limitations;detection performance;deepfakes data;deepfakes generation methods;sufficient fake images data;fake face images;binary-classification based methods;binary-classification based detection;detecting Deepfakes;person;computer-generated image;privacy issues;image forgery method;one-class variational autoencoder;OC-FakeDect","","21","","38","","28 Jul 2020","","","IEEE","IEEE Conferences"
"Vehicle Trajectory Prediction Using Intention-based Conditional Variational Autoencoder","X. Feng; Z. Cen; J. Hu; Y. Zhang","Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China","2019 IEEE Intelligent Transportation Systems Conference (ITSC)","28 Nov 2019","2019","","","3514","3519","Vehicle trajectory prediction has been an active research area in autonomous driving. In a real traffic scene, autonomous vehicle needs to predict future motion of surrounding vehicles before motion planning to improve driving safety and efficiency. In this paper, we first modify a sequence to sequence (seq-to-seq) maneuver-based model to produce possibility prediction of vehicle trajectory in future 5 seconds. Then we propose a novel method based on conditional variational autoencoder (CVAE). Our model generates multi-modal trajectory possibility prediction with high interpretability according to the estimation of driver's latent intention. Finally, we experiment the model on public traffic dataset and compare it with prior methods on trajectory prediction. The results show a great improvement on both lateral and longitudinal motion prediction, which also demonstrates the effectiveness of our model.","","978-1-5386-7024-8","10.1109/ITSC.2019.8917482","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917482","","Trajectory;Predictive models;Decoding;Uncertainty;Probability distribution;Autonomous vehicles","automobiles;driver information systems;path planning;road safety;road traffic control","multimodal trajectory possibility prediction;lateral motion prediction;longitudinal motion prediction;vehicle trajectory prediction;intention-based conditional variational autoencoder;autonomous driving;autonomous vehicle;motion planning;driving safety;seq-to-seq;sequence to sequence maneuver-based model;CVAE;time 5.0 s","","16","","14","","28 Nov 2019","","","IEEE","IEEE Conferences"
"Multimodal Deep Generative Models for Trajectory Prediction: A Conditional Variational Autoencoder Approach","B. Ivanovic; K. Leung; E. Schmerling; M. Pavone","Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA; Institute for Computational & Mathematical Engineering, Stanford University, Stanford, CA, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA","IEEE Robotics and Automation Letters","22 Dec 2020","2021","6","2","295","302","Human behavior prediction models enable robots to anticipate how humans may react to their actions, and hence are instrumental to devising safe and proactive robot planning algorithms. However, modeling complex interaction dynamics and capturing the possibility of many possible outcomes in such interactive settings is very challenging, which has recently prompted the study of several different approaches. In this work, we provide a self-contained tutorial on a conditional variational autoencoder (CVAE) approach to human behavior prediction which, at its core, can produce a multimodal probability distribution over future human trajectories conditioned on past interactions and candidate robot future actions. Specifically, the goals of this tutorial paper are to review and build a taxonomy of state-of-the-art methods in human behavior prediction, from physics-based to purely data-driven methods, provide a rigorous yet easily accessible description of a data-driven, CVAE-based approach, highlight important design characteristics that make this an attractive model to use in the context of model-based planning for human-robot interactions, and provide important design considerations when using this class of models.","2377-3766","","10.1109/LRA.2020.3043163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286482","Autonomous vehicle navigation;deep learning methods;social HRI","Robots;Predictive models;Trajectory;Mathematical model;Data models;Planning;Context modeling","behavioural sciences computing;human-robot interaction;neural nets;path planning;statistical distributions","model-based planning;design characteristics;complex interaction dynamics modeling;human trajectories;multimodal probability distribution;proactive robot planning algorithms;safe robot planning algorithms;human behavior prediction models;conditional variational autoencoder approach;trajectory prediction;multimodal deep generative models;human-robot interactions;CVAE-based approach;data-driven methods","","14","","46","IEEE","8 Dec 2020","","","IEEE","IEEE Journals"
"Variational Autoencoders Pursue PCA Directions (by Accident)","M. Rolínek; D. Zietlow; G. Martius","Max-Planck-Institute for Intelligent Systems, Tubingen, Germany; Max-Planck-Institute for Intelligent Systems, Tübingen, Germany; Max-Planck-Institute for Intelligent Systems, Tübingen, Germany","2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","12398","12407","The Variational Autoencoder (VAE) is a powerful architecture capable of representation learning and generative modeling. When it comes to learning interpretable (disentangled) representations, VAE and its variants show unparalleled performance. However, the reasons for this are unclear, since a very particular alignment of the latent embedding is needed but the design of the VAE does not encourage it in any explicit way. We address this matter and offer the following explanation: the diagonal approximation in the encoder together with the inherent stochasticity force local orthogonality of the decoder. The local behavior of promoting both reconstruction and orthogonality matches closely how the PCA embedding is chosen. Alongside providing an intuitive understanding, we justify the statement with full theoretical analysis as well as with experiments.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.01269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8953837","Representation Learning;Computer Vision Theory; Deep Learning","","approximation theory;image matching;learning (artificial intelligence);neural nets;principal component analysis","orthogonality matches;PCA embedding;VAE;generative modeling;interpretable representation learning;disentangled representation;unparalleled performance;latent embedding;diagonal approximation;inherent stochasticity force local orthogonality;local behavior;variational autoencoder;principal component analysis","","11","","44","","9 Jan 2020","","","IEEE","IEEE Conferences"
"Learning Representations by Maximizing Mutual Information in Variational Autoencoders","A. L. Rezaabad; S. Vishwanath","The University of Texas, Austin, TX, USA; The University of Texas, Austin, TX, USA","2020 IEEE International Symposium on Information Theory (ISIT)","24 Aug 2020","2020","","","2729","2734","Variational autoencoders (VAE) have ushered in an new era of unsupervised learning methods for complex distributions. Although these techniques are elegant in their approach, they are typically not useful for representation learning. In this work, we propose a simple yet powerful class of VAEs that simultaneously result in meaningful learned representations. Our solution is to combine traditional VAEs with mutual information maximization, with the goal to enhance amortized inference in VAEs using Information Theoretic techniques. We call this approach InfoMax-VAE, and such an approach can significantly boost the quality of learned high-level representations. We realize this through explicit maximization of information measures associated with the representation. Using extensive experiments on varied datasets and setups, we show that InfoMax-VAE outperforms contemporary popular approaches, including Info- VAE and β-VAE.","2157-8117","978-1-7281-6432-8","10.1109/ISIT44484.2020.9174424","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9174424","","","information theory;neural nets;optimisation;unsupervised learning","variational autoencoders;unsupervised learning methods;representation learning;VAEs;mutual information maximization;amortized inference;information theoretic techniques;explicit maximization;InfoMax-VAE","","8","","24","","24 Aug 2020","","","IEEE","IEEE Conferences"
"Joint Source-Channel Coding for Gaussian Sources over AWGN Channels using Variational Autoencoders","Y. M. Saidutta; A. Abdi; F. Fekri","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, Georgia, U.S.A.; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, Georgia, U.S.A.; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, Georgia, U.S.A.","2019 IEEE International Symposium on Information Theory (ISIT)","26 Sep 2019","2019","","","1327","1331","In this paper, we study joint source-channel coding of gaussian sources over multiple AWGN channels where the source dimension is greater than the number of channels. We model our system as a Variational Autoencoder and show that its loss function takes up a form that is an upper bound on the optimization function got from rate-distortion theory. The constructed system employs two encoders that learn to split the source input space into almost half with no constraints. The system is jointly trained in a data-driven manner, end-to-end. We achieve state of the art results for certain configurations, some of which are 0.7dB better than previous works. We also showcase that the trained encoder/decoder is robust, i.e., even if the channel conditions change by +/-5dB, the performance of the system does not vary by more than 0.7dB w.r.t. a system trained at that channel condition. The trained system, to an extent, has the ability to generalize when a single input dimension is dropped and for some scenarios it is less than 1dB away from the system trained for that reduced dimension.","2157-8117","978-1-5386-9291-2","10.1109/ISIT.2019.8849476","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8849476","","AWGN channels;Decoding;Distortion;Neural networks;Channel coding;Upper bound","AWGN channels;combined source-channel coding;decoding;learning (artificial intelligence);neural nets;optimisation;rate distortion theory;telecommunication computing","joint source-channel coding;variational autoencoders;multiple AWGN channels;source dimension;source input space;channel condition;trained system;rate-distortion theory;optimization function;loss function;Gaussian sources;noise figure 0.7 dB","","8","","16","","26 Sep 2019","","","IEEE","IEEE Conferences"
"Many-to-Many Voice Conversion based on Bottleneck Features with Variational Autoencoder for Non-parallel Training Data","Y. Li; K. A. Lee; Y. Yuan; H. Li; Z. Yang","College of Telecommunication & Information Engineering, Nanjing University of Posts and Telecommunications, China; Data Science Research Laboratories, NEC Corporation, Japan; Northwestern Polytechnical University, Xi'an, China; Department of Electronic and Computer-Engineering, National University of Singapore, Singapore; College of Telecommunication & Information Engineering, Nanjing University of Posts and Telecommunications, China","2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","7 Mar 2019","2018","","","829","833","This paper proposes a novel approach to many-to-many (M2M) voice conversion for non-parallel training data. In the proposed approach, we first obtain bottleneck features (BNFs) as speaker representations from a deep neural network (DNN). Then, a variational autoencoder (VAE) implements the mapping function (i.e., a reconstruction process) using both the latent semantic information and the speaker representations. Furthermore, we propose an adaptive scheme by intervening the training process of the DNN, which can enrich the target speaker's personality feature space in the case of limited training data. Our approach has three advantages: 1) neither parallel training data nor explicit frame alignment process is required; 2) consolidates multiple pair-wise systems into a single M2M model (many-source speakers to many-target speakers); 3) expands M2M conversion task from closed set to open set when the training data of target speaker is very limited. The objective and subjective evaluations show that our proposed approach outperforms the baseline system.","2640-0103","978-9-8814-7685-2","10.23919/APSIPA.2018.8659628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8659628","","Training data;Training;Machine-to-machine communications;Feature extraction;Speaker recognition;Decoding;Error analysis","Gaussian processes;learning (artificial intelligence);neural nets;signal reconstruction;signal representation;speaker recognition;speech processing","bottleneck features;variational autoencoder;nonparallel training data;speaker representations;deep neural network;DNN;reconstruction process;training process;parallel training data;explicit frame alignment process;single M2M model;many-source speakers;many-target speakers;M2M conversion task;M2M voice conversion;many-to-many voice conversion;VAE;target speaker personality feature space;multiple pair-wise systems;latent semantic information","","4","","26","","7 Mar 2019","","","IEEE","IEEE Conferences"
"Simulating Tariff Impact in Electrical Energy Consumption Profiles With Conditional Variational Autoencoders","M. Brégère; R. J. Bessa","INRIA - Département d’Informatique de l’école Normale Supérieure, PSL Research University, Paris, France; INESC Technology and Science (INESC TEC), Porto, Portugal","IEEE Access","24 Jul 2020","2020","8","","131949","131966","The implementation of efficient demand response (DR) programs for household electricity consumption would benefit from data-driven methods capable of simulating the impact of different tariffs schemes. This paper proposes a novel method based on conditional variational autoencoders (CVAE) to generate, from an electricity tariff profile combined with weather and calendar variables, daily consumption profiles of consumers segmented in different clusters. First, a large set of consumers is gathered into clusters according to their consumption behavior and price-responsiveness. The clustering method is based on a causality model that measures the effect of a specific tariff on the consumption level. Then, daily electrical energy consumption profiles are generated for each cluster with CVAE. This non-parametric approach is compared to a semi-parametric data generator based on generalized additive models. Experiments in a publicly available data set show that, the proposed method presents comparable performance to the semi-parametric one when it comes to generating the average value of the original data (13% difference in root mean square error). The main contribution from this new method is the capacity to reproduce rebound and side effects in the generated consumption profiles. Indeed, the application of a special electricity tariff over a time window may also affect consumption outside this time window. Another contribution is that the proposed clustering approach is capturing the reaction to a tariff change. When compared to a clustering method with classical features (min, max and average consumption), the improvement in the Calinski-Harabasz index was 128% for consumers associated with tariff changes.","2169-3536","","10.1109/ACCESS.2020.3009060","European Regional Development Fund (ERDF) through the Operational Programme for Competitiveness and Internationalisation - COMPETE 2020 Programme; National Funds through the Portuguese funding agency, FCT – Fundação para a Ciência e a Tecnologia, within project ESGRIDS – Desenvolvimento Sustentável da Rede Elétrica Inteligente/SAICTPAC/0004/2015-POCI-01-0145-FEDER-016434; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9139305","Deep learning;clustering;simulation;demand response;smart grids;energy consumption","Tariffs;Energy consumption;Home appliances;Data models;Clustering algorithms;Generators;Load modeling","demand side management;pattern clustering;power consumption;power engineering computing;pricing;tariffs","generated consumption profiles;time window;clustering approach;tariff change;average consumption;Calinski-Harabasz index;generalized additive models;semiparametric data generator;nonparametric approach;electrical energy consumption;causality model;clustering method;price-responsiveness;consumption behavior;weather;electricity tariff profile;CVAE;data-driven methods;household electricity consumption;demand response;conditional variational autoencoders;tariff impact","","4","","52","CCBY","13 Jul 2020","","","IEEE","IEEE Journals"
"Variational AutoEncoder for Reference based Image Super-Resolution","Z. -S. Liu; W. -C. Siu; L. -W. Wang",Caritas Institute of Higher Education; The Hong Kong Polytechnic University; The Hong Kong Polytechnic University,"2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","1 Sep 2021","2021","","","516","525","In this paper, we propose a novel reference based image super-resolution approach via Variational AutoEncoder (RefVAE). Existing state-of-the-art methods mainly focus on single image super-resolution which cannot perform well on large upsampling factors, e.g., 8×. We propose a reference based image super-resolution, for which any arbitrary image can act as a reference for super-resolution. Even using random map or low-resolution image itself, the proposed RefVAE can transfer the knowledge from the reference to the super-resolved images. Depending upon different references, the proposed method can generate different versions of super-resolved images from a hidden super- resolution space. Besides using different datasets for some standard evaluations with PSNR and SSIM, we also took part in the NTIRE2021 SR Space challenge [29] and have provided results of the randomness evaluation of our approach. Compared to other state-of-the-art methods, our approach achieves higher diverse scores.","2160-7516","978-1-6654-4899-4","10.1109/CVPRW53098.2021.00063","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9522932","","Computer vision;Quantization (signal);Conferences;Computational modeling;Superresolution;Space exploration;Pattern recognition","image resolution;neural nets","image super-resolution approach;single image super-resolution;arbitrary image;low-resolution image;super-resolved images;hidden super-resolution space;variational autoencoder;PSNR;SSIM;NTIRE2021 SR space challenge;diverse scores;RefVAE","","3","","46","","1 Sep 2021","","","IEEE","IEEE Conferences"
"Estimation of Orientation and Camera Parameters from Cryo-Electron Microscopy Images with Variational Autoencoders and Generative Adversarial Networks","N. Miolane; F. Poitevin; Y. -T. Li; S. Holmes",Stanford University; Stanford University; SLAC National Accelerator; Stanford University,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","4174","4183","Cryo-electron microscopy (cryo-EM) is capable of producing reconstructed 3D images of biomolecules at near-atomic resolution. However, raw cryo-EM images are only highly corrupted - noisy and band-pass filtered - 2D projections of the target 3D biomolecules. Reconstructing the 3D molecular shape requires the estimation of the orientation of the biomolecule that has produced the given 2D image, and the estimation of camera parameters to correct for intensity defects. Current techniques performing these tasks are often computationally expensive, while the dataset sizes keep growing. There is a need for next-generation algorithms that preserve accuracy while improving speed and scalability. In this paper, we combine variational autoencoders (VAEs) and generative adversarial networks (GANs) to learn a low-dimensional latent representation of cryoEM images. This analysis leads us to design an estimation method for orientation and camera parameters of single-particle cryo-EM images, which opens the door to faster cryo-EM biomolecule reconstruction.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150810","","Space vehicles;Three-dimensional displays;Two dimensional displays;Orbits;Cameras;Estimation;Image reconstruction","bioinformatics;cameras;electron microscopy;image reconstruction;image representation;image resolution;molecular biophysics;neural nets","target 3D biomolecules;3D molecular shape;biomolecule;given 2D image;camera parameters;next-generation algorithms;variational autoencoders;generative adversarial networks;cryoEM images;estimation method;single-particle cryo-EM images;faster cryo-EM;cryo-electron microscopy images;near-atomic resolution;raw cryo-EM images;noisy band-pass","","3","","46","","28 Jul 2020","","","IEEE","IEEE Conferences"
"A Noise Removal Approach from EEG Recordings Based on Variational Autoencoders","J. F. Hwaidi; T. M. Chen","Department of Electrical and Electronic Engineering, City, University of London, London, United Kingdom; Department of Electrical and Electronic Engineering, City, University of London, London, United Kingdom","2021 13th International Conference on Computer and Automation Engineering (ICCAE)","10 May 2021","2021","","","19","23","This paper presents a novel approach for reducing noise in electroencephalography (EEG) signals using the Variational AutoEncoders (VAE) algorithm. VAE's are attractive as they are designed on top of standard function approximators neural networks and can be trained with stochastic gradient descent to produce the desired output. Moreover, VAE has been compared with standard fast fixed-point algorithm for independent component analysis (FastICA) algorithm to measure the performance quantitatively by using machine learning algorithms like Support Vector Machines, Naive Bayes, and Decision Tree. The catch of this algorithm is utilised using the concept of misclassification as opposed to the classification accuracy of the above mentioned algorithms.","","978-1-6654-1295-7","10.1109/ICCAE51876.2021.9426150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9426150","EEG;Noise removal;misclassification;FastICA;VAE","Support vector machines;Machine learning algorithms;Neural networks;Independent component analysis;Approximation algorithms;Electroencephalography;Classification algorithms","decision trees;electroencephalography;function approximation;gradient methods;image denoising;independent component analysis;learning (artificial intelligence);medical signal processing;neural nets;pattern classification;support vector machines","noise removal approach;EEG recordings;electroencephalography signals;Variational AutoEncoders algorithm;VAE;standard function approximators neural networks;stochastic gradient descent;fixed-point algorithm;independent component analysis algorithm;Support Vector Machines;mentioned algorithms","","3","","22","","10 May 2021","","","IEEE","IEEE Conferences"
"Conditional Constrained Graph Variational Autoencoders for Molecule Design","D. Rigoni; N. Navarin; A. Sperduti","Fondazione Bruno Kessler, Povo, Italy; Department of Mathematics, University of Padua, Padua, Italy; Department of Mathematics, University of Padua, Padua, Italy","2020 IEEE Symposium Series on Computational Intelligence (SSCI)","5 Jan 2021","2020","","","729","736","In recent years, deep generative models for graphs have been used to generate new molecules. These models have produced good results, leading to several proposals in the literature. However, these models may have troubles learning some of the complex laws governing the chemical world. In this work, we explore the usage of the histogram of atom valences to drive the generation of molecules in such models. We present Conditional Constrained Graph Variational Autoencoder (CCGVAE), a model that implements this key-idea in a state-of-the-art model, and shows improved results on several evaluation metrics on two commonly adopted datasets for molecule generation.","","978-1-7281-2547-3","10.1109/SSCI47803.2020.9308554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308554","Deep Learning;VAE;Graphs;Molecule generation","Decoding;Computational modeling;Histograms;Training;Grammar;Chemicals;Optimization","chemistry computing;deep learning (artificial intelligence);graph theory","molecule generation;conditional constrained graph variational autoencoders;molecule design;deep generative models;CCGVAE","","2","","31","","5 Jan 2021","","","IEEE","IEEE Conferences"
"Stochastic Virtual Battery Modeling of Uncertain Electrical Loads Using Variational Autoencoder","I. Chakraborty; S. P. Nandanoori; S. Kundu; K. Kalsi","Center for Applied Scientific Computing, Lawrence Livermore National Laboratory, Livermore, CA, USA; Optimization and Control Group, Pacific Northwest National Laboratory, Richland, WA, USA; Optimization and Control Group, Pacific Northwest National Laboratory, Richland, WA, USA; Optimization and Control Group, Pacific Northwest National Laboratory, Richland, WA, USA","2020 American Control Conference (ACC)","27 Jul 2020","2020","","","1305","1310","Effective utilization of flexible loads for grid services, while satisfying end-user preferences and constraints, requires an accurate estimation of the aggregated predictive flexibility offered by the electrical loads. Virtual battery (VB) models are often used to quantify the predictive flexibility in thermostatic loads (e.g. residential air-conditioners, electric water-heaters), which model the temporal evolution of a (virtual) energy state via a first order dynamics including self-dissipation rate, and power and energy capacities as parameters. Uncertainties and lack of information regarding end-usage and equipment models render deterministic VB models impractical. In this paper, we introduce the notion of stochastic VB models, and propose a variational autoencoder-based deep learning algorithm to identify the probability distribution of the VB model parameters. Using available sensors and meters data, the proposed algorithm generates not only point estimates of the VB parameters, but also confidence intervals around those values. Effectiveness of the proposed frameworks is demonstrated on a collection of electric water-heater loads, whose operation is driven by uncertain water usage profiles.","2378-5861","978-1-5386-8266-1","10.23919/ACC45564.2020.9147609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9147609","","Load modeling;Energy states;Uncertainty;Atmospheric modeling;Predictive models;Stochastic processes;Batteries","battery management systems;electric heating;learning (artificial intelligence);load regulation;neural nets;power engineering computing;probability;stochastic processes;thermostats","probability distribution;first order dynamics;virtual energy state;deep learning algorithm;variational autoencoder;stochastic virtual battery modeling;uncertain water usage profiles;electric water-heater loads;VB model parameters;stochastic VB models;deterministic VB models;equipment models;energy capacities;self-dissipation rate;electric water-heaters;residential air-conditioners;thermostatic loads;aggregated predictive flexibility;end-user preferences;grid services;uncertain electrical loads","","2","","32","","27 Jul 2020","","","IEEE","IEEE Conferences"
"Reverse Variational Autoencoder for Visual Attribute Manipulation and Anomaly Detection","L. Gauerhof; N. Gu","Corporate Research, Robert Bosch GmbH; Corporate Research, Robert Bosch GmbH","2020 IEEE Winter Conference on Applications of Computer Vision (WACV)","14 May 2020","2020","","","2103","2112","In this paper, we introduce the `Reverse Variational Autoencoder"" (Reverse-VAE) which is a generative network. On the one hand, visual attributes can be manipulated and combined while generating images. On the other hand, anomalies, meaning deviations from the data space used for training, can be detected. During training the generator network maps samples from stochastic latent vectors to the data space. Meanwhile the encoder network takes these generated images to reconstruct the latent vector. The generator and discriminator are trained adversarially. The discriminator is trained to distinguish between real and generated data. Overall, our model tries to match the joint latent/data-space distribution of the generator and the latent/data-space joint distribution of the encoder by minimizing their Kullback-Leibler divergence. Desired visual attributes of CelebA images are successfully manipulated. The performance of anomaly detection is competitive with state-of-the-art on MNIST.","2642-9381","978-1-7281-6553-0","10.1109/WACV45572.2020.9093319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9093319","","Generators;Image reconstruction;Training;Gallium nitride;Data models;Visualization;Image generation","estimation theory;image processing;learning (artificial intelligence);neural nets;stochastic processes","visual attribute manipulation;anomaly detection;generative network;data space;generator network maps samples;stochastic latent vectors;encoder network;latent vector;desired visual attributes;CelebA images;reverse-VAE;reverse variational autoencoder;MNIST;latent-data-space joint distribution;Kullback-Leibler divergence","","2","1","37","","14 May 2020","","","IEEE","IEEE Conferences"
"Soft-IntroVAE: Analyzing and Improving the Introspective Variational Autoencoder","T. Daniel; A. Tamar","Department of Electrical Engineering, Technion, Haifa, Israel; Department of Electrical Engineering, Technion, Haifa, Israel","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","2 Nov 2021","2021","","","4389","4398","The recently introduced introspective variational autoencoder (IntroVAE) exhibits outstanding image generations, and allows for amortized inference using an image encoder. The main idea in IntroVAE is to train a VAE adversarially, using the VAE encoder to discriminate between generated and real data samples. However, the original IntroVAE loss function relied on a particular hinge-loss formulation that is very hard to stabilize in practice, and its theoretical convergence analysis ignored important terms in the loss. In this work, we take a step towards better under-standing of the IntroVAE model, its practical implementation, and its applications. We propose the Soft-IntroVAE, a modified IntroVAE that replaces the hinge-loss terms with a smooth exponential loss on generated samples. This change significantly improves training stability, and also enables theoretical analysis of the complete algorithm. Interestingly, we show that the IntroVAE converges to a distribution that minimizes a sum of KL distance from the data distribution and an entropy term. We discuss the implications of this result, and demonstrate that it induces competitive image generation and reconstruction. Finally, we describe an application of Soft-IntroVAE to unsupervised image translation, and demonstrate compelling results. Code and additional information is available on the project website -taldatech.github.io/soft-intro-vae-web.","2575-7075","978-1-6654-4509-2","10.1109/CVPR46437.2021.00437","Israel Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9577895","","Training;Computer vision;Codes;Image synthesis;Computational modeling;Stability analysis;Entropy","entropy;image coding;unsupervised learning","unsupervised image translation;Soft-IntroVAE;introspective variational autoencoder;image encoder;VAE encoder;theoretical convergence analysis;hinge-loss terms;smooth exponential loss;training stability;competitive image generation;hinge-loss formulation","","2","","58","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Compressing Uniform Test Suites Using Variational Autoencoders","A. Reichstaller; A. Knapp","Institute for Software & Systems Engineering, University of Augsburg, Germany; Institute for Software & Systems Engineering, University of Augsburg, Germany","2017 IEEE International Conference on Software Quality, Reliability and Security Companion (QRS-C)","10 Aug 2017","2017","","","435","440","Uniform test suites consist of test cases exclusively differing in test inputs - not in test goals. Intended to gain confidence that a given invariant holds, these inputs trigger particular behavior of the system under test. Equipped with a simulation of the system under test we are able to cheaply explore this behavior virtually. When changing over to reality, testing the system within its real context, we are, however, often forced to limit the number of test inputs.We consider the task of compressing such uniform test suites. Similar to the task of minimizing classical test suites, this activity aims at finding a small number of representatives out of many test cases that are composed in the suite. In contrast, for uniform test suites we only have to take test inputs into account. As we know the uniform test goal, i.e., validating the invariants, we are able to automatically derive even new test cases within the compression. This work reports on first experiments with using variational autoencoders for this task. We show that generating test cases by utilizing these neural models might provide the tester with completely new insights while still performing well w.r.t. a presented compression coverage goal.","","978-1-5386-2072-4","10.1109/QRS-C.2017.128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8004355","Software Testing;Test Suite Minimization;Distance","Testing;Robots;Minimization;Vacuum systems;Training;Image reconstruction;Modeling","automatic testing","uniform test suites compression;variational autoencoders;system under test;neural models;compression coverage goal","","2","","20","","10 Aug 2017","","","IEEE","IEEE Conferences"
"Discriminative Feature Extraction Based on Sequential Variational Autoencoder for Speaker Recognition","T. Yoshimura; N. Koike; K. Hashimoto; K. Oura; Y. Nankaku; K. Tokuda","Nagoya Institute of Technology, Nagoya, Japan; Nagoya Institute of Technology, Nagoya, Japan; Nagoya Institute of Technology, Nagoya, Japan; Nagoya Institute of Technology, Nagoya, Japan; Nagoya Institute of Technology, Nagoya, Japan; Nagoya Institute of Technology, Nagoya, Japan","2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","7 Mar 2019","2018","","","1742","1746","This paper presents an extended version of the variational autoencoder (VAE) for sequence modeling. In contrast to the original VAE, the proposed model can directly handle variable-length observation sequences. Furthermore, the discriminative model and the generative model are simultaneously learned in a unified framework. The network architecture of the proposed model is inspired by the i-vector/PLDA framework, whose effectiveness has been proven in sequence modeling tasks such as speaker recognition. Experimental results on the TIMIT database show that the proposed model outperforms the traditional i-vector/PLDA system.","2640-0103","978-9-8814-7685-2","10.23919/APSIPA.2018.8659722","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8659722","","Standards;Feature extraction;Network architecture;Neural networks;Speaker recognition;Analytical models;Decoding","feature extraction;learning (artificial intelligence);speaker recognition;vectors","discriminative feature extraction;sequential variational autoencoder;speaker recognition;variable-length observation sequences;discriminative model;generative model;network architecture;i-vector/PLDA framework;sequence modeling tasks;i-vector/PLDA system;VAE","","2","","29","","7 Mar 2019","","","IEEE","IEEE Conferences"
"Fault Detection With LSTM-Based Variational Autoencoder for Maritime Components","P. Han; A. L. Ellefsen; G. Li; F. T. Holmeset; H. Zhang","Department of Ocean Operations and Civil Engineering, Norwegian University of Science and Technology (NTNU), Aalesund, Norway; Department of Ocean Operations and Civil Engineering, Norwegian University of Science and Technology (NTNU), Aalesund, Norway; Department of Ocean Operations and Civil Engineering, Norwegian University of Science and Technology (NTNU), Aalesund, Norway; Department of Ocean Operations and Civil Engineering, Norwegian University of Science and Technology (NTNU), Aalesund, Norway; Department of Ocean Operations and Civil Engineering, Norwegian University of Science and Technology (NTNU), Aalesund, Norway","IEEE Sensors Journal","1 Oct 2021","2021","21","19","21903","21912","Maintenance routines on ships today follow either a reactive maintenance (RM) or preventive maintenance (PvM) approach. RM can be regarded as post-failure repair, which might create large costs. PvM uses predetermined maintenance intervals, which often involves unnecessary maintenance. Recently, prognostics and health management (PHM) has emerged as a potential way to develop an ideal maintenance policy. PHM aims to provide optimal maintenance schedule through the use of sensor measurement for fault detection and fault prognostics, among which fault detection is the first and fundamental action. In this paper, a long-short term memory based variational autoencoder (LSTM-VAE) is proposed for fault detection of maritime components onboard. It is a semi-supervised approach that requires only fault-free data for training. Therefore, it is widely applicable in the maritime industry since operational data in normal conditions already exists. Real-world operation data collected from a diesel engine on the research vessel (RV) Gunnerus is used to validate the method. Results show that the LSTM-VAE can detect the fault accurately.","1558-1748","","10.1109/JSEN.2021.3105226","Research Council of Norway through the Knowledge-Building Project for Industry “Digital Twins For Vessel Life Cycle Service”(grant numbers:280703); Research Council of Norway through the IKTPLUSS Project “Remote Control Centre for Autonomous Ship Support”(grant numbers:309323); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9514856","Fault detection;anomaly detection;ship autonomy;condition monitoring;prognostic and health management","Fault detection;Sensors;Decoding;Anomaly detection;Prognostics and health management;Training;Recurrent neural networks","condition monitoring;fault diagnosis;maintenance engineering;preventive maintenance;railway safety;ships","post-failure repair;PvM;maintenance intervals;unnecessary maintenance;PHM;ideal maintenance policy;optimal maintenance schedule;fault detection;fault prognostics;LSTM-VAE;maritime components;fault-free data;LSTM-based variational autoencoder;maintenance routines;RM","","1","","31","IEEE","16 Aug 2021","","","IEEE","IEEE Journals"
"Denoising 3D Human Poses from Low-Resolution Video using Variational Autoencoder","C. Nakatsuka; S. Komorita","KDDI Research, Saitama, Japan; KDDI Research, Saitama, Japan","2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","16 Dec 2021","2021","","","4625","4630","We tackle the problem of refining and denoising a series of 3D human poses estimated from a low-resolution video. Low-resolution often causes the wrong pose estimation, e.g., left-right switching and the absence of keypoints. We propose to use the variational autoencoder (VAE) to remove these challenging noises. The VAE model utilizes time-series information and motion priors in denoising. From our experiments, the VAE model can reduce the pose estimation error (MPJPE) for poor-quality images by 24.37mm, from the original 105.53mm. This improves about 6.5 times over the traditional DCT approach. In addition, it removes jitters and generates smooth movements, which is helpful in recognition of human behaviors.","2153-0866","978-1-6654-1714-3","10.1109/IROS51168.2021.9636144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9636144","","Three-dimensional displays;Pose estimation;Noise reduction;Refining;Switches;Jitter;Noise measurement","image denoising;image resolution;jitter;neural nets;pose estimation;time series","low-resolution video;variational autoencoder;VAE model;time-series information;motion priors;pose estimation error;human behaviors recognition;denoising 3D human poses;MPJPE;poor-quality images;DCT approach","","1","","37","IEEE","16 Dec 2021","","","IEEE","IEEE Conferences"
"Anomaly Detection in Distributed Systems via Variational Autoencoders","Y. Qian; S. Ying; B. Wang","School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China","2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","14 Dec 2020","2020","","","2822","2829","Distributed systems have been widely used in the information technology industry. However, with the increasing scale and complexity of distributed systems, the efficiency and accuracy of manual anomaly detection in system logs have decreased. Therefore, there is a great demand for a highly accurate and efficient automatic anomaly detection method based on system log analysis to ensure the reliability and the stability of large-scale distributed systems. In this paper, we propose VeLog, an automatic anomaly detection method based on variational autoencoders (VAEs). In the offline training phase, VeLog learns the patterns of normal log sequences and then generates normal intervals. In the online detection phase, VeLog detects an anomaly by automatically evaluating whether the distance between the input vector and its estimated vector matches these normal intervals. We evaluate VeLog on log datasets collected from representative distributed systems. The experimental results demonstrate that VeLog can detect anomalies with high accuracy and good efficiency.","2577-1655","978-1-7281-8526-2","10.1109/SMC42975.2020.9283078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283078","Anomaly detection;deep learning;distributed systems;log data analysis","Training;Industries;Manuals;Stability analysis;Reliability;Information technology;Anomaly detection","distributed processing;DP industry;learning (artificial intelligence);neural nets;security of data;system monitoring;vectors","online detection phase;VeLog;representative distributed systems;variational autoencoders;information technology industry;system logs;anomaly detection;large-scale distributed systems;normal log sequences","","1","","33","","14 Dec 2020","","","IEEE","IEEE Conferences"
"Text-based Malicious Domain Names Detection Based on Variational Autoencoder And Supervised Learning","Y. Sun; N. S. T. Chong; H. Ochiai","Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Campus Computing Centre, United Nations University, Tokyo, Japan; Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan","2020 54th Annual Conference on Information Sciences and Systems (CISS)","7 May 2020","2020","","","1","5","With the rapid development of information technology, adaptation of an information system in industries and institutes has become more and more common. However, attacks like using zombie networks to access a host thus causing it to shut down are frequent in recent years. Domain names play a significant role in the connection with a server, considered as a key for detecting these attacks. In this paper, we propose a text-based method to convert domain names into numeric features, based on the term frequency and inverse document frequency (TF-IDF). Then we adopt the variational autoencoder (VAE) consisting of an encoder and a decoder, extracting hidden information from features. Moreover, through collapsing the Gaussian distribution of these features at the hidden layer to its mean, the distribution of domain names is visualized. After that, we adopt a supervised learning called Convolutional Neural Network (CNN) for the classification between the malicious and benign. We train the model using feature vectors from the VAE. At last, the scheme achieves a validation accuracy of 0.868 for the malicious domain names detection.","","978-1-7281-4085-8","10.1109/CISS48834.2020.1570601577","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9086229","malicious domain names detection;VAE;cybersecurity;machine learning","Support vector machines;Recurrent neural networks;Frequency-domain analysis;Supervised learning;Feature extraction;Frequency conversion;Convolutional neural networks","computer crime;convolutional neural nets;data visualisation;Gaussian distribution;information retrieval;information systems;supervised learning;text analysis","text-based malicious domain names detection;variational autoencoder;supervised learning;information technology;information system;zombie networks;term frequency and inverse document frequency;hidden information extraction;VAE;TF-IDF;Gaussian distribution;convolutional neural network;CNN;feature vectors;data visualization","","1","","15","","7 May 2020","","","IEEE","IEEE Conferences"
"Gated Variational AutoEncoders: Incorporating Weak Supervision to Encourage Disentanglement","M. J. Vowels; N. C. Camgoz; R. Bowden","University of Surrey: CVSSP, Guildford, Surrey, UK; University of Surrey: CVSSP, Guildford, Surrey, UK; University of Surrey: CVSSP, Guildford, Surrey, UK","2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)","18 Jan 2021","2020","","","125","132","Variational AutoEncoders (VAEs) provide a means to generate representational latent embeddings. Previous research has highlighted the benefits of achieving representations that are disentangled, particularly for downstream tasks. However, there is some debate about how to encourage disentanglement with VAEs, and evidence indicates that existing implementations do not achieve disentanglement consistently. The evaluation of how well a VAE's latent space has been disentangled is often evaluated against our subjective expectations of which attributes should be disentangled for a given problem. Therefore, by definition, we already have domain knowledge of what should be achieved and yet we use unsupervised approaches to achieve it. We propose a weakly-supervised approach that incorporates any available domain knowledge into the training process to form a Gated-VAE. The process involves partitioning the representational embedding and gating backpropagation. All partitions are utilised on the forward pass but gradients are backpropagated through different partitions according to selected image/target pairings. The approach can be used to modify existing VAE models such as beta-VAE, InfoVAE and DIP-VAE-II. Experiments demonstrate that using gated backpropagation, latent factors are represented in their intended partition. The approach is applied to images of faces for the purpose of disentangling head-pose from facial expression. Quantitative metrics show that using Gated-VAE improves average disentanglement, completeness and informativeness, as compared with un-gated implementations. Qualitative assessment of latent traversals demonstrate its disentanglement of head-pose from expression, even when only weak/noisy supervision is available.","","978-1-7281-3079-8","10.1109/FG47880.2020.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9320221","VAE;disentanglement;representation learning;generative models","Training;Logic gates;Measurement;Task analysis;Image reconstruction;Decoding;Faces","backpropagation;face recognition;feature selection;image denoising;image representation;neural nets;supervised learning;unsupervised learning","weak supervision;disentanglement;representational latent embeddings;unsupervised approach;weakly-supervised approach;Gated-VAE;representational embedding;gated backpropagation;gated variational autoencoders;VAE;image pairing selection;target pairing selection;face image","","1","","29","","18 Jan 2021","","","IEEE","IEEE Conferences"
"Unsupervised Anomaly Detection in Multivariate Time Series through Transformer-based Variational Autoencoder","H. Zhang; Y. Xia; T. Yan; G. Liu","Key Laboratory of Intelligent Control and Decision of Complex Systems, School of Automation, Beijing Institute of Technology, Beijing, P. R. China; Key Laboratory of Intelligent Control and Decision of Complex Systems, School of Automation, Beijing Institute of Technology, Beijing, P. R. China; Key Laboratory of Intelligent Control and Decision of Complex Systems, School of Automation, Beijing Institute of Technology, Beijing, P. R. China; Alibaba Group, Hangzhou, P. R. China","2021 33rd Chinese Control and Decision Conference (CCDC)","30 Nov 2021","2021","","","281","286","Modern industrial devices often use multiple sensors to detect the status of system, which produce a large amount of multivariate time series. Due to the complex temporal dependency of intra-channel and inter-correlations among different channels, few of proposed algorithms have addressed these challenges for anomaly detection in multivariate time series. Besides, previous work does not consider future dependency, which has been shown to be critical for sequential data modeling. In this paper, we develop an unsupervised anomaly detection algorithm TransAnomaly, which integrates Transformer, variational autoencoder (VAE) and nonlinear state space model. TransAnomaly not only reduces the computational complexity and allows for more parallelization but also provides explainable insights. To the best of our knowledge, it is the first model that combines VAE and Transformer for multivariate time series anomaly detection. Extensive experiments on several public real-world datasets show that TransAnomaly outperforms state-of-the-art baseline methods while training cost is reduced by nearly 80%.","1948-9447","978-1-6654-4089-9","10.1109/CCDC52312.2021.9601669","National Key Research and Development Program of China(grant numbers:2018YFB1003700); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9601669","Multivariate Time Series;Anomaly Detection;Transformer;Parallelization","Training;Costs;Computational modeling;Time series analysis;Transformers;Probabilistic logic;Sensor systems","data mining;security of data;time series;unsupervised learning","multivariate time series;unsupervised anomaly detection algorithm;nonlinear state space model;transformer-based variational autoencoder;TransAnomaly algorithm;VAE","","1","","18","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Variational Autoencoder-Based Metamodeling for Multi-Objective Topology Optimization of Electrical Machines","V. Parekh; D. Flore; S. Schöps","Engineering, Acquisition, Building Set (PS-EM/EAB), Robert Bosch GmbH, Stuttgart, Germany; Engineering, Acquisition, Building Set (PS-EM/EAB), Robert Bosch GmbH, Stuttgart, Germany; Computational Electromagnetics Group, Technical University of Darmstadt, Darmstadt, Germany","IEEE Transactions on Magnetics","26 Aug 2022","2022","58","9","1","4","Conventional magneto-static finite element (FE) analysis of electrical machine design is time-consuming and computationally expensive. Since each machine topology has a distinct set of parameters, design optimization is commonly performed independently. This article presents a novel method for predicting key performance indicators (KPIs) of differently parameterized electrical machine topologies at the same time by mapping a high-dimensional integrated design parameters in a lower-dimensional latent space using a variational autoencoder (VAE). After training, via a latent space, the decoder and multi-layer neural network will function as meta-models for sampling new designs and predicting associated KPIs, respectively. This enables parameter-based concurrent multi-topology optimization.","1941-0069","","10.1109/TMAG.2022.3163972","Robert Bosch GmbH, Stuttgart, Germany, through TU Darmstadt; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745548","Design optimization;electrical machine;finite element (FE) analysis;multi-layer neural network","Topology;Training;Decoding;Optimization;Iron;Rotors;Stators","design engineering;electric machines;finite element analysis;neural nets;optimisation;power engineering computing;topology","electrical machine design;machine topology;design optimization;key performance indicators;variational autoencoder-based metamodeling;multiobjective topology optimization;conventional magneto-static finite element analysis;FE analysis;KPIs;low-dimensional latent space;VAE;multilayer neural network","","1","","9","IEEE","31 Mar 2022","","","IEEE","IEEE Journals"
"Improving Data Generalization With Variational Autoencoders for Network Traffic Anomaly Detection","M. Monshizadeh; V. Khatri; M. Gamdou; R. Kantola; Z. Yan","Department of Comnet, Aalto University, Espoo, Finland; Nokia Bell Labs, Espoo, Finland; Centralesupélec Engineering School, Paris-Saclay University, Gif-sur-Yvette, France; Department of Comnet, Aalto University, Espoo, Finland; The State Key Lab of Integrated Services Network, Xidian University, Xi’an, China","IEEE Access","16 Apr 2021","2021","9","","56893","56907","Deep generative models have increasingly become popular in different domains such as image processing, though, they hardly appear in the cybersecurity arena. While the main application of these models is dimensionality reduction, marginally they have been utilized for overcoming challenges such as data generalization and overfitting issues inherited from feature selection methods. To solve the mentioned challenges, we propose a combined architecture comprising a Conditional Variational AutoEncoder (CVAE) and a Random Forest (RF) classifier to automatically learn similarity among input features, provide data distribution in order to extract discriminative features from original features, and finally classify various types of attacks. CVAE introduces the labels of traffic packets into a latent space in order to better learn the changes of input samples and distinguish the data characteristics of each class. It avoids the confusion between classes while learning the whole data distribution. Compared with feature selection mechanisms such as Support Vector Machine Online (SVMo) by considering various evaluation metrics, the proposed architecture demonstrates considerable improvement in terms of performance. To verify the versatility of the proposed architecture, two publicly available datasets have been used in experiments.","2169-3536","","10.1109/ACCESS.2021.3072126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9399440","Anomaly detection;data mining;feature selection;machine learning;security","Feature extraction;Random forests;Classification algorithms;Telecommunication traffic;Anomaly detection;Measurement;Vegetation","feature extraction;learning (artificial intelligence);pattern classification;random forests;security of data;support vector machines;telecommunication traffic","improving data generalization;network traffic anomaly detection;deep generative models;image processing;cybersecurity arena;feature selection methods;combined architecture;conditional variational autoencoder;CVAE;random forest classifier;data distribution;discriminative features;traffic packets;latent space;data characteristics;feature selection mechanisms;support vector machine online;data generalization","","1","","30","CCBY","9 Apr 2021","","","IEEE","IEEE Journals"
"Facial Attribute Editing by Latent Space Adversarial Variational Autoencoders","D. Li; M. Zhang; W. Chen; G. Feng","Guangdong Province Key Laboratory, Sun Yat-sen University, Guangzhou, China; Guangdong Province Key Laboratory, Sun Yat-sen University, Guangzhou, China; Guangdong Province Key Laboratory, Sun Yat-sen University, Guangzhou, China; Guangdong Province Key Laboratory, Sun Yat-sen University, Guangzhou, China","2018 24th International Conference on Pattern Recognition (ICPR)","29 Nov 2018","2018","","","1337","1342","This work focuses on the problem of editing facial images by manipulating specified attributes of interest. To learn latent representations disentangled with respect to specified face attribute, a novel attribute-disentangled generative model is proposed by combining variational autoencoders (VAEs) and generative adversarial networks (GANs). In the proposed model, only two deep mappings are included: an encoder and a decoder, similarly as the counterparts in the context of VAEs. Latent space mapped by the encoder is split into two parts: style space and attribute space. The former represents attribute-irrelevant factors, such as identity, position, illumination and background, etc. The latter represents the attributes, such as hair color, gender, with or without glasses, etc, of which each dimension represents one single attribute. By regarding constraints on the output of the encoder as discriminative objectives, the encoder can act not only as a discriminator that is expected to discriminate a sample is a real or a generated one, but also as an attribute classifier that can discriminate whether a sample has the specified attributes or not. Combining reconstruction and Kullback-Leibler (KL) divergence regularization losses like in VAEs, the adversarial training loss defined for the style and the attribute in the latent space is introduced, which drives the proposed model to generate images whose distribution are close to the real data distribution in the latent space. Finally, the model was evaluated on the CelebA dataset and experimental results showed its effectiveness in disentangling face attributes and generating high-quality face images.","1051-4651","978-1-5386-3788-3","10.1109/ICPR.2018.8545633","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8545633","","Training;Gallium nitride;Decoding;Image reconstruction;Face;Facial features;Generative adversarial networks","face recognition;image classification;image coding;image colour analysis;image reconstruction;image representation;learning (artificial intelligence)","facial attribute editing;latent space adversarial variational autoencoders;generative adversarial networks;deep mappings;attribute classifier;adversarial training loss;high-quality face images;VAE;attribute-disentangled generative model;GAN;Kullback-Leibler divergence regularization losses;KL divergence regularization losses;CelebA dataset","","1","","37","","29 Nov 2018","","","IEEE","IEEE Conferences"
"Variational Autoencoders for Reliability Optimization in Multi-Access Edge Computing Networks","A. Ahmadi; O. Semiari; M. Bennis; M. Debbah","Department of Electrical and Computer Engineering, University of Colorado, Colorado Springs, CO, USA; Department of Electrical and Computer Engineering, University of Colorado, Colorado Springs, CO, USA; Department of Communications Engineering, University of Oulu, Oulu, Finland; Technology Innovation Institute, Mohamed Bin Zayed University of Artificial Intelligence, Masdar City, Abu Dhabi, United Arab Emirates","2022 IEEE Wireless Communications and Networking Conference (WCNC)","16 May 2022","2022","","","752","757","Multi-access edge computing (MEC) is viewed as an integral part of future wireless networks to support new applications with stringent service reliability and latency requirements. However, guaranteeing ultra-reliable and low-latency MEC (URLL MEC) is very challenging due to uncertainties of wireless links, limited communications and computing resources, as well as dynamic network traffic. Enabling URLL MEC man-dates taking into account the statistics of the end-to-end (E2E) latency and reliability across the wireless and edge computing systems. In this paper, a novel framework is proposed to optimize the reliability of MEC networks by considering the distribution of E2E service delay, encompassing over-the-air transmission and edge computing latency. The proposed framework builds on correlated variational autoencoders (VAEs) to estimate the full distribution of the E2E service delay. Using this result, a new optimization problem based on risk theory is formulated to maximize the network reliability by minimizing the Conditional Value at Risk (CVaR) as a risk measure of the E2E service delay. To solve this problem, a new algorithm is developed to efficiently allocate users’ processing tasks to edge computing servers across the MEC network, while considering the statistics of the E2E service delay learned by VAEs. The simulation results show that the proposed scheme outperforms several baselines that do not account for the risk analyses or statistics of the E2E service delay.","1558-2612","978-1-6654-4266-4","10.1109/WCNC51071.2022.9771710","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9771710","","Multi-access edge computing;Uncertainty;Simulation;Wireless networks;Reliability theory;Delays;Servers","computer network reliability;learning (artificial intelligence);multi-access systems;neural nets;optimisation;quality of service;radio links;radio networks;resource allocation;risk analysis;statistical analysis;telecommunication traffic","reliability optimization;multiaccess edge computing networks;future wireless networks;stringent service reliability;wireless links;computing resources;dynamic network traffic;end-to-end latency;wireless edge computing systems;MEC network;E2E service delay;over-the-air transmission;correlated variational autoencoders;network reliability;computing servers;URLL MEC;latency requirements;E2E latency;E2E service delay distribution;edge computing latency;optimization problem;risk theory;CVaR;risk measure;conditional value at risk minimization;user processing task allocation;VAEs;risk analysis","","1","","16","IEEE","16 May 2022","","","IEEE","IEEE Conferences"
"Extended Reproduction of Demonstration Motion Using Variational Autoencoder","D. Takahashi; S. Katsura","Department of System Design Engineering, Keio University, Japan; Department of System Design Engineering, Keio University, Japan","2018 IEEE 27th International Symposium on Industrial Electronics (ISIE)","13 Aug 2018","2018","","","1057","1062","Learning from demonstration (LfD) is an effective method for robot motion learning because hand-coded cost function is not necessary. However, the number of times demonstrations can be performed is limited and performing a demonstration in every environmental condition is difficult. Therefore, an algorithm for generating a motion data not obtained by demonstrations is required. In order to deal with this problem, this research generates motion latent space by abstracting the demonstration data. Motion latent space is a space expressing the demonstration motion in lower dimensions. Also the demonstration data can be extended by decoding the points in the latent space. These things are realized by applying variational autoencoder (VAE) used in the field of image generation to time-series data. Demonstrations of the reaching task are conducted, and the paper shows that the manipulator can reach the object even when the object is located at a different position from demonstrations.","2163-5145","978-1-5386-3705-0","10.1109/ISIE.2018.8433683","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8433683","","Neural networks;Manipulators;Decoding;Image generation;Education;IEEE Constitution","image motion analysis;learning (artificial intelligence);manipulators;motion control;time series","demonstration data;variational autoencoder;time-series data;demonstration motion;robot motion learning;times demonstrations;motion latent space;learning from demonstration;motion data generation;VAE;image generation","","1","","19","","13 Aug 2018","","","IEEE","IEEE Conferences"
"Improving the Responses Diversity of Persona-based Neural Conversation System: A Conditional Variational Autoencoders-based Approach","T. Shi; W. Yu; H. Yang; Y. Song","School of Automation, Chongqing University, Chongqing, China; School of Automation, Chongqing University, Chongqing, China; School of Automation, Chongqing University, Chongqing, China; School of Automation, Chongqing University, Chongqing, China","2020 Chinese Automation Congress (CAC)","29 Jan 2021","2020","","","6317","6320","Given a conversational context based on persona information to a chatbot, how to generate diverse and relevant responses? Many existing works could effectively capture useful information from external knowledge, but they rarely consider the diversity of responses. In this paper, we consider both the persona information and the responses' diversity, upon which we develop a Seq2Seq-based model with hierarchical RNN context encoder, Conditional Variational Autoencoder (CVAE) and pointer generator. Hierarchical RNN allows those context utterances to be used more effectively. CVAE is used to capture the relationship between question and several appropriate answers. With pointer generator, an output token in a response could either be generated or copied from persona facts. The model is trained and tested on Persona-Chat dataset. Finally, automatic evaluation shows that compared with the baseline model, this developed model is able to better integrate the persona information and generate more diverse responses.","2688-0938","978-1-7281-7687-1","10.1109/CAC51589.2020.9326580","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9326580","Seq2Seq;CVAE;Hierarchical RNN;Pointer-generator;Diversity;Persona-based","Decoding;Context modeling;Generators;Training;Neural networks;History;Automation","encoding;human computer interaction;recurrent neural nets","responses diversity;conversational context;persona information;Seq2Seq-based model;hierarchical RNN context encoder;CVAE;pointer generator;Persona-Chat dataset;persona-based neural conversation system;conditional variational autoencoders-based approach","","1","","17","","29 Jan 2021","","","IEEE","IEEE Conferences"
"Multi-digit image synthesis using recurrent conditional variational autoencoder","Haoze Sun; Weidi Xu; Chao Deng; Ying Tan","Department of Machine Intelligence, Peking University, Beijing, China; Department of Machine Intelligence, Peking University, Beijing, China; Department of Machine Intelligence, Peking University, Beijing, China; Department of Machine Intelligence, Peking University, Beijing, China","2016 International Joint Conference on Neural Networks (IJCNN)","3 Nov 2016","2016","","","375","380","In the field of deep neural networks, several generative methods have been proposed to address the challenges from generative and discriminative tasks, e.g., natural language process, image caption and image generation. In this paper, a conditional recurrent variational autoencoder is proposed for multi-digit image synthesis. This model is capable of generating multi-digit images from the given number sequences and retaining the generalisation ability to recover different types of background. Our method is evaluated on SVHN dataset and the experimental results show it succeeds to generate multi-digit images with various styles according to the given sequential inputs. The generated images can also be easily identified by both human beings and convolutional neural networks for digit classification.","2161-4407","978-1-5090-0620-5","10.1109/IJCNN.2016.7727223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727223","","Mathematical model;Image generation;Computational modeling;Neural networks;Decoding;Data models;Standards","generalisation (artificial intelligence);image processing;neural nets","multidigit image synthesis;recurrent conditional variational autoencoder;deep neural networks;generative method;generative task;discriminative task;multidigit image generation;number sequence;generalisation ability;background recovery;SVHN dataset","","1","","22","","3 Nov 2016","","","IEEE","IEEE Conferences"
"Variational Autoencoders with Euclidean and Hyperbolic Latent Spaces for Population Genetics","I. Bogdanov; V. Shchur","International Laboratory of Statistical and Computational Genomics, HSE University, Moscow, Russia; International Laboratory of Statistical and Computational Genomics, HSE University, Moscow, Russia","2021 XVII International Symposium "Problems of Redundancy in Information and Control Systems" (REDUNDANCY)","11 Nov 2021","2021","","","91","94","Population structure inference is one of the main problems of population genetics. Genetic variation might give a clue on relations between populations as well as to identify population components in a single individual. Currently, principle component analysis (PCA) is one of standard tools for genetic data structure visualisation. In this work we present the application of variational autoencoders (VAE) with Euclidean and hyperbolic latent spaces and compare these approaches with PCA. In contrast to the PCA, VAE allows to find nonlinear dependencies in the data, and hyperbolic geometry is better suited for data with hierarchical structure. We show that VAEs have more power to separate population components in some complicated population scenarios.","2694-5215","978-1-6654-3308-2","10.1109/REDUNDANCY52534.2021.9606448","Russian Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9606448","","Training;Geometry;Sociology;Redundancy;Data visualization;Tools;Genetics","biology computing;data structures;data visualisation;genetics;geometry;hyperbolic equations;neural nets;principal component analysis","variational autoencoders;Euclidean;hyperbolic latent spaces;population genetics;population structure inference;genetic variation;principle component analysis;PCA;genetic data structure visualisation;VAE;hyperbolic geometry;hierarchical structure;population components;nonlinear dependencies","","","","15","IEEE","11 Nov 2021","","","IEEE","IEEE Conferences"
"Learning the Features ignored by Classification Models using Staged Modeling Variational Autoencoder","Z. Ruan; J. Zhang","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","8","Classification networks usually only save the specified factor associated with labels. We propose a probabilistic graphical model (PGM) to learn the features ignored by arbitrary classification networks using staged modeling. To implement the staged PGM, we introduce Staged Modeling Variational Autoencoder (SMVAE), in which the first stage can apply arbitrary classification models to encode the specified factor, then optimizing the Evidence Lower Bound (ELBO) given optimal specified factor to compress the features ignored at the first stage into the unspecified factor. Besides, SMVAE can learn the disentangled unspecified factors unsupervised by further decomposing the ELBO given the optimal specified factor. At last, we introduce Adain based on Infusion Training in SMVAE to learn more details to reconstruct data. Detailed experiments are given to evaluate the disentanglement and performance of SMVAE.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533812","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533812","","Training;Graphical models;Neural networks;Probabilistic logic","data compression;neural nets;optimisation;pattern classification;unsupervised learning","Staged Modeling Variational Autoencoder;probabilistic graphical model;arbitrary classification networks;staged PGM;SMVAE;arbitrary classification models;optimal specified factor;unspecified factor;disentangled unspecified factors;feature learning;unsupervised learning;ence lower bound optimization;ELBO;data reconstruction;feature compression;Adain;infusion training","","","","25","","20 Sep 2021","","","IEEE","IEEE Conferences"
"Variational Autoencoders for Polyphonic Music Interpolation","P. L. Diéguez; V. -W. Soo","Institute of Information Systems and Applications, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan","2020 International Conference on Technologies and Applications of Artificial Intelligence (TAAI)","23 Mar 2021","2020","","","56","61","This paper aims to use machine learning techniques to solve the novel problem of music interpolation composition. Two models based on Variational Autoencoders (VAEs) are proposed to generate a suitable polyphonic harmonic bridge between two given songs, smoothly changing the pitches and dynamics of the interpolation. The interpolations generated by the first model surpass a Random data baseline and a bidirectional LSTM approach and its performance is comparable to the current state-of-the-art. The novel architecture of the second model outperforms the state-of-the-art interpolation approaches in terms of reconstruction loss by using an additional neural network for direct estimation of the interpolation encoded vector. Furthermore, the Hsinchu Interpolation MIDI Dataset was created, making both models proposed in this paper more efficient than previous approaches in the literature in terms of computational and time requirements during training. Finally, a subjective evaluation was done in order to ensure the validity of the metric-based results.","2376-6824","978-1-6654-0380-1","10.1109/TAAI51410.2020.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9382444","Polyphonic Music Composition;VAE;Music Interpolation","Training;Interpolation;Computational modeling;Music;Machine learning;Data models;Computational efficiency","interpolation;learning (artificial intelligence);music;recurrent neural nets","polyphonic music interpolation;music interpolation composition;songs;pitches;bidirectional LSTM approach;Hsinchu Interpolation MIDI Dataset;random data baseline;polyphonic harmonic bridge;variational autoencoders;machine learning;subjective evaluation","","","","15","","23 Mar 2021","","","IEEE","IEEE Conferences"
"Mind the gap: functional network connectivity interpolation between schizophrenia patients and controls using a variational autoencoder","X. Li; E. Geenjaar; Z. Fu; S. Plis; V. Calhoun","Tri - institutional Center for Translational Research in N euroimaging and Data Science, Georgia State University, Georgia Institute of Technology, Emory University, Atlanta, GA, USA; Tri - institutional Center for Translational Research in N euroimaging and Data Science, Georgia State University, Georgia Institute of Technology, Emory University, Atlanta, GA, USA; Tri - institutional Center for Translational Research in N euroimaging and Data Science, Georgia State University, Georgia Institute of Technology, Emory University, Atlanta, GA, USA; The Department of Computer Science, Georgia State University, Atlanta, GA, USA; Tri - institutional Center for Translational Research in N euroimaging and Data Science, Georgia State University, Georgia Institute of Technology, Emory University, Atlanta, GA, USA","2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","8 Sep 2022","2022","","","1477","1480","Mental disorders such as schizophrenia have been challenging to characterize due in part to their heterogeneous presentation in individuals. Most studies have focused on identifying groups differences and have typically ignored the heterogeneous patterns within groups. Here we propose a novel approach based on a variational autoencoder (VAE) to interpolate static functional network connectivity (sFNC) across individuals, with group-specific patterns between schizophrenia patients and controls captured simultaneously. We then visualize the original sFNC in a 2D grid according to the samples in the VAE latent space. We observe a high correspondence between the generated and the original sFNC. The proposed framework facilitates data visualization and can potentially be applied to predict the stage that a subject falls within a disorder continuum as well as characterize individual heterogeneity within and between groups.","2694-0604","978-1-7281-2782-8","10.1109/EMBC48229.2022.9871803","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9871803","","Interpolation;Mental disorders;Data visualization;Aerospace electronics;Biology","biomedical MRI;brain;data visualisation;diseases;interpolation;learning (artificial intelligence);medical disorders;medical image processing;neurophysiology","functional network connectivity interpolation;schizophrenia patients;variational autoencoder;mental disorders;heterogeneous presentation;identifying groups differences;heterogeneous patterns;static functional network connectivity;group-specific patterns;original sFNC;VAE latent space;data visualization;disorder continuum;characterize individual heterogeneity","Computer Systems;Data Visualization;Humans;Schizophrenia","","","16","IEEE","8 Sep 2022","","","IEEE","IEEE Conferences"
"Adversarial Defense Through High Frequency Loss Variational Autoencoder Decoder and Bayesian Update With Collective Voting","Z. He; M. Singhal","Merced Electrical Engineering & Computer Science, University of California, Merced, CA; Merced Electrical Engineering & Computer Science, University of California, Merced, CA","2021 17th International Conference on Machine Vision and Applications (MVA)","19 Aug 2021","2021","","","1","7","In recent years, Deep Neural Network (DNN) approaches for computer vision tasks have shown tremendous promise and potential. However, they are vulnerable to data that are carefully crafted with adversarial attacks, which can cause mis-prediction and raise security risk to real-world deep learning systems. To make the DNN-based approaches more robust, we propose a defense strategy based on High Frequency Loss Variational Autoencoder Decoder (VAE) and randomization among multiple post-VAE classifiers' predictions. The main contributions of the proposed defense framework are: 1) a new adversarial defense framework that features randomization process to effectively mitigate adversarial attacks; 2) reconstruction of high-quality images from adversarial samples with the VAE enhanced with spatial frequency loss; 3) use of a Bayesian process to jointly combine the collective voting results and the targeted classifier's prediction for final decision. We evaluate our approach and compare it with existing approaches on CIFAR10 and Fashion-MNIST data sets. The experimental study shows that the proposed method outperforms existing methods.","","978-4-901122-20-7","10.23919/MVA51890.2021.9511384","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9511384","","Deep learning;Computer vision;Perturbation methods;Machine vision;Bayes methods;Decoding;High frequency","Bayes methods;computer vision;deep learning (artificial intelligence);image reconstruction;neural nets;security of data","real-world deep learning systems;DNN-based approaches;defense strategy;multiple post-VAE classifiers;adversarial defense framework;randomization process;adversarial attacks;high-quality images;adversarial samples;spatial frequency loss;Bayesian process;collective voting results;targeted classifier;High Frequency Loss Variational Autoencoder Decoder;Bayesian update;Deep Neural Network;computer vision tasks;mis-prediction;security risk","","","","28","","19 Aug 2021","","","IEEE","IEEE Conferences"
"A Semi-supervised Approach for Early Identifying the Abnormal Carotid Arteries Using a Modified Variational Autoencoder","X. Huang; G. Cui; D. Wu; Y. Li","Control Science and Engineering Shandong University, Jinan, China; Shenzhen Institues of Advanced Technology Chinese Academy of Sciences, Shenzhen, China; Shenzhen Institues of Advanced Technology Chinese Academy of Sciences, Shenzhen, China; Shenzhen Institues of Advanced Technology Chinese Academy of Sciences, Shenzhen, China","2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","13 Jan 2021","2020","","","595","600","Carotid artery lesions could be the pathology of subclinical atherosclerosis and hence lead to the onset of stroke. Early detection of abnormal carotid artery might help to better identify individuals susceptible to stroke. Considering the carotid artery ultrasonography is time-consuming and costly, the object of this paper is to establish a model to detect the status of carotid artery for preliminary screening of stroke, according to the simple physiological examination and survey information. However, most of the previous studies were based on the linear regression or the traditional machine learning methods, those suffer from two limitations. One is the limited labeled samples, and the other one is the missing data. To address these issues, we firstly propose a semi-supervised approach based on a modified variational autoencoder (VAE) to identify the abnormal carotid arteries. In this paper, a mixture of mean and K th nearest neighbours (MKNN) and a modified VAE were used for missing data imputation. The experimental results demonstrate that the proposed method can not only handle the missing values, but also outperform four widely used supervised approaches. Therefore, we can conclude that this semi-supervised model is a promising way to identify the abnormal carotid arteries.","","978-1-7281-6215-7","10.1109/BIBM49941.2020.9313193","National Natural Science Foundation of China; Natural Science Foundation of Guangdong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9313193","stroke;preliminary screening;MKNN;VAE;supervised and semi-supervised","Carotid arteries;Support vector machines;Machine learning;Radio frequency;Lesions;Predictive models;Data models","biomedical ultrasonics;blood vessels;cardiovascular system;diseases;medical computing;regression analysis;supervised learning","semisupervised approach;modified variational autoencoder;carotid artery lesions;stroke;carotid artery ultrasonography;physiological examination;linear regression;machine learning;modified VAE;mean and K th nearest neighbours;MKNN","","","","14","","13 Jan 2021","","","IEEE","IEEE Conferences"
"Synthetic Generation of Cardiac MR Images Combining Convolutional Variational Autoencoders and Style Transfer","J. M. Jaén-Lorites; M. Pérez-Pelegrí; V. Laparra; M. P. López-Lereu; J. V. Monmeneu; A. M. Maceira; D. Moratal","Center for Biomaterials and Tissue Engineering, Universitat Politècnica de València, Valencia, Spain; Center for Biomaterials and Tissue Engineering, Universitat Politècnica de València, Valencia, Spain; Universitat de València, Valencia, Spain; ASCIRES Biomedical Group, Valencia, Spain; ASCIRES Biomedical Group, Valencia, Spain; ASCIRES Biomedical Group, Valencia, Spain; Center for Biomaterials and Tissue Engineering, Universitat Politècnica de València, Valencia, Spain","2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","8 Sep 2022","2022","","","2084","2087","The number of studies in the medical field that uses machine learning and deep learning techniques has been increasing in the last years. However, these techniques require a huge amount of data that can be difficult and expensive to obtain. This specially happens with cardiac magnetic resonance (MR) images. One solution to the problem is raise the dataset size by generating synthetic data. Convolutional Variational Autoencoder (CVAe) is a deep learning technique which allows to generate synthetic images, but sometimes the synthetic images can be slightly blurred. We propose the combination of the CVAe technique combined with Style Transfer technique to generate synthetic realistic cardiac MR images. Clinical Relevance-The current work presents a tool to increase in a simple easy and fast way the cardiac magnetic resonance images dataset with which perform machine learning and deep learning studies","2694-0604","978-1-7281-2782-8","10.1109/EMBC48229.2022.9871135","Conselleria d'Innovació, Universitats, Ciència i Societat Digital(grant numbers:AEST/2020/029,AEST/2021/050); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9871135","","Deep learning;Magnetic resonance;Biology;Biomedical imaging","biomedical MRI;cardiology;learning (artificial intelligence);medical image processing","cardiac magnetic resonance images dataset;machine learning;synthetic generation;medical field;deep learning technique;synthetic data;Convolutional Variational Autoencoder;synthetic images;CVAe technique;Style Transfer technique;synthetic realistic cardiac MR images","Algorithms;Heart;Machine Learning;Magnetic Resonance Imaging","","","12","IEEE","8 Sep 2022","","","IEEE","IEEE Conferences"
"Anomaly Detection in Time Series with Robust Variational Quasi-Recurrent Autoencoders","T. Kieu; B. Yang; C. Guo; R. -G. Cirstea; Y. Zhao; Y. Song; C. S. Jensen","Aalborg University, Denmark; Aalborg University, Denmark; Aalborg University, Denmark; Aalborg University, Denmark; Aalborg University, Denmark; Microsoft Research, USA; Aalborg University, Denmark","2022 IEEE 38th International Conference on Data Engineering (ICDE)","2 Aug 2022","2022","","","1342","1354","We propose variational quasi-recurrent autoencoders (VQRAEs) to enable robust and efficient anomaly detection in time series in unsupervised settings. The proposed VQRAEs employs a judiciously designed objective function based on robust divergences, including a, ß, and, -divergence, making it possible to separate anomalies from normal data without the reliance on anomaly labels, thus achieving robustness and fully unsupervised training. To better capture temporal dependencies in time series data, VQRAEs are built upon quasi-recurrent neural networks, which employ convolution and gating mechanisms to avoid the inefficient recursive computations used by classic recurrent neural networks. Further, VQRAEs can be extended to bi-directional Bi VQRAEs that utilize bi-directional information to further improve the accuracy. The above design choices make VQRAEs not only robust and thus accurate, but also efficient at detecting anomalies in streaming settings. Experiments on five real-world time series offer insight into the design properties of VQRAEs and demonstrate that VQRAEs are capable of outperforming state-of-the-art methods.","2375-026X","978-1-6654-0883-7","10.1109/ICDE53745.2022.00105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9835268","","Training;Convolution;Computational modeling;Time series analysis;Transportation;Stochastic processes;Bidirectional control","learning (artificial intelligence);neural nets;recurrent neural nets;time series;unsupervised learning","robust detection;efficient anomaly detection;unsupervised settings;judiciously designed objective function;robust divergences;anomaly labels;fully unsupervised training;time series data;quasirecurrent neural networks;classic recurrent neural networks;bi-directional Bi VQRAEs;real-world time series offer insight;robust variational quasirecurrent autoencoders","","","","55","IEEE","2 Aug 2022","","","IEEE","IEEE Conferences"
"Time Delay Attack Detection Using Recurrent Variational Autoencoder and K-means Clustering","S. Ghahremani; D. K. Y. Yau; J. Albrethsen; R. Sidhu; N. -M. Cheung",Singapore University of Technology and Design; Singapore University of Technology and Design; Singapore University of Technology and Design; Singapore University of Technology and Design; Singapore University of Technology and Design,"2021 IEEE PES Innovative Smart Grid Technologies - Asia (ISGT Asia)","24 Feb 2022","2021","","","1","5","Conventional security methods deployed in power plants have difficulty detecting time delay attacks, since they do not alter network packets. However, these attacks can cause damage and instability in power systems, so detecting them is an urgent anomaly detection problem. Current state-of-the-art anomaly detection methods employ machine learning (ML) or statistical regression models in a supervised fashion, which require large amounts of labeled data for training. This data may be hard to practically obtain, so it is preferable to use unsupervised methods, which do not need labeled data. However, unsupervised anomaly detection solutions suffer from high false positive rates, especially under weak and moderate attacks. To improve on existing unsupervised solutions, we develop and present a dual-stage anomaly detection method using a Recurrent Variational Autoencoder (RVAE) and K-means clustering for detecting time delay attacks in power systems. We focus on samples including weak or moderate attacks which existing solutions cannot accurately detect, but can still harm the system if strategically targeted. We call these cases borderline samples, and use an additional clustering enhancement to more accurately classify them. Evaluation of the proposed approach on our power plant dataset demonstrates that our approach is effective in detecting time delay attacks, with 14.7% higher area under the ROC curve (AUC) than RVAE for borderline samples.","2378-8542","978-1-6654-3339-6","10.1109/ISGTAsia49270.2021.9715557","Energy Market Authority of Singapore(grant numbers:NRF2017EWT-EP003-061); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9715557","","Training;Delay effects;Asia;Machine learning;Power system stability;Smart grids;Security","computer network security;delays;pattern classification;pattern clustering;recurrent neural nets;regression analysis;supervised learning;unsupervised learning","time delay attack detection;recurrent variational autoencoder;power systems instability;urgent anomaly detection problem;statistical regression models;unsupervised anomaly detection solutions;dual-stage anomaly detection method;power plant dataset;security methods;network packets;machine learning;RVAE;K-means clustering;ROC curve;borderline samples","","","","13","IEEE","24 Feb 2022","","","IEEE","IEEE Conferences"
"Variational Autoencoder for 3D Voxel Compression","J. Liu; S. Mills; B. McCane","Department of Computer Science, University of Otago, Dunedin, New Zealand; Department of Computer Science, University of Otago, Dunedin, New Zealand; Department of Computer Science, University of Otago, Dunedin, New Zealand","2020 35th International Conference on Image and Vision Computing New Zealand (IVCNZ)","17 Dec 2020","2020","","","1","6","3D scene sensing and understanding is a fundamental task in the field of computer vision and robotics. One widely used representation for 3D data is a voxel grid. However, explicit representation of 3D voxels always requires large storage space, which is not suitable for light-weight applications and scenarios such as robotic navigation and exploration. In this paper we propose a method to compress 3D voxel grids using an octree representation and Variational Autoencoders (VAEs). We first capture a 3D voxel grid -in our application with collaborating Realsense D435 and T265 cameras. The voxel grid is decomposed into three types of octants which are then compressed by the encoder and reproduced by feeding the latent code into the decoder. We demonstrate the efficiency of our method by two applications: scene reconstruction and path planning.","2151-2205","978-1-7281-8579-8","10.1109/IVCNZ51579.2020.9290656","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9290656","","Solid modeling;Three-dimensional displays;Computational modeling;Octrees;Data models;Task analysis;Image reconstruction","cameras;computer vision;data visualisation;feature extraction;image representation;mobile robots;neural nets;octrees","path planning;scene reconstruction;T265 cameras;Realsense D435;VAEs;robotic exploration;3D data;3D scene sensing;variational autoencoder;octree representation;3D voxel grids;robotic navigation;light-weight applications;explicit representation;computer vision;3D voxel compression","","","","21","","17 Dec 2020","","","IEEE","IEEE Conferences"
"Fusing multimodal neuroimaging data with a variational autoencoder","E. Geenjaar; N. Lewis; Z. Fu; R. Venkatdas; S. Plis; V. Calhoun","Faculty of Electrical Engineering, Mathematics & Computer Science, TU Delft, Delft, the Netherlands; Tri-Institutional Center for Translational Research in Neuroimaging and Data Science (TReNDS), Georgia State, Georgia Tech, Atlanta, GA, USA; Tri-Institutional Center for Translational Research in Neuroimaging and Data Science (TReNDS), Georgia State, Georgia Tech, Atlanta, GA, USA; Lambert High School, Suwanee, GA, USA; Tri-Institutional Center for Translational Research in Neuroimaging and Data Science (TReNDS), Georgia State, Georgia Tech, Atlanta, GA, USA; Tri-Institutional Center for Translational Research in Neuroimaging and Data Science (TReNDS), Georgia State, Georgia Tech, Atlanta, GA, USA","2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","9 Dec 2021","2021","","","3630","3633","Neuroimaging studies often collect multimodal data. These modalities contain both shared and mutually exclusive information about the brain. This work aims to find a scalable and interpretable method to fuse the information of multiple neuroimaging modalities into a lower-dimensional latent space using a variational autoencoder (VAE). To assess whether the encoder-decoder pair retains meaningful information, this work evaluates the representations using a schizophrenia classification task. The linear classifier, trained on the representations obtained through dimensionality reduction, achieves an area under the curve of the receiver operating characteristic (ROC-AUC) of 0.8609. Thus, training on a multimodal dataset with functional brain networks and a structural magnetic resonance imaging (sMRI) scan, leads to dimensionality reduction that retains meaningful information. The proposed dimensionality reduction outperforms both early and late fusion principal component analysis on the classification task.Clinical relevance — This work examines the interplay between neuroimaging modalities and their relation to mental disorders. This allows for more complex and rigorous analysis of multimodal neuroimaging data throughout clinical settings.","2694-0604","978-1-7281-1179-7","10.1109/EMBC46164.2021.9630806","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9630806","","Neuroimaging;Dimensionality reduction;Training;Representation learning;Fuses;Mental disorders;Magnetic resonance imaging","biomedical MRI;brain;data analysis;image classification;image fusion;learning (artificial intelligence);medical image processing;neurophysiology;principal component analysis","functional brain networks;structural magnetic resonance imaging scan;dimensionality reduction;multimodal neuroimaging data;variational autoencoder;neuroimaging studies;multimodal data;shared information;mutually exclusive information;scalable method;interpretable method;multiple neuroimaging modalities;lower-dimensional latent space;encoder-decoder pair;schizophrenia classification task;multimodal dataset","Brain;Humans;Magnetic Resonance Imaging;Neuroimaging","","","21","","9 Dec 2021","","","IEEE","IEEE Conferences"
"3D Shape Variational Autoencoder Latent Disentanglement via Mini-Batch Feature Swapping for Bodies and Faces","S. Foti; B. Koo; D. Stoyanov; M. J. Clarkson",University College London; University College London; University College London; University College London,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","18709","18718","Learning a disentangled, interpretable, and structured latent representation in 3D generative models of faces and bodies is still an open problem. The problem is particularly acute when control over identity features is required. In this paper, we propose an intuitive yet effective self-supervised approach to train a 3D shape variational autoencoder (VAE) which encourages a disentangled latent representation of identity features. Curating the mini-batch generation by swapping arbitrary features across different shapes allows to define a loss function leveraging known differences and similarities in the latent representations. Experimental results conducted on 3D meshes show that state-of-the-art methods for latent disentanglement are not able to disentangle identity features of faces and bodies. Our proposed method properly decouples the generation of such features while maintaining good representation and reconstruction capabilities. Our code and pretrained models are available at github.com/simofoti/3DVAE-SwapDisentangled.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01817","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879012","Face and gestures; Machine learning; Self-& semi-& meta- Vision + graphics","Solid modeling;Three-dimensional displays;Shape;Semantics;Fitting;Training data;Machine learning","feature extraction;image reconstruction;image representation;learning (artificial intelligence);neural nets;stereo image processing","3D shape variational autoencoder latent disentanglement;3D generative models;mini-batch generation;loss function;mini-batch feature swapping;latent representation;face identity features;body identity features","","","","47","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Variational Autoencoders and Evolutionary Algorithms for Targeted Novel Enzyme Design","M. Martins; M. Rocha; V. Pereira","Department of Informatics, University of Minho, Portugal; LABBELS – Associate Laboratory, Braga/Guimarães, Portugal; LABBELS – Associate Laboratory, Braga/Guimarães, Portugal","2022 IEEE Congress on Evolutionary Computation (CEC)","6 Sep 2022","2022","","","1","8","Recent developments in Generative Deep Learning have fostered new engineering methods for protein design. Although deep generative models trained on protein sequence can learn biologically meaningful representations, the design of proteins with optimised properties remains a challenge. We combined deep learning architectures with evolutionary computation to steer the protein generative process towards specific sets of properties to address this problem. The latent space of a Variational Autoencoder is explored by evolutionary algorithms to find the best candidates. A set of single-objective and multi-objective problems were conceived to evaluate the algorithms' capacity to optimise proteins. The optimisation tasks consider the average proteins' hydrophobicity, their solubility and the probability of being generated by a defined functional Hidden Markov Model profile. The results show that Evolutionary Algorithms can achieve good results while allowing for more variability in the design of the experiment, thus resulting in a much greater set of possibly functional novel proteins.","","978-1-6654-6708-7","10.1109/CEC55065.2022.9870421","European Union's Horizon 2020 research and innovation programme(grant numbers:814408); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870421","Deep Learning;Generative Models;Protein Design;Evolutionary Algorithms;Novel Proteins","Proteins;Deep learning;Computational modeling;Biological system modeling;Transfer learning;Hidden Markov models;Evolutionary computation","biology computing;deep learning (artificial intelligence);enzymes;evolutionary computation;hidden Markov models;proteins","optimisation tasks;targeted novel enzyme design;generative deep learning;protein sequence;evolutionary computation;protein generative process;functional hidden Markov model profile;variational autoencoder","","","","37","IEEE","6 Sep 2022","","","IEEE","IEEE Conferences"
"Unsupervised Learning of Independent Components from a Noisy and Non-Linear Mixture via Variational Autoencoders","A. Payani; F. Fekri","Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA; Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA","2019 IEEE 20th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)","29 Aug 2019","2019","","","1","5","Separating the underlying independent components from the observed data is an important problem in machine learning. We propose a novel unsupervised learning algorithm for nonlinear Independent Component Analysis in presence of additive Gaussian noise. In the proposed algorithm, we adopt a Variational AutoEncoder (VAE) framework for learning the latent independent components. Further, to encourage the independence of the components, we introduce a new loss function by obtaining approximate samples from the product of marginals. We demonstrate via experiments that our proposed method outperforms the state of the art in several cases. Further, we show our algorithm is robust to the noise compared to the past methods.","1948-3252","978-1-5386-6528-2","10.1109/SPAWC.2019.8815480","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8815480","","","Gaussian noise;independent component analysis;learning (artificial intelligence);neural nets;unsupervised learning","nonlinear mixture;underlying independent components;machine learning;novel unsupervised learning algorithm;additive Gaussian noise;latent independent components;variational autoencoder framework;unsupervised learning algorithm;nonlinear independent component analysis;VAE","","","","14","","29 Aug 2019","","","IEEE","IEEE Conferences"
"Mixed-Variable Bayesian Optimization for Analog Circuit Sizing using Variational Autoencoders","K. Touloupas; P. P. Sotiriadis","National Technical University of Athens, Greece; National Technical University of Athens, Greece","2022 18th International Conference on Synthesis, Modeling, Analysis and Simulation Methods and Applications to Circuit Design (SMACD)","11 Jul 2022","2022","","","1","4","Bayesian Optimization (BO) has recently gained popularity within the context of automatic sizing of analog and Radio-Frequency (RF) Integrated Circuits (ICs). However, its reliance on Gaussian Process models, which operate only on continuous-valued spaces, reduces its applicability in real-world scenarios, where multiple discrete-valued variables often exist. In this paper, we propose an approach to mitigate this issue by using a Deep Learning scheme to transform devices parametrizations to continuous ones, where classic BO can be applied. Specifically, a composite architecture that consists of a Convolutional Variational Autoencoder (VAE) and a dense Neural Network is built to define a continuous representation of integrated inductors in a TSMC 90nm process. By optimizing using these representations, we overcome the limitation of discrete-valued variables. Experimental results on a Low Noise Amplifier highlight the efficiency of the proposed approach.","","978-1-6654-6703-2","10.1109/SMACD55068.2022.9816185","European Social Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9816185","sizing;optimization;analog;deep learning","Radio frequency;Deep learning;Analytical models;Low-noise amplifiers;Neural networks;Transforms;Bayes methods","Bayes methods;circuit analysis computing;circuit optimisation;deep learning (artificial intelligence);Gaussian processes;inductors;integrated circuit modelling;low noise amplifiers;neural net architecture;radiofrequency integrated circuits","mixed-variable Bayesian optimization;analog circuit sizing;Radio-Frequency Integrated Circuits;RF ICs;Gaussian process models;continuous-valued spaces;classic BO;composite architecture;Convolutional Variational Autoencoder;dense neural network;integrated inductors;TSMC process;multiple discrete-valued variables;device parametrizations;deep learning scheme;VAE;low noise amplifier;size 90.0 nm;BO","","","","14","IEEE","11 Jul 2022","","","IEEE","IEEE Conferences"
"Simpler is Better: Spectral Regularization and Up-Sampling Techniques for Variational Autoencoders","S. Björk; J. N. Myhre; T. Haugland Johansen",UiT The Arctic University of Norway; UiT The Arctic University of Norway; UiT The Arctic University of Norway,"ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","3778","3782","Full characterization of the spectral behavior of generative models based on neural networks remains an open issue. Recent research has focused heavily on generative adversarial networks and the high-frequency discrepancies between real and generated images. The current solution to avoid this is to either replace transposed convolutions with bilinear up-sampling or add a spectral regularization term in the generator. We propose a 2D Fourier transform-based spectral regularization loss and evaluate it on the variational autoencoder. We show that it can achieve results equal to, or better than, the current state-of-the-art in frequency-aware losses for generative models. In addition, we experiment with altering the up-sampling procedure in the generator network and investigate how it influences the spectral performance of the model. We include experiments on synthetic and real data sets to demonstrate our results.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746027","","Convolution;Conferences;Neural networks;Generative adversarial networks;Generators;Acoustics;Speech processing","convolutional neural nets;Fourier transforms;image sampling","variational autoencoder;spectral behavior;neural networks;generative adversarial networks;transposed convolutions;bilinear up-sampling;spectral regularization loss;frequency-aware losses;generated image;real image;2D Fourier transform","","","","38","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Motor Imagery Classification Using Inter-Task Transfer Learning via a Channel-Wise Variational Autoencoder-Based Convolutional Neural Network","D. -Y. Lee; J. -H. Jeong; B. -H. Lee; S. -W. Lee","Department of Brain and Cognitive Engineering, Korea University, Anam-dong, Seongbuk-gu, Seoul, South Korea; Department of Artificial Intelligence, Korea University, Anam-dong, Seongbuk-gu, Seoul, South Korea; Department of Brain and Cognitive Engineering, Korea University, Anam-dong, Seongbuk-gu, Seoul, South Korea; Department of Artificial Intelligence, Korea University, Anam-dong, Seongbuk-gu, Seoul, South Korea","IEEE Transactions on Neural Systems and Rehabilitation Engineering","1 Feb 2022","2022","30","","226","237","Highly sophisticated control based on a brain-computer interface (BCI) requires decoding kinematic information from brain signals. The forearm is a region of the upper limb that is often used in everyday life, but intuitive movements within the same limb have rarely been investigated in previous BCI studies. In this study, we focused on various forearm movement decoding from electroencephalography (EEG) signals using a small number of samples. Ten healthy participants took part in an experiment and performed motor execution (ME) and motor imagery (MI) of the intuitive movement tasks (Dataset I). We propose a convolutional neural network using a channel-wise variational autoencoder (CVNet) based on inter-task transfer learning. We approached that training the reconstructed ME-EEG signals together will also achieve more sufficient classification performance with only a small amount of MI-EEG signals. The proposed CVNet was validated on our own Dataset I and a public dataset, BNCI Horizon 2020 (Dataset II). The classification accuracies of various movements are confirmed to be 0.83 (±0.04) and 0.69 (±0.04) for Dataset I and II, respectively. The results show that the proposed method exhibits performance increases of approximately 0.09~0.27 and 0.08~0.24 compared with the conventional models for Dataset I and II, respectively. The outcomes suggest that the training model for decoding imagined movements can be performed using data from ME and a small number of data samples from MI. Hence, it is presented the feasibility of BCI learning strategies that can sufficiently learn deep learning with a few amount of calibration dataset and time only, with stable performance.","1558-0210","","10.1109/TNSRE.2022.3143836","Institute of Information and Communications Technology Planning and Evaluation (IITP) Grant by the Korean Government(grant numbers:2017-0-00432,2017-0-00451,2019-0-00079); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684414","Brain-computer interface;electroencephalogram;motor imagery;motor execution;deep learning","Electroencephalography;Task analysis;Decoding;Training;Transfer learning;Deep learning;Convolutional neural networks","biomechanics;brain;brain-computer interfaces;convolutional neural nets;decoding;deep learning (artificial intelligence);electroencephalography;medical signal processing;neurophysiology;signal classification","imagined movements;BCI learning strategies;deep learning;calibration dataset;motor imagery classification;channel-wise variational autoencoder-based convolutional neural network;brain-computer interface;kinematic information;brain signals;upper limb;forearm movement decoding;electroencephalography signals;intuitive movement tasks;CVNet;ME-EEG signals;MI-EEG signals;public dataset;intertask transfer learning","Algorithms;Brain-Computer Interfaces;Electroencephalography;Hand;Humans;Imagination;Machine Learning;Neural Networks, Computer","","","55","CCBY","18 Jan 2022","","","IEEE","IEEE Journals"
"Variational Autoencoder Generative Adversarial Network for Synthetic Data Generation in Smart Home","M. Razghandi; H. Zhou; M. Erol-Kantarci; D. Turgut","Department of Computer Science, University of Central Florida; School of Electrical Engineering and Computer Science, University of Ottawa; School of Electrical Engineering and Computer Science, University of Ottawa; Department of Computer Science, University of Central Florida","ICC 2022 - IEEE International Conference on Communications","11 Aug 2022","2022","","","4781","4786","Data is the fuel of data science and machine learning techniques for smart grid applications, similar to many other fields. However, the availability of data can be an issue due to privacy concerns, data size, data quality, and so on. To this end, in this paper, we propose a Variational AutoEncoder Generative Adversarial Network (VAE-GAN) as a smart grid data generative model which is capable of learning various types of data distributions and generating plausible samples from the same distribution without performing any prior analysis on the data before the training phase. We compared the Kullback–Leibler (KL) divergence, maximum mean discrepancy (MMD), and Wasserstein distance between the synthetic data (electrical load and PV production) distribution generated by the proposed model, vanilla GAN network, and the real data distribution, to evaluate the performance of our model. Furthermore, we used five key statistical parameters to describe the smart grid data distribution and compared them between synthetic data generated by both models and real data. Experiments indicate that the proposed synthetic data generative model outperforms the vanilla GAN network. The distribution of VAE-GAN synthetic data is the most comparable to that of real data.","1938-1883","978-1-5386-8347-7","10.1109/ICC45855.2022.9839249","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9839249","synthetic data;load consumption;smart grid;deep learning;generative adversarial network","Training;Time series analysis;Smart homes;Production;Machine learning;Data science;Generative adversarial networks","home automation;learning (artificial intelligence);neural nets;smart power grids","smart grid data generative model;data distributions;generating plausible samples;vanilla GAN network;smart grid data distribution;synthetic data generative model;VAE-GAN synthetic data;variational autoencoder generative adversarial network;synthetic data generation;smart home;data science;smart grid applications;data size;data quality;Kullback-Leibler divergence;KL;electrical load;PV production","","","","19","IEEE","11 Aug 2022","","","IEEE","IEEE Conferences"
"Adaptive Beam Alignment in Mm-Wave Networks: A Deep Variational Autoencoder Architecture","M. Hussain; N. Michelusi","School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; School of Electrical, Computer and Energy Engineering, Arizona State University, AZ, USA","2021 IEEE Global Communications Conference (GLOBECOM)","2 Feb 2022","2021","","","1","6","This paper proposes a dual timescale learning and adaptation framework to learn a probabilistic model of beam dynamics and concurrently exploit this model to design adaptive beam-training with low overhead: on a long timescale, a deep recurrent variational autoencoder (DR-VAE) uses noisy beam-training observations to learn a probabilistic model of beam dynamics; on a short timescale, an adaptive beam-training procedure is formulated as a partially observable Markov decision process and optimized using point-based value iteration by leveraging beam-training feedback and probabilistic predictions of the strongest beam pair provided by the DR-VAE. In turn, beam-training observations are used to refine the DR-VAE via stochastic gradient ascent in a continuous process of learning and adaptation. It is shown that the proposed DR-VAE learning framework learns accurate beam dynamics and, as learning progresses, the training overhead decreases and the spectral efficiency increases. Moreover, the proposed dual timescale approach achieves near-optimal spectral efficiency, with a gain of 85% over a policy that scans exhaustively over the dominant beam pairs, and of 18% over a state-of-the-art POMDP policy.","","978-1-7281-8104-2","10.1109/GLOBECOM46510.2021.9685969","National Science Foundation(grant numbers:CNS-1642982,CNS-2129015); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9685969","","Training;Adaptation models;Spectral efficiency;Heuristic algorithms;Predictive models;Markov processes;Probabilistic logic","deep learning (artificial intelligence);gradient methods;iterative methods;Markov processes;millimetre waves;probability;telecommunication computing;vehicular ad hoc networks","DR-VAE learning framework;beam dynamics;adaptive beam alignment;millimeter-wave networks;dual timescale learning;adaptation framework;deep recurrent variational autoencoder;noisy beam-training observations;adaptive beam-training procedure;partially observable Markov decision process;point-based value iteration;beam-training feedback;probabilistic predictions;stochastic gradient ascent;POMDP policy","","","","20","IEEE","2 Feb 2022","","","IEEE","IEEE Conferences"
"Exploiting Probabilistic Siamese Visual Tracking with a Conditional Variational Autoencoder","W. Huang; J. Gu; P. Duan; S. Hou; Y. Zheng","School of Information Science and Engineering, Shandong Normal University, China; Department of Electrical and Computer Engineering, Dalhousie University, Halifax, Canada; School of Information Science and Engineering, Shandong Normal University, China; School of Information Science and Engineering, Shandong Normal University, China; Shandong Provincial Key Laboratory for Novel Distributed Computer Software Technology, Shandong Normal University, China","2021 IEEE International Conference on Robotics and Automation (ICRA)","18 Oct 2021","2021","","","14213","14219","Visual tracking is a fundamental capability for robots tasked with humans and environment interaction. However, state-of-the-art visual tracking methods are still prone to failures and are imprecise when applied to challenging stereos, and their results are generally confidence agonistic. These methods depend on an embedded deep learning model to provide deterministic features or regression maps. A deterministic output with low confidence can result in disastrous consequences and lacks evidence needed for subsequent operations. Moreover, training data ambiguities or noise in the observations (so-called data uncertainty) can also lead to inherent uncertainty. In this paper, we focus on exploiting probabilistic Siamese visual tracking with a conditional variational autoencoder (CVAE). First, we build a bridge between the Siamese architecture and the CVAE and propose a novel Bayesian visual tracking method. Second, the proposed method generates a complete probability distribution that enables the production of multiple plausible tracking outputs. Third, CVAE conditioned by ground truth data encodes a low-dimensional latent space and conducts noise-injection training to prevent overfitting. Our proposed tracking method outperformed the state-of-the-art trackers on the VOT2016, VOT2018 and TColor-128 datasets.","2577-087X","978-1-7281-9077-8","10.1109/ICRA48506.2021.9561757","Nature; Nature; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9561757","","Bridges;Training;Visualization;Uncertainty;Training data;Probabilistic logic;Probability distribution","Bayes methods;deep learning (artificial intelligence);image representation;object tracking;regression analysis;robot vision;statistical distributions","conditional variational autoencoder;embedded deep learning model;deterministic features;regression maps;data uncertainty;probabilistic Siamese visual tracking;CVAE;Siamese architecture;Bayesian visual tracking method;low-dimensional latent space;robots;complete probability distribution;VOT2016 dataset;VOT2018 dataset;TColor-128 dataset;noise-injection training","","","","38","IEEE","18 Oct 2021","","","IEEE","IEEE Conferences"
"Highly-Confident Protein Interactome Prediction via Variational Autoencoder","Z. Xiao; H. Yuan; W. Li; N. Jiang; Y. Xia","School of Computer Science and Technology, Dongguan University of Technology, Dongguan, China; School of Computer Science and Technology, Dongguan University of Technology, Dongguan, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; Mashang Consumer Finance Co., Ltd. (MSCF), Chongqing, China; School of Computer Science, Chongqing University, Chongqing, China","2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","6 Jan 2022","2021","","","958","963","Protein-protein interactions (PPIs) play a critical role in cellular activities. However, discover them experimentally is exhausted. How to predict the missing PPIs with the known PPI networks (PPINs) is a challenging task considering their large scale and extreme sparsity. To utilize the known data efficiently, this work proposes a Highly-Confident Protein Interactome Prediction (HPIP) model with two-fold ideas: a) employing a variational autoencoder model based on Gaussian distribution as a basic PPI predictor for processing the sparse input PPIN; b) embedding the basic PPI predictor into an elastic architecture which based on a block and probability summing strategy. Experimental results on two real world PPINs from the STRING database indicate that HPIP can effectively predict PPIs with high confidence.","2577-1655","978-1-6654-4207-7","10.1109/SMC52423.2021.9659005","National Natural Science Foundation of China; China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9659005","","Proteins;Analytical models;Databases;Scalability;Computer architecture;Predictive models;Parallel processing","biology computing;cellular biophysics;Gaussian distribution;molecular biophysics;proteins","variational autoencoder model;protein-protein interactions;cellular activities;highly-confident protein interactome prediction;Gaussian distribution;STRING database","","","","35","IEEE","6 Jan 2022","","","IEEE","IEEE Conferences"
"Medical Data Wrangling With Sequential Variational Autoencoders","D. Barrejón; P. M. Olmos; A. Artés-Rodríguez","Gregorio Marañón Health Research Insitute (Spain), Madrid, Spain; Gregorio Marañón Health Research Insitute (Spain), Madrid, Spain; Gregorio Marañón Health Research Insitute (Spain), Madrid, Spain","IEEE Journal of Biomedical and Health Informatics","3 Jun 2022","2022","26","6","2737","2745","Medical data sets are usually corrupted by noise and missing data. These missing patterns are commonly assumed to be completely random, but in medical scenarios, the reality is that these patterns occur in bursts due to sensors that are off for some time or data collected in a misaligned uneven fashion, among other causes. This paper proposes to model medical data records with heterogeneous data types and bursty missing data using sequential variational autoencoders (VAEs). In particular, we propose a new methodology, the Shi-VAE, which extends the capabilities of VAEs to sequential streams of data with missing observations. We compare our model against state-of-the-art solutions in an intensive care unit database (ICU) and a dataset of passive human monitoring. Furthermore, we find that standard error metrics such as RMSE are not conclusive enough to assess temporal models and include in our analysis the cross-correlation between the ground truth and the imputed signal. We show that Shi-VAE achieves the best performance in terms of using both metrics, with lower computational complexity than the GP-VAE model, which is the state-of-the-art method for medical records.","2168-2208","","10.1109/JBHI.2021.3123839","Spanish Government MCI(grant numbers:TEC2017-92552-EXP,RTI2018-099655-B-100); Comunidad de Madrid(grant numbers:IND2017/TIC-7618,IND2018/TIC-9649,IND2020/TIC-17372,Y2018/TCS-4705); BBVA Foundation; Deep-DARWiN; European Union; European Research Council; European Union’s Horizon 2020 research and innovation program(grant numbers:714161); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9594658","Deep learning;VAE;missing data;heterogeneous;sequential data","Data models;Correlation;Monitoring;Databases;Measurement;Hospitals;Time series analysis","computational complexity;data analysis;database management systems;electronic health records;medical computing;neural nets;patient care;patient monitoring","computational complexity;human monitoring;sequential variational autoencoders;medical data wrangling;medical records;GP-VAE model;Shi-VAE;intensive care unit database","Databases, Factual;Humans","","","35","IEEE","29 Oct 2021","","","IEEE","IEEE Journals"
"Variational Autoencoders for Generating Hyperspectral Imaging Honey Adulteration Data","T. Phillips; W. Abdulla","University of Auckland, Auckland, New Zealand; University of Auckland, Auckland, New Zealand","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","23 Aug 2022","2022","","","213","220","Honey fraud and adulteration are an increasing concern globally. Hyperspectral imaging and machine learning can detect adulterated honey within a known set of honey, where we have captured data at different sugar concentrations. Previous work in this area has used a minimal number of honey types, as sample preparation and data capture is a time-consuming process. This paper develops a new approach using variational autoencoders (VAEs) for generating adulterated honey data for unseen honey types. The results show that the binary adulteration detector can achieve on average 81.3% accuracy on unseen honey types by adding the generated data to the existing training data. Without including the generated data while training, the classifier can only achieve 44% on unseen honey types.","2160-7516","978-1-6654-8739-9","10.1109/CVPRW56347.2022.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9857172","","Training;Computer vision;Conferences;Training data;Machine learning;Detectors;Pattern recognition","food products;food technology;learning (artificial intelligence);pattern classification","adulterated honey data;unseen honey types;binary adulteration detector;existing training data;variational autoencoders;generating hyperspectral imaging honey adulteration data;machine learning;different sugar concentrations","","","","24","IEEE","23 Aug 2022","","","IEEE","IEEE Conferences"
"Detecting Malicious Gradients from Asynchronous SGD on Variational Autoencoder","Z. Gu; Y. Yang; H. Shi","College of Computer Science and Technology, National University of Defense Technology, Changsha, China; College of Computer Science and Technology, National University of Defense Technology, Changsha, China; KLISS, BNRist Tsinghua University, Beijing, China","2021 40th International Symposium on Reliable Distributed Systems (SRDS)","22 Nov 2021","2021","","","321","330","In asynchronous distributed learning, the parameter server updates the global model as soon as a new gradient is received from any device. The asynchronous systems are designed to address the existence of lagging devices which is inevitable due to device heterogeneity and network unreliability. However, the lack of synchrony incurs additional noise and makes detecting and defending against malicious model gradients a challenging task. Unlike existing works that struggle to design robust methods to tolerate untargeted model poisoning gradients, the paper considers detecting and removing targeted model poisoning gradients from the normal asynchronous training process. This paper proposes Asynvae, a robust distributed asynchronous learning framework where the parameter server uses variational autoencoder to detect and exclude malicious gradients. Since the reconstruction error of malicious updates is much larger than that of benign ones, it can be used as an anomaly score. We formulate a threshold of reconstruction error to differentiate malicious updates from normal ones based on this idea. Asynvae is tested with extensive experiments on distributed learning benchmarks, showing a competitive performance over existing distributed learning methods under untargeted model poisoning attack, targeted model poisoning attack and lagging attack.","2575-8462","978-1-6654-3819-3","10.1109/SRDS53918.2021.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9603557","asynchronous distributed learning;model poisoning attack;backdoor attack;straggler","Training;Performance evaluation;Computer aided instruction;Distance learning;Design methodology;Benchmark testing;Servers","gradient methods;learning (artificial intelligence);security of data","asynchronous SGD;variational autoencoder;asynchronous distributed learning;asynchronous systems;normal asynchronous training process;Asynvae;robust distributed asynchronous learning framework;malicious gradient detection;untargeted model poisoning gradients","","","","32","IEEE","22 Nov 2021","","","IEEE","IEEE Conferences"
"Detecting Adversarial Examples in Learning-Enabled Cyber-Physical Systems using Variational Autoencoder for Regression","F. Cai; J. Li; X. Koutsoukos","Vanderbilt University, Nashville, TN; Vanderbilt University, Nashville, TN; Vanderbilt University, Nashville, TN","2020 IEEE Security and Privacy Workshops (SPW)","18 Dec 2020","2020","","","208","214","Learning-enabled components (LECs) are widely used in cyber-physical systems (CPS) since they can handle the uncertainty and variability of the environment and increase the level of autonomy. However, it has been shown that LECs such as deep neural networks (DNN) are not robust and adversarial examples can cause the model to make a false prediction. The paper considers the problem of efficiently detecting adversarial examples in LECs used for regression in CPS. The proposed approach is based on inductive conformal prediction and uses a regression model based on variational autoencoder. The architecture allows to take into consideration both the input and the neural network prediction for detecting adversarial, and more generally, out-of-distribution examples. We demonstrate the method using an advanced emergency braking system implemented in an open source simulator for self-driving cars where a DNN is used to estimate the distance to an obstacle. The simulation results show that the method can effectively detect adversarial examples with a short detection delay.","","978-1-7281-9346-5","10.1109/SPW50608.2020.00050","National Science Foundation(grant numbers:CNS 1739328); Defense Advanced Research Projects Agency(grant numbers:FAS750-1S-C-0089); Air Force Office of Scientific Research(grant numbers:FA9550-15-1-0126); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283885","adversarial example detection;inductive conformal prediction;VAE based regression;self-driving vehicles","Training;Uncertainty;Neural networks;Predictive models;Cyber-physical systems;Delays;Autonomous automobiles","automobiles;braking;computer simulation;cyber-physical systems;driver information systems;learning (artificial intelligence);neural nets;public domain software;regression analysis","inductive conformal prediction;regression model;variational autoencoder;neural network prediction;advanced emergency braking system;adversarial example detection;learning-enabled cyber-physical systems;LEC;CPS;false prediction;open source simulator;self-driving cars","","","","19","","18 Dec 2020","","","IEEE","IEEE Conferences"
"Dimension Reduction on Open Data Using Variational Autoencoder","H. Lee; Z. H. Wu; Z. Zhang","Donnelly Center for Cellular and Molecular Biology, University of Toronto, Toronto, Canada; University of Toronto, Toronto, ON, CA; Department of Molecular Genetics, University of Toronto, Toronto, Canada","2018 IEEE International Conference on Data Mining Workshops (ICDMW)","10 Feb 2019","2018","","","1080","1085","Open Data movement has led to large number of databases published in the web. However, effectively accessing these databases remain a challenge due to its large volume and heterogeneity. To retrieve similar queries, min-wise independent permutation locality sensitive hashing (MinHash LSH) became a popular technique to estimate the similarity between two domains. With the recent advancements in deep learning and its ability to revolutionize multiple fields of science, we explored how deep learning could improve similarity search on an internet scale. To do so, we first formulate the similarity search problem as a Euclidean nearest neighbour problem by transforming the set representation into a latent representation of learned features.We then apply Variational Autoencoders (VAEs) to embed domains into a significantly smaller, continuous latent dimension. VAEs learn an embedding that minimizes reconstruction error and the Kullback-Leibler divergence between the encoder and prior. Optimizing both terms allow the model to learn a dense representation with local similarities preserved from the original input space. We evaluate our algorithm using a subset of joint Open Data (Canada, US and UK) that contain more than 1.4 million documents with a domain size greater than 128 thousand. We demonstrate that the latent space correlates significantly with the Jaccard similarity coefficient. Then, we show domains that embed spatially closer in latent space are indeed similar. Lastly, we show that our algorithm outperforms MinHash LSH in accuracy and precision for all dimensions tested. These improvements show that deep learning techniques can be a promising approach for internet scale domain search.","2375-9259","978-1-5386-9288-2","10.1109/ICDMW.2018.00156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8637536","Open Data, Deep Learning, Similarity Search","Search problems;Deep learning;Probability distribution;Neural networks;Indexes;Decoding;Time complexity","database management systems;file organisation;Internet;learning (artificial intelligence);Linked Data;minimisation;query processing;search problems","dimension reduction;databases;min-wise independent permutation locality sensitive hashing;MinHash LSH;similarity search problem;Euclidean nearest neighbour problem;latent representation;learned features;Variational Autoencoders;Kullback-Leibler divergence;deep learning;Open Data;queries retrieval;VAE;Internet scale domain search","","","","14","","10 Feb 2019","","","IEEE","IEEE Conferences"
"Detecting Malicious Model Updates from Federated Learning on Conditional Variational Autoencoder","Z. Gu; Y. Yang","College of Computer Science and Technology, National University of Defense Technology, Changsha, China; College of Computer Science and Technology, National University of Defense Technology, Changsha, China","2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS)","28 Jun 2021","2021","","","671","680","In federated learning, the central server combines local model updates from the clients in the network to create an aggregated model. To protect clients' privacy, the server is designed to have no visibility into how these updates are generated. The nature of federated learning makes detecting and defending against malicious model updates a challenging task. Unlike existing works that struggle to defend against Byzantine clients, the paper considers defending against targeted model poisoning attack in the federated learning setting. The adversary aims to reduce the model performance on targeted subtasks while maintaining the main task's performance. This paper proposes Fedcvae, a robust and unsupervised federated learning framework where the central server uses conditional variational autoencoder to detect and exclude malicious model updates. Since the reconstruction error of malicious updates is much larger than that of benign ones, it can be used as an anomaly score. We formulate a dynamic threshold of reconstruction error to differentiate malicious updates from normal ones based on this idea. Fedcvae is tested with extensive experiments on IID and non-IID federated benchmarks, showing a competitive performance over existing aggregation methods under Byzantine attack and targeted model poisoning attack.","1530-2075","978-1-6654-4066-0","10.1109/IPDPS49936.2021.00075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9460523","federated learning;anomaly detection","Privacy;Distributed processing;Benchmark testing;Collaborative work;Servers;Task analysis;Anomaly detection","security of data;unsupervised learning","malicious model updates detection;differentiate malicious updates;conditional variational autoencoder;central server;unsupervised federated learning framework;robust learning framework;targeted model poisoning attack;Byzantine clients;aggregated model;local model updates","","","","35","","28 Jun 2021","","","IEEE","IEEE Conferences"
"Robust Autoencoder-based State Estimation in Power Systems","M. Picot; F. J. Messina; F. Labeau; P. Piantanida","Telecommunications and Signal Processing Lab, McGill University, McConnell Engineering Building, Canada; Universidad de Buenos Aires, Argentina; Telecommunications and Signal Processing Lab, McGill University, McConnell Engineering Building, Canada; Laboratoire des Signaux et Systèmes (L2S), CentraleSupelec CNRS Université Paris-Saclay, Gif-Sur-Yvette, France","2022 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT)","12 Jul 2022","2022","","","1","5","Smart Grids are critical cyber-physical systems where monitoring is crucial, especially the process of state estimation. Since this task strongly depends on the reliability of power grid meters and their communication channels, it is vulnerable to cyber-attacks and, particularly, false data injection attacks (FDIAs), which are modifications on the meter readings that are often hard to detect. In this paper, we propose a method to construct a robust state estimator based on a variational autoencoder trained on the Fisher-Rao distance, which is a measure of dissimilarity between probability distributions. Then, we introduce a novel method to generate FDIAs that exploits knowledge of the state estimator and its learning procedure, for which we show effectiveness. Finally, numerical results and comparison with state-of-the-art methods confirm that our approach can archive similar estimation errors for clean and noisy (attacked) measurements.","2472-8152","978-1-6654-3775-2","10.1109/ISGT50606.2022.9817514","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9817514","Smart Grids;false data injection attacks;robustness;autoencoder;state estimation","Training;Particle measurements;Robustness;Probability distribution;Smart grids;Power system reliability;Noise measurement","learning (artificial intelligence);power engineering computing;power grids;power system security;power system state estimation;probability;security of data;smart power grids","robust autoencoder-based state estimation;power systems;smart grids;critical cyber-physical systems;power grid meters;communication channels;cyber-attacks;false data injection attacks;FDIAs;meter readings;robust state estimator;variational autoencoder;Fisher-Rao distance;estimation errors","","","","17","IEEE","12 Jul 2022","","","IEEE","IEEE Conferences"
"Variational Auto-Encoders Without Graph Coarsening For Fine Mesh Learning","N. Vercheval; H. D. Bie; A. Pižurica","Department of Telecommunications and Information Processing, Ghent University, Belgium; Department of Electronics and Information Systems, Ghent University, Belgium; Department of Telecommunications and Information Processing, Ghent University, Belgium","2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","2681","2685","In this paper, we propose a Variational Auto-Encoder able to correctly reconstruct a fine mesh from a very low-dimensional latent space. The architecture avoids the usual coarsening of the graph and relies on pooling layers for the decoding phase and on the mean values of the training set for the up-sampling phase. We select new operators compared to previous work, and in particular, we define a new Dirac operator which can be extended to different types of graph structured data. We show the improvements over the previous operators and compare the results with the current benchmark on the Coma Dataset.","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9191189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9191189","Variational Autoencoder;Geometric Deep Learning;Mesh processing","Decoding;Laplace equations;Shape;Machine learning;Convolution;Training;Surface reconstruction","data handling;deep learning (artificial intelligence);graph theory;neural nets","decoding;Dirac operator;graph structured data;graph coarsening;fine mesh learning;low-dimensional latent space;pooling layers;variational autoencoder;fine mesh reconstruction;Coma Dataset","","1","","16","","30 Sep 2020","","","IEEE","IEEE Conferences"
"Variational Auto-encoders application in wireless Vehicle-to-Everything communications","M. Q. Hamdan; K. A. Hamdi","Department of EEE, The University of Manchester, Manchester, UK; Department of EEE, The University of Manchester, Manchester, UK","2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring)","30 Jun 2020","2020","","","1","6","In this paper, a new technique called Embedded Variational Auto Encoder (EVAE) is proposed for Vehicle-to-Everything (V2X) up-link scenario. An innovative method has been proposed for the accurate prediction of the interference at the receiving end of each user which leads to the enhancement of the end-to-end performance of the V2X. The new algorithm infers noise and fading probabilistic models effect using decentralized Probabilistic Neural Networks (PNNs), while a second centralized PNN has been embedded inside the first group of the PNNs. This single PNN will be used to infer the interference effect on each V2X receiver. The performance of EVAE is compared with the recently proposed neural networks (NN) algorithms based on conventional auto-encoders (AE). Numerical and simulation results for the achievable symbol error rates (SER) have shown a significant improvement particularly in the high SINR regime, compared with the classical systems based on maximum likeli-hood detection.","2577-2465","978-1-7281-5207-3","10.1109/VTC2020-Spring48590.2020.9128376","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9128376","Deep Learning;Variational Autoencoder;V2X;Interference prediction;Artificial Intelligence;Machine Learning;Wireless Communications","Interference;Receivers;Wireless communication;Fading channels;Transmitters;Mathematical model;Vehicle-to-everything","error statistics;neural nets;probability;telecommunication computing;vehicular ad hoc networks","receiving end;end-to-end performance;fading probabilistic models effect;decentralized Probabilistic Neural Networks;PNNs;centralized PNN;single PNN;interference effect;EVAE;neural networks algorithms;Variational Auto-encoders application;Vehicle-to-Everything communications;Embedded Variational Auto Encoder;Vehicle-to-Everything up-link scenario","","1","","17","","30 Jun 2020","","","IEEE","IEEE Conferences"
"Interference Motion Removal for Doppler Radar Vital Sign Detection Using Variational Encoder-Decoder Neural Network","M. Czerkawski; C. Ilioudis; C. Clemente; C. Michie; I. Andonovic; C. Tachtatzis","Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, UK; Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, UK; Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, UK; Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, UK; Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, UK; Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, UK","2021 IEEE Radar Conference (RadarConf21)","18 Jun 2021","2021","","","1","6","The treatment of interfering motion contributions remains one of the key challenges in the domain of radar-based vital sign monitoring. Removal of the interference to extract the vital sign contributions is demanding due to overlapping Doppler bands, the complex structure of the interference motions and significant variations in the power levels of their contributions. A novel approach to the removal of interference through the use of a probabilistic deep learning model is presented. Results show that a convolutional encoder-decoder neural network with a variational objective is capable of learning a meaningful representation space of vital sign Doppler-time distribution facilitating their extraction from a mixture signal. The approach is tested on semi-experimental data containing real vital sign signatures and simulated returns from interfering body motions. It is demonstrated that the application of the proposed network enhances the extraction of the micro-Doppler frequency corresponding to the respiration rate.","2375-5318","978-1-7281-7609-3","10.1109/RadarConf2147009.2021.9454986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9454986","Doppler radar;heart rate monitoring;respiration rate monitoring;vital signs;random body movement;variational autoencoder","Legged locomotion;Sensitivity;Neural networks;Radar detection;Interference;Probabilistic logic;Doppler radar","decoding;Doppler radar;learning (artificial intelligence);medical signal detection;neural nets;patient monitoring;radar signal processing","interference motion removal;Doppler radar vital sign detection;variational encoder-decoder neural network;motion contributions;radar-based vital sign monitoring;vital sign contributions;overlapping Doppler bands;complex structure;interference motions;power levels;probabilistic deep learning model;convolutional encoder-decoder neural network;variational objective;vital sign Doppler-time distribution;vital sign signatures;body motions;microDoppler frequency","","1","","25","","18 Jun 2021","","","IEEE","IEEE Conferences"
"Unsupervised Learning Approach to Feature Analysis for Automatic Speech Emotion Recognition","S. E. Eskimez; Z. Duan; W. Heinzelman","Electrical and Computer Engineering, University of Rochester, Rochester, NY, USA; Electrical and Computer Engineering, University of Rochester, Rochester, NY, USA; Electrical and Computer Engineering, University of Rochester, Rochester, NY, USA","2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 Sep 2018","2018","","","5099","5103","The scarcity of emotional speech data is a bottleneck of developing automatic speech emotion recognition (ASER) systems. One way to alleviate this issue is to use unsupervised feature learning techniques to learn features from the widely available general speech and use these features to train emotion classifiers. These unsupervised methods, such as denoising autoencoder (DAE), variational autoencoder (VAE), adversarial autoencoder (AAE) and adversarial variational Bayes (AVB), can capture the intrinsic structure of the data distribution in the learned feature representation. In this work, we systematically investigate four kinds of unsupervised feature learning methods for improving speaker-independent ASER. We show that all methods improve the performance regarding unweighted accuracy rating (UAR) and Fl-score over methods that use hand-crafted features or that do not perform feature learning on external datasets. We also show that VAE, AAE and AVB methods, which control the distribution of the latent representation, outperform DAE that does not control such distribution. This suggests the benefits of using variational inference methods to learn features from general speech for the speech tasks such as ASER that has very limited labeled data.","2379-190X","978-1-5386-4658-8","10.1109/ICASSP.2018.8462685","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8462685","Automatic speech emotion classification;unsupervised feature learning;autoencoders;variational inference","Decoding;Task analysis;Speech recognition;Emotion recognition;Unsupervised learning;Noise reduction;Training","Bayes methods;emotion recognition;feature extraction;pattern classification;speech recognition;unsupervised learning","feature representation;general speech;speech tasks;variational inference methods;AVB methods;hand-crafted features;speaker-independent ASER;data distribution;adversarial variational Bayes;adversarial autoencoder;unsupervised methods;emotion classifiers;unsupervised feature;automatic speech emotion recognition systems;emotional speech data;feature analysis;unsupervised learning approach","","17","","28","","13 Sep 2018","","","IEEE","IEEE Conferences"
"An Attribute-invariant Variational Learning for Emotion Recognition Using Physiology","H. -C. Yang; C. -C. Lee","Department of Electrical Engineering, National Tsing Hua University, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Taiwan","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","1184","1188","Studies have shown that people with different personalities would result in a different physiological reaction when encountering emotional stimulus. In this work, we propose an attribute-invariance loss embedded variational autoencoder (AI-VAE) to learn the personality-invariant physiological signal representation. The AI-VAE includes an additional loss aiming to perturb features from different personality polarity to obtain emotion discriminative representation. We evaluate our framework on a large emotion corpus of physiological data. Our method achieves a state of the art unweighted accuracy of 68.8% and 67.0% in a binary classification of arousal and valence, which improves over the baseline vanilla VAE by 5.5% and 6.5%. Further analysis reveals that several EEG features are statistically relevant between different personalities types across emotional states, and ECG features are also specifically correlated to personality dimension of ""Creativeness"", underscoring the importance of personality in modulating psychophysiological processes.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683290","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683290","personality;physiological representation;emotion recognition;variational learning;psychophysiology","","electrocardiography;electroencephalography;emotion recognition;feature extraction;learning (artificial intelligence);medical signal processing;neurophysiology;psychology;signal classification;signal representation","physiological reaction;EEG features;baseline vanilla VAE;physiological data;emotion corpus;emotion discriminative representation;personality-invariant physiological signal representation;variational autoencoder;emotion recognition;attribute-invariant variational learning;personality dimension;ECG features;emotional states","","8","","20","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Classification by Re-generation: Towards Classification Based on Variational Inference","S. Rezaeifar; O. Taran; S. Voloshynovskiy","University of Geneva, SIP group Geneva, Switzerland; University of Geneva, SIP group Geneva, Switzerland; University of Geneva, SIP group Geneva, Switzerland","2018 26th European Signal Processing Conference (EUSIPCO)","2 Dec 2018","2018","","","2005","2009","As Deep Neural Networks (DNNs) are considered the state-of-the-art in many classification tasks, the question of their semantic generalizations has been raised. To address semantic interpretability of learned features, we introduce a novel idea of classification by re-generation based on variational autoencoder (VAE) in which a separate encoder-decoder pair of VAE is trained for each class. Moreover, the proposed architecture overcomes the scalability issue in current DNN networks as there is no need to re-train the whole network with the addition of new classes and it can be done for each class separately. We also introduce a criterion based on Kullback-Leibler divergence to reject doubtful examples. This rejection criterion should improve the trust in the obtained results and can be further exploited to reject adversarial examples.","2076-1465","978-9-0827-9701-5","10.23919/EUSIPCO.2018.8553530","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8553530","classification;variational auto encoder;regeneration;rejection","Probes;Training;Scalability;Image reconstruction;Semantics;Europe;Signal processing","encoding;learning (artificial intelligence);neural nets;pattern classification","deep neural networks;Kullback-Leibler divergence;current DNN networks;scalability issue;encoder-decoder pair;VAE;variational autoencoder;learned features;semantic interpretability;semantic generalizations;classification tasks;variational inference","","1","","12","","2 Dec 2018","","","IEEE","IEEE Conferences"
"Modeling Password Guessability via Variational Auto-Encoder","J. Wang; Y. Li; X. Chen; Y. Zhou","School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China","2021 IEEE 24th International Conference on Computer Supported Cooperative Work in Design (CSCWD)","28 May 2021","2021","","","348","353","Human-chosen text passwords remain an important form of authentication. To better understand properties of passwords chosen by users and password guessing models adopted by attackers, a lot of researches on password guessing are carried out. In recent studies, people try to guess passwords through deep learning models. However, existing deep learning-based guessing models (such as RNN and GAN) show unsatisfactory performance under limited guesses. In this paper, we propose PGVAE, a password guessing model based on variational autoencoder. The model can learn highly structured and continuous latent representations of passwords and then generate highquality candidate guesses. The effectiveness of PGVAE is verified in multiple leaked dataset. Results show that our model is capable of modeling the guessability of passwords, detecting vulnerable passwords and strengthening the security of authentication systems.","","978-1-7281-6597-4","10.1109/CSCWD49262.2021.9437859","National Natural Science Foundation of China(grant numbers:61632020,U1936209,62002353); Beijing Natural Science Foundation(grant numbers:4192067); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9437859","Password Guessing;Deep Learning;Variational Auto-Encoder","Deep learning;Conferences;Computational modeling;Authentication;Information filters;Collaborative work;Password","learning (artificial intelligence);message authentication;neural nets","deep learning-based guessing models;password guessing model;variational autoencoder;highquality candidate guesses;vulnerable passwords;modeling password guessability;variational auto-encoder;text passwords;deep learning models","","","","23","","28 May 2021","","","IEEE","IEEE Conferences"
"Variational Abnormal Behavior Detection With Motion Consistency","J. Li; Q. Huang; Y. Du; X. Zhen; S. Chen; L. Shao","School of Information Engineering, Nanchang University, Nanchang, China; School of Information Engineering, Nanchang University, Nanchang, China; AIM Laboratory, University of Amsterdam, Amsterdam, XH, The Netherlands; Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates; School of Computer Science and Engineering, Tianjin University of Technology, Tianjin, China; Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates","IEEE Transactions on Image Processing","7 Dec 2021","2022","31","","275","286","Abnormal crowd behavior detection has recently attracted increasing attention due to its wide applications in computer vision research areas. However, it is still an extremely challenging task due to the great variability of abnormal behavior coupled with huge ambiguity and uncertainty of video contents. To tackle these challenges, we propose a new probabilistic framework named variational abnormal behavior detection (VABD), which can detect abnormal crowd behavior in video sequences. We make three major contributions: (1) We develop a new probabilistic latent variable model that combines the strengths of the U-Net and conditional variational auto-encoder, which also are the backbone of our model; (2) We propose a motion loss based on an optical flow network to impose the motion consistency of generated video frames and input video frames; (3) We embed a Wasserstein generative adversarial network at the end of the backbone network to enhance the framework performance. VABD can accurately discriminate abnormal video frames from video sequences. Experimental results on UCSD, CUHK Avenue, IITB-Corridor, and ShanghaiTech datasets show that VABD outperforms the state-of-the-art algorithms on abnormal crowd behavior detection. Without data augmentation, our VABD achieves 72.24% in terms of AUC on IITB-Corridor, which surpasses the state-of-the-art methods by nearly 5%.","1941-0042","","10.1109/TIP.2021.3130545","National Natural Science Foundation of China(grant numbers:61963027,62020106004,61871016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9633236","Abnormal crowd behavior detection;conditional variational auto-encoder;optical flow network;motion loss;Wasserstein generative adversarial network","Feature extraction;Probabilistic logic;Video sequences;Image reconstruction;Anomaly detection;Training;Optical losses","computer vision;feature extraction;image motion analysis;image sequences;neural nets;probability;video signal processing","VABD;video sequences;probabilistic latent variable model;conditional variational autoencoder;motion consistency;abnormal crowd behavior detection;variational abnormal behavior detection;computer vision research areas;optical flow network;Wasserstein generative adversarial network","","","","49","IEEE","2 Dec 2021","","","IEEE","IEEE Journals"
"Towards Predictive Analysis on Disease Progression: A Variational Hawkes Process Model","Z. Sun; Z. Sun; W. Dong; J. Shi; Z. Huang","Zhejiang University, Hangzhou, China; Zhejiang Lab, Hangzhou, China; Zhejiang Lab, Hangzhou, China; Zhejiang Lab, Hangzhou, China; Zhejiang University, Hangzhou, China","IEEE Journal of Biomedical and Health Informatics","5 Nov 2021","2021","25","11","4195","4206","Massively available longitudinal data about long-term disease trajectories of patients provides a golden mine for the understanding of disease progression and efficient health service delivery. It calls for quantitative modeling of disease progression, which is a tricky problem due to the complexity of the disease progression process as well as the irregularity of time documented in trajectories. In this study, we tackle the problem with the goal of predictively analyzing disease progression. Specifically, we propose a novel Variational Hawkes Process (VHP) model to generalize disease progression and predict future patient states based on the clinical observational data of past disease trajectories. First, Hawkes Process captures the intensity of irregular visits in a trajectory documented to medical facilities and controls the aforementioned information flowing into future visits. Thereafter, the captured intensity is incorporated into a Variational Auto-Encoder to generate the representation of the future partial disease trajectory for a target patient in a predictive manner. To further improve the prediction performance, we equip the proposed model with a disease trajectory discriminator to distinguish the generated trajectories from real ones. We evaluate the proposed model on two public datasets from the MIMIC-III database pertaining to heart failure and sepsis patients, respectively, and one real-world dataset from a Chinese hospital pertaining to heart failure patients with multiple admissions. Experimental results demonstrate that the proposed model significantly outperforms state-of-the-art baselines, and may derive a set of practical implications that can benefit a wide spectrum of management and applications on disease progression.","2168-2208","","10.1109/JBHI.2021.3101113","National Natural Science Foundation of China(grant numbers:61672450,Alibaba Cloud); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9502579","Disease progression;disease trajectory;electronic health records;hawkes process;variational auto encoder","Diseases;Trajectory;Predictive models;Hidden Markov models;Biological system modeling;Electronic medical records","cardiology;diseases;health care;medical administrative data processing;medical computing;neural nets;patient diagnosis","disease progression;disease trajectory discriminator;variational Hawkes process model;partial disease trajectory;VHP model;variational autoencoder;MIMIC-III database;sepsis patients;heart failure patients","Databases, Factual;Disease Progression;Heart Failure;Humans","","","51","IEEE","30 Jul 2021","","","IEEE","IEEE Journals"
"Nonparametric Variational Auto-Encoders for Hierarchical Representation Learning","P. Goyal; Z. Hu; X. Liang; C. Wang; E. P. Xing; C. Mellon",Carnegie Mellon University; Petuum Inc.; Carnegie Mellon University; Petuum Inc.; Petuum Inc.; NA,"2017 IEEE International Conference on Computer Vision (ICCV)","25 Dec 2017","2017","","","5104","5112","The recently developed variational autoencoders (VAEs) have proved to be an effective confluence of the rich representational power of neural networks with Bayesian methods. However, most work on VAEs use a rather simple prior over the latent variables such as standard normal distribution, thereby restricting its applications to relatively simple phenomena. In this work, we propose hierarchical non-parametric variational autoencoders, which combines tree-structured Bayesian nonparametric priors with VAEs, to enable infinite flexibility of the latent representation space. Both the neural parameters and Bayesian priors are learned jointly using tailored variational inference. The resulting model induces a hierarchical structure of latent semantic concepts underlying the data corpus, and infers accurate representations of data instances. We apply our model in video representation learning. Our method is able to discover highly interpretable activity hierarchies, and obtain improved clustering accuracy and generalization capacity based on the learned rich representations.","2380-7504","978-1-5386-1032-9","10.1109/ICCV.2017.545","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8237807","","Bayes methods;Data models;Semantics;Neural networks;Standards;Decoding","Bayes methods;image representation;inference mechanisms;learning (artificial intelligence);neural nets;pattern clustering;trees (mathematics);video coding","latent representation space;neural parameters;Bayesian priors;tailored variational inference;latent semantic concepts;video representation learning;nonparametric variational auto-encoders;hierarchical representation learning;neural networks;Bayesian methods;nonparametric variational autoencoders;tree-structured Bayesian nonparametric priors","","25","","21","","25 Dec 2017","","","IEEE","IEEE Conferences"
"Privacy-Aware Communication over a Wiretap Channel with Generative Networks","E. Erdemir; P. L. Dragotti; D. Gündüz","Department of Electrical and Electronic Engineering, Imperial College, London, UK; Department of Electrical and Electronic Engineering, Imperial College, London, UK; Department of Electrical and Electronic Engineering, Imperial College, London, UK","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","2989","2993","We study privacy-aware communication over a wiretap channel using end-to-end learning. Alice wants to transmit a source signal to Bob over a binary symmetric channel, while passive eavesdropper Eve tries to infer some sensitive attribute of Alice’s source based on its overheard signal. Since we usually do not have access to true distributions, we propose a data-driven approach using variational autoencoder (VAE)-based joint source channel coding (JSCC). We show through simulations with the colored MNIST dataset that our approach provides high reconstruction quality at the receiver while confusing the eavesdropper about the latent sensitive attribute, which consists of the color and thickness of the digits. Finally, we consider a parallel-channel scenario, and show that our approach arranges the information transmission such that the channels with higher noise levels at the eavesdropper carry the sensitive information, while the non-sensitive information is transmitted over more vulnerable channels.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9747068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747068","Privacy-utility trade-off;wiretap channel;physical layer security;generative networks;variational autoencoders","Wireless communication;Wireless sensor networks;Simulation;Conferences;Receivers;Information processing;Signal processing","channel coding;combined source-channel coding;data privacy;radio networks;telecommunication security","wiretap channel;end-to-end learning;source signal;binary symmetric channel;Alice's source;overheard signal;data-driven approach;variational autoencoder-based joint source channel coding;colored MNIST dataset;latent sensitive attribute;parallel-channel scenario;sensitive information;vulnerable channels;privacy-aware communication;generative networks;variational autoencoder;joint source channel coding;receivers;passive eavesdropper eve","","","","24","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Mixture of Inference Networks for VAE-Based Audio-Visual Speech Enhancement","M. Sadeghi; X. Alameda-Pineda","Multispeech Team, Inria Research Centre Nancy Grand Est, Villers-les-Nancy, France; Perception Team, Inria Centre de Recherche Grenoble Rhone-Alpes, Montbonnot, France","IEEE Transactions on Signal Processing","2 Apr 2021","2021","69","","1899","1909","We address unsupervised audio-visual speech enhancement based on variational autoencoders (VAEs), where the prior distribution of clean speech spectrogram is simulated using an encoder-decoder architecture. At enhancement (test) time, the trained generative model (decoder) is combined with a noise model whose parameters need to be estimated. The initialization of the latent variables describing the generative process of the clean speech via the decoder, is crucial, as the overall inference problem is non-convex. This is usually done by using the output of the trained encoder given the noisy audio and clean visual data as input. Current audio-visual VAE models do not provide an effective initialization because the two modalities are tightly coupled (concatenated) in the associated architectures. To overcome this issue, we introduce the mixture of inference networks variational autoencoder (MIN-VAE). Two encoder networks input, respectively, audio and visual data, and the posterior of the latent variables is modeled as a mixture of two Gaussian distributions output from each encoder. The mixture variable is also latent, and therefore learning the optimal balance between the audio and visual encoders is unsupervised as well. By training a shared decoder, the overall network learns to adaptively fuse the two modalities. Moreover, at test time, the visual encoder, taking (clean) visual data, is used for initialization. A variational inference approach is derived to train the proposed model. Thanks to the novel inference procedure and the robust initialization, the MIN-VAE exhibits superior performance than the standard audio-only as well as audio-visual counterparts.","1941-0476","","10.1109/TSP.2021.3066038","ANR ML3RI(grant numbers:ANR-19-CE33-0008-01); ANR-3IA MIAI(grant numbers:ANR-19-P3IA-0003); H2020 SPRING(grant numbers:GA 871245); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380713","Audio-visual speech enhancement;generative models;variational auto-encoder;mixture model","Speech enhancement;Visualization;Spectrogram;Decoding;Noise measurement;Neural networks;Data models","approximation theory;audio signal processing;Bayes methods;decoding;encoding;filtering theory;Gaussian distribution;Gaussian processes;inference mechanisms;learning (artificial intelligence);speech enhancement;speech recognition","inference problem;trained encoder;noisy audio;clean visual data;audio-visual VAE models;effective initialization;generative process;noise model whose parameters;trained generative model;enhancement time;encoder-decoder architecture;clean speech spectrogram;VAEs;variational autoencoders;VAE-based audio-visual speech enhancement;audio-visual counterparts;standard audio-only;novel inference procedure;variational inference approach;visual encoder;shared decoder;visual encoders;audio encoders;mixture variable;Gaussian distributions output;latent variables;audio data;encoder networks input;MIN-VAE;inference networks variational autoencoder","","2","","41","IEEE","17 Mar 2021","","","IEEE","IEEE Journals"
"A New Deep Stacked Architecture for Multi-Fault Machinery Identification With Imbalanced Samples","H. Karamti; M. M. A. Lashin; F. M. Alrowais; A. M. Mahmoud","MIRACL Laboratory, Higher Institute of Computer Science and Multimedia of Sfax (ISIMS), University of Sfax, Sfax, Tunisia; Mechanical Engineering Department, Faculty of Engineering Shoubra, Benha University, Banha, Egypt; Computer Sciences Department, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia; Department of Computer Science, Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt","IEEE Access","20 Apr 2021","2021","9","","58838","58851","Effective intelligent fault diagnosis of rotating machinery using its vibrational signals has a considerable influence on certain analysis factors such as the reliability, performance, and productivity of a variety of modern manufacturing machines. Traditional intelligent approaches lack generalization schemes and add the burden of extracting features from data-driven cases. On the other hand, the Deep Learning (DL) studies have reported capabilities higher than the expectations of the researchers' objectives. In this context, this paper proposes a new deep architecture based on Stacked Variant Autoencoders for multi-fault machinery identification with imbalanced samples. The proposed model starts with a Variational Autoencoder (VAE) for facilitating data augmentation of small and imbalanced data samples using Gaussian distribution. After the preparation of suitable samples based on quality and size, the preprocessed vibration signals obtained are injected into the deep framework. The proposed deep architecture contains two subsequent unsupervised Sparse Autoencoders (SAE) with a penalty term that helps in acquiring more abstract and essential features as well as avoiding redundancy. The output of the second SAE is integrated on a supervised Logistic Regression (LR) with 10 classes. This is utilized for the proposed classifier training to achieve accurate fault identification. Experimental results show the efficiency of the proposed model which achieved an accuracy of 93.2%. In addition, for extensive comparative analysis issue, the Generative Adversarial Network (GAN) and triNetwork Generative Adversarial Network (tnGAN) were both implemented on the vibrational signal data, where the proposed method reported better results in terms of training and testing time and overall accuracy.","2169-3536","","10.1109/ACCESS.2021.3071796","Deanship of Scientific Research, Princess Nourah bint Abdulrahman University, through the Program of Research Project Funding After Publication(grant numbers:41-PRFA-P-38); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9399084","Fault diagnosis;imbalanced samples;logistic regression;rotating machinery;sparse autoencoders;variational autoencoder;vibrational signals","Feature extraction;Vibrations;Deep learning;Fault diagnosis;Data models;Training;Principal component analysis","fault diagnosis;feature extraction;Gaussian distribution;learning (artificial intelligence);machinery;neural nets;pattern classification;production engineering computing;regression analysis;vibrational signal processing","deep architecture;subsequent unsupervised Sparse Autoencoders;abstract features;accurate fault identification;vibrational signal data;new Deep Stacked architecture;multifault machinery identification;imbalanced samples;effective intelligent fault diagnosis;modern manufacturing machines;data-driven cases;Stacked Variant Autoencoders;data augmentation;imbalanced data samples;preprocessed vibration signals","","1","","52","CCBY","8 Apr 2021","","","IEEE","IEEE Journals"
"Towards speech enhancement using a variational U-Net architecture","E. J. Nustede; J. Anemüller","Dept. med. Physics & Acoustics and Cluster of Excellence Hearing4all, Carl von Ossietzky University Oldenburg, Computational Audition Group, Oldenburg, Germany; Dept. med. Physics & Acoustics and Cluster of Excellence Hearing4all, Carl von Ossietzky University Oldenburg, Computational Audition Group, Oldenburg, Germany","2021 29th European Signal Processing Conference (EUSIPCO)","8 Dec 2021","2021","","","481","485","We investigate the viability of a variational U-Net architecture for denoising of single-channel audio data. Deep network speech enhancement systems commonly aim to estimate filter masks, or opt to work on the waveform signal, potentially neglecting relationships across higher dimensional spectro-temporal features. We study the adoption of a probabilistic (variational) bottleneck into the classic U-Net architecture for direct spectral reconstruction. Evaluation of several ablation network variants is carried out using signal-to-distortion ratio and perceptual measures, on audio data that includes known and unknown noise types as well as reverberation. Our experiments show that the residual (skip) connections in the proposed system are a prerequisite for successful spectral reconstruction, i.e., without filter mask estimation. Results show, on average, an advantage of the proposed variational U-Net architecture over its classic, non-variational version in signal enhancement performance under reverberant conditions of 0.31 and 6.98 in PESQ and STOI scores, respectively. Anecdotal evidence points to improved suppression of impulsive noise sources with the variational U-Net compared to the recurrent mask estimation network baseline.","2076-1465","978-9-0827-9706-0","10.23919/EUSIPCO54536.2021.9616114","Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)(grant numbers:352015383,SFB 1330/B3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616114","Speech enhancement;U-Net architecture;variational autoencoder;deep learning;audio source separation","Training;Source separation;Estimation;Speech enhancement;Probabilistic logic;Data models;Reverberation","filtering theory;probability;signal denoising;signal reconstruction;speech enhancement","single-channel audio data;deep network speech enhancement systems;waveform signal;higher dimensional spectro-temporal features;probabilistic bottleneck;direct spectral reconstruction;ablation network variants;signal-to-distortion ratio;spectral reconstruction;filter mask estimation;signal enhancement performance;recurrent mask estimation network baseline;PESQ;STOI;variational U-Net architecture","","","","22","","8 Dec 2021","","","IEEE","IEEE Conferences"
"Generalized Autoencoder for Volumetric Shape Generation","Y. Guan; T. Jahan; O. van Kaick","School of Computer Science, Carleton University, Canada; School of Computer Science, Carleton University, Canada; School of Computer Science, Carleton University, Canada","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","1082","1088","We introduce a 3D generative shape model based on the generalized autoencoder (GAE). GAEs learn a manifold latent space from data relations explicitly provided during training. In our work, we train a GAE for volumetric shape generation from data similarities derived from the Chamfer distance, and with a loss function which is the combination of the traditional autoencoder loss and the GAE loss. We show that this shape model is able to learn more meaningful structures for the latent manifolds of different categories of shapes, and provides better interpolations between shapes when compared to previous approaches such as autoencoders and variational autoencoders.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9151074","","Shape;Three-dimensional displays;Training;Solid modeling;Manifolds;Interpolation;Decoding","data analysis;learning (artificial intelligence);neural nets;solid modelling","3D generative shape model;generalized autoencoder;manifold latent space;data relations;volumetric shape generation;data similarities;loss function;traditional autoencoder loss;GAE loss;latent manifolds;variational autoencoders","","6","","25","","28 Jul 2020","","","IEEE","IEEE Conferences"
"An Efficient Image Categorization Method With Insufficient Training Samples","L. Lin; B. Liu; X. Zheng; Y. Xiao","School of Automation, Guangdong University of Technology, Guangzhou, China; School of Automation, Guangdong University of Technology, Guangzhou, China; School of Automation, Guangdong University of Technology, Guangzhou, China; School of Computer, Guangdong University of Technology, Guangzhou, China","IEEE Transactions on Cybernetics","19 May 2022","2022","52","5","3244","3260","Image classification is an important part of pattern recognition. With the development of convolutional neural networks (CNNs), many CNN methods are proposed, which have a large number of samples for training, which can have high performance. However, there may exist limited samples in some real-world applications. In order to improve the performance of CNN learning with insufficient samples, this article proposes a new method called the classifier method based on a variational autoencoder (CFVAE), which is comprised of two parts: 1) a standard CNN as a prior classifier and 2) a CNN based on variational autoencoder (VAE) as a posterior classifier. First, the prior classifier is utilized to generate the prior label and information about distributions of latent variables; and the posterior classifier is trained to augment some latent variables from regularized distributions to improve the performance. Second, we also present the uniform objective function of CFVAE and put forward an optimization method based on the stochastic gradient variational Bayes method to solve the objective model. Third, we analyze the feasibility of CFVAE based on Hoeffding’s inequality and Chernoff’s bounding method. This analysis indicates that the latent variables augmentation method based on regularized latent variables distributions can generate samples fitting well with the distribution of data such that the proposed method can improve the performance of CNN with insufficient samples. Finally, the experiments manifest that our proposed CFVAE can provide more accurate performance than state-of-the-art methods.","2168-2275","","10.1109/TCYB.2020.3011165","Natural Science Foundation of China(grant numbers:61876044,61672169); Guangdong Natural Science Foundation(grant numbers:2020A1515010670,2020A1515011501); Science and Technology Planning Project of Guangzhou(grant numbers:202002030141); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9165163","Convolutional neural networks (CNNs);image recognition;insufficient samples;variational autoencoder (VAE)","Training;Gallium nitride;Decoding;Neural networks;Task analysis;Computer architecture;Learning systems","Bayes methods;convolutional neural nets;feature extraction;image classification;image representation;learning (artificial intelligence)","efficient image categorization method;insufficient training samples;image classification;pattern recognition;convolutional neural networks;CNN methods;real-world applications;insufficient samples;classifier method;variational autoencoder;CFVAE;standard CNN;prior classifier;posterior classifier;prior label;regularized distributions;uniform objective function;optimization method;stochastic gradient variational Bayes method;Chernoff's bounding method;latent variables augmentation method;regularized latent variables distributions;accurate performance","Bayes Theorem;Neural Networks, Computer","3","","65","IEEE","11 Aug 2020","","","IEEE","IEEE Journals"
"3D Face Reprentation and Reconstruction with Multi-scale Graph Convolutional Autoencoders","C. Yuan; K. Li; Y. -K. Lai; Y. Liu; J. Yang","Tianjin University, Tianjin, China; Tianjin University, Tianjin, China; Cardiff University, Wales, UK; Tsinghua University, Beijing, China; Tianjin University, Tianjin, China","2019 IEEE International Conference on Multimedia and Expo (ICME)","5 Aug 2019","2019","","","1558","1563","Effective representation and reconstruction for human faces are very important in many applications. Existing linear representation methods cannot reconstruct high quality 3D faces with details, while the newest non-linear representation method is less suitable for real shapes since spectral decompositions are unstable across different graphs. To address these problems, we propose a multi-scale graph convolutional autoencoder for face representation and reconstruction. Our autoencoder uses graph convolution, which is easily trained for the data with graph structures and can be used for other deformable models. Our model can also be used for variational training to generate high quality face shapes. Experimental results demonstrate that our model can generate more plausible, complex, and stable 3D shapes, and achieves higher quality face reconstruction compared with state-of-the-art methods.","1945-788X","978-1-5386-9552-4","10.1109/ICME.2019.00269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8784723","Face representation;face reconstruction;autoencoder;mesh;variational training","Face;Three-dimensional displays;Shape;Convolution;Solid modeling;Training;Mouth","convolutional neural nets;face recognition;graph theory;image coding;image reconstruction;image representation;stereo image processing","3D face reprentation;multiscale graph convolutional autoencoder;effective representation;human faces;nonlinear representation method;face representation;graph convolution;graph structures;face shapes;face reconstruction;spectral decompositions","","2","","20","","5 Aug 2019","","","IEEE","IEEE Conferences"
"Deep generative autoencoder for low-dimensional embeding extraction from single-cell RNAseq data","S. Sun; Y. Liu; X. Shang","National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, Northwestern Polytechnical University, Xi'an, Shaanxi, People's Republic of China; School of Computer Science, Northwestern Polytechnical University, Xi'an, Shaanxi, P.R. China; National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, Northwestern Polytechnical University, Xi'an, Shaanxi, People's Republic of China","2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","6 Feb 2020","2019","","","1365","1372","Single-cell RNA sequencing (scRNAseq) can reveal biological diversity at the cellular level that are unexplored by bulk RNA sequencing (RNAseq), but they suffer from the excessive zero expression counts and the limitation of the scalability in practice. Here, we propose a non-linear generative autoencoder based method, scSVA, relying on an integration of variational autoencoder and dropout imputations. Specifically, scSVA automatically identifies the dropouts and recovery these values only to avoid introducing new biases. Then, scSVA utilizes stochastic optimization and deep neural network to extract the low-dimensional embedding from gene expression levels. We illustrate the benefits of scSVA through in-depth real analyses of six published scRNAseq data sets. scSVA is up to 1.3 times more powerful cell clustering accuracy than existing approaches. The high power of scSVA allows us to identify new cell types that reveal new biology from scRNAseq data that otherwise cannot be revealed by existing approaches.","","978-1-7281-1867-3","10.1109/BIBM47256.2019.8983289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8983289","Dimensionality reduction;Cell types;Single cell;Variational autoencoder","","bioinformatics;cellular biophysics;data analysis;genetics;genomics;molecular biophysics;neural nets;pattern clustering;RNA;stochastic processes","gene expression levels;scSVA;cell types;low-dimensional embeding extraction;single-cell RNAseq data;single-cell RNA sequencing;cellular level;bulk RNA sequencing;deep neural network;nonlinear generative autoencoder;cell clustering;stochastic optimization","","1","","43","","6 Feb 2020","","","IEEE","IEEE Conferences"
"Semi-Supervised EEG Signals Classification System for Epileptic Seizure Detection","A. M. Abdelhameed; M. Bayoumi","Center for Advanced Computer Studies, University of Louisiana at Lafayette, Lafayette, USA; Department of Electrical and Computer Engineering, University of Louisiana at Lafayette, Lafayette, USA","IEEE Signal Processing Letters","16 Dec 2019","2019","26","12","1922","1926","In the past few decades, measuring and recording the brain electrical activities using Electroencephalogram (EEG) has become a standout amongst the tools utilized for neurological disorders' diagnosis, especially seizure detection. In this letter, a novel epileptic seizure detection system based on classifying raw EEG signals' recordings, eliminating the overhead of engineered feature extraction, is proposed. The system employs a mixing of unsupervised and supervised deep learning utilizing a one-dimensional convolutional variational autoencoder. To ascertain the robustness of the system against classifying unseen data, the evaluation of the proposed system is done using k-fold cross-validation. The classification results between normal and ictal cases have achieved a 100% accuracy while the classification results between the normal, inter-ictal and ictal cases accomplished a 99% overall accuracy which makes our system one of the most efficient among other state-of-the-art systems.","1558-2361","","10.1109/LSP.2019.2953870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903437","Classification;cross-validation;deep learning;epileptic seizure detection;feature extraction;variational autoencoder","Electroencephalography;Feature extraction;Deep learning;Epilepsy;Training","convolutional neural nets;electroencephalography;feature extraction;medical disorders;medical signal processing;patient monitoring;signal classification;supervised learning;unsupervised learning;variational techniques","inter-ictal case;semisupervised EEG signals classification;ictal cases;k-fold cross-validation;one-dimensional convolutional variational autoencoder;deep learning;neurological disorder diagnosis;Electroencephalogram;epileptic seizure detection","","16","","24","IEEE","18 Nov 2019","","","IEEE","IEEE Journals"
"Discrete Auto-regressive Variational Attention Models for Text Modeling","X. Fang; H. Bai; J. Li; Z. Xu; M. Lyu; I. King","Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; School of Computer Science and Engineering, Harbin Institute of Technology, Shenzhen; Department of Computer Science and Engineering, The Chinese University of Hong Kong","2021 International Joint Conference on Neural Networks (IJCNN)","23 Sep 2021","2021","","","1","8","Variational autoencoders (VAEs) have been widely applied for text modeling. In practice, however, they are troubled by two challenges: information underrepresentation and posterior collapse. The former arises as only the last hidden state of LSTM encoder is transformed into the latent space, which is generally insufficient to summarize the data. The latter is a longstanding problem during the training of VAEs as the optimization is trapped to a disastrous local optimum. In this paper, we propose Discrete Auto-regressive Variational Attention Model (DAVAM) to address the challenges. Specifically, we introduce an auto-regressive variational attention approach to enrich the latent space by effectively capturing the semantic dependency from the input. We further design discrete latent space for the variational attention and mathematically show that our model is free from posterior collapse. Extensive experiments on language modeling tasks demonstrate the superiority of DAVAM against several VAE counterparts. Code will be released.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9534375","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534375","Text Modeling;Information Underrepresentation;Posterior Collapse","Training;Codes;Semantics;Neural networks;Network architecture;Transformers;Mathematical models","autoregressive processes;learning (artificial intelligence);recurrent neural nets;text analysis","semantic dependency;DAVAM;variational autoencoders;discrete autoregressive variational attention models;VAE;autoregressive variational attention approach;language modeling task;discrete latent space;LSTM encoder;posterior collapse;information underrepresentation;text modeling","","","","32","IEEE","23 Sep 2021","","","IEEE","IEEE Conferences"
"Variational Autoencoded Compositional Pattern Generative Adversarial Network for Handwritten Super Resolution Image Generation","C. G. Turhan; H. S. Bilge","Computer Engineering Department Faculty of Engineering, Gazi University, Ankara, Turkey; Electric-Electronic Engineering Department Faculty of Engineering, Gazi University, Ankara, Turkey","2018 3rd International Conference on Computer Science and Engineering (UBMK)","9 Dec 2018","2018","","","564","568","Since generative adversarial training has been decleared as one of the most exciting topics of the last 10 years by the pioneers, many researchers have focused on the Generative Adversarial Network (GAN) in their studies. On the otherhand, Variational Autoencoders (VAE) had gain autoencoders' popularity back. Due to some restrictions of GAN models and their lack of inference mechanism, hybrid models of GAN and VAE have emerged for image generation problem in nowadays. With the influence of these views and improvements, we have focused on addressing not only generating synthetic handwritten images but also their high-resolution version. For these tasks, Compositional Pattern Producing Networks (CPPN), VAE and GAN models are combined inspired by an existing model with some modification of its objective function. With this model, the idea behind the inspired study for generating high-resolution images are combined with the feature-wise reconstruction objective of a VAE/GAN hybrid model instead of pixel-like reconstruction approach of traditional VAE. For evaluating the model efficiency, our VAE/CPGAN model is compared with its basis models (GAN, VAE and VAE/GAN) and inspired model accoording to inception score. In this study, it is clearly seen that the proposed model is able to converge much faster than compared models for modeling the underlying distribution of handwritten image data.","","978-1-5386-7893-0","10.1109/UBMK.2018.8566539","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8566539","variational autoencoders;generative models;adversarial training;image generation;synthetic handwritten images;high-resolution images","Gallium nitride;Image reconstruction;Training;Mathematical model;Generative adversarial networks;Data models;Adaptation models","encoding;handwriting recognition;image reconstruction;image resolution;learning (artificial intelligence);neural nets","handwritten super resolution image generation;generative adversarial training;feature-wise reconstruction objective;handwritten image data;variational autoencoded compositional pattern generative adversarial network;inference mechanism;CPGAN model;VAE-GAN hybrid model;CPPN;pixel-like reconstruction approach","","","","13","","9 Dec 2018","","","IEEE","IEEE Conferences"
"Clustering of Astronomical Transient Candidates Using Deep Variational Embedding","N. Astorga; P. Huijse; P. A. Estévez; F. Förster","Department of Electrical Engineering, Universidad de Chile, Santiago, Chile; Department of Electrical Engineering, Universidad de Chile, Santiago, Chile; Department of Electrical Engineering, Universidad de Chile, Santiago, Chile; Center for Mathematical Modeling, Universidad de Chile, Santiago, Chile","2018 International Joint Conference on Neural Networks (IJCNN)","14 Oct 2018","2018","","","1","8","The exponential growth of the data collected by telescopes have turned astronomy into a data-drive science. The detection of astronomical transient events, short-lived and bright phenomena such as the Supernovae, is currently a main science driver of many astronomical surveys. There is an opportunity for the application of machine learning methods for the automatic detection of astronomical transients.In this paper we focus on the unsupervised learning case to perform an exploratory analysis on a dataset of 1,250,000 astronomical transient candidates from the High Cadence Transient Survey. Our contributions can be summarized in 1) The application of Deep Variational Embedding for latent space clustering of a large database of transient candidates obtaining a clustering accuracy of 95.33% and 2) The proposal of an auto-regularization term as a novel approach to solve the common problem of over-regularization in variational autoencoders, we show that using this term not only improves the convergence of the algorithm but also increases the clustering accuracy and reconstruction quality.","2161-4407","978-1-5090-6014-6","10.1109/IJCNN.2018.8489358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489358","autoencoder;variational inference;clustering;astronomical images;transients","Transient analysis;Data models;Neural networks;Decoding;Training;Image reconstruction;Feature extraction","astronomical image processing;astronomical surveys;astronomical telescopes;astronomy computing;data analysis;image coding;pattern clustering;unsupervised learning","Deep Variational Embedding;data-drive science;astronomical transient events;main science driver;astronomical surveys;automatic detection;astronomical transients;unsupervised learning case;High Cadence Transient Survey;latent space clustering;clustering accuracy;astronomical transient candidates;machine learning methods;reconstruction quality","","","","24","","14 Oct 2018","","","IEEE","IEEE Conferences"
"Joint Source-Channel Coding of Gaussian sources over AWGN channels via Manifold Variational Autoencoders","Y. M. Saidutta; A. Abdi; F. Fekri","Dept. of ECE, Georgia Institute of Technology, Atlanta, GA, USA; Dept. of ECE, Georgia Institute of Technology, Atlanta, GA, USA; Dept. of ECE, Georgia Institute of Technology, Atlanta, GA, USA","2019 57th Annual Allerton Conference on Communication, Control, and Computing (Allerton)","5 Dec 2019","2019","","","514","520","In this paper, we give a new scheme for Joint Source-Channel Coding of Gaussian sources over AWGN channels. We present a novel VAE architecture that exploits the manifold nature of joint source-channel coding. Since the projection onto a complex manifold is a highly discontinuous function we split the encoder into two arms and a selector. This design combined with the power of data-driven deep neural networks allows us to efficiently train an encoder-decoder system end-to-end. The scheme achieves state of the art performance for five out of the seven configurations tested upon and match the state of the art for one of the other configurations for almost all channel conditions tested upon. Further, without providing any expert prior on the optimum JSCC encoder, the proposed method learns an encoding function that is similar to the ones proposed and found by the researchers in the past three decades via heuristic approaches or complex variational analysis for simple configurations. It is also able to find excellent encoders and decoders for those source channel dimensions where past works have been unable to find any good solutions. Finally, we show that the system is also robust to changes in channel conditions.","","978-1-7281-3151-1","10.1109/ALLERTON.2019.8919888","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8919888","","Channel coding;Neural networks;Decoding;Optimization;AWGN channels;Signal to noise ratio","AWGN channels;combined source-channel coding;learning (artificial intelligence);neural nets;telecommunication computing","source channel dimensions;channel conditions;encoder-decoder system end-to-end;Gaussian sources;joint source-channel coding;manifold variational autoencoders;AWGN channels","","5","","25","","5 Dec 2019","","","IEEE","IEEE Conferences"
"Discrete Memory Addressing Variational Autoencoder for Visual Concept Learning","Y. Min; H. Su; J. Zhu; B. Zhang","dept. computer science and technology, Tsinghua University, Beijing, China; dept. computer science and technology, Tsinghua University, Beijing, China; dept. computer science and technology, Tsinghua University, Beijing, China; dept. computer science and technology, Tsinghua University, Beijing, China","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","8","A substantial aspect of general intelligence is the ability to summarize basic building blocks from various high-level concepts. Artificial vision systems with such hierarchical property can not only perform accurate reasoning for complex observations, but also learn useful low-level knowledge shared across scenes. To achieve this goal, we propose a discrete memory addressing VAE model (DM-VAE) for explicitly memorizing and reasoning about shared primitives in images. A time-persistence memory module is used to store the learned abstract knowledge and to interact with the generative model. The model decides what to pay attention to at each step, and constructs the primitive library automatically as the learning progresses in a fully unsupervised setting. While performing inference, the model attempts to interpret a new observation as a combination of previously learned elements. We further derive a proper variational lower bound which can be optimized efficiently. We conduct visual comprehension experiments on images and demonstrate that our model is able to search, identify, and memorize semantically meaningful primitive concepts.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9206745","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206745","deep generative model;hierarchical Bayesian model;concept learning;deep model with memory","Generators;Atmospheric modeling;Libraries;Neural networks;Computer science;Data models;Random variables","computer vision;inference mechanisms;unsupervised learning","discrete memory;learned abstract knowledge;time-persistence memory module;DM-VAE;artificial vision systems;general intelligence;visual concept learning;variational autoencoder","","","","29","","28 Sep 2020","","","IEEE","IEEE Conferences"
"Predictive Coding with Topographic Variational Autoencoders","T. A. Keller; M. Welling","UvA-Bosch Delta Lab, University of Amsterdam; UvA-Bosch Delta Lab, University of Amsterdam","2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)","24 Nov 2021","2021","","","1086","1091","Predictive coding is a model of visual processing which suggests that the brain is a generative model of input, with prediction error serving as a signal for both learning and attention. In this work, we show how the equivariant capsules learned by a Topographic Variational Autoen-coder can be extended to fit within the predictive coding framework by treating the slow rolling of capsule activations as the forward prediction operator. We demonstrate quantitatively that such an extension leads to improved sequence modeling compared with both topographic and non-topographic baselines, and that the resulting forward predictions are qualitatively more coherent with the provided partial input transformations.","2473-9944","978-1-6654-0191-3","10.1109/ICCVW54120.2021.00127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9607394","","Visualization;Computer vision;Conferences;Computational modeling;Predictive models;Predictive coding;Brain modeling","brain;learning (artificial intelligence)","brain;topographic variational autoencoders;prediction error;generative model;visual processing;nontopographic baselines;sequence modeling;forward prediction operator;capsule activations;predictive coding framework;equivariant capsules;learning","","","","53","IEEE","24 Nov 2021","","","IEEE","IEEE Conferences"
"Anomaly Detection Using Autoencoder With Feature Vector Frequency Map","Y. -G. Kim; T. -H. Park","Industrial AI Research Center, Chungbuk National University, Cheongju, South Korea; Department of Intelligent Systems and Robotics, Chungbuk National University, Cheongju, South Korea","IEEE Access","24 May 2021","2021","9","","73808","73817","Anomaly detection uses various machine learning techniques to identify and classify defective data on the production line. The autoencoder-based anomaly detection method is an unsupervised method that classifies abnormal samples using an autoencoder trained only from normal samples and is useful in environments where it is difficult to obtain abnormal samples. This method uses an abnormal score based on the reconstruction loss function, making it difficult to detect defects, such as stains, having a similar texture to a normal sample. To solve this problem, we propose an anomaly detection method using a vector quantized variational autoencoder and a feature vector frequency map. We use the prototype vector histogram and its frequency for anomaly detection instead of the reconstruction loss function. The prototype vector histogram is obtained from the vector quantized variational autoencoder's codebook in the training stage. The feature vector frequency map of the input image is generated using the prototype vector histogram in the inference stage. We calculated the abnormal score using the generated frequency map and classified the abnormal samples. The experimental results showed that the proposed method has a higher Area Under Receiver Operating Characteristics (AUROC) than the previous method in stain and scratch defects.","2169-3536","","10.1109/ACCESS.2021.3080330","Ministry of Science and Information and Communications Technology (ICT) (MSIT), South Korea, through the Grand Information Technology Research Center support program supervised by the Institute for Information and Communications Technology Planning and Evaluation (IITP)(grant numbers:IITP-2021-2020-0-01462); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9431179","Anomaly detection;automatic optical inspection;deep learning","Anomaly detection;Feature extraction;Prototypes;Image reconstruction;Training;Inspection;Histograms","image classification;inference mechanisms;neural nets","abnormal score;reconstruction loss function;feature vector frequency map;prototype vector histogram;autoencoder-based anomaly detection method;unsupervised method;abnormal sample classification;inference stage;vector quantized variational autoencoder;area under receiver operating characteristics;AUROC;defect detection","","2","","29","CCBY","14 May 2021","","","IEEE","IEEE Journals"
"Compression Techniques for MIMO Channels in FDD Systems","V. Rizzello; H. Zhang; M. Joham; W. Utschick","Department of Electrical and Computer Engineering, Technical University of Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Germany","2022 IEEE Data Science and Learning Workshop (DSLW)","12 Jul 2022","2022","","","1","6","In this work, we present an innovative application of transformers and vector quantized variational autoencoders (VQ-VAE) to compress multiple-input-multiple-output (MIMO) channels in frequency-division-duplex (FDD) systems. Existing works consider multiple-input-single-output (MISO) channels across all frequencies (subcarriers) of a certain bandwidth, where high compression ratios can be achieved due to the structure of the channels across the frequency domain, or due to their sparsity in the time domain. With this work, we take into account that in reality, the channels cannot be observed for all the subcarriers inside the bandwidth, therefore, it is crucial to compress the channels considering a single subcarrier observation. Simulation results demonstrate that transformers can be used to construct efficient autoencoders with a reduced amount of parameters. Furthermore, we show that embedding the quantization during the training, using the VQ-VAE framework, helps to achieve better performances compared to a post-training quantization based on standard techniques.","","978-1-6654-5426-1","10.1109/DSLW53931.2022.9820270","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9820270","Transformers;autoencoders;vector quantized variational autoencoders;MIMO systems;FDD systems","Training;Time-frequency analysis;Quantization (signal);Simulation;Bandwidth;MISO communication;Transformers","learning (artificial intelligence);MIMO communication;MISO communication;neural nets;telecommunication computing;time-frequency analysis;vectors;wireless channels","multiple-input-single-output channels;frequency domain analysis;time domain analysis;single subcarrier observation;transformers;VQ-VAE framework;compression techniques;MIMO channels;FDD systems;vector quantized variational autoencoders;multiple-input-multiple-output channels;frequency-division-duplex systems;MISO channels;post-training quantization","","","","37","IEEE","12 Jul 2022","","","IEEE","IEEE Conferences"
"Conditional Generative Denoising Autoencoder","S. Karatsiolis; C. N. Schizas","Department of Computer Science, University of Cyprus, Nicosia, Cyprus; Department of Computer Science, University of Cyprus, Nicosia, Cyprus","IEEE Transactions on Neural Networks and Learning Systems","5 Oct 2020","2020","31","10","4117","4129","We present a generative denoising autoencoder model that has an embedded data classifier in its architecture in order to take advantage of class-based discriminating features and produce better data samples. The proposed model is a conditional generative model and is sampled with a Markov chain Monte Carlo (MCMC) process according to a label that denotes the desired (or undesired) class or classes. In this sense, any chosen predefined class or characteristic may have a positive or negative effect on the image generation process, meaning that it can be instructed to be present or absent from the generated sample. We argue that allowing discriminative information in the form of feature detectors to be present in the latent representation of the autoencoder can be generally beneficial. This technique is an alternative approach to variational autoencoders (VAEs) that enforce a prior on the latent distribution. We further claim that supervised learning may be generally able to serve unsupervised learning through an interaction between the two paradigms. However, the extreme majority of research done on the interaction of the two learning regimes has the goal of using unsupervised learning to improve supervised learning. In this article, we explore the two learning paradigms' interaction in the opposite direction.","2162-2388","","10.1109/TNNLS.2019.2952203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924906","Artificial neural networks;image denoising;image sampling;multilayer perceptron;unsupervised learning","Noise reduction;Supervised learning;Training;Unsupervised learning;Decoding;Data models;Markov processes","feature extraction;image denoising;Markov processes;Monte Carlo methods;unsupervised learning","conditional generative denoising autoencoder;generative denoising autoencoder model;data samples;conditional generative model;Markov chain Monte Carlo process;image generation;discriminative information;feature detectors;latent representation;variational autoencoders;latent distribution;supervised learning;unsupervised learning;learning paradigms interaction;opposite direction;learning regimes;MCMC;class-based discriminating features;data classifier embedding;VAEs","","3","","41","IEEE","5 Dec 2019","","","IEEE","IEEE Journals"
"HDR Image Compression with Convolutional Autoencoder","F. Han; J. Wang; R. Xiong; Q. Zhu; B. Yin","Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Institute of Digital Media, Peking University, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China","2020 IEEE International Conference on Visual Communications and Image Processing (VCIP)","29 Dec 2020","2020","","","25","28","As one of the next-generation multimedia technology, high dynamic range (HDR) imaging technology has been widely applied. Due to its wider color range, HDR image brings greater compression and storage burden compared with traditional LDR image. To solve this problem, in this paper, a two-layer HDR image compression framework based on convolutional neural networks is proposed. The framework is composed of a base layer which provides backward compatibility with the standard JPEG, and an extension layer based on a convolutional variational autoencoder neural networks and a post-processing module. The autoencoder mainly includes a nonlinear transform encoder, a binarized quantizer and a nonlinear transform decoder. Compared with traditional codecs, the proposed CNN autoencoder is more flexible and can retain more image semantic information, which will improve the quality of decoded HDR image. Moreover, to reduce the compression artifacts and noise of reconstructed HDR image, a post-processing method based on group convolutional neural networks is designed. Experimental results show that our method outperforms JPEG XT profile A, B, C and other methods in terms of HDR-VDP-2 evaluation metric. Meanwhile, our scheme also provides backward compatibility with the standard JPEG.","2642-9357","978-1-7281-8068-7","10.1109/VCIP49819.2020.9301853","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9301853","","Image reconstruction;Image coding;Transform coding;Decoding;Convolutional codes;Standards;Neural networks","codecs;convolutional neural nets;data compression;image coding;image denoising;image reconstruction","two-layer HDR image compression framework;backward compatibility;standard JPEG;convolutional variational autoencoder neural networks;post-processing module;traditional codecs;CNN autoencoder;image semantic information;decoded HDR image;compression artifacts;reconstructed HDR image;post-processing method;group convolutional neural networks;HDR-VDP-2 evaluation metric;convolutional autoencoder;next-generation multimedia technology;high dynamic range imaging technology;HDR image compression;binarized quantizer;nonlinear transform decoder","","","","15","","29 Dec 2020","","","IEEE","IEEE Conferences"
"A Variational Auto-Encoder and Transformer Based Approach for Metasurface Unit Cell Synthesis","C. Niu; P. Mojabi","Department of Electrical and Computer Engineering, University of Manitoba, Winnipeg, MB, Canada; Department of Electrical and Computer Engineering, University of Manitoba, Winnipeg, MB, Canada","2022 IEEE International Symposium on Antennas and Propagation and USNC-URSI Radio Science Meeting (AP-S/URSI)","21 Sep 2022","2022","","","1376","1377","Inspired by the similarity between the text-to-image synthesis problem and the scattering parameters to metasurface unit cell synthesis problem, we utilize a variational auto-encoder and transformer based approach to synthesize three-layer dog-bone unit cells from the knowledge of two-port scattering parameters in the X band.","1947-1491","978-1-6654-9658-2","10.1109/AP-S/USNC-URSI47032.2022.9886702","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9886702","","Conferences;Transformers;Metasurfaces;Scattering parameters","electromagnetic metamaterials","three-layer dog-bone unit cells;two-port scattering parameters;transformer based approach;metasurface unit cell synthesis;text-to-image synthesis problem;variational autoencoder","","1","","21","IEEE","21 Sep 2022","","","IEEE","IEEE Conferences"
"DynaLAP: Human Activity Recognition in Fixed Protocols via Semi-Supervised Variational Recurrent Neural Networks With Dynamic Priors","S. An; A. H. Gazi; O. T. Inan","School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Sensors Journal","8 Sep 2022","2022","22","18","17963","17976","Learning the route and order of tasks can be critical to human activity recognition (HAR) for fixed protocols of movement. In this article, we propose a novel framework, DynaLAP, a semi-supervised variational recurrent neural network (VRNN) with a dynamic prior distribution, to perform activity recognition in fixed protocols. DynaLAP takes single tri-axial accelerometry data as input and causally classifies the activity of 10–30-s windows at a time. DynaLAP learns not only a window-specific short-term state, but also a long-term dynamic state iteratively updated throughout the protocol’s measurements. Additionally, instead of using a stationary prior distribution of activity classes, DynaLAP learns a dynamic prior that updates for each window. DynaLAP thereby learns protocol-specific dynamics when trained on data from subjects abiding by a fixed protocol. Two datasets from previously published literature were used to evaluate DynaLAP: the fully labeled MotionSense dataset of 24 subjects and a weakly labeled dataset of 17 subjects collected at the Georgia Institute of Technology. For each dataset, we varied the number of training labels used from a single subject’s data to the entire dataset. DynaLAP outperformed previous supervised and semi-supervised HAR approaches by 6–42 percentage points, with F1 scores that remained above 80%. These results suggest that DynaLAP can achieve state-of-the-art HAR performance in fixed protocols by learning protocol-specific dynamics, especially in weakly and scarcely labeled settings. DynaLAP could ultimately reduce the necessity for labor-intensive annotation efforts in HAR applications involving routine activities (e.g., military training).","1558-1748","","10.1109/JSEN.2022.3194677","Office of Naval Research(grant numbers:N00014-20-1-2137); Linda J. and Mark C. Smith Chair in Bioscience and Bioengineering at the Georgia Institute of Technology; National Science Foundation Graduate Research Fellowship(grant numbers:DGE-1650044); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9849451","Activity recognition;deep learning;semi-supervised learning;variational recurrent neural networks (VRNNs)","Sensors;Recurrent neural networks;Deep learning;Training;Mathematical models;Task analysis;Semisupervised learning","accelerometers;deep learning (artificial intelligence);iterative methods;pattern classification;recurrent neural nets;semi-supervised learning (artificial intelligence);signal classification","human activity recognition;fixed protocol;DynaLAP;semisupervised variational recurrent neural network;dynamic prior distribution;window-specific short-term state;long-term dynamic state;semisupervised HAR approach;dynamic prior learning;tri-axial accelerometry data;activity classification;stationary prior distribution;protocol-specific dynamics learning;MotionSense dataset;semisupervised variational autoencoder","","","","54","IEEE","3 Aug 2022","","","IEEE","IEEE Journals"
"Modeling Melodic Feature Dependency with Modularized Variational Auto-encoder","Y. -A. Wang; Y. -K. Huang; T. -C. Lin; S. -Y. Su; Y. -N. Chen","National Taiwan University, Taipei, Taiwan; National Taiwan University, Taipei, Taiwan; National Taiwan University, Taipei, Taiwan; National Taiwan University, Taipei, Taiwan; National Taiwan University, Taipei, Taiwan","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","191","195","Automatic melody generation has been a long-time aspiration for both AI researchers and musicians. However, learning to generate euphonious melodies has turned out to be highly challenging. This paper introduces 1) a new variant of variational autoencoder (VAE), where the model structure is designed in a modularized manner in order to model polyphonic and dynamic music with domain knowledge, and 2) a hierarchical encoding/decoding strategy, which explicitly models the dependency between melodic features. The proposed framework is capable of generating distinct melodies that sounds natural, and the experiments for evaluating generated music clips show that the proposed model outperforms the baselines in human evaluation.1","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683106","Music Generation;VAE;Modularization","","audio signal processing;feature extraction;music;neural nets","automatic melody generation;euphonious melodies;variational autoencoder;melodic feature dependency;modularized variational autoencoder;encoding/decoding strategy;polyphonic music;dynamic music;music generation","","1","","21","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Learned Compression Framework With Pyramidal Features and Quality Enhancement for SAR Images","Z. Di; X. Chen; Q. Wu; J. Shi; Q. Feng; Y. Fan","School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Microelectronics, Xidian University, Xi’an, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; State Key Laboratory of ASIC and System, Fudan University, Shanghai, China","IEEE Geoscience and Remote Sensing Letters","18 Mar 2022","2022","19","","1","5","Current image compression algorithms based on transforms can achieve ideal performance for natural images, but do not do well with synthetic aperture radar (SAR) images. We propose a learned compression framework with pyramidal features and quality enhancement to fully exploit the redundancy among image pixels and to improve the compression bitrate and reconstruction quality. Based on the variational autoencoder (VAE) architecture, pyramidal decomposition is performed at the first autoencoder to extract both global and coarse feature maps. The latent distribution is modeled by the second hyperprior autoencoder with a single-Gaussian model for more accurate and flexible entropy estimation. Universal quantization is applied to consolidate the entropy estimation accuracy of the hyperprior network. To further improve reconstruction quality, a residual dense network (RDN) is adopted to fully capture local and global features. Experimental results demonstrate that the proposed framework provides a better rate-distortion tradeoff than standard codecs such as JPEG, JPEG2000, and learning-based methods on both the Sandia and ICEYE datasets.","1558-0571","","10.1109/LGRS.2022.3155651","National Natural Science Foundation of China(grant numbers:61504110,62090012); Sichuan Science and Technology Program(grant numbers:2019YFG0092,2020YFG0452); State Key Laboratory of ASIC and System Open Research Project Fund(grant numbers:2021KF013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723081","Image compression;pyramidal decomposition;remote sensing;residual dense network (RDN);variational autoencoder (VAE)","Image coding;Feature extraction;Transform coding;Radar polarimetry;Quantization (signal);Decoding;Distortion","data compression;entropy;image coding;image reconstruction;image resolution;learning (artificial intelligence);radar imaging;synthetic aperture radar","reconstruction quality;local features;global features;learning-based methods;learned compression framework;pyramidal features;quality enhancement;SAR;current image compression algorithms;ideal performance;natural images;synthetic aperture radar images;image pixels;compression bitrate;variational autoencoder architecture;pyramidal decomposition;global feature maps;coarse feature maps;hyperprior autoencoder;single-Gaussian model;accurate entropy estimation;flexible entropy estimation;entropy estimation accuracy","","","","25","IEEE","28 Feb 2022","","","IEEE","IEEE Journals"
"A Nonlinear Model Compression Scheme Based on Variational Autoencoder for Microwave Data Inversion","R. Guo; Z. Lin; M. Li; F. Yang; S. Xu; A. Abubakar","Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Schlumberger, Houston, Texas, USA","IEEE Transactions on Antennas and Propagation","","2022","PP","99","1","1","We present an inversion algorithm with a deep-learning-based model compression scheme. Models are described with latent parameters of a trained variational autoencoder (VAE) neural network. Given observed data, latent parameters are inverted by minimizing the data misfit cost function using the Gauss-Newton method. This inversion algorithm is tested using both synthetic and experimental datasets. We achieve a 0.87% compression rate while maintaining high-quality reconstruction. The deep neural network renders nonlinear model compression, which largely reduces the number of unknowns; hence, it has higher computational efficiency. Furthermore, various prior knowledge that is difficult to describe with rigorous forms can be incorporated into inversion through training the neural network, which mitigates the ill-posedness of the inverse problem.","1558-2221","","10.1109/TAP.2022.3195553","Beijing Innovation Center for Future Chip; Shuimu Tsinghua Scholar Program of Tsinghua University(grant numbers:2021SM031); National Natural Science Foundation of China(grant numbers:61971263); Institute for Precision Medicine, Tsinghua University; Biren Tech, Beijing; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9852109","model compression;inversion algorithm;deep learning;variational antoencoder;inverse scattering","Data models;Computational modeling;Training;Mathematical models;Decoding;Neural networks;Permittivity","","","","","","","IEEE","8 Aug 2022","","","IEEE","IEEE Early Access Articles"
"Semi-Supervised Seq2seq Joint-Stochastic-Approximation Autoencoders With Applications to Semantic Parsing","Y. Song; Z. Ou","Beijing National Research Center for Information Science and Technology, Beijing, China; Beijing National Research Center for Information Science and Technology, Beijing, China","IEEE Signal Processing Letters","22 Jan 2020","2020","27","","31","35","Developing Semi-Supervised Seq2Seq (S4) learning for sequence transduction tasks in natural language processing (NLP), e.g. semantic parsing, is challenging, since both the input and the output sequences are discrete. This discrete nature makes trouble for methods which need gradients either from the input space or from the output space. Recently, a new learning method called joint stochastic approximation is developed for unsupervised learning of fixed-dimensional autoencoders and theoretically avoids gradient propagation through discrete latent variables, which is suffered by Variational Auto-Encoders (VAEs). In this letter, we propose seq2seq Joint-stochastic-approximation AutoEncoders (JAEs) and apply them to S4 learning for NLP sequence transduction tasks. Further, we propose bi-directional JAEs (called bi-JAEs) to leverage not only unpaired input sequences (which is most commonly studied) but also unpaired output sequences. Experiments on two benchmarking datasets for semantic parsing show that JAEs consistently outperform VAEs in S4 learning and bi-JAEs yield further improvements.","1558-2361","","10.1109/LSP.2019.2953999","National Natural Science Foundation of China(grant numbers:61976122); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903435","Semi-supervised learning;seq2seq;semantic parsing;joint stochastic approximation;variational auto-encoder","Semantics;Task analysis;Decoding;Natural language processing;Training;Semisupervised learning","natural language processing;unsupervised learning","output sequences;discrete nature;output space;learning method;unsupervised learning;fixed-dimensional autoencoders;discrete latent variables;NLP sequence transduction tasks;semantic parsing;unpaired input sequences;biJAE;semisupervised Seq2Seq learning;semisupervised Seq2seq joint-stochastic-approximation autoencoders","","1","","19","IEEE","18 Nov 2019","","","IEEE","IEEE Journals"
"FusionNet: An Unsupervised Convolutional Variational Network for Hyperspectral and Multispectral Image Fusion","Z. Wang; B. Chen; R. Lu; H. Zhang; H. Liu; P. K. Varshney","National Laboratory of Radar Signal Processing, Collaborative Innovation Center of Information Sensing and Understanding, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Collaborative Innovation Center of Information Sensing and Understanding, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Collaborative Innovation Center of Information Sensing and Understanding, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Collaborative Innovation Center of Information Sensing and Understanding, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Collaborative Innovation Center of Information Sensing and Understanding, Xidian University, Xi’an, China; Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, USA","IEEE Transactions on Image Processing","10 Jul 2020","2020","29","","7565","7577","Due to hardware limitations of the imaging sensors, it is challenging to acquire images of high resolution in both spatial and spectral domains. Fusing a low-resolution hyperspectral image (LR-HSI) and a high-resolution multispectral image (HR-MSI) to obtain an HR-HSI in an unsupervised manner has drawn considerable attention. Though effective, most existing fusion methods are limited due to the use of linear parametric modeling for the spectral mixture process, and even the deep learning-based methods only focus on deterministic fully-connected networks without exploiting the spatial correlation and local spectral structures of the images. In this paper, we propose a novel variational probabilistic autoencoder framework implemented by convolutional neural networks, in order to fuse the spatial and spectral information contained in the LR-HSI and HR-MSI, called FusionNet. The FusionNet consists of a spectral generative network, a spatial-dependent prior network, and a spatial-spectral variational inference network, which are jointly optimized in an unsupervised manner, leading to an end-to-end fusion system. Further, for fast adaptation to different observation scenes, we give a meta-learning explanation to the fusion problem, and combine the FusionNet with meta-learning in a synergistic manner. Effectiveness and efficiency of the proposed method are evaluated based on several publicly available datasets, demonstrating that the proposed FusionNet outperforms the state-of-the-art fusion methods.","1941-0042","","10.1109/TIP.2020.3004261","Program for Oversea Talent by the Chinese Central Government; Higher Education Discipline Innovation Project(grant numbers:B18039); NSFC(grant numbers:61771361); NSFC for Distinguished Young Scholars(grant numbers:61525105); Shaanxi Innovation Team Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9127776","Hyperspectral images;multispectral images;image fusion;probabilistic generative model;convolutional neural network;meta-learning","Sensors;Spatial resolution;Task analysis;Probabilistic logic;Hyperspectral imaging","Bayes methods;feature extraction;geophysical image processing;geophysical signal processing;hyperspectral imaging;image classification;image fusion;image resolution;image sensors;neural nets;sensor fusion;unsupervised learning","unsupervised convolutional variational network;hardware limitations;imaging sensors;spatial domains;spectral domains;low-resolution hyperspectral image;high-resolution multispectral image;HR-MSI;unsupervised manner;effective existing fusion methods;most existing fusion methods;linear parametric modeling;spectral mixture process;deep learning-based methods only focus;fully-connected networks;spatial correlation;local spectral structures;convolutional neural networks;spatial information;spectral information;LR-HSI;called FusionNet;spectral generative network;spatial-dependent prior network;spatial-spectral variational inference network;end-to-end fusion system;meta-learning explanation;fusion problem;synergistic manner;state-of-the-art fusion methods;variational probabilistic autoencoder framework","","17","","39","IEEE","29 Jun 2020","","","IEEE","IEEE Journals"
"Variational Transformer Networks for Layout Generation","D. M. Arroyo; J. Postels; F. Tombari","Google, Inc; ETH Zürich; Technische Universität München","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","2 Nov 2021","2021","","","13637","13647","Generative models able to synthesize layouts of different kinds (e.g. documents, user interfaces or furniture arrangements) are a useful tool to aid design processes and as a first step in the generation of synthetic data, among other tasks. We exploit the properties of self-attention layers to capture high level relationships between elements in a layout, and use these as the building blocks of the well-known Variational Autoencoder (VAE) formulation. Our proposed Variational Transformer Network (VTN) is capable of learning margins, alignments and other global design rules without explicit supervision. Layouts sampled from our model have a high degree of resemblance to the training data, while demonstrating appealing diversity. In an extensive evaluation on publicly available benchmarks for different layout types VTNs achieve state-of-the-art diversity and perceptual quality. Additionally, we show the capabilities of this method as part of a document layout detection pipeline.","2575-7075","978-1-6654-4509-2","10.1109/CVPR46437.2021.01343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9578374","","Computer vision;Layout;Pipelines;Training data;User interfaces;Tools;Transformers","document handling;furniture;learning (artificial intelligence);user interfaces","training data;document layout detection pipeline;layout generation;generative models;user interfaces;furniture arrangements;synthetic data;self-attention layers;high level relationships;building blocks;global design rules;variational transformer network;variational autoencoder formulation;variational transformer networks;layout types VTN","","6","","43","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Vapar Synth - A Variational Parametric Model for Audio Synthesis","K. Subramani; P. Rao; A. D’Hooge",Indian Institute of Technology Bombay; Indian Institute of Technology Bombay; ENS Paris-Saclay,"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","796","800","With the advent of data-driven statistical modeling and abundant computing power, researchers are turning increasingly to deep learning for audio synthesis. These methods try to model audio signals directly in the time or frequency domain. In the interest of more flexible control over the generated sound, it could be more useful to work with a parametric representation of the signal which corresponds more directly to the musical attributes such as pitch, dynamics and timbre. We present Va-Par Synth - a Variational Parametric Synthesizer which utilizes a conditional variational autoencoder (CVAE) trained on a suitable parametric representation. We demonstrate1 our proposed model's capabilities via the reconstruction and generation of instrumental tones with flexible control over their pitch.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9054181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054181","Generative Models;Conditional VAE;Source-Filter Model;Spectral Modeling Synthesis","Instruments;Computational modeling;Synthesizers;Turning;Parametric statistics;Timbre;Speech processing","audio signal processing;learning (artificial intelligence);neural nets;statistical analysis","audio signals;frequency domain;generated sound;musical attributes;conditional variational autoencoder;parametric representation;audio synthesis;data-driven statistical modeling;variational parametric model;Vapar Synth model;variational parametric synthesizer","","1","","23","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Variational methods for conditional multimodal deep learning","G. Pandey; A. Dukkipati","Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India; Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India","2017 International Joint Conference on Neural Networks (IJCNN)","3 Jul 2017","2017","","","308","315","In this paper, we address the problem of conditional modality learning, whereby one is interested in generating one modality given the other. While it is straightforward to learn a joint distribution over multiple modalities using a deep multi-modal architecture, we observe that such models are not very effective at conditional generation. Hence, we address the problem by learning conditional distributions between the modalities. We use variational methods for maximizing the corresponding conditional log-likelihood. The resultant deep model, which we refer to as conditional multimodal autoencoder (CMMA), forces the latent representation obtained from a single modality alone to be `close' to the joint representation obtained from multiple modalities. We use the proposed model to generate faces from attributes. We show that the faces generated from attributes using the proposed model are qualitatively and quantitatively more representative of the attributes from which they were generated, than those obtained by other deep generative models. We also propose a secondary task, whereby the existing faces are modified by modifying the corresponding attributes. We observe that the modifications in face introduced by the proposed model are representative of the corresponding modifications in attributes.","2161-4407","978-1-5090-6182-2","10.1109/IJCNN.2017.7965870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7965870","","Computational modeling;Training;Neural networks;Gallium nitride;Mathematical model;Correlation;Encoding","face recognition;learning (artificial intelligence);variational techniques","variational methods;conditional multimodal deep learning;conditional modality learning;deep multimodal architecture;conditional multimodal autoencoder;CMMA;face modifications","","15","","17","","3 Jul 2017","","","IEEE","IEEE Conferences"
"Classical and Deep Learning Classifiers for Anomaly Detection","M. Raza; U. Qayyum","School of Electrical Engineering and Computer Science, National University of Sciences and Technology, Islamabad, Pakistan; Center of Excellence in Sciences and Applied Technology, Islamabad, Pakistan","2019 16th International Bhurban Conference on Applied Sciences and Technology (IBCAST)","18 Mar 2019","2019","","","614","618","The recent years have seen a heightened interest in the realm of machine learning (ML) for cyber crime detection. The ML approaches use to identify the hidden patterns from the data where the behavior does not comply with usual pattern are called anomaly detection techniques. In this paper we have proposed a 10-layer deep Variational Auto-Encoder (VAE) neural network approach and perform a detailed comparison with different classical classifiers, namely Decision Tree, Support Vector Machine and Ensemble Classifiers. We have employed these classifiers on the credit card transaction anomaly dataset (available online). In conclusion the paper provides the evaluation of each classifier (supervised/unsupervised) through ROC curve, F1-score and confusion matrices.","2151-1411","978-1-5386-7729-2","10.1109/IBCAST.2019.8667245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8667245","Support Vector Machine;Neural Network;Decision Tree;Ensemble Classifiers and Variational Autoencoder","Classification algorithms;Neural networks;Anomaly detection;Support vector machines;Credit cards;Decision trees;Supervised learning","computer crime;decision trees;financial data processing;neural nets;pattern classification;supervised learning;support vector machines;transaction processing;unsupervised learning;variational techniques","machine learning;cyber crime detection;credit card transaction;anomaly detection;decision tree;support vector machine;ensemble classifiers;deep variational autoencoder neural network","","4","","16","","18 Mar 2019","","","IEEE","IEEE Conferences"
"Improved Response Generation Consistency in Multiturn Dialog","T. Onishi; S. Onishi; H. Shiina","Systems Nakashima Co., Ltd., Okayama, Japan; Graduate School of Informatics, Okayama University of Science, Okayama, Japan; Faculty of Information Science and Engineering, Okayama University of Science, Okayama, Japan","2022 12th International Congress on Advanced Applied Informatics (IIAI-AAI)","23 Sep 2022","2022","","","416","419","The consistency of response generation in multi-turn dialog must be improved. The existing VHDER model, that extends the RNN model to dialog generation, does not distinguish turns. Thus, in this study, we improve it by adding implementing a User-RNN that corresponds to a speaker who conveys information every odd and even turn. In addition, the global vibrational transformer model, which applies the CVAE, an advanced autoencoder, enables diverse response generation. However, latent variables sampled from the entire context are diluted by speaker characteristics, which degrades the consistency of generated responses. In this study, we employed speaker-specific latent variables to generate speaker-consistent responses.","2472-0070","978-1-6654-9755-8","10.1109/IIAIAAI55812.2022.00088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9894590","Dialogue System;Latent Variable Hierarchical Recurrent Encoder-Decoder model;User-RNN, Conditional Variational Autoencoder;Global Variational Transformer","Transformers;Decoding;Task analysis;Informatics","interactive systems;recurrent neural nets;speaker recognition","advanced autoencoder;VHDER model;speaker-specific latent variables;speaker characteristics;diverse response generation;global vibrational transformer model;User-RNN;dialog generation;multiturn dialog;improved response generation consistency;speaker-consistent responses","","","","6","IEEE","23 Sep 2022","","","IEEE","IEEE Conferences"
"Variational voxelwise rs-fMRI representation learning: Evaluation of sex, age, and neuropsychiatric signatures","E. Geenjaar; T. White; V. Calhoun","Faculty of EEMCS, Delft University of Technology, Delft, the Netherlands; Department of Radiology and Nuclear Medicine, Erasmus MC, Rotterdam, the Netherlands; TReNDS center, GaTech, GSU, & Emory University, Atlanta, USA","2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","14 Jan 2022","2021","","","1733","1740","This work uses a variational autoencoder (VAE) to perform non-linear representation learning from voxelwise rs-fMRI data. The VAE learns a non-linear dimensionality reduction of the data in the form of a latent vector. These latent vectors retain meaningful information related to a subject’s demographics and clinical diagnosis. The retention of meaningful information in the latent vectors is evaluated using age regression and sex classification tasks on the UK Biobank dataset. The results on these tasks are highly encouraging and a linear regressor trained on the latent vectors to predict age performs almost on par with a supervised neural network. Further, the same latent vectors can almost perfectly linearly separate sex. The model that is pre-trained on UK Biobank is also fine-tuned on a smaller neuropsychiatric dataset for a varying number of epochs. The latent vectors it generates for this dataset are then evaluated by performing a schizophrenia diagnosis classification task. We find that pre-training the model on UK Biobank significantly improves the quality of the latent vectors and that the vectors themselves are fairly discriminative. To understand the structure of the latent vectors with respect to demographic variables or neuropsychiatric disorders we train a variety of supervised models on the latent vectors. The results presented in this work open up more in-depth research into the factors of variation that the VAE models and how they can be improved for voxelwise rs-fMRI data.","","978-1-6654-0126-5","10.1109/BIBM52615.2021.9669775","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669775","Neuroimaging;variational autoencoders;spatio-temporal;deep learning;unsupervised learning","Representation learning;Dimensionality reduction;Deep learning;Neuroimaging;Biological system modeling;Conferences;Neural networks","biomedical MRI;brain;image classification;learning (artificial intelligence);medical computing;medical disorders;medical image processing;neural nets;neurophysiology;pattern classification;regression analysis","variational voxelwise rs-fMRI representation learning;voxelwise rs-fMRI data;latent vector","","","","38","IEEE","14 Jan 2022","","","IEEE","IEEE Conferences"
"Variational Autoencoder for End-to-End Control of Autonomous Driving with Novelty Detection and Training De-biasing","A. Amini; W. Schwarting; G. Rosman; B. Araki; S. Karaman; D. Rus","Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology; Toyota Research Institute (TRI); Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology; Laboratory for Information and Decision Systems, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","6 Jan 2019","2018","","","568","575","This paper introduces a new method for end-to-end training of deep neural networks (DNNs) and evaluates it in the context of autonomous driving. DNN training has been shown to result in high accuracy for perception to action learning given sufficient training data. However, the trained models may fail without warning in situations with insufficient or biased training data. In this paper, we propose and evaluate a novel architecture for self-supervised learning of latent variables to detect the insufficiently trained situations. Our method also addresses training data imbalance, by learning a set of underlying latent variables that characterize the training data and evaluate potential biases. We show how these latent distributions can be leveraged to adapt and accelerate the training pipeline by training on only a fraction of the total dataset. We evaluate our approach on a challenging dataset for driving. The data is collected from a full-scale autonomous vehicle. Our method provides qualitative explanation for the latent variables learned in the model. Finally, we show how our model can be additionally trained as an end-to-end controller, directly outputting a steering control command for an autonomous vehicle.","2153-0866","978-1-5386-8094-0","10.1109/IROS.2018.8594386","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594386","","Training;Autonomous vehicles;Aerospace electronics;Image reconstruction;Training data;Data models;Robots","learning (artificial intelligence);neural nets;traffic engineering computing","variational autoencoder;end-to-end control;autonomous driving;novelty detection;end-to-end training;deep neural networks;DNN training;sufficient training data;trained models;insufficient training data;biased training data;self-supervised learning;latent variables;insufficiently trained situations;training data imbalance;latent distributions;training pipeline;full-scale autonomous vehicle;end-to-end controller","","34","2","32","","6 Jan 2019","","","IEEE","IEEE Conferences"
"Robust and Unsupervised KPI Anomaly Detection Based on Conditional Variational Autoencoder","Z. Li; W. Chen; D. Pei",Beijing National Research Center for Information Science and Technology(BNRist); Beijing National Research Center for Information Science and Technology(BNRist); Beijing National Research Center for Information Science and Technology(BNRist),"2018 IEEE 37th International Performance Computing and Communications Conference (IPCCC)","13 May 2019","2018","","","1","9","To ensure undisrupted web-based services, operators need to closely monitor various KPIs (Key Performance Indicator, such as CPU usages, network throughput, page views, number of online users, and etc), detect anomalies in them, and trigger timely troubleshooting or mitigation. There can be hundreds of thousands to even millions of KPIs to be monitored, thus operators need automatic anomaly detection approaches. However, neither traditional statistical approaches nor supervised ensemble approaches satisfy this requirement in practice when facing large number of KPIs. A state-of-art unsupervised approach Donut offering promising results, but it is not a sequential model thus cannot deal with the time information related anomalies. Thus, in this paper we propose Bagel, a robust and unsupervised anomaly detection algorithm for KPI that can handle time information related anomalies, using CVAE to incorporate time information and dropout layer to avoid overfitting. Our experiments using real data from Internet companies show that, compared to Donut, Bagel improves the anomaly detection best F1-score by 0.08 to 0.43.","2374-9628","978-1-5386-6808-5","10.1109/PCCC.2018.8710885","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8710885","","Anomaly detection;Neural networks;Key performance indicator;Monitoring;Training;Standards;Timing","data mining;Internet;learning (artificial intelligence);security of data;statistical analysis;unsupervised learning;Web services","dropout layer;anomaly detection best F1-score;conditional variational autoencoder;CPU usages;network throughput;page views;online users;trigger timely troubleshooting;detection approaches;traditional statistical approaches;supervised ensemble approaches;time information related anomalies;robust detection algorithm;unsupervised anomaly detection algorithm;key performance indicator;undisrupted Web-based services;unsupervised KPI anomaly detection;unsupervised approach Donut","","19","","34","","13 May 2019","","","IEEE","IEEE Conferences"
"Data-Driven Maneuver Modeling using Generative Adversarial Networks and Variational Autoencoders for Safety Validation of Highly Automated Vehicles","R. Krajewski; T. Moers; D. Nerger; L. Eckstein","Automated Driving Department, RWTH Aachen University, Aachen, Germany; Automated Driving Department, Forschungs-gesellschaft Kraftfahrwesen mbH Aachen, Aachen, Germany; Automated Driving Department, Forschungs-gesellschaft Kraftfahrwesen mbH Aachen, Aachen, Germany; Automated Driving Department, RWTH Aachen University, Aachen, Germany","2018 21st International Conference on Intelligent Transportation Systems (ITSC)","9 Dec 2018","2018","","","2383","2390","Scenario-based validation is a promising approach for the safety validation of highly automated driving systems. By modeling relevant driving scenarios, utilizing simulations and selecting insightful test cases, the testing effort is reduced. However, current methods can't automatically create intuitive models of the vehicle trajectories in a scenario. We propose to use unsupervised machine learning to train neural networks to solve the modeling problem. The models learn a small set of intuitive parameters without the need for labeled data and use them to generate new realistic trajectories. The neural networks, which base on the InfoGAN and beta-VAE architectures, are adapted from the image domain to the time series domain. Although our methods are generally applicable, our experiments focus on lane change maneuvers on highways. To train the networks, we use more than 5600 measured lane change trajectories extracted from the highD dataset. Our results show that the networks learn to describe lane change maneuvers by up to four intuitive parameters. Furthermore, the networks are able to map existing lane change trajectories to values of the learned parameters and generate new, previously unseen, realistic trajectories. We compare both architectures among themselves and to a polynomial model, and show respective advantages.","2153-0017","978-1-7281-0323-5","10.1109/ITSC.2018.8569971","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8569971","","Trajectory;Mathematical model;Neural networks;Safety;Data models;Road transportation;Gallium nitride","driver information systems;learning (artificial intelligence);neural nets;road vehicles;time series;traffic engineering computing","data-driven maneuver;generative adversarial networks;variational autoencoders;highly automated vehicles;scenario-based validation;highly automated driving systems;relevant driving scenarios;vehicle trajectories;unsupervised machine;neural networks;intuitive parameters;realistic trajectories;beta-VAE architectures;image domain;time series domain;lane change maneuvers;learned parameters;unseen trajectories;polynomial model;measured lane change trajectories","","13","","24","","9 Dec 2018","","","IEEE","IEEE Conferences"
"BézierVAE: Improved Trajectory Modeling using Variational Autoencoders for the Safety Validation of Highly Automated Vehicles","R. Krajewski; T. Moers; A. Meister; L. Eckstein","Automated Driving Department, Institute for Automotive Engineering RWTH Aachen University, Aachen, Germany; Automated Driving Department, fka GmbH, Aachen, Germany; Deloitte Analytics Institute, Berlin, Germany; Automated Driving Department, Institute for Automotive Engineering RWTH Aachen University, Aachen, Germany","2019 IEEE Intelligent Transportation Systems Conference (ITSC)","28 Nov 2019","2019","","","3788","3795","Scenario-based safety validation is a new approach to handle the increased testing complexity of highly automated vehicles. After categorizing traffic into relevant driving scenarios, every scenario element needs to be modeled in order to be used for testing. While driving maneuvers are typically modeled by experts, data-driven generative models allow to automate the modeling process. We propose an improved unsupervised modeling approach called BézierVAE, which is based on our previously published TraVAE framework. TraVAE is extended by a Bézier-curve output layer, which ensures the trajectories' smoothness in both the position and speed domain. The results are evaluated on lane changes and acceleration/deceleration trajectories extracted from the highD dataset. In comparison to our previous findings, BézierVAE learns a larger set of intuitive model parameters through unsupervised learning, hence enabling a more detailed modeling process. At the same time, the reconstruction errors are reduced by up to 91.3% and the unsmoothness decreased by 83.4% compared to TraVAE. Partially specifying parameters in a semi-supervised fashion maintains the ability to learn disentangled parameters while allowing the parameter learning process to be guided. Finally, we demonstrate the modeling of multiple maneuvers through a single model by introducing discrete parameters into the latent representation.","","978-1-5386-7024-8","10.1109/ITSC.2019.8917297","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917297","","Trajectory;Data models;Training;Testing;Computer architecture;Safety;Biological system modeling","traffic engineering computing;unsupervised learning","unsupervised learning;BézierVAE;trajectory modeling;variational autoencoders;highly automated vehicles;scenario-based safety validation;testing complexity;driving scenarios;data-driven generative models;improved unsupervised modeling approach;Bézier-curve output layer;speed domain;intuitive model parameters;TraVAE framework;discrete parameters","","2","","18","","28 Nov 2019","","","IEEE","IEEE Conferences"
"Generative Oversampling with a Contrastive Variational Autoencoder","W. Dai; K. Ng; K. Severson; W. Huang; F. Anderson; C. Stultz","Department of EECS, MIT Cambridge, Massachusetts, USA; Center for Computational Health and MIT-IBM Watson AI Lab Cambridge, Massachusetts, USA; Center for Computational Health, IBM Watson AI Lab Cambridge, Cambridge, MA, USA; University of Massachusetts Medical School Worcester, Massachusetts, USA; University of Massachusetts Medical School Worcester, Massachusetts, USA; Department of EECS, Institute of Medical Engineering and Science, Cambridge, MA, USA","2019 IEEE International Conference on Data Mining (ICDM)","30 Jan 2020","2019","","","101","109","Although oversampling methods are widely used to deal with class imbalance problems, most only utilize observed samples in the minority class and ignore the rich information available in the majority class. In this work, we use an oversampling method that leverages information in both the majority and minority classes to mitigate the class imbalance problem. Experimental results on two clinical datasets with highly imbalanced outcomes demonstrate that prediction models can be significantly improved using data obtained from this oversampling method when the number of minority class samples is very small.","2374-8486","978-1-7281-4604-1","10.1109/ICDM.2019.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8970705","class imbalance;oversampling;generative model;contrastive learning","","pattern classification;sampling methods","class imbalance problem;generative oversampling;contrastive variational autoencoder;class imbalance problems","","2","","16","","30 Jan 2020","","","IEEE","IEEE Conferences"
"An intelligent music generation based on Variational Autoencoder","T. Wang; J. Liu; C. Jin; J. Li; S. Ma","School of Information Engineering, Zhengzhou University, Henan, China; School of Information and Communication Engineering, Communication University of China, Beijing, China; School of Information and Communication Engineering, Communication University of China, Beijing, China; School of Information and Communication Engineering, Communication University of China, Beijing, China; School of Information Engineering, Zhengzhou University, Henan, China","2020 International Conference on Culture-oriented Science & Technology (ICCST)","24 Nov 2020","2020","","","394","398","In this paper, GAN and VAE are combined with deep learning network to generate intelligent music based on music theory rules, and to explore intelligent music generation algorithm. Different from the traditional algorithmic composition, it is not necessary to manually add complex rules, but trains the initial music set, evaluates and filters the music collection, and ultimately generates music via the RVAE-GAN neural network. The fitness function calculates a weighted sum of a series of features of a piece of music, such as pitch and rhythm distribution, and can also calculate a series of theoretical rules of music theory from the distance between a particular piece of music. Furthermore, we take the music theory and practical experience into account, put forward the expressions and a rule function of rhythm, which are given in a mathematical way. On this basis, the semi-supervised algorithm is used to form the chord structure model, combined with the feature extraction of music, and the intelligent generation music based on GAN confrontation generation network and VAE network combined with music theory rules is proposed and proposed. And mass production has important theoretical and practical significance.","","978-1-7281-8138-7","10.1109/ICCST50977.2020.00082","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262797","VAE;GAN;Music theory rules;Rhythm","Generators;Rhythm;Decoding;Training;Mathematical model;Gallium nitride;Generative adversarial networks","feature extraction;learning (artificial intelligence);music;neural nets","deep learning network;music theory rules;traditional algorithmic composition;music collection;RVAE-GAN neural network;intelligent music generation;variational autoencoder;music feature extraction","","1","","16","","24 Nov 2020","","","IEEE","IEEE Conferences"
"Efficient Evolution of Variational Autoencoders","J. Hajewski; S. Oliveira","Salesforce; Department of Computer Science, University of Iowa","2021 IEEE 11th Annual Computing and Communication Workshop and Conference (CCWC)","17 Mar 2021","2021","","","1541","1550","Despite the extensive successes of deep learning, designing effective neural networks remains an unsolved challenge in deep learning. The complexity of interactions between all the network hyperparameters such as activation type, layer size, number of layers, and connection patterns is far beyond current understanding. As a result, designing an effective neural network can be as much art as it is science. To that end, neural architecture search aims to automate the task of network design; however, many neural architecture search systems are not feasible for the typical research institution due to the high cost of operation. In this work we propose two simple techniques that have a dramatic impact on search cost, achieving as much as a 900% speed-up in per generation training time, with minimal impact on the efficacy of the search algorithm. Similarly, we achieve a 50% reduction in search time without sacrificing any performance.","","978-1-6654-1490-6","10.1109/CCWC51732.2021.9376167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9376167","","Training;Deep learning;Heuristic algorithms;Conferences;Neural networks;Computer architecture;Task analysis","learning (artificial intelligence);neural nets","variational autoencoders;deep learning;neural network;unsolved challenge;network hyperparameters;activation type;layer size;connection patterns;network design;neural architecture search systems;search cost;search algorithm;search time","","","","35","","17 Mar 2021","","","IEEE","IEEE Conferences"
"Deep Beacon: Image Storage and Broadcast over BLE Using Variational Autoencoder Generative Adversarial Network","C. Shao; S. Nirjon","Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC; University of North Carolina at Chapel Hill, Chapel Hill, NC, US","2018 14th International Conference on Distributed Computing in Sensor Systems (DCOSS)","28 Oct 2018","2018","","","147","154","This paper describes Deep Beacon which uses a set of cheap, low-power, storage-constrained Bluetooth Low Energy (BLE) devices to beacon (i.e. broadcast) a color image over a very long period (months, as opposed to days or weeks). The system employs deep neural network image encoder to encode a given input image and generates an extremely compact representation (as small as 10 bytes) of the image. At the receiver end, another deep neural network decoder runs on a mobile device which decodes (i.e. generates) the original image from the BLE broadcast messages. We evaluate Deep Beacon's performance using hand-written digit images and different types of RGB images that contain objects such as birds, flowers, and traffic signs. We empirically determine the tradeoffs between the system lifetime and the quality of broadcast images, and determine an optimal set of parameters for our system, under user-specified constraints such as the number of available beacon devices, maximum latency, and life expectancy. We develop a smartphone application that takes an image and user-requirements as inputs, shows previews of different quality output images, writes the encoded image into a set of beacons, and reads the broadcasted image back. Our evaluation shows that one beacon device is capable of broadcasting high-quality images (90% structurally similar to original images) for a year-long continuous broadcasting, and both the lifetime and the image quality improve when two beacons are used.","2325-2944","978-1-5386-5470-5","10.1109/DCOSS.2018.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8510976","BLE;deep learning;image processing","Image coding;Decoding;Broadcasting;Image quality;Internet;Navigation;Training","Bluetooth;decoding;image coding;image colour analysis;learning (artificial intelligence);neural nets;smart phones","low-power;color image;deep neural network image encoder;extremely compact representation;deep neural network decoder;mobile device;original image;BLE broadcast messages;RGB images;system lifetime;broadcast images;available beacon devices;different quality output images;encoded image;broadcasted image;beacon device;high-quality images;year-long continuous broadcasting;image quality;image storage;variational autoencoder generative adversarial network;Deep Beacon performance using hand-written digit images;storage-constrained Bluetooth low energy devices","","","","30","","28 Oct 2018","","","IEEE","IEEE Conferences"
"New Generative Image Model for Variational Autoencoders Based on Counts Partition","V. Antsiperov","Signal processing and telecommunication lab, Kotelnikov Institute of Radioengineering and Electronics of Russian Academy of Sciences, Moscow, Russian Federation","2021 International Conference on Information Technology and Nanotechnology (ITNT)","24 Dec 2021","2021","","","1","8","The article substantiates a generative image model based on a sample of random counts and its representation using compressed (coded) lattice partitioning. The basics of the model proposed is a concept of the ideal image. To avoid the problems with cumbersome descriptions, the ideal image is reduced to a sample of counts of a fixed (controlled) size. It is shown that the corresponding statistical description can be factorized into the product of the distributions of individual counts, which fits well with naive Bayesian algorithms and other machine learning approaches. Guided by this association in the image and likeness of the well-known K–means algorithm, the method of iterative partitioning - maximization of counts was synthesized. The main goal of the method is to calculate the maximum likelihood parameters of sample probability distribution and to use these parameters as a code for some intermediate representation of the input data. The method specific feature is the use of lattice neighbourhood trick for partitioning counts, that allows to control both the computation time and some characteristics of the resulting code. The final of the article is devoted to the algorithmic details of the proposed partition-maximization method are considered and several iterations related characteristics, including the convergence property, convergence criterion and asymptotic efficiency of the resulting estimates are discussed. Most of those characteristics are illustrated by the results of numerical simulations.","","978-1-6654-3217-7","10.1109/ITNT52450.2021.9649307","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9649307","generative model;image representation;random counts;machine learning;K-means method;lattice partitioning","Codes;Machine learning algorithms;Scalability;Redundancy;Lattices;Numerical simulation;Partitioning algorithms","Bayes methods;expectation-maximisation algorithm;image representation;iterative methods;learning (artificial intelligence);Markov processes;maximum likelihood estimation;statistical distributions","partition-maximization method;variational autoencoders;counts partition;random counts;lattice partitioning;statistical description;naive Bayesian algorithms;machine learning approaches;iterative partitioning;maximum likelihood parameters;probability distribution;intermediate representation;lattice neighbourhood trick;generative image model","","","","13","IEEE","24 Dec 2021","","","IEEE","IEEE Conferences"
"Predicting miRNA-Disease Associations Based On Multi-View Variational Graph Auto-Encoder With Matrix Factorization","Y. Ding; X. Lei; B. Liao; F. -X. Wu","Division of Biomedical Engineering, University of Saskatchewan, Saskatoon, SK, Canada; School of Computer Science, Shaanxi Normal University, Xi&#x0027;an, China; School of Mathematics and Statistics, Hainan Normal University, Haikou, China; Division of Biomedical Engineering, Department of Mechanical Engineering, and Department of Computer Science, University of Saskatchewan, Saskatoon, SK, Canada","IEEE Journal of Biomedical and Health Informatics","17 Jan 2022","2022","26","1","446","457","MicroRNAs (miRNAs) have been proved to play critical roles in diverse biological processes, including the human disease development process. Exploring the potential associations between miRNAs and diseases can help us better understand complex disease mechanisms. Given that traditional biological experiments are expensive and time-consuming, computational models can serve as efficient means to uncover potential miRNA-disease associations. This study presents a new computational model based on variational graph auto-encoder with matrix factorization (VGAMF) for miRNA-disease association prediction. More specifically, VGAMF first integrates four different types of information about miRNAs into an miRNA comprehensive similarity network and two types of information about diseases into a disease comprehensive similarity network, respectively. Then, VGAMF gets the non-linear representations of miRNAs and diseases, respectively, from those two comprehensive similarity networks with variational graph auto-encoders. Simultaneously, a non-negative matrix factorization is conducted on the miRNA-disease association matrix to get the linear representations of miRNAs and diseases. Finally, a fully connected neural network combines linear and non-linear representations of miRNAs and diseases to get the final predicted association score for all miRNA-disease pairs. In the 10-fold cross-validation experiments, VGAMF achieves an average AUC of 0.9280 on HMDD <italic>v</italic>2.0 and 0.9470 on HMDD <italic>v</italic>3.2, which outperforms other competing methods. Besides, the case studies on colon cancer and esophageal cancer further demonstrate the effectiveness of VGAMF in predicting novel miRNA-disease associations.","2168-2208","","10.1109/JBHI.2021.3088342","Natural Science and Engineering Research Council of Canada (NSERC); China Scholarship Council (CSC); National Natural Science Foundation of China(grant numbers:U19A2064,61428209); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9451570","miRNA-disease associations;non-negative matrix factorization;variational graph autoencoder;similarity network","Diseases;Predictive models;Databases;Computational modeling;Biology;Biological system modeling;Feature extraction","bioinformatics;cancer;diseases;genetics;genomics;matrix decomposition;molecular biophysics;neural nets;RNA","miRNA-disease associations;multiview variational graph auto-encoder;MicroRNAs;miRNAs;human disease development process;VGAMF;miRNA-disease association prediction;miRNA comprehensive similarity network;disease comprehensive similarity network;nonlinear representations;nonnegative matrix factorization;miRNA-disease association matrix;miRNA-disease pairs","Algorithms;Computational Biology;Genetic Predisposition to Disease;Humans;MicroRNAs;Neural Networks, Computer","6","","67","IEEE","10 Jun 2021","","","IEEE","IEEE Journals"
"Deep variational auto-encoder for text classification","L. Xie; G. Liu; H. Lian","College of Mathematics and Computer Sciences, Fuzhou University, Fuzhou, China; College of Mathematics and Computer Sciences, Fuzhou University, Fuzhou, China; College of Mathematics and Computer Sciences, Fuzhou University, Fuzhou, China","2019 IEEE International Conference on Industrial Cyber Physical Systems (ICPS)","1 Aug 2019","2019","","","737","742","Dimensionality reduction is an important technique in machine learning and data mining, which makes the processing of high dimensional data faster. An efficient method for dimensionality reduction can find a low-dimension feature subset extracting the most relevant information. The dimensionality reduction methods based on neural network are applied to all kinds of data, especially computer vision data. In this paper, we focus on the text data with high sparse and high dimension, then reduce its dimension by using the variational auto-encoder. The performance of variational auto-encoder in dimensionality reduction is observed by comparison test. First, unstructured text data is converted to computer-processable vectors using term frequencyCinverse document frequency. Then variational auto-encoder is used to reduce the dimensionality. Finally, the experiment verifies the efficiency of variational auto-encoder by comparing seven commonly used dimensionality reduction methods.","","978-1-5386-8500-6","10.1109/ICPHYS.2019.8780129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8780129","Machine learning;dimensionality reduction;text classification;variational auto-encoder;feature representation","Dimensionality reduction;Feature extraction;Biological neural networks;Data models;Data mining;Neurons;Manganese","data mining;feature extraction;learning (artificial intelligence);neural nets;pattern classification;text analysis","text classification;machine learning;data mining;high dimensional data;low-dimension feature subset;dimensionality reduction methods;computer vision data;high sparse dimension;unstructured text data;deep variational autoencoder;computer-processable vectors;inverse document frequency","","","","25","","1 Aug 2019","","","IEEE","IEEE Conferences"
"Enhancing Profit by Predicting Stock Prices using Deep Neural Networks","S. Abrishami; M. Turek; A. Roy Choudhury; P. Kumar","Department of Computer Science, Florida State University, Tallahassee, FL, USA; Department of Computer Science, Florida State University, Tallahassee, FL, USA; Department of Computer Science, Florida State University, Tallahassee, FL, USA; Department of Computer Science, Florida State University, Tallahassee, FL, USA","2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)","13 Feb 2020","2019","","","1551","1556","Financial time series forecasting is a challenging task, which has attracted the interest of several researchers and is immensely important for investors. In this paper, we present a deep learning system, which uses a variety of data for a subset of the stocks on the NASDAQ exchange to forecast the stock price. The prediction model is trained on the minutely data for a specific stock ticker and predicts the closing price of that stock ticker for multi-step-ahead. Our deep learning framework consists of a Variational Autoencoder for removing noise and uses time-series data engineering to combine the higher-level features with the original features. This new set of features is fed to a Stacked LSTM Autoencoder for multi-step-ahead prediction of the stock closing price. Besides, this prediction is used by a profit-maximization strategy to provide advice on the appropriate time for buying and selling a specific stock. Results show that the proposed framework outperforms the state-of-the-art time series forecasting approaches with respect to predictive accuracy and profitability.","2375-0197","978-1-7281-3798-8","10.1109/ICTAI.2019.00223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8995189","Financial time series prediction, Stock price, LSTM, Variational autoencoder, Feature engineering.","","forecasting theory;learning (artificial intelligence);pricing;profitability;recurrent neural nets;stock markets;time series","deep neural networks;financial time series forecasting;deep learning system;NASDAQ exchange;stock price;prediction model;minutely data;specific stock ticker;deep learning framework;Variational Autoencoder;time-series data engineering;higher-level features;Stacked LSTM Autoencoder;multistep-ahead prediction;stock closing price;profit-maximization strategy;time series forecasting approaches;profitability","","1","","20","","13 Feb 2020","","","IEEE","IEEE Conferences"
"Generating High-Fidelity Images with Disentangled Adversarial VAEs and Structure-Aware Loss","H. Naderi; B. H. Soleimani; S. Matwin","Institute for Big Data Analytics, Faculty of Computer Science, Dalhousie University, Halifax, Canada; Kinaxis Inc., Ottawa, Canada; Institute of Computer Science, Polish Academy of Sciences, Warsaw, Poland","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","8","While variational autoencoders (VAE) provide the theoretical basis for deep generative models, they often produce ""blurry"" images which is linked to their training objective. In this paper, we propose the ""Sharpened Adversarial Variational Auto-Encoder"" (AVAE-S) which uses an adversarial training mechanism to fine-tune the learned latent code vector of the VAE with a specialized objective function. The loss function is designed to uncover global structure as well as the local and high frequency features in VAE and leading to the smaller variance in the aggregated posterior and hence, reducing the blurriness of their generated samples. AVAE-S leverages the learned representations to the meaningful latent features by enforcing feature consistency between the model distribution and the target distribution leading to the sharpened output with better perceptual quality. Then, AVAE-S starts training a GAN network, which generator has been collapsed on the VAE's decoder, upon that learned latent code vector. Moreover, we augment the standard VAE's evidence lower bound objective function with other element-wise similarity measures. Our experiments show that AVAE-S achieves the state-of-the-art sample quality in the common MNIST and CelebA datasets. AVAE-S shares many of the good properties of the VAE (stable training, encoder-decoder architecture, nice latent manifold structure) while generating more realistic images, as measured by the sharpness score.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9207056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207056","variational autoencoders;adversarial training;information bottleneck;constrained optimization","Image reconstruction;Gallium nitride;Training;Decoding;Linear programming;Measurement;Data models","approximation theory;image coding;learning (artificial intelligence)","AVAE-S;disentangled adversarial VAE;sharpened adversarial variational auto-encoder;latent features;feature consistency;learned representations;local frequency features;global structure;loss function;objective function;adversarial training mechanism;training objective;deep generative models;variational autoencoders;structure-aware loss;high-fidelity images;realistic images;latent manifold structure;stable training;bound objective function;standard VAE;learned latent code vector;sharpened output;model distribution","","1","","30","","28 Sep 2020","","","IEEE","IEEE Conferences"
"Deep Mixture Generative Autoencoders","F. Ye; A. G. Bors","Department of Computer Science, University of York, York, U.K.; Department of Computer Science, University of York, York, U.K.","IEEE Transactions on Neural Networks and Learning Systems","5 Oct 2022","2022","33","10","5789","5803","Variational autoencoders (VAEs) are one of the most popular unsupervised generative models that rely on learning latent representations of data. In this article, we extend the classical concept of Gaussian mixtures into the deep variational framework by proposing a mixture of VAEs (MVAE). Each component in the MVAE model is implemented by a variational encoder and has an associated subdecoder. The separation between the latent spaces modeled by different encoders is enforced using the  $d$ -variable Hilbert–Schmidt independence criterion (dHSIC). Each component would capture different data variational features. We also propose a mechanism for finding the appropriate number of VAE components for a given task, leading to an optimal architecture. The differentiable categorical Gumbel-softmax distribution is used in order to generate dropout masking parameters within the end-to-end backpropagation training framework. Extensive experiments show that the proposed MVAE model can learn a rich latent data representation and is able to discover additional underlying data representation factors.","2162-2388","","10.1109/TNNLS.2021.3071401","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9408405","Generative deep learning;mixtures of variational autoencoders (MVAEs);optimal number of components in mixtures;representation learning","Mixture models;Decoding;Data models;Training;Linear programming;Probabilistic logic;Task analysis","","","","3","","62","IEEE","19 Apr 2021","","","IEEE","IEEE Journals"
"Generalized Zero-Shot Learning Using Conditional Wasserstein Autoencoder","J. Kim; B. Shim","Department of Electrical and Computer Engineering, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, Korea","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","3413","3417","Generalized zero-shot learning (GZSL) is a technique to train a deep learning model to identify unseen classes. Conventionally, conditional generative models have been employed to generate training data for unseen classes from the attribute. In this paper, we propose a new conditional generative model that improves the GZSL performance greatly. In a nutshell, the proposed model, called conditional Wasserstein autoencoder (CWAE), minimizes the Wasserstein distance between the real and generated image feature distributions using an encoder-decoder architecture. From the extensive experiments on various benchmark datasets, we show that the proposed CWAE outperforms conventional generative models in terms of the GZSL classification performance.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9747741","Samsung; National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747741","Generalized zero-shot learning;generative model;generative adversarial network;variational autoencoder","Deep learning;Conferences;Training data;Benchmark testing;Signal processing;Data models;Acoustics","deep learning (artificial intelligence);feature extraction;image classification","generalized zero-shot learning;deep learning;GZSL;conditional Wasserstein autoencoder;Wasserstein distance;CWAE;image feature distributions;encoder-decoder architecture;image classification","","","","23","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Timbre Transfer with Variational Auto Encoding and Cycle-Consistent Adversarial Networks","R. S. Bonnici; M. Benning; C. Saitis","EECS, Queen Mary University of London, United Kingdom; School of Mathematical Sciences, Queen Mary University of London, United Kingdom; EECS, Queen Mary University of London, United Kingdom","2022 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2022","2022","","","1","8","This work investigates the application of deep learning to timbre transfer. The adopted approach combines Variational Autoencoders with Generative Adversarial Networks to construct meaningful representations of the source audio and produce realistic generations of the target audio and is applied to the Flickr 8k Audio dataset for transferring the vocal timbre between speakers and the URMP dataset for transferring the musical timbre between instruments. Variations of the adopted approach were trained, and performance was compared using the metrics SSIM (Structural Similarity Index) and FAD (Frechét Audio Distance). It was found that a many-to-many approach supersedes a one-to-one approach in terms of reconstructive capabilities, while one-to-one showed better results in terms of adversarial translation. The adoption of a basic over a bottleneck residual block design is more suitable for enriching content information about a latent space, and the decision on whether cyclic loss takes on a variational autoencoder or vanilla auto encoder approach does not have a significant impact on reconstructive and adversarial translation aspects of the model.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9892107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9892107","music;speech;generative adversarial networks;cyclic consistency;variational autoencoders;voice conversion;timbre transfer;style transfer","Measurement;Deep learning;Image databases;Instruments;Neural networks;Multimedia Web sites;Generative adversarial networks","","","","","","26","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"Style-driven Handwritten Character Generation","Ö. Uçar; Y. Genç","Bilgisayar Mühendisliği Bölümü, Gebze Teknik Üniversitesi, Gebze, Türkiye; Bilgisayar Mühendisliği Bölümü, Gebze Teknik Üniversitesi, Gebze, Türkiye","2022 30th Signal Processing and Communications Applications Conference (SIU)","29 Aug 2022","2022","","","1","4","Handwritten character generation is a popular topic with a variety of applications. Many methods of character generation have been proposed in the literature, but few of these methods focus on preserving the writer’s style while producing handwritten characters. Representing handwriting styles involves the challenge of representing both the style of each character and the overall style of the writer. In this study, unlike the studies in the literature, it is tried to produce the characters of the person that we have not seen yet by extracting the handwriting style of the person with limited data. While producing handwritten characters, spline curves of the characters were used as input, as well as handwritten images. In the developed method, a multitasking learning network is proposed by using the Conditional Variable Autoencoder (CVAE) model, which is one of the deep learning methods. In the experiments carried out, three different models were compared and the performance of the Conditionally Variable Autoencoder (CVAE) network trained with spline curves gave better results compared to other models.","2165-0608","978-1-6654-5092-8","10.1109/SIU55565.2022.9864817","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9864817","Handwritting Generation;Conditional Variational Autoencoder;Writing Style;Spline Curve","Deep learning;Character generation;Signal processing;Multitasking;Data mining;Splines (mathematics)","deep learning (artificial intelligence);handwriting recognition;handwritten character recognition;splines (mathematics)","handwritten images;deep learning methods;style-driven handwritten character generation;spline curves;multitasking learning network;conditional variable autoencoder model;CVAE model","","","","0","IEEE","29 Aug 2022","","","IEEE","IEEE Conferences"
"Two-Stage DDoS Mitigation with Variational Auto-Encoder and Cyclic Queuing","R. Yaegashi; E. Takeshita; Y. Nakayama","Department of Computer and Information Sciences, Tokyo University of Agriculture and Technology, Tokyo, Japan; Department of Computer and Information Sciences, Tokyo University of Agriculture and Technology, Tokyo, Japan; Department of Computer and Information Sciences, Tokyo University of Agriculture and Technology, Tokyo, Japan","ICC 2022 - IEEE International Conference on Communications","11 Aug 2022","2022","","","5421","5426","Distributed Denial-of-Service (DDoS) defense mechanisms have been a significant research issue in network security. A wide variety of DDoS defense strategies have been introduced such as machine learning based approaches. Among them, the cyclic queuing based approach is a promising solution for mitigating flooding attacks with resource-limited devices at a network edge. Attacking flows are detected via the cyclic queuing, i.e. repeated reconfiguration of queue mappings, with the variation of the current queue sizes as metrics. However, continuous reconfiguration during normal operation periods is computationally intensive and increases power consumption. To address this problem, this paper proposes a two-stage mitigation scheme with variational auto-encoder (VAE) and cyclic queuing. With the proposed scheme, an edge node such as a layer-2 switch first detects anomaly with VAE, and then high-rate malicious flows are identified with the cyclic queuing algorithm. The key idea for improving detection speed is to narrow down suspected flows with the history of queue sizes around the anomaly detection. The performance of anomaly detection with VAE was evaluated with open datasets. Then, the performance of the proposed algorithm was confirmed via theoretical analysis and computer simulation.","1938-1883","978-1-5386-8347-7","10.1109/ICC45855.2022.9838914","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9838914","Internet of Things;Communication system security;Queueing analysis","Measurement;Power demand;Image edge detection;Computer simulation;Switches;Network security;Throughput","computer network security;Internet;neural nets;queueing theory;variational techniques","high-rate malicious flows;cyclic queuing algorithm;anomaly detection;VAE;network security;DDoS defense strategies;flooding attacks;network edge;queue mappings;two-stage mitigation scheme;two-stage DDoS mitigation;distributed denial-of-service defense mechanisms;variational autoencoder;power consumption;edge node;layer-2 switch;computer simulation","","","","22","IEEE","11 Aug 2022","","","IEEE","IEEE Conferences"
"Supervised Nonlinear Dynamic System for Soft Sensor Application Aided by Variational Auto-Encoder","B. Shen; Z. Ge","Alibaba-Zhejiang University Joint Institute of Frontier Technologies, Hangzhou, China; Alibaba-Zhejiang University Joint Institute of Frontier Technologies, Hangzhou, China","IEEE Transactions on Instrumentation and Measurement","11 Aug 2020","2020","69","9","6132","6142","Dynamic data modeling has been attracting much attention from researchers and has been introduced into the probabilistic latent variable model in the process industry. It is a huge challenge to extend these dynamic probabilistic latent variable models to nonlinear forms. In this article, a supervised nonlinear dynamic system (NDS) based on variational auto-encoder (VAE) is introduced for processes with dynamic behaviors and nonlinear characteristics. Based on the framework of VAE, which has a probabilistic data representation and a high fitting ability, the supervised NDS can extract effective nonlinear features for latent variable regression. The feasibility of the proposed supervised NDS is tested on two numerical examples and an industrial case. Detailed comparisons verify the effectiveness and superiority of the proposed model.","1557-9662","","10.1109/TIM.2020.2968162","National Natural Science Foundation of China (NSFC)(grant numbers:61722310); National Basic Research Program of China (973 Program)(grant numbers:2018YFC0808600); Natural Science Foundation of Zhejiang Province(grant numbers:LR18F030001); Fundamental Research Funds for the Central Universities(grant numbers:2018XZZX002-09); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8964008","Dynamic data modeling;nonlinear features;probabilistic latent variable model;supervised nonlinear dynamic system (NDS);variational autoencoder (VAE)","Data models;Nonlinear dynamical systems;Probabilistic logic;Feature extraction;Numerical models;Neural networks;Principal component analysis","data models;data structures;nonlinear dynamical systems;probability;regression analysis","variational auto-encoder;probabilistic data representation;supervised NDS;latent variable regression;supervised nonlinear dynamic system;soft sensor application;dynamic data modeling;process industry;dynamic probabilistic latent variable models;nonlinear forms","","22","","43","IEEE","20 Jan 2020","","","IEEE","IEEE Journals"
"A Sequentially-Adaptive Deep Variational Model for Multirate Process Anomaly Detection","Z. Chai; C. Zhao; Y. Sun","State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, China; State Key Laboratory of Synthetical Automation for Process Industries, Northeastern University, Shenyang, China; State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, China","2021 3rd International Conference on Industrial Artificial Intelligence (IAI)","30 Nov 2021","2021","","","1","6","Deep learning based process monitoring methods are attracting increasing research attention in recent years, which generally assume that the process variables are uniformly sampled. In practice, however, the process data are generally collected at multiple different rates, resulting in structurally-incomplete training data. Under such circumstances, how to build effective deep models to fully mine the multirate sampled data has become a constraint in achieving better process monitoring performance. In this paper, a sequentially-adaptive deep variational model is designed in which the knowledge that existed in variables with different rates is comprehensively extracted through deep generative neural networks. The multirate samples are first divided into multiple data blocks in which each block is collected at a uniform rate. A deep generative model is then constructed to model the uncertain data distribution and extract probabilistic feature representations considering the slowness principle. To restrain the small data problem in the blocks with slow rates, a sequentially-adaptation strategy is designed to adapt the knowledge from the fast blocks with sufficient training data and enhance the overall modeling performance. The effectiveness is demonstrated through a real-world industrial thermal power plant case.","","978-1-6654-3517-8","10.1109/IAI53119.2021.9619404","State Key Laboratory of Synthetical Automation for Process Industries; State Key Laboratory of Industrial Control Technology; Zhejiang University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9619404","process monitoring;anomaly detection;deep learning;variational autoencoders","Process monitoring;Adaptation models;Neural networks;Training data;Feature extraction;Thermal conductivity;Probabilistic logic","deep learning (artificial intelligence);power engineering computing;process monitoring;thermal power stations","uncertain data distribution;data problem;sequentially-adaptation strategy;sequentially-adaptive deep variational model;multirate process anomaly detection;deep learning based process monitoring methods;process variables;process data;structurally-incomplete training data;effective deep models;multirate sampled data;process monitoring performance;deep generative neural networks;multiple data blocks;uniform rate;deep generative model;real-world industrial thermal power plant case","","","","25","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Path Tracking Control Using Imitation Learning with Variational Auto-Encoder","S. -J. Lee; T. Y. Chun; H. W. Lim; S. -H. Lee","Institute of Defense Advanced Technology Research, Agency for Defense Development, Yuseong P.O.Box 35, Daejeon, Korea; Institute of Defense Advanced Technology Research, Agency for Defense Development, Yuseong P.O.Box 35, Daejeon, Korea; Institute of Defense Advanced Technology Research, Agency for Defense Development, Yuseong P.O.Box 35, Daejeon, Korea; Institute of Defense Advanced Technology Research, Agency for Defense Development, Yuseong P.O.Box 35, Daejeon, Korea","2019 19th International Conference on Control, Automation and Systems (ICCAS)","30 Jan 2020","2019","","","501","505","This paper presents a path tracking algorithm for autonomous driving that learns an action command from high-dimensional input state vector, e.g., grid-maps. The learning framework is built upon a variational auto-encoder (VAE) and takes advantage of the efficient path tracking results that already exist or can be obatined from a human expert. The VAE is known to give smooth latent representations of the input data and we make one of the latent attribute follow the expert's command. We implement an autonomous driving system on the open source robot simulator (Webots) and collect the demonstration data for training the VAE. Numerical results show that the proposed tracking method can drive a vehicle robustly without explicitly detecting the road features.","2642-3901","978-89-93215-17-5","10.23919/ICCAS47443.2019.8971711","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8971711","autonomous driving;path tracking;imitation learning;variational autoencoder","","control engineering computing;learning (artificial intelligence);mobile robots;neural nets;object tracking;path planning;public domain software","imitation learning;variational auto-encoder;VAE;autonomous driving system;open source robot simulator;path tracking control;high-dimensional input state vector;Webots;road features","","","","13","","30 Jan 2020","","","IEEE","IEEE Conferences"
"Cost–effective Variational Active Entity Resolution","A. Bogatu; N. W. Paton; M. Douthwaite; S. Davie; A. Freitas","University of Manchester, UK; Peak AI Ltd.; University of Manchester, UK; University of Manchester, UK; Idiap Research Institute, Switzerland","2021 IEEE 37th International Conference on Data Engineering (ICDE)","22 Jun 2021","2021","","","1272","1283","Accurately identifying different representations of the same real–world entity is an integral part of data cleaning and many methods have been proposed to accomplish it. The challenges of this entity resolution task that demand so much research attention are often rooted in the task–specificity and user–dependence of the process. Adopting deep learning techniques has the potential to lessen these challenges. In this paper, we set out to devise an entity resolution method that builds on the robustness conferred by deep autoencoders to reduce human–involvement costs. Specifically, we reduce the cost of training deep entity resolution models by performing unsupervised representation learning. This unveils a transferability property of the resulting model that can further reduce the cost of applying the approach to new datasets by means of transfer learning. Finally, we reduce the cost of labeling training data through an active learning approach that builds on the properties conferred by the use of deep autoencoders. Empirical evaluation confirms the accomplishment of our cost–reduction desideratum, while achieving comparable effectiveness with state–of–the–art alternatives.","2375-026X","978-1-7281-9184-3","10.1109/ICDE51399.2021.00114","Innovate UK; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9458760","Entity Resolution;Variational Auto Encoders;Deep Learning;Data Cleaning","Deep learning;Training;Adaptation models;Transfer learning;Training data;Robustness;Data models","data handling;deep learning (artificial intelligence);unsupervised learning","entity resolution task;task-specificity;user-dependence;deep learning techniques;entity resolution method;deep autoencoders;human-involvement costs;deep entity resolution models;unsupervised representation learning;transfer learning;training data;active learning approach;cost-reduction desideratum;cost-effective variational active entity resolution;real-world entity;data cleaning","","","","44","IEEE","22 Jun 2021","","","IEEE","IEEE Conferences"
"Detection of Abnormal Line Loss Rate in Low-voltage Transformer District Based on VAE","Z. Ma; W. Chen; C. Liu; H. Zhu; L. Wei","State Grid Jiangsu Electric Power Co., Ltd. Nanjing power supply branch College of Energy and Electrical Engineering, Hohai University, Nanjing, Jiangsu Province, China; College of Energy and Electrical Engineering, Hohai University, Nanjing, Jiangsu Province, China; College of Energy and Electrical Engineering, Hohai University, Nanjing, Jiangsu Province, China; State Grid Jiangsu Electric Power Co., Ltd. Nanjing power supply branch, Janjing, Jiangsu Province, China; State Grid Jiangsu Electric Power Co., Ltd., Nanjing, Jiangsu Province, China","2021 IEEE Sustainable Power and Energy Conference (iSPEC)","24 Mar 2022","2021","","","3739","3744","Line loss rate is an important indicator of the safe, stable, and efficient operation of the power system. As the number of low-voltage transformer district at the end of the power supply is huge and the lines are complex, the power loss generated should be paid more attention to. Starting from the low-voltage transformer district, this paper proposes a line loss rate anomaly detection model based on a variational autoencoder. Use the random matrix theory to analyze the correlation of the line loss data, filter out the line loss rate influencing factors, and construct the low-voltage transformer district line loss rate influencing factor index system. On this basis, a line loss rate anomaly detection model based on a variational autoencoder is established, the input features are modeled in the hidden space, and anomalous features are sampled from them. The reconstruction probability of the reconstructed data will be the same as the threshold. It compares the identification of outliers, and proves the superiority of the variational autoencoder in the identification of abnormal data of online damage through the test and analysis of the sample transformer district.","","978-1-6654-1439-5","10.1109/iSPEC53008.2021.9735892","State Grid Jiangsu Electric Power; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9735892","Low-voltage transformer district;Line loss rate;Anomaly detection;Variational autoencoder","Low voltage;Power supplies;Forestry;Transformers;Feature extraction;Data models;Power grids","fault diagnosis;losses;matrix algebra;neural net architecture;power distribution lines;power engineering computing;power transformers;probability;support vector machines","variational autoencoder;sample transformer district;abnormal line loss rate;power loss;line loss rate anomaly detection model;line loss data;line loss rate influencing factors;low-voltage transformer district line loss rate;factor index system;online damage;random matrix theory","","","","15","IEEE","24 Mar 2022","","","IEEE","IEEE Conferences"
"Closing the Sim-to-Real Gap in Guided Wave Damage Detection with Adversarial Training of Variational Auto-Encoders","I. D. Khurjekar; J. B. Harley","Dept. of Electrical and Computer Engineering, University of Florida, Gainesville, FL; Dept. of Electrical and Computer Engineering, University of Florida, Gainesville, FL","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","3823","3827","Guided wave testing is a popular approach for monitoring the structural integrity of infrastructures. We focus on the primary task of damage detection, where signal processing techniques are commonly employed. The detection performance is affected by a mismatch between the wave propagation model and experimental wave data. External variations, such as temperature, which are difficult to model, also affect the performance. While deep learning models can be an alternative detection method, there is often a lack of real-world training datasets. In this work, we counter this challenge by training an ensemble of variational autoencoders only on simulation data with a wave physics-guided adversarial component. We set up an experiment with non-uniform temperature variations to test the robustness of the methods. We compare our scheme with existing deep learning detection schemes and observe superior performance on experimental data.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746196","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746196","Damage detection;guided waves;sim-to-real;variational auto-encoder;adversarial training","Training;Deep learning;Temperature distribution;Propagation;Signal processing;Data models;Robustness","condition monitoring;deep learning (artificial intelligence);nondestructive testing;signal detection;structural engineering computing;wave propagation","sim-to-real gap;guided wave damage detection;adversarial training;guided wave testing;signal processing techniques;wave propagation model;experimental wave data;alternative detection method;variational autoencoders;wave physics-guided adversarial component;nonuniform temperature variations;deep learning detection schemes;infrastructure structural integrity","","","","21","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Improving Emotion Classification through Variational Inference of Latent Variables","S. Parthasarathy; V. Rozgic; M. Sun; C. Wang",University of Texas at Dallas; Amazon Alexa; Amazon Alexa; Amazon Alexa,"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","7410","7414","Conventional models for emotion recognition from speech signal are trained in supervised fashion using speech utterances with emotion labels. In this study we hypothesize that speech signal depends on multiple latent variables including the emotional state, age, gender, and speech content. We propose an Adversarial Autoencoder (AAE) to perform variational inference over the latent variables and reconstruct the input feature representations. Reconstruction of feature representations is used as an auxiliary task to aid the primary emotion recognition task. Experiments on the IEMOCAP dataset demonstrate that the auxiliary learning tasks improve emotion classification accuracy compared to a baseline supervised classifier. Further, we demonstrate that the proposed learning approach can be used for the end-to-end speech emotion recognition, as its applicable for models that operate on frame-level inputs.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682823","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682823","Emotion recognition;Autoencoder;Adversarial training","Speech recognition;Emotion recognition;Task analysis;Training;Feature extraction;Sun;Indexes","emotion recognition;inference mechanisms;learning (artificial intelligence);pattern classification;signal classification;speech recognition","emotional state;speech content;variational inference;input feature representations;auxiliary task;primary emotion recognition task;auxiliary learning tasks;emotion classification accuracy;baseline supervised classifier;end-to-end speech emotion recognition;conventional models;speech signal;supervised fashion;speech utterances;emotion labels;multiple latent variables;adversarial autoencoder;IEMOCAP dataset;AAE","","12","","17","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Uniform and Variational Deep Learning for RGB-D Object Recognition and Person Re-Identification","L. Ren; J. Lu; J. Feng; J. Zhou","State Key Laboratory of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China; State Key Laboratory of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China; State Key Laboratory of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China; State Key Laboratory of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Beijing, China","IEEE Transactions on Image Processing","1 Aug 2019","2019","28","10","4970","4983","In this paper, we propose a uniform and variational deep learning (UVDL) method for RGB-D object recognition and person re-identification. Unlike most existing object recognition and person re-identification methods, which usually use only the visual appearance information from RGB images, our method recognizes visual objects and persons with RGB-D images to exploit more reliable information such as geometric and anthropometric information that are robust to different viewpoints. Specifically, we extract the depth feature and the appearance feature from the depth and RGB images with two deep convolutional neural networks, respectively. In order to combine the depth feature and the appearance feature to exploit their relationship, we design a uniform and variational multi-modal auto-encoder at the top layer of our deep network to seek a uniform latent variable by projecting them into a common space, which contains the whole information of RGB-D images and has small intra-class variation and large inter-class variation, simultaneously. Finally, we optimize the auto-encoder layer and two deep convolutional neural networks jointly to minimize the discriminative loss and the reconstruction error. The experimental results on both RGB-D object recognition and RGB-D person re-identification are presented to show the efficiency of our proposed approach.","1941-0042","","10.1109/TIP.2019.2915655","National Basic Research Program of China (973 Program)(grant numbers:2016YFB1001004); National Natural Science Foundation of China(grant numbers:61822603,U1813218,U1713214,61672306,61572271); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8715446","Deep learning;object recognition;person re-identification;uniform;variational;multi-modal learning","Object recognition;Feature extraction;Deep learning;Image color analysis;Visualization;Convolutional neural networks;Image reconstruction","convolutional neural nets;feature extraction;image classification;image colour analysis;image recognition;learning (artificial intelligence);object detection;object recognition","RGB-D object recognition;person re-identification;visual appearance information;RGB images;visual objects;RGB-D images;geometric information;anthropometric information;depth feature;appearance feature;deep convolutional neural networks;deep network;uniform latent variable;object recognition;intraclass variation;interclass variation;variational multimodal autoencoder","","15","","80","IEEE","15 May 2019","","","IEEE","IEEE Journals"
"Split Hierarchical Variational Compression","T. Ryder; C. Zhang; N. Kang; S. Zhang",Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","386","395","Variational autoencoders (VAEs) have witnessed great success in performing the compression of image datasets. This success, made possible by the bits-back coding framework, has produced competitive compression performance across many benchmarks. However, despite this, VAE architectures are currently limited by a combination of coding practicalities and compression ratios. That is, not only do state-of the-art methods, such as normalizing flows, often demonstrate out-performance, but the initial bits required in coding makes single and parallel image compression challenging. To remedy this, we introduce Split Hierarchical Variational Compression (SHVC). SHVC introduces two novelties. Firstly, we propose an efficient autoregressive prior, the autoregressive sub-pixel convolution, that allows a generalisation between per-pixel autoregressions and fully factorised probability models. Secondly, we define our coding framework, the autoregressive initial bits, that flexibly supports parallel coding and avoids -for the first time - many of the practicalities commonly associated with bits-back coding. In our experiments, we demonstrate SHVC is able to achieve state-of the-art compression performance across full-resolution lossless image compression tasks, with up to 100x fewer model parameters than competing VAE approaches.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879306","Statistical methods; Image and video synthesis and generation; Machine learning; Vision applications and systems","Image coding;Statistical analysis;Convolution;Computational modeling;Machine vision;Data compression;Machine learning","autoregressive processes;data compression;image coding;neural nets","bits-back coding framework;coding practicalities;VAE architectures;competitive compression performance;image datasets;Variational autoencoders;full-resolution lossless image compression tasks;compression performance;parallel coding;autoregressive initial bits;coding framework;per-pixel autoregressions;autoregressive sub-pixel convolution;SHVC;Split Hierarchical Variational Compression;parallel image compression;compression ratios","","","","43","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Radar HRRP Data Augmentation Using CVAE with Extended Latent Space Distribution","W. Zhang; Y. Lin; L. Zhuang; J. Guo",Nanjing Research Institute of Electronics Technology; Nanjing Research Institute of Electronics Technology; Nanjing Research Institute of Electronics Technology; Nanjing Research Institute of Electronics Technology,"2021 IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)","19 Jul 2021","2021","4","","1346","1354","In this paper, we propose a variational autoencoder (VAE) based generative model with particular regard to the aspect angle sensitivity of the radar HRRP data of maritime vessels, and conduct high-resolution range profile (HRRP) data augmentation experiments to improve the recognition performance. Specifically, we train the extended conditional Variational auto-encoder (ECVAE) model to reconstruction data, and consider the latent space distribution of the sample as a more general multidimensional posterior Gaussian distribution. Discrete or continuous labels can be input to the model. Design a periodic latent distribution to deal with periodic labels. Use Kullback-Leibler (KL) divergence to evaluate the similarity of the distribution and reconstruct data with the latent space distribution which making the dimension as low as possible. Experiments based on MNIST data and measured vessels HRRP data show that the ECVAE model can augment the data of samples to improve recognition Performance, in especial in the case of a small number of data samples.","2693-2776","978-1-7281-8535-4","10.1109/IMCEC51613.2021.9482276","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9482276","high-resolution range profile;Variational auto-encoder;data augmentation;posterior distribution;kl divergence","Sensitivity;Target recognition;Spaceborne radar;Conferences;Gaussian distribution;Generative adversarial networks;Data models","Gaussian distribution;image coding;image recognition;image resolution;learning (artificial intelligence);radar computing;radar imaging;radar resolution;radar target recognition","ECVAE model;recognition performance;radar HRRP data augmentation;extended latent space distribution;variational autoencoder;generative model;aspect angle sensitivity;maritime vessels;high-resolution range profile;data augmentation experiments;reconstruction data;general multidimensional posterior Gaussian distribution;discrete labels;continuous labels;periodic latent distribution;periodic labels;MNIST data;extended conditional variational autoencoder model;vessel HRRP data;Kullback-Leibler divergence","","1","","29","IEEE","19 Jul 2021","","","IEEE","IEEE Conferences"
"Sentimental Style Transfer in Text with Multigenerative Variational Auto-Encoder","M. H. Palash; P. P. Das; S. Haque","Department of Computer Science and Engineering, Shahjalal University of Science and Technology; Department of Computer Science and Engineering, Shahjalal University of Science and Technology; Department of Computer Science and Engineering, Shahjalal University of Science and Technology","2019 International Conference on Bangla Speech and Language Processing (ICBSLP)","4 May 2020","2019","","","1","4","Style transfer is an emerging trend in the fields of deep learning's applications, especially in images and audio data this is proven very useful and sometimes the results are astonishing. Gradually styles of textual data are also being changed in many novel works. This paper focuses on the transfer of the sentimental vibe of a sentence. Given a positive clause, the negative version of that clause or sentence is generated keeping the context same. The opposite is also done with negative sentences. Previously this was a very tough job because the go-to techniques for such tasks such as Recurrent Neural Networks (RNNs) [1] and Long Short-Term Memories(LSTMs) [2] can't perform well with it. But since newer technologies like Generative Adversarial Network(GAN) and Variational AutoEncoder(VAE) are emerging, this work seem to become more and more possible and effective. In this paper, Multi-Genarative Variational Auto-Encoder is employed to transfer sentiment values. Inspite of working with a small dataset, this model proves to be promising.","","978-1-7281-5241-7","10.1109/ICBSLP47725.2019.201508","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9084042","text;style;style-transfer;vae;sentiment-transfer","","image processing;learning (artificial intelligence);recurrent neural nets;text analysis","sentimental style transfer;multigenerative variational auto-encoder;deep learning;audio data;textual data;recurrent neural networks;transfer sentiment values;generative adversarial network;long short-term memories","","","","15","","4 May 2020","","","IEEE","IEEE Conferences"
"MoveAE: Modifying Affective Robot Movements Using Classifying Variational Autoencoders","M. Suguitan; R. Gomez; G. Hoffman","HRC2 Lab, Cornell University, Ithaca, New York, United States; Honda Research Institute Japan, Wako, Saitama, Japan; HRC2 Lab, Cornell University, Ithaca, New York, United States","2020 15th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","21 Jul 2021","2020","","","481","489","We propose a method for modifying affective robot movements using neural networks. Social robots use gestures and other movements to express their internal states. However, a robot’s interactive capabilities are hindered by the predominant use of a limited set of preprogrammed or hand-animated behaviors, which can be repetitive and predictable, making sustained human-robot interactions difficult to maintain. To address this, we developed a method for modifying existing emotive robot movements by using neural networks. We use hand-crafted movement samples and a classifying variational autoencoder trained on these samples. Our method then allows for adjustment of affective movement features by using simple arithmetic in the network’s latent embedding space. We present the implementation and evaluation of this approach and show that editing in the latent space can modify the emotive quality of the movements while preserving recognizability and legibility in many cases. This supports neural networks as viable tools for creating and modifying expressive robot behaviors. CCS CONCEPTS • Artificial intelligence→Cognitive robotics; • Machine learning→ neural networks; • Human-centered computing→HCI theory, concepts and models. ACM Reference Format: Michael Suguitan, Randy Gomez, and Guy Hoffman. 2020. MoveAE: Modifying Affective Robot Movements Using Classifying Variational Autoencoders. In Proceedings of the 2020 ACM/IEEE International Conference on HumanRobot Interaction (HRI’20), March 23-26, 2020, Cambridge, United Kingdom. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3319502.3374807","2167-2148","978-1-4503-6746-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9484275","Social robots;deep learning;neural networks;affective generation","Measurement;Emotion recognition;Computational modeling;Neural networks;Linear regression;Human-robot interaction;Kinematics","","","","","","38","","21 Jul 2021","","","IEEE","IEEE Conferences"
"ANE: Network Embedding via Adversarial Autoencoders","Y. Xiao; D. Xiao; B. Hu; C. Shi","Beijing Key Lab of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Key Lab of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Key Lab of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Key Lab of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China","2018 IEEE International Conference on Big Data and Smart Computing (BigComp)","28 May 2018","2018","","","66","73","Network embedding is an important method to learn low-dimensional representations of vertexes in network, whose goal is to capture and preserve the highly non-linear network structures. Here, we propose an Adversarial autoencoders based Network Embedding method (ANE for short), which utilizes the rencently proposed adversarial autoencoders to perform variational inference by matching the aggregated posterior of low-dimensional representations of vertexes with an arbitraray prior distribution. This framework introduces adversarial regularization to autoencoders. And it is able to attaches the latent representations of similar vertexes to each other and thus prevents the manifold fracturing problem that is typically encountered in the embeddings learnt by the autoencoders. Experiments demonstrate the effictiveness of ANE on link prediction and multi-label classification on three real-world information networks.","2375-9356","978-1-5386-3649-7","10.1109/BigComp.2018.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8367099","network embedding;adversarial autoencoders;latent representations.","Training;Image reconstruction;Gallium nitride;Manifolds;Decoding;Linear programming;Laplace equations","information networks;learning (artificial intelligence);network theory (graphs);pattern classification","similar vertexes;embeddings learnt;ANE;real-world information networks;adversarial autoencoders;nonlinear network structures;Network Embedding method;adversarial regularization;latent representations;manifold fracturing problem;multi-label classification;link prediction","","5","","26","IEEE","28 May 2018","","","IEEE","IEEE Conferences"
"Variational manifold learning from incomplete data: application to multi-slice dynamic MRI","Q. Zou; A. H. Ahmed; P. Nagpal; S. Priya; R. F. Schulte; M. Jacob","Iowa City, IA, USA; Rochester, MN, USA; Madison, WI, USA; Iowa City, IA, USA; Munich, Germany; Iowa City, IA, USA","IEEE Transactions on Medical Imaging","","2022","PP","99","1","1","Current deep learning-based manifold learning algorithms such as the variational autoencoder (VAE) require fully sampled data to learn the probability density of real-world datasets. However, fully sampled data is often unavailable in a variety of problems, including the recovery of dynamic and high-resolution MRI. We introduce a novel variational approach to learn a manifold from undersampled data. The VAE uses a decoder fed by latent vectors, drawn from a conditional density estimated from the fully sampled images using an encoder. Since fully sampled images are not available in our setting, we approximate the conditional density of the latent vectors by a parametric model whose parameters are estimated from the undersampled measurements using back-propagation. We use the framework for the joint alignment and recovery of multi-slice free breathing and ungated cardiac MRI data from highly undersampled measurements. Experimental results demonstrate the utility of the proposed scheme in dynamic imaging alignment and reconstructions.","1558-254X","","10.1109/TMI.2022.3189905","National Institute on Aging(grant numbers:R01AG067078-01A1); NIH(grant numbers:1S10OD025025-01); National Institute of Biomedical Imaging and Bioengineering(grant numbers:R01EB019961); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825710","Variational autoencoder;Generative model;CNN;Manifold approach;Unsupervised learning;Free-breathing cardiac MRI;Image reconstruction","Magnetic resonance imaging;Manifolds;Three-dimensional displays;Data models;Time series analysis;Convolutional neural networks;Volume measurement","","","","","","","IEEE","11 Jul 2022","","","IEEE","IEEE Early Access Articles"
"A Minimally Supervised Approach Based on Variational Autoencoders for Anomaly Detection in Autonomous Robots","D. Azzalini; L. Bonali; F. Amigoni","Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy","IEEE Robotics and Automation Letters","18 Mar 2021","2021","6","2","2985","2992","Detection of anomalies and faults is a crucial ability for fully autonomous robots. This letter proposes a new deep learning-based minimally supervised method for detecting anomalies in autonomous robots. We contribute a new Variational Auto-Encoder architecture able to model very long multivariate sensor logs exploiting a new incremental training method, which induces a progress-based latent space that can be used to detect anomalies both at runtime and offline. While most existing approaches are trained in a semi-supervised fashion and require big batches of nominal observations, our method is trained using unlabeled observations of a robot performing a task, containing both nominal and anomalous executions. Only a very little amount (even just one) of labeled nominal executions is then required to partition the learned latent space into nominal and anomalous regions. Experimental results show that our method outperforms state-of-the-art anomaly detectors commonly used in robotics both in terms of false positive rate and alert delay.","2377-3766","","10.1109/LRA.2021.3062597","Politecnico di Milano; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9364363","Deep learning methods;failure detection and recovery","Robots;Anomaly detection;Robot sensing systems;Image reconstruction;Task analysis;Decoding;Training","learning (artificial intelligence);mobile robots;robot vision","robotics;state-of-the-art anomaly detectors;anomalous regions;nominal regions;learned latent space;labeled nominal executions;anomalous executions;unlabeled observations;nominal observations;semisupervised fashion;progress-based latent space;incremental training method;long multivariate sensor;variational auto-encoder architecture;deep learning-based minimally supervised method;fully autonomous robots;crucial ability;anomaly detection;minimally supervised approach","","4","","30","IEEE","26 Feb 2021","","","IEEE","IEEE Journals"
"An Analysis on Disentanglement in Machine Learning","H. Mogultay; S. Kalkan; F. T. Yarman Vural","Bilgisayar Mühendisliği, Orta Doğu Teknik Üniversitesi, Ankara, Türkiye; Bilgisayar Mühendisliği, Orta Doğu Teknik Üniversitesi, Ankara, Türkiye; Bilgisayar Mühendisliği, Orta Doğu Teknik Üniversitesi, Ankara, Türkiye","2022 30th Signal Processing and Communications Applications Conference (SIU)","29 Aug 2022","2022","","","1","4","Learnt representations by Deep autoencoders is not capable of decomposing the complex information into simple notion. In other words, attributes of samples are entangled in the basis vectors spanning the learned space. This leads to significant errors in deep learning algorithms. In order to avoid these errors, it is necessary to separate the feature space according to the common features shared between classes and to define a simple subspace for each feature. This approach has led to the birth of a new paradigm in Machine Learning, called disentanglement.Roughly, disentangled models can be defined as models that can independently learn the different components of the probability density function that produces the dataset in the feature space. Unfortunately, it is not always possible to learn these models. For this reason, there is still no easily applicable mathematical definition of disentanglement in the literature. In this study, a mathematical definition of the concept of disentanglement will be made and methods and metrics related to this approach will be discussed.","2165-0608","978-1-6654-5092-8","10.1109/SIU55565.2022.9864743","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9864743","Disentanglement;variational autoencoder;representation learning","Measurement;Deep learning;Machine learning algorithms;Signal processing algorithms;Signal processing;Probability density function;Mathematical models","feature extraction;image representation;learning (artificial intelligence);probability","basis vectors;learned space;deep learning algorithms;feature space;machine learning;disentangled models;probability density function;learnt representations;deep autoencoders;complex information;mathematical definition","","","","0","IEEE","29 Aug 2022","","","IEEE","IEEE Conferences"
"VISinger: Variational Inference with Adversarial Learning for End-to-End Singing Voice Synthesis","Y. Zhang; J. Cong; H. Xue; L. Xie; P. Zhu; M. Bi","Audio, Speech and Language Processing Group (ASLP@NPU) School of Computer Science, Northwestern Polytechnical University, Xi’an, China; Audio, Speech and Language Processing Group (ASLP@NPU) School of Computer Science, Northwestern Polytechnical University, Xi’an, China; Audio, Speech and Language Processing Group (ASLP@NPU) School of Computer Science, Northwestern Polytechnical University, Xi’an, China; Audio, Speech and Language Processing Group (ASLP@NPU) School of Computer Science, Northwestern Polytechnical University, Xi’an, China; Fuxi AI Lab, NetEase Inc, Hangzhou, China; Fuxi AI Lab, NetEase Inc, Hangzhou, China","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","7237","7241","In this paper, we propose VISinger, a complete end-to-end high-quality singing voice synthesis (SVS) system that directly generates singing audio from lyrics and musical score. Our approach is inspired by VITS [1], an end-to-end speech generation model which adopts VAE-based posterior encoder augmented with normalizing flow based prior encoder and adversarial decoder. VISinger follows the main architecture of VITS, but makes substantial improvements to the prior encoder according to the characteristics of singing. First, instead of using phoneme-level mean and variance of acoustic features, we introduce a length regulator and a frame prior network to get the frame-level mean and variance on acoustic features, modeling the rich acoustic variation in singing. Second, we further introduce an F0 predictor to guide the frame prior network, leading to stabler singing performance. Finally, to improve the singing rhythm, we modify the duration predictor to specifically predict the phoneme to note duration ratio, helped with singing note normalization. Experiments on a professional Mandarin singing corpus show that VISinger significantly outperforms FastSpeech+Neural-Vocoder two-stage approach and the oracle VITS; ablation study demonstrates the effectiveness of different contributions.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9747664","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747664","Singing voice synthesis;variational autoencoder;adversarial learning;normalizing flows","Regulators;Conferences;Signal processing;Rhythm;Adversarial machine learning;Decoding;Speech processing","audio signal processing;music;speech processing;speech synthesis;vocoders","rich acoustic variation;frame prior network;stabler singing performance;singing rhythm;singing note normalization;professional Mandarin singing corpus show;VISinger;variational inference;adversarial learning;end-to-end singing;complete end-to-end high-quality singing voice synthesis system;singing audio;VITS;end-to-end speech generation model;VAE-based posterior encoder;prior encoder;adversarial decoder;phoneme-level mean;acoustic features;frame-level mean","","","","24","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Chiller Fault Diagnosis Based on VAE-Enabled Generative Adversarial Networks","K. Yan; J. Su; J. Huang; Y. Mo","National University of Singapore, Singapore; Key Laboratory of Electromagnetic Wave Information Technology and Metrology of Zhejiang Province, College of Information Engineering, China Jiliang University, Hangzhou, China; School of Information and Electronic Engineering, Zhejiang Gongshang University, Hangzhou, China; Fujian Province University Key Laboratory of Computational Science, School of Mathematical Sciences, Huaqiao University, Quanzhou, China","IEEE Transactions on Automation Science and Engineering","5 Jan 2022","2022","19","1","387","395","Artificial intelligence (AI)-enhanced automated fault diagnosis (AFD) has become increasingly popular for chiller fault diagnosis with promising classification performance. In practice, a sufficient number of fault samples are required by the AI methods in the training phase. However, faulty training samples are generally much more difficult to be collected than normal training samples. Data augmentation is introduced in these scenarios to enhance the training data set with synthetic data. In this study, a variational autoencoder-based conditional Wasserstein GAN with gradient penalty (CWGAN-GP-VAE) is proposed to diagnose various faults for chillers. A detailed comparative study has been conducted with real-world fault data samples to verify the effectiveness and robustness of the proposed methodology. Note to Practitioners—This work attacks the fact that faulty training samples are usually much harder to be collected than the normal training samples in the practice of chiller automated fault diagnosis (AFD). Modern supervised learning chiller AFD relies on a sufficient number of faulty training samples to train the classifier. When the number of faulty training samples is insufficient, the conventional AFD methods fail to work. This study proposed a variational autoencoder-based conditional Wasserstein GAN with gradient penalty (CWGAN-GP-VAE) framework for generating synthetic faulty training samples to enrich the training data set for machine learning-based AFD methods. The proposed algorithm has been carefully designed, implemented, and practically proved to be more effective than the existing methods in the literature.","1558-3783","","10.1109/TASE.2020.3035620","Ministry of Education (MOE) Singapore, Tier 1 Grant for National University of Singapore (NUS)(grant numbers:R296000208133); National Natural Science Foundation of China(grant numbers:61850410531,61602431,61972156); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9264218","Data augmentation;fault diagnosis;generative adversarial network (GAN);variational autoencoder (VAE)","Training;Generative adversarial networks;Training data;Gallium nitride;Fault diagnosis;Refrigerants;HVAC","condition monitoring;fault diagnosis;HVAC;mechanical engineering computing;neural nets;pattern classification;supervised learning","chiller fault diagnosis;VAE-enabled generative adversarial networks;artificial intelligence;CWGAN-GP-VAE;gradient penalty framework;machine learning based AFD;supervised learning;faulty training samples;classifier training;variational autoencoder-based conditional Wasserstein GAN with gradient penalty (;HVAC systems","","6","","38","IEEE","19 Nov 2020","","","IEEE","IEEE Journals"
"Robotic Grasp Detection By Learning Representation in a Vector Quantized Manifold","M. Mahajan; T. Bhattacharjee; A. Krishnan; P. Shukla; G. C. Nandi","Center of Intelligent Robotics, Indian Institute of Information Technology, Allahabad, Prayagraj, India; Center of Intelligent Robotics, Indian Institute of Information Technology, Allahabad, Prayagraj, India; Center of Intelligent Robotics, Indian Institute of Information Technology, Allahabad, Prayagraj, India; Center of Intelligent Robotics, Indian Institute of Information Technology, Allahabad, Prayagraj, India; Center of Intelligent Robotics, Indian Institute of Information Technology, Allahabad, Prayagraj, India","2020 International Conference on Signal Processing and Communications (SPCOM)","28 Aug 2020","2020","","","1","5","For a robot to perform complex manipulation tasks, it is necessary for it to have a good grasping ability. However, vision based robotic grasp detection is hindered by the unavailability of sufficient labelled data. Furthermore, the application of semi-supervised learning techniques to grasp detection is underexplored. In this paper, a semi-supervised learning based grasp detection approach has been presented, which models a discrete latent space using a Vector Quantized Variational AutoEncoder (VQ-VAE). To the best of our knowledge, this is the first time a Variational AutoEncoder (VAE) has been applied in the domain of robotic grasp detection. The VAE helps the model in generalizing beyond the Cornell Grasping Dataset (CGD) despite having a limited amount of labelled data by also utilizing the unlabelled data. This claim has been validated by testing the model on images, which are not available in the CGD. Along with this, we augment the Generative Grasping Convolutional Neural Network (GGCNN) architecture with the decoder structure used in the VQ-VAE model with the intuition that it should help to regress in the vector-quantized latent space. Subsequently, the model performs significantly better than the existing approaches which do not make use of unlabelled images to improve the grasp.","2474-915X","978-1-7281-8895-9","10.1109/SPCOM50965.2020.9179578","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9179578","Grasp Rectangle;Vector Quantized Variational AutoEncoder (VQ-VAE);Generative Grasp Convolutional Neural Network (GGCNN)","Task analysis;Training data;Grasping;Decoding;Robot kinematics;Data models","control engineering computing;convolutional neural nets;learning (artificial intelligence);manipulators;object detection;robot vision;vector quantisation","complex manipulation tasks;vision based robotic grasp detection;semisupervised learning techniques;vector quantized variational autoencoder;Cornell grasping dataset;VQ-VAE model;vector-quantized latent space;robotic grasp detection;learning representation;generative grasping convolutional neural network architecture","","3","","19","","28 Aug 2020","","","IEEE","IEEE Conferences"
"An Efficient Prediction Method for Coronary Heart Disease Risk Based on Two Deep Neural Networks Trained on Well-Ordered Training Datasets","T. Amarbayasgalan; V. -H. Pham; N. Theera-Umpon; Y. Piao; K. H. Ryu","Database and Bioinformatics Laboratory, School of Electrical and Computer Engineering, Chungbuk National University, Cheongju, South Korea; Faculty of Information Technology, Ton Duc Thang University, Ho Chi Minh City, Vietnam; Department of Electrical Engineering, Faculty of Engineering, Chiang Mai University, Chiang Mai, Thailand; Tianjin Key Laboratory of Human Development and Reproductive Regulation, Tianjin Central Hospital of Gynecology Obstetrics, Tianjin, China; Biomedical Engineering Institute, Chiang Mai University, Chiang Mai, Thailand","IEEE Access","7 Oct 2021","2021","9","","135210","135223","This study proposes an efficient prediction method for coronary heart disease risk based on two deep neural networks trained on well-ordered training datasets. Most real datasets include an irregular subset with higher variance than most data, and predictive models do not learn well from these datasets. While most existing prediction models learned from the whole or randomly sampled training datasets, our suggested method draws up training datasets by separating regular and highly biased subsets to build accurate prediction models. We use a two-step approach to prepare the training dataset: (1) divide the initial training dataset into two groups, commonly distributed and highly biased using Principal Component Analysis, (2) enrich the highly biased group by Variational Autoencoders. Then, two deep neural network classifiers learn from the isolated training groups separately. The well-organized training groups enable a chance to build more accurate prediction models. When predicting the risk of coronary heart disease from the given input, only one appropriate model is selected based on the reconstruction error on the Principal Component Analysis model. Dataset used in this study was collected from the Korean National Health and Nutritional Examination Survey. We have conducted two types of experiments on the dataset. The first one proved how Principal Component Analysis and Variational Autoencoder models of the proposed method improves the performance of a single deep neural network. The second experiment compared the proposed method with existing machine learning algorithms, including Naïve Bayes, Random Forest, K-Nearest Neighbor, Decision Tree, Support Vector Machine, and Adaptive Boosting. The experimental results show that the proposed method outperformed conventional machine learning algorithms by giving the accuracy of 0.892, specificity of 0.840, precision of 0.911, recall of 0.920, f-measure of 0.915, and AUC of 0.882.","2169-3536","","10.1109/ACCESS.2021.3116974","Basic Science Research Program through the National Research Foundation of Korea (NRF); Ministry of Science, ICT, and Future Planning(grant numbers:2019K2A9A2A06020672,2020R1A2B5B02001717); National Natural Science Foundation of China(grant numbers:61802209); Open Fund of Tianjin Central Hospital of Gynecology Obstetrics/Tianjin Key Laboratory of Human Development and Reproductive Regulation(grant numbers:2020XHY03); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555589","Coronary heart disease;deep neural network;machine learning;principal component analysis;reconstruction error;variational autoencoder","Training;Heart;Principal component analysis;Predictive models;Diseases;Deep learning;Support vector machines","cardiology;decision trees;deep learning (artificial intelligence);diseases;medical computing;naive Bayes methods;nearest neighbour methods;pattern classification;principal component analysis;random forests;support vector machines","deep neural network classifiers;principal component analysis;single deep neural network;coronary heart disease risk;deep neural network training;well-ordered training datasets;variational autoencoder;Korean National Health;Nutritional Examination Survey;naive Bayes;random forest;k-nearest neighbor;decision tree;support vector machine;adaptive boosting","","1","","41","CCBY","1 Oct 2021","","","IEEE","IEEE Journals"
"IDA-GAN: A Novel Imbalanced Data Augmentation GAN","H. Yang; Y. Zhou","Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, Hunan, P.R. China; Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, Hunan, P.R. China","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","8299","8305","Class imbalance is a widely existed and challenging problem in real-world applications such as disease diagnosis, fraud detection, network intrusion detection and so on. Due to the scarce of data, it could significantly deteriorate the accuracy of classification. To address this challenge, we propose a novel Imbalanced Data Augmentation Generative Adversarial Networks (GAN) named IDA-GAN as an augmentation tool to deal with the imbalanced dataset. This is a great challenge because it is hard to train a GAN model under this situation. We address this issue by coupling variational autoencoder along with GAN training. In this paper, specifically, we introduce the variational autoencoder to learn the majority and minority class distributions in the latent space, and use the generative model to utilize each class distribution for the subsequent GAN training. The generative model learns useful features to generate target minority-class samples. Compared with the state-of-the-art GAN model, the experimental results demonstrate that our proposed IDA-GAN could generate more diverse minority samples with better qualities, and it could benefits the imbalanced classification task in terms of several widely-used evaluation metrics on five benchmark datasets: MNIST, Fashion-MNIST, SVHN, CIFAR-10 and GTSRB.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9411996","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9411996","Imbalanced learning;Data augmentation;Variational autoencoder;GAN","Training;Measurement;Network intrusion detection;Benchmark testing;Tools;Generative adversarial networks;Performance analysis","diseases;feature extraction;learning (artificial intelligence);pattern classification;sampling methods;security of data","variational autoencoder;minority class distributions;generative model;class distribution;subsequent GAN training;target minority-class samples;state-of-the-art GAN model;IDA-GAN;imbalanced classification task;novel Imbalanced Data Augmentation GAN;class imbalance;widely existed problem;fraud detection;network intrusion detection;novel Imbalanced Data Augmentation Generative Adversarial Networks;augmentation tool;imbalanced dataset","","1","","29","","5 May 2021","","","IEEE","IEEE Conferences"
"Context-Awareness in Ensemble Recommender System Framework","A. Drif; H. Eddine Zerrad; H. Cherifi","Networks and Distributed System Laboratory, Ferhat Abbas University, Setif, Algeria; Computer science department, Ferhat Abbas University, Setif, Algeria; Computer Laboratory of Burgundy, University of Burgundy, Dijon, France","2021 International Conference on Electrical, Communication, and Computer Engineering (ICECCE)","27 Aug 2021","2021","","","1","6","Recommender systems that provide recommendations based uniquely on information over users and items may not be very accurate in some situations. Therefore, adding contextual information to recommendations may be a good choice resulting in a system with increased precision. In an early work, we proposed an Ensemble Variational Autoencoders (EnsVAE) framework for recommendation. EnsVAE is adjusted to output interest probabilities by learning the distribution of each item's ratings and attempts to provide diverse novel items that are pertinent to users. In this paper, we propose and investigate a context awareness framework based on the Ensemblist Variational Autoencoders model with integrating the contextual information. The context awareness EnsVAE can easily be inferred from preceding sub-recommenders or applied as a filter to the final output. Test performed on real dataset, using an instance of the proposed framework show clear improvement compared to baseline architectures with similar ends as of this instance.","","978-1-6654-3897-1","10.1109/ICECCE52056.2021.9514087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9514087","Neural Recommender Models;Collaborative Filtering;Content-Based Filtering;Variational Autoencoders;Context-Aware Recommender System","Context-aware services;Computational modeling;Computer architecture;Gaussian distribution;Information filters;Data models;Task analysis","recommender systems;ubiquitous computing","recommender systems;contextual information;output interest probabilities;context awareness framework;context awareness EnsVAE;ensemble recommender system framework;ensemble variational autoencoders framework","","1","","25","","27 Aug 2021","","","IEEE","IEEE Conferences"
"Topic-Document Inference With the Gumbel-Softmax Distribution","A. Kumar; N. Esmaili; M. Piccardi","Food Agility CRC Ltd., Ultimo, NSW, Australia; School of Electrical and Data Engineering, FEIT, University of Technology Sydney, Sydney, NSW, Australia; School of Electrical and Data Engineering, FEIT, University of Technology Sydney, Sydney, NSW, Australia","IEEE Access","5 Jan 2021","2021","9","","1313","1320","Topic modeling is an important application of natural language processing (NLP) that can automatically identify the set of main topics of a given, typically large, collection of documents. In addition to identifying the main topics in the given collection, topic modeling infers which combination of topics is addressed by each individual document (the so-called topic-document inference), which can be useful for their classification and organization. However, the distributional assumptions for this inference are typically restricted to the Dirichlet family which can limit the performance of the model. For this reason, in this paper we propose modeling the topic-document inference with the Gumbel-Softmax distribution, a distribution recently introduced to expand differentiability in deep networks. To set up a performing system, the proposed approach integrates Gumbel-Softmax topic-document inference in a state-of-the-art topic model based on a deep variational autoencoder. Experimental results over two probing datasets show that the proposed approach has been able to outperform the original deep variational autoencoder and other popular topic models in terms of test-set perplexity and two topic coherence measures.","2169-3536","","10.1109/ACCESS.2020.3046607","Food Agility CRC Ltd., through the Commonwealth Government CRC Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9305202","Topic models;topic-document inference;variational autoencoders;Gumbel-Softmax distribution;deep neural networks","Computational modeling;Analytical models;Natural language processing;Matrix decomposition;Large scale integration;Vocabulary;Resource management","inference mechanisms;information retrieval;natural language processing;probability;speech recognition;text analysis","topic coherence measures;Gumbel-Softmax topic-document inference;Gumbel-softmax distribution;topic modeling;deep variational autoencoder","","1","","34","CCBY","23 Dec 2020","","","IEEE","IEEE Journals"
"Cross-Scene Relationship Mining with Learning Graph Net for Hyperspectral Image Classification","J. Chen; M. Ye; H. Lu; L. Lei","College of Information Engineering, China Jiliang University, Hangzhou, China; College of Information Engineering, China Jiliang University, Hangzhou, China; College of Information Engineering, China Jiliang University, Hangzhou, China; College of Information Engineering, China Jiliang University, Hangzhou, China","2021 2nd International Conference on Artificial Intelligence and Computer Engineering (ICAICE)","24 Jun 2022","2021","","","519","524","The problem of hyperspectral image (HSI) classification is usually accompanied by the problem of high dimension and few samples, that is, the high-dimensional-small-sample-size problem. In recent years, transfer learning has been widely used to solve this problem. In the cross-scene HSI classification, we consider a scene with a rich number of samples (called source scene) and a scene with a small number of samples (called target scene). The idea of transfer learning is to transfer the knowledge contained in the rich samples of source scene to target scene. Many HSI classification methods assume that two scenes come from the same feature space. However, the facts are often unsatisfactory, and the two scenes are likely to come from different feature spaces. In this case, we proposed a heterogeneous transfer learning method named cross-domain variational autoencoder (CDVAE), which achieved good results. But the imperfection is that CDVAE cannot use unlabeled samples on target scene to help classification. Therefore, on this basis, we have proposed a learning graph net (LGnet) of using convolutional neural networks (CNN) and graph to learn the relationship between cross-scene samples, so as to use the potential information of unlabeled samples. Then, a new method cross-domain variational autoencoder with learned graph (CDVAE-LG) was proposed by combining LGnet with CDVAE. The experimental results show that CDVAE-LG can effectively learn the information between cross-scene samples and help classification.","","978-1-6654-2186-7","10.1109/ICAICE54393.2021.00106","National Natural Science Foundation of China(grant numbers:61701468); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9797643","Hyperspectral image;cross-scene classification;heterogeneous transfer learning;cross-domain variational autoencoder;learning graph net","Manifolds;Transfer learning;Computer architecture;Convolutional neural networks;Artificial intelligence;Hyperspectral imaging;Image classification","data mining;geophysical image processing;graph theory;hyperspectral imaging;image classification;learning (artificial intelligence);neural nets","cross-scene HSI classification;source scene;target scene;rich samples;classification methods;heterogeneous transfer learning method;CDVAE;unlabeled samples;help classification;learning graph net;cross-scene samples;method cross-domain variational autoencoder;learned graph;cross-scene relationship mining;hyperspectral image classification;high-dimensional-small-sample-size problem","","","","10","IEEE","24 Jun 2022","","","IEEE","IEEE Conferences"
"Construction of source-charge probability distribution model for electric power field","S. Qu; X. Wang; Z. Li; K. Qu; B. Li; S. Wang; H. Cui; T. Peng","State Grid Jilin Electric Power Company Limited, Changchun, China; College of Computer Science and Technology, Jilin University, Changchun, China; State Grid Jilin Electric Power Company Limited, Changchun, China; Northeast Branch of State Grid Corporation of China, Shenyang, China; State Grid Jilin Electric Power Company Limited, Changchun, China; College of Computer Science and Technology, Jilin University, Changchun, China; College of Computer Science and Technology, Jilin University, Changchun, China; College of Computer Science and Technology, Jilin University, Changchun, China","2020 7th International Conference on Information Science and Control Engineering (ICISCE)","20 Sep 2021","2020","","","2326","2330","With the development of new energy industry, it’s beneficial to analyze the characteristics of new energy which stabilize the operation of the power grid and economic dispatch. It’s more and more important to model the uncertainty of new energy. Although there are some probabilistic modeling methods based on real load data for wind power output, they are not accurate and have high computational complexity. In order to solve these problems, this paper proposes a source-charge probability distribution model based on variational autoencoder. The model uses deep learning techniques to perform variational autoencoder and probabilistic modeling for real-time wind power data. This unsupervised method can learn the characteristics of wind power data and generate new data based on the characteristics of the observation without the scene reduction process. It improves the efficiency and quality of scene generation.","","978-1-7281-6406-9","10.1109/ICISCE50968.2020.00456","National Natural Science Foundation of China; China Postdoctoral Science Foundation; State Grid Corporation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9532081","power system;probabilistic modeling;variational autoencoder","Deep learning;Analytical models;Uncertainty;Computational modeling;Wind power generation;Probabilistic logic;Data models","computational complexity;deep learning (artificial intelligence);electricity supply industry;power engineering computing;power generation dispatch;power generation economics;power grids;statistical distributions;unsupervised learning;wind power;wind power plants","source-charge probability distribution model;electric power field;new energy industry;power grid;probabilistic modeling methods;wind power output;variational autoencoder;real-time wind power data;operation stabilization;real load data;computational complexity;deep learning techniques;unsupervised method;scene generation","","","","20","","20 Sep 2021","","","IEEE","IEEE Conferences"
"Autoencoder in Autoencoder Networks","C. Zhang; Y. Geng; Z. Han; Y. Liu; H. Fu; Q. Hu","Tianjin Key Laboratory of Machine Learning and the College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; Institute of High Performance Computing (IHPC), Agency for Science, Technology and Research (A*STAR), Singapore, Singapore; Tianjin Key Laboratory of Machine Learning and the College of Intelligence and Computing, Tianjin University, Tianjin, China","IEEE Transactions on Neural Networks and Learning Systems","","2022","PP","99","1","13","Modeling complex correlations on multiview data is still challenging, especially for high-dimensional features with possible noise. To address this issue, we propose a novel unsupervised multiview representation learning (UMRL) algorithm, termed autoencoder in autoencoder networks (AE<inline-formula> <tex-math notation=""LaTeX"">$^2$</tex-math> </inline-formula>-Nets). The proposed framework effectively encodes information from high-dimensional heterogeneous data into a compact and informative representation with the proposed bidirectional encoding strategy. Specifically, the proposed AE<inline-formula> <tex-math notation=""LaTeX"">$^2$</tex-math> </inline-formula>-Nets conduct encoding in two directions: the inner-AE-networks extract view-specific intrinsic information (forward encoding), while the outer-AE-networks integrate this view-specific intrinsic information from different views into a latent representation (backward encoding). For the nested architecture, we further provide a probabilistic explanation and extension from hierarchical variational autoencoder. The forward–backward strategy flexibly addresses high-dimensional (noisy) features within each view and encodes complementarity across multiple views in a unified framework. Extensive results on benchmark datasets validate the advantages compared to the state-of-the-art algorithms.","2162-2388","","10.1109/TNNLS.2022.3189239","National Key Research and Development Program of China(grant numbers:2019YFB2101900); National Natural Science Foundation of China(grant numbers:61976151,61925602,61732011); Natural Science Foundation of Tianjin City(grant numbers:19JCYBJC15200); AISG Tech Challenge Funding(grant numbers:AISG2-TC-2021-003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9831107","Bidirectional encoding;complete representation;multiview representation learning","Encoding;Correlation;Feature extraction;Degradation;Data mining;Representation learning;Kernel","","","","","","","IEEE","15 Jul 2022","","","IEEE","IEEE Early Access Articles"
"Computational Intelligence Techniques Applied to a Preliminary Exploration of Climatic Traits using Meteosat Water Vapor Images","J. J. Valdés; A. Pou","Digital Technologies Research Centre National Research Council Canada, Ottawa, Canada; Dept. of Ecology Autonomous, University of Madrid, Madrid, Spain","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","8","Meteorological satellites are crucial for understanding and forecasting the flow dynamics of the General Atmospheric Circulation System. They produce large amounts of image information whose analysis and interpretation poses numerous challenges. A collection of computational intelligence techniques are used for investigating the structure of a large series of water vapor (WV) band images from ESA Meteosat satellites from 2009–2020. They include the use of the Visual Information Fidelity image quality measure, intrinsic dimensionality, Uniform Manifold Approximation and Projection (with density information) and deep learning (variational autoencoders, convolutional neural networks and transfer learning). The variational autoencoder extracted features that characterize Water Vapor dynamics, distinguished different season patterns, exposed their interrelationships and provided highly effective classification features. Dimensionality reduction was highly instrumental applied to the VAE's latent spaces, and to VIFp image disimilarity analysis in a novel approach applied to major geographical areas. Supervised classification with deep learning and with the XGBoost algorithm on VAE's latent space, produced highly accurate models for predicting seasons. This computational intelligence approach provided insights about atmospheric dynamics as seen from the WV band images and suggested possible weather- teleconnection processes, as well as new ways for finding signs of unusual climate behavior.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533823","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533823","computational intelligence;water vapor satellite images;VIFp image similarity;intrinsic dimension;Umap dimensionality reduction;variational autoencoder;convolutional neural networks;transfer learning;atmosphere dynamics;climate variations","Deep learning;Satellites;Atmospheric modeling;Transfer learning;Aerospace electronics;Predictive models;Feature extraction","atmospheric humidity;atmospheric techniques;deep learning (artificial intelligence);feature extraction;geophysical image processing;image classification;image representation;neural nets;pattern classification;remote sensing","computational intelligence techniques;preliminary exploration;climatic traits;meteosat water vapor images;meteorological satellites;flow dynamics;image information whose analysis;water vapor band images;ESA Meteosat satellites;intrinsic dimensionality;uniform manifold approximation;density information;deep learning;variational autoencoder;convolutional neural networks;transfer learning;water vapor dynamics;season patterns;highly effective classification features;dimensionality reduction;VAE latent space;VIFp image disimilarity analysis;highly accurate models;computational intelligence approach;atmospheric dynamics;WV band images;visual information fidelity image quality measure;general atmospheric circulation system","","","","26","","20 Sep 2021","","","IEEE","IEEE Conferences"
"Learning a Deep Structural Subspace Across Hyperspectral Scenes With Cross-Domain VAE","M. Ye; J. Chen; F. Xiong; Y. Qian","Key Laboratory of Electromagnetic Wave Information Technology and Metrology of Zhejiang Province, College of Information Engineering, China Jiliang University, Hangzhou, China; Key Laboratory of Electromagnetic Wave Information Technology and Metrology of Zhejiang Province, College of Information Engineering, China Jiliang University, Hangzhou, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; College of Computer Science, Zhejiang University, Hangzhou, China","IEEE Transactions on Geoscience and Remote Sensing","15 Mar 2022","2022","60","","1","13","Hyperspectral image (HSI) classification is a small-sample-size problem due to the expensive cost of labeling. As a novel approach to this problem, cross-scene HSI classification has become a hot research topic in recent years. In cross-scene HSI classification, the scene containing enough labeled samples (called source scene) is used to benefit the classification in another scene containing a small number of training samples (called target scene). Transfer learning is a typical solution for cross-scene classification. However, many transfer learning algorithms assume an identical feature space for source and target scenes, which violates the fact that source and target scenes often lie in different feature spaces with various dimensions due to different HSI sensors. Aiming at the different feature spaces between the two scenes, we propose an end-to-end heterogeneous deep transfer learning algorithm, namely, cross-domain variational autoencoder (CDVAE). This algorithm is mainly composed of two key parts: 1) the features of the two scenes are embedded into the shared feature subspace through the two-stream variational autoencoder (VAE) to ensure that the output feature dimensions of the two scenes are identical and 2) graph regularization is used to establish the manifold constraints between source and target scenes in the shared subspace, so as to align the feature spaces. Experiments on two different cross-scene HSI datasets have proved the superior performance of the proposed CDVAE algorithm.","1558-0644","","10.1109/TGRS.2022.3142941","Zhejiang Provincial Natural Science Foundation of China(grant numbers:LY22F010010); National Natural Science Foundation of China(grant numbers:61701468,62071421); Jiangsu Provincial Natural Science Foundation of China(grant numbers:BK20200466); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680683","Cross-domain variational autoencoder (CDVAE);cross-scene classification;heterogeneous transfer learning;hyperspectral image (HSI)","Transfer learning;Feature extraction;Training;Sensors;Manifolds;Decoding;Task analysis","feature extraction;geophysical image processing;graph theory;hyperspectral imaging;image classification;image representation;learning (artificial intelligence)","hyperspectral scenes;cross-domain VAE;hyperspectral image classification;small-sample-size problem;cross-scene HSI classification;source scene;target scene;cross-scene classification;transfer learning algorithms;identical feature space;target scenes;different feature spaces;different HSI sensors;end-to-end heterogeneous deep transfer learning algorithm;cross-domain variational autoencoder;different cross-scene HSI datasets","","","","39","IEEE","13 Jan 2022","","","IEEE","IEEE Journals"
"Deformable Shape Completion with Graph Convolutional Autoencoders","O. Litany; A. Bronstein; M. Bronstein; A. Makadia",Google Research; Tel Aviv University; USI Lugano; Google Research,"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition","16 Dec 2018","2018","","","1886","1895","The availability of affordable and portable depth sensors has made scanning objects and people simpler than ever. However, dealing with occlusions and missing parts is still a significant challenge. The problem of reconstructing a (possibly non-rigidly moving) 3D object from a single or multiple partial scans has received increasing attention in recent years. In this work, we propose a novel learning-based method for the completion of partial shapes. Unlike the majority of existing approaches, our method focuses on objects that can undergo non-rigid deformations. The core of our method is a variational autoencoder with graph convolutional operations that learns a latent space for complete realistic shapes. At inference, we optimize to find the representation in this latent space that best fits the generated shape to the known partial input. The completed shape exhibits a realistic appearance on the unknown part. We show promising results towards the completion of synthetic and real scans of human body and face meshes exhibiting different styles of articulation and partiality.","2575-7075","978-1-5386-6420-9","10.1109/CVPR.2018.00202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8578300","","Shape;Three-dimensional displays;Task analysis;Training;Strain;Neural networks","convolutional codes;graph theory;image coding;image representation;inference mechanisms;learning (artificial intelligence);neural nets","deformable shape completion;portable depth sensors;occlusions;nonrigid deformations;variational autoencoder;object scanning;learning-based method;latent space representation;multiple partial scanning;graph convolutional autoencoder operations","","78","","62","","16 Dec 2018","","","IEEE","IEEE Conferences"
"Hierarchy Denoising Recursive Autoencoders for 3D Scene Layout Prediction","Y. Shi; A. X. Chang; Z. Wu; M. Savva; K. Xu",National University of Defense Technology; Eloquent Labs; Princeton University; Simon Fraser University; National University of Defense Technology,"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","1771","1780","Indoor scenes exhibit rich hierarchical structure in 3D object layouts. Many tasks in 3D scene understanding can benefit from reasoning jointly about the hierarchical context of a scene, and the identities of objects. We present a variational denoising recursive autoencoder (VDRAE) that generates and iteratively refines a hierarchical representation of 3D object layouts, interleaving bottom-up encoding for context aggregation and top-down decoding for propagation. We train our VDRAE on large-scale 3D scene datasets to predict both instance-level segmentations and a 3D object detections from an over-segmentation of an input point cloud. We show that our VDRAE improves object detection performance on real-world 3D point cloud datasets compared to baselines from prior work.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.00187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8954246","Scene Analysis and Understanding;Recognition: Detection;Categorization;Retrieval;Segmentation;Grouping and Shape","Point cloud compression;Three-dimensional displays;Layout;Noise reduction;Refining;Object detection;Encoding","image denoising;image segmentation;object detection;traffic engineering computing","hierarchy denoising recursive autoencoders;indoor scenes;hierarchical structure;3D object layouts;hierarchical context;variational denoising recursive autoencoder;VDRAE;hierarchical representation;3D object detections;object detection performance;real-world 3D point cloud datasets;large-scale 3D scene datasets;instance-level segmentation","","14","","65","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Unsupervised Feature Representation Learning using Sequence-to-sequence Autoencoder Architecture for Low-resource Language","L. Sun","Center for the Protection and Research of Language Resources of China, Faculty of Linguistic Sciences, Beijing Language and Culture University, Beijing, China","2021 International Conference on Computer Communication and Artificial Intelligence (CCAI)","9 Jun 2021","2021","","","76","80","In this paper, we aim to improve the traditional bottleneck feature extraction under the low-resource scenario. We employ the factorized hierarchical variational autoencoder (FHVAE) to learn an unsupervised feature representation by encoding the linguistic-relevant information into latent variables. In order to obtain more significant latent variables, the attention mechanism is introduced into the encoders of FHVAE. In addition to the reconstruction decoder of FHVAE, the phonetic-aware decoder is introduced to backward transmit the phonemic information into the latent variables, enhancing the performance of feature representation learning. The idea of multi-task learning is used to organize the encoders of FHVAE, the reconstruction decoder of FHVAE and the phonetic-aware decoder into the training process. To demonstrate the effectiveness of the proposed method, the ABX discriminability and the language identification are evaluated on the ZeroSpeech 2017 and the LRE 2017 respectively. These experimental results shown that the learned feature representation outperforms traditional acoustic feature.","","978-1-7281-9401-1","10.1109/CCAI50917.2021.9447504","Beijing Language and Culture University; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9447504","low-resource scenario;bottleneck feature;feature representation;unsupervised learning;language identification","Training;Computer architecture;Linguistics;Feature extraction;Acoustics;Encoding;Decoding","acoustic signal processing;feature extraction;natural language processing;speech coding;unsupervised learning","sequence-to-sequence autoencoder architecture;unsupervised feature representation learning;learned feature representation;language identification;multitask learning;phonemic information;phonetic-aware decoder;reconstruction decoder;latent variables;linguistic-relevant information;FHVAE;factorized hierarchical variational autoencoder;low-resource scenario;low-resource language","","","","24","","9 Jun 2021","","","IEEE","IEEE Conferences"
"Fetal Skull Reconstruction via Deep Convolutional Autoencoders","J. J. Cerrolaza; Y. Li; C. Biffi; A. Gomez; J. Matthew; M. Sinclair; C. Gupta; C. L. Knight; D. Rueckert","Imperial College London, London, London, GB; Imperial College London, London, London, GB; Imperial College London, London, London, GB; King's College London, London, London, GB; King's College London, London, London, GB; Imperial College London, London, London, GB; King's College London, London, London, GB; King's College London, London, London, GB; Imperial College London, London, London, GB","2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","28 Oct 2018","2018","","","887","890","Ultrasound (US) imaging is arguably the most commonly used modality for fetal screening. Recently, 3DUS has been progressively adopted in modern obstetric practice, showing promising diagnosis capabilities, and alleviating many of the inherent limitations of traditional 2DUS, such as subjectivity and operator dependence. However, the involuntary movements of the fetus, and the difficulty for the operator to inspect the entire volume in real-time can hinder the acquisition of the entire region of interest. In this paper, we present two deep convolutional architectures for the reconstruction of the fetal skull in partially occluded 3DUS volumes: a TL deep convolutional network (TL-Net), and a conditional variational autoencoder (CVAE). The performance of the two networks was evaluated for occlusion rates up to 50%, both showing accurate results even when only 60% of the skull is included in the US volume (Dice coeff. $0.84\pm 0.04$ for CVAE and $0.83\pm 0.03$ for TL-Net). The reconstruction networks proposed here have the potential to optimize image acquisition protocols in obstetric sonography, reducing the acquisition time and providing comprehensive anatomical information even from partially occluded images.","1558-4615","978-1-5386-3646-6","10.1109/EMBC.2018.8512282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8512282","","Image reconstruction;Training;Three-dimensional displays;Computer architecture;Two dimensional displays;Skull;Imaging","biomedical ultrasonics;convolution;feedforward neural nets;image reconstruction;medical image processing;obstetrics","CVAE;TL-Net;reconstruction networks;image acquisition protocols;obstetric sonography;partially occluded images;fetal skull reconstruction;deep convolutional autoencoders;ultrasound imaging;fetal screening;deep convolutional architectures;TL deep convolutional network;conditional variational autoencoder;US volume;diagnosis capabilities;3D US volumes;US","Female;Fetus;Humans;Imaging, Three-Dimensional;Pregnancy;Skull;Ultrasonography","","","13","","28 Oct 2018","","","IEEE","IEEE Conferences"
"Multi-Task Disentangled Autoencoder for Time-Series Data in Glucose Dynamics","M. H. Lim; Y. M. Cho; S. Kim","Department of Biomedical Engineering, College of Medicine, Seoul National University, Seoul, South Korea; Department of Internal Medicine, College of Medicine, Seoul National University, Seoul, South Korea; Institute of Bioengineering, Seoul National University, Seoul, South Korea","IEEE Journal of Biomedical and Health Informatics","9 Sep 2022","2022","26","9","4702","4713","The objective of this study is to propose MD-VAE: a multi-task disentangled variational autoencoders (VAE) for exploring characteristics of latent representations (LR) and exploiting LR for diverse tasks including glucose forecasting, event detection, and temporal clustering. We applied MD-VAE to one virtual continuous glucose monitoring (CGM) data from an FDA-approved Type 1 Diabetes Mellitus simulator (T1DMS) and one publicly available CGM data of real patients for glucose dynamics of Type 1 Diabetes Mellitus. LR captured meaningful information to be exploited for diverse tasks, and was able to differentiate characteristics of sequences with clinical parameters. LR and generative models have received relatively little attention for analyzing CGM data so far. However, as proposed in our study, VAE has the potential to integrate not only current but also future information on glucose dynamics and unexpected events including interactions of devices in the data-driven manner. We expect that our model can provide complementary views on the analysis of CGM data.","2168-2208","","10.1109/JBHI.2022.3175928","National Research Foundation of Korea(grant numbers:2018M1A3A3A02065779); Korea Medical Device Development Fund; Ministry of Science and ICT,; Ministry of Trade, Industry and Energy; Ministry of Health & Welfare; Ministry of Food and Drug Safety(grant numbers:1711138228,RS-2020-KD000123); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9779115","Continuous glucose monitoring;disentanglement;generative model;latent representation;Type 1 diabetes mellitus","Glucose;Task analysis;Insulin;Trajectory;Diabetes;Decoding;Reactive power","biomedical measurement;diseases;medical diagnostic computing;patient monitoring;sugar;time series","autoencoder;time-series data;glucose dynamics;MD-VAE;variational autoencoders;latent representations;diverse tasks;glucose forecasting;event detection;temporal clustering;virtual continuous glucose monitoring;FDA-approved Type 1 Diabetes Mellitus simulator;T1DMS;publicly available CGM data;CGM data;data-driven manner","Blood Glucose;Blood Glucose Self-Monitoring;Diabetes Mellitus, Type 1;Forecasting;Glucose;Humans","","","57","IEEE","19 May 2022","","","IEEE","IEEE Journals"
"Unsupervised Heart Abnormality Detection Based on Phonocardiogram Analysis with Beta Variational Auto-Encoders","S. Li; K. Tian; R. Wang",Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications; Beijing University of Posts and Telecommunications,"ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","8353","8357","Heart Sound (also known as phonocardiogram (PCG)) analysis, is a popular way that detects cardiovascular diseases (CVDs). Most PCG analysis uses supervised way, which demands both normal and abnormal samples. This paper proposes a method of unsupervised PCG analysis that uses beta variational auto-encoder (β – VAE) to model the normal PCG signals. The best performed model reaches an AUC (Area Under Curve) value of 0.91 in ROC (Receiver Operating Characteristic) test for PCG signals collected from the same source. Unlike majority of β – VAEs that are used as generative models, the best-performed β – VAE has a β value smaller than 1. This fact demonstrates that the resampling process helps the improvements on anomaly PCG detection through reconstruction loss worth a heavier weight. Further investigations suggest that anomaly score based on reconstruction loss may be better than anomaly scores based on latent vectors of samples in PCG analysis based on VAE systems.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414165","Phonocardiogram Analysis;Variational- Auto-Encoder;Anomaly Detection;Outlier Detection;Unsupervised Learning","Heart;Analytical models;Conferences;Receivers;Signal processing;Acoustics;Cardiovascular diseases","acoustic signal processing;cardiovascular system;diseases;medical signal detection;medical signal processing;phonocardiography;unsupervised learning","receiver operating characteristics;PCG detection;unsupervised heart abnormality detection;phonocardiogram analysis;heart sound;cardiovascular diseases;abnormal samples;unsupervised PCG analysis;normal PCG signals;ROC test;beta variational autoencoder;VAE systems","","2","","16","","13 May 2021","","","IEEE","IEEE Conferences"
"Fault Diagnosis of Bearing Based on Variational Mode Decomposition and Deep Learning","J. Cui; S. Tang; X. Cui; J. Wang; M. Yu; W. Du; L. Jiang","School of Automation, Shenyang Aerospace University, Shenyang, China; School of Automation, Shenyang Aerospace University, Shenyang, China; Model Balance and Wind Tunnel Equipment Department 5, AVIC Aerodynamics Research Institute, Shenyang, China; Aviation Key Laboratory of Science and Technology on Fault Diagnosis and Health Management, Shanghai, China; School of Automation, Shenyang Aerospace University, Shenyang, China; School of Automation, Shenyang Aerospace University, Shenyang, China; School of Automation, Shenyang Aerospace University, Shenyang, China","2021 33rd Chinese Control and Decision Conference (CCDC)","30 Nov 2021","2021","","","5413","5417","Aiming at the problem of difficult fault diagnosis caused by serious noise pollution and weak fault characteristic information in the rolling bearing vibration signal, a fault diagnosis method based on the combination of variational mode decomposition (VMD) and deep learning is proposed. First, VMD is performed on the original bearing vibration signal to obtain several Intrinsic Mode Functions (IMF). Then, the envelope spectral entropy of each IMF can be obtained by calculating. The IMF with the smallest envelope spectral entropy is selected as the main analysis IMF. Secondly, a stacked auto encoder (SAE) network initial model is built according to the data characteristics, and the initial values of the model parameters can be obtained by performing unsupervised pre-training on the network model; then the supervised backpropagation algorithm is used to fine-tune the network parameters to obtain the model of optimal parameter. Finally, the model is use to perform pattern recognition on the test set. Validation of examples and comparative experiments show that this method has higher diagnostic accuracy, better diagnostic effect, and better engineering application value.","1948-9447","978-1-6654-4089-9","10.1109/CCDC52312.2021.9602776","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9602776","Variational Mode Decomposition;Envelope Spectrum Entropy;Stacked Auto Encoder;Fault Diagnosis","Fault diagnosis;Deep learning;Vibrations;Support vector machines;Pollution;Rolling bearings;Feature extraction","backpropagation;deep learning (artificial intelligence);entropy;fault diagnosis;mechanical engineering computing;rolling bearings;supervised learning;unsupervised learning;vibrations","optimal parameter modelling;diagnostic effect;pattern recognition;supervised backpropagation algorithm;SAE network initial model;noise pollution;stacked autoencoder network initial model;network parameter tuning;network model;unsupervised pre-training;model parameters;data characteristics;main analysis IMF;envelope spectral entropy;Intrinsic Mode Functions;deep learning;VMD;variational mode decomposition;fault diagnosis method;rolling bearing vibration signal;weak fault characteristic information;serious noise pollution","","","","16","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Intrusion Detection Results Analysis Based on Variational Auto-Encoder","H. Xie; A. Li; R. Jiang; Y. Jia; L. Huang; W. Han","College of Computer, National University of Defense Technology, ChangSha, China; College of Computer, National University of Defense Technology, ChangSha, China; College of Computer, National University of Defense Technology, ChangSha, China; College of Computer, National University of Defense Technology, ChangSha, China; Department of High-Tech Research, Hunan Institute of Traffic Engineering, Hengyang, China; Cyberspace Institute of Advanced Technology, Guangzhou University Institute of Electronic and Information Engineering of UESTC in Guangdong, Guangzhou, China","2019 IEEE Fourth International Conference on Data Science in Cyberspace (DSC)","5 Dec 2019","2019","","","516","521","In the face of increasingly complex network environment, network security plays an increasingly important role in today's era. Therefore, analyze and detect network intrusion based on existing collected data in the complex network environment is one of the current research hotspots in the field of network security. Data mining and knowledge discovery based on the big data analysis is also a major trend of current research on intrusion detection. In the analysis and detection of network intrusion based on big data, the key step is to cluster and extract features of a large amount of collected data in advance. The model introduced in this paper mainly improves the structural model of variational auto-encoder[1] and adds the function of sample clustering, which integrates feature extraction, sample clustering and sample generation[1][2][3], laying a foundation for the detection and analysis of network intrusion behavior based on big data.","","978-1-7281-4528-0","10.1109/DSC.2019.00084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8923836","variational auto-encoder;Intrusion detection;neural network;clustering","Training;Data models;Analytical models;Feature extraction;Encoding;Intrusion detection;Computer hacking","Big Data;data analysis;data mining;feature extraction;pattern clustering;security of data","big data analysis;sample clustering;network intrusion detection;complex network environment;network security;knowledge discovery;variational autoencoder model;feature extraction","","","","14","","5 Dec 2019","","","IEEE","IEEE Conferences"
"Approximating the Void: Learning Stochastic Channel Models from Observation with Variational Generative Adversarial Networks","T. J. O’Shea; T. Roy; N. West","Virginia Polytechnic Institute and State University, Blacksburg, VA, US; DeepSig Inc., Arlington, VA; DeepSig Inc., Arlington, VA","2019 International Conference on Computing, Networking and Communications (ICNC)","11 Apr 2019","2019","","","681","686","Channel modeling is a critical topic when considering accurately designing or evaluating the performance of a communications system. Most prior work in designing or learning new modulation schemes has focused on using simplified analytic channel models such as additive white Gaussian noise (AWGN), Rayleigh fading channels or other similar compact parametric models. In this paper, we extend recent work training generative adversarial networks (GANs) to approximate wireless channel responses to more accurately reflect the probability distribution functions (PDFs) of stochastic channel behaviors. We introduce the use of variational GANs to provide appropriate architecture and loss functions which accurately capture these stochastic behaviors. Finally, we illustrate why prior GAN-based methods failed to accurately capture these behaviors and share results illustrating the performance of such as system over a range of complex realistic channel effects.","2325-2626","978-1-5386-9223-3","10.1109/ICCNC.2019.8685573","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8685573","machine learning;deep learning;neural networks;autoencoders;generative adversarial networks;modulation;neural networks;software radio","Stochastic processes;Training;Channel models;Communication systems;Optimization;Gallium nitride;Generative adversarial networks","approximation theory;AWGN channels;probability;radio networks;Rayleigh channels;stochastic processes;wireless channels","modulation schemes;simplified analytic channel models;additive white Gaussian noise;Rayleigh fading channels;similar compact parametric models;approximate wireless channel responses;probability distribution functions;stochastic channel behaviors;variational GANs;loss functions;prior GAN-based methods;complex realistic channel effects;stochastic channel models;variational generative adversarial networks;critical topic;communications system;work training generative adversarial networks","","34","","15","","11 Apr 2019","","","IEEE","IEEE Conferences"
"Pixel-based Continuous State Prediction with Perceptual Loss","D. Lee; J. H. Park","Autonomous IoT Research Section Electronics and Telecommunications Research Institute, Daejeon, South Korea; Smart ICT Convergence Research Department, Electronics and Telecommunications Research Institute, Daejeon, South Korea","2021 International Conference on Information and Communication Technology Convergence (ICTC)","7 Dec 2021","2021","","","1117","1119","Predicting the future is an essential but challenging process because of inherently uncertain model dynamics in our nature. In this paper, a perceptual loss is utilized to improve uncertainty and blurriness of video prediction in a stochastic approach. High dimensionality is reduced to a latent variable using a variation of the beta variational autoencoder. The latent variable contains temporal information from the consecutive state images and utilizes to predict the future states from the past. Perceptual loss is used rather than per-pixel loss between the reconstructed image and the original image to extract high-level image features. The perceptual loss using pre-trained network and KL divergence loss are combined during the training process. The proposed algorithm could show improved reconstruction ability and result in clear future state predictions.","2162-1233","978-1-6654-2383-0","10.1109/ICTC52510.2021.9621189","Electronics and Telecommunications Research Institute (ETRI)(grant numbers:21ZR1100); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9621189","Video Prediction;Autoencoder;Perceptual Loss;Model-based Reinforcement Learning","Training;Uncertainty;Stochastic processes;Reinforcement learning;Predictive models;Prediction algorithms;Feature extraction","feature extraction;image reconstruction;learning (artificial intelligence);neural nets;stochastic processes","pixel-based continuous state prediction;perceptual loss;uncertain model dynamics;video prediction;beta variational autoencoder;latent variable;consecutive state images;future states;per-pixel loss;high-level image feature extraction;KL divergence loss","","","","16","IEEE","7 Dec 2021","","","IEEE","IEEE Conferences"
"A Variational U-Net for Conditional Appearance and Shape Generation","P. Esser; E. Sutter","Heidelberg Collaboratory for Image Processing, Heidelberg University, Germany; Heidelberg Collaboratory for Image Processing, Heidelberg University, Germany","2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition","16 Dec 2018","2018","","","8857","8866","Deep generative models have demonstrated great performance in image synthesis. However, results deteriorate in case of spatial deformations, since they generate images of objects directly, rather than modeling the intricate interplay of their inherent shape and appearance. We present a conditional U-Net [30] for shape-guided image generation, conditioned on the output of a variational autoencoder for appearance. The approach is trained end-to-end on images, without requiring samples of the same object with varying pose or appearance. Experiments show that the model enables conditional image generation and transfer. Therefore, either shape or appearance can be retained from a query image, while freely altering the other. Moreover, appearance can be sampled due to its stochastic latent representation, while preserving shape. In quantitative and qualitative experiments on COCO [20], DeepFashion [21, 23], shoes [43], Market-1501 [47] and handbags [49] the approach demonstrates significant improvements over the state-of-the-art.","2575-7075","978-1-5386-6420-9","10.1109/CVPR.2018.00923","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8579021","","Shape;Generators;Image generation;Standards;Image color analysis;Training;Footwear","image coding;image representation;image retrieval;learning (artificial intelligence);stochastic processes","image synthesis;spatial deformations;shape-guided image generation;variational autoencoder;conditional image generation;query image;variational U-net;conditional appearance;shape generation;deep generative models;COCO;DeepFashion;Market-1501;stochastic latent representation","","193","","52","","16 Dec 2018","","","IEEE","IEEE Conferences"
"6-DOF GraspNet: Variational Grasp Generation for Object Manipulation","A. Mousavian; C. Eppner; D. Fox",NVIDIA; NVIDIA; NVIDIA,"2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","2901","2910","Generating grasp poses is a crucial component for any robot object manipulation task. In this work, we formulate the problem of grasp generation as sampling a set of grasps using a variational autoencoder and assess and refine the sampled grasps using a grasp evaluator model. Both Grasp Sampler and Grasp Refinement networks take 3D point clouds observed by a depth camera as input. We evaluate our approach in simulation and real-world robot experiments. Our approach achieves 88% success rate on various commonly used objects with diverse appearances, scales, and weights. Our model is trained purely in simulation and works in the real-world without any extra steps.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.00299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010919","","Three-dimensional displays;Grippers;Cameras;Task analysis;Robot vision systems;Geometry","cameras;image sampling;learning (artificial intelligence);manipulators;path planning;pose estimation;robot vision","variational Grasp generation;grasp poses;robot object manipulation task;variational autoencoder;sampled grasps;grasp evaluator model;Grasp Sampler;Grasp Refinement networks;3D point clouds;real-world robot experiments;GraspNet","","123","","37","","27 Feb 2020","","","IEEE","IEEE Conferences"
"Variational Adversarial Active Learning","S. Sinha; S. Ebrahimi; T. Darrell","University of Toronto, Toronto, ON, Canada; UC Berkeley; UC Berkeley","2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","5971","5980","Active learning aims to develop label-efficient algorithms by sampling the most representative queries to be labeled by an oracle. We describe a pool-based semi-supervised active learning algorithm that implicitly learns this sampling mechanism in an adversarial manner. Our method learns a latent space using a variational autoencoder (VAE) and an adversarial network trained to discriminate between unlabeled and labeled data. The mini-max game between the VAE and the adversarial network is played such that while the VAE tries to trick the adversarial network into predicting that all data points are from the labeled pool, the adversarial network learns how to discriminate between dissimilarities in the latent space. We extensively evaluate our method on various image classification and semantic segmentation benchmark datasets and establish a new state of the art on CIFAR10/100, Caltech-256, ImageNet, Cityscapes, and BDD100K. Our results demonstrate that our adversarial approach learns an effective low dimensional latent space in large-scale settings and provides for a computationally efficient sampling method. Our code is available at \url{https://github.com/sinhasam/vaal}.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.00607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9009538","","Uncertainty;Image segmentation;Semantics;Task analysis;Data models;Predictive models;Labeling","image classification;image segmentation;learning (artificial intelligence);neural nets;sampling methods","variational adversarial active learning;label-efficient algorithms;active learning algorithm;sampling mechanism;VAE;adversarial network;variational autoencoder;image classification;semantic segmentation","","107","1","58","IEEE","27 Feb 2020","","","IEEE","IEEE Conferences"
"Variational Auto-Regularized Alignment for Sim-to-Real Control","M. Hwasser; D. Kragic; R. Antonova","Northvolt, Sweden; Robotics, Perception and Learning, CSC, KTH Royal Institute of Technology, Stockholm, Sweden; Robotics, Perception and Learning, CSC, KTH Royal Institute of Technology, Stockholm, Sweden","2020 IEEE International Conference on Robotics and Automation (ICRA)","15 Sep 2020","2020","","","2732","2738","General-purpose simulators can be a valuable data source for flexible learning and control approaches. However, training models or control policies in simulation and then directly applying to hardware can yield brittle control. Instead, we propose a novel way to use simulators as regularizers. Our approach regularizes a decoder of a variational autoencoder to a black-box simulation, with the latent space bound to a subset of simulator parameters. This enables successful encoder training from a small number of real-world trajectories (10 in our experiments), yielding a latent space with simulation parameter distribution that matches the real-world setting. We use a learnable mixture for the latent prior/posterior, which implies a highly flexible class of densities for the posterior fit. Our approach is scalable and does not require restrictive distributional assumptions. We demonstrate ability to recover matching parameter distributions on a range of benchmarks, challenging custom simulation environments and several real-world scenarios. Our experiments using ABB YuMi robot hardware show ability to help reinforcement learning approaches overcome cases of severe sim-to-real mismatch.","2577-087X","978-1-7281-7395-5","10.1109/ICRA40945.2020.9197130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197130","","Hardware;Decoding;Computational modeling;Neural networks;Training;Trajectory;Benchmark testing","control engineering computing;learning (artificial intelligence);manipulators;neural nets","variational auto-regularized alignment;sim-to-real control;general-purpose simulators;variational autoencoder;black-box simulation;latent space;encoder training;simulation parameter distribution;matching parameter distributions;ABB YuMi robot hardware","","2","","28","","15 Sep 2020","","","IEEE","IEEE Conferences"
"Deep Conditional Variational Estimation for Depth-Based Hand Poses","L. Xu; C. Hu; Y. Li; J. Tao; J. Xue; K. Mei","Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Rocket Force University of Engineering, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China","2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)","11 Jul 2019","2019","","","1","7","We propose a novel and effective approach for 3D hand pose estimation on single depth image. Instead of doing deterministic regression from depth images, our model focuses on learning a latent distribution to model the high dimensional space of pose joints, which can also be interpreted as a kinematics model for human hands. Specifically, the proposed network combines the framework of conditional variational autoencoder which learns an encoder and a decoder with standard convolutional network. The encoder models the latent variable as a prior or a regularization for the pose joints. Then probabilistic inference is performed by the decoder to generate the output prediction conditioned on input depth images. In addition, we introduce a pool-convolution module to improve the localization regression of the network. The architecture can be trained end-to-end. In experiments, we demonstrate the effectiveness of our proposed approach in comparison to various state-of-art holistic regression approaches.","","978-1-7281-0089-0","10.1109/FG.2019.8756559","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756559","","","convolutional neural nets;learning (artificial intelligence);pose estimation;probability;regression analysis;stereo image processing","conditional variational autoencoder;encoder models;pool-convolution module;localization regression;deep conditional variational estimation;depth-based hand poses;convolutional network;3D hand pose estimation;probabilistic inference","","2","","29","","11 Jul 2019","","","IEEE","IEEE Conferences"
"Towards Explainable Semantic Segmentation for Autonomous Driving Systems by Multi-Scale Variational Attention","M. Abukmeil; A. Genovese; V. Piuri; F. Rundo; F. Scotti","Department of Computer Science, Università degli Studi di Milano, Italy; Department of Computer Science, Università degli Studi di Milano, Italy; Department of Computer Science, Università degli Studi di Milano, Italy; STMicroelectronics, ADG, Central R&D, Catania (CT), Italy; Department of Computer Science, Università degli Studi di Milano, Italy","2021 IEEE International Conference on Autonomous Systems (ICAS)","6 Oct 2021","2021","","","1","5","Explainable autonomous driving systems (EADS) are emerging recently as a combination of explainable artificial intelligence (XAI) and vehicular automation (VA). EADS explains events, ambient environments, and engine operations of an autonomous driving vehicular, and it also delivers explainable results in an orderly manner. Explainable semantic segmentation (ESS) plays an essential role in building EADS, where it offers visual attention that helps the drivers to be aware of the ambient objects irrespective if they are roads, pedestrians, animals, or other objects. In this paper, we propose the first ESS model for EADS based on the variational autoencoder (VAE), and it uses the multiscale second-order derivatives between the latent space and the encoder layers to capture the curvatures of the neurons’ responses. Our model is termed as Mgrad2 VAE and is bench-marked on the SYNTHIA and A2D2 datasets, where it outperforms the recent models in terms of image segmentation metrics.","","978-1-7281-7289-7","10.1109/ICAS49788.2021.9551172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9551172","Autonomous Driving System;VAE;XAI;ESS","Visualization;Image segmentation;Analytical models;Statistical analysis;Snow;Roads;Semantics","image segmentation;learning (artificial intelligence);neural nets;traffic engineering computing","ambient environments;engine operations;autonomous driving vehicular;EADS;visual attention;ambient objects;ESS model;variational autoencoder;image segmentation metrics;multiscale variational attention;explainable autonomous driving systems;vehicular automation;explainable semantic segmentation;Mgrad2 VAE;A2D2 dataset;SYNTHIA dataset","","2","","32","","6 Oct 2021","","","IEEE","IEEE Conferences"
"Multitask Variational Autoencoding of Human-to-Human Object Handover","H. Razali; Y. Demiris","Dept of EEE, Personal Robotics Laboratory, Imperial College London, UK; Dept of EEE, Personal Robotics Laboratory, Imperial College London, UK","2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","16 Dec 2021","2021","","","7315","7320","Assistive robots that operate alongside humans require the ability to understand and replicate human behaviours during a handover. A handover is defined as a joint action between two participants in which a giver hands an object over to the receiver. In this paper, we present a method for learning human-to-human handovers observed from motion capture data. Given the giver and receiver pose from a single timestep, and the object label in the form of a word embedding, our Multitask Variational Autoencoder jointly forecasts their pose as well as the orientation of the object held by the giver at handover. Our method is in large contrast to existing works for human pose forecasting that employ deep autoregressive models requiring a sequence of inputs. Furthermore, our method is novel in that it learns both the human pose and object orientation in a joint manner. Experimental results on the publicly available Handover Orientation and Motion Capture Dataset show that our proposed method outperforms the autoregressive baselines for handover pose forecasting by approximately 20% while being on-par for object orientation prediction with a runtime that is 5x faster. a","2153-0866","978-1-6654-1714-3","10.1109/IROS51168.2021.9636221","Royal Academy of Engineering; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9636221","","Runtime;Image color analysis;Stochastic processes;Receivers;Handover;Predictive models;Spatiotemporal phenomena","autoregressive processes;hidden Markov models;human-robot interaction;image motion analysis;learning (artificial intelligence);mobility management (mobile radio);pose estimation","Variational autoencoding;human-to-human object Handover;human behaviours;joint action;giver hands;human-to-human handovers;motion capture data;object label;Multitask Variational Autoencoder;human pose;publicly available Handover Orientation;object orientation prediction","","","","26","IEEE","16 Dec 2021","","","IEEE","IEEE Conferences"
"Federated Variational Learning for Anomaly Detection in Multivariate Time Series","K. Zhang; Y. Jiang; L. Seversky; C. Xu; D. Liu; H. Song","Embry-Riddle Aeronautical University, Daytona Beach, FL; Embry-Riddle Aeronautical University, Daytona Beach, FL; Air Force Research Laboratory, Rome, NY; Embry-Riddle Aeronautical University, Daytona Beach, FL; Embry-Riddle Aeronautical University, Daytona Beach, FL; Embry-Riddle Aeronautical University, Daytona Beach, FL","2021 IEEE International Performance, Computing, and Communications Conference (IPCCC)","20 Jan 2022","2021","","","1","9","Anomaly detection has been a challenging task given high-dimensional multivariate time series data generated by networked sensors and actuators in Cyber-Physical Systems (CPS). Besides the highly nonlinear, complex, and dynamic nature of such time series, the lack of labeled data impedes data exploitation in a supervised manner and thus prevents an accurate detection of abnormal phenomenons. On the other hand, the collected data at the edge of the network is often privacy sensitive and large in quantity, which may hinder the centralized training at the main server. To tackle these issues, we propose an unsupervised time series anomaly detection framework in a federated fashion to continuously monitor the behaviors of interconnected devices within a network and alert for abnormal incidents so that countermeasures can be taken before undesired consequences occur. To be specific, we leave the training data distributed at the edge to learn a shared Variational Autoencoder (VAE) based on Convolutional Gated Recurrent Unit (ConvGRU) model, which jointly captures feature and temporal dependencies in the multivariate time series data for representation learning and downstream anomaly detection tasks. Experiments on three real-world networked sensor datasets illustrate the advantage of our approach over other state-of-the-art models. We also conduct extensive experiments to demonstrate the effectiveness of our detection framework under non-federated and federated settings in terms of overall performance and detection latency.","2374-9628","978-1-6654-4331-9","10.1109/IPCCC51483.2021.9679367","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679367","Anomaly Detection;Federate Learning;Net-work Security;Data-efficient Machine Learning","Training;Representation learning;Image edge detection;Time series analysis;Training data;Sensor phenomena and characterization;Sensor systems","cyber-physical systems;data handling;learning (artificial intelligence);time series","cyber-physical systems;data exploitation;centralized training;unsupervised time series;anomaly detection framework;abnormal incidents;convolutional gated recurrent unit model;representation learning;real-world networked sensor datasets;high-dimensional multivariate time series data;shared variational autoencoder;federated variational learning","","","","31","IEEE","20 Jan 2022","","","IEEE","IEEE Conferences"
"Zero-Shot Voice Cloning Using Variational Embedding with Attention Mechanism","J. Lee; J. Kim; J. -H. Chang","Department of Electronics and Computer Engineering, Hanyang University, Seoul, Republic of Korea; Department of Electronics and Computer Engineering, Hanyang University, Seoul, Republic of Korea; Department of Electronics and Computer Engineering, Hanyang University, Seoul, Republic of Korea","2021 7th IEEE International Conference on Network Intelligence and Digital Content (IC-NIDC)","4 Jan 2022","2021","","","344","348","Many voice cloning studies based on multi-speaker text-to-speech (TTS) have been conducted. Among the techniques of voice cloning, we focus on zero-shot voice cloning. The most important aspect of zero-shot voice cloning is which speaker embedding is used. In this study, two types of speaker embeddings are used. One is extracted from the mel spectrogram using a speaker encoder and the other is stored in an embedding dictionary, such as a vector quantized-variational autoencoder (VQ-VAE). To extract embedding from the embedding dictionary, an attention mechanism is applied, which we call attention- V AE (AT - V AE). By employing the embedding extracted by the speaker encoder as a query in the attention mechanism, the attention weights are calculated in the embedding dictionary. This mechanism allows the extraction of speaker embedding, which represents unseen speakers. In addition, training is applied to make our model robust to unseen speakers. Through the training stage, our system has developed further. The performance of the proposed method was validated in terms of various metrics, and it was demonstrated that the proposed method enables voice cloning without adaptation training.","2575-4955","978-1-6654-0582-9","10.1109/IC-NIDC54101.2021.9660599","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9660599","Voice cloning;Global style token;Text-to-speech;Multi-speaker","Training;Measurement;Adaptation models;Dictionaries;Conferences;Cloning;Spectrogram","feature extraction;learning (artificial intelligence);neural nets;speaker recognition;speech processing;speech synthesis;vector quantisation","embedding dictionary;attention mechanism;speaker encoder;speaker embedding;unseen speakers;zero-shot voice cloning;variational embedding;voice cloning studies;multispeaker text-to-speech;attention-VAE;vector quantized-variational autoencoder","","","","21","IEEE","4 Jan 2022","","","IEEE","IEEE Conferences"
"Unsupervised IoT Fingerprinting Method via Variational Auto-encoder and K-means","S. Zhang; Z. Wang; J. Yang; D. Bai; F. Li; Z. Li; J. Wu; X. Liu","Beijing National Research Center for Information Science and Technology; Beijing National Research Center for Information Science and Technology; Institute for Network Sciences and Cyberspace, Tsinghua University, Beijing, China; Northeastern University, Liaoning, China; Northeastern University, Liaoning, China; Institute for Network Sciences and Cyberspace, Tsinghua University, Beijing, China; Institute for Network Sciences and Cyberspace, Tsinghua University, Beijing, China; National Computer Network Emergency Response Technical Team/Coordination Center of China, Beijing, China","ICC 2021 - IEEE International Conference on Communications","6 Aug 2021","2021","","","1","6","With the rapid growth of the number of IoT devices on the Internet, security problems of IoT devices are becoming more and more serious, which bring more challenges to network administrators. The first task to solve these problems for network administrators is being aware of IoT devices in the network. Previous IoT device identification methods typically use supervised machine learning methods, which require a large amount of labeled sample data. However, it is difficult to obtain a large number of labeled samples effectively. In order to address this problem, we propose an unsupervised IoT device fingerprinting method at the network level, which can effectively cluster IoT devices without labeled samples. We deeply analyze the temporal and spatial dimension characteristics of network traffic, which can adequately reflect the differences between different IoT devices. By using these features, we develop a clustering framework based on variational autoencoder and K-means algorithms. We conduct evaluation experiments on a public dataset including 24 different IoT devices. The experimental results show that our clustering algorithm can achieve accuracy of 86.7% outperforming a k-NN based state-of-art supervised approach.","1938-1883","978-1-7281-7122-7","10.1109/ICC42927.2021.9500301","National Key Research and Development Program of China; Research and Development; Science and Technology Planning Project of Guangdong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9500301","IoT;fingerprinting method;unsupervised","Conferences;Internet security;Clustering algorithms;Telecommunication traffic;Machine learning;Fingerprint recognition;Classification algorithms","Internet of Things;learning (artificial intelligence);pattern clustering","variational auto-encoder;unsupervised IoT fingerprinting method;24 different IoT devices;variational autoencoder;unsupervised IoT device fingerprinting method;labeled samples;previous IoT device identification methods;network administrators","","","","21","IEEE","6 Aug 2021","","","IEEE","IEEE Conferences"
"Cross-Domain Latent Modulation for Variational Transfer Learning","J. Hou; J. D. Deng; S. Cranefield; X. Ding","Department of Information Science, University of Otago; Department of Information Science, University of Otago; Department of Information Science, University of Otago; Department of Information Science, University of Otago","2021 IEEE Winter Conference on Applications of Computer Vision (WACV)","14 Jun 2021","2021","","","3148","3157","We propose a cross-domain latent modulation mechanism within a variational autoencoders (VAE) framework to enable improved transfer learning. Our key idea is to procure deep representations from one data domain and use it as perturbation to the reparameterization of the latent variable in another domain. Specifically, deep representations of the source and target domains are first extracted by a unified inference model and aligned by employing gradient reversal. Second, the learned deep representations are cross-modulated to the latent encoding of the alternate domain. The consistency between the reconstruction from the modulated latent encoding and the generation using deep representation samples is then enforced in order to produce inter-class alignment in the latent space. We apply the proposed model to a number of transfer learning tasks including unsupervised domain adaptation and image-to-image translation. Experimental results show that our model gives competitive performance.","2642-9381","978-1-6654-0477-8","10.1109/WACV48630.2021.00319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9423388","","Adaptation models;Visualization;Computer vision;Perturbation methods;Conferences;Transfer learning;Modulation","computer vision;deep learning (artificial intelligence);image reconstruction;image representation","variational transfer learning;cross-domain latent modulation mechanism;variational autoencoders framework;data domain;inference model;deep representations;latent encoding;unsupervised domain adaptation;latent variable reparameterization;image-to-image translation;gradient reversal","","","","48","IEEE","14 Jun 2021","","","IEEE","IEEE Conferences"
"A New Variational Method for Deep Supervised Semantic Image Hashing","F. Zhuang; P. Moulin","Dept of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, Illinois; Dept of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, Illinois","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","4532","4536","We present a supervised semantic hashing method which uses a variational autoencoder to represent each database image sample as a product Bernoulli distribution. We show that the probability parameters approach extreme values during training, allowing them to be used directly as hash bits. We show how our method allows balanced bits to be directly specified, and is superior to state-of-the-art methods across four datasets.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9053665","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9053665","supervised;hashing;image;retrieval","Training;Acoustic distortion;Databases;Semantics;Signal processing algorithms;Rate distortion theory;Speech processing","feature extraction;image representation;probability;supervised learning","variational method;deep supervised semantic image hashing;supervised semantic hashing method;variational autoencoder;database image sample;product Bernoulli distribution;hash bits;probability parameters approach","","","","19","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Deep Convolutional Graph Rough Variational Auto-Encoder for Short-Term Photovoltaic Power Forecasting","M. Saffari; M. Khodayar; S. M. J. Jalali; M. Shafie-khah; J. P. S. Catalão","Department of Computer Science, University of Tulsa, Tulsa, OK, USA; Department of Computer Science, University of Tulsa, Tulsa, OK, USA; IISRI, Deakin University, Victoria, Australia; School of Technology and Innovations, University of Vaasa, Vaasa, Finland; Faculty of Engineering, INESCTEC, University of Porto, Porto, Portugal","2021 International Conference on Smart Energy Systems and Technologies (SEST)","27 Sep 2021","2021","","","1","6","Photovoltaic (PV) power is considered as one of the most promising sustainable energy resources in recent years. However, the existing intermittency in the nature of solar energy is a significant problem for the optimization of smart grids. In this paper, to overcome PV generation uncertainty and provide an accurate spatio-temporal (ST) PV forecast, we propose a novel deep generative convolutional graph rough variational autoencoder (CGRVAE) that captures each PV site's probability distribution functions (PDFs) of future PV generation in a modeled weighted graph. Having the learned PDFs enables CGRVAE to accurately generate the future values of PV power time series. To train and evaluate our model, we used the measurements of a set of PV sites in California, US. The sites are modeled as a weighted graph where each node represents PV measurements at each site while edges reflect their correlations. Using graph spectral convolutions the proposed model extracts the most relevant information of the graph to estimate the future PV given the historical time series for each node in the modeled graph. Experimental results show the superiority of CGRVAE over state-of-the-art forecasting approaches in terms of the root mean square error (RMSE) and mean absolute error (MAE) metric.","","978-1-7281-7660-4","10.1109/SEST50973.2021.9543326","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9543326","Solar energy;Photovoltaic power forecasting;Spectral Graph Convolution;Deep Neural Networks","Photovoltaic systems;Weight measurement;Correlation;Uncertainty;Time series analysis;Predictive models;Probability density function","graph theory;load forecasting;neural nets;photovoltaic power systems;power engineering computing;probability;time series","convolutional graph rough variational auto-encoder;short-term photovoltaic power forecasting;promising sustainable energy resources;existing intermittency;solar energy;smart grids;PV generation uncertainty;accurate spatio-temporal;deep generative convolutional graph rough variational autoencoder;CGRVAE;PV site;future PV generation;modeled weighted graph;learned PDFs;future values;PV power time series;PV sites;PV measurements;graph spectral convolutions;historical time series;modeled graph;state-of-the-art forecasting","","","","21","EU","27 Sep 2021","","","IEEE","IEEE Conferences"
"Unsupervised Deep Variational Model for Multivariate Sensor Anomaly Detection","M. Weldezgina Asres; G. Cummings; P. Parygin; A. Khukhunaishvili; M. Toms; A. Campbell; S. I. Cooper; D. Yu; J. Dittmann; C. W. Omlin","University of Agder, Norway; University of Virginia, USA; National Research Nuclear Univ., Russia; University of Rochester, USA; NRC “Kurchatov Institute” (ITEP), Russia; Deutsches Elektronen-Synchrotron, Germany; University of Alabama, USA; Brown University, USA; Baylor University, USA; University of Agder, Norway","2021 IEEE International Conference on Progress in Informatics and Computing (PIC)","25 Jan 2022","2021","","","364","371","The ever-increasing detector complexity at CERN triggers a call for an increasing level of automation. Since the quality of collected physics data hinges on the quality of the detector components at the time of data-taking, the rapid identification and resolution of detector system anomalies will result in a better amount of high-quality particle data. Therefore, this study proposes CGVAE, a data-driven unsupervised anomaly detection using a deep learning model, for detector system monitoring from multivariate time series sensor data. The CGVAE model is composed of a variational autoencoder with convolutional and gated recurrent unit networks for fast localized feature extraction, long temporal characteristics capturing, and descriptive representation learning. Furthermore, to mitigate signal reconstruction overfitting on anomalous patterns, the CGVAE employs encoded latent feature- and reconstruction-based metrics for anomaly detection. Moreover, the model integrates feature attribution algorithms to explain the contribution of the input sensors to the detected anomalies. The experimental evaluation on large sensor data sets of the Hadron Calorimeter of the CMS experiment demonstrates the efficacy of the proposed model in capturing temporal anomalies.","2329-6259","978-1-6654-2655-8","10.1109/PIC53636.2021.9687034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9687034","Anomaly Detection;Multivariate Time Series;Deep Learning;Sensor;Monitoring;Explanation;HCAL;CMS","Representation learning;Measurement;Time series analysis;Detectors;Feature extraction;Data models;Signal reconstruction","convolution;feature extraction;image reconstruction;learning (artificial intelligence);neural nets;particle calorimetry;signal reconstruction;time series;unsupervised learning","deep learning model;detector system monitoring;multivariate time series sensor data;CGVAE model;variational autoencoder;convolutional unit networks;gated recurrent unit networks;fast localized feature extraction;representation learning;signal reconstruction;latent feature;reconstruction-based metrics;model integrates;input sensors;detected anomalies;sensor data sets;temporal anomalies;unsupervised deep variational model;multivariate sensor anomaly detection;detector complexity;CERN triggers;collected physics data hinges;detector components;data-taking;detector system anomalies;high-quality particle data","","","","36","IEEE","25 Jan 2022","","","IEEE","IEEE Conferences"
"Denoising Autoencoder-Based Missing Value Imputation for Smart Meters","S. Ryu; M. Kim; H. Kim","Department of Electronic Engineering, Sogang University, Seoul, South Korea; Department of Electronic Engineering, Sogang University, Seoul, South Korea; Department of Electronic Engineering, Sogang University, Seoul, South Korea","IEEE Access","4 Mar 2020","2020","8","","40656","40666","Electric load data are essential for data-driven approaches (including deep learning) in smart grid, and advanced smart meter technologies provide fine-grained data with reliable communications. Despite the recent development of smart metering devices, however, missing data still arise due to unexpected device power off, communication failure, measuring error, or other unknown reasons. In this paper, we investigate a deep learning framework for missing imputation of smart meter data by leveraging a denoising autoencoder (DAE). Then, we compare the performance of the proposed DAE with traditional methods as well as other recently developed generative models, e.g., variational autoencoder and Wasserstein autoencoder. The proposed DAE based imputation shows significantly better results compared to other methods in terms of root mean square error (RMSE) by up to 28.9% for point-wise error, and by up to 56% for daily-accumulated error.","2169-3536","","10.1109/ACCESS.2020.2976500","Ministry of Land, Infrastructure and Transport(grant numbers:19NSPS-B152996-02); National Research Foundation of Korea(grant numbers:NRF-2017R1A1A1A05001377); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9016055","Deep learning;smart grid;missing imputation;smart meters;denoising autoencoder;generative model;daily load profile (DLP)","Machine learning;Smart meters;Noise reduction;Smart grids;Load modeling","data analysis;learning (artificial intelligence);neural nets;power engineering computing;smart meters;smart power grids","electric load data;smart grid;smart meter technologies;deep learning;smart meter data;DAE based imputation;denoising autoencoder-based missing value imputation","","21","","30","CCBY","27 Feb 2020","","","IEEE","IEEE Journals"
"Joint Constellation Design and Multiuser Detection for Grant-Free NOMA","Z. Ma; W. Wu; M. Jian; F. Gao; X. Shen","Department of Automation, State Key Laboratory of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology, Institute for Artificial Intelligence, Tsinghua University, Beijing, China; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Algorithm Department, Wireless Product R&D Institute, ZTE Corporation, Shenzhen, China; Department of Automation, State Key Laboratory of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology, Institute for Artificial Intelligence, Tsinghua University, Beijing, China; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada","IEEE Transactions on Wireless Communications","9 Mar 2022","2022","21","3","1973","1988","As a promising solution for massive machine-type communication, grant-free non-orthogonal multiple access (GF-NOMA) has received considerable attention in recent years. However, the multidimensional constellation design (MCD) and multiuser detection (MUD) in GF-NOMA are usually optimized in a divide and conquer way, leading to local optima and performance degradation. To address this issue, we investigate the joint optimization of MCD and MUD for GF-NOMA. The formulated joint optimization is based on variational inference, which is intractable due to the signal superimposition that makes the optimization variables intricately coupled. Then, we resort to end-to-end deep learning (DL) to obtain the optimal solution. Specifically, we propose a DL-based multi-task variational autoencoder (Mul-VAE) that adopts a variational autoencoder network to optimize the distribution of the constellation points. We further derive the loss function of the proposed network and analyze it from an information-theoretic perspective. On this basis, multi-task learning is employed to deal with mutually conflicting yet related detection processes. Besides, taking heterogeneous transmission rates of users into account, a multi-task prioritizing strategy is designed to balance training performance. Simulation results reveal that the proposed method enables significant gains compared to state-of-the-art techniques.","1558-2248","","10.1109/TWC.2021.3108666","National Key Research and Development Program of China(grant numbers:2018AAA0102401); National Natural Science Foundation of China(grant numbers:61831013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9530373","NOMA;deep learning;mMTC;constellation design;multiuser detection;multi-task learning","Multiuser detection;Optimization;Wireless communication;Task analysis;Training;NOMA;Deep learning","deep learning (artificial intelligence);multiuser detection;nonorthogonal multiple access;optimisation","multiuser detection;grant-free NOMA;massive machine-type communication;nonorthogonal multiple access;GF-NOMA;MCD;MUD;performance degradation;formulated joint optimization;variational inference;multitask variational autoencoder;variational autoencoder network;constellation points;multitask learning;related detection processes;multitask prioritizing strategy","","","","59","IEEE","6 Sep 2021","","","IEEE","IEEE Journals"
"Deep Learning Approach for Epileptic Focus Localization","H. Daoud; M. Bayoumi","Center for Advanced Computer Studies, University of Louisiana at Lafayette, Lafayette, USA; Department of Electrical and Computer Engineering, University of Louisiana at Lafayette, Lafayette, USA","IEEE Transactions on Biomedical Circuits and Systems","27 Mar 2020","2020","14","2","209","220","The task of epileptic focus localization receives great attention due to its role in an effective epileptic surgery. The clinicians highly depend on the intracranial EEG data to make a surgical decision related to epileptic subjects suffering from uncontrollable seizures. This surgery usually aims to remove the epileptogenic region which requires precise characterization of that area using the EEG recordings. In this paper, we propose two methods based on deep learning targeting accurate automatic epileptic focus localization using the non-stationary EEG recordings. Our first proposed method is based on semi-supervised learning, in which a deep convolutional autoencoder is trained and then the pre-trained encoder is used with multi-layer perceptron as a classifier. The goal is to determine the location of the EEG signal that is responsible for the epileptic activity. In the second proposed method, unsupervised learning scheme is implemented by merging deep convolutional variational autoencoder and K-means algorithm for clustering the iEEG signals into two distinct clusters based on the seizure source. The proposed methods automate and integrate the features extraction and classification processes instead of manually extracting the features as done in the previous studies. Dimensionality reduction is achieved using the autoencoder, while the important spatio-temporal features are extracted from the EEG recordings using the convolutional layers. Moreover, we implemented the inference network of the semi-supervised model on FPGA. The results of our experiments demonstrate high classification accuracy and clustering performance in localizing the epileptic focus compared with the state of the art.","1940-9990","","10.1109/TBCAS.2019.2957087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918409","Classification;clustering;convolutional autoen-coder;EEG;epileptic focus localization;variational autoencoder","Electroencephalography;Feature extraction;Training;Surgery;Machine learning;Convolution;Brain modeling","convolutional neural nets;electroencephalography;feature extraction;medical disorders;medical signal processing;multilayer perceptrons;signal classification;surgery;unsupervised learning","multilayer perceptron;seizure source;K-means algorithm;iEEG signals;automatic epileptic focus localization;semisupervised learning;nonstationary EEG recordings;effective epileptic surgery;deep learning approach;clustering performance;classification accuracy;classification processes;features extraction;deep convolutional variational autoencoder;unsupervised learning scheme;epileptic activity","Algorithms;Deep Learning;Electroencephalography;Epilepsy;Humans;Seizures;Signal Processing, Computer-Assisted;Unsupervised Machine Learning","14","","34","IEEE","2 Dec 2019","","","IEEE","IEEE Journals"
"Latent Space Conditional Adversarial Learning for Intelligent Dialogue Generation","Z. Zhuan; Y. Huang; Z. Wang; Y. Gao","Nanjing Fenghuo Tiandi Communication Technology Co., Ltd, Nanjing, China; Wuhan University of Science and Technology, Wuhan, China; Nanjing Fenghuo Tiandi Communication Technology Co., Ltd, Nanjing, China; Nanjing Fenghuo Tiandi Communication Technology Co., Ltd, Nanjing, China","2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI)","28 Feb 2022","2021","","","592","596","Generating reasonable and relevant responses remains a challenge for dialogue generation tasks. Currently, latent variable models in deep learning have been applied in text generation, but these latent variables are often full of randomness, leading to uncontrollable generated responses. In this paper, we propose a two-stage conditional-response generation framework based on latent space adversarial learning. Our model first performs representation learning of latent sentence encoding through an autoencoder, and then adds the latent variables of the context to the latent space adversarial learning so that the latent representations of replies generated by our encoder can be highly correlated with our context and further, we decode the latent encoding representations of replies into sentences of replies. The related experimental results show that our model can generate more contextually relevant, fluent, and rich replies than the baseline model.","","978-1-6654-0692-5","10.1109/CISAI54367.2021.00120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9718870","dialog generation;deeplearning;adversarial learning;variational autoencoder;variational autoencoder","Representation learning;Deep learning;Information science;Computational modeling;Adversarial machine learning;Encoding;Task analysis","interactive systems;learning (artificial intelligence);natural language interfaces;text analysis","conditional-response generation framework;latent space adversarial learning;representation learning;latent sentence;latent variables;latent space conditional adversarial learning;intelligent dialogue generation;reasonable responses;relevant responses;dialogue generation tasks;latent variable models;deep learning;text generation;uncontrollable generated responses","","","","20","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"Predictive Modeling With Multiresolution Pyramid VAE and Industrial Soft Sensor Applications","B. Shen; L. Yao; Z. Ge","State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou 310027, China.; State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou 310027, China.; State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou 310027, China, and also with Peng Cheng Laboratory, Shenzhen 518000, China","IEEE Transactions on Cybernetics","","2022","PP","99","1","13","In industrial processes, the sampling rates of process variables are discrepant because of the nature of instruments and measuring demands, which forms the challenging issue, that is, the multirate modeling in the data-driven soft sensor development. In this work, a multiresolution pyramid variational autoencoder (MR-PVAE) predictive model is proposed to solve this problem based on the deep feature extraction and feature pyramid augmentation. First, a multirate data filter is designed through a resolution searching strategy to turn the original process data into a multiresolution dataset. Then, the pyramid variational autoencoder (PVAE) is proposed to extract deep nonlinear features from the data with different resolutions. In PVAE, the augmented feature pyramid is constructed layer by layer to fuse extracted features from low resolution to the high. As a consequence, the extracted features with various resolutions are gathered to form the regression model, where the process information contained in data with discrepant sampling rates can be fully utilized. Due to the layer-by-layer enhanced features, the prediction accuracy of the soft sensing model are gradually improved. Meanwhile, an optimized training strategy is established to select the optimal feature pyramid for prediction. A numerical experiment and an industrial soft sensing case are given to validate the effectiveness and superiority of the proposed MR-PVAE model.","2168-2275","","10.1109/TCYB.2022.3143613","National Natural Science Foundation of China(grant numbers:62003300,62103362,92167106); China Postdoctoral Science Foundation(grant numbers:2021T140597,2019M662050); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9716052","Deep feature extraction;feature pyramid augmentation;multirate data filter;multiresolution pyramid variational autoencoder (MR-PVAE);soft sensor","Feature extraction;Data models;Predictive models;Soft sensors;Numerical models;Data mining;Spatial resolution","","","","1","","","IEEE","17 Feb 2022","","","IEEE","IEEE Early Access Articles"
"Adversarial Autoencoder for trajectory generation and maneuver classification","O. Rakos; T. Becsi; S. Aradi","Department of Control for Transportation and Vehicle Systems, Budapest Univ. of Technology and Economics, Budapest, Hungary; Department of Control for Transportation and Vehicle Systems, Budapest Univ. of Technology and Economics, Budapest, Hungary; Department of Control for Transportation and Vehicle Systems, Budapest Univ. of Technology and Economics, Budapest, Hungary","2021 IEEE 25th International Conference on Intelligent Engineering Systems (INES)","16 Aug 2021","2021","","","000013","000018","For the development of self-driving cars, it is essential to perceive the environment as accurately as possible and to interpret the movement of the surrounding vehicles. It makes sense to draw conclusions based on the past trajectories of these vehicles, whether it is maneuver detection or, in more complex cases, maneuver or trajectory prediction. Trajectories are time series data, so it is obvious to deploy recurrent neural networks for their analysis, or 1-dimensional convolutional networks that can capture temporal patterns. The concept is presented that trajectories starting from the origin can be compressed efficiently so that the reconstructed trajectory is quite similar to the original, and the latent space code obtained by compression can be used for maneuver detection. Using a variational autoencoder, assuming a normal distribution, the latent spatial distribution can be approximated. However, in this article, the goal was to test this concept with adversarial training, so the so-called adversarial autoencoder is trained. It has been shown that this method is suitable for twelve-fold compression of trajectories, and the latent code is suitable for maneuver detection. This proves that the encoder has learned useful features about the distribution that generates trajectories.","1543-9259","978-1-6654-4499-6","10.1109/INES52918.2021.9512929","European Social Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9512929","Adversarial autoencoder;NGSIM;maneuver deteciton;trajectory compression","Training;Convolutional codes;Recurrent neural networks;Graphical models;Conferences;Time series analysis;Switches","automobiles;convolution;driver information systems;feature extraction;learning (artificial intelligence);pattern classification;recurrent neural nets;time series","maneuver detection;recurrent neural networks;1-dimensional convolutional networks;reconstructed trajectory;adversarial autoencoder;trajectory generation;maneuver classification;self-driving cars","","","","23","","16 Aug 2021","","","IEEE","IEEE Conferences"
"End-to-End Sinkhorn Autoencoder With Noise Generator","K. Deja; J. Dubiński; P. Nowak; S. Wenzel; P. Spurek; T. Trzcinski","Faculty of Electronics and Information Technology, Warsaw University of Technology, Warsaw, Poland; Faculty of Electronics and Information Technology, Warsaw University of Technology, Warsaw, Poland; Faculty of Physics, Warsaw University of Technology, Warsaw, Poland; CERN, Geneva, Switzerland; Faculty of Mathematics and Computer Science, Jagiellonian University, Poland; Tooploox, Poland","IEEE Access","12 Jan 2021","2021","9","","7211","7219","In this work, we propose a novel end-to-end Sinkhorn Autoencoder with a noise generator for efficient data collection simulation. Simulating processes that aim at collecting experimental data is crucial for multiple real-life applications, including nuclear medicine, astronomy, and high energy physics. Contemporary methods, such as Monte Carlo algorithms, provide high-fidelity results at a price of high computational cost. Multiple attempts are taken to reduce this burden, e.g. using generative approaches based on Generative Adversarial Networks or Variational Autoencoders. Although such methods are much faster, they are often unstable in training and do not allow sampling from an entire data distribution. To address these shortcomings, we introduce a novel method dubbed end-to-end Sinkhorn Autoencoder, that leverages the Sinkhorn algorithm to explicitly align distribution of encoded real data examples and generated noise. More precisely, we extend autoencoder architecture by adding a deterministic neural network trained to map noise from a known distribution onto autoencoder latent space representing data distribution. We optimise the entire model jointly. Our method outperforms co mpeting approaches on a challenging dataset of simulation data from Zero Degree Calorimeters of ALICE experiment in LHC. as well as standard benchmarks, such as MNIST and CelebA.","2169-3536","","10.1109/ACCESS.2020.3048622","Polish National Science Center Project(grant numbers:UMO-2018/31/N/ST6/02374,UMO-2016/21/D/ST6/01946); Warsaw University of Technology(grant numbers:IDUB-POB-FWEiTE-1); Dean of the Faculty of Electronics and Information Technology, Warsaw University of Technology(grant numbers:II/2017/GD/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311504","Computer simulation;generative modeling;machine learning","Computational modeling;Noise generators;Training;Neural networks;Decoding;Data models;Standards","computer simulation;encoding;learning (artificial intelligence);Monte Carlo methods;neural nets;sampling methods;statistical distributions;stochastic processes","noise generator;efficient data collection simulation;high energy physics;high-fidelity results;high computational cost;generative approaches;data distribution;Sinkhorn algorithm;encoded real data examples;generated noise;autoencoder architecture;autoencoder latent space;simulation data","","","","47","CCBY","31 Dec 2020","","","IEEE","IEEE Journals"
"The Importance Weighted Autoencoder in End-to-End Speech Synthesis","Y. Wang; Y. Peng; J. Wang; H. Wang; Q. Zhang","Key Laboratory of Media Audio & Video (Communication University of China), Ministry of Education, Beijing, China; Key Laboratory of Media Audio & Video (Communication University of China), Ministry of Education, Beijing, China; State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China; State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China; State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China","2020 IEEE International Conference on Information Technology,Big Data and Artificial Intelligence (ICIBA)","14 Dec 2020","2020","1","","1273","1277","The modeling of style when synthesizing speech from text aim to enrich the emotional expression of synthesized speech. In this paper, the importance weighted autoencoder(IWAE) is introduced into Tacotron, an end-to-end speech synthesis system, to learn the latent representation of speaking styles independent of text content in an unsupervised way. Compared with the Variational Autoencoder(VAE), a generative model that can be used to model prior data distribution, IWAE has a strictly tighter variational lower bound derive from different weighted importance. In the proposed network, we input the style representation, learned by IWAE, into Tacotron to generate speech with more rhythmic. Finally, the proposed model shows better performance of speech quality in both objective and subjective ways compared to Global Style Token (GST) and VAE-Tacotron.","","978-1-7281-5224-0","10.1109/ICIBA50161.2020.9277263","National Natural Science Foundation of China(grant numbers:61631016,61501410); Fundamental Research Funds for the Central Universities(grant numbers:3132018XNG1805); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9277263","importance weighted;unsupervised learning;tone transfer;text-to-speech synthesis","Training;Spectrogram;Computational modeling;Vocoders;Speech synthesis;Decoding;Neural networks","emotion recognition;neural nets;signal representation;speech synthesis","emotional expression;end-to-end speech synthesis system;latent representation;generative model;prior data distribution;variational lower bound;weighted importance;style representation;speech quality;Tacotron;importance weighted autoencoder;IWAE;speaking styles","","","","23","","14 Dec 2020","","","IEEE","IEEE Conferences"
"Primitives Generation Policy Learning without Catastrophic Forgetting for Robotic Manipulation","F. Xiong; Z. Liu; K. Huang; X. Yang; A. Hussain","School of Computer and Control, University of Chinese Academy of Sciences (UCAS), China; CAS Centre for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, China; Department of EEE, Xi’an Jiaotong-Liverpool University, China; School of Computer and Control, University of Chinese Academy of Sciences (UCAS), China; School of Computing, Edinburgh Napier University, U.K.","2019 International Conference on Data Mining Workshops (ICDMW)","13 Jan 2020","2019","","","890","897","Catastrophic forgetting is a tough challenge when agent attempts to address different tasks sequentially without storing previous information, which gradually hinders the development of continual learning. Except for image classification tasks in continual learning, however, there are little reviews related to robotic manipulation. In this paper, we present a novel hierarchical architecture called Primitives Generation Policy Learning to enable continual learning. More specifically, a generative method by Variational Autoencoder is employed to generate state primitives from task space, then separate policy learning component is designed to learn torque control commands for different tasks sequentially. Furthermore, different task policies could be identified automatically by comparing reconstruction loss in the autoencoder. Experiment on robotic manipulation task shows that the proposed method exhibits substantially improved performance over some other continual learning methods.","2375-9259","978-1-7281-4896-0","10.1109/ICDMW.2019.00130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8955489","Variational Autoencoder, Continual learning, Catastrophic forgetting, Robotic manipulation","Task analysis;Robots;Neural networks;Learning systems;Trajectory;Decoding;Aerospace electronics","image classification;image reconstruction;learning (artificial intelligence);manipulators;robot vision;torque control","reconstruction loss;torque control commands;variational autoencoder;primitives generation policy learning;policy learning component;continual learning methods;robotic manipulation task;task policies;task space;state primitives;generative method;image classification tasks;catastrophic forgetting","","","","25","","13 Jan 2020","","","IEEE","IEEE Conferences"
"Pattern Recognition and Reconstruction: Detecting Malicious Deletions in Textual Communications","A. A. Solanke; X. Chen; Y. Ramírez-Cruz","Cirsfid-AlmaAI, University of Bologna, Bologna, Italy; SnT, University of Luxembourg, Luxembourg; SnT, University of Luxembourg, Luxembourg","2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","2574","2582","Digital forensic artifacts aim to provide evidence from digital sources for attributing blame to suspects, assessing their intents, corroborating their statements or alibis, etc. Textual data is a significant source of artifacts, which can take various forms, for instance in the form of communications. E-mails, memos, tweets, and text messages are all examples of textual communications. Complex statistical, linguistic and other scientific procedures can be manually applied to this data to uncover significant clues that point the way to factual information. While expert investigators can undertake this task, there is a possibility that critical information is missed or overlooked. The primary objective of this work is to aid investigators by partially automating the detection of suspicious e-mail deletions. Our approach consists in building a dynamic graph to represent the temporal evolution of communications, and then using a Variational Graph Autoencoder to detect possible e-mail deletions in this graph. Our model uses multiple types of features for representing node and edge attributes, some of which are based on metadata of the messages and the rest are extracted from the contents using natural language processing and text mining techniques. We use the autoencoder to detect missing edges, which we interpret as potential deletions; and to reconstruct their features, from which we emit hypotheses about the topics of deleted messages. We conducted an empirical evaluation of our model on the Enron e-mail dataset, which shows that our model is able to accurately detect a significant proportion of missing communications and to reconstruct the corresponding topic vectors.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671921","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671921","Digital Forensics;Variational Graph Autoencoders;Forensic Artificial Intelligence","Text mining;Image edge detection;Semantics;Metadata;Big Data;Linguistics;Feature extraction","data mining;digital forensics;electronic mail;electronic messaging;graph theory;natural language processing;pattern recognition;social networking (online);text analysis","statements;alibis;textual data;e-mails;text messages;textual communications;other scientific procedures;significant clues;factual information;expert investigators;critical information;suspicious e-mail deletions;dynamic graph;Variational Graph Autoencoder;possible e-mail deletions;edge attributes;natural language processing;text mining techniques;potential deletions;deleted messages;Enron e-mail dataset;significant proportion;pattern recognition;malicious deletions;digital forensic artifacts;digital sources","","","","54","EU","13 Jan 2022","","","IEEE","IEEE Conferences"
"Semi-supervised Cardiac MRI Segmentation Based on Generative Adversarial Network and Variational Auto-Encoder","S. Li; Y. Zhang; X. Yang","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China","2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","14 Jan 2022","2021","","","1402","1405","Segmentation of the heart structure plays an essential role in cardiac diseases diagnosis and treatment planning. This paper proposes a semi-supervised learning network for multi-objective segmentation of cardiac MRI data, which comprises a U-Net as encoder and a conditional generative adversarial network (GAN) as the decoder. The process of segmentation takes the predictive result as latent variables and aims to estimate the distribution of the latent. We pre-align cardiac images to each other in an affine way and pre-train the GAN using a small amount of annotated data. A loss function focusing on the region of interest (ROI) is proposed. Experimental results on MICCAI 2020 Multi-Centre, Multi-Vendor & MultiDisease Cardiac Image Segmentation Challenge (M & Ms) dataset show that the performance of our semi-supervised learning network not only reaches or exceeds the supervised methods in multi-object segmentation but also has the generalization ability of supervised learning-based networks.","","978-1-6654-0126-5","10.1109/BIBM52615.2021.9669685","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669685","Semi-supervised learning;Variational auto-encoder;Generative adversial network;Cardiac segmentation","Training;Image segmentation;Magnetic resonance imaging;Supervised learning;Semantics;Interference;Semisupervised learning","biomedical MRI;cardiology;convolutional neural nets;diseases;image segmentation;medical image processing;semi-supervised learning (artificial intelligence)","semisupervised learning network;semisupervised cardiac MRI segmentation;heart structure;cardiac disease diagnosis;multiobjective segmentation;generative adversarial network;GAN;prealign cardiac images;cardiac disease treatment planning;variational autoencoder;U-Net","","","","9","IEEE","14 Jan 2022","","","IEEE","IEEE Conferences"
"Learning a Probabilistic Model for Diffeomorphic Registration","J. Krebs; H. Delingette; B. Mailhé; N. Ayache; T. Mansi","Université Côte d’Azur, Inria, Epione Team, Sophia Antipolis, France; Université Côte d’Azur, Inria, Epione Team, Sophia Antipolis, France; Siemens Healthineers, Digital Services, Digital Technology and Innovation, Princeton, NJ, USA; Université Côte d’Azur, Inria, Epione Team, Sophia Antipolis, France; Siemens Healthineers, Digital Services, Digital Technology and Innovation, Princeton, NJ, USA","IEEE Transactions on Medical Imaging","30 Aug 2019","2019","38","9","2165","2176","We propose to learn a low-dimensional probabilistic deformation model from data which can be used for the registration and the analysis of deformations. The latent variable model maps similar deformations close to each other in an encoding space. It enables to compare deformations, to generate normal or pathological deformations for any new image, or to transport deformations from one image pair to any other image. Our unsupervised method is based on the variational inference. In particular, we use a conditional variational autoencoder network and constrain transformations to be symmetric and diffeomorphic by applying a differentiable exponentiation layer with a symmetric loss function. We also present a formulation that includes spatial regularization such as the diffusion-based filters. In addition, our framework provides multi-scale velocity field estimations. We evaluated our method on 3-D intra-subject registration using 334 cardiac cine-MRIs. On this dataset, our method showed the state-of-the-art performance with a mean DICE score of 81.2% and a mean Hausdorff distance of 7.3 mm using 32 latent dimensions compared to three state-of-the-art methods while also demonstrating more regular deformation fields. The average time per registration was 0.32 s. Besides, we visualized the learned latent space and showed that the encoded deformations can be used to transport deformations and to cluster diseases with a classification accuracy of 83% after applying a linear projection.","1558-254X","","10.1109/TMI.2019.2897112","AAP Santé(grant numbers:06 2017-260 DGA-DSH); INRIA Sophia Antipolis–Méditerranée, “NEF” computation cluster; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8633848","Deformable registration;probabilistic encoding;deep learning;conditional variational autoencoder;latent variable model;deformation transport","Strain;Probabilistic logic;Deformable models;Training;Estimation;Image registration;Computational modeling","biomedical MRI;diseases;image registration;learning (artificial intelligence);medical image processing;pattern clustering","constrain transformations;symmetric loss function;learned latent space;encoded deformations;probabilistic model;diffeomorphic registration;low-dimensional probabilistic deformation model;pathological deformations;image pair;unsupervised method;conditional variational autoencoder network;3D intrasubject registration;disease;cardiac cine-MRI","Algorithms;Deep Learning;Heart;Humans;Image Processing, Computer-Assisted;Magnetic Resonance Imaging, Cine;Models, Statistical","68","","55","IEEE","3 Feb 2019","","","IEEE","IEEE Journals"
"Audio2Gestures: Generating Diverse Gestures from Speech Audio with Conditional Variational Autoencoders","J. Li; D. Kang; W. Pei; X. Zhe; Y. Zhang; Z. He; L. Bao","Harbin Institute of Technology, Shenzhen; Tencent AI Lab; Harbin Institute of Technology, Shenzhen; Tencent AI Lab; Tencent AI Lab; Harbin Institute of Technology, Shenzhen; Tencent AI Lab","2021 IEEE/CVF International Conference on Computer Vision (ICCV)","28 Feb 2022","2021","","","11273","11282","Generating conversational gestures from speech audio is challenging due to the inherent one-to-many mapping be-tween audio and body motions. Conventional CNNs/RNNs assume one-to-one mapping, and thus tend to predict the average of all possible target motions, resulting in plain/boring motions during inference. In order to over-come this problem, we propose a novel conditional variational autoencoder (VAE) that explicitly models one-to-many audio-to-motion mapping by splitting the cross-modal latent code into shared code and motion-specific code. The shared code mainly models the strong correlation between audio and motion (such as the synchronized audio and motion beats), while the motion-specific code captures diverse motion information independent of the audio. However, splitting the latent code into two parts poses training difficulties for the VAE model. A mapping network facilitating random sampling along with other techniques including relaxed motion loss, bicycle constraint, and diversity loss are designed to better train the VAE. Experiments on both 3D and 2D motion datasets verify that our method generates more realistic and diverse motions than state-of-the-art methods, quantitatively and qualitatively. Finally, we demonstrate that our method can be readily used to generate motion sequences with user-specified motion clips on the timeline. Code and more results are at https://jingli513.github.io/audio2gestures.","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.01110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9710107","Gestures and body pose;Action and behavior recognition;Vision + other modalities","Training;Computer vision;Codes;Three-dimensional displays;Correlation;Speech coding;Bicycles","","","","2","","43","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"Robust AUV Visual Loop-Closure Detection Based on Variational Autoencoder Network","Y. Wang; X. Ma; J. Wang; S. Hou; J. Dai; D. Gu; H. Wang","School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; School of Information Science and Technology, Dalian Maritime University, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; Peng Cheng Laboratory, Shenzhen, China; School of Computer Science and Electronic Engineering, University of Essex, Colchester, U.K.; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China","IEEE Transactions on Industrial Informatics","30 Sep 2022","2022","18","12","8829","8838","The visual loop-closure detection for autonomous underwater vehicles (AUVs) is a key component to reduce the drift error accumulated in simultaneous localization and mapping tasks. However, due to viewpoint changes, textureless images, and fast-moving objects, the loop closure detection in dramatically changing underwater environments remains a challenging problem to traditional geometric methods. Inspired by strong feature learning ability of deep neural networks, we propose an underwater loop-closure detection method based on a variational autoencoder network in this article. Our proposed method can learn effective image representations to deal with the challenges caused by dynamic underwater environments. Specifically, the proposed network is an unsupervised method, which avoids the difficulty and cost of labeling a great quantity of underwater data. Also included is a semantic object segmentation module, which is utilized to segment the underwater environments and assign weights to objects in order to alleviate the impact of fast-moving objects. Furthermore, an underwater image description scheme is used to enable efficient access to geometric and object-level semantic information, which helps to build a robust and real-time system in dramatically changing underwater scenarios. Finally, we test the proposed system under complex underwater environments and get a recall rate of 92.31% in the tested environments.","1941-0050","","10.1109/TII.2022.3145860","National Natural Science Foundation of China(grant numbers:61801078,62071081,U1933104); Fundamental Research Funds for the Central Universities(grant numbers:DUT21GF204); China Postdoctoral Science Foundation(grant numbers:2020M682827); China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9693268","Autonomous underwater vehicle (AUV) simultaneous localization and mapping (SLAM);deep neural network;loop closure detection;semantic segmentation","Location awareness;Visualization;Semantics;Simultaneous localization and mapping;Informatics;Task analysis;Sonar navigation","","","","1","","30","IEEE","25 Jan 2022","","","IEEE","IEEE Journals"
"Multiple Style Transfer Via Variational Autoencoder","Z. -S. Liu; V. Kalogeiton; M. -P. Cani","LIX, École Polytechnique, CNRS, IP Paris; LIX, École Polytechnique, CNRS, IP Paris; LIX, École Polytechnique, CNRS, IP Paris","2021 IEEE International Conference on Image Processing (ICIP)","23 Aug 2021","2021","","","2413","2417","Modern works on style transfer focus on transferring style from a single image. Recently, some approaches study multiple style transfer; these, however, are either too slow or fail to mix multiple styles. We propose ST-VAE, a Variational AutoEncoder for latent space-based style transfer. It performs multiple style transfer by projecting nonlinear styles to a linear latent space, enabling to merge styles via linear interpolation before transferring the new style to the content image. To evaluate ST-VAE, we experiment on COCO for single and multiple style transfer. We also present a case study revealing that ST-VAE outperforms other methods while being faster, flexible, and setting a new path for multiple style transfer.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506379","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506379","","Training;Interpolation;Image processing;Conferences;Gaussian distribution;Videos;Testing","document image processing;image processing;interpolation;learning (artificial intelligence)","multiple style transfer;style transfer focus;transferring style;multiple styles;latent space-based style transfer","","1","","29","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"A Variational AutoEncoder-Based Relational Model for Cost-Effective Automatic Medical Fraud Detection","J. Chen; X. Hu; D. Yi; J. Li; M. Alazab","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; Department of Network and Technology, Shenzhen Nanshan People&#x2019;s Hospital, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Engineering, IT and Environment, Charles Darwin University, NT, Australia","IEEE Transactions on Dependable and Secure Computing","","2022","PP","99","1","14","This work aims to develop a framework of automatic medical fraud detection (AMFD) which can be deployed in healthcare industry. To address the issue that the medical fraud labels are insufficient in both size and classes for training a good AMFD model, this work proposes a novel Variational AutoEncoder-based Relational Model (VAERM) which can simultaneously exploit Patient-Doctor relational network and one-class fraud labels to improve the fraud detection. Then, the proposed VAERM coupled with active learning strategy can assist healthcare industry experts to conduct cost-effective fraud investigation. Finally, we propose an online model updating method to reduce the computation and memory requirement while preserving the predictive performance. The proposed framework is tested in a real world dataset and it empirically outperforms the state-of-the-art methods in both automatic fraud detection and fraud investigation tasks.","1941-0018","","10.1109/TDSC.2022.3187973","National Key R&amp;D Program of China(grant numbers:2020YFA0908700); National Nature Science Foundation of China(grant numbers:U1713212,62072315,62073225,61806130,61836005,62006157); Natural Science Foundation of Guangdong Province-Outstanding Youth Program(grant numbers:2019B151502018); Guangdong &#x201C;Pearl River Talent Recruitment Program&#x201D;(grant numbers:2019ZT08X603); Technology Research Project of Shenzhen City(grant numbers:JSGG20180507182904693); Public Technology Platform of Shenzhen City(grant numbers:GGFW2018021118145859); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9827573","Active learning;automatic fraud detection;graph convolution network;healthcare industry;one-class learning","Industries;Medical diagnostic imaging;Computational modeling;Hospitals;Costs;Predictive models;Insurance","","","","","","","IEEE","12 Jul 2022","","","IEEE","IEEE Early Access Articles"
"Radar-Based Gesture Recognition Using a Variational Autoencoder With Deep Statistical Metric Learning","T. Stadelmayer; A. Santra; R. Weigel; F. Lurz","Infineon Technologies AG, Neubiberg, Germany; Infineon Technologies AG, Neubiberg, Germany; Institute of Electronics Engineering, Friedrich-Alexander University Erlangen-Nuremberg, Erlangen, Germany; Institute of High-Frequency Technology, Hamburg University of Technology, Hamburg, Germany","IEEE Transactions on Microwave Theory and Techniques","","2022","PP","99","1","12","Radar-based gesture recognition systems are a promising concept for new human–machine interfaces. However, the systems are sensitive to user-dependent gesture patterns, sensor noise characteristics, background environments, and unknown gestures or background motions. To overcome such challenges, we propose a variational autoencoder architecture-based deep metric learning, which is optimized using a novel loss function combining a statistical distance triplet loss and the center loss. By learning the statistical distance between distributions, the proposed solution, compared with triplet loss, is able to better learn the nonlinear characteristics in the data, is less sensitivity to training strategy, and is capable of creating close knit embedding clusters. Moreover, it is experimentally demonstrated that the proposed gesture recognition system using radar spectrograms has improved classification accuracy and random gesture rejection accuracy compared with the state-of-the-art deep metric learning approaches. Furthermore, we proof the real-world capability of the system by implementing a real-time demonstrator, which allows playing “Tetris” with hand gestures.","1557-9670","","10.1109/TMTT.2022.3201265","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9882981","Frequency-modulated continuous wave (FMCW) radar;hand gesture recognition;microwave motion sensors;open-set classification;radar systems","Gesture recognition;Radar imaging;Radar antennas;Measurement;Spectrogram;Chirp;Doppler radar","","","","","","","IEEE","9 Sep 2022","","","IEEE","IEEE Early Access Articles"
"Predictive Coding, Variational Autoencoders, and Biological Connections","J. Marino","Computation and Neural Systems, California Institute of Technology, Pasadena, CA 91125, U.S.A.","Neural Computation","27 Jun 2022","2022","34","1","1","44","We present a review of predictive coding, from theoretical neuroscience, and variational autoencoders, from machine learning, identifying the common origin and mathematical framework underlying both areas. As each area is prominent within its respective field, more firmly connecting these areas could prove useful in the dialogue between neuroscience and machine learning. After reviewing each area, we discuss two possible correspondences implied by this perspective: cortical pyramidal dendrites as analogous to (nonlinear) deep networks and lateral inhibition as analogous to normalizing flows. These connections may provide new directions for further investigations in each field.","0899-7667","","10.1162/neco_a_01458","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9808237","","","","","","","","","","27 Jun 2022","","","MIT Press","MIT Press Journals"
"Data Augmentation in High Dimensional Low Sample Size Setting Using a Geometry-Based Variational Autoencoder","C. Chadebec; E. Thibeau-Sutre; N. Burgos; S. Allassonni&#x00E8;re","Universit&#x00E9; de Paris, INRIA, Centre de Recherche des Cordeliers, INSERM, Sorbonne Universit&#x00E9;, Paris, France; Institut du Cerveau - Paris Brain Institute, ICM, Inserm U 1127, CNRS UMR 7225, Inria Aramis project-team, Sorbonne Universit&#x00E9;, Paris, France; Institut du Cerveau - Paris Brain Institute, ICM, Inserm U 1127, CNRS UMR 7225, Inria Aramis project-team, Sorbonne Universit&#x00E9;, Paris, France; Universit&#x00E9; de Paris, INRIA, Centre de Recherche des Cordeliers, INSERM, Sorbonne Universit&#x00E9;, Paris, France","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2022","PP","99","1","18","In this paper, we propose a new method to perform data augmentation in a reliable way in the High Dimensional Low Sample Size (HDLSS) setting using a geometry-based variational autoencoder (VAE). Our approach combines the proposal of 1) a new VAE model, the latent space of which is modeled as a Riemannian manifold and which combines both Riemannian metric learning and normalizing flows and 2) a new generation scheme which produces more meaningful samples especially in the context of small data sets. The method is tested through a wide experimental study where its robustness to data sets, classifiers and training samples size is stressed. It is also validated on a medical imaging classification task on the challenging ADNI database where a small number of 3D brain magnetic resonance images (MRIs) are considered and augmented using the proposed VAE framework. In each case, the proposed method allows for a significant and reliable gain in the classification metrics. For instance, balanced accuracy jumps from 66.3% to 74.3% for a <italic>state-of-the-art</italic> convolutional neural network classifier trained with 50 MRIs of cognitively normal (CN) and 50 Alzheimer disease (AD) patients and from 77.7% to 86.3% when trained with 243 CN and 210 AD while improving greatly sensitivity and specificity metrics.","1939-3539","","10.1109/TPAMI.2022.3185773","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9806307","","Data models;Measurement;Training;Magnetic resonance imaging;Databases;Three-dimensional displays;Task analysis","","","","","","","IEEE","24 Jun 2022","","","IEEE","IEEE Early Access Articles"
"An Improved Technique for Pneumonia Infected Patients Image Recognition Based on Combination Algorithm of Smooth Generalized Pinball SVM and Variational Autoencoders","W. Ratiphaphongthon; W. Panup; R. Wangkeeree","Department of Mathematics, University of York, Heslington, U.K; Geo-Informatics and Space Technology Development Agency (GISTDA), Bangkok, Thailand; Department of Mathematics, Faculty of Science, Research Center for Academic Excellence in Mathematics, Naresuan University, Phitsanulok, Thailand","IEEE Access","13 Oct 2022","2022","10","","107431","107445","We present a method based on combining a smooth generalized pinball support vector machine (SVM) and variational autoencoders (VAEs) in chest X-ray (CXR) images. We incorporate generalized pinball into the SVM model to address the hinge loss function’s noise sensitivity and resampling instability. Since the generalized pinball loss is a non-differentiable function, the objective function is non-differentiable. To solve the non-differentiable term in the model’s objective function, we construct a smooth approximation function for the generalized pinball loss function so that the model in the original space can be solved directly. More specifically, using the proposed smoothing functions, we employ the smoothing stochastic quasi-Newton method to solve the primal problem. Moreover, we have introduced verified theorems related to our approaches, and the theoretical convergence of our approaches has been proposed. Numerical comparisons between parameter values of several iteration objective functions are also provided to test the model. Experiments with several benchmark datasets show that our method has the best prediction accuracy 64% and 57% from all of binary datasets and multiclass datasets, respectively. Moreover, our method has the best prediction of Matthews correlation coefficient (MCC) 64% from all of datasets.","2169-3536","","10.1109/ACCESS.2022.3212535","National Science, Research and Innovation Fund (NSRF) via the Program Management Unit for Human Resources and Institutional Development, Research and Innovation, Thailand(grant numbers:B05F640180); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9912421","Support vector machine;generalized pinball loss;feature noise;regularized stochastic BFGS algorithm;image recognition","Support vector machines;Stochastic processes;Pulmonary diseases;Sensitivity;X-ray imaging;Linear programming;Image recognition;Pneumonia","","","","","","65","CCBY","5 Oct 2022","","","IEEE","IEEE Journals"
"RVAE-LAMOL: Residual Variational Autoencoder to Enhance Lifelong Language Learning","H. Wang; R. Fu; X. Zhang; J. Zhou","University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China","2022 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2022","2022","","","1","9","Lifelong Language Learning (LLL) aims to train a neural network to learn a stream of NLP tasks while retaining knowledge from previous tasks. However, previous works which followed data-free constraint still suffer from catastrophic forgetting issue, where the model forgets what it just learned from previous tasks. In order to alleviate catastrophic forgetting, we propose the residual variational autoencoder (RVAE) to enhance LAMOL, a recent LLL model, by mapping different tasks into a limited unified semantic space. In this space, previous tasks are easy to be correct to their own distribution by pseudo samples. Furthermore, we propose an identity task to make the model is discriminative to recognize the sample belonging to which task. For training RVAE-LAMOL better, we propose a novel training scheme Alternate Lag Training. In the experiments, we test RVAE-LAMOL on permutations of three datasets from DecaNLP. The experimental results demonstrate that RVAE-LAMOL outperforms naïve LAMOL on all permutations and generates more meaningful pseudo-samples.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9892670","Chinese Academy of Sciences(grant numbers:E1291902,2021025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9892670","Residual VAE;lifelong language model learning;GPT-2","Training;Knowledge engineering;Correlation;Semantics;Neural networks;Multitasking;Task analysis","","","","","","35","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"Distribution Network Anomaly Detection Algorithm Based on VAE","Z. Wang; Y. Ding; T. Zhang","University of Chinese Academy of Sciences, Beijing, China; Shenyang Institute of Computing Technology, Chinese Academy of Sciences, Shenyang, China; Beijing Union University, Beijing, China","2022 11th International Conference of Information and Communication Technology (ICTech))","18 Aug 2022","2022","","","84","87","With the booming development of economy and technology, China's electric industry has gradually realized intelligent, has developed into a comprehensive network including computer network, power network, information network. The current power information monitoring technology is mainly aimed at the power generation, transmission and transformation stage, and the lack of effective power information detection means in the power distribution stage. Therefore, a distribution network anomaly detection algorithm based on variational auto-encoder is proposed to solve the problem of anomaly detection of distribution terminal data. The input time series power load data is compressed and reconstructed, and the anomaly degree of samples is detected by reconstruction error. Experimental results show that the proposed algorithm has high detection rate and accuracy, as well as high robustness.","","978-1-6654-9694-0","10.1109/ICTech55460.2022.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9849633","distribution network;anomaly detection;variational auto-encoder;power load","Substations;Time series analysis;Power distribution;Distribution networks;Robustness;Power grids;Anomaly detection","data handling;distribution networks;power engineering computing;time series","power distribution stage;distribution network anomaly detection algorithm;distribution terminal data;input time series power load data;computer network;power network;information network;power generation;effective power information detection;China electric industry;power information monitoring technology;variational autoencoder;reconstruction error","","","","9","IEEE","18 Aug 2022","","","IEEE","IEEE Conferences"
"Convolutional Graph Autoencoder: A Generative Deep Neural Network for Probabilistic Spatio-Temporal Solar Irradiance Forecasting","M. Khodayar; S. Mohammadi; M. E. Khodayar; J. Wang; G. Liu","Department of Electrical and Computer Engineering, Southern Methodist University, Dallas, USA; Department of Electrical and Computer Engineering, Southern Methodist University, Dallas, USA; Department of Electrical and Computer Engineering, Southern Methodist University, Dallas, USA; Department of Electrical and Computer Engineering, Southern Methodist University, Dallas, USA; Global Energy Interconnection Research Institute North America (GEIRI North America or GEIRINA), San Jose, USA","IEEE Transactions on Sustainable Energy","20 Mar 2020","2020","11","2","571","583","Machine learning on graphs is an important and omnipresent task for a vast variety of applications including anomaly detection and dynamic network analysis. In this paper, a deep generative model is introduced to capture continuous probability densities corresponding to the nodes of an arbitrary graph. In contrast to all learning formulations in the area of discriminative pattern recognition, we propose a scalable generative optimization/algorithm theoretically proved to capture distributions at the nodes of a graph. Our model is able to generate samples from the probability densities learned at each node. This probabilistic data generation model, i.e., convolutional graph autoencoder (CGAE), is devised based on the localized first-order approximation of spectral graph convolutions, deep learning, and the variational Bayesian inference. We apply the CGAE to anew problem, the spatio-temporal probabilistic solar irradiance prediction. Multiple solar radiation measurement sites in a wide area in northern states of the U.S. are modeled as an undirected graph. Using our proposed model, the distribution of future irradiance given historical radiation observations is estimated for every site/node. Numerical results on the national solar radiation database show state-of-the-art performance for probabilistic radiation prediction on geographically distributed irradiance data in terms of reliability, sharpness, and continuous ranked probability score.","1949-3037","","10.1109/TSTE.2019.2897688","National Science Foundation(grant numbers:ECCS-1710923); State Grid Corporation Technology(grant numbers:5455HJ180018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8663347","Deep neural network;spatio-temporal forecasting;probabilistic forecasting;spectral graph convolutions;variational Bayesian inference","Predictive models;Probabilistic logic;Forecasting;Data models;Mathematical model;Solar radiation;Computational modeling","Bayes methods;graph theory;learning (artificial intelligence);neural nets;pattern recognition;power engineering computing;probability;solar power stations;solar radiation;spatiotemporal phenomena;sunlight","convolutional graph autoencoder;generative deep neural network;probabilistic spatio-temporal;machine learning;omnipresent task;anomaly detection;dynamic network analysis;deep generative model;continuous probability densities;arbitrary graph;learning formulations;discriminative pattern recognition;probabilistic data generation model;CGAE;spectral graph convolutions;deep learning;spatio-temporal probabilistic solar irradiance prediction;multiple solar radiation measurement sites;undirected graph;future irradiance;national solar radiation database;probabilistic radiation prediction;geographically distributed irradiance data","","61","","58","IEEE","8 Mar 2019","","","IEEE","IEEE Journals"
"A Variational Inference Method for Few-Shot Learning","J. Xu; B. Liu; Y. Xiao","School of Automation, Guangdong University of Technology, Guangzhou, China; School of Automation, Guangdong University of Technology, Guangzhou, China; School of Computer, Guangdong University of Technology, Guangzhou, China","IEEE Transactions on Circuits and Systems for Video Technology","","2022","PP","99","1","1","Existing few-shot learning (FSL) methods usually treat each sample as a single feature point or utilize intra-class feature transformation to augment features. However, few-shot novel features are always vulnerable to noise, intra-class features have large variance and the direction of intra-class feature transformations is uncontrollable, which result in degradation of FSL models. Besides, existing FSL methods are one-generation based which do not utilize the prior knowledge obtained in the prior generation model to generate more robust posterior model in FSL and lack the interpretability in FSL. In this paper, we propose a novel two-generation based Latent Feature Augmentation and Distribution Regularization framework (LFADR) including prior relation net (PRN) and vae-based posterior relation net (VPORN) to generate a more robust VPORN based on PRN by transferring the prior knowledge in FSL. Firstly, we utilize a simple single-original-feature-point-based PRN to generate the more informative prior knowledge. We then propose a regularized-distribution-based VPORN driven by VAE to augment latent features by sampling from regularized class-specific distribution based on the prior knowledge transferred from PRN in order to guarantee and control the diversity of intra-class features which avoids uncontrollable feature transformations and reduces the variance of intra-class features and the impact of noise. As a result, LFADR can learn more key and robust intra-class and discriminative inter-class features and make decision boundary clearer in FSL, which is optimized as a variational inference problem. Furthermore, we analyse the feasibility and effectiveness of our framework based on Hoeffding’s inequality and Chernoff’s bounding method. Finally, experimental results validate our theoretical analysis and the effectiveness of our proposed FSL framework.","1558-2205","","10.1109/TCSVT.2022.3199496","National Natural Science Foundation of China(grant numbers:61672169,61876044,62076074); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9858880","Few-shot learning(FSL);latent feature augmentation;distribution regularization;variational autoencoder(VAE)","Task analysis;Power capacitors;Estimation;Image synthesis;Feature extraction;Training;Neural networks","","","","","","","IEEE","17 Aug 2022","","","IEEE","IEEE Early Access Articles"
"Learning Product Codebooks Using Vector-Quantized Autoencoders for Image Retrieval","H. Wu; M. Flierl","School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm; School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm","2019 IEEE Global Conference on Signal and Information Processing (GlobalSIP)","28 Jan 2020","2019","","","1","5","Vector-Quantized Variational Autoencoders (VQ-VAE)[1] provide an unsupervised model for learning discrete representations by combining vector quantization and autoencoders. In this paper, we study the use of VQ-VAE for representation learning of downstream tasks, such as image retrieval. First, we describe the VQ-VAE in the context of an information-theoretic framework. Then, we show that the regularization effect on the learned representation is determined by the size of the embedded codebook before the training. As a result, we introduce a hyperparameter to balance the strength of the vector quantizer and the reconstruction error. By tuning the hyperparameter, the embedded bottleneck quantizer is used as a regularizer that forces the output of the encoder to share a constrained coding space. With that, the learned latent features better preserve the similarity relations of the data space. Finally, we incorporate the product quantizer into the bottleneck stage of VQ-VAE and use it as an end-to-end unsupervised learning model for image retrieval tasks. The product quantizer has the advantage of generating large and structured codebooks. Fast retrieval can be achieved by using lookup tables that store the distance between any pair of sub-codewords. State-of-the-art retrieval results are achieved by the proposed codebooks.","","978-1-7281-2723-1","10.1109/GlobalSIP45357.2019.8969272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8969272","","Image coding;Decoding;Image reconstruction;Image retrieval;Vector quantization;Training","content-based retrieval;image coding;image retrieval;neural nets;probability;unsupervised learning;vector quantisation","VQ-VAE;embedded codebook;embedded bottleneck quantizer;learned latent features;product quantizer;unsupervised learning model;image retrieval tasks;learning product codebooks;vector-quantized variational autoencoders;learning discrete representations;information-theoretic framework;constrained coding space","","1","","19","","28 Jan 2020","","","IEEE","IEEE Conferences"
"Learning Latent Representations for Style Control and Transfer in End-to-end Speech Synthesis","Y. -J. Zhang; S. Pan; L. He; Z. -H. Ling","National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China, Hefei, P.R. China; Microsoft China; Microsoft China; National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China, Hefei, P.R. China","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","6945","6949","In this paper, we introduce the Variational Autoencoder (VAE) to an end-to-end speech synthesis model, to learn the latent representation of speaking styles in an unsupervised manner. The style representation learned through VAE shows good properties such as disentangling, scaling, and combination, which makes it easy for style control. Style transfer can be achieved in this framework by first inferring style representation through the recognition network of VAE, then feeding it into TTS network to guide the style in synthesizing speech. To avoid Kullback-Leibler (KL) divergence collapse in training, several techniques are adopted. Finally, the proposed model shows good performance of style control and outperforms Global Style Token (GST) model in ABX preference tests on style transfer.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683623","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683623","unsupervised learning;variational autoencoder;style transfer;speech synthesis","Spectrogram;Speech synthesis;Speech;Training;Interpolation;Mathematical model;Decoding","knowledge representation;speech synthesis;unsupervised learning","end-to-end speech synthesis model;style transfer;Global Style Token model;representation learning;style representation;variational autoencoder;speaking styles;unsupervised learning","","65","1","19","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Generative Neural Networks for Anomaly Detection in Crowded Scenes","T. Wang; M. Qiao; Z. Lin; C. Li; H. Snoussi; Z. Liu; C. Choi","School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Computing, Ulster University, Jordanstown, U.K.; College of Electrical and Information Engineering, Lanzhou University of Technology, Lanzhou, China; Institute Charles Delaunay-LM2S FRE CNRS 2019, University of Technology of Troyes, Troyes, France; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Computer Engineering and IT Research Institute, Chosun University, Gwangju, South Korea","IEEE Transactions on Information Forensics and Security","31 Jan 2019","2019","14","5","1390","1399","Security surveillance is critical to social harmony and people's peaceful life. It has a great impact on strengthening social stability and life safeguarding. Detecting anomaly timely, effectively and efficiently in video surveillance remains challenging. This paper proposes a new approach, called S2-VAE, for anomaly detection from video data. The S2-VAE consists of two proposed neural networks: a Stacked Fully Connected Variational AutoEncoder (SF-VAE) and a Skip Convolutional VAE (SC-VAE). The SF-VAE is a shallow generative network to obtain a model like Gaussian mixture to fit the distribution of the actual data. The SC-VAE, as a key component of S2-VAE, is a deep generative network to take advantages of CNN, VAE and skip connections. Both SF-VAE and SC-VAE are efficient and effective generative networks and they can achieve better performance for detecting both local abnormal events and global abnormal events. The proposed S2-VAE is evaluated using four public datasets. The experimental results show that the S2-VAE outperforms the state-of-the-art algorithms. The code is available publicly at https://github.com/tianwangbuaa/.","1556-6021","","10.1109/TIFS.2018.2878538","National Natural Science Foundation of China(grant numbers:61503017,U1435220,61866022,61802180); Aeronautical Science Foundation of China(grant numbers:2016ZC51022); SURECAP CPER Project; EU Horizon 2020 Research and Innovation Programme(grant numbers:690238); DESIREE Project; UK EPSRC(grant numbers:EP/P031668/1); BT Ireland Innovation Centre (BTIIC); Platform CAPSEC; Région Champagne-Ardenne and FEDER; National Research Foundation of Korea; Korea Government (Ministry of Science and ICT)(grant numbers:2017R1E1A1A01077913); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8513816","Spatio-temporal;anomaly detection;variational autoencoder;loss function","Convolutional neural networks;Feature extraction;Anomaly detection;Gaussian distribution;Guassian processes;Mixture models;Video surveillance","convolutional neural nets;Gaussian distribution;Gaussian processes;mixture models;video signal processing;video surveillance","generative neural networks;timely anomaly detection;skip convolutional VAE;crowded scenes;security surveillance;social harmony;social stability;life safeguarding;video surveillance;S2-VAE approach;video data;stacked fully connected variational autoencoder;shallow generative network;data distribution;Gaussian mixture;deep generative network;skip connections;abnormal events","","59","","48","IEEE","28 Oct 2018","","","IEEE","IEEE Journals"
"Deep Generative Endmember Modeling: An Application to Unsupervised Spectral Unmixing","R. A. Borsoi; T. Imbiriba; J. C. M. Bermudez","Lagrange Laboratory, Université Côte d’Azur, 06108 Nice, France; ECE Department, Northeastern University, Boston, MA, USA; Graduate Program on Electronic Engineering and Computing, Catholic University of Pelotas, Pelotas, Brazil","IEEE Transactions on Computational Imaging","3 Feb 2020","2020","6","","374","384","Endmember (EM) spectral variability can greatly impact the performance of standard hyperspectral image analysis algorithms. Extended parametric models have been successfully applied to account for the EM spectral variability. However, these models still lack the compromise between flexibility and lowdimensional representation that is necessary to properly explore the fact that spectral variability is often confined to a low-dimensional manifold in real scenes. In this article we propose to learn a spectral variability model directly from the observed data, instead of imposingitapriori. This is achieved through a deep generative EM model, which is estimated using a variational autoencoder (VAE). The encoder and decoder that compose the generative model are trained using pure pixel information extracted directly from the observed image, what allows for an unsupervised formulation. The proposed EM model is applied to the solution of a spectral unmixing problem, which we cast as an alternating nonlinear least-squares problem that is solved iteratively with respect to the abundances and to the low-dimensional representations of the EMs in the latent space of the deep generative model. Simulations using both synthetic and real data indicate that the proposed strategy can outperform the competing state-of-the-art algorithms.","2333-9403","","10.1109/TCI.2019.2948726","Conselho Nacional de Desenvolvimento Científico e Tecnológico(grant numbers:304250/2017-1,409044/2018-0,141271/2017-5,204991/2018-8); Brazilian Education Ministry(grant numbers:PNPD/1811213); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8878112","Hyperspectral data;endmember variability;generative models;deep neural networks;variational autoencoders (VAE);spectral unmixing","Computational modeling;Parametric statistics;Manifolds;Data models;Neural networks;Training data;Hyperspectral imaging","geophysical image processing;hyperspectral imaging;image representation;iterative methods;learning (artificial intelligence);least squares approximations;spectral analysis","unsupervised spectral unmixing;endmember spectral variability;standard hyperspectral image analysis algorithms;EM spectral variability;low-dimensional representation;low-dimensional manifold;spectral variability model;deep generative EM model;alternating nonlinear least-squares problem;low-dimensional representations;deep generative model;deep generative endmember modeling;variational autoencoder","","43","","60","IEEE","21 Oct 2019","","","IEEE","IEEE Journals"
"Adversarial Action Prediction Networks","Y. Kong; Z. Tao; Y. Fu","B. Thomas Golisano College of Computing and Information Sciences, Rochester Institute of Technology, Rochester; Department of ECE, Northeastern University, Boston, USA; Department of ECE and College of CIS, Northeastern University, Boston, USA","IEEE Transactions on Pattern Analysis and Machine Intelligence","6 Feb 2020","2020","42","3","539","553","Different from after-the-fact action recognition, action prediction task requires action labels to be predicted from partially observed videos containing incomplete action executions. It is challenging because these partial videos have insufficient discriminative information, and their temporal structure is damaged. We study this problem in this paper, and propose an efficient and powerful deep network for learning representative and discriminative features for action prediction. Our approach exploits abundant sequential context information in full videos to enrich the feature representations of partial videos. This information is encoded in latent representations using a variational autoencoder (VAE), which are encouraged to be progress-invariant. Decoding such latent representations using another VAE, we can reconstruct missing information in the features extracted from partial videos. An adversarial learning scheme is adopted to differentiate the reconstructed features from the features directly extracted from full videos in order to well align their distributions. A multi-class classifier is also used to encourage the features to be discriminative. Our network jointly learns features and classifiers, and generates the features particularly optimized for action prediction. Extensive experimental results on UCF101, Sports-1M and BIT datasets demonstrate that our approach remarkably outperforms state-of-the-art methods, and shows significant speedup over these methods. Results also show that actions differ in their prediction characteristics; some actions can be correctly predicted even though only the beginning 10% portion of videos is observed.","1939-3539","","10.1109/TPAMI.2018.2882805","NSF IIS(grant numbers:1651902); Army Research Office(grant numbers:W911NF-17-1-0367); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543243","Action prediction;action recognition;sequential context;variational autoencoder;adversarial learning","Videos;Feature extraction;Decoding;Accidents;Prediction methods;Training;Task analysis","feature extraction;image representation;learning (artificial intelligence);object recognition;video signal processing","after-the-fact action recognition;action prediction task;action labels;partially observed videos;incomplete action executions;partial videos;insufficient discriminative information;representative features;discriminative features;abundant sequential context information;feature representations;latent representations;VAE;adversarial learning scheme;reconstructed features;prediction characteristics;adversarial action prediction networks;deep network;variational autoencoder","","21","","50","IEEE","22 Nov 2018","","","IEEE","IEEE Journals"
"SRUN: Spectral Regularized Unsupervised Networks for Hyperspectral Target Detection","W. Xie; J. Yang; J. Lei; Y. Li; Q. Du; G. He","State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China; Department of Electronic and Computer Engineering, Mississippi State University, Starkville, USA; State Key Laboratory of Integrated Service Networks, Xidian University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","22 Jan 2020","2020","58","2","1463","1474","The high dimensionality of a hyperspectral image (HSI) provides the possibility of deeply capturing the underlying and intrinsic characteristics in spectra, such that targets embedded in the background can be detected. However, redundant information, deteriorated bands, and other interferences from background challenge the target detection problem. In this article, an effective feature extraction method based on unsupervised networks is proposed to mine intrinsic properties underlying HSIs. Our approach, called spectral regularized unsupervised networks (SRUN), imposes spectral regularization on autoencoder (AE) and variational AE (VAE) to emphasize spectral consistency, which is more suitable for characterizing spectral information of HSIs by hidden nodes than the original AE and VAE models. Then, we conduct a simple feature selection algorithm on the hidden nodes in the deepest code to select specific nodes that contain distinguishability between target and background, which is based on the spectral angular difference between a known target spectrum and spectra of other pixels in input. The selected nodes are further weighted adaptively to obtain a discriminative map depending on the observation that each selected node provides different contribution rates to target detection. Experimental results on several data sets illustrate that the proposed SRUN-based target detection algorithm is suitable for targets at the subpixel level and those with structural information.","1558-0644","","10.1109/TGRS.2019.2947033","National Natural Science Foundation of China(grant numbers:61801359,61571345,91538101,61501346,61502367,61701360); Young Talent Fund from the University Association for Science and Technology, Shaanxi, China(grant numbers:20190103); China Postdoctoral Science Foundation(grant numbers:2019T120878); Higher Education Discipline Innovation Project(grant numbers:B08038); Fundamental Research Funds for the Central Universities(grant numbers:JB180104); Natural Science Basic Research Plan in Shaanxi Province, China(grant numbers:2019JQ153,2016JQ6023,2016JQ6018); China Postdoctoral Science Foundation(grant numbers:2017M620440); Yangtse Rive Scholar Bonus Schemes(grant numbers:CJT160102); Ten Thousand Talent Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886704","Background suppression;hyperspectral target detection;spectral regularization;unsupervised feature learning;variational autoencoders (VAEs)","Feature extraction;Object detection;Hyperspectral imaging;Anomaly detection;Decoding;Aircraft","feature extraction;feature selection;geophysical image processing;geophysics computing;hyperspectral imaging;image segmentation;neural nets;object detection;unsupervised learning","hyperspectral target detection;feature extraction;feature selection algorithm;SRUN-based target detection algorithm;hyperspectral image dimensionality;spectral regularized unsupervised networks;autoencoder;variational AE","","19","","45","IEEE","30 Oct 2019","","","IEEE","IEEE Journals"
"Cardiac Segmentation With Strong Anatomical Guarantees","N. Painchaud; Y. Skandarani; T. Judge; O. Bernard; A. Lalande; P. -M. Jodoin","Department of Computer Science, University of Sherbrooke, Sherbrooke, QC, Canada; CASIS, Dijon, France; Department of Computer Science, University of Sherbrooke, Sherbrooke, QC, Canada; Univ Lyon, INSA-Lyon, Université Claude Bernard Lyon 1, UJM-Saint Etienne, CNRS, Inserm, CREATIS UMR 5220, U1206, Lyon, France; ImVIA Laboratory, University Bourgogne Franche-Comté, Dijon, France; Department of Computer Science, University of Sherbrooke, Sherbrooke, QC, Canada","IEEE Transactions on Medical Imaging","28 Oct 2020","2020","39","11","3703","3713","Convolutional neural networks (CNN) have had unprecedented success in medical imaging and, in particular, in medical image segmentation. However, despite the fact that segmentation results are closer than ever to the inter-expert variability, CNNs are not immune to producing anatomically inaccurate segmentations, even when built upon a shape prior. In this paper, we present a framework for producing cardiac image segmentation maps that are guaranteed to respect pre-defined anatomical criteria, while remaining within the inter-expert variability. The idea behind our method is to use a well-trained CNN, have it process cardiac images, identify the anatomically implausible results and warp these results toward the closest anatomically valid cardiac shape. This warping procedure is carried out with a constrained variational autoencoder (cVAE) trained to learn a representation of valid cardiac shapes through a smooth, yet constrained, latent space. With this cVAE, we can project any implausible shape into the cardiac latent space and steer it toward the closest correct shape. We tested our framework on short-axis MRI as well as apical two and four-chamber view ultrasound images, two modalities for which cardiac shapes are drastically different. With our method, CNNs can now produce results that are both within the inter-expert variability and always anatomically plausible without having to rely on a shape prior.","1558-254X","","10.1109/TMI.2020.3003240","NSERC Discovery Grants’ program; NSERC Canada Graduate Scholarships-Master’s program and a CIFRE grant (French National Association of Research and Technology) for CASIS(grant numbers:N 2017/1663); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9119450","CNN;variational autoencoder;cardiac segmentation;MRI;ultrasound","Shape;Image segmentation;Magnetic resonance imaging;Ultrasonic imaging;Three-dimensional displays;Neural networks","biomedical MRI;biomedical ultrasonics;cardiology;convolutional neural nets;image segmentation;medical image processing","convolutional neural networks;CNN;medical image segmentation;cardiac image segmentation maps;cardiac images;constrained variational autoencoder;cardiac latent space;four-chamber view ultrasound images;interexpert variability;cardiac shapes;short-axis MRI","Heart;Image Processing, Computer-Assisted;Magnetic Resonance Imaging;Neural Networks, Computer;Ultrasonography","19","","35","IEEE","17 Jun 2020","","","IEEE","IEEE Journals"
"Diagnosis Prediction via Medical Context Attention Networks Using Deep Generative Modeling","W. Lee; S. Park; W. Joo; I. -C. Moon","Department of Industrial and Systems Engineering, KAIST, Daejeon, South Korea; Department of Industrial and Systems Engineering, KAIST, Daejeon, South Korea; Department of Industrial and Systems Engineering, KAIST, Daejeon, South Korea; Department of Industrial and Systems Engineering, KAIST, Daejeon, South Korea","2018 IEEE International Conference on Data Mining (ICDM)","30 Dec 2018","2018","","","1104","1109","Predicting the clinical outcome of patients from the historical electronic health records (EHRs) is a fundamental research area in medical informatics. Although EHRs contain various records associated with each patient, the existing work mainly dealt with the diagnosis codes by employing recurrent neural networks (RNNs) with a simple attention mechanism. This type of sequence modeling often ignores the heterogeneity of EHRs. In other words, it only considers historical diagnoses and does not incorporate patient demographics, which correspond to clinically essential context, into the sequence modeling. To address the issue, we aim at investigating the use of an attention mechanism that is tailored to medical context to predict a future diagnosis. We propose a medical context attention (MCA)-based RNN that is composed of an attention-based RNN and a conditional deep generative model. The novel attention mechanism utilizes the derived individual patient information from conditional variational autoencoders (CVAEs). The CVAE models a conditional distribution of patient embeddings and his/her demographics to provide the measurement of patient's phenotypic difference due to illness. Experimental results showed the effectiveness of the proposed model.","2374-8486","978-1-5386-9159-5","10.1109/ICDM.2018.00143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594952","sequential diagnosis prediction;healthcare informatics;recurrent neural networks;variational autoencoders;attention mechanism","Medical diagnostic imaging;Context modeling;Medical services;Sequential diagnosis;Predictive models;Computer architecture","electronic health records;health care;medical information systems;patient care;patient diagnosis;recurrent neural nets","sequence modeling;EHRs;historical diagnoses;medical context attention-based RNN;conditional deep generative model;derived individual patient information;conditional variational autoencoders;CVAE models;diagnosis prediction;medical context attention networks;deep generative modeling;historical electronic health records;medical informatics;diagnosis codes;recurrent neural networks;attention mechanism;patient demographics","","14","","21","","30 Dec 2018","","","IEEE","IEEE Conferences"
"A Semi-Supervised and Incremental Modeling Framework for Wafer Map Classification","Y. Kong; D. Ni","College of Control Science and Engineering, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China","IEEE Transactions on Semiconductor Manufacturing","3 Feb 2020","2020","33","1","62","71","Wafer map analysis provides critical information for quality control and yield improvement tasks in semiconductor manufacturing. In particular, wafer patterns of gross failing areas (GFA) are important clues to identify the causes of relevant failures during the manufacturing process. In this work, a semi-supervised classification framework is proposed for wafer map analysis, and its application to wafer bin maps with GFA patterns classification is demonstrated. The Ladder network and the semi-supervised variational autoencoder are adopted to classify wafer bin maps in comparison with a standard convolutional neural network (CNN) model on two real-world datasets. The results have illustrated that two semi-supervised models are consistently and substantially better than the CNN model across various training data percentages by effective utilization of the unlabeled data. Active learning and pseudo labeling are also utilized to accelerate the learning curve.","1558-2345","","10.1109/TSM.2020.2964581","National Natural Science Foundation of China(grant numbers:U1609213,61473287); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951123","Wafer map;semi-supervised classification;ladder network;variational autoencoder;semiconductor manufacturing","Semiconductor device modeling;Decoding;Unsupervised learning;Noise reduction;Feature extraction;Manufacturing;Acceleration","convolutional neural nets;electronic engineering computing;manufacturing processes;pattern classification;production engineering computing;quality control;semiconductor device manufacture;semiconductor technology;supervised learning","semiconductor manufacturing;wafer patterns;manufacturing process;semisupervised classification framework;wafer map analysis;wafer bin maps;GFA;semisupervised variational autoencoder;convolutional neural network;semisupervised models;CNN;incremental modeling;wafer map classification;gross failing areas;patterns classification;active learning;pseudo labeling","","14","","44","IEEE","7 Jan 2020","","","IEEE","IEEE Journals"
"Intelligent Condition-Based Monitoring of Rotary Machines With Few Samples","S. Dixit; N. K. Verma","Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India; Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India","IEEE Sensors Journal","5 Nov 2020","2020","20","23","14337","14346","Recently, intelligent condition based monitoring systems build on deep learning methods have gained popularity. The success of these methods relies upon the large labeled training datasets, which are crucial to collect in industries. Therefore, building an effective fault diagnosis system becomes challenging. In this paper, a novel fault diagnosis framework is proposed to tackle the issue of limited samples in the training dataset. In the proposed framework, firstly, new training samples termed as synthetic samples are generated to increase the size of the dataset. After that, both original and synthetic samples are stacked, and the classifier model is trained. This study proposes a modified Conditional Variational Autoencoder (CVAE) to generate synthetic samples. In the proposed CVAE, centroid loss is added to the standard CVAE objective function. This loss directs generated samples to remain close with the centroid of their respective class, which helps in generating synthetic samples quite similar to the original samples. This paper also investigates the performance of proposed model in the presence of noise and effect of transformed data and original data. To verify the effectiveness of the proposed approach, the Air compressor and Case Western Reserve University datasets have been investigated. For the CWRU dataset with only 80 samples, accuracy of 96.39%, 99.58%, 98.33% was obtained using multilayer neural network, support vector machine, and RF classifiers respectively. Classification accuracy increased to 63.33% when modified CVAE is used instead of standard CVAE. Finally, a comparative analysis between proposed methods and other state-of-the-art methods has been presented.","1558-1748","","10.1109/JSEN.2020.3008177","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9137139","Sensor data,conditional variational autoencoder;condition based monitoring;synthetic data","Rotsting machines;Fault diagnosis;Intelligent sensors;Condition monitoring","condition monitoring;fault diagnosis;mechanical engineering computing;neural nets;pattern classification;random forests;support vector machines","intelligent condition based monitoring systems;deep learning;fault diagnosis;conditional variational autoencoder;rotary machines;multilayer neural network;support vector machine;RF classifiers","","11","","40","IEEE","9 Jul 2020","","","IEEE","IEEE Journals"
"Learning Representations from Healthcare Time Series Data for Unsupervised Anomaly Detection","J. Pereira; M. Silveira","Instituto Superior Técnico, University of Lisbon, Lisbon, Portugal; Institute for Systems and Robotics, University of Lisbon, Lisbon, Portugal","2019 IEEE International Conference on Big Data and Smart Computing (BigComp)","4 Apr 2019","2019","","","1","7","The amount of time series data generated in Healthcare is growing very fast and so is the need for methods that can analyse these data, detect anomalies and provide meaningful insights. However, most of the data available is unlabelled and, therefore, anomaly detection in this scenario has been a great challenge for researchers and practitioners. Recently, unsupervised representation learning with deep generative models has been applied to find representations of data, without the need for big labelled datasets. Motivated by their success, we propose an unsupervised framework for anomaly detection in time series data. In our method, both representation learning and anomaly detection are fully unsupervised. In addition, the training data may contain anomalous data. We first learn representations of time series using a Variational Recurrent Autoencoder. Afterwards, based on those representations, we detect anomalous time series using Clustering and the Wasserstein distance. Our results on the publicly available ECG5000 electrocardiogram dataset show the ability of the proposed approach to detect anomalous heartbeats in a fully unsupervised fashion, while providing structured and expressive data representations. Furthermore, our approach outperforms previous supervised and unsupervised methods on this dataset.","2375-9356","978-1-5386-7789-6","10.1109/BIGCOMP.2019.8679157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8679157","Variational Recurrent Autoencoder;Representation Learning;Clustering;Electrocardiogram","Time series analysis;Anomaly detection;Recurrent neural networks;Decoding;Mathematical model;Data models","data structures;electrocardiography;health care;medical computing;pattern clustering;recurrent neural nets;time series;unsupervised learning","healthcare time series data;unsupervised anomaly detection;deep generative models;unsupervised framework;training data;anomalous data;anomalous time series;structured data representations;expressive data representations;unsupervised methods;supervised methods;ECG5000 electrocardiogram dataset;data analysis;unsupervised representation learning;variational recurrent autoencoder;Wasserstein distance;clustering;anomalous heartbeat detection","","11","","34","","4 Apr 2019","","","IEEE","IEEE Conferences"
"Extracting Domain Invariant Features by Unsupervised Learning for Robust Automatic Speech Recognition","W. -N. Hsu; J. Glass","MIT Computer Science and Artificial Intelligence Laboratory Cambridge, MA, USA; MIT Computer Science and Artificial Intelligence Laboratory Cambridge, MA, USA","2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 Sep 2018","2018","","","5614","5618","The performance of automatic speech recognition (ASR) systems can be significantly compromised by previously unseen conditions, which is typically due to a mismatch between training and testing distributions. In this paper, we address robustness by studying domain invariant features, such that domain information becomes transparent to ASR systems, resolving the mismatch problem. Specifically, we investigate a recent model, called the Factorized Hierarchical Variational Autoencoder (FHVAE). FHVAEs learn to factorize sequence-level and segment-level attributes into different latent variables without supervision. We argue that the set of latent variables that contain segment -level information is our desired domain invariant feature for ASR. Experiments are conducted on Aurora-4 and CHiME-4, which demonstrate 41 % and 27% absolute word error rate reductions respectively on mismatched domains.","2379-190X","978-1-5386-4658-8","10.1109/ICASSP.2018.8462037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8462037","robust speech recognition;factorized hierarchical variational autoencoder;domain invariant representations","Training;Feature extraction;Noise measurement;Hidden Markov models;Robustness;Testing;Acoustics","feature extraction;speech coding;speech recognition;unsupervised learning","mismatched domains;unsupervised learning;robust automatic speech recognition;automatic speech recognition systems;ASR systems;Factorized Hierarchical Variational Autoencoder;FHVAE;domain invariant feature extraction","","10","","27","","13 Sep 2018","","","IEEE","IEEE Conferences"
"Graph-Deep-Learning-Based Inference of Fine-Grained Air Quality From Mobile IoT Sensors","T. H. Do; E. Tsiligianni; X. Qin; J. Hofman; V. P. La Manna; W. Philips; N. Deligiannis","imec, Leuven, Belgium; imec, Leuven, Belgium; Department of Telecommunications and Information Processing, Ghent University, Ghent, Belgium; imec, Eindhoven, The Netherlands; imec, Eindhoven, The Netherlands; Department of Telecommunications and Information Processing, Ghent University, Ghent, Belgium; imec, Leuven, Belgium","IEEE Internet of Things Journal","15 Sep 2020","2020","7","9","8943","8955","Internet-of-Things (IoT) technologies incorporate a large number of different sensing devices and communication technologies to collect a large amount of data for various applications. Smart cities employ IoT infrastructures to build services useful for the administration of the city and the citizens. In this article, we present an IoT pipeline for acquisition, processing, and visualization of air pollution data over the city of Antwerp, Belgium. Our system employs IoT devices mounted on vehicles as well as static reference stations to measure a variety of city parameters, such as humidity, temperature, and air pollution. Mobile measurements cover a larger area compared to static stations; however, there is a tradeoff between temporal and spatial resolution. We address this problem as a matrix completion on graphs problem and rely on variational graph autoencoders to propose a deep learning solution for the estimation of the unknown air pollution values. Our model is extended to capture the correlation among different air pollutants, leading to improved estimation. We conduct experiments at different spatial and temporal resolution and compare with state-of-the-art methods to show the efficiency of our approach. The observed and estimated air pollution values can be accessed by interested users through a Web visualization tool designed to provide an air pollution map of the city of Antwerp.","2327-4662","","10.1109/JIOT.2020.2999446","imec; VUB SRP Project(grant numbers:M3D2); FWO; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9106368","Deep learning;Internet of Things (IoT);smart cities;variational graph autoencoder (VGAE)","Atmospheric measurements;Pollution measurement;Sensors;Air pollution;Atmospheric modeling;Internet of Things","air pollution measurement;air quality;data visualisation;environmental science computing;Internet of Things;learning (artificial intelligence);neural nets","graph-deep-learning-based inference;fine-grained air quality;mobile IoT sensors;Internet-of-Things technologies;sensing devices;communication technologies;smart cities;IoT pipeline;air pollution data;Antwerp;IoT devices;static reference stations;city parameters;mobile measurements;static stations;temporal resolution;spatial resolution;graphs problem;variational graph autoencoders;deep learning solution;air pollutants;air pollution values;Web visualization tool;air pollution map","","10","","61","IEEE","2 Jun 2020","","","IEEE","IEEE Journals"
"Multimodal Learning of Social Image Representation by Exploiting Social Relations","F. Huang; X. Zhang; J. Xu; Z. Zhao; Z. Li","Guangdong Key Laboratory of Data Security and Privacy Preserving, Jinan University, Guangzhou, China; School of Cyber Science and Technology, Beihang University, Beijing, China; Beijing Key Laboratory of Network Technology, Beihang University, Beijing, China; Information Center, National Computer Emergency Technical Team/Coordination Center of China, Beijing, China; Beijing Key Laboratory of Network Technology, Beihang University, Beijing, China","IEEE Transactions on Cybernetics","17 Feb 2021","2021","51","3","1506","1518","Learning the representation for social images has recently made remarkable achievements for many tasks, such as cross-modal retrieval and multilabel classification. However, since social images contain both multimodal contents (e.g., visual images and textual descriptions) and social relations among images, simply modeling the content information may lead to suboptimal embedding. In this paper, we propose a novel multimodal representation learning model for social images, that is, correlational multimodal variational autoencoder (CMVAE) via triplet network. Specifically, in order to mine the highly nonlinear correlation between the visual content and the textual content, a CMVAE is proposed to learn a unified representation for the multiple modalities of social images. Both common information in all modalities and private information in each modality are encoded for the representation learning. To incorporate the social relations among images, we employ the triplet network to embed multiple types of social links in the representation learning. Then, a joint embedding model is proposed to combine the social relations for representation learning of the multimodal contents. Comprehensive experiment results on four datasets confirm the effectiveness of our method in two tasks, namely, multilabel classification and cross-modal retrieval. Our method outperforms the state-of-the-art multimodal representation learning methods with significant improvement of performance.","2168-2275","","10.1109/TCYB.2019.2896100","National Natural Science Foundation of China(grant numbers:U1636211); Beijing Natural Science Foundation of China(grant numbers:4182037); National Key Research and Development Plan of China(grant numbers:2017YFB0802203); Guangdong Provincial Special Funds for Applied Technology Research and Development and Transformation of Important Scientific and Technological Achieve(grant numbers:2017B010124002); Guangdong Key Laboratory of Data Security and Privacy Preserving(grant numbers:2017B030301004); Natural Science Foundation of Guangdong Province, China(grant numbers:2017A030313334); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8661755","Multimodal;social image;triplet network;variational autoencoder (VAE)","Learning systems;Correlation;Visualization;Social networking (online);Task analysis;Image edge detection;Cybernetics","image representation;information retrieval;learning (artificial intelligence);pattern classification;social networking (online)","multimodal learning;social image representation;social relations;social images;cross-modal retrieval;multimodal contents;visual images;novel multimodal representation;correlational multimodal variational autoencoder;representation learning;social links;state-of-the-art multimodal representation","Algorithms;Animals;Data Mining;Humans;Image Processing, Computer-Assisted;Machine Learning;Semantics;Social Interaction;Social Media","10","","55","IEEE","6 Mar 2019","","","IEEE","IEEE Journals"
"Anomaly Detection in Video Data Based on Probabilistic Latent Space Models","G. Slavic; D. Campo; M. Baydoun; P. Marin; D. Martin; L. Marcenaro; C. Regazzoni","DITEN, University of Genova, Italy; DITEN, University of Genova, Italy; DITEN, University of Genova, Italy; Intelligent systems lab, University Carlos III de Madrid, Spain; Intelligent systems lab, University Carlos III de Madrid, Spain; DITEN, University of Genova, Italy; DITEN, University of Genova, Italy","2020 IEEE Conference on Evolving and Adaptive Intelligent Systems (EAIS)","23 Jun 2020","2020","","","1","8","This paper proposes a method for detecting anomalies in video data. A Variational Autoencoder (VAE) is used for reducing the dimensionality of video frames, generating latent space information that is comparable to low-dimensional sensory data (e.g., positioning, steering angle), making feasible the development of a consistent multi-modal architecture for autonomous vehicles. An Adapted Markov Jump Particle Filter defined by discrete and continuous inference levels is employed to predict the following frames and detecting anomalies in new video sequences. Our method is evaluated on different video scenarios where a semi-autonomous vehicle performs a set of tasks in a closed environment.","2473-4691","978-1-7281-4384-2","10.1109/EAIS48028.2020.9122766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9122766","Variational autoencoder;anomaly detection;particle filtering;Kalman filtering","","image sequences;Markov processes;mobile robots;neural nets;object detection;particle filtering (numerical methods);probability;robot vision;security of data;vehicles;video signal processing","anomaly detection;video data;probabilistic latent space models;Variational Autoencoder;video frames;multimodal architecture;Adapted Markov Jump Particle Filter;discrete inference levels;continuous inference levels;video sequences;semiautonomous vehicle;autonomous vehicles;latent space information generation","","9","","36","","23 Jun 2020","","","IEEE","IEEE Conferences"
"A Flow-Based Deep Latent Variable Model for Speech Spectrogram Modeling and Enhancement","A. A. Nugraha; K. Sekiguchi; K. Yoshii","Center for Advanced Intelligence Project (AIP), RIKEN, Tokyo, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20 Apr 2020","2020","28","","1104","1117","This article describes a deep latent variable model of speech power spectrograms and its application to semi-supervised speech enhancement with a deep speech prior. By integrating two major deep generative models, a variational autoencoder (VAE) and a normalizing flow (NF), in a mutually-beneficial manner, we formulate a flexible latent variable model called the NF-VAE that can extract low-dimensional latent representations from high-dimensional observations, akin to the VAE, and does not need to explicitly represent the distribution of the observations, akin to the NF. In this article, we consider a variant of NF called the generative flow (GF a.k.a. Glow) and formulate a latent variable model called the GF-VAE. We experimentally show that the proposed GF-VAE is better than the standard VAE at capturing fine-structured harmonics of speech spectrograms, especially in the high-frequency range. A similar finding is also obtained when the GF-VAE and the VAE are used to generate speech spectrograms from latent variables randomly sampled from the standard Gaussian distribution. Lastly, when these models are used as speech priors for statistical multichannel speech enhancement, the GF-VAE outperforms the VAE and the GF.","2329-9304","","10.1109/TASLP.2020.2979603","JSPS KAKENHI(grant numbers:19H04137); NII CRIS-Line Collaborative Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9028147","Deep generative model;variational autoencoder (VAE);normalizing flow (NF);power spectrogram;speech enhancement","Speech enhancement;Noise measurement;Spectrogram;Decoding;Computational modeling;Gaussian distribution","Gaussian distribution;neural nets;speech enhancement;supervised learning","deep generative models;normalizing flow;NF-VAE;low-dimensional latent representations;high-dimensional observations;GF-VAE;statistical multichannel speech enhancement;flow-based deep latent variable model;speech spectrogram modeling;speech power spectrograms;semisupervised speech enhancement;variational autoencoder;standard Gaussian distribution","","6","","63","IEEE","9 Mar 2020","","","IEEE","IEEE Journals"
"ContainerGuard: A Real-Time Attack Detection System in Container-Based Big Data Platform","Y. Wang; Q. Wang; X. Chen; D. Chen; X. Fang; M. Yin; N. Zhang","School of Cyber Science and Engineering, Sichuan University, Chengdu, China; School of Cyber Science and Engineering, Sichuan University, Chengdu, China; School of Cyber Science and Engineering, Sichuan University, Chengdu, China; Peng Cheng Laboratory, Shenzhen, China; Department of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; Institute of Computer Application, China Academy of Engineering Physics, Mianyang, China; Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada","IEEE Transactions on Industrial Informatics","3 Feb 2022","2022","18","5","3327","3336","As a lightweight, flexible, and high-performance operating system virtualization, containers are used to speed up the big data platform. However, due to the imperfection of the resource isolation mechanism and the property of shared kernel, the meltdown and spectre attacks can lead to information leakage of kernel space and coresident containers. In this article, a noise-resilient and real-time detection system, named ContainerGuard, is proposed to detect meltdown and spectre attacks in the container-based big data platform. ContainerGuard uses a nonintrusive manner to collect lifecycle multivariate time-series performance event data of processes in containers and then uses ensemble of variational autoencoders as generative neural networks to learn the robust representations of normal patterns. Therefore, ContainerGuard meets the urgent need for information protection in the container-based big data platform. Our evaluations using real-world datasets show that ContainerGuard achieves excellent detection performance and only introduces about 4.5% of running performance overhead to the platform.","1941-0050","","10.1109/TII.2020.3047416","National Natural Science Foundation of China(grant numbers:U19A2081,61872059,61502085); The Verification Platform of Multi-tier Coverage Communication Network for Oceans(grant numbers:LZC0020); Fundamental Research Funds for the Central Universities(grant numbers:2019SCU12069,SCU2020D038); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9309057","Anomaly detection;big data platform security;container;meltdown and spectre;variational autoencoder (VAE)","Containers;Big Data;Process control;Side-channel attacks;Kernel;Security;Hardware","Big Data;learning (artificial intelligence);neural nets;security of data;time series","ContainerGuard;real-time attack detection system;container-based big data platform;lightweight performance operating system virtualization;high-performance operating system virtualization;meltdown;spectre attacks;kernel space;coresident containers;real-time detection system;flexible performance operating system virtualization;resource isolation mechanism;shared kernel;nonintrusive manner;lifecycle multivariate time-series performance event data;variational autoencoders;generative neural networks;nformation protection","","6","","37","IEEE","25 Dec 2020","","","IEEE","IEEE Journals"
"Data Augmentation with Generative Models for Improved Malware Detection: A Comparative Study","R. Burks; K. A. Islam; Y. Lu; J. Li","Department of MCS, Samford University, Birmingham, AL; Department of ECE, Old Dominion University, Norfolk, VA; Department of ECE, Old Dominion University, Norfolk, VA; Department of CMSE, Old Dominion University, Norfolk, VA","2019 IEEE 10th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)","13 Feb 2020","2019","","","0660","0665","Generative Models have been very accommodating when it comes to generating artificial data. Two of the most popular and promising models are the Generative Adversarial Network (GAN) and Variational Autoencoder (VAE) models. They both play critical roles in classification problems by generating synthetic data to train classifier more accurately. Malware detection is the process of determining whether or not software is malicious on the host's system and diagnosing what type of attack it is. Without adequate amount of training data, it makes malware detection less efficient. In this paper, we compare the two generative models to generate synthetic training data to boost the Residual Network (ResNet-18) classifier for malware detection. Experiment results show that adding synthetic malware samples generated by VAE to the training data improved the accuracy of ResNet-18 by 2% as it compared to 6% by GAN.","","978-1-7281-3885-5","10.1109/UEMCON47517.2019.8993085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8993085","Variational Autoencoders;Generative Adversarial Networks;Deep Residual Networks;Deep Learning;CNN","Deep learning;Training data;Tools;Generative adversarial networks;Mobile communication;Malware;Data models","invasive software;learning (artificial intelligence);pattern classification","data augmentation;generative models;improved malware detection;artificial data;popular models;synthetic data;synthetic training data;synthetic malware samples;GAN;generative adversarial network;variational autoencoder;malware detection;ResNet-18;VAE","","5","","8","","13 Feb 2020","","","IEEE","IEEE Conferences"
"Improving the Performance of Just-In-Time Learning-Based Soft Sensor Through Data Augmentation","X. Jiang; Z. Ge","State Key Laboratory of Industrial Control Technology, Institute of Industrial Process Control, College of Control Science and Engineering, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Industrial Process Control, College of Control Science and Engineering, Zhejiang University, Hangzhou, China","IEEE Transactions on Industrial Electronics","12 Jul 2022","2022","69","12","13716","13726","Just-in-time learning (JITL) is a widely used method for online soft sensing. The limitation of available data and the increase of sample dimensions will make the historical dataset sparse, seriously impair the reliability and usability of JITL applications in the industry. To this end, data augmentation technology (DA) is introduced into the JITL framework for the first time to improve the performance of JITL-based soft sensors. In this article, a novel causality-informed variational autoencoder (CIVAE) is developed to generate virtual samples to augment the historical dataset. Based on this, a complete framework of data augmentation just-in-time learning (DA-JITL) is formulated offline and online and implemented with two different strategies. Finally, a numeral example and an actual industrial example are applied to verify the effectiveness of the proposed method. Besides, the effect of virtual data on JITL and the influence of virtual data volume, virtual data ratio and other factors are carefully discussed on the proposed method. In the industrial case, two indicators (rmse and R2) of the proposed method have been improved by an average of 25% and 17%, respectively, compared to the traditional JITL approach.","1557-9948","","10.1109/TIE.2021.3139194","National Natural Science Foundation of China(grant numbers:92167106,62103362,62003300); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9673119","Causality-informed variational autoencoder (CIVAE);data augmentation (DA);just-in-time learning (JITL);soft sensor","Data models;Predictive models;Soft sensors;Generators;Decoding;Data integration;Aerospace electronics","data handling;just-in-time;learning (artificial intelligence);neural nets;production engineering computing;soft sensors","Just-In-Time Learning-Based Soft Sensor;online soft sensing;sample dimensions;historical dataset sparse;reliability;JITL applications;data augmentation technology;JITL framework;JITL-based soft sensors;novel causality-informed variational autoencoder;virtual samples;DA-JITL;actual industrial example;virtual data volume;virtual data ratio;industrial case;CIVAE","","4","","27","IEEE","6 Jan 2022","","","IEEE","IEEE Journals"
"Deep Learning Based Unsupervised and Semi-supervised Classification for Keratoconus","N. Hallett; K. Yi; J. Dick; C. Hodge; G. Sutton; Y. Guang Wang; J. You","The Sydney Eye Hospital, The University of Sydney, Sydney, Australia; School of Mathematics and Statistics, The University of New South Wales, Sydney, Australia; School of Mathematics and Statistics, The University of New South Wales, Sydney, Australia; The Sydney Eye Hospital, The University of Sydney, Sydney, Australia; The Sydney Eye Hospital, The University of Sydney, Sydney, Australia; School of Mathematics and Statistics, The University of New South Wales, Sydney, Australia; The Sydney Eye Hospital, The University of Sydney, Sydney, Australia","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","7","The transparent cornea is the window of the eye, facilitating the entry of light rays and controlling focusing the movement of the light within the eye. The cornea is critical, contributing to 75% of the refractive power of the eye. Keratoconus is a progressive and multifactorial corneal degenerative disease affecting 1 in 2000 individuals worldwide. Currently, there is no cure for keratoconus other than corneal transplantation for advanced stage keratoconus or corneal cross-linking, which can only halt KC progression. The ability to accurately identify subtle KC or KC progression is of vital clinical significance. To date, there has been little consensus on a useful model to classify KC patients, which therefore inhibits the ability to predict disease progression accurately.In this paper, we utilised machine learning to analyse data from 124 KC patients, including topographical and clinical variables. Both supervised multilayer perceptron and unsupervised variational autoencoder models were used to classify KC patients with reference to the existing Amsler-Krumeich (A-K) classification system. Both methods result in high accuracy, with the unsupervised method showing better performance. The result showed that the unsupervised method with a selection of 29 variables could be a powerful tool to provide an automatic classification tool for clinicians. These outcomes provide a platform for additional analysis for the progression and treatment of keratoconus.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9206694","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206694","Variational Autoencoder;Multilayer Perceptron;Cornea;Keratoconus;Bayesian Neural Networks;Clustering;Deep Learning;Semi-supervised Learning;Dimensionality Reduction;Diagnosis;Amsler-Krumeich Classification","Machine learning;Diseases;Indexes;Australia;Medical diagnostic imaging;Cornea","biomedical optical imaging;diseases;eye;image classification;learning (artificial intelligence);medical image processing;multilayer perceptrons;optical tomography;patient treatment;supervised learning","multifactorial corneal degenerative disease;corneal transplantation;advanced stage keratoconus;corneal cross-linking;KC progression;disease progression;topographical variables;clinical variables;supervised multilayer perceptron;unsupervised variational autoencoder models;automatic classification tool;Amsler-Krumeich classification system;progressive corneal degenerative disease;refractive power;light rays;eye;transparent cornea;semisupervised classification","","4","","24","","28 Sep 2020","","","IEEE","IEEE Conferences"
"Cauchy Multichannel Speech Enhancement with a Deep Speech Prior","M. Fontaine; A. A. Nugraha; R. Badeau; K. Yoshii; A. Liutkus","Université de Lorraine, CNRS, Inria, LORIA, Nancy, France; AIP, RIKEN, Tokyo, Japan; LTCI, Téelécom ParisTech, Université Paris-Saclay, Paris, France; AIP, RIKEN, Tokyo, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan","2019 27th European Signal Processing Conference (EUSIPCO)","18 Nov 2019","2019","","","1","5","We propose a semi-supervised multichannel speech enhancement system based on a probabilistic model which assumes that both speech and noise follow the heavy-tailed multi-variate complex Cauchy distribution. As we advocate, this allows handling strong and adverse noisy conditions. Consequently, the model is parameterized by the source magnitude spectrograms and the source spatial scatter matrices. To deal with the non-additivity of scatter matrices, our first contribution is to perform the enhancement on a projected space. Then, our second contribution is to combine a latent variable model for speech, which is trained by following the variational autoencoder framework, with a low-rank model for the noise source. At test time, an iterative inference algorithm is applied, which produces estimated parameters to use for separation. The speech latent variables are estimated first from the noisy speech and then updated by a gradient descent method, while a majoriation-equalization strategy is used to update both the noise and the spatial parameters of both sources. Our experimental results show that the Cauchy model outperforms the state-of-art methods. The standard deviation scores also reveal that the proposed method is more robust against non-stationary noise.","2076-1465","978-9-0827-9703-9","10.23919/EUSIPCO.2019.8903091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903091","Multichannel speech enhancement;multivariate complex Cauchy distribution;variational autoencoder;nonnegative matrix factorization","Speech enhancement;Computational modeling;Spectrogram;Decoding;Probabilistic logic;Noise measurement;Training","gradient methods;inference mechanisms;learning (artificial intelligence);matrix algebra;speech enhancement;statistical distributions","latent variable model;variational autoencoder framework;low-rank model;noise source;iterative inference algorithm;speech latent variables;noisy speech;nonstationary noise;Cauchy multichannel speech enhancement;semisupervised multichannel speech enhancement;probabilistic model;source magnitude spectrograms;source spatial scatter matrices;heavy-tailed multivariate complex Cauchy distribution;gradient descent method;majoriation-equalization strategy;standard deviation scores","","3","","38","","18 Nov 2019","","","IEEE","IEEE Conferences"
"Deep Demixing: Reconstructing the Evolution of Epidemics using Graph Neural Networks","G. Čutura; B. Li; A. Swami; S. Segarra","University of Belgrade, Serbia; Rice University, USA; US Army Research Laboratory, USA; Rice University, USA","2021 29th European Signal Processing Conference (EUSIPCO)","8 Dec 2021","2021","","","2204","2208","We study the temporal reconstruction of epidemics evolving over networks. Given partial or aggregated temporal information of the epidemic, our goal is to estimate the complete evolution of the spread leveraging the topology of the network but being agnostic to the precise epidemic model. We overcome this lack of model awareness through a data-driven solution to the inverse problem at hand. In particular, we propose DDmix, a graph conditional variational autoencoder that can be trained from past epidemic spreads and whose latent space seeks to capture key aspects of the underlying (unknown) spreading dynamics. We illustrate the accuracy and generalizability of DDmix and compare it with non-graph-aware learning algorithms through numerical experiments on epidemic spreads simulated on synthetic and real-world networks.","2076-1465","978-9-0827-9706-0","10.23919/EUSIPCO54536.2021.9616110","Army Research Office(grant numbers:W911NF-19-2-0269); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616110","Network;inverse problem;epidemics;graph neural network;variational autoencoder","Epidemics;Network topology;Inverse problems;Heuristic algorithms;Signal processing algorithms;Europe;Signal processing","complex networks;data handling;epidemics;graph theory;inverse problems;learning (artificial intelligence);neural nets","deep demixing;graph neural networks;given partial information;aggregated temporal information;complete evolution;precise epidemic model;model awareness;data-driven solution;inverse problem;DDmix;graph conditional variational autoencoder;epidemic spreads;underlying spreading dynamics;nongraph-aware learning algorithms;real-world networks","","3","","29","","8 Dec 2021","","","IEEE","IEEE Conferences"
"Missing Data Imputation on IoT Sensor Networks: Implications for on-Site Sensor Calibration","N. U. Okafor; D. T. Delaney","Federal Polytechnic, Nekede, Nigeria; School of Electrical and Electronic Engineering, University College Dublin, Dublin 4, Ireland","IEEE Sensors Journal","19 Oct 2021","2021","21","20","22833","22845","IoT sensors are becoming increasingly important supplement to traditional monitoring systems, particularly for in-situ based monitoring. Data collected using IoT sensors are often plagued with missing values occurring as a result of sensor faults, network failures, drifts and other operational issues. Missing data can have substantial impact on in-field sensor calibration methods. The goal of this research is to achieve effective calibration of sensors in the context of such missing data. To this end, two objectives are presented in this paper. 1) Identify and examine effective imputation strategy for missing data in IoT sensors. 2) Determine sensor calibration performance using calibration techniques on data set with imputed values. Specifically, this paper examines the performance of Variational Autoencoder (VAE), Neural Network with Random Weights (NNRW), Multiple Imputation by Chain Equations (MICE), Random Forest-based Imputation (missForest) and K-Nearest Neighbour (KNN) for imputation of missing values on IoT sensors. Furthermore, the performance of sensor calibration via different supervised algorithms trained on the imputed dataset were evaluated. The analysis showed VAE technique to outperform the other methods in imputing the missing values at different proportions of missingness on two real-world datasets. Experimental results also showed improved calibration performance with imputed dataset.","1558-1748","","10.1109/JSEN.2021.3105442","Schlumberger Foundation through the Faculty for the Future Program; Tertiary Education Trust Fund (TETFUND-Nigeria); SmartBOG Project through the Environmental Protection Agency (EPA) Research Program(grant numbers:2014-202042617/03); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9518376","Calibration;imputation;Internet of Things (IoT);missing data;neural network;regression;sensors;variational autoencoder;XGBoost","Sensors;Calibration;Artificial neural networks;Mice;Task analysis;Sensor phenomena and characterization;Measurement uncertainty","calibration;data analysis;Internet of Things;nearest neighbour methods;neural nets;random forests;sensors;supervised learning","missing data imputation;IoT sensor networks;on-site sensor calibration;sensor faults;in-field sensor calibration methods;imputed values;imputed dataset;calibration performance;variational autoencoder;neural network with random weights;multiple imputation by chain equations;random forest-based imputation;k-nearest neighbour;supervised algorithms;in-situ based monitoring","","3","","72","CCBY","19 Aug 2021","","","IEEE","IEEE Journals"
"A Study of Inductive Biases for Unsupervised Speech Representation Learning","G. Boulianne","École de technologie supérieure (ÉTS), Montréal, Qc, Canada","IEEE/ACM Transactions on Audio, Speech, and Language Processing","27 Oct 2020","2020","28","","2781","2795","Distributed representations, or embeddings, are commonly learned without supervision on very large unannotated corpora for natural language processing. In speech processing, deep network-based representations such as bottlenecks and x-vectors have had some success,but are limited to supervised or partly supervised settings where annotations are available and are not optimized to separate underlying factors. Here, we propose a generative model with deep encoders and decoders that can learn interpretable speech representations without supervision. Our inductive biases operate as prior distributions in a variational autoencoder model and allow us to separate several latent variables along a continuous range of time-scale properties, as opposed to binary oppositions or hierarchical factorization that have been previously proposed. On simulated data, we confirm that these biases enable the model to accurately recover phonetic and speaker underlying factors. On TIMIT and LibriSpeech, they yield representations that separate phonetic and speaker information, as evidenced by unsupervised results on downstream phoneme and speaker classification tasks using a simple k-means classifier.","2329-9304","","10.1109/TASLP.2020.3030494","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222229","Unsupervised;speech representation;representation learning;variational autoencoder","Speech processing;Phonetics;Task analysis;Speech recognition;Neural networks;Decoding","natural language processing;neural nets;pattern classification;speaker recognition;unsupervised learning","inductive biases;unsupervised speech representation learning;distributed representations;unannotated corpora;natural language processing;speech processing;deep network-based representations;partly supervised settings;generative model;deep encoders;deep decoders;interpretable speech representations;prior distributions;variational autoencoder model;time-scale properties;hierarchical factorization;phonetic information;speaker information;downstream phoneme classification;speaker classification;k-means classifier","","3","","80","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"Manifold-based Test Generation for Image Classifiers","T. Byun; A. Vijayakumar; S. Rayadurgam; D. Cofer","Computer Science & Eng., University of Minnesota, Minneapolis, MN, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Computer Science & Eng., University of Minnesota, Minneapolis, MN, USA; Advanced Technology Center, Collins Aerospace, Bloomington, MN, USA","2020 IEEE International Conference On Artificial Intelligence Testing (AITest)","25 Aug 2020","2020","","","15","22","Neural networks used for image classification tasks in critical applications must be tested with sufficient realistic data to assure their correctness. This raises two challenges: first, an adequate subset of the data points must be carefully chosen to inspire confidence, and second, the implicit requirements must be meaningfully extrapolated to data points beyond those in the explicit training set. This paper proposes a novel framework to address these challenges. Our approach is based on the premise that patterns in a large input data space can be effectively captured in a smaller manifold space, from which similar yet novel test cases-both the input and the label-can be sampled and generated. A variant of Conditional Variational Autoencoder (CVAE) is used for capturing this manifold with a generative function, and a search technique is applied on this manifold space to efficiently find fault-revealing inputs. Experiments show that this approach enables generation of thousands of realistic yet fault-revealing test cases efficiently even for well-trained models.","","978-1-7281-6984-2","10.1109/AITEST49225.2020.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9176830","machine learning testing;test generation;neural networks;variational autoencoder","Manifolds;Decoding;Test pattern generators;Task analysis;Probability density function;Image reconstruction","image classification;learning (artificial intelligence);neural nets;program testing;search problems","neural networks;image classification;conditional variational autoencoder;fault revealing test cases;manifold based test generation;search technique","","2","","29","","25 Aug 2020","","","IEEE","IEEE Conferences"
"Dual-Domain-Based Adversarial Defense With Conditional VAE and Bayesian Network","J. Zhu; G. Peng; D. Wang","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Industrial Informatics","29 Oct 2020","2021","17","1","596","605","Adversarial examples can be imperceptible to human eyes but can easily fool deep models. Such intrigue property has raised security issues for real-world industrial deep learning systems. To combat those malicious attacks, a novel defense strategy has been proposed based on the conditional variational autoencoder (CVAE) and Bayesian network (BN). The main contribution lies in the provided systematic dual-domain-based defense framework, which covers three modules named detection, diagnosis, and recovery. Specifically, the CVAE is first introduced for latent- and residual-domain generation. Subsequently, a composite and hierarchical BN detector is proposed to conduct the adversary detection through feature validation and output justification. Afterwards, a diagnosis strategy has been constructed for residual domain and different attacks can be evaluated in the unified framework. Finally, a two-step recovery mechanism is established on the CVAE that can effectively restore the feature representations and the network predictions from various adversaries. The feasibility of the entire defense diagram has been extensively demonstrated on three real-world recognition problems.","1941-0050","","10.1109/TII.2020.2964154","Nanyang Technological University(grant numbers:M4082293.040); Singapore MINDEF(grant numbers:9016102800); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8950195","Adversarial examples;Bayesian network (BN);defense;security;variational autoencoder","Perturbation methods;Bayes methods;Detectors;Informatics;Manifolds;Monitoring;Security","belief networks;feature extraction;learning (artificial intelligence);neural nets;security of data","adversarial defense;conditional VAE;Bayesian network;adversarial examples;human eyes;deep models;intrigue property;security issues;real-world industrial deep learning systems;malicious attacks;novel defense strategy;conditional variational autoencoder;CVAE;provided systematic dual-domain-based defense framework;residual-domain generation;composite BN detector;hierarchical BN detector;adversary detection;feature validation;output justification;diagnosis strategy;residual domain;two-step recovery mechanism;network predictions;entire defense diagram","","2","","32","IEEE","6 Jan 2020","","","IEEE","IEEE Journals"
"Passive Sonar Target Classification Using Deep Generative $\beta $-VAE","C. Satheesh; S. Kamal; A. Mujeeb; M. H. Supriya","Department of Electronics, Cochin University of Science and Technology, Kochi, India; Department of Electronics, Cochin University of Science and Technology, Kochi, India; International School of Photonics, Cochin University of Science and Technology, Kochi, India; Department of Electronics, Cochin University of Science and Technology, Kochi, India","IEEE Signal Processing Letters","4 May 2021","2021","28","","808","812","The intrinsic complexity associated with passive sonar data makes the task of target recognition extremely challenging. The conventional classifier architectures based on hand-engineered feature transforms often fail miserably to disentangle the high-dimensional non-linear structures in the observed target records. Although the modern deep learning algorithms through hierarchical feature learning yield acceptable success rates, they often require tremendous amounts of data when trained in a supervised manner. An unsupervised generative framework utilizing a variational autoencoder (VAE) is proposed in this work in order to create better disentangled representations for the downstream classification task. The disentanglement is further enforced using a hyperparameter β. For the purpose of better segregating the spectro-temporal features, an intermediate non-linearly scaled time-frequency representation is also employed in conjunction with β-VAE. Experimental analysis of various classifier configurations yields encouraging results in terms of data efficiency and classification accuracy on target records collected from various locations of the Indian Ocean.","1558-2361","","10.1109/LSP.2021.3071255","University Grants Commission Research Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9397277","Passive sonar;target recognition;deep learning;variational autoencoder","Task analysis;Target recognition;Acoustics;Signal processing algorithms;Oceans;Machine learning algorithms;Decoding","deep learning (artificial intelligence);marine engineering;pattern classification;signal classification;sonar signal processing","passive sonar target classification;deep generative β-VAE;passive sonar data;target recognition;conventional classifier architectures;hand-engineered feature transforms;observed target records;modern deep learning algorithms;unsupervised generative framework;variational autoencoder;disentangled representations;downstream classification task;hyperparameter β;spectro-temporal features;nonlinearly scaled time-frequency representation;classifier configurations;Indian ocean","","2","","42","IEEE","6 Apr 2021","","","IEEE","IEEE Journals"
"Semi-supervised Multichannel Speech Separation Based on a Phone- and Speaker-Aware Deep Generative Model of Speech Spectrograms","Y. Du; K. Sekiguchi; Y. Bando; A. Arie Nugraha; M. Fontaine; K. Yoshii; T. Kawahara","Graduate School of Informatics, Kyoto University, Kyoto, Japan; Center for Advanced Intelligence Project (AIP), RIKEN, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology (AIST), Tokyo, Japan; Center for Advanced Intelligence Project (AIP), RIKEN, Tokyo, Japan; Center for Advanced Intelligence Project (AIP), RIKEN, Tokyo, Japan; Center for Advanced Intelligence Project (AIP), RIKEN, Tokyo, Japan; Graduate School of Informatics, Kyoto University, Kyoto, Japan","2020 28th European Signal Processing Conference (EUSIPCO)","18 Dec 2020","2021","","","870","874","This paper describes a semi-supervised multichannel speech separation method that uses clean speech signals with frame-wise phonetic labels and sample-level speaker labels for pre-training. A standard approach to statistical source separation is to formulate a probabilistic model of multichannel mixture spectrograms that combines source models representing the time-frequency characteristics of sources with spatial models representing the covariance structure between channels. For speech separation and enhancement, deep generative models with latent variables have successfully been used as source models. The parameters of such a speech model can be trained beforehand from clean speech signals with a variational autoencoder (VAE) or its conditional variant (CVAE) that takes speaker labels as auxiliary inputs. Because human speech is characterized by both phonetic features and speaker identities, we propose a probabilistic model that combines a phone- and speaker-aware deep speech model with a full-rank spatial model. Our speech model is trained with a CVAE taking both phone and speaker labels as conditions. Given speech mixtures, the spatial covariance matrices, latent variables of sources, and phone and speaker labels of sources are jointly estimated. Comparative experimental results showed that the performance of speech separation can be improved by explicitly considering phonetic features and/or speaker identities.","2076-1465","978-9-0827-9705-3","10.23919/Eusipco47968.2020.9287464","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287464","multichannel source separation;speech separation;variational autoencoder","Time-frequency analysis;Source separation;Phonetics;Speech enhancement;Probabilistic logic;Spectrogram;Standards","covariance matrices;source separation;speaker recognition;speech enhancement;statistical analysis","statistical source separation;probabilistic model;multichannel mixture spectrograms;source models;spatial models;deep generative models;latent variables;clean speech signals;human speech;phonetic features;speaker identities;speaker-aware deep speech model;full-rank spatial model;speech mixtures;speaker-aware deep generative model;speech spectrograms;semisupervised multichannel speech separation method;frame-wise phonetic labels;sample-level speaker labels;speech enhancement;variational autoencoder;conditional variant;phone-aware deep speech model;spatial covariance matrices","","2","","27","","18 Dec 2020","","","IEEE","IEEE Conferences"
"Unsupervised Representation Learning of Speech for Dialect Identification","S. Shon; W. -N. Hsu; J. Glass","Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA","2018 IEEE Spoken Language Technology Workshop (SLT)","14 Feb 2019","2018","","","105","111","In this paper, we explore the use of a factorized hierarchical variational autoencoder (FHVAE) model to learn an unsupervised latent representation for dialect identification (DID). An FHVAE can learn a latent space that separates the more static attributes within an utterance from the more dynamic attributes by encoding them into two different sets of latent variables. Useful factors for dialect identification, such as phonetic or linguistic content, are encoded by a segmental latent variable, while irrelevant factors that are relatively constant within a sequence, such as a channel or a speaker information, are encoded by a sequential latent variable. The disentanglement property makes the segmental latent variable less susceptible to channel and speaker variation, and thus reduces degradation from channel domain mismatch. We demonstrate that on fully-supervised DID tasks, an end-to-end model trained on the features extracted from the FHVAE model achieves the best performance, compared to the same model trained on conventional acoustic features and an i-vector based system. Moreover, we also show that the proposed approach can leverage a large amount of unlabeled data for FHVAE training to learn domain-invariant features for DID, and significantly improve the performance in a low-resource condition, where the labels for the in-domain data are not available.","","978-1-5386-4334-1","10.1109/SLT.2018.8639650","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8639650","language recognition;dialect identification;variational autoencoder;unsupervised learning","Feature extraction;Training;Acoustics;Task analysis;Data models;Neural networks;Degradation","feature extraction;natural language processing;speaker recognition;unsupervised learning","dynamic attributes;dialect identification;phonetic content;linguistic content;speaker information;speaker variation;FHVAE model;FHVAE training;factorized hierarchical variational autoencoder model;unsupervised latent representation;static attributes","","2","","34","","14 Feb 2019","","","IEEE","IEEE Conferences"
"Dungeon and Platformer Level Blending and Generation using Conditional VAEs","A. Sarkar; S. Cooper","Northeastern University, Boston, MA, USA; Northeastern University, Boston, MA, USA","2021 IEEE Conference on Games (CoG)","7 Dec 2021","2021","","","1","8","Variational autoencoders (VAEs) have been used in prior works for generating and blending levels from different games. To add controllability to these models, conditional VAEs (CVAEs) were recently shown capable of generating output that can be modified using labels specifying desired content, albeit working with segments of levels and platformers exclusively. We expand these works by using CVAEs for generating whole platformer and dungeon levels, and blending levels across these genres. We show that CVAEs can reliably control door placement in dungeons and progression direction in platformer levels. Thus, by using appropriate labels, our approach can generate whole dungeons and platformer levels of interconnected rooms and segments respectively as well as levels that blend dungeons and platformers. We demonstrate our approach using The Legend of Zelda, Metroid, Mega Man and Lode Runner.","2325-4289","978-1-6654-3886-5","10.1109/CoG52621.2021.9619051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9619051","PCGML;variational autoencoder;level generation;game blending","Conferences;Games;Controllability;Reliability","computer games;neural nets","platformer levels;blend dungeons;platformer level blending;conditional VAEs;variational autoencoders;CVAEs;The Legend of Zelda;Metroid;Mega Man;Lode Runner","","2","","35","IEEE","7 Dec 2021","","","IEEE","IEEE Conferences"
"Using Deep Generative Models to Boost Forecasting: A Phishing Prediction Case Study","S. H. Amin Mahmood; A. Abbasi","Department of Electrical Engineering, Lahore University of Management Sciences, Lahore, Pakistan; Department of IT, Analytics, and Operations, University of Notre Dame, Notre Dame, IN, USA","2020 International Conference on Data Mining Workshops (ICDMW)","16 Feb 2021","2020","","","496","505","Time series predictions are important for various application domains. However, effective forecasting can be challenging in noisy contexts devoid of time series data encompassing stationarity, cyclicality, completeness, and non-sparseness. Cyber-security is a good example of such context. In organizational security settings, predicting time series related to emerging attacks could enhance cyber threat intelligence, resulting in timely and actionable insights at the operational, tactical, and strategic levels. In order to explore this gap, we propose a deep generative model-based framework for time series forecasting in noisy data environments. The proposed framework incorporates a novel ensembling strategy where generative adversarial networks and recurrent variational autoencoders are leveraged in unison with base predictors for enhanced regularization of time series predictive models. The framework is extensible, supporting different model combinations and analytical or iterative model fusion strategies. Using a test bed encompassing 10 years of weekly phishing attack volume data from 5 organizations in the technology, financial services, and social networking sectors, we show that the framework can boost predictive power for various standard time series models. Additional results reveal that the framework outperforms generative data augmentation approaches designed to enrich the input time series data matrices. Collectively, our findings suggest that utilizing generative models in more robust end-to-end setup can improve prediction in cyber threat intelligence contexts, as well as related problems involving challenging time series data.","2375-9259","978-1-7281-9012-9","10.1109/ICDMW51313.2020.00073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9346362","Time series modeling;generative adversarial networks;variational autoencoders;phishing;cyber threat intelligence;cybersecurity;deep learning;predictive analytics","Analytical models;Phishing;Time series analysis;Predictive models;Data models;Noise measurement;Forecasting","computer crime;deep learning (artificial intelligence);forecasting theory;recurrent neural nets;time series","deep generative models;boost forecasting;phishing prediction case study;time series predictions;application domains;effective forecasting;noisy contexts;time series data;nonsparseness;cyber-security;organizational security settings;emerging attacks;timely insights;actionable insights;operational levels;tactical levels;strategic levels;deep generative model-based framework;time series forecasting;noisy data environments;generative adversarial networks;recurrent variational autoencoders;base predictors;enhanced regularization;time series predictive models;different model combinations;analytical model fusion strategies;iterative model fusion strategies;weekly phishing attack volume data;predictive power;standard time series models;generative data augmentation;input time series data matrices;cyber threat intelligence contexts;challenging time series data;generative models;time 10.0 year","","2","","39","","16 Feb 2021","","","IEEE","IEEE Conferences"
"End-to-End Image-to-Speech Generation for Untranscribed Unknown Languages","J. Effendi; S. Sakti; S. Nakamura","RIKEN Center for Advanced Intelligence Project AIP, Tokyo, Japan; RIKEN Center for Advanced Intelligence Project AIP, Tokyo, Japan; RIKEN Center for Advanced Intelligence Project AIP, Tokyo, Japan","IEEE Access","13 Apr 2021","2021","9","","55144","55154","Describing orally what we are seeing is a simple task we do in our daily life. However, in the natural language processing field, this simple task needs to be bridged by a textual modality that helps the system to generalize various objects in the image and various pronunciations in speech utterances. In this study, we propose an end-to-end Image2Speech system that does not need any textual information in its training. We use a vector-quantized variational autoencoder (VQ-VAE) model to learn the discrete representation of a speech caption in an unsupervised manner, where discrete labels are used by an image-captioning model. This self-supervised speech representation enables the Image2Speech model to be trained with the minimum amount of paired image-speech data while still maintaining the quality of the speech caption. Our experimental results with a multi-speaker natural speech dataset demonstrate our proposed text-free Image2Speech system's performance close to the one with textual information. Furthermore, our approach also successfully outperforms the most recent existing frameworks with phoneme-based and grounding-based Image2Speech systems.","2169-3536","","10.1109/ACCESS.2021.3071541","Japan Society for the Promotion of Science (JSPS) KAKENHI(grant numbers:JP17H06101); Google AI Focused Research Awards Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9398708","Image-to-speech;image captioning;self-supervised speech representation;vector-quantized variational autoencoder;untranscribed unknown language","Task analysis;Image reconstruction;Decoding;Training;Bridges;Speech recognition;Data models","acoustic signal processing;learning (artificial intelligence);natural language processing;speech processing;speech recognition;speech synthesis;text analysis;vector quantisation","self-supervised speech representation;Image2Speech model;paired image-speech data;multispeaker natural speech dataset;text-free Image2Speech system;Image2Speech systems;image-captioning model;speech caption;discrete representation;vector-quantized variational autoencoder;textual information;end-to-end Image2Speech system;speech utterances;textual modality;natural language processing field;untranscribed unknown languages;image-to-speech generation","","2","","39","CCBYNCND","7 Apr 2021","","","IEEE","IEEE Journals"
"Speaker Anonymization for Personal Information Protection Using Voice Conversion Techniques","I. -C. Yoo; K. Lee; S. Leem; H. Oh; B. Ko; D. Yook","Department of Computer Science and Engineering, Artificial Intelligence Laboratory, Korea University, Seoul, South Korea; Department of Computer Science and Engineering, Artificial Intelligence Laboratory, Korea University, Seoul, South Korea; Department of Computer Science and Engineering, Artificial Intelligence Laboratory, Korea University, Seoul, South Korea; Department of Computer Science and Engineering, Artificial Intelligence Laboratory, Korea University, Seoul, South Korea; Department of Computer Science and Engineering, Artificial Intelligence Laboratory, Korea University, Seoul, South Korea; Department of Computer Science and Engineering, Artificial Intelligence Laboratory, Korea University, Seoul, South Korea","IEEE Access","9 Nov 2020","2020","8","","198637","198645","As speech-based user interfaces integrated in the devices such as AI speakers become ubiquitous, a large amount of user voice data is being collected to enhance the accuracy of speech recognition systems. Since such voice data contain personal information that can endanger the privacy of users, the issue of privacy protection in the speech data has garnered increasing attention after the introduction of the General Data Protection Regulation in the EU, which implies that restrictions and safety measures for the use of speech data become essential. This study aims to filter the speaker-related voice biometrics present in speech data such as voice fingerprint without altering the linguistic content to preserve the usefulness of the data while protecting the privacy of users. To achieve this, we propose an algorithm that produces anonymized speeches by adopting many-to-many voice conversion techniques based on variational autoencoders (VAEs) and modifying the speaker identity vectors of the VAE input to anonymize the speech data. We validated the effectiveness of the proposed method by measuring the speaker-related information and the original linguistic information retained in the resultant speech, using an open source speaker recognizer and a deep neural network-based automatic speech recognizer, respectively. Using the proposed method, the speaker identification accuracy of the speech data was reduced to 0.1-9.2%, indicating successful anonymization, while the speech recognition accuracy was maintained as 78.2-81.3%.","2169-3536","","10.1109/ACCESS.2020.3035416","Basic Science Research Program through the National Research Foundation of Korea (NRF); Ministry of Science, ICT and Future Planning(grant numbers:NRF-2017R1E1A1A01078157); Ministry of Science and ICT (MSIT) through the Information Technology Research Center (ITRC) Support Program supervised by the Institute for Information & Communications Technology Promotion (IITP)(grant numbers:IITP-2018-0-01405); IITP; Korean Government (MSIP) (A research on safe and convenient big data processing methods)(grant numbers:2018-0-00269); Korea University Grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9247219","Data privacy;deep neural networks;speaker anonymization;variational autoencoder;voice conversion","Training;Data privacy;Vocoders;Training data;Speech recognition;Linguistics;User interfaces","biometrics (access control);data privacy;filtering theory;neural nets;speaker recognition;speech codecs;speech coding;speech recognition;speech-based user interfaces","linguistic information;voice fingerprint;AI speakers;VAE;variational autoencoders;automatic speech recognizer;speaker-related voice biometrics;General Data Protection Regulation;speech recognition systems;user voice data;speech-based user;personal information Protection;speaker anonymization;speech recognition accuracy;deep neural network;speaker-related information;voice conversion techniques;speech data","","2","","29","CCBYNCND","3 Nov 2020","","","IEEE","IEEE Journals"
"Improve Regression Network on Depth Hand Pose Estimation With Auxiliary Variable","L. Xu; C. Hu; J. Tao; J. Xue; K. Mei","Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Department of Automation, Rocket Force University of Engineering, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China","IEEE Transactions on Circuits and Systems for Video Technology","4 Mar 2021","2021","31","3","890","904","The regression based deep neural networks have achieved state-of-the-arts performance on depth 3D hand pose estimation task. This paper focuses on improving the regression mapping between features and pose joints. Inspired by the distribution modeling ability of Variational Autoencoders, we introduce an auxiliary variable into the regression network. During training, the auxiliary variable is modeled by an inference distribution that learns the underlying structural kinematics of human hand. Different with other regression methods on hand poses, our network estimates the pose joints from input depth features and the learned auxiliary variable as well. We show that by introducing the auxiliary variable, the regression is benefited from 1) regularization modeled by inference distribution; and 2) prior information carried by the auxiliary model. The effectiveness of the proposed regression method is evaluated with extensively self-comparative experiments and in comparison with other regression methods on hand pose datasets. The proposed network is easy to train in an end-to-end manner and can work with various feature extraction methods. We apply the proposed regression method to an existing hand pose estimation system, and improves the estimation accuracy by 18.35% and 16.65% on public hand pose datasets.","1558-2205","","10.1109/TCSVT.2020.2991987","National Key Research and Development Plan(grant numbers:2016YFB1001004); National Natural Science Foundation of China(grant numbers:91748208); Guangdong Science and Technology Project(grant numbers:2017B010123003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9085372","Hand pose estimation;depth images;auxiliary variable;regression network;variational autoencoder","Pose estimation;Feature extraction;Kinematics;Three-dimensional displays;Task analysis;Training","feature extraction;neural nets;pose estimation;regression analysis","human hand;regression method;3D hand pose estimation;depth features;inference distribution;auxiliary model;feature extraction methods;public hand;regression network;depth hand pose estimation;auxiliary variable;deep neural networks;estimation task;regression mapping;distribution modeling ability;structural kinematics;variational autoencoders","","2","","45","IEEE","4 May 2020","","","IEEE","IEEE Journals"
"Comparison of an Automatic Classification of Partial Dischage Patterns for Large Hydrogenerator","O. Kokoko; C. Hudon; M. Lévesque; N. Amyot; R. Zemouri","Ireq, Hydro-Québec, Canada; lIREQ, Hydro-Québec, Canada; Ireq, Hydro-Québec, Canada; Ireq, Hydro-Québec, Canada; Ireq, Hydro-Québec, Canada","2021 IEEE International Conference on Prognostics and Health Management (ICPHM)","20 Jul 2021","2021","","","1","6","More and more scientific disciplines are using deep learning techniques for the automatic classification of massive high dimensionality unlabeled data. Among these disciplines, the classification of partial discharge (PD) patterns is one that represents major challenges in the field of hydrogenerator diagnosis. This paper proposes a method of comparison of five classification topology based on a single convolutional variational autoencoder (CVAE) and ten classifiers. The comparison is based on five cases exploiting all the same database, but using five different feature extraction rules to create the input vectors of the neural networks. These feature extraction rules are based on the expert judgement and are automatically computed in the pre-processing stage. Analysis of the output of all classifiers for each topology suggests that the accuracy level of the classification can be significantly improved by refining the feature extraction rules. Moreover, the visualization of the 2D latent space from the CVAE also suggests that the accuracy level can be even further improved if the whole dataset is considered instead of a smaller reference dataset randomly selected. Results raise many questions about the performance of feature extraction rules and the possibilities to better handling classification of large databases such as the one of PD measurement files used for hydrogenerator diagnosis.","","978-1-6654-1970-3","10.1109/ICPHM51084.2021.9486644","Hydro-Québec; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9486644","convolutional variational autoencoder;diagnosis;partial discharges;deep neural networks;expert knowledge;feature extraction;hydro-generators;latent space;partial discharge pattern)","Partial discharges;Deep learning;Handheld computers;Network topology;Filtering;Refining;Neural networks","data mining;feature extraction;image classification;learning (artificial intelligence);neural nets;pattern classification;support vector machines;unsupervised learning","handling classification;hydrogenerator diagnosis;automatic classification;partial dischage patterns;deep learning techniques;massive high dimensionality unlabeled data;partial discharge patterns;classification topology;single convolutional variational autoencoder;CVAE;classifiers;different feature extraction rules;accuracy level","","2","","8","IEEE","20 Jul 2021","","","IEEE","IEEE Conferences"
"A Generative Learning Approach for Spatio-temporal Modeling in Connected Vehicular Network","R. Xia; Y. Xiao; Y. Li; M. Krunz; D. Niyato","School of Electronic Information and Communications, Huazhong Univ. of Science & Technology, China; School of Electronic Information and Communications, Huazhong Univ. of Science & Technology, China; School of Electronic Information and Communications, Huazhong Univ. of Science & Technology, China; Department of Electrical and Computer Engineering, University of Arizona, AZ; School of Computer Science and Engineering, Nanyang Technological University, Singapore","ICC 2020 - 2020 IEEE International Conference on Communications (ICC)","27 Jul 2020","2020","","","1","6","Spatio-temporal modeling of wireless access latency is of great importance for connected-vehicular systems. The quality of the molded results rely heavily on the number and quality of samples which can vary significantly due to the sensor deployment density as well as traffic volume and density. This paper proposes LaMI (Latency Model Inpainting), a novel framework to generate a comprehensive spatio-temporal of wireless access latency of a connected vehicles across a wide geographical area. LaMI adopts the idea from image inpainting and synthesizing and can reconstruct the missing latency samples by a two-step procedure. In particular, it first discovers the spatial correlation between samples collected in various regions using a patching-based approach and then feeds the original and highly correlated samples into a Variational Autoencoder (VAE), a deep generative model, to create latency samples with similar probability distribution with the original samples. Finally, LaMI establishes the empirical PDF of latency performance and maps the PDFs into the confidence levels of different vehicular service requirements. Extensive performance evaluation has been conducted using the real traces collected in a commercial LTE network in a university campus. Simulation results show that our proposed model can significantly improve the accuracy of latency modeling especially compared to existing popular solutions such as interpolation and nearest neighbor-based methods.","1938-1883","978-1-7281-5089-5","10.1109/ICC40277.2020.9149319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9149319","Connected vehicle;latency modeling;Variational Autoencoder;C-V2X","Computational modeling;Wireless communication;Edge computing;Servers;Correlation;Adaptation models;Wireless sensor networks","image reconstruction;image sampling;interpolation;learning (artificial intelligence);Long Term Evolution;nearest neighbour methods;neural nets;radio access networks;sensor placement;traffic engineering computing","nearest neighbor-based methods;interpolation methods;LTE network;variational autoencoder;wireless access spatio-temporal modeling;vehicular service requirements;deep generative model;correlated samples;patching-based approach;image inpainting;wide geographical area;Latency Model Inpainting;LaMI;sensor deployment density;connected-vehicular systems;generative learning approach","","1","","15","","27 Jul 2020","","","IEEE","IEEE Conferences"
"Fault Classification of Industrial Processes based on Generalized Zero-Shot Learning","J. Huang; Z. Li; L. Ye; Z. Zhou","School of Engineering, Huzhou University, Huzhou, P. R. China; School of Engineering, Huzhou University, Huzhou, P. R. China; School of Engineering, Huzhou University, Huzhou, P. R. China; School of Engineering, Huzhou University, Huzhou, P. R. China","2021 IEEE 10th Data Driven Control and Learning Systems Conference (DDCLS)","25 Jun 2021","2021","","","887","892","In the process industry, the supervised learning methods cannot classify the unseen faults (i.e., those faults without training samples to participate in the establishment of the model). Although Zero-Shot Learning (ZSL) has been proposed and successfully solved the problem of unseen fault classification, it failed to classify the seen faults (i.e., those faults participate in the establishment of the model). To overcome their shortcomings, in this paper, a generalized Zero-Shot Learning (GZSL) method is proposed to classify all the faults including the seen and the unseen faults by only using the samples of the seen fault and the human-defined fault semantic attribute description information. We use a gating mechanism based on Conditional Variational Autoencoder (CVAE) and a binary classifier to distinguish the online sample into the classes of the seen and unseen faults. Thus, the GZSL problem can be transformed into a supervised fault classification problem and a ZSL fault classification problem. Firstly, we train a CVAE to generate pseudo unseen fault samples and seen fault samples. Secondly, a binary classifier is trained to classify the online samples into seen and unseen categories. Finally, the specific category of the online samples will be determined by the supervised method and ZSL method, respectively. We validate our approach on the Tennessee-Eastman benchmark process.","2767-9861","978-1-6654-2423-3","10.1109/DDCLS52934.2021.9455689","National Natural Science Foundation (NNSF) of China(grant numbers:61703158); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9455689","Fault classification;Generalized zero-shot learning;Zero-shot learning;Conditional variational autoencoder;Process industry","Industries;Training;Conferences;Supervised learning;Semantics;Process control;Benchmark testing","fault diagnosis;neural nets;pattern classification;production engineering computing;supervised learning","supervised fault classification problem;ZSL fault classification problem;pseudounseen fault samples;binary classifier;GZSL method;industrial processes;generalized zero-shot learning;process industry;supervised learning methods;training samples;unseen fault classification;human-defined fault semantic attribute description information;GZSL problem;gating mechanism;conditional variational autoencoder;CVAE;seen fault samples;online sample classification;Tennessee-Eastman benchmark process","","1","","17","IEEE","25 Jun 2021","","","IEEE","IEEE Conferences"
"Analysing protein dynamics using machine learning based generative models","A. -I. Albu; G. Czibula","Department of Computer Science, Babeş-Bolyai University, Cluj-Napoca, Romania; Department of Computer Science, Babeş-Bolyai University, Cluj-Napoca, Romania","2020 IEEE 14th International Symposium on Applied Computational Intelligence and Informatics (SACI)","16 Jun 2020","2020","","","000135","000140","The ability to understand and model proteins’ dynamics is of great relevance in biology and medicine. A good comprehension of the way the proteins change their structure is important as these transitions give the function of the protein within the organism. In this paper we are introducing an unsupervised learning based approach using variational autoencoders, for uncovering protein motions and conformational transitions. The main goal of the research is to offer an interpretable method for proteins’ trajectories visualisation by learning a low dimensional space that accurately represents the input data, as empirically confirmed through the performed experiments. An additional aim is to comparatively evaluate the impact of two protein representations on the learning process.","","978-1-7281-7377-1","10.1109/SACI49304.2020.9118834","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9118834","Protein dynamics;unsupervised learning;generative models;variational autoencoders","Proteins;Analytical models;Computational modeling;Data visualization;Machine learning;Organisms;Trajectory","bioinformatics;data analysis;data visualisation;proteins;unsupervised learning","conformational transitions;protein representations;machine learning;generative models;unsupervised learning based approach;variational autoencoders;protein motions;proteins trajectories visualisation;protein dynamics analysis","","1","","16","","16 Jun 2020","","","IEEE","IEEE Conferences"
"Context-Aware Learning for Generative Models","S. Perdikis; R. Leeb; R. Chavarriaga; J. d. R. Millán","Brain-Computer Interfaces and Neural Engineering Laboratory, School of Computer Science and Electronic Engineering, University of Essex, Colchester, U.K.; Mindmaze SA, Lausanne, Switzerland; School of Engineering, Institute of Applied Information Technology (InIT), Zurich University of Applied Sciences, Winterthur, Switzerland; Department of Neurology, The University of Texas at Austin, Austin, TX, USA","IEEE Transactions on Neural Networks and Learning Systems","3 Aug 2021","2021","32","8","3471","3483","This work studies the class of algorithms for learning with side-information that emerges by extending generative models with embedded context-related variables. Using finite mixture models (FMMs) as the prototypical Bayesian network, we show that maximum-likelihood estimation (MLE) of parameters through expectation-maximization (EM) improves over the regular unsupervised case and can approach the performances of supervised learning, despite the absence of any explicit ground-truth data labeling. By direct application of the missing information principle (MIP), the algorithms' performances are proven to range between the conventional supervised and unsupervised MLE extremities proportionally to the information content of the contextual assistance provided. The acquired benefits regard higher estimation precision, smaller standard errors, faster convergence rates, and improved classification accuracy or regression fitness shown in various scenarios while also highlighting important properties and differences among the outlined situations. Applicability is showcased with three real-world unsupervised classification scenarios employing Gaussian mixture models. Importantly, we exemplify the natural extension of this methodology to any type of generative model by deriving an equivalent context-aware algorithm for variational autoencoders (VAs), thus broadening the spectrum of applicability to unsupervised deep learning with artificial neural networks. The latter is contrasted with a neural-symbolic algorithm exploiting side information.","2162-2388","","10.1109/TNNLS.2020.3011671","European ICT Programme(grant numbers:FP7-224631); Tools for Brain-Computer Interaction (TOBI); Hasler Foundation, Switzerland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9163155","Context awareness;expectation–maximization (EM);finite mixture models (FMMs);maximum likelihood (ML);parameter estimation;side information;unsupervised learning;variational autoencoder (VA)","Context modeling;Maximum likelihood estimation;Brain-computer interfaces;Learning systems;Probabilistic logic;Approximation algorithms","belief networks;expectation-maximisation algorithm;Gaussian processes;mixture models;neural nets;pattern classification;regression analysis;supervised learning;unsupervised learning","real-world unsupervised classification scenarios;Gaussian mixture models;generative model;equivalent context-aware algorithm;unsupervised deep learning;context-aware learning;embedded context-related variables;finite mixture models;prototypical Bayesian network;supervised learning;explicit ground-truth data labeling;missing information principle;unsupervised MLE extremities;information content;supervised MLE extremities;maximum-likelihood estimation;variational autoencoders;neural-symbolic algorithm","","1","","54","IEEE","10 Aug 2020","","","IEEE","IEEE Journals"
"Remote Sensing Image Generation Based on Attention Mechanism and VAE-MSGAN for ROI Extraction","L. Zhang; Y. Liu","School of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China","IEEE Geoscience and Remote Sensing Letters","30 Dec 2021","2022","19","","1","5","A variety of deep learning approaches have been applied to region of interest (ROI) extraction, which is a fundamental task in the field of remote sensing image (RSI) processing. However, the unbalanced distribution of positive and negative samples in most RSIs greatly restricts the performance of these deep learning-based methods. In this study, a data augmentation method based on variational autoencoder-multiscale generative adversarial network (VAE-MSGAN) with spatial and channelwise attention (SCA) is proposed to balance the sample distribution and improve the subsequent ROI extraction results. First, we combine the original multispectral information with handcrafted texture features to make full use of the low-level visual features of RSIs. We then design a VAE-MSGAN to generate realistic RSIs with high quality and diversity. Specifically, in the generator construct, SCA blocks are introduced to adaptively recalibrate the varying importance of different channels and spatial regions. We also build a multiscale discriminator architecture to improve the visual quality of the generated samples. Finally, we compare the ROI extraction results before and after the augmentation. Our experimental results demonstrate that the proposed method can not only improve the performance of ROI extraction but also be superior to other classical generative methods.","1558-0571","","10.1109/LGRS.2021.3068271","Beijing Natural Science Foundation(grant numbers:L182029); National Natural Science Foundation of China(grant numbers:61571050,41771407); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9393473","Generative adversarial networks (GANs);region of interest (ROI) extraction;remote sensing;variational autoencoder (VAE)","Training;Generators;Data mining;Task analysis;Remote sensing;Generative adversarial networks;Feature extraction","feature extraction;geophysical image processing;image classification;image segmentation;image texture;learning (artificial intelligence);remote sensing","attention mechanism;VAE-MSGAN;deep learning approaches;interest extraction;remote sensing image processing;unbalanced distribution;positive samples;negative samples;deep learning-based methods;data augmentation method;variational autoencoder-multiscale;spatial attention;channelwise attention;sample distribution;subsequent ROI extraction results;original multispectral information;handcrafted texture features;low-level visual features;realistic RSIs;spatial regions;multiscale discriminator architecture;visual quality;classical generative methods;sensing image generation","","1","","15","IEEE","1 Apr 2021","","","IEEE","IEEE Journals"
"A Prediction Model for Remaining Useful Life of Turbofan Engines by Fusing Broad Learning System and Temporal Convolutional Network","K. Yu; D. Wang; H. Li","School of Control Science and Engineering, Dalian University of Technology, Dalian, China; School of Control Science and Engineering, Dalian University of Technology, Dalian, China; School of Control Science and Engineering, Dalian University of Technology, Dalian, China","2021 8th International Conference on Information, Cybernetics, and Computational Social Systems (ICCSS)","1 Mar 2022","2021","","","137","142","In this paper, a prediction model based on a broad learning system (BLS) and temporal convolutional network (TCN) is proposed to measure the remaining useful life (RUL) of turbofan engines. Firstly, a variational autoencoder (VAE) is used to extract important low-dimensional features from the engine sensor data. Then, the degradation information is extracted from the time and feature dimensions of fragment data using TCN. Further, the BLS combined with residual connection is used to enhance the nonlinear representation of the model. The proposed method is validated on the commercial modular aero propulsion system simulation (C-MAPSS) dataset and compared with some state-of-the-art methods. The experimental results show that the proposed method is effective in RUL prediction.","2639-4235","978-1-6654-0245-3","10.1109/ICCSS53909.2021.9722026","Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9722026","remaining useful life;variational autoencoder;temporal convolutional network;board learning system;C-MAPSS","Degradation;Computational modeling;Predictive models;Propulsion;Feature extraction;Systems simulation;Data mining","aerospace computing;aerospace propulsion;condition monitoring;convolutional neural nets;jet engines;mechanical engineering computing;remaining life assessment","prediction model;remaining useful life;turbofan engines;broad learning system;temporal convolutional network;BLS;TCN;variational autoencoder;engine sensor data;fragment data;commercial modular aero propulsion system simulation dataset;RUL prediction","","1","","18","IEEE","1 Mar 2022","","","IEEE","IEEE Conferences"
"Coarse-to-Fine Joint Distribution Alignment for Cross-Domain Hyperspectral Image Classification","J. Miao; B. Zhang; B. Wang","Research Center of Smart Networks and Systems, School of Information Science and Technology, Fudan University, Shanghai, China; Research Center of Smart Networks and Systems, School of Information Science and Technology, Fudan University, Shanghai, China; Research Center of Smart Networks and Systems, School of Information Science and Technology, Fudan University, Shanghai, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15 Dec 2021","2021","14","","12415","12428","Domain adaptation (DA) aims to enhance the feature transferability of a model across different domains with feature distribution differences, which has been widely explored in many computer vision tasks such as semantic segmentation and object detection, but has not been fully studied in hyperspectral image (HSI) classification task. Compared with the natural image-based DA, HSI-based DA still faces two main challenges: First, due to the strong spectral variability of HSIs, it is difficult to extract discriminative and domain-invariant features from different domains, resulting in the misalignment of cross-domain features; Second, class-wise (or fine-grained) spectral feature inconsistency between domains also inevitably degrades the classification accuracy. To address these issues, in this article, we propose a novel coarse-to-fine joint distribution alignment (JDA) framework for cross-domain classification of HSIs. Specifically, the training samples from source and target domains are first fed into a coupled variational autoencoders (VAE) module, which is composed of two well-designed VAEs equipped with mutual information metric to learn high-level domain-invariant representations in a shared latent space, so that the network can learn a coarse-grained source-target feature consistency. Furthermore, to alleviate the class-wise inter-domain feature inconsistency, a JDA module is constructed to perform a fine-grained cross-domain alignment by matching the joint probability distributions between the source and target domains through adversarial learning. Extensive experiments on both simulated and real hyperspectral datasets demonstrate the superiority of the proposed method in comparison with several conventional and state-of-the-art methods.","2151-1535","","10.1109/JSTARS.2021.3129177","National Natural Science Foundation of China(grant numbers:61971141,61731021); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622150","Adversarial learning;domain adaptation (DA);hyperspectral image (HSI) classification;variational autoencoders (VAEs)","Feature extraction;Task analysis;Adaptation models;Hyperspectral imaging;Training data;Semantics;Image classification","computer vision;feature extraction;geophysical image processing;image classification;image representation;image segmentation;learning (artificial intelligence);object detection;probability","fine-grained cross-domain alignment;joint probability distributions;target domains;simulated hyperspectral datasets;real hyperspectral datasets;cross-domain hyperspectral image classification;domain adaptation;feature transferability;feature distribution differences;computer vision tasks;semantic segmentation;object detection;hyperspectral image classification task;natural image-based DA;HSI-based DA;domain-invariant features;cross-domain features;classification accuracy;coupled variational autoencoders module;high-level domain-invariant representations;coarse-grained source-target feature consistency;class-wise inter-domain feature inconsistency;coarse-to-fine joint distribution alignment framework;source domains;adversarial learning","","1","","47","CCBY","19 Nov 2021","","","IEEE","IEEE Journals"
"Bitcoin Data Analytics: Scalable techniques for transaction clustering and embedding generation","R. S. Shah; A. Bhatia; A. Gandhi; S. Mathur","Dept. of Computer Science and Information Systems, Birla Institute of Technology and Science Pilani, Pilani, India; Dept. of Computer Science and Information Systems, Birla Institute of Technology and Science Pilani, Pilani, India; Dept. of Computer Science and Information Systems, Birla Institute of Technology and Science Pilani, Pilani, India; Dept. of Computer Science and Information Systems, Birla Institute of Technology and Science Pilani, Pilani, India","2021 International Conference on COMmunication Systems & NETworkS (COMSNETS)","17 Feb 2021","2021","","","1","6","Bitcoin provides pseudo-anonymity to its users, leading to many transactions related to illicit activities. The advent of mixing services like OnionBC, Bitcoin Fog, and Blockchain.info has allowed users to increase their anonymity further. This paper tackles the pseudo-anonymity of the Bitcoin blockchain by developing a scalable spark based framework to find patterns in the transaction data. The efficacy of the framework is demonstrated by performing exploratory analysis. Furthermore, the paper shows the capabilities of bitcoin-based graph representations and addresses the issue of user profiling based on unsupervised learning approaches for analysing Bitcoin transactions and users. The authors convert the transaction graph of the Bitcoin data to contain only Wallet-IDs and generate graph embeddings using Variational Graph Autoencoder [1]. Additionally, the authors use explainable-AI techniques and Kohonen self organizing maps to visualize and understand the results obtained from the unsupervised learning methods.","2155-2509","978-1-7281-9127-0","10.1109/COMSNETS51098.2021.9352922","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9352922","bitcoin;de-anonymization;Graph Convolutional Networks;Variational Graph Autoencoder;Self Organizing Maps;Apache Spark","Self-organizing feature maps;Data analysis;Data visualization;Bitcoin;Blockchain;Unsupervised learning;Cluster computing","data analysis;data mining;electronic money;financial data processing;graph theory;pattern clustering;self-organising feature maps;unsupervised learning","transaction data;exploratory analysis;bitcoin-based graph representations;addresses;user profiling;unsupervised learning approaches;Bitcoin transactions;transaction graph;graph embeddings;Variational Graph Autoencoder [1];explainable-AI techniques;unsupervised learning methods;Bitcoin data analytics;scalable techniques;transaction clustering;embedding generation;pseudoanonymity;illicit activities;OnionBC;Bitcoin Fog;Blockchain.info;Bitcoin blockchain;scalable spark","","1","","22","","17 Feb 2021","","","IEEE","IEEE Conferences"
"Classification of Imbalanced Near-infrared Spectroscopy Data","Q. Wang; L. Li; X. Pan; H. Yang","College of Electronic Engineering and Automation., Guilin University of Electronic Technology, Guilin, China; School of Computer Science and Information Security, Guilin University of Electronic Technology, Guilin, China; School of Computer Science and Information Security, Guilin University of Electronic Technology, Guilin, China; College of Automation, Beijing University of Posts & Telecommunications, Beijing, China","2020 12th International Conference on Advanced Computational Intelligence (ICACI)","26 Aug 2020","2020","","","577","584","Due to the imbalanced distribution of real near-infrared spectroscopy data, it is difficult for traditional machine learning methods to correctly classify samples during the modeling process. In general, near-infrared spectral data sets are high-dimensional and have few samples. In order to enhance the classification accuracy of machine learning, here we propose an ensemble-based learning approach. Specifically, the proposed method first generates a number of samples using a variational autoencoder (VAE) network, and merges these with the original data to form a new balanced data set. Then a classification model is built using the multi-feature fusion cascade forest (FCForest) method. We verified and evaluated our approach using an imbalanced near-infrared spectroscopy data set from citrus greening. The experimental results showed that using VAE to generate the samples improved the classification accuracy for the imbalanced data. Furthermore, by using the FCForest method on the new, balanced data set, the performance of the classifier was further improved.","2573-3311","978-1-7281-4248-7","10.1109/ICACI49185.2020.9177516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9177516","near-infrared spectroscopy;imbalanced data;variational autoencoder;multi-feature fusion","Automation;Computer science;Computational intelligence;Telecommunications;Forestry;Noise measurement","infrared spectroscopy;learning (artificial intelligence);neural nets;pattern classification;random forests;sensor fusion","imbalanced distribution;near-infrared spectral data sets;machine learning;balanced dataset;imbalanced dataset;imbalanced near-infrared spectroscopy data classification;FCForest;variational autoencoder network;multifeature fusion cascade forest;ensemble-based learning","","1","","21","","26 Aug 2020","","","IEEE","IEEE Conferences"
"PoseCVAE: Anomalous Human Activity Detection","Y. Jain; A. K. Sharma; R. Velmurugan; B. Banerjee","Department of Electrical Engineering; Department of Electrical Engineering; Department of Electrical Engineering; Centre of Studies in Resources Engineering, Indian Institute of Technology, Bombay, India","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","2927","2934","Anomalous human activity detection is the task of identifying human activities that differ from the usual. Existing techniques, in general, try to deploy some samples from an open-set (anomalous activities can not be represented as a closed set) to define the discriminator. However, it is non-trivial to obtain novel activity instances. To this end, we propose PoseCVAE, a novel anomalous human activity detection strategy using the notion of generative modeling. We adopt a hybrid training strategy comprising of self-supervised and unsupervised learning. The self-supervised learning helps the encoder and decoder to learn better latent space representation of human pose trajectories. We train our framework to predict future pose trajectory given a normal track of past poses, i.e., the goal is to learn a conditional posterior distribution that represents normal training data. To achieve this we use a novel adaptation of a conditional variational autoencoder (CVAE) and refer it as PoseCVAE. Future pose prediction will be erroneous if the given poses are sampled from a distribution different from the learnt posterior, which is indeed the case with abnormal activities. To further separate the abnormal class, we imitate abnormal poses in the encoded space by sampling from a distinct mixture of Gaussians (MoG). We use a binary cross-entropy (BCE) loss as a novel addition to the standard CVAE loss function to achieve this. We test our framework on three publicly available datasets and achieve comparable performance to existing unsupervised methods that exploit pose information.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9412132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9412132","Stochastic Generative Models;Conditional Variational Autoencoder;Pose Trajectory","Training;Stochastic processes;Training data;Coherence;Trajectory;Pattern recognition;Decoding","entropy;image coding;image representation;neural nets;pose estimation;supervised learning;unsupervised learning","PoseCVAE;human activities;activity instances;hybrid training strategy;unsupervised learning;self-supervised learning;human pose trajectories;abnormal activities;abnormal poses;anomalous human activity detection;encoder-decoder;conditional variational autoencoder;distinct mixture of Gaussians;binary cross-entropy;standard CVAE loss function;pose prediction;learnt posterior;encoded space;generative modeling;latent space representation;conditional posterior distribution","","1","","20","","5 May 2021","","","IEEE","IEEE Conferences"
"Learning Of Linear Video Prediction Models In A Multi-Modal Framework For Anomaly Detection","G. Slavic; A. S. Alemaw; L. Marcenaro; C. Regazzoni","DITEN, University of Genova, Italy; DITEN, University of Genova, Italy; DITEN, University of Genova, Italy; DITEN, University of Genova, Italy","2021 IEEE International Conference on Image Processing (ICIP)","23 Aug 2021","2021","","","1569","1573","This paper proposes a method for performing future-frame prediction and anomaly detection on video data in a multi-modal framework based on Dynamic Bayesian Networks (DBNs). In particular, odometry data and video data from a moving vehicle are fused. A Markov Jump Particle Filter (MJPF) is learned on odometry data, and its features are used to aid the learning of a Kalman Variational Autoencoder (KVAE) on video data. Consequently, anomaly detection can be performed on video data using the learned model. We evaluate the proposed method using multi-modal data from a vehicle performing different tasks in a closed environment.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506049","Variational Autoencoder;anomaly detection;Kalman Filter;data fusion;Dynamic Bayesian Networks","Maximum likelihood detection;Nonlinear filters;Predictive models;Markov processes;Particle filters;Bayes methods;Kalman filters","belief networks;data handling;distance measurement;feature extraction;Kalman filters;learning (artificial intelligence);Markov processes;neural nets;particle filtering (numerical methods);video signal processing","Kalman variational autoencoder;MJPF;Markov jump particle filter;dynamic bayesian networks;future-frame prediction;multimodal framework;linear video prediction models;multimodal data;anomaly detection;video data;odometry data","","1","","25","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"Anomaly Detection in Aerial Videos Via Future Frame Prediction Networks","P. Jin; L. Mou; G. -S. Xia; X. X. Zhu","LIESMARS, Wuhan University, China; Remote Sensing Technology Institute (IMF), German Aerospace Center (DLR), Germany; LIESMARS, Wuhan University, China; Remote Sensing Technology Institute (IMF), German Aerospace Center (DLR), Germany","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","8237","8240","By the virtue of high flexibility, low-cost, real-time, and high-resolution data acquisition capacity, unmanned aerial vehicles (UAVs) can be exploited for a wide range of applications, especially in surveillance, inspection, and search fields. Such applications aim to detect potential suspicious events, violent human actions from an untrimmed and lengthy UAV video. Anomaly detection methods are highly in demand because it is unrealistic for human experts to manually detect all abnormal events in image scene. However, anomaly detection methods in aerial videos are rarely studied in the remote sensing community. In this paper, We propose a future frame prediction network based on convolutional variational autoencoder networks to detect anomalous events. Compared to several models, our network has a superior performance.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554396","Aerial videos;anomaly detection;convolutional variational autoencoder networks;future frame prediction;unmanned aerial vehicles (UAVs)","Surveillance;Data acquisition;Streaming media;Inspection;Feature extraction;Unmanned aerial vehicles;Real-time systems","autonomous aerial vehicles;data acquisition;feature extraction;geophysical signal processing;object detection;remote sensing;remote sensing by radar;remotely operated vehicles;surveillance;video signal processing;video surveillance","high-resolution data acquisition capacity;unmanned aerial vehicles;UAVs;search fields;potential suspicious events;violent human actions;untrimmed UAV video;lengthy UAV video;anomaly detection methods;human experts;abnormal events;aerial videos;future frame prediction network;convolutional variational autoencoder networks;anomalous events","","1","","15","","12 Oct 2021","","","IEEE","IEEE Conferences"
"Learning A Continuous and Reconstructible Latent Space for Hardware Accelerator Design","Q. Huang; C. Hong; J. Wawrzynek; M. Subedar; Y. S. Shao",NVIDIA; UC Berkeley; UC Berkeley; Intel Labs; UC Berkeley,"2022 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)","27 Jun 2022","2022","","","277","287","The hardware design space is high-dimensional and discrete. Systematic and efficient exploration of this space has been a significant challenge. Central to this problem is the intractable search complexity that grows exponentially with the design choices and the discrete nature of the search space. This work investigates the feasibility of learning a meaningful low-dimensional continuous representation for hardware designs to reduce such complexity and facilitate the search process. We devise a variational autoencoder (VAE)-based design space exploration framework called VAESA, to encode the hardware design space in a compact and continuous representation. We show that black-box and gradient-based design space exploration algorithms can be applied to the latent space, and design points optimized in the latent space can be reconstructed to high-performance realistic hardware designs. Our experiments show that performing the design space search on the latent space consistently leads to the optimal design point under a fixed number of samples. In addition, the latent space can improve the sample efficiency of the original algorithm by 6.8$\times$ and can discover hardware designs that are up to 5% more efficient than the optimal design searched directly in the high-dimensional input space.","","978-1-6654-5954-9","10.1109/ISPASS55109.2022.00041","Facebook; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9804604","accelerator;design space exploration;latent space;variational autoencoder;vae;representation learning","Visualization;Systematics;Predictive models;Search problems;Prediction algorithms;Hardware;Software","genetic algorithms;gradient methods;learning (artificial intelligence);optimisation;search problems","continuous space;reconstructible latent space;hardware accelerator design;hardware design space;high-dimensional anddiscrete;systematic exploration;theintractable search complexity;search space;meaningfullow-dimensional continuous representation;hardware designsto;search process;variational autoencoder-based design spaceexploration framework;hardwaredesign space;compact representation;black-box;gradient-based design space explorationalgorithms;high-performance realistic hardware designs;design space search;optimal design point;6.8×;candiscover hardware designs;high-dimensional input space","","","","42","IEEE","27 Jun 2022","","","IEEE","IEEE Conferences"
"Local Spatial–Spectral Information-Integrated Semisupervised Two-Stream Network for Hyperspectral Anomaly Detection","X. Wang; L. Wang; Q. Wang","College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Information and Communications Engineering, Dalian Minzu University, Dalian, China; College of Surveying and Geo-Informatics, Tongji University, Shanghai, China","IEEE Transactions on Geoscience and Remote Sensing","19 Aug 2022","2022","60","","1","15","Hyperspectral images (HSIs) always contain abundant spectral and spatial information. Most of the existing deep learning-based hyperspectral anomaly detection methods consider spectral differences between the background and anomalies, and the local spatial information is usually ignored. To make complete use of the spatial–spectral information, this article proposed a local spatial–spectral information-integrated semisupervised two-stream network (LS3T-Net) for hyperspectral anomaly detection. The two-stream network comprises an adaptive convolution and fully connected network and a variational autoencoder (VAE). The adaptive convolution and fully connected network is used to extract the local spatial features of patches, while VAE is trained to learn spectral information close to the background pixels. Furthermore, the detection maps from the two-stream network are incorporated through a process combining the benefits of spatial learning and spectral learning. This enhances the ability to separate the background and anomalies and suppress the false alarm. The experimental results for six real HSI datasets reveal that LS3T-Net can produce more accurate detection results than seven popular benchmark methods.","1558-0644","","10.1109/TGRS.2022.3196409","National Natural Science Foundation of China(grant numbers:42171345,41971297,62071084); Tongji University(grant numbers:02502350047); Fundamental Research Funds for the Central Universities(grant numbers:3072022GIP0801); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9849502","Convolution;hyperspectral anomaly detection;local spatial–spectral information;semisupervised;two-stream;variational autoencoder (VAE)","Hyperspectral imaging;Anomaly detection;Training;Convolution;Adaptive systems;Image reconstruction;Feature extraction","deep learning (artificial intelligence);geophysical image processing;hyperspectral imaging;object detection","local spatial-spectral information-integrated semisupervised two-stream network;hyperspectral images;adaptive convolution;detection maps;spatial learning;spectral learning;deep learning-based hyperspectral anomaly detection;HSIs;fully connected network;variational autoencoder;VAE;LS3T-Net;background pixels","","","","48","IEEE","4 Aug 2022","","","IEEE","IEEE Journals"
"A Novel Approach of Unknown Network Attack Detection Based on Zero-Shot Learning","H. Wang; Y. Wang; Y. Guo","Cryptography Engineering Institute Information Engineering University, Zhengzhou, China; Cryptography Engineering Institute Information Engineering University, Zhengzhou, China; Cryptography Engineering Institute Information Engineering University, Zhengzhou, China","2021 IEEE International Conference on Data Science and Computer Application (ICDSCA)","23 Dec 2021","2021","","","312","318","Along with the computer network and software systems tend to be complex, using new technology, the method such as holes or social engineering skills on the implementation of the unknown network attack methods emerge in endlessly. Due to lack of corresponding labels in such attacks when detecting actually, traditional learning methods which need large amounts of labelled data will often appear low accuracy, besides, existing approaches of zero-shot learning suffer from domain shift problems. In our paper, we put forward a novel approach of unknown network attack detection on the basis of zero-shot learning. Under the multi-metric space, we align semantic embedding and visual embedding via designing a zero-shot learning model based on variational autoencoder, and transfer known class learning to the unknown class through the semantic feature vector. This approach not only alleviates the projection domain shift problem, but also improving the detection accuracy of unknown network attacks. Experiments show that our model has good practicability and feasibility on the NSL - KDD dataset, comparing with the other classifier models.","","978-1-6654-4054-7","10.1109/ICDSCA53499.2021.9650182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9650182","zero-shot learning;variational autoencoder;unknown network attack detection;NSL-KDD dataset","Learning systems;Visualization;Conferences;Semantics;Telecommunication traffic;Computer applications;Data science","computer network security;learning (artificial intelligence);neural nets;pattern classification","unknown network attack detection;computer network;software systems;social engineering skills;zero-shot learning model;projection domain shift problem;domain shift problems;variational autoencoder;semantic feature vector;NSL - KDD dataset","","","","26","IEEE","23 Dec 2021","","","IEEE","IEEE Conferences"
"Three-dimensional multi-target tracking of point cloud from bird's-eye view","S. Hou; Z. Wang; X. Li; J. Song","State Key Laboratory of Integrated Optoelectronics, College of Electronic Science and Engineering, Jilin University, Changchun, China; Jilin Xiangyun Information &Technology Co., Ltd, Changchun, China; Peng Cheng Laboratory, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China","2021 International Conference on Electronic Information Engineering and Computer Science (EIECS)","9 Nov 2021","2021","","","13","19","Currently, the most popular approach for multitarget tracking is tracking-by-detection. Existing algorithms cannot balance the quality and speed of three-dimensional (3D) multi-target online point cloud tracking. We propose a low-complexity high-quality 3D multi-target online tracking algorithm to track a 3D point cloud from a bird's-eye view. First, we use a detector to obtain a bird's-eye view of a 3D point cloud and object information. Then, a 3D multi-target online tracking scheme is constructed to obtain the target trajectory. The scheme is mainly divided into state estimation and target association. State estimation uses a 3D Kalman filter algorithm Target association is divided into two steps: cascade matching and intersection over union (IoU) matching. The apparent feature used by the cascade matching algorithm is determined by using the unsupervised algorithm variational autoencoder on the candidate target in a bird's-eye view. The IoU matching algorithm uses the 3D spatial features of the candidate target. We demonstrate the effectiveness of our algorithms on the KITTI dataset. The values of multiple object tracking accuracy (MOTA), multiple object tracking precision (MOTP), and speed are 66.02, 85.81, and 43 frames per second, respectively, indicating the effectiveness of our algorithm in tracking quality and speed.","","978-1-6654-1674-0","10.1109/EIECS53707.2021.9588028","National Natural Science Foundation of China(grant numbers:61934003,62090054); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9588028","3D multi-target online tracking;computer vision;bird's-eye view;variational autoencoder;point cloud","Three-dimensional displays;Target tracking;Pose estimation;Detectors;Feature extraction;Real-time systems;Trajectory","feature extraction;Kalman filters;neural nets;object tracking;state estimation;stereo image processing;target tracking","tracking-by-detection;three-dimensional multitarget online point cloud tracking;target trajectory;state estimation;cascade matching algorithm;unsupervised algorithm variational autoencoder;IoU matching algorithm;3D spatial features;multiple object tracking precision;three-dimensional multitarget tracking;low-complexity high-quality 3D multitarget online tracking algorithm;3D Kalman filter algorithm target association","","","","19","IEEE","9 Nov 2021","","","IEEE","IEEE Conferences"
"Leveraging 3d Information In Unsupervised Brain Mri Segmentation","B. Lambert; M. Louis; S. Doyle; F. Forbes; M. Dojat; A. Tucholka","Pixyl, Research and Development Laboratory, Grenoble, France; Pixyl, Research and Development Laboratory, Grenoble, France; Pixyl, Research and Development Laboratory, Grenoble, France; Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, Grenoble, France; Univ. Grenoble Alpes, Inserm, U1216, Grenoble Institut Neurosciences, GIN, Grenoble, France; Pixyl, Research and Development Laboratory, Grenoble, France","2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)","25 May 2021","2021","","","187","190","Automatic segmentation of brain abnormalities is challenging, as they vary considerably from one pathology to another. Current methods are supervised and require numerous annotated images for each pathology, a strenuous task. To tackle anatomical variability, Unsupervised Anomaly Detection (UAD) methods are proposed, detecting anomalies as outliers of a healthy model learned using a Variational Autoencoder (VAE). Previous work on UAD adopted 2D approaches, meaning that MRIs are processed as a collection of independent slices. Yet, it does not fully exploit the spatial information contained in MRI. Here, we propose to perform UAD in a 3D fashion and compare 2D and 3D VAEs. As a side contribution, we present a new loss function guarantying a robust training. Learning is performed using a multicentric dataset of healthy brain MRIs, and segmentation performances are estimated on White-Matter Hyperintensities and tumors lesions. Experiments demonstrate the interest of 3D methods which outperform their 2D counterparts.","1945-8452","978-1-6654-1246-9","10.1109/ISBI48211.2021.9433894","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9433894","Deep Learning;Variational Autoencoder;Anomaly Detection;Medical Imaging","Training;Image segmentation;Pathology;Three-dimensional displays;Magnetic resonance imaging;Brain modeling;Lesions","biomedical MRI;brain;image segmentation;medical image processing;tumours;unsupervised learning","independent slices;spatial information;UAD;healthy brain MRI;segmentation performances;3D information;automatic segmentation;brain abnormalities;pathology;annotated images;anatomical variability;unsupervised anomaly detection methods;healthy model;3D VAE;unsupervised brain MRI segmentation;variational autoencoder;white-matter hyperintensities;tumor lesions","","","","18","","25 May 2021","","","IEEE","IEEE Conferences"
"Discriminative Clustering of High-Dimensional Data Using Generative Modeling","M. Abdi; C. P. Lim; S. Mohamed; S. Nahavandi; E. Abbasnejad; A. V. D. Hengel","Institute for Intelligent Systems Research and Innovation (IISRI), Deakin University, Waurn Ponds, Australia; Institute for Intelligent Systems Research and Innovation (IISRI), Deakin University, Waurn Ponds, Australia; Institute for Intelligent Systems Research and Innovation (IISRI), Deakin University, Waurn Ponds, Australia; Institute for Intelligent Systems Research and Innovation (IISRI), Deakin University, Waurn Ponds, Australia; Australian Centre for Visual Technologies, University of Adelaide, South Australia, Australia; Australian Centre for Visual Technologies, University of Adelaide, South Australia, Australia","2018 IEEE 61st International Midwest Symposium on Circuits and Systems (MWSCAS)","24 Jan 2019","2018","","","799","802","We approach unsupervised clustering from a generative perspective. We hybridize Variational Autoencoder (VAE) and Generative Adversarial Network (GAN) in a novel way to obtain a vigorous clustering model that can effectively be applied to challenging high-dimensional datasets. The powerful inference of the VAE is used along with a categorical discriminator that aims to obtain a cluster assignment of the data, by maximizing the mutual information between the observations and their predicted class distribution. The discriminator is regularized with examples produced by an adversarial generator, whose task is to trick the discriminator into accepting them as real data. We demonstrate that using a shared latent representation greatly helps with discriminative power of our model and leads to a powerful unsupervised clustering model. The method can be applied to raw data in a high-dimensional space. Training can be performed end-to-end from randomly-initialized weights by alternating stochastic gradient descent on the parameters of the model. Experiments on two datasets including the challenging MNIST dataset show that the proposed method performs better than the existing models. Additionally, our method yields an efficient generative model.","1558-3899","978-1-5386-7392-8","10.1109/MWSCAS.2018.8623970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8623970","Clustering;unsupervised learning;generative adversarial network;variational autoencoder;deep learning","Generative adversarial networks;Gallium nitride;Data models;Generators;Mutual information;Unsupervised learning;Training","gradient methods;learning (artificial intelligence);pattern classification;pattern clustering;stochastic processes;unsupervised learning","discriminative clustering;high-dimensional data;generative perspective;VAE;vigorous clustering model;challenging high-dimensional datasets;powerful inference;categorical discriminator;cluster assignment;mutual information;predicted class distribution;adversarial generator;shared latent representation;discriminative power;powerful unsupervised clustering model;raw data;high-dimensional space;challenging MNIST dataset show;efficient generative model;generative adversarial network;variational autoencoder","","","","23","","24 Jan 2019","","","IEEE","IEEE Conferences"
"Build Connections Between Two Groups of Images Using Deep Learning Method","H. Du; E. Barut; J. Su","Statistics Department, The George Washington University; Statistics Department, The George Washington University; Amazon","2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)","10 Aug 2022","2022","","","1231","1236","Finding relationships between two related groups of images has been a challenging question in many fields. E.g., it is informative in neuron science studies to build the connection between experiment animals' neuron activity images and their behavior images. Very few previous works have achieved this task since most generative models focus on reconstructing the output images similar to input images. We proposed a novel framework in this paper to accomplish this goal, which could map images from one group to images from another group. We apply the singular value decomposition (SVD) method to remove the original images' background noise. Next, we combine two deep learning approaches, variational autoencoder (VAE) and convolutional neural networks (CNN), to directly connect two groups of images. We test our framework on images from a neuron science experiment. Results show that the proposed framework could generate mice paw movement images given the mice neuron images, which are very close to the ground truth images. In terms of capturing the paw gestures in paw movement images, experiment results demonstrate that our framework outperforms the state-of-art paw location detection method.","0730-3157","978-1-6654-8810-5","10.1109/COMPSAC54236.2022.00194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842517","Variational Autoencoder;Convolutional Neural Networks;Singular Value Decomposition","Deep learning;Training;Neurons;Feature extraction;Mice;Software;Convolutional neural networks","convolutional neural nets;deep learning (artificial intelligence);gesture recognition;image reconstruction;neurophysiology;singular value decomposition","deep learning method;neuron science studies;experiment animals;behavior images;input images;singular value decomposition method;neuron science experiment;mice paw movement images;ground truth images;animals neuron activity images;variational autoencoder;VAE;convolutional neural networks;CNN;mice neuron images;paw location detection method;image reconstruction","","","","25","IEEE","10 Aug 2022","","","IEEE","IEEE Conferences"
"Miku VMD: Special Motion Data and Predictive Methods for Choreography Model","J. Chen; C. Fang; J. Chen; Q. Chen","School of Electron and Computer, Southeast University, Nanjing, Jiangsu Province, P. R. China; School of Electron and Computer, Southeast University, Nanjing, Jiangsu Province, P. R. China; CATS College Canterbury, London, UK; School of Economics and Management, Southeast University, Nanjing, Jiangsu Province, P. R. China","2018 IEEE 4th International Conference on Computer and Communications (ICCC)","1 Aug 2019","2018","","","1792","1797","At present, most large-scale gesture data sets do not include dance gestures, and it takes a lot of effort to produce our own data sets, which makes a lot of trouble to train a choreography model. We find a large number of Miku's dance videos on many video websites. The videos are created by fans using MikuMikuDance software and the dance gestures are stored as VMD format. Converting them into CSV format, then we get the 3D coordinates of the key points of the human skeleton which can be used as a dataset for training choreography model. This paper presents a choreography model based on variational autoencoder and LSTM which use Miku's dance gestures as data set. Our choreography model can generate continuous and graceful dance gestures using the 3D coordinates of the key points of the human skeleton at some moment or the 3D coordinates of the key points of the human skeleton at several consecutive moments as input, helping people for better dance choreography and dance learning.","","978-1-5386-8339-2","10.1109/CompComm.2018.8780677","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8780677","Vmd format;dance gesture;choreography model;variational autoencoder;LSTM","Three-dimensional displays;Skeleton;Decoding;Feature extraction;Data models;Videos;Encoding","gesture recognition;humanities;image motion analysis;recurrent neural nets","Miku VMD;special motion data;choreography model;large-scale gesture data sets;continuous dance gestures;graceful dance gestures;dance choreography;dance learning;Miku dance videos;MikuMikuDance software;CSV format;variational autoencoder","","","","26","","1 Aug 2019","","","IEEE","IEEE Conferences"
"EPMS: A Framework for Large-Scale Patient Matching","H. Singhal; H. Ravi; S. N. Chakravarthy; P. Balasundaram; C. Babu","Department of CSE, SSN College of Engineering, Chennai, India; Department of CSE, SSN College of Engineering, Chennai, India; Department of CSE, SSN College of Engineering, Chennai, India; Department of CSE, SSN College of Engineering, Chennai, India; Department of CSE, SSN College of Engineering, Chennai, India","2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)","13 Feb 2020","2019","","","1096","1101","The healthcare industry, through digitization, is trying to achieve interoperability, but has not been able to achieve complete Health Information Exchange (HIE). One of the major challenges in achieving this is the inability to accurately match patient data. Mismatching of patient records can lead to improper treatment which can prove to be fatal. Also, the presence of duplicate overheads has caused inaccessibility to crucial information in the time of need. Existing solutions to patient matching are both time-consuming and non-scalable. This paper proposes a framework, namely, Electronic Patient Matching System (EPMS), which attempts to overcome these barriers while achieving a good accuracy in matching patient records. The framework encodes the patient records using variational autoencoder and amalgamates them by performing locality sensitive hashing on an Apache spark cluster. This makes the process faster and highly scalable. Furthermore, a fuzzy matching of the records in each block is performed using Levenshtein distances to identify the duplicate patient records. Experimental investigations were performed on a synthetically generated dataset consisting of 44555 patient records. The proposed framework achieved a matching accuracy of 81.15% on this dataset.","2375-0197","978-1-7281-3798-8","10.1109/ICTAI.2019.00153","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8995221","Patient matching, Deduplication, Variational autoencoders, Blocking, Locality sensitive hashing, Fuzzy matching","","fuzzy set theory;health care;medical information systems;neural nets;open systems;patient care;records management","EPMS;health information exchange;patient data;fuzzy matching;duplicate patient records;healthcare industry;HIE;electronic patient matching system;variational autoencoder;locality sensitive hashing;Apache spark cluster;Levenshtein distance","","","","20","","13 Feb 2020","","","IEEE","IEEE Conferences"
"Using Variants of Conditional-Decoder VAE for Spatial-Temporal Precipitation Nowcasting in Thailand","C. Sudprasert; S. Supratid","College of Digital Innovation Technology, Rangsit University, Pathum-thani, Thailand; College of Digital Innovation Technology, Rangsit University, Pathum-thani, Thailand","2022 19th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)","16 Jun 2022","2022","","","1","4","This paper proposes variants of conditional-decoder variational autoencoder based on convolutional gated recurrent unit (ConvGRU), namely CD-VAEs for spatial-temporal precipitation nowcasting in Thailand. Such precipitation nowcasting relies on ERA5 hourly dataset, the efficient fifth generation of atmospheric reanalysis. Eight ERA5 precipitation-related variables are combined as multi-channel to feed into the models, based on 4–4 input - output hourly time steps. Multiple precipitation-related variables are combined as multi-channel to feed into the models. Three comparative CD-VAE models: Cond-O, Cond-H and Cond-Z differ in terms of the way hidden states, H and latent representation Z are passed from encoder to decoder. Performance evaluations rely on F1 scores, root mean squared errors (RMAEs) along with false negative (FN) as most data falls in no/hardly rainfall noticeable category. Comparison results indicate at least 74.81% better averaged F1 score is yielded by CD-VAEs than unconditional one. Cond-O, whose only the first-state decoder obtains Z as input provides the best nowcasting in terms of averaged RMAE, F1 as well as FN. For rainfall intensity range 0-0.5 mm./hour with 83.69% frequency rate, Cond-O yields 0.9467 and 0.0347 F1 and RMAE scores; in range 5-72 mm./hour with 0.35% frequency rate, it results 0.4244 and 0.6955. However, visually examining step-by-step output, Cond-Z, where Z is input to decoding states at all time steps yields the lowest decrease rate of performance over time-step passed.","","978-1-6654-8584-5","10.1109/ECTI-CON54298.2022.9795432","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9795432","Convolutional GRU;Variational Autoencoder;Precipitation Nowcasting;ERA5","Performance evaluation;Atmospheric modeling;Computational modeling;Neural networks;Logic gates;Generative adversarial networks;Decoding","decoding;mean square error methods;neural nets;rain;regression analysis;weather forecasting","Cond-O;decoding states;step-by-step output;Cond-O yields;Cond-Z;Cond-H;comparative CD-VAE models;multiple precipitation-related variables;ERA5 precipitation-related variables;ERA5 hourly dataset;CD-VAEs;convolutional gated recurrent unit;conditional-decoder variational autoencoder;Thailand;spatial-temporal precipitation nowcasting;conditional-decoder VAE","","","","11","IEEE","16 Jun 2022","","","IEEE","IEEE Conferences"
"Retinal Vessel Segmentation with VAE Reconstruction and Multi-Scale Context Extractor","W. Xu; H. Yang; M. Zhang; X. Pan; W. Liu; S. Yan","Beijing University of Posts and Telecommunications, China; Beijing University of Posts and Telecommunications, China; China Electronics Standardization Institute, China; China Electronics Standardization Institute, China; Beijing University of Posts and Telecommunications, China; Beijing University of Posts and Telecommunications, China","2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)","26 Apr 2022","2022","","","1","5","The clinical diagnosis of eye disorders including diabetic retinopathy relies heavily on retinal vessel segmentation. CNN-based methods are the preferred approaches for retina vessel segmentation in recent years, but they are data hungry and prone to overfitting on the training set and achieving sub-optimal results on the validation set or the test set. Taking this into consideration, we propose to integrate a variational autoencoder reconstruction branch to pose extra regularization on the shared encoder and increase the generalization ability of networks. Furthermore, to deal with the unbalanced vessel scale distribution, a multi-scale context extractor is carefully designed, which employed the regular convolution and dilated convolution to extract multi-scale context and utilized different fusion method to obtain better complementary features. Extensive experiment results demonstrate that our proposed method achieves comparable state-of-the-art performance on the popular datasets: DRIVE and CHASEDB1.","1945-8452","978-1-6654-2923-8","10.1109/ISBI52829.2022.9761563","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761563","Retinal vessel segmentation;convolutional neural network;variational autoencoder;multi-scale","Training;Image segmentation;Convolution;Retinopathy;Feature extraction;Retinal vessels;Diabetes","convolutional neural nets;diseases;eye;feature extraction;image reconstruction;image segmentation;medical image processing","variational autoencoder reconstruction branch;multiscale context extractor;retinal vessel segmentation;VAE reconstruction;clinical diagnosis;eye disorders;diabetic retinopathy;CNN-based methods;fusion method","","","","18","IEEE","26 Apr 2022","","","IEEE","IEEE Conferences"
"Generating Explanations for Recommendation Systems via Injective VAE","Z. Cai","East China Normal University, ShangHai, China","2021 IEEE International Conference on Data Mining (ICDM)","24 Jan 2022","2021","","","1012","1017","Generating explanations for recommendation systems is essential for improving its transparency since informative explanations such as generated reviews can help users comprehend the reason for receiving a specified recommendation. The generated reviews should be specific for the given user, item, and rating, however, recent works only focus on designing more and more powerful decoder, merely treating this task as a plain natural language generation process. We argue that there may exist the risk that the powerful decoder neglects the input embeddings and suffers from the biases that exist in data. In this paper, we propose a novel Injective Variational Autoencoders (InVAE) for generating high-quality reviews. Specifically, we employ a Collaborative Kullback-Leibler divergences (CKL) mechanism to building a better latent space that captures meaningful information. Base on this, the Spectral Regularization on Flow-based transformation (SRF) method is designed to backward transfer the priorities of generated latent variables to the input embeddings. Therefore, our method can construct more informative input embeddings and provides more specific explanations for different inputs. Extensive empirical experiments demonstrate that our model can construct much more meaningful feature embeddings and generate personalized reviews in high quality.","2374-8486","978-1-6654-2398-4","10.1109/ICDM51629.2021.00115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679194","Recommendation System;Explanation Generation;Variational AutoEncoder","Training;Conferences;Natural languages;Buildings;Collaboration;Decoding;Data mining","learning (artificial intelligence);natural language processing;natural languages;recommender systems","recommendation systems;Injective VAE;informative explanations;generated reviews;specified recommendation;powerful decoder;plain natural language generation process;novel Injective Variational Autoencoders;high-quality reviews;Collaborative Kullback-Leibler divergences;Flow-based transformation method;generated latent variables;informative input embeddings;specific explanations;meaningful feature embeddings;personalized reviews","","","","44","IEEE","24 Jan 2022","","","IEEE","IEEE Conferences"
"Application of a New VAE-MF Generative Model in TCD Dataset","X. Zhang; X. Chen; Y. Guo; S. Wang; W. Jia","College of Information and Computer, Taiyuan University of Technology, Jinzhong, China; College of Information and Computer, Taiyuan University of Technology, Jinzhong, China; College of Information and Computer, Taiyuan University of Technology, Jinzhong, China; College of Information and Computer, Taiyuan University of Technology, Jinzhong, China; Department of Neurology, Shanxi Province People's Hospital, Taiyuan, China","2022 International Conference on Computer Engineering and Artificial Intelligence (ICCEAI)","17 Aug 2022","2022","","","114","118","Transcranial Doppler (TCD) is a non-invasive method for detecting ischemic stroke disease and is widely used in clinical diagnosis. Due to the obvious imbalance of medical data, oversampling is needed to balance it. Although the oversampling method is one of the important means to solve the problem of imbalanced data classification, the traditional oversampling method will inevitably introduce noise, which will affect the classification results. To address this issue, we proposed a new oversampling method combining the membership function (MF) and the variational autoencoder (VAE). Our method utilized VAE as a generative model to generate new samples to reduce the Imbalance Ratio (IR) of the dataset. Then the new samples are filtered using MF to weaken the impact of the noise introduced by the oversampling method on classification performance. In addition, in view of the weak adaptability of traditional MFs to complex sample distributions in practical applications, a new MF is proposed by using kernel function mapping and hypersphere. The classification experiments on TCD imbalanced dataset prove that the oversampling method we proposed has improved classification performance on multiple evaluation criteria compared with traditional oversampling methods.","","978-1-6654-6803-9","10.1109/ICCEAI55464.2022.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9853377","variational autoencoder;membership function;generative model;imbalanced dataset;Transcranial Doppler","Adaptation models;Computational modeling;Doppler effect;Clinical diagnosis;Kernel;Artificial intelligence;Medical diagnostic imaging","brain;diseases;information filtering;medical information systems;patient diagnosis;sampling methods","imbalance ratio;VAE;variational autoencoder;medical data;clinical diagnosis;detecting ischemic stroke disease;Transcranial Doppler;TCD dataset;new VAE-MF generative model;traditional oversampling method;imbalanced data classification;noninvasive method","","","","14","IEEE","17 Aug 2022","","","IEEE","IEEE Conferences"
"System and Component Anomaly Detection Using LSTM-VAE","J. H. Park; H. S. Jo; M. G. Na","Dept. of Nuclear Engineering, Chosun University, Gwangju, Republic of Korea; Dept. of Nuclear Engineering, Chosun University, Gwangju, Republic of Korea; Dept. of Nuclear Engineering, Chosun University, Gwangju, Republic of Korea","2021 5th International Conference on System Reliability and Safety (ICSRS)","3 Jan 2022","2021","","","131","137","In the event of an accident at a nuclear power plant, the operators have to take appropriate actions after carrying out the diagnosis of the accident. However, the accident diagnosis can cause the human error because complex procedures have to be performed quickly within a limited time. Accordingly, researches using artificial intelligence are actively being conducted to reduce the occurrence frequency of human errors that may occur in diagnostic tasks. Most studies use a supervised learning strategy to assist operators in diagnostic tasks using artificial intelligence. However, there is a problem that the supervised learning strategy cannot be handled properly when untrained data is input. Therefore, this paper aims to provide information to operators by adopting an unsupervised learning strategy that does not cause such a problem. Therefore, we intend to detect abnormalities in the systems and components of nuclear power plants by utilizing long short-term memory variational autoencoder, an artificial intelligence methodology. It is expected that the results of detecting anomalies in systems and components will help operators in diagnosing and mitigating accidents.","","978-1-6654-0049-7","10.1109/ICSRS53853.2021.9660704","National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9660704","diagnostic task;unsupervised learning strategy;long short-term memory variational autoencoder;system and component anomaly detection","Performance evaluation;Supervised learning;Safety;Reliability;Artificial intelligence;Task analysis;Anomaly detection","data handling;nuclear power stations;power engineering computing;recurrent neural nets;unsupervised learning","LSTM-VAE;nuclear power plant;accident diagnosis;human error;complex procedures;occurrence frequency;supervised learning strategy;untrained data;unsupervised learning strategy;artificial intelligence methodology;long short-term memory variational autoencoder;component anomaly detection","","","","10","IEEE","3 Jan 2022","","","IEEE","IEEE Conferences"
"Anomaly Detection for Solder Joints Using β-VAE","F. Ulger; S. E. Yuksel; A. Yilmaz","Aselsan Inc., Ankara, Turkey; Department of Electrical and Electronics Engineering, Hacettepe University, Ankara, Turkey; Department of Electrical and Electronics Engineering, Hacettepe University, Ankara, Turkey","IEEE Transactions on Components, Packaging and Manufacturing Technology","15 Dec 2021","2021","11","12","2214","2221","In the assembly process of printed circuit boards (PCBs), most of the errors are caused by solder joints in surface mount devices (SMDs). In the literature, traditional feature extraction-based methods require designing hand-crafted features and rely on the tiered red green blue (RGB) illumination to detect solder joint errors, whereas the supervised convolutional neural network (CNN)-based approaches require a lot of labeled abnormal samples (defective solder joints) to achieve high accuracy. To solve the optical inspection problem in unrestricted environments with no special lighting and without the existence of error-free reference boards, we propose a new beta-variational autoencoder (beta-VAE) architecture for anomaly detection that can work on both integrated circuit (IC) and non-IC components. We show that the proposed model learns disentangled representation of data, leading to more independent features and improved latent space representations. We compare the activation and gradient-based representations that are used to characterize anomalies and observe the effect of different beta parameters on accuracy and untwining the feature representations in beta-VAE. Finally, we show that anomalies on solder joints can be detected with high accuracy via a model trained directly on normal samples without designated hardware or feature engineering.","2156-3985","","10.1109/TCPMT.2021.3121265","Aselsan Inc., through a project between Hacettepe University and Aselsan Inc; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9579423","β-variational autoencoder (VAE);automated optical inspection (AOI);solder joint inspection (SJI);unsupervised anomaly detection;VAE","Soldering;Feature extraction;Anomaly detection;Inspection;Automatic optical inspection;Training","assembling;automatic optical inspection;convolutional neural nets;design engineering;feature extraction;gradient methods;integrated circuit manufacture;learning (artificial intelligence);printed circuits;production engineering computing;solders;surface mount technology","anomaly detection;printed circuit boards;surface mount devices;feature extraction-based methods;tiered red green blue illumination;solder joint errors;supervised convolutional neural network-based approaches;labeled abnormal samples;error-free reference boards;beta-variational autoencoder architecture;beta-VAE;integrated circuit;gradient-based representations;assembly process;PCB;SMD;CNN;optical inspection problem;nonIC components;latent space representations;hand-crafted features design","","","","35","IEEE","18 Oct 2021","","","IEEE","IEEE Journals"
"Generator Information Enhancement Generative Adversarial Networks for Alleviating Data Imbalance Problems","J. Li; Z. Zhu","School of Computer and Artificial Intelligence, Zhengzhou University, Zhengzhou, China; School of Computer and Artificial Intelligence, Zhengzhou University, Zhengzhou, China","2022 7th International Conference on Intelligent Computing and Signal Processing (ICSP)","24 May 2022","2022","","","1511","1517","In real-world datasets, numerous class distributions are imbalanced, which severely affects the classification ability of deep learning methods. Data augmentation can address such problem by creating data for the minority class to rebalance the datasets. However, it is still challenging that how to generate data from a true distribution of given finite training data. To overcome this challenge, we propose a novel and efficient synthetic oversampling approach, Generator Information Enhancement Generative Adversarial Networks (GIE-GAN). Its generative information is enhanced in two aspects. First, the generator can get common knowledge of all classes by initializing with a variational autoencoder. Second, during the training process, an independent classifier, which can provide accurate classification results for the generator, is added to the GAN for further augmenting the generative information. Experimental results on benchmark datasets show that, compared with the rival methods, our method can generate high-quality images and obtain better classifier performance of deep learning, especially for high imbalance ratios.","","978-1-6654-7857-1","10.1109/ICSP54964.2022.9778313","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9778313","imbalanced classification;data augmentation;variational autoencoder;generative adversarial networks","Deep learning;Training;Training data;Signal processing;Benchmark testing;Generative adversarial networks;Generators","deep learning (artificial intelligence);image classification","data imbalance problems;data augmentation;generator information enhancement generative adversarial networks;deep learning method;synthetic oversampling approach;GIE-GAN;variational autoencoder;independent classifier;high-quality images;class distributions","","","","17","IEEE","24 May 2022","","","IEEE","IEEE Conferences"
"Diagnostic Data Integration Using Deep Neural Networks for Real-Time Plasma Analysis","A. Rigoni Garola; R. Cavazzana; M. Gobbin; R. S. Delogu; G. Manduchi; C. Taliercio; A. Luchetta","Consorzio RFX (CNR, ENEA, INFN, Universitá Degli Studi di Padova, Acciaierie Venete SpA), Padua, Italy; Consorzio RFX (CNR, ENEA, INFN, Universitá Degli Studi di Padova, Acciaierie Venete SpA), Padua, Italy; Consorzio RFX (CNR, ENEA, INFN, Universitá Degli Studi di Padova, Acciaierie Venete SpA), Padua, Italy; Consorzio RFX (CNR, ENEA, INFN, Universitá Degli Studi di Padova, Acciaierie Venete SpA), Padua, Italy; Consorzio RFX (CNR, ENEA, INFN, Universitá Degli Studi di Padova, Acciaierie Venete SpA), Padua, Italy; Consorzio RFX (CNR, ENEA, INFN, Universitá Degli Studi di Padova, Acciaierie Venete SpA), Padua, Italy; Consorzio RFX (CNR, ENEA, INFN, Universitá Degli Studi di Padova, Acciaierie Venete SpA), Padua, Italy","IEEE Transactions on Nuclear Science","16 Aug 2021","2021","68","8","2165","2172","Recent advances in acquisition equipment are providing experiments with growing amounts of precise, yet affordable sensors. At the same time, an improved computational power, coming from new hardware resources [GPU, field-programmable gate array (FPGA), adaptive compute acceleration platform (ACAP)] has been made available at relatively low costs. This led us to explore the possibility of completely renewing the chain of acquisition for a fusion experiment, where many high-rate sources of data, coming from different diagnostics, can be combined in a wide framework of algorithms. If, on the one hand, adding new data sources with different diagnostics enriches our knowledge about physical aspects, on the other hand, the dimensions of the overall model grow, making relations among variables more and more opaque. A new approach for integrating such heterogeneous diagnostics, based on the composition of deep variational autoencoders, could ease this problem, acting as a structural sparse regularizer. This has been applied to RFX-mod experimental data, integrating the soft X-ray linear images of plasma temperature with the magnetic state. However, to ensure a real-time signal analysis, these algorithmic techniques must be adapted to run in well-suited hardware. In particular, it is shown that, attempting a quantization of neuron transfer functions, such models can be adapted to run in an embedded programmable logic device. The resulting firmware, approximating the deep inference model to a set of simple operations, fits well with the simple logic units that are largely abundant in FPGAs. This is the key factor that permits the use of affordable hardware with complex deep neural topology and operates them in real-time.","1558-1578","","10.1109/TNS.2021.3096837","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9481901","Data imputation;data integration;field-programmable gate array (FPGA);missing data;neural networks;plasma diagnostic;quantized networks;real-time control;sparse regularization;variational autoencoders (VAEs)","Data models;Mathematical model;Real-time systems;Plasmas;Temperature measurement;Field programmable gate arrays;Plasma temperature","field programmable gate arrays;neural nets;plasma temperature;programmable logic devices","hardware resources;relatively low costs;fusion experiment;different diagnostics;data sources;physical aspects;heterogeneous diagnostics;deep variational autoencoders;structural sparse regularizer;RFX-mod experimental data;soft X-ray linear images;plasma temperature;real-time signal analysis;algorithmic techniques;embedded programmable logic device;deep inference model;affordable hardware;complex deep neural topology;diagnostic data integration;deep neural networks;real-time plasma analysis;acquisition equipment;affordable sensors;improved computational power","","","","25","IEEE","13 Jul 2021","","","IEEE","IEEE Journals"
"Deep Generative Model-based RSSI Synthesis for Indoor Localization","D. J. Suroso; P. Cherntanomwong; P. Sooraksa","School of Engineering, King Mongkut’s Institute of Technology Ladkrabang, Bangkok, Thailand; School of Engineering, King Mongkut’s Institute of Technology Ladkrabang, Bangkok, Thailand; School of Engineering, King Mongkut’s Institute of Technology Ladkrabang, Bangkok, Thailand","2022 19th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)","16 Jun 2022","2022","","","1","5","Indoor localization via deep learning (DL) is attracting researchers' attention. DL is mainly used for fingerprinting-based indoor localization as it generally employs a vast offline database to ensure its reliability. However, the long effort and high cost of constructing this database are the disadvantages of this technique. This paper implements variational autoencoders (VAE), one of the popular deep generative models, to alleviate the drawbacks of offline database issues. Our proposal works using the received signal strength indicator (RSSI); unfortunately, it is known for its fluctuation and instability. Thus, instead of using RSSI directly as a localization parameter, we learn its distribution via VAE to generate the synthetic RSSI values. We utilized the RSSI from an actual measurement campaign. The VAE implementation results show that we can obtain the RSSI synthesis by exploring the latent distribution learned from the input distribution. Thus, the offline database density grids can be enhanced. We validated the results by varying epochs to map the learned latent distribution. However, we still have relatively low accuracy in the synthetic RSSI values, especially when applying a small number of epochs, i.e., 10 and 100. When we applied epoch number 1000, the error was relatively low (-3dBm average error) in the sampled position. Our preliminary assumption is that the dataset is small for VAE learning, and probably the 3-by-3 RSSI-to-image size assumption could still be inadequate.","","978-1-6654-8584-5","10.1109/ECTI-CON54298.2022.9795409","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9795409","deep learning;indoor localization;fingerprint technique;variational autoencoders;RSSI","Location awareness;Deep learning;Fluctuations;Costs;Databases;Fingerprint recognition;Telecommunications","indoor navigation;indoor radio;learning (artificial intelligence);RSSI;telecommunication computing","fingerprinting-based indoor localization;vast offline database;long effort;variational autoencoders;popular deep generative models;offline database issues;received signal strength indicator;RSSI directly;localization parameter;synthetic RSSI values;actual measurement campaign;VAE implementation results;input distribution;offline database density grids;learned latent distribution;VAE learning;RSSI-to-image size assumption;deep generative model-based RSSI synthesis;deep learning;researchers","","","","14","IEEE","16 Jun 2022","","","IEEE","IEEE Conferences"
"Generating Musical Sequences with a Given Emotion","J. Grekow","Faculty of Computer Science, Bialystok University of Technology, Bialystok, Poland","2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","6 Jan 2022","2021","","","1941","1946","This article presents the process of building a system generating music content of a specified emotion. As the emotion labels, four basic emotions: happy, angry, sad, relaxed, which correspond to the four quarters of Russell’s model, were used. Conditional variational autoencoder using a recurrent neural network for sequence processing was used as a generative model. The obtained results in the form of the generated music examples with a specific emotion are convincing in their structure and sound. The generated examples were evaluated through comparison with the training set.","2577-1655","978-1-6654-4207-7","10.1109/SMC52423.2021.9658604","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9658604","Generative models;music generation;music emotion;variational autoencoder","Training;Emotion recognition;Recurrent neural networks;Conferences;Computational modeling;Buildings;Music","directed graphs;emotion recognition;music;recurrent neural nets","emotion labels;Russell model;conditional variational autoencoder;recurrent neural network;sequence processing;musical sequence generation","","","","18","IEEE","6 Jan 2022","","","IEEE","IEEE Conferences"
"Equivalent Circuit Theory-Assisted Deep Learning for Accelerated Generative Design of Metasurfaces","Z. Wei; Z. Zhou; P. Wang; J. Ren; Y. Yin; G. F. Pedersen; M. Shen","Department of the Electronic Systems, Aalborg University, Aalborg, Denmark; Department of the Electronic Systems, Aalborg University, Aalborg, Denmark; Department of the Electronic Systems, Aalborg University, Aalborg, Denmark; National Key Laboratory of Antennas and Microwave Technology, Xidian University, Xi’an, China; National Key Laboratory of Antennas and Microwave Technology, Xidian University, Xi’an, China; Department of the Electronic Systems, Aalborg University, Aalborg, Denmark; Department of the Electronic Systems, Aalborg University, Aalborg, Denmark","IEEE Transactions on Antennas and Propagation","27 Jul 2022","2022","70","7","5120","5129","In this article, we propose an equivalent circuit theory-assisted deep learning approach to accelerate the design of metasurfaces. By combining the filter equivalent circuit theory and a sophisticated deep learning model, designers can achieve efficient metasurface designs. Compared with most existing metasurface generative design methods that rely on arbitrarily generated training dataset (TDS), the proposed method can adaptively produce highly relevant and low-noise training samples under the guidance of filter equivalent circuit theory, resulting in a significantly narrowed target solution space and improved model training efficiency. Furthermore, we select the variational autoencoder (VAE) as a generative model, which can compress the raw training samples into a lower-dimensional latent space where optimization methods, such as genetic algorithm, can be more efficiently executed to find the optimal design than a brute-force search. To verify the effectiveness of the proposed method, we apply it in the creation of three examples of frequency selective surfaces (FSSs), presenting wide-band, dual-band, and band-stop responses. Experimental results show that the proposed method can realize much faster and more stable convergence than deep learning design methods without domain knowledge.","1558-2221","","10.1109/TAP.2022.3152592","China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9721703","Frequency selective surface (FSS);generative design;inverse design;variational autoencoder (VAE)","Metasurfaces;Equivalent circuits;Training;Design methodology;Band-pass filters;Inductance;Data models","circuit analysis computing;deep learning (artificial intelligence);equivalent circuits;frequency selective surfaces;genetic algorithms","deep learning design methods;accelerated generative design;low-noise training samples;metasurface generative design methods;arbitrarily generated training dataset;TDS;variational autoencoder;VAE;lower-dimensional latent space;optimization methods;brute-force search;frequency selective surfaces;FSS;band-stop responses;dual-band responses;wide-band responses;filter equivalent circuit theory-assisted deep learning approach","","","","37","IEEE","25 Feb 2022","","","IEEE","IEEE Journals"
"Paraphrase Generation Based on VAE and Pointer-Generator Networks","L. Ravuru; H. Choi; K. M. Siddarth; H. Lee; I. Hwang","Samsung Research, Samsung Electronics Co. Ltd., Seoul, Korea; Samsung Research, Samsung Electronics Co. Ltd., Seoul, Korea; Samsung Research, Samsung Electronics Co. Ltd., Seoul, Korea; Samsung Research, Samsung Electronics Co. Ltd., Seoul, Korea; Samsung Research, Samsung Electronics Co. Ltd., Seoul, Korea","2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)","20 Feb 2020","2019","","","860","866","Paraphrase generation is a challenging task that involves expressing the meaning of a sentence using synonyms or different phrases, either to achieve variations or a certain stylistic response. Most previous sequence-to-sequence (Seq2Seq) models focus on either generating variations or preserving the content. We mainly address the issue of preserving the content in a sentence while generating diverse paraphrases. In this paper, we propose a novel approach for paraphrase generation using variational autoencoder (VAE) and Pointer Generator Network (PGN). The proposed model uses a copy mechanism to control the content transfer, a VAE to introduce variations and a training technique to restrict the gradient flow for efficient learning. Our evaluations on QUORA and MS COCO datasets show that our model outperforms the state-of-the-art approaches and the generated paraphrases are highly diverse as well as consistent with their original meaning.","","978-1-7281-0306-8","10.1109/ASRU46091.2019.9003874","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003874","Paraphrase Generation;Variational Autoencoder;Pointer Generator Network;Sequence to Sequence;Long Short-Term Memory (LSTM)","Decoding;Training;Task analysis;Logic gates;Generators;Knowledge based systems;Semantics","gradient methods;learning (artificial intelligence);natural language processing;neural nets","paraphrase generation;VAE;Pointer-Generator networks;sequence-to-sequence models;Seq2Seq;variational autoencoder;QUORA dataset;MS COCO dataset;gradient flow","","","","34","","20 Feb 2020","","","IEEE","IEEE Conferences"
"SmartSSO - A Deep Learning Platform for Automated Account Linkage in Federated Identity Management","S. D. Varnosfaderani; P. Kasprzak; C. Pohl; R. Yahyapour","Institute of Informatics, Georg-August-Universität Göttingen, Göttingen, Germany; Gesellschaft für Wissenschaftliche Datenverarbeitung mbH Göttingen (GWDG), Göttingen, Germany; Gesellschaft für Wissenschaftliche Datenverarbeitung mbH Göttingen (GWDG), Göttingen, Germany; Institute of Informatics, Georg-August-Universität Göttingen, Göttingen, Germany","2021 IEEE International Conference on Omni-Layer Intelligent Systems (COINS)","2 Sep 2021","2021","","","1","8","User identity linkage (UIL) refers to linking users’ assets and identities across social networks. With the rapid growth of social media in our day-to-day life, UIL’s importance has gone beyond being just a research topic, and it has become a necessary precondition for critical tasks like fraud detection.However, only a few models have been proposed to tackle UIL in different domains than social networks. This limitation becomes even more evident in academic federated identity management (FIM) domains. Service providers (SP) deal with restricted users’ data in these environments, and often data related to connections between entities and resources (i.e., network-based information) such as friends associations or the clients’ inclinations is not available.This research addresses the account linkage (AL) problem for organizations inside federated environments with limited or no access to users’ data. In the proposed model, we focus on analyzing users’ habits and behavior during login processes by utilizing a Variational Autoencoder’s (VAE) latent space. The learned structure in this space is used to derive related accounts owned by one user.To the best of our knowledge, the proposed model is the first approach attempting to solve the AL problem inside an academic FIM domain with its high requirements regarding data security and limited users’ information. Preliminary results show that the proposed model could achieve almost 90% accuracy in linking accounts possessed by one user.","","978-1-6654-3156-9","10.1109/COINS51742.2021.9524207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9524207","Federated Identity Management;Level of Assurance;Linking Accounts;Automated Account Linkage;Deep Learning;Variational AutoEncoder","Couplings;Deep learning;Analytical models;Social networking (online);Data security;Conferences;Organizations","deep learning (artificial intelligence);fraud;Internet;security of data;social networking (online)","SmartSSO;deep learning platform;automated account linkage;user identity linkage;social networks;social media;UIL;fraud detection;academic federated identity management;service providers;network-based information;academic FIM domain;data security;variational autoencoder","","","","27","","2 Sep 2021","","","IEEE","IEEE Conferences"
"MolBit: De novo Drug Design via Binary Representations of SMILES for avoiding the Posterior Collapse Problem","J. Choi; S. Seo; J. Park; S. Park","UBLBio Corporation, Suwon, Gyeonggi-do, Republic of Korea; UBLBio Corporation, Suwon, Gyeonggi-do, Republic of Korea; Department of Computer Science, Yonsei University, Seoul, Republic of Korea; Department of Computer Science, Yonsei University, Seoul, Republic of Korea","2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","14 Jan 2022","2021","","","364","367","Deep generative models for molecular generation have accelerated the development of de novo drug design by introducing how to generate novel molecular structures expressed in simplified molecular-input line-entry system (SMILES) or molecular graph formats. Numerous drug design studies have proposed combinations of variational autoencoder (VAE) and autoregressive generators such as recurrent neural networks (RNNs) to generate SMILES strings. However, RNN-VAE has one notorious issue, called posterior collapse, in which different latent vectors produce indistinguishable molecular distributions. In this study, we proposed a Gumbel-Softmax-based generative model, MolBit, and a genetic algorithm-based molecular property optimization method. We confirmed that the proposed model avoided the posterior collapse problem and outperformed the existing drug design models with SMILES.","","978-1-6654-0126-5","10.1109/BIBM52615.2021.9669668","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669668","drug design;variational autoencoder;posterior collapse;Gumbel-Softmax;genetic algorithm","Drugs;Recurrent neural networks;Conferences;Biological system modeling;Optimization methods;Generators;Bioinformatics","autoregressive processes;deep learning (artificial intelligence);drugs;genetic algorithms;graph theory;molecular biophysics;molecular configurations;pharmaceutical technology;recurrent neural nets","molecular generation;de novo drug design;molecular structures;molecular graph formats;autoregressive generators;recurrent neural networks;SMILES strings;RNN-VAE;molecular distributions;Gumbel-Softmax-based generative model;MolBit;genetic algorithm-based molecular property optimization method;posterior collapse;drug design;binary representations;deep generative models;simplified molecular-input line-entry system;variational autoencoder","","","","16","IEEE","14 Jan 2022","","","IEEE","IEEE Conferences"
"Normalizing Flow-Based Probability Distribution Representation Detector for Hyperspectral Anomaly Detection","X. Li; S. Yu; S. Chen; L. Zhao","Department of Electrical Engineering, Zhejiang University, Hangzhou, China; Department of Electrical Engineering, Zhejiang University, Hangzhou, China; Department of Electrical Engineering, Zhejiang University, Hangzhou, China; Department of Computer Science, Hangzhou Dianzi University, Hangzhou, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","28 Jun 2022","2022","15","","4885","4896","Due to the powerful reconstruction ability, deep learning based hyperspectral anomaly detection methods have been prevalent in recent years. However, the capability of neural networks and the meaning of latent space remains unexplainable to some extent. To address the issue, we propose a normalizing flow-based probability distribution representation detector (NF-PDRD) for hyperspectral anomaly detection in this article, which clarifies the capability of the model from a probabilistic perspective. The framework first utilizes the variational autoencoder to acquire the probability distribution representation with the mean vector and standard deviation vector for the original data. Subsequently, we introduce a normalizing flow to transform the Gaussian approximate posterior to a more complex distribution, making the model generative and expressive. We finally accomplish the detection process with the extracted probabilistic representation data using the strategy of Gaussian mixture model estimation to fully leverage the spatial information. Experimental results on both synthetic and real data sets demonstrate the outstanding performance of the proposed NF-PDRD.","2151-1535","","10.1109/JSTARS.2022.3182538","National Natural Science Foundation of China(grant numbers:62171404); Joint Fund of the Ministry of Education of China(grant numbers:8091B022118); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9795242","Anomaly detection;hyperspectral imagery (HSI);normalizing flows;probability representation;variational autoencoder (VAE)","Anomaly detection;Detectors;Probability distribution;Feature extraction;Hyperspectral imaging;Gaussian distribution;Computer architecture","data handling;deep learning (artificial intelligence);Gaussian processes;geophysical image processing;hyperspectral imaging;mixture models;probability;statistical distributions","normalizing flow-based probability distribution representation detector;hyperspectral anomaly detection;extracted probabilistic representation data;deep learning;neural networks;variational autoencoder;mean vector;standard deviation;Gaussian approximate posterior;Gaussian mixture model estimation;NF-PDRD","","","","44","CCBYNCND","13 Jun 2022","","","IEEE","IEEE Journals"
"Synthetic PPG Signal Generation to Improve Coronary Artery Disease Classification: Study With Physical Model of Cardiovascular System","O. Mazumder; R. Banerjee; D. Roy; S. Bhattacharya; A. Ghose; A. Sinha","TCS Research, Tata Consultancy Services Ltd., Kolkata, West Bengal, India; TCS Research, Tata Consultancy Services Ltd., Kolkata, West Bengal, India; TCS Research, Tata Consultancy Services Ltd., Kolkata, West Bengal, India; TCS Research, Tata Consultancy Services Ltd., Kolkata, West Bengal, India; TCS Research, Tata Consultancy Services Ltd., Kolkata, West Bengal, India; TCS Research, Tata Consultancy Services Ltd., Kolkata, West Bengal, India","IEEE Journal of Biomedical and Health Informatics","5 May 2022","2022","26","5","2136","2146","This paper presents a novel approach of generating synthetic Photoplethysmogram (PPG) data using a physical model of the cardiovascular system to improve classifier performance with a combination of synthetic and real data. The physical model is an in-silico cardiac computational model, consisting of a four-chambered heart with electrophysiology, hemodynamic, and blood pressure auto-regulation functionality. Starting with a small number of measured PPG data, the cardiac model is used to synthesize healthy as well as PPG time-series pertaining to coronary artery disease (CAD) by varying pathophysiological parameters. A Variational Autoencoder (VAE) structure is proposed to derive a statistical feature space for CAD classification. Results are presented in two perspectives namely, (i) using artificially reduced real disease data and (ii) using all the real disease data. In both cases, by augmenting with the synthetic data for training, the performance (sensitivity, specificity) of the classifier changes from (i) (0.65, 1) to (1, 0.9) and (ii) (1, 0.95) to (1, 1). The proposed hybrid approach of combining physical modelling and statistical feature space selection generates realistic PPG data with pathophysiological interpretation and can outperform a baseline Generative Adversarial Network (GAN) architecture with a relatively small amount of real data for training. This proposed method could aid as a substitution technique for handling the problem of bulk data required for training machine learning algorithms for cardiac health-care applications.","2168-2208","","10.1109/JBHI.2022.3147383","Tata Consultancy Services; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9699075","Cardiac computational model;coronary artery disease;photoplethysmogram;synthetic data;variational autoencoder","Solid modeling;Electrocardiography;Diseases;Data models;Training;Hemodynamics;Bioinformatics","blood;blood vessels;cardiology;cardiovascular system;diseases;feature extraction;haemodynamics;image classification;learning (artificial intelligence);medical computing;medical image processing;medical signal processing;patient monitoring;pattern classification","coronary artery disease classification;physical model;cardiovascular system;synthetic Photoplethysmogram data;classifier performance;in-silico cardiac computational model;blood pressure auto-regulation functionality;measured PPG data;cardiac model;PPG time-series pertaining;Variational Autoencoder structure;statistical feature space;CAD classification;disease data;synthetic data;realistic PPG data;baseline Generative Adversarial Network architecture;bulk data;synthetic PPG signal generation","Algorithms;Cardiovascular System;Coronary Artery Disease;Hemodynamics;Humans;Machine Learning","","","41","IEEE","1 Feb 2022","","","IEEE","IEEE Journals"
"CQ-VAE: Coordinate Quantized VAE for Uncertainty Estimation with Application to Disk Shape Analysis from Lumbar Spine MRI Images","L. Qian; J. Chen; T. Urakov; W. Gu; L. Liang","Department of Computer Science, University of Miami, Coral Gables, FL, USA; Department of Computer Science, University of Miami, Coral Gables, FL, USA; Department of Neurological Surgery, University of Miami, Coral Gables, FL, USA; Department of Mechanical and Aerospace Engineering, University of Miami, Coral Gables, FL, USA; Department of Computer Science, University of Miami, Coral Gables, FL, USA","2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA)","23 Feb 2021","2020","","","580","585","Ambiguity is inevitable in medical images, which often results in different image interpretations (e.g. object boundaries or segmentation maps) from different human experts. Thus, a model that learns the ambiguity and outputs a probability distribution of the target, would be valuable for medical applications to assess the uncertainty of diagnosis. In this paper, we propose a powerful generative model to learn a representation of ambiguity and to generate probabilistic outputs. Our model, named Coordinate Quantization Variational Autoencoder (CQ-VAE) employs a discrete latent space with an internal discrete probability distribution by quantizing the coordinates of a continuous latent space. As a result, the output distribution from CQ-VAE is discrete. During training, Gumbel-Softmax sampling is used to enable backpropagation through the discrete latent space. A matching algorithm is used to establish the correspondence between model-generated samples and ""ground-truth"" samples, which makes a trade-off between the ability to generate new samples and the ability to represent training samples. Besides these probabilistic components to generate possible outputs, our model has a deterministic path to output the best estimation. We demonstrated our method on a lumbar disk image dataset, and the results show that our CQ-VAE can learn lumbar disk shape variation and uncertainty.","","978-1-7281-8470-8","10.1109/ICMLA51294.2020.00097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9356321","uncertainty;shape regression;discrete latent space;variational autoencoder","Training;Uncertainty;Shape;Linear regression;Estimation;Probabilistic logic;Probability distribution","backpropagation;biomedical MRI;feature extraction;image classification;image segmentation;learning (artificial intelligence);medical image processing;probability;statistical distributions","CQ-VAE;Gumbel-Softmax sampling;discrete latent space;model-generated samples;lumbar disk image dataset;lumbar disk shape variation;uncertainty estimation;lumbar spine MRI;medical images;image interpretations;human experts;medical applications;probabilistic outputs;internal discrete probability distribution;coordinate quantization variational autoencoder;coordinate quantized VAE","","","","12","","23 Feb 2021","","","IEEE","IEEE Conferences"
"Clustering Single-Cell RNA Sequencing Data by Deep Learning Algorithm","L. Bai; Y. Zhu; M. Yi","Hubei Key Laboratory of Advanced Control and Intelligent Automation for Complex Systems, Engineering Research Center of Intelligent Technology for Geo-Exploration, Ministry of Education, Wuhan, China; Hubei Key Laboratory of Advanced Control and Intelligent Automation for Complex Systems, Engineering Research Center of Intelligent Technology for Geo-Exploration, Ministry of Education, Wuhan, China; School of Mathematics and Physics, China University of Geosciences (Wuhan), Wuhan, China","2021 IEEE 9th International Conference on Bioinformatics and Computational Biology (ICBCB)","25 Jun 2021","2021","","","118","124","The development of single-cell RNA sequencing (scRNA-seq) technology provides a good opportunity to study cell heterogeneity and diversity. Especially, clustering is an important step in scRNA-seq analysis. With the advance of technology, many scRNA-seq data are available, which develop a lot of clustering methods. However, the existing methods usually employ the gene expression data, ignoring the related information between genes and the structure information in data. Therefore, we propose a new method (NDMgcn) to reconstruct the gene expression data based on the association of gene network, and cluster the data by Variational Autoencoder (V AE) and Graph Convolutional Network (GCN). The V AE learns low-dimensional information and the GCN learns structural information. The experimental results indicate that NDMgcn outperforms other popular algorithms in terms of NMI and ARI metrics. It provides a new insight for clustering scRNA-seq data from the network perspective.","","978-1-6654-1500-2","10.1109/ICBCB52223.2021.9459219","China University of Geosciences (Wuhan)(grant numbers:CUGGC02); National Natural Science Foundation of China(grant numbers:11675060,91730301); Hubei Provincial Natural Science Foundation of China(grant numbers:2015CFA010); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9459219","Single-cell RNA sequencing;Variational Autoencoder;Graph Convolutional Network;reconstruct data","Sequential analysis;Network topology;RNA;Clustering methods;Neural networks;Clustering algorithms;Optimization methods","bioinformatics;cellular biophysics;convolutional neural nets;genetics;genomics;graph theory;learning (artificial intelligence);molecular biophysics;pattern clustering","clustering single-cell RNA sequencing data;deep learning algorithm;cell heterogeneity;scRNA-seq analysis;clustering methods;gene expression data;structure information;gene network;low-dimensional information;structural information;clustering scRNA-seq data;graph convolutional network;GCN;variational autoencoder;VAE","","","","22","IEEE","25 Jun 2021","","","IEEE","IEEE Conferences"
"Efficient Deep Learning-driven Approach for PM2.5 Forecasting at Different Locations in Spain","A. Dairi; F. Harrou; Y. Sun","Universit&#x00E9; des Sciences et de la Technologie d'Oran Mohamed-Boudiaf USTOMB Laboratoire de Recherche SIMPA (Signal, Image, Parole), Oran, Alg&#x00E9;rie; Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia","2021 IEEE 3rd Eurasia Conference on Biomedical Engineering, Healthcare and Sustainability (ECBIOS)","13 Aug 2021","2021","","","173","178","Forecasting dust pollution is necessary for achieving satisfactory air quality. This work proposes an improved deep learning-based forecasting approach for PM2.5 concentration forecasting. Importantly, this approach introduces an improved variational autoencoder (VAE) model by incorporating a bidirectional gated recurrent unit (BiGRU) at the encoder side of the VAE model. The forecasting quality of the coupled model is verified via comparisons with the traditional VAE model when forecasting PM2.5 concentration time-series data. The assessment is carried out using five statistical metrics. PM2.5 datasets from different stations in Spain are used in this study. Results reveal the accuracy of the improved VAE model for PM2.5 concentration forecasting over the traditional VAE, LSTM, GRU, biLSTM, and BiGRU.","","978-1-7281-9304-5","10.1109/ECBIOS51820.2021.9510462","King Abdullah University of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9510462","PM2.5 pollution;time-series forecasting;deep learning;variational autoencoder;self-attention","Recurrent neural networks;Pollution;Atmospheric modeling;Predictive models;Feature extraction;Data models;Pollution measurement","aerosols;air pollution;dust;learning (artificial intelligence);time series","improved deep learning-based forecasting;PM2.5 concentration forecasting;improved variational autoencoder model;bidirectional gated recurrent unit;forecasting quality;coupled model;traditional VAE model;PM2.5 concentration time-series data;Spain;improved VAE model;learning-driven approach;forecasting dust pollution;satisfactory air quality","","","","42","IEEE","13 Aug 2021","","","IEEE","IEEE Conferences"
"Future Network Traffic Matrix Synthesis and Estimation Based on Deep Generative Models","G. Kakkavas; M. Kalntis; V. Karyotis; S. Papavassiliou","School of Electrical & Computer Engineering, National Technical University of Athens, Iroon Polytechniou 9, Zografou, Athens, Greece; School of Electrical & Computer Engineering, National Technical University of Athens, Iroon Polytechniou 9, Zografou, Athens, Greece; Department of Informatics, Ionian University, Tsirigoti Square 7, Corfu, Greece; School of Electrical & Computer Engineering, National Technical University of Athens, Iroon Polytechniou 9, Zografou, Athens, Greece","2021 International Conference on Computer Communications and Networks (ICCCN)","31 Aug 2021","2021","","","1","8","Traffic matrices (TMs) contain information that is essential for network management, traffic engineering, and anomaly detection. However, constructing a TM through direct traffic measurements has a high administrative and computational cost. A more feasible approach is to estimate the TM from the easily obtainable link load measurements. In this paper, we address the issue of traffic matrix estimation (TME) from link loads using a deep generative model – namely, a variational autoencoder (VAE) – to solve the respective ill-posed inverse problem. In particular, we train the VAE with historical data (previously observed TMs) and we leverage the trained decoder to transform TME into a minimization problem in the latent space, which in turn can be solved by employing a gradient-based optimizer. Furthermore, the trained decoder can be used for traffic matrix synthesis, i.e., for generating synthetic TM examples that have “similar” properties to the samples of the training set. Finally, we explore the incremental optimization of the sequence of objectives constructed from the sequence of decoders that we obtain at different stages of the VAE training. The performance of the proposed methods is evaluated using a publicly available dataset of actual traffic matrices recorded in a real backbone network.","2637-9430","978-1-6654-1278-0","10.1109/ICCCN52240.2021.9522222","European Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9522222","Network monitoring;network tomography;traffic matrix estimation;deep learning;variational autoencoder.","Training;Atmospheric measurements;Inverse problems;Computational modeling;Estimation;Transforms;Telecommunication traffic","computer network management;decoding;gradient methods;inverse problems;matrix algebra;neural nets;telecommunication computing;telecommunication traffic","real backbone network;decoders sequence;incremental optimization;TME transform;historical data;traffic matrices;deep generative models;network traffic matrix estimation;network traffic matrix synthesis;observed TM;ill-posed inverse problem;variational autoencoder;link loads;TME;traffic matrix estimation;link load measurements;computational cost;high administrative cost;direct traffic measurements;anomaly detection;traffic engineering;network management;deep generative model;backbone network;actual traffic matrices;VAE training;training set;synthetic TM examples;trained decoder;gradient-based optimizer;minimization problem","","","","31","","31 Aug 2021","","","IEEE","IEEE Conferences"
"An Attention Mechanism for Combination of CNN and VAE for Image-Based Malware Classification","T. V. Dao; H. Sato; M. Kubo","Department of Computer Science, National Defense Academy, Yokosuka, Japan; Department of Computer Science, National Defense Academy, Yokosuka, Japan; Department of Computer Science, National Defense Academy, Yokosuka, Japan","IEEE Access","19 Aug 2022","2022","10","","85127","85136","Currently, malware is increasing in both number and complexity dramatically. Several techniques and methodologies have been proposed to detect and neutralize malicious software. However, traditional methods based on the signatures or behaviors of malware often require considerable computational time and resources for feature engineering. Recent studies have applied machine learning to the problems of identifying and classifying malware families. Combining many state-of-the-art techniques has become popular but choosing the appropriate combination with high efficiency is still a problem. The classification performance has been significantly improved using complex neural network architectures. However, the more complex the network, the more resources it requires. This paper proposes a novel lightweight architecture by combining small Convolutional Neural Networks and advanced Variational Autoencoder, enhanced by channel and spatial attention mechanisms. We achieve overperformance and sufficient time through various experiments compared to other cutting-edge techniques using unbalanced and balanced Malimg datasets.","2169-3536","","10.1109/ACCESS.2022.3198072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9854888","Malware classification;variational autoencoder;channel attention;spatial attention;latent representation;information security","Malware;Feature extraction;Computer architecture;Convolutional neural networks;Computational modeling;Codes;Behavioral sciences;Encoding;Information security;Channel capacity","convolutional neural nets;image classification;invasive software;learning (artificial intelligence);neural net architecture","convolutional neural networks;spatial attention mechanisms;cutting-edge techniques;image-based malware classification;malicious software;feature engineering;complex neural network architectures;lightweight architecture;advanced variational autoencoder;balanced Malimg datasets","","","","44","CCBY","11 Aug 2022","","","IEEE","IEEE Journals"
"Segtransvae: Hybrid Cnn - Transformer with Regularization for Medical Image Segmentation","Q. -D. Pham; H. Nguyen-Truong; N. N. Phuong; K. N. A. Nguyen; C. D. T. Nguyen; T. Bui; S. Q. H. Truong","VinBrain JSC., Vietnam; Vietnam National University, Ho Chi Minh City, Vietnam; VinBrain JSC., Vietnam; Vietnam National University, Ho Chi Minh City, Vietnam; Vin University, Vietnam; VinBrain JSC., Vietnam; VinBrain JSC., Vietnam","2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)","26 Apr 2022","2022","","","1","5","Current research on deep learning for medical image segmentation exposes their limitations in learning either global semantic information or local contextual information. To tackle these issues, a novel network named SegTransVAE is proposed in this paper. SegTransVAE is built upon encoder-decoder architecture, exploiting transformer with the variational autoencoder (VAE) branch to the network to reconstruct the input images jointly with segmentation. To the best of our knowledge, this is the first method combining the success of CNN, transformer, and VAE. Evaluation on various recently introduced datasets shows that SegTransVAE outperforms previous methods in Dice Score and 95%-Haudorff Distance while having comparable inference time to a simple CNN-based architecture network. The source code is available at: https://github.com/itruonghai/SegTransVAE.","1945-8452","978-1-6654-2923-8","10.1109/ISBI52829.2022.9761417","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761417","Transformer;Variational Autoencoder;Medical Image Segmentation;MRI brain tumor;CT kidney","Deep learning;Image segmentation;Three-dimensional displays;Codes;Semantics;Training data;Transformers","cellular neural nets;image segmentation;learning (artificial intelligence);medical image processing","VAE;input images;simple CNN-based architecture network;hybrid cnn - transformer;medical image segmentation;deep learning;global semantic information;local contextual information;encoder-decoder architecture;variational autoencoder branch","","","","12","IEEE","26 Apr 2022","","","IEEE","IEEE Conferences"
"Disentangling Latent Groups Of Factors","N. Inoue; R. Yamada; R. Kawakami; I. Sato","Tokyo Institute of Technology; Tokyo Institute of Technology; Denso IT Laboratory, Inc.; Denso IT Laboratory, Inc.","2021 IEEE International Conference on Image Processing (ICIP)","23 Aug 2021","2021","","","2548","2552","This paper proposes a framework for training variational autoencoders (VAEs) for image distributions that have latent groups of factors. Our key idea is to introduce a mechanism to predict the factor group an image belongs to while simultaneously disentangling factors in it. More specifically, we propose an architecture consisting of three components: an encoder, a decoder, and a factor-group prediction header. The first two components are trained with a VAE objective, and the last one is trained with the proposed algorithm using the loss of unsupervised contrastive learning. In experiments, we designed a task in which more than one group of factors were entangled by combining multiple datasets and demonstrated the effectiveness of the proposed framework. The Mutual Information Gap score was improved from 0.089 to 0.125 on a merged dataset of Color-dSprites, 3DShapes, and MPI3D.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506505","Variational autoencoders;Disentangling factors;Metric learning;Unsupervised contrastive learning","Training;Image processing;Conferences;Image retrieval;Prediction algorithms;Decoding;Task analysis","feature extraction;image classification;image colour analysis;image representation;neural nets;unsupervised learning","variational autoencoder training;image distributions;factor-group prediction header;VAE objective;unsupervised contrastive learning;factor latent group disentanglement;encoder;decoder;mutual information gap score;Color-dSprites;3DShapes;MPI3D","","","","25","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"Deep Latent-Variable Models for Controllable Molecule Generation","Y. Du; Y. Wang; F. Alam; Y. Lu; X. Guo; L. Zhao; A. Shehu","Dept. of Computer Science, George Mason University, Fairfax, VA, USA; Dept. of Computer Science, George Mason University, Fairfax, VA, USA; Dept. of Computer Science, George Mason University, Fairfax, VA, USA; Dept. of Computer Science, George Mason University, Fairfax, VA, USA; Dept. of Computer Science, George Mason University, Fairfax, VA, USA; Dept. of Computer Science, Emory University, Atlanta, GA, USA; Dept. of Computer Science, George Mason University, Fairfax, VA, USA","2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","14 Jan 2022","2021","","","372","375","Representation learning via deep generative models is opening a new avenue for small molecule generation in silico. Linking chemical and biological space remains a key challenge. In this paper, we debut a graph-based variational autoencoder framework to address this challenge under the umbrella of disentangled representation learning. The framework permits several inductive biases that connect the learned latent factors to molecular properties. Evaluation on diverse benchmark datasets shows that the resulting models are powerful and open up an exciting line of research on controllable molecule generation in support of cheminformatics, drug discovery, and other application settings.","","978-1-6654-0126-5","10.1109/BIBM52615.2021.9669692","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669692","Graph variational autoencoder;disentangled representation;molecule generation;controllable generation","Representation learning;Drugs;Biological system modeling;Conferences;Aerospace electronics;Benchmark testing;Bioinformatics","drugs;graph theory;learning (artificial intelligence)","latent-variable models;controllable molecule generation;deep generative models;linking chemical;biological space;graph-based variational autoencoder framework;disentangled representation learning;learned latent factors","","","","17","IEEE","14 Jan 2022","","","IEEE","IEEE Conferences"
"D2D-TM: A Cycle VAE-GAN for Multi-Domain Collaborative Filtering","L. Nguyen; T. Ishigaki","Graduate School of Economics and Management, Tohoku University, Sendai, Japan; Graduate School of Economics and Management, Tohoku University, Sendai, Japan","2019 IEEE International Conference on Big Data (Big Data)","24 Feb 2020","2019","","","1175","1180","Multi-domain recommender systems can solve cold-start problems and can support cross-selling of products and services. We propose a model to address these difficulties by extracting homogeneous and divergent features from domains. Our Domain-to-Domain Translation Model (D2D-TM), which is based on generative adversarial networks (GANs) and variational autoencoders (VAEs), uses the user interaction history. Domain cycle consistency (CC) constrains the inter-domain relations. Results obtained from experimentation demonstrate the great effectiveness of the proposed system when compared to several state-of-the-art systems.","","978-1-7281-0858-2","10.1109/BigData47090.2019.9006461","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9006461","Collaborative Filtering;Deep Learning;General Adversarial Network;Recommender System;Variational Autoencoder;Cycle consistency","Feature extraction;Generative adversarial networks;Gallium nitride;Generators;Recommender systems;History;Clothing","collaborative filtering;neural nets;recommender systems","D2D-TM;cycle VAE-GAN;multidomain recommender systems;cold-start problems;homogeneous features;divergent features;domain-to-domain translation model;GANs;variational autoencoders;VAEs;user interaction history;inter-domain relations;domain cycle consistency;multidomain collaborative filtering","","","","13","","24 Feb 2020","","","IEEE","IEEE Conferences"
"Synthetic Hyperspectral Images With Controllable Spectral Variability and Ground Truth","B. Palsson; M. O. Ulfarsson; J. R. Sveinsson","Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland","IEEE Geoscience and Remote Sensing Letters","1 Mar 2022","2022","19","","1","5","Spectral variability in hyperspectral images (HSIs) has received lot of attention over the last years, especially in the field of hyperspectral unmixing (HU) where it is a major issue. In this letter, we propose a method utilizing a variational autoencoder (VAE) for creating synthetic HSIs having controllable degree of spectral variability from existing HSIs with established ground-truth abundance maps and endmembers. Such synthetic datasets can be useful for developing HU methods that can handle spectral variability in HSIs. We investigate how the variability in the synthetic images differs from the original images and perform blind unmixing experiments using generated datasets to illustrate the effect of increasing variability. Code for method is available at https://github.com/burknipalsson/vae_synthetic_hsi.","1558-0571","","10.1109/LGRS.2022.3150245","Icelandic Research Fund(grant numbers:174075-05,207233-051); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9707767","Deep learning;hyperspectral unmixing (HU);neural network;synthetic hyperspectral images (HSIs);variational autoencoder (VAE)","Codes;Hyperspectral imaging;Decoding;Image reconstruction;Training;Sensors;Data models","geophysical image processing;hyperspectral imaging;image denoising;neural nets;remote sensing","synthetic hyperspectral images;controllable spectral variability;ground truth;hyperspectral unmixing;synthetic HSIs;controllable degree;synthetic datasets;HU methods;ground-truth abundance maps;variational autoencoder","","","","20","IEEE","8 Feb 2022","","","IEEE","IEEE Journals"
"A Secure Federated Learning Mechanism for Data Privacy Protection","H. Lin; W. Liu; X. Wang","Engineering Research Center of Cyber Security and Education Informatization, Fujian Province University, Fuzhou, Fujian, China; Engineering Research Center of Cyber Security and Education Informatization, Fujian Province University, Fuzhou, Fujian, China; Engineering Research Center of Cyber Security and Education Informatization, Fujian Province University, Fuzhou, Fujian, China","2021 20th International Conference on Ubiquitous Computing and Communications (IUCC/CIT/DSCI/SmartCNS)","3 Mar 2022","2021","","","25","31","The combination of big data and machine learning brings more convenience to people, but also brings security risks of data privacy leakage. The services provided by traditional machine learning can no longer meet the needs of privacy protection. The emergence of federated learning technology has alleviated privacy disclosure threats, however adversaries can still infer from the data model or even reconstruct the raw training data, causing the data privacy of the raw training data to be leaked. To solve this problem, we propose a secure federated learning mechanism based on variational autoencoder (VAE) to resist inference attacks. Participants use raw data to generate forged data through a VAE and train a local model with forged data, thereby protecting the data privacy and guaranteeing the quality of the global model. The experimental results show that the proposed secure federated learning mechanism can guarantee the high accuracy of the global model while reducing the probability of the raw data of the participants being reconstructed.","","978-1-6654-6667-7","10.1109/IUCC-CIT-DSCI-SmartCNS55181.2021.00019","National Natural Science Foundation of China(grant numbers:U1905211,61702103); Natural Science Foundation of Fujian Province(grant numbers:2020J01167,2020J01169); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9719602","Federated Learning;Variational Autoencoder;Data Privacy","Data privacy;Privacy;Computational modeling;Training data;Machine learning;Resists;Collaborative work","data protection;learning (artificial intelligence);neural nets;probability","secure federated learning mechanism;data privacy protection;Big Data;security risks;data privacy leakage;privacy disclosure threats;machine learning;variational autoencoder;VAE;probability","","","","23","IEEE","3 Mar 2022","","","IEEE","IEEE Conferences"
"EM-LAST: Effective Multidimensional Latent Space Transport for an Unpaired Image-to-Image Translation With an Energy-Based Model","G. Han; J. Min; S. W. Han","School of Industrial and Management Engineering, Korea University, Seongbuk-gu, Seoul, Republic of Korea; School of Industrial and Management Engineering, Korea University, Seongbuk-gu, Seoul, Republic of Korea; School of Industrial and Management Engineering, Korea University, Seongbuk-gu, Seoul, Republic of Korea","IEEE Access","15 Jul 2022","2022","10","","72839","72849","For an unpaired image-to-image translation to work effectively, the latent space of each image domain must be well-designed. The codes of each style must be translated toward the target while preserving the parts corresponding to the source content. In general, most Variational Autoencoder (VAE)-based models use a one-dimensional latent space. However, to apply high dimensional methodologies such as vector quantization, controlling a multidimensional latent space is necessary. In this study, among the VAE-based models that use relatively complex multidimensional latent spaces, we apply an Energy-Based Model and Vector-Quantized VAE v2, with the latter as the main model. We show that among the latent spaces that represent each image domain, the importance of each feature at the top and bottom latent spaces must be interpreted differently for appropriate translation. Therefore, we argue that simply understanding the features of latent space composition well can show effective image translation results. We also present various analyses and visual outcomes of multidimensional latent space transport.","2169-3536","","10.1109/ACCESS.2022.3189352","Brain Korea 21 FOUR; Korea TechnoComplex Foundation Grant(grant numbers:R2112651); Korea University(grant numbers:K2107521,K2202151); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9819914","Energy-based model;image-to-image translation;Langevin dynamics;multidimensional latent space;vector-quantized variational autoencoder","Task analysis;Aerospace electronics;Visualization;Generative adversarial networks;Deep learning;Decoding;Encoding","computational geometry;data visualisation;feature extraction;knowledge based systems;learning (artificial intelligence);neural nets;regression analysis;vector quantisation;visual perception","image domain;appropriate translation;latent space composition;effective image translation results;effective multidimensional latent space transport;unpaired image-to-image translation;energy-based model;Variational Autoencoder-based models;one-dimensional latent space;VAE-based models;relatively complex multidimensional latent spaces;Vector-Quantized VAE v;main model","","","","41","CCBYNCND","7 Jul 2022","","","IEEE","IEEE Journals"
"Automated Antenna Testing Using Encoder-Decoder-based Anomaly Detection","H. H. -H. Hsu; J. Xu; R. Sama; M. Kovatsch","Huawei Tech. / TU Munich, Munich, Germany; Huawei Technologies, Munich, Germany; Huawei Technologies, Munich, Germany; Huawei Technologies, Munich, Germany","2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA)","25 Jan 2022","2021","","","135","142","We propose a new method for testing antenna arrays that records the radiating electromagnetic (EM) field using an absorbing material and evaluating the resulting thermal image series through an AI using a conditional encoder-decoder model. Given the power and phase of the signals fed into each array element, we are able to reconstruct normal sequences through our trained model and compare it to the real sequences observed by a thermal camera. These thermograms only contain low-level patterns such as blobs of various shapes. A contour-based anomaly detector can then map the reconstruction error matrix to an anomaly score to identify faulty antenna arrays and increase the classification F-measure (F-M) by up to 46%. We show our approach on the time series thermograms collected by our antenna testing system. Conventionally, a variational autoencoder (VAE) learning observation noise may yield better results than a VAE with a constant noise assumption. However, we demonstrate that this is not the case for anomaly detection on such low-level patterns for two reasons. First, the baseline metric reconstruction probability, which incorporates the learned observation noise, fails to differentiate anomalous patterns. Second, the area under the receiver operating characteristic (ROC) curve of a VAE with a lower observation noise assumption achieves 11.83% higher than that of a VAE with learned noise.","","978-1-6654-4337-1","10.1109/ICMLA52953.2021.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680009","Anomaly Detection;Autoencoder;Variaitonal Autoencoder;Antenna Array;Testing;Automation","Antenna measurements;Analytical models;Time series analysis;Machine learning;Detectors;Image sequences;Anomaly detection","acoustic signal processing;antenna arrays;antenna testing;cameras;feature extraction;Gaussian processes;image classification;image reconstruction;image sequences;infrared imaging;learning (artificial intelligence);neural nets;object detection;probability;statistical analysis;time series","encoder-decoder-based anomaly detection;radiating electromagnetic field;absorbing material;resulting thermal image series;conditional encoder-decoder model;array element;normal sequences;trained model;thermal camera;low-level patterns;contour-based anomaly detector;reconstruction error matrix;anomaly score;faulty antenna arrays;classification F-measure;time series thermograms;antenna testing system;variational autoencoder learning observation noise;VAE;constant noise assumption;baseline metric reconstruction probability;learned observation noise;differentiate anomalous patterns;lower observation noise assumption;learned noise","","","","28","IEEE","25 Jan 2022","","","IEEE","IEEE Conferences"
"Many-to-Many Unsupervised Speech Conversion From Nonparallel Corpora","Y. K. Lee; H. W. Kim; J. G. Park","Artificial Intelligence Research Laboratory, Electronics and Telecommunications Research Institute (ETRI), Daejeon, South Korea; Artificial Intelligence Research Laboratory, Electronics and Telecommunications Research Institute (ETRI), Daejeon, South Korea; Artificial Intelligence Research Laboratory, Electronics and Telecommunications Research Institute (ETRI), Daejeon, South Korea","IEEE Access","17 Feb 2021","2021","9","","27278","27286","We address a nonparallel data-driven many-to-many speech modeling and multimodal style conversion method. In this work, we train a speech conversion model for multiple domains rather than a specific source and target domain pair, and we generate diverse output speech signals from a given source domain speech by transferring some speech style-related characteristics while preserving its linguistic content information. The proposed method comprises a variational autoencoder (VAE)-based many-to-many speech conversion network with a Wasserstein generative adversarial network (WGAN) and a skip-connected autoencoder-based self-supervised learning network. The proposed conversion network trains the models by decomposing the spectral features of the input speech signal into a content factor that represents domain-invariant information and a style factor that represents domain-related information to automatically estimate the various speech styles of each domain, and the network converts the input speech signal to another domain using the computed content factor with the target style factor we want to change. Diverse and multimodal outputs can be generated by sampling different style factors. We also train models in a stable manner and improve the quality of generated outputs by sharing the discriminator of the VAE-based speech conversion network and that of the self-supervised learning network. We apply the proposed method to speaker conversion and perform the perceptual evaluations. Experimental results revealed that the proposed method obtained high accuracy of converted spectra, significantly improved the sound quality and speaker similarity of the converted speech, and contributed to stable model training.","2169-3536","","10.1109/ACCESS.2021.3058382","Electronics and Telecommunications Research Institute (ETRI) funded by the Korean Government (Core Technology Research for Self-Improving Integrated Artificial Intelligence System)(grant numbers:20ZS1100); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9351918","Speech conversion (SC);non-parallel SC;many-to-many SC;Wasserstein generative adversarial network (WGAN);variational auto-encoder (VAE);self-supervised learning","Decoding;Generative adversarial networks;Gallium nitride;Training;Data models;Speech","natural language processing;speech codecs;speech coding;supervised learning","perceptual evaluations;sound quality;spectral features;WGAN;many-to-many speech conversion network;variational autoencoder;self-supervised learning network;skip-connected autoencoder;computed content factor;domain-related information;domain-invariant information;input speech signal;Wasserstein generative adversarial network;linguistic content information;speech style-related characteristics;source domain speech;diverse output speech signals;speech conversion model;multimodal style conversion method;nonparallel data-driven many-to-many speech;nonparallel corpora;unsupervised speech conversion;stable model training;speaker conversion;VAE-based speech conversion network","","2","","39","CCBYNCND","10 Feb 2021","","","IEEE","IEEE Journals"
"Structured variational inference for simulating populations of radio galaxies","D. J. Bastien; A. M. M. Scaife; H. Tang; M. Bowles; F. Porter","Jodrell Bank Centre for Astrophysics, Department of Physics and Astronomy, University of Manchester, Oxford Road, Manchester M13 9PL, UK; Square Kilometre Array Organisation, Jodrell Bank Observatory, Macclesfield SK11 9FT, UK; david.bastien@postgrad.manchester.ac.uk; Jodrell Bank Centre for Astrophysics, Department of Physics and Astronomy, University of Manchester, Oxford Road, Manchester M13 9PL, UK; The Alan Turing Institute, Euston Road, London NW1 2DB, UK; Jodrell Bank Centre for Astrophysics, Department of Physics and Astronomy, University of Manchester, Oxford Road, Manchester M13 9PL, UK; Jodrell Bank Centre for Astrophysics, Department of Physics and Astronomy, University of Manchester, Oxford Road, Manchester M13 9PL, UK; Jodrell Bank Centre for Astrophysics, Department of Physics and Astronomy, University of Manchester, Oxford Road, Manchester M13 9PL, UK","Monthly Notices of the Royal Astronomical Society","20 Jul 2021","2021","503","3","3351","3370","We present a model for generating postage stamp images of synthetic Fanaroff–Riley Class I and Class II radio galaxies suitable for use in simulations of future radio surveys such as those being developed for the Square Kilometre Array. This model uses a fully connected neural network to implement structured variational inference through a variational autoencoder and decoder architecture. In order to optimize the dimensionality of the latent space for the autoencoder, we introduce the radio morphology inception score (RAMIS), a quantitative method for assessing the quality of generated images, and discuss in detail how data pre-processing choices can affect the value of this measure. We examine the 2D latent space of the VAEs and discuss how this can be used to control the generation of synthetic populations, whilst also cautioning how it may lead to biases when used for data augmentation.","1365-2966","","10.1093/mnras/stab588","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9491279","methods: statistical;surveys;radio continuum: galaxies","","","","","","","","","20 Jul 2021","","","OUP","OUP Journals"
"Learning to Cluster with Auxiliary Tasks: A Semi-Supervised Approach","J. A. Figueroa; A. R. Rivera","Institute of Computing, University of Campinas, Campinas, SP, Brazil; Institute of Computing, University of Campinas, Campinas, SP, Brazil","2017 30th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)","7 Nov 2017","2017","","","141","148","In this paper, we propose a model to learn a feature-category latent representation of the data, that is guided by a semi-supervised auxiliary task. The goal of this auxiliary task is to assign labels to unlabeled data and regularize the feature space. Our model is represented by a modified version of a Categorical Variational Autoencoder, i.e., a probabilistic generative model that approximates a categorical distribution with variational inference. We benefit from the autoencoder's architecture to learn powerful representations with Deep Neural Networks in an unsupervised way, and to optimize the model with semi-supervised tasks. We derived a loss function that integrates the probabilistic model with our auxiliary task to guide the learning process. Experimental results show the effectiveness of our method achieving more than 90% of clustering accuracy by using only 100 labeled examples. Moreover we show that the learned features have discriminative properties that can be used for classification.","2377-5416","978-1-5386-2219-3","10.1109/SIBGRAPI.2017.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8097305","deep learning;generative models;clustering;semi-supervised learning;probabilistic models","Probabilistic logic;Data models;Computer architecture;Neural networks;Transforms;Decoding","learning (artificial intelligence);neural nets;pattern clustering;probability","learning process;feature-category latent representation;semisupervised auxiliary task;unlabeled data;feature space;probabilistic generative model;categorical variational autoencoder;clustering;categorical distribution;variational inference;autoencoder architecture;deep neural networks;loss function","","4","","31","","7 Nov 2017","","","IEEE","IEEE Conferences"
"Unsupervised Evaluation of Lidar Domain Adaptation","C. Hubschneider; S. Roesler; J. M. Zöllner","FZI Research Center for Information Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology (KIT), Germany; Karlsruhe Institute of Technology (KIT), Germany","2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)","24 Dec 2020","2020","","","1","6","In this work, we investigate the potential of latent representations generated by Variational Autoencoders (VAE) to analyze and distinguish between real and synthetic data. Although the details of the domain adaptation task are not the focus of this work, we use the example of simulated lidar data adapted by a generative model to match real lidar data. To assess the resulting adapted data, we evaluate the potential of latent representations learned by a VAE. During training, the VAE aims to reduce the input data to a fixed-dimensional feature vector, while also enforcing stochastic independence between the latent variables. These properties can be used to define pseudometrics to make statements about generative models that perform domain adaptation tasks. The variational autoencoder is trained on real target data only and is subsequently used to generate distributions of feature vectors for data coming from different data sources such as simulations or the output of Generative Adversarial Networks.","","978-1-7281-4149-7","10.1109/ITSC45102.2020.9294540","Ministry of Economic Affairs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9294540","","Laser radar;Three-dimensional displays;Semantics;Task analysis;Training;Data models;Training data","feature extraction;image classification;learning (artificial intelligence);optical radar;stochastic processes;unsupervised learning","unsupervised evaluation;lidar domain adaptation;latent representations;Variational Autoencoders;VAE;synthetic data;domain adaptation task;simulated lidar data;generative model;resulting adapted data;fixed-dimensional feature vector;latent variables;variational autoencoder;Generative Adversarial Networks","","1","","19","","24 Dec 2020","","","IEEE","IEEE Conferences"
"Robust Semisupervised Deep Generative Model Under Compound Noise","X. Chen","SAS Institute Inc., Cary, NC 27513 USA (e-mail: steven.xu.chen@gmail.com)","IEEE Transactions on Neural Networks and Learning Systems","","2021","PP","99","1","15","Semisupervised learning has been widely applied to deep generative model such as variational autoencoder. However, there are still limited work in noise-robust semisupervised deep generative model where the noise exists in both of the data and the labels simultaneously, which are referred to as outliers and noisy labels or compound noise. In this article, we propose a novel noise-robust semisupervised deep generative model by jointly tackling the noisy labels and outliers in a unified robust semisupervised variational autoencoder randomized generative adversarial network (URSVAE-GAN). Typically, we consider the uncertainty of the information of the input data in order to enhance the robustness of the variational encoder toward the noisy data in our unified robust semisupervised variational autoencoder (URSVAE). Subsequently, in order to alleviate the detrimental effects of noisy labels, a denoising layer is integrated naturally into the semisupervised variational autoencoder so that the variational inference is conditioned on the corrected labels. Moreover, to enhance the robustness of the variational inference in the presence of outliers, the robust β-divergence measure is employed to derive the novel variational lower bound, which already achieves competitive performance. This further motivates the development of URSVAE-GAN that collapses the decoder of URSVAE and the generator of a robust semisupervised generative adversarial network into one unit. By applying the end-to-end denoising scheme in the joint optimization, the experimental results demonstrate the superiority of the proposed framework by the evaluating on image classification and face recognition tasks and comparing with the state-of-the-art approaches.","2162-2388","","10.1109/TNNLS.2021.3105080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9523628","Joint optimization;overfitting;regularization;robust divergence;variational inference.","Noise measurement;Data models;Semisupervised learning;Uncertainty;Generative adversarial networks;Deep learning;Compounds","","","","","","","IEEE","26 Aug 2021","","","IEEE","IEEE Early Access Articles"
"Deep Diffusion Processes for Active Learning of Hyperspectral Images","A. Tasissa; D. Nguyen; J. M. Murphy","Department of Mathematics, Tufts University, USA; Department of Mathematics, University of Maryland, College Park, USA; Department of Mathematics, Tufts University, USA","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","3665","3668","A method for active learning of hyperspectral images (HSI) is proposed, which combines deep learning with diffusion processes on graphs. A deep variational autoencoder extracts smoothed, denoised features from a high-dimensional HSI, which are then used to make labeling queries based on graph diffusion processes. The proposed method combines the robust representations of deep learning with the mathematical tractability of diffusion geometry, and leads to strong performance on real HSI.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553196","hyperspectral images;variational autoencoders;deep clustering;active learning;semi-supervised learning;diffusion geometry","Geometry;Deep learning;Diffusion processes;Geoscience and remote sensing;Feature extraction;Labeling;Hyperspectral imaging","","","","4","","24","","12 Oct 2021","","","IEEE","IEEE Conferences"
"Optimal configuration planning of multi-energy microgird based on deep joint generation of source-load-temperature scenarios","N. Huang; W. Wang; G. Cai","School of Electrical Engineering, Key Laboratory of Modern Power System Simulation and Control & Renewable Energy Technology (Northeast Electric Power University), Jilin 132012, China; School of Electrical Engineering, Key Laboratory of Modern Power System Simulation and Control & Renewable Energy Technology (Northeast Electric Power University), Jilin 132012, China; School of Electrical Engineering, Key Laboratory of Modern Power System Simulation and Control & Renewable Energy Technology (Northeast Electric Power University), Jilin 132012, China","CSEE Journal of Power and Energy Systems","","2020","PP","99","1","12","An optimal configuration method of a multi-energy microgrid system based on the deep joint generation of source-load-temperature scenarios is proposed to improve the multi-energy complementation and the reliability of energy supply in extreme scenarios. Firstly, based on the historical meteorological data, the typical meteorological clusters and extreme temperature types are obtained. Then, to reflect the uncertainty of energy consumption and renewable energy output in different weather types, a deep joint generation model of radiation-electric load-temperature scenario based on denoising variational autoencoder is established for each weather module. At the same time, to cover the potential high energy consumption scenarios with extreme temperatures, the extreme scenarios with fewer data samples are expanded. After that, the scenarios are reduced by clustering analysis. The typical days of different typical scenarios and extreme temperature scenarios are determined, and the cooling and heating loads are determined by temperature. Finally, the optimal configuration of a multi-energy microgrid system is carried out. Experiments show that the optimal configuration based on the extreme scenarios and typical scenarios can improve the power supply reliability of the system. The proposed method can accurately capture the complementary potential of energy sources. And the economy of the system configuration is improved by 14.56%.","2096-0042","","10.17775/CSEEJPES.2020.01090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9171690","Multi-energy microgrid system;Optimal configuration planning;deep joint generation;Denoising variational autoencoders","Load modeling;Cogeneration;Micromechanical devices;Microgrids;Reliability engineering","","","","2","","","","19 Aug 2020","","","CSEE","CSEE Early Access Articles"
"Temporal Network Embedding for Link Prediction via VAE Joint Attention Mechanism","P. Jiao; X. Guo; X. Jing; D. He; H. Wu; S. Pan; M. Gong; W. Wang","Center of Biosafety Research and Strategy, Law School, Tianjin University, Tianjin 300350, China.; College of Intelligence and Computing, Tianjin University, Tianjin 300350, China.; College of Intelligence and Computing, Tianjin University, Tianjin 300350, China.; College of Intelligence and Computing, Tianjin University, Tianjin 300350, China (e-mail: pjiao@tju.edu.cn); Center for Applied Mathematics, Tianjin University, Tianjin 300072, China.; Department of Data Science and AI, Faculty of Information Technology, Monash University, Clayton, VIC 3800, Australia.; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Xidian University, Xi'an 710071, China.; College of Intelligence and Computing, Tianjin University, Tianjin 300350, China.","IEEE Transactions on Neural Networks and Learning Systems","","2021","PP","99","1","14","Network representation learning or embedding aims to project the network into a low-dimensional space that can be devoted to different network tasks. Temporal networks are an important type of network whose topological structure changes over time. Compared with methods on static networks, temporal network embedding (TNE) methods are facing three challenges: 1) it cannot describe the temporal dependence across network snapshots; 2) the node embedding in the latent space fails to indicate changes in the network topology; and 3) it cannot avoid a lot of redundant computation via parameter inheritance on a series of snapshots. To overcome these problems, we propose a novel TNE method named temporal network embedding method based on the VAE framework (TVAE), which is based on a variational autoencoder (VAE) to capture the evolution of temporal networks for link prediction. It not only generates low-dimensional embedding vectors for nodes but also preserves the dynamic nonlinear features of temporal networks. Through the combination of a self-attention mechanism and recurrent neural networks, TVAE can update node representations and keep the temporal dependence of vectors over time. We utilize parameter inheritance to keep the new embedding close to the previous one, rather than explicitly using regularization, and thus, it is effective for large-scale networks. We evaluate our model and several baselines on synthetic data sets and real-world networks. The experimental results demonstrate that TVAE has superior performance and lower time cost compared with the baselines.","2162-2388","","10.1109/TNNLS.2021.3084957","National Key Research and Development Program of China(grant numbers:2018YFC0809804); National Natural Science Foundation of China(grant numbers:61902278,62071327,61876128); Tianjin Municipal Science and Technology Project(grant numbers:19ZXZNGX00030); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9449483","Link prediction;self-attention mechanism;temporal network embedding (TNE);variational autoencoder (VAE).","Network topology;Task analysis;Predictive models;Topology;Logic gates;Social networking (online);Matrix decomposition","","","","2","","","IEEE","9 Jun 2021","","","IEEE","IEEE Early Access Articles"
"Asymmetric Training of Generative Adversarial Network for High Fidelity SAR Image Generation","Y. Huang; W. Mei; S. Liu; T. Li","School of Software Engineering Chongqing University of Posts and Telecommunications, Chongqing, China; School of Software Engineering Chongqing University of Posts and Telecommunications, Chongqing, China; School of Software Engineering Chongqing University of Posts and Telecommunications, Chongqing, China; School of Software Engineering Chongqing University of Posts and Telecommunications, Chongqing, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1576","1579","In practical application, the research of synthetic aperture radar (SAR) target recognition has fallen into a bottle-neck due to the lack of samples. Data argumentation methods based on generative adversarial networks (GAN) have received widespread attention in solving this type of few-shot sample problem. However, the generated images suffer from various shortcomings, such as lack of diversity, low signal-to-noise ratio, blur, etc. In this article, the VAE-WGANGP is proposed, which combines GAN and variational autoencoder (VAE) to alleviate these shortcomings. The innovations of this paper are as follows: firstly, the generator of GAN is replaced with VAE, which constructs an asymmetric network ensuring the stability of GAN training; secondly, the asymmetric loss function is composed of four parts, including reconstruction loss, divergence loss, adversarial loss, and gradient penalty. In this way, the problem of gradient explosion or gradient disappearance is alleviated. The experimental results with the MSTAR dataset show that the images generated by the proposed model outperform the advanced technology with many similar deep features and achieve significant improvement in the target recognition accuracy rate.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884284","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884284","Generative adversarial network (GAN);variational autoencoder (VAE);synthetic aperture radar (SAR);data augmentation;automatic target recognition (ATR)","Training;Technological innovation;Target recognition;Azimuth;Generative adversarial networks;Radar polarimetry;Stability analysis","image denoising;radar imaging;radar resolution;synthetic aperture radar","low signal-to-noise ratio;VAE-WGANGP;asymmetric network;GAN training;asymmetric loss function;adversarial loss;target recognition accuracy rate;asymmetric training;generative adversarial network;high fidelity SAR image generation;synthetic aperture radar target recognition;bottle-neck;data argumentation methods;few-shot sample problem","","","","8","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Integration of Niching Technique and Surrogate-assisted Method with Particle Swarm Optimization for History Matching","X. Ma; K. Zhang","School of Petroleum Engineering, China University of Petroleum (Huadong), Qingdao, China; School of Petroleum Engineering, China University of Petroleum (Huadong), Qingdao, China","2021 3rd International Conference on Intelligent Control, Measurement and Signal Processing and Intelligent Oil Field (ICMSP)","20 Aug 2021","2021","","","249","253","History matching can provide reliable numerical models for reservoir management and development by assimilating the historical production data into prior geological realizations. It is usually a typical inverse problem with multiple solutions. However, efficiently obtaining multiple posterior solutions is still challenging for most existing history matching algorithms. In this paper, we present a novel algorithm to tackle this problem, which integrates the niching technique and surrogate-assisted method into the particle swarm optimization (PSO), in which, the niching technique can improve the exploration ability and maintain the diversity of the population, while the surrogate-assisted method is focused on accelerating the convergence. Additionally, the convolutional variational autoencoder (CVAE), a deep learning model, is adopted to map the high-dimensional spatially uncertain parameters such as permeability and porosity to low-dimensional latent variables. Experimental results show that the proposed algorithm has good convergence and sampling ability for history matching problems.","","978-1-6654-3715-8","10.1109/ICMSP53480.2021.9513346","National Natural Science Foundation of China(grant numbers:51722406,52074340,51874335); Shandong Provincial Natural Science Foundation(grant numbers:JQ201808); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9513346","history matching;niching technique;surrogate model;particle swarm optimization;variational autoencoder","Sociology;Signal processing algorithms;Production;Reservoirs;Permeability;History;Reliability","evolutionary computation;geology;hydrocarbon reservoirs;inverse problems;learning (artificial intelligence);particle swarm optimisation;petroleum industry","evolutionary algorithm;surrogate assisted method;geological realization;existing history matching algorithms;multiple posterior solutions;typical inverse problem;historical production data;reservoir management;reliable numerical models;history matching problems;niching technique;particle swarm optimization","","","","6","IEEE","20 Aug 2021","","","IEEE","IEEE Conferences"
"A Novel Two-Stage Generation Framework for Promoting the Persona-Consistency and Diversity of Responses in Neural Dialog Systems","T. Shi; Y. Song","Mihoyo, Shanghai, China.; State Key Laboratory of Power Transmission Equipment System Security and New Technology, the Chongqing Key Laboratory of Intelligent Unmanned Systems, School of Automation, Chongqing University, Chongqing 400044, China (e-mail: ydsong@cqu.edu.cn)","IEEE Transactions on Neural Networks and Learning Systems","","2021","PP","99","1","11","Although quite natural for human beings to communicate based on their own personality in daily life, it is rather challenging for neural dialog systems to do the same. This is because the general dialog systems are difficult to generate diverse responses while at the same time maintaining consistent persona information. Existing methods basically focus on merely one of them, ignoring either of them will reduce the quality of dialog. In this work, we propose a two-stage generation framework to promote the persona-consistency and diversity of responses. In the first stage, we propose a persona-guided conditional variational autoencoder (persona-guided CVAE) to generate diverse responses, and the main difference when compared with general CVAE-based model is that we use additional dialog attribute to assist the latent variables to encode the effective information in the response and further use it as a guiding vector for response generation. In the second stage, we employ persona-consistency checking module and the response rewriting module to mask the inconsistent word in the generated response prototype and rewrite it to more consistent. Automatic evaluation results demonstrate that the proposed model is able to generate diverse and persona-consistent responses.","2162-2388","","10.1109/TNNLS.2021.3105584","National Natural Science Foundation of China(grant numbers:61860206008,61773081,61933012,61833013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9525043","Persona-consistency check;persona-guided conditional variational autoencoder (persona-guided CVAE);response rewrite;two-stage generation framework.","Prototypes;Decoding;Task analysis;Generative adversarial networks;Encoding;Recurrent neural networks;Probability distribution","","","","","","","IEEE","30 Aug 2021","","","IEEE","IEEE Early Access Articles"
"ControlVAE: Tuning, Analytical Properties, and Performance Analysis","H. Shao; Z. Xiao; S. Yao; D. Sun; A. Zhang; S. Liu; T. Wang; J. Li; T. Abdelzaher","Computer Science, College of William & Mary, 8604 Williamsburg, Virginia, United States, (e-mail: hshao5@illinois.edu); Computational and Applied Mathematics, University of Chicago, 2462 Chicago, Illinois, United States, 60637-5418 (e-mail: zxiao@uchicago.edu); Computer Science, George Mason University, 3298 Fairfax, Virginia, United States, (e-mail: shuochao@gmu.edu); Computer Science, University of Illinois at Urbana-Champaign, 14589 Urbana, Illinois, United States, (e-mail: dsun18@illinois.edu); Amazon Web Services, Palo Alto, California, United States, (e-mail: astonz@amazon.com); Computer Science, University of Illinois at Urbana-Champaign, 14589 Urbana, Illinois, United States, (e-mail: sl29@illinois.edu); Computer Science, University of Illinois at Urbana-Champaign, 14589 Urbana, Illinois, United States, 61801-3028 (e-mail: tianshi3@illinois.edu); Computer Science Department, University of Illinois at Urbana-Champaign, 14589 Urbana, Illinois, United States, (e-mail: jinyang7@illinois.edu); Computer Science, University of Illinois at Urbana-Champaign, 14589 Urbana, Illinois, United States, 61801-3028 (e-mail: zaher@illinois.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2021","PP","99","1","1","This paper reviews the novel concept of a controllable variational autoencoder (ControlVAE), discusses its parameter tuning to meet application needs, derives its key analytic properties, and offers useful extensions and applications. ControlVAE combines control theory with the basic VAE to stabilize the KL-divergence of VAEs to a specified value. It leverages a non-linear PI controller, a variant of the proportional-integral-derivative (PID), to dynamically tune the weight of the KL-divergence in the evidence lower bound (ELBO). This allows us to precisely control the KL-divergence to a desired value that is effective in avoiding posterior collapse and learning disentangled representations. While prior work developed alternative techniques for controlling the KL divergence, we show that our PI controller has better stability properties and thus better convergence. To improve the ELBO of ControlVAE over that of the regular VAE, we provide a simplified theoretical analysis to inform the choice of set point for the KL-divergence of ControlVAE. Evaluation results show that ControlVAE achieves better reconstruction quality than other methods for comparable disentanglement. For language modeling, it can avoid posterior collapse and improve the diversity of generated text. Moreover, it can change the optimization trajectory, improving the ELBO and the reconstruction quality for image generation.","1939-3539","","10.1109/TPAMI.2021.3127323","Army Research Laboratory(grant numbers:W911NF-09-2-0053;W911NF-17-2-0196); Defense Advanced Research Projects Agency(grant numbers:W911NF-17-C-0099); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9618835","Variational autoencoders (VAEs);ControlVAE;PID controller;Disentangled representation learning;language modeling;image generation","Image reconstruction;Training;PI control;Optimization;Image synthesis;Task analysis;Tuning","","","","","","","IEEE","17 Nov 2021","","","IEEE","IEEE Early Access Articles"
"Collaborative Decision-Reinforced Self-Supervision for Attributed Graph Clustering","P. Zhu; J. Li; Y. Wang; B. Xiao; S. Zhao; Q. Hu","College of Intelligence and Computing, Tianjin University, Tianjin 300350, China, and also with the Haihe Laboratory of Information Technology Application Innovation, Tianjin, China.; College of Intelligence and Computing, Tianjin University, Tianjin 300350, China.; College of Intelligence and Computing, Tianjin University, Tianjin 300350, China, and also with the Haihe Laboratory of Information Technology Application Innovation, Tianjin, China.; Department of Computer Science and Technology, Chongqing University of Posts and Telecommunication, Chongqing 400065, China.; College of Intelligence and Computing, Tianjin University, Tianjin 300350, China, and also with Automotive Data of China (Tianjin) Company Ltd., Tianjin 300300, China.; College of Intelligence and Computing, Tianjin University, Tianjin 300350, China, and also with the Haihe Laboratory of Information Technology Application Innovation, Tianjin, China.","IEEE Transactions on Neural Networks and Learning Systems","","2022","PP","99","1","13","Attributed graph clustering aims to partition nodes of a graph structure into different groups. Recent works usually use variational graph autoencoder (VGAE) to make the node representations obey a specific distribution. Although they have shown promising results, how to introduce supervised information to guide the representation learning of graph nodes and improve clustering performance is still an open problem. In this article, we propose a Collaborative Decision-Reinforced Self-Supervision (CDRS) method to solve the problem, in which a pseudo node classification task collaborates with the clustering task to enhance the representation learning of graph nodes. First, a transformation module is used to enable end-to-end training of existing methods based on VGAE. Second, the pseudo node classification task is introduced into the network through multitask learning to make classification decisions for graph nodes. The graph nodes that have consistent decisions on clustering and pseudo node classification are added to a pseudo-label set, which can provide fruitful self-supervision for subsequent training. This pseudo-label set is gradually augmented during training, thus reinforcing the generalization capability of the network. Finally, we investigate different sorting strategies to further improve the quality of the pseudo-label set. Extensive experiments on multiple datasets show that the proposed method achieves outstanding performance compared with state-of-the-art methods. Our code is available at https://github.com/Jillian555/TNNLS_CDRS.","2162-2388","","10.1109/TNNLS.2022.3171583","National Key Research and Development Program of China(grant numbers:2019YFB2101904); National Natural Science Foundation of China(grant numbers:62106174,61732011,61876127,61925602); China Postdoctoral Science Foundation(grant numbers:2021TQ0242,2021M690118); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9777842","Attributed graph clustering (AGC);collaborative training;self-supervised learning;variational graph autoencoder (VGAE).","Task analysis;Training;Automatic generation control;Representation learning;Collaboration;Convolution;Sorting","","","","","","","IEEE","18 May 2022","","","IEEE","IEEE Early Access Articles"
"Exploring Temporal Community Structure via Network Embedding","T. Li; W. Wang; P. Jiao; Y. Wang; R. Ding; H. Wu; L. Pan; D. Jin","College of Intelligence and Computing, Tianjin University, Tianjin 300350, China.; College of Intelligence and Computing, Tianjin University, Tianjin 300350, China.; School of Cyberspace, Hangzhou Dianzi University, Hangzhou 310018, China.; College of Intelligence and Computing, Tianjin University, Tianjin 300350, China.; College of Intelligence and Computing, Tianjin University, Tianjin 300350, China.; Center for Applied Mathematics, Tianjin University, Tianjin 300072, China.; College of Intelligence and Computing, Tianjin University, Tianjin 300350, China, and also with the Marine Science and Technology, Tianjin University, Tianjin 300072, China.; College of Intelligence and Computing, Tianjin University, Tianjin 300350, China.","IEEE Transactions on Cybernetics","","2022","PP","99","1","13","Temporal community detection is helpful to discover and analyze significant groups or clusters hidden in dynamic networks in the real world. A variety of methods, such as modularity optimization, spectral method, and statistical network model, has been developed from diversified perspectives. Recently, network embedding-based technologies have made significant progress, and one can exploit deep learning superiority to network tasks. Although some methods for static networks have shown promising results in boosting community detection by integrating community embedding, they are not suitable for temporal networks and unable to capture their dynamics. Furthermore, the dynamic embedding methods only model network varying without considering community structures. Hence, in this article, we propose a novel unsupervised dynamic community detection model, which is based on network embedding and can effectively discover temporal communities and model dynamic networks. More specifically, we propose the community prior by introducing the Gaussian mixture model (GMM) in the variational autoencoder, which can obtain community information and better model the evolutionary characteristics of community structure and node embedding by utilizing the variant of gated recurrent unit (GRU). Extensive experiments conducted in real-world and artificial networks demonstrate that our proposed model has a better effect on improving the accuracy of dynamic community detection.","2168-2275","","10.1109/TCYB.2022.3168343","National Natural Science Foundation of China(grant numbers:61902278,61806061,62003120,62071327); Intelligent Manufacturing Special Fund Project of Tianjin China(grant numbers:20201198); National Key Research and Development Program of Jiangxi China(grant numbers:20212ABCO3W12); Shenzhen Sustainable Development Project(grant numbers:KCXFZ20201221173013036); National Key Research and Development Program of China(grant numbers:2020YFC1522600); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9768181","Community detection;dynamic networks;network embedding;temporal community structure;variational autoencoder (VAE)","Heuristic algorithms;Hidden Markov models;Optimization;Task analysis;Clustering algorithms;Bayes methods;Uncertainty","","","","","","","IEEE","4 May 2022","","","IEEE","IEEE Early Access Articles"
"Occluded Face Restoration Based on Generative Adversarial Networks","M. Zhang; L. Huang; M. Zhu","School of Information & Electronic Engineering, Zhejiang Gongshang University, Hangzhou, China; School of Information & Electronic Engineering, Zhejiang Gongshang University, Hangzhou, China; School of Information & Electronic Engineering, Zhejiang Gongshang University, Hangzhou, China","2020 3rd International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE)","2 Jul 2020","2020","","","315","319","In recent years, the combination of Convolutional Neural Networks and Generative Adversarial Networks has played a huge potential in the field of face restoration. In order to effectively repair the large area of random occlusion face, this paper constructs an improved Generative Adversarial Networks model based on the Context Encoder, and proposes a self-localization occlusion face image restoration algorithm. Firstly, the occluded part of the face is marked by occlusion locator, and then the marked face image is sent to the generator of Generative Adversarial Networks for restoration. The model generator uses the Convolutional Neural Networks of the Variational Autoencoder structure, and adds the Batch Normalization layer in the model to enhance the information prediction ability of the generator. At the same time, the discriminator is constructed by combining with VGG19, and the discriminator is trained against the generator. Through the experiment on CelebA face data set, this algorithm is significantly better than other methods in the aspect of random large area occlusion face image restoration.","","978-1-7281-8143-1","10.1109/AEMCSE50948.2020.00074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9131308","face restoration;Generative Adversarial Networks;Variational Autoencoder;self localization","","convolutional neural nets;face recognition;image representation;image restoration","random occlusion face;self-localization occlusion face image restoration algorithm;marked face image;model generator;convolutional neural networks;CelebA face data;face restoration;improved generative adversarial networks model","","","","7","IEEE","2 Jul 2020","","","IEEE","IEEE Conferences"
"Preliminary tasks of unsupervised speech recognition based on unaligned audio and text data","Z. Kozhirbayev; T. Islamgozhayev; Z. Yessenbayev; A. Sharipbay","National Laboratory Astana, Nazarbayev University, Nur-Sultan, Kazakhstan; National Laboratory Astana, Nazarbayev University, Nur-Sultan, Kazakhstan; National Laboratory Astana, Nazarbayev University, Nur-Sultan, Kazakhstan; Faculty of Information Technologies, L.N. Gumilyov Eurasian National University, Nur-Sultan, Kazakhstan","2022 International Conference on Engineering & MIS (ICEMIS)","13 Oct 2022","2022","","","1","3","We present herein our work on the preliminary tasks of unsupervised speech recognition using only unaligned audio and text datasets. The motivation for this is the general progress in generative models. Using the assumption that the frequencies and contextual relationships of words are close in audio and text domains for the same language. The experiments on acoustic and test data using the variational autoencoder (VAE) architecture were conducted on word level. Our plan to extract the encoding part of the acoustic VAE and the decoding part of the text VAE to build a joint VAE.","","978-1-6654-5436-0","10.1109/ICEMIS56295.2022.9914249","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9914249","unsupervised speech recognition;word embedding;variational autoencoders","Frequency-domain analysis;Speech recognition;Acoustics;Encoding;Data models;Decoding;Speech synthesis","","","","","","20","IEEE","13 Oct 2022","","","IEEE","IEEE Conferences"
"Pilot Decontamination Scheme for mmWave Grant-free IoT Networks","S. Wu; Y. Shin","School of Electronic Engineering, Soongsil University, Seoul, Korea; School of Electronic Engineering, Soongsil University, Seoul, Korea","2022 IEEE VTS Asia Pacific Wireless Communications Symposium (APWCS)","10 Oct 2022","2022","","","150","154","In this paper, we propose a deep learning-based pilot decontamination scheme for mmWave grant-free IoT networks. Considering sporadic traffic in IoT networks, grant-free random access is inevitable and enables massive machine connections in IoT networks. Despite its great potential, grant-free random access is vulnerable to pilot contamination. To tackle the pilot contamination problem, we utilize the channel virtual representation to emphasize the characteristics of a mmWave channel. We utilize a variational autoencoder to reconstruct a decontaminated channel, and the simulation results validate the decontamination performance of the proposed scheme.","","978-1-6654-7121-3","10.1109/APWCS55727.2022.9906506","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9906506","grant-free IoT;mmWave;channel virtual representation;pilot decontamination;variational autoencoder","Wireless communication;Decontamination;Simulation;Asia;Magnetic heads;Reliability;Millimeter wave communication","","","","","","11","IEEE","10 Oct 2022","","","IEEE","IEEE Conferences"
"CSCAD: Correlation Structure-based Collective Anomaly Detection in Complex System","H. Qin; X. Zhan; Y. Zheng","the School of Computer Science and Technology, Xidian University, 47905 Xian, ShanXi, China; Institute for AI Industry Research, Tsinghua University, Beijing, Beijing, China; JD Urban Computing Business Unit, JD.com Inc, 539038 Beijing, Beijing, China","IEEE Transactions on Knowledge and Data Engineering","","2022","PP","99","1","1","Detecting anomalies in large complex systems is a critical and challenging task. The difficulties arise from several aspects. First, collecting ground truth labels or prior knowledge for anomalies is hard in real-world systems, which often lead to limited or no anomaly labels in the dataset. Second, anomalies in large systems usually occur in a collective manner due to the underlying dependency structure among devices or sensors. Lastly, real-time anomaly detection for high-dimensional data requires efficient algorithms that are capable of handling different types of data (i.e. continuous and discrete). We propose a correlation structure-based collective anomaly detection (CSCAD) model for high-dimensional anomaly detection problem in large systems, which is also generalizable to semi-supervised or supervised settings. Our framework utilize graph convolutional network combining a variational autoencoder to jointly exploit the feature space correlation and reconstruction deficiency of samples to perform anomaly detection. We propose an extended mutual information (EMI) metric to mine the internal correlation structure among different data features, which enhances the data reconstruction capability of CSCAD. The reconstruction loss and latent standard deviation vector of a sample obtained from reconstruction network can be perceived as two natural anomalous degree measures. An anomaly discriminating network can then be trained using low anomalous degree samples as positive samples, and high anomalous degree samples as negative samples. Experimental results on five public datasets demonstrate that our approach consistently outperforms all the competing baselines.","1558-2191","","10.1109/TKDE.2022.3154166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9740038","Anomaly Detection;Complex System;Variational Autoencoder;Correlation Mining;Unsupervised Learning;urban computing","Anomaly detection;Correlation;Sensors;Feature extraction;Data models;Loss measurement;Complex systems","","","","","","","IEEE","22 Mar 2022","","","IEEE","IEEE Early Access Articles"
"AstroVaDEr: astronomical variational deep embedder for unsupervised morphological classification of galaxies and synthetic image generation","A. Spindler; J. E. Geach; M. J. Smith","Centre for Astrophysics Research, School of Physics, Engineering & Computer Science, University of Hertfordshire, College Lane, Hatfield AL10 9AB, UK; Centre of Data Innovation Research, School of Physics, Engineering & Computer Science, University of Hertfordshire, College Lane, Hatfield AL10 9AB, UK; a.spindler@herts.ac.uk; Centre for Astrophysics Research, School of Physics, Engineering & Computer Science, University of Hertfordshire, College Lane, Hatfield AL10 9AB, UK; Centre of Data Innovation Research, School of Physics, Engineering & Computer Science, University of Hertfordshire, College Lane, Hatfield AL10 9AB, UK; Centre for Astrophysics Research, School of Physics, Engineering & Computer Science, University of Hertfordshire, College Lane, Hatfield AL10 9AB, UK; Centre of Data Innovation Research, School of Physics, Engineering & Computer Science, University of Hertfordshire, College Lane, Hatfield AL10 9AB, UK","Monthly Notices of the Royal Astronomical Society","12 Jul 2021","2021","502","1","985","1007","We present AstroVaDEr (Astronomical Variational Deep Embedder), a variational autoencoder designed to perform unsupervised clustering and synthetic image generation using astronomical imaging catalogues. The model is a convolutional neural network that learns to embed images into a low-dimensional latent space, and simultaneously optimizes a Gaussian Mixture Model (GMM) on the embedded vectors to cluster the training data. By utilizing variational inference, we are able to use the learned GMM as a statistical prior on the latent space to facilitate random sampling and generation of synthetic images. We demonstrate AstroVaDEr’s capabilities by training it on grey-scaled gri images from the Sloan Digital Sky Survey, using a sample of galaxies that are classified by Galaxy Zoo 2. An unsupervised clustering model is found that separates galaxies based on learned morphological features such as axial ratio, surface brightness profile, orientation, and the presence of companions. We use the learned mixture model to generate synthetic images of galaxies based on the morphological profiles of the Gaussian components. AstroVaDEr succeeds in producing a morphological classification scheme from unlabelled data, but unexpectedly places high importance on the presence of companion objects – demonstrating the importance of human interpretation. The network is scalable and flexible, allowing for larger data sets to be classified, or different kinds of imaging data. We also demonstrate the generative properties of the model, which allow for realistic synthetic images of galaxies to be sampled from the learned classification scheme. These can be used to create synthetic image catalogues or to perform image processing tasks such as deblending.","1365-2966","","10.1093/mnras/staa3670","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9480010","methods: data analysis;methods: observational;galaxies: general;galaxies: structure","","","","","","","","","12 Jul 2021","","","OUP","OUP Journals"
"Dual Adversarial Autoencoders for Clustering","P. Ge; C. -X. Ren; D. -Q. Dai; J. Feng; S. Yan","Intelligent Data Center, School of Mathematics, Sun Yat-sen University, Guangzhou, China; Intelligent Data Center, School of Mathematics, Sun Yat-sen University, Guangzhou, China; Intelligent Data Center, School of Mathematics, Sun Yat-sen University, Guangzhou, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Department of Electrical and Computer Engineering, National University of Singapore, Singapore","IEEE Transactions on Neural Networks and Learning Systems","3 Apr 2020","2020","31","4","1417","1424","As a powerful approach for exploratory data analysis, unsupervised clustering is a fundamental task in computer vision and pattern recognition. Many clustering algorithms have been developed, but most of them perform unsatisfactorily on the data with complex structures. Recently, adversarial autoencoder (AE) (AAE) shows effectiveness on tackling such data by combining AE and adversarial training, but it cannot effectively extract classification information from the unlabeled data. In this brief, we propose dual AAE (Dual-AAE) which simultaneously maximizes the likelihood function and mutual information between observed examples and a subset of latent variables. By performing variational inference on the objective function of Dual-AAE, we derive a new reconstruction loss which can be optimized by training a pair of AEs. Moreover, to avoid mode collapse, we introduce the clustering regularization term for the category variable. Experiments on four benchmarks show that Dual-AAE achieves superior performance over state-of-the-art clustering methods. In addition, by adding a reject option, the clustering accuracy of Dual-AAE can reach that of supervised CNN algorithms. Dual-AAE can also be used for disentangling style and content of images without using supervised information.","2162-2388","","10.1109/TNNLS.2019.2919948","National Natural Science Foundation of China(grant numbers:61572536,11631015,U1611265); Science and Technology Program of Guangzhou(grant numbers:201804010248); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8742794","AAE;clustering;deep generative models;latent variable;mutual information regularization","Mutual information;Training;Clustering methods;Clustering algorithms;Gallium nitride;Generative adversarial networks;Task analysis","computer vision;data analysis;image classification;inference mechanisms;learning (artificial intelligence);pattern clustering","computer vision;pattern recognition;adversarial training;unlabeled data;dual AAE;clustering regularization term;clustering accuracy;Dual adversarial autoencoders;exploratory data analysis;unsupervised clustering;variational inference;objective function;reconstruction loss;likelihood function;mutual information","","15","","45","IEEE","20 Jun 2019","","","IEEE","IEEE Journals"
"Uncertainty Inspired RGB-D Saliency Detection","J. Zhang; D. -P. Fan; Y. Dai; S. Anwar; F. Saleh; S. Aliakbarian; N. Barnes","School of Computing, ACRV, DATA61-CSIRO, The Australian National University, Canberra, ACT, Australia; CS, Nankai University, Tianjin, China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China; DATA61-CSIRO, Australian National University, Canberra, ACT, Australia; School of Computing, ACRV, The Australian National University, Canberra, ACT, Australia; School of Computing, ACRV, The Australian National University, Canberra, ACT, Australia; School of Computing, The Australian National University, Canberra, ACT, Australia","IEEE Transactions on Pattern Analysis and Machine Intelligence","4 Aug 2022","2022","44","9","5761","5779","We propose the first stochastic framework to employ uncertainty for RGB-D saliency detection by learning from the data labeling process. Existing RGB-D saliency detection models treat this task as a point estimation problem by predicting a single saliency map following a deterministic learning pipeline. We argue that, however, the deterministic solution is relatively ill-posed. Inspired by the saliency data labeling process, we propose a generative architecture to achieve probabilistic RGB-D saliency detection which utilizes a latent variable to model the labeling variations. Our framework includes two main models: 1) a generator model, which maps the input image and latent variable to stochastic saliency prediction, and 2) an inference model, which gradually updates the latent variable by sampling it from the true or approximate posterior distribution. The generator model is an encoder-decoder saliency network. To infer the latent variable, we introduce two different solutions: i) a Conditional Variational Auto-encoder with an extra encoder to approximate the posterior distribution of the latent variable; and ii) an Alternating Back-Propagation technique, which directly samples the latent variable from the true posterior distribution. Qualitative and quantitative results on six challenging RGB-D benchmark datasets show our approach's superior performance in learning the distribution of saliency maps. The source code is publicly available via our project page: https://github.com/JingZhang617/UCNet.","1939-3539","","10.1109/TPAMI.2021.3073564","National Natural Science Foundation of China(grant numbers:61871325,61671387,61620106008,61572264); National Key Research and Development Program of China(grant numbers:2018AAA0102803); Tianjin Natural Science Foundation(grant numbers:17JCJQJC43700); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9405467","Uncertainty;RGB-D saliency detection;conditional variational autoencoders;alternating back-propagation","Saliency detection;Predictive models;Uncertainty;Pipelines;Data models;Labeling;Training","backpropagation;feature extraction;image coding;image colour analysis;learning (artificial intelligence);object detection;stochastic processes","uncertainty inspired RGB-D saliency detection;stochastic framework;point estimation problem;saliency map;deterministic learning pipeline;saliency data labeling process;generative architecture;probabilistic RGB-D saliency detection;labeling variations;generator model;stochastic saliency prediction;inference model;true distribution;approximate posterior distribution;encoder-decoder saliency network;conditional variational autoencoder;RGB-D benchmark datasets;saliency maps;alternating back-propagation technique","","6","","119","IEEE","15 Apr 2021","","","IEEE","IEEE Journals"
"A Three-Stage Ensemble Short-Term Wind Power Prediction Method Based on VMD-WT Transform and SDAE Deep Learning","P. Xiaosheng; Z. Zuowei; X. Qiyou; W. Bo; C. Jianfeng; Y. Fan; L. Wenze; H. Zian","State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Operation and Control of Renewable Energy & Storage Systems, China Electric Power Research Institute, Beijing, China; State Key Laboratory of Operation and Control of Renewable Energy & Storage Systems, China Electric Power Research Institute, Beijing, China; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China","2020 IEEE/IAS Industrial and Commercial Power System Asia (I&CPS Asia)","29 Sep 2020","2020","","","1350","1356","Accurate wind power prediction (WPP) will contribute not only to the economic dispatching of power system but also to the safe and stable operation of the power grid. A novel three-stage ensemble short-term WPP method is proposed in this paper to effectively improve the WPP accuracy. First, in stage one, variational mode decomposition (VMD) and wavelet transform (WT) are applied to decompose the original wind power sequence into multiple subsequences. Second, in stage two, multiple stacked denoising auto-encoders (SDAE) are constructed based on the subsequences to perform WPPs separately. Third, in stage three, and the support vector machine (SVM) is applied to assign weights to each sub-prediction value to obtain the final ensemble prediction result. The case study shows that, compared with back propagation neural network (BPNN) and SVM, the average normalized root mean square error (NRMSE) and normalized mean absolute error (NMAE) of proposed ensemble WPP method, in the step range of 12 hours, are reduced by 19.66% and 19.91% compared to BPNN, and 14.43% and 14.65% compared to SVM, respectively, which illustrates the effectiveness and advancement of the proposed method.","","978-1-7281-4303-3","10.1109/ICPSAsia48933.2020.9208460","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9208460","Wind power prediction;ensemble model;stacked denoising autoencoder;variational mode decomposition;wavelet transform","Predictive models;Support vector machines;Machine learning;Wind power generation;Training;Noise reduction;Wind forecasting","backpropagation;image denoising;learning (artificial intelligence);mean square error methods;neural nets;power engineering computing;power grids;support vector machines;wavelet transforms;wind power;wind power plants","short-term wind power prediction method;VMD-WT;SDAE deep learning;accurate wind power prediction;economic dispatching;power system;safe operation;stable operation;power grid;short-term WPP method;WPP accuracy;one mode decomposition;variational mode decomposition;original wind power sequence;multiple subsequences;multiple stacked denoising autoencoders;SVM;normalized mean absolute error;ensemble WPP method;subprediction value;ensemble prediction","","1","","28","","29 Sep 2020","","","IEEE","IEEE Conferences"
"Bayesian Adversarial Learning for Speaker Recognition","J. -T. Chien; C. -L. Kuo","Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan","2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)","20 Feb 2020","2019","","","381","388","This paper presents a new generative adversarial network (GAN) which artificially generates the i-vectors to compensate the imbalanced or insufficient data in speaker recognition based on the probabilistic linear discriminant analysis. Theoretically, GAN is powerful to generate the artificial data which are misclassified as the real data. However, GAN suffers from the mode collapse problem in two-player optimization over generator and discriminator. This study deals with this challenge by improving the model regularization through characterizing the weight uncertainty in GAN. A new Bayesian GAN is implemented to learn a regularized model from diverse data where the strong modes are flattened via the marginalization. In particular, we present a variational GAN (VGAN) where the encoder, generator and discriminator are jointly estimated according to the variational inference. The computation cost is significantly reduced. To assure the preservation of gradient values, the learning objective based on Wasserstein distance is further introduced. The issues of model collapse and gradient vanishing are alleviated. Experiments on NIST i-vector Speaker Recognition Challenge demonstrate the superiority of the proposed VGAN to the variational autoencoder, the standard GAN and the Bayesian GAN based on the sampling method. The learning efficiency and generation performance are evaluated.","","978-1-7281-0306-8","10.1109/ASRU46091.2019.9004033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9004033","generative adversarial networks;Bayesian learning;variational autoencoder;speaker recognition","Gallium nitride;Generative adversarial networks;Generators;Bayes methods;Training;Data models;Uncertainty","Bayes methods;learning (artificial intelligence);sampling methods;speaker recognition;vectors","mode collapse problem;model regularization;Bayesian GAN;regularized model;strong modes;variational GAN;learning objective;model collapse;gradient vanishing;standard GAN;learning efficiency;generation performance;Bayesian adversarial;generative adversarial network;imbalanced data;insufficient data;probabilistic linear discriminant analysis;artificial data;NIST i-vector speaker recognition challenge","","2","","34","","20 Feb 2020","","","IEEE","IEEE Conferences"
"Supervised Determined Source Separation with Multichannel Variational Autoencoder","H. Kameoka; L. Li; S. Inoue; S. Makino","Nippon Telegraph and Telephone Corporation, Kanagawa, 243-0198, Japan; University of Tsukuba, Ibaraki, 305-8577, Japan; University of Tsukuba, Ibaraki, 305-8577, Japan; University of Tsukuba, Ibaraki, 305-8577, Japan","Neural Computation","15 Aug 2019","2019","31","9","1891","1914","This letter proposes a multichannel source separation technique, the multichannel variational autoencoder (MVAE) method, which uses a conditional VAE (CVAE) to model and estimate the power spectrograms of the sources in a mixture. By training the CVAE using the spectrograms of training examples with source-class labels, we can use the trained decoder distribution as a universal generative model capable of generating spectrograms conditioned on a specified class index. By treating the latent space variables and the class index as the unknown parameters of this generative model, we can develop a convergence-guaranteed algorithm for supervised determined source separation that consists of iteratively estimating the power spectrograms of the underlying sources, as well as the separation matrices. In experimental evaluations, our MVAE produced better separation performance than a baseline method.","0899-7667","","10.1162/neco_a_01217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802366","","","","","","25","","","Traditional","15 Aug 2019","","","MIT Press","MIT Press Journals"
"Detecting Outlier Machine Instances Through Gaussian Mixture Variational Autoencoder With One Dimensional CNN","Y. Su; Y. Zhao; M. Sun; S. Zhang; X. Wen; Y. Zhang; X. Liu; X. Liu; J. Tang; W. Wu; D. Pei","Beijing National Research Center for Information Science and Technology, Beijing, China; Beijing National Research Center for Information Science and Technology, Beijing, China; Department of IIIS, Tsinghua University, Beijing, China; Nankai University, Tianjin, China; Beijing National Research Center for Information Science and Technology, Beijing, China; ByteDance, Beijing, China; ByteDance, Beijing, China; ByteDance, Beijing, China; ByteDance, Beijing, China; Department of IIIS, Tsinghua University, Beijing, China; Beijing National Research Center for Information Science and Technology, Beijing, China","IEEE Transactions on Computers","10 Mar 2022","2022","71","4","892","905","Today's large datacenters house a massive number of machines, each of which is being closely monitored with multivariate time series (e.g., CPU idle, memory utilization) to ensure service quality. Detecting outlier machine instances with multivariate time series is crucial for service management. However, it is a challenging task due to the multiple classes and various shapes, high dimensionality, and lack of labels of multivariate time series. In this article, we propose DOMI, a novel unsupervised model that combines Gaussian mixture VAE with 1D-CNN, to detect outlier machine instances. Its core idea is to capture the normal patterns of machine instances by learning their latent representations that consider the shape characteristics, reconstruct input data by the learned representations, and apply reconstruction probabilities to determine outliers. Moreover, DOMI interprets the detected outlier instance based on the reconstruction probability changes of univariate time series. Extensive experiments have been conducted on the dataset collected from 1821 machines with a 1.5-month-period, which are deployed in ByteDance, a top global content service provider. DOMI achieves the best F1-Score of 0.94 and AUC score of 0.99, significantly outperforming the best performing baseline method by 0.08 and 0.03, respectively. Moreover, its interpretation accuracy is up to 0.93.","1557-9956","","10.1109/TC.2021.3065073","National Key Research and Development Program of China(grant numbers:2019YFB1802504); National Natural Science Foundation of China(grant numbers:61902200,62072264); China Postdoctoral Science Foundation(grant numbers:2019M651015); Beijing National Research Center for Information Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9373923","Outlier machine instances;multivariate time series;service management;1D-CNN;GMVAE","Time series analysis;Measurement;Shape;Central Processing Unit;Monitoring;Image reconstruction;Hardware","","","","4","","45","IEEE","9 Mar 2021","","","IEEE","IEEE Journals"
"Notice of Removal: Modeling neural dynamics during speech production using a state space variational autoencoder","P. Sun; D. A. Moses; E. F. Chang","Department of Neurological Surgery and Center for Integrative Neuroscience, UC San Francisco, CA, USA; Department of Neurological Surgery and Center for Integrative Neuroscience, UC San Francisco, CA, USA; Department of Neurological Surgery and Center for Integrative Neuroscience, UC San Francisco, CA, USA","2019 9th International IEEE/EMBS Conference on Neural Engineering (NER)","20 May 2019","2019","","","428","432","Removed.","1948-3554","978-1-5386-7921-0","10.1109/NER.2019.8716931","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8716931","","","","","","1","","10","","20 May 2019","","","IEEE","IEEE Conferences"
"Clustering Analysis via Deep Generative Models With Mixture Models","L. Yang; W. Fan; N. Bouguila","Department of Computer Science and Technology, Huaqiao University, Xiamen, China; Department of Computer Science and Technology, Huaqiao University, Xiamen, China; Concordia Institute for Information Systems Engineering (CIISE), Concordia University, Montreal, QC, Canada","IEEE Transactions on Neural Networks and Learning Systems","5 Jan 2022","2022","33","1","340","350","Clustering is a fundamental problem that frequently arises in many fields, such as pattern recognition, data mining, and machine learning. Although various clustering algorithms have been developed in the past, traditional clustering algorithms with shallow structures cannot excavate the interdependence of complex data features in latent space. Recently, deep generative models, such as autoencoder (AE), variational AE (VAE), and generative adversarial network (GAN), have achieved remarkable success in many unsupervised applications thanks to their capabilities for learning promising latent representations from original data. In this work, first we propose a novel clustering approach based on both Wasserstein GAN with gradient penalty (WGAN-GP) and VAE with a Gaussian mixture prior. By combining the WGAN-GP with VAE, the generator of WGAN-GP is formulated by drawing samples from the probabilistic decoder of VAE. Moreover, to provide more robust clustering and generation performance when outliers are encountered in data, a variant of the proposed deep generative model is developed based on a Student’s-t mixture prior. The effectiveness of our deep generative models is validated though experiments on both clustering analysis and samples generation. Through the comparison with other state-of-art clustering approaches based on deep generative models, the proposed approach can provide more stable training of the model, improve the accuracy of clustering, and generate realistic samples.","2162-2388","","10.1109/TNNLS.2020.3027761","National Natural Science Foundation of China(grant numbers:61876068); Natural Science Foundation of Fujian Province(grant numbers:2018J01094); Promotion Program for Young and Middle-aged Teacher in Science and Technology Research of Huaqiao University(grant numbers:ZQNPY510); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222350","Clustering;generative adversarial network (GAN);mixture models;student’s-t mixture model;variational autoencoder (AE);variational inference;Wasserstein GAN","Generative adversarial networks;Gallium nitride;Generators;Training;Clustering algorithms;Data models;Decoding","deep learning (artificial intelligence);Gaussian processes;mixture models;pattern clustering","clustering analysis;deep generative model;mixture models;VAE;generative adversarial network;WGAN-GP;robust clustering;unsupervised applications;gradient penalty;Wasserstein GAN","","1","","48","IEEE","13 Oct 2020","","","IEEE","IEEE Journals"
"A Decoder-Free Variational Deep Embedding for Unsupervised Clustering","Q. Ji; Y. Sun; J. Gao; Y. Hu; B. Yin","Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Discipline of Business Analytics, The University of Sydney Business School, The University of Sydney, Sydney, NSW, Australia; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China","IEEE Transactions on Neural Networks and Learning Systems","5 Oct 2022","2022","33","10","5681","5693","In deep clustering frameworks, autoencoder (AE)- or variational AE-based clustering approaches are the most popular and competitive ones that encourage the model to obtain suitable representations and avoid the tendency for degenerate solutions simultaneously. However, for the clustering task, the decoder for reconstructing the original input is usually useless when the model is finished training. The encoder–decoder architecture limits the depth of the encoder so that the learning capacity is reduced severely. In this article, we propose a decoder-free variational deep embedding for unsupervised clustering (DFVC). It is well known that minimizing reconstruction error amounts to maximizing a lower bound on the mutual information (MI) between the input and its representation. That provides a theoretical guarantee for us to discard the bloated decoder. Inspired by contrastive self-supervised learning, we can directly calculate or estimate the MI of the continuous variables. Specifically, we investigate unsupervised representation learning by simultaneously considering the MI estimation of continuous representations and the MI computation of categorical representations. By introducing the data augmentation technique, we incorporate the original input, the augmented input, and their high-level representations into the MI estimation framework to learn more discriminative representations. Instead of matching to a simple standard normal distribution adversarially, we use end-to-end learning to constrain the latent space to be cluster-friendly by applying the Gaussian mixture distribution as the prior. Extensive experiments on challenging data sets show that our model achieves higher performance over a wide range of state-of-the-art clustering approaches.","2162-2388","","10.1109/TNNLS.2021.3071275","National Natural Science Foundation of China(grant numbers:61772048,U19B2039,U1811463,61806014,61632006); Beijing Talents Fund(grant numbers:2017A24); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9410431","Augmented mutual information (MI);deep clustering;self-supervised learning (SSL);variational embedding","Clustering algorithms;Data models;Neural networks;Image reconstruction;Decoding;Training;Estimation","","","","","","63","IEEE","21 Apr 2021","","","IEEE","IEEE Journals"
"Deep learning in power systems research: A review","M. Khodayar; G. Liu; J. Wang; M. E. Khodayar","Global Energy Interconnection Research Institute North America, San Jose, CA, USA; Envision Digital, Redwood City, CA, USA; Department of Electrical and Computer Engineering, Southern Methodist University, Dallas, TX, USA; Department of Electrical and Computer Engineering, Southern Methodist University, Dallas, TX, USA","CSEE Journal of Power and Energy Systems","23 Mar 2021","2021","7","2","209","220","With the rapid growth of power systems measurements in terms of size and complexity, discovering statistical patterns for a large variety of real-world applications such as renewable energy prediction, demand response, energy disaggregation, and state estimation is considered a crucial challenge. In recent years, deep learning has emerged as a novel class of machine learning algorithms that represents power systems data via a large hypothesis space that leads to the state-of-the-art performance compared to most recent data-driven algorithms. This study explores the theoretical advantages of deep representation learning in power systems research. We review deep learning methodologies presented and applied in a wide range of supervised, unsupervised, and semi-supervised applications as well as reinforcement learning tasks. We discuss various settings of problems solved by discriminative deep models including stacked autoencoders and convolutional neural networks as well as generative deep architectures such as deep belief networks and variational autoencoders. The theoretical and experimental analysis of deep neural networks in this study motivates long- term research on optimizing this cutting-edge class of models to achieve significant improvements in the future power systems research.","2096-0042","","10.17775/CSEEJPES.2020.02700","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9265470","Autoencoder;convolution neural network;deep learning;discriminative model;deep belief network;generative architecture;variational inference","Power system stability;Feature extraction;Deep learning;Stability analysis;Probabilistic logic;Power systems;Training","belief networks;deep learning (artificial intelligence);neural net architecture;power engineering computing;power system measurement;supervised learning;unsupervised learning","stacked autoencoders;unsupervised learning;long- term research;deep neural networks;deep belief networks;generative deep architectures;discriminative deep models;reinforcement learning tasks;semisupervised applications;deep representation learning;data-driven algorithms;power systems data;machine learning;state estimation;energy disaggregation;demand response;renewable energy prediction;real-world applications;statistical patterns;power systems measurements","","9","","70","","20 Nov 2020","","","CSEE","CSEE Journals"
"Deep Learning Anomaly Detection methods to passively detect COVID-19 from Audio","S. N. Murthy; E. Agu","Worcester Polytechnic Institute, Worcester, MA; Worcester Polytechnic Institute, Worcester, MA","2021 IEEE International Conference on Digital Health (ICDH)","8 Nov 2021","2021","","","114","121","The world has been severely affected by COVID-19, an infectious disease caused by the SARS-Cov-2 coronavirus. COVID-19 incubates in a patient for 7 days before symptoms manifest. The identification of the presence of COVID-19 is challenging as its symptoms are similar to influenza symptoms such as cough, cold, runny nose, and chills. COVID-19 affects human speech sub-systems involved in respiration, phonation, and articulation. We propose a deep anomaly detection framework for passive, speech-based detection of COVID-related anomalies in voice samples of COVID-19 affected individuals. The low percentage of positive cases and extreme imbalance in available COVID audio datasets present a challenge to machine learning classifiers but create an opportunity to utilize anomaly detection techniques. We investigate COVID detection from audio using various types of deep anomaly detectors and convolutional autoencoders. Contrastive loss methods are also explored to force our models to learn discrepancies between COVID and non-COVID cough data representations. In contrast with prior work that controlled data collection, our work focuses on crowdsourced datasets that are true representatives of the general population. In rigorous evaluation, the variational autoencoder with the elliptic envelope as the anomaly detector analyzing Mel Filterbanks audio representations performed best with an AUC of 0.65, outperforming the state of the art.","","978-1-6654-1685-6","10.1109/ICDH52753.2021.00023","DARPA(grant numbers:FA8750-18-2-0077); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9581238","Convolutional Autoencoder;Variational Autoen-coder;Contrastive Learning;COVID-19;Anomaly detection;Cough","COVID-19;Training;Learning systems;Sociology;MIMICs;Nose;Influenza","audio signal processing;convolutional neural nets;deep learning (artificial intelligence);diseases;epidemics;feature extraction;medical signal processing;patient diagnosis;signal classification;signal representation;speech processing","deep learning anomaly detection;COVID audio datasets;COVID-19 detection;cough data representations;passive speech based detection;infectious disease;SARS-Cov-2 coronavirus;machine learning classifiers;convolutional autoencoders;contrastive loss methods;mel filterbanks audio representations","","","","38","IEEE","8 Nov 2021","","","IEEE","IEEE Conferences"
"Generating Physically-Realistic Tertiary Protein Structures with Deep Latent Variable Models Learning Over Experimentally-available Structures","F. F. Alam; A. Shehu","Dept of Computer Science, George Mason University, Fairfax, VA; Dept of Computer Science, George Mason University, Fairfax, VA","2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","14 Jan 2022","2021","","","2463","2470","Sophisticated deep neural networks have significantly advanced our ability to predict a native structure of a protein amino-acid sequence. However, going beyond a single-structure view remains challenging. While rapid advances are being made, fundamental questions on the ability of generative deep modeling to learn to generate physically-realistic tertiary structures remain. This paper makes two key contributions. It first extends deep convolutional variable autoencoder networks to be able to learn from experimentally-available tertiary structures of proteins of variable lengths. The presented models learn over distance matrix representations of tertiary structures. A systematic and detailed analysis demonstrates that the design of the training data is of primary importance to the ability of the proposed models to learn key characteristics of tertiary structures. The second contribution this paper makes is a careful analysis along several metrics that measure the physical realism of generated tertiary structures. The presented results are promising and show that once seeded with sufficient, physically-realistic structures, variational autoencoders are efficient models for generating physically-realistic tertiary structures.","","978-1-6654-0126-5","10.1109/BIBM52615.2021.9669584","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669584","protein modeling;tertiary structure;generative model;variational autoencoder;spatial pyramidal pooling","Training;Proteins;Measurement;Heating systems;Analytical models;Protein engineering;Systematics","biology computing;convolutional neural nets;deep learning (artificial intelligence);molecular biophysics;molecular configurations;proteins","physically-realistic tertiary protein structures;protein amino-acid sequence;generative deep modeling;deep convolutional variable autoencoder networks","","","","21","IEEE","14 Jan 2022","","","IEEE","IEEE Conferences"
"Variational Autoencoded Regression: High Dimensional Regression of Visual Data on Complex Manifold","Y. Yoo; S. Yun; H. J. Chang; Y. Demiris; J. Y. Choi","Graduate School of Convergence Science and Technology, Seoul National University, South Korea; Dept. of Electrical and Computer Eng., Seoul National University, South Korea; Department of Electrical and Electronic Engineering, Personal Robotics Laboratory, United Kingdom; Department of Electrical and Electronic Engineering, Personal Robotics Laboratory, United Kingdom; Dept. of Electrical and Computer Eng., Seoul National University, South Korea","2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","9 Nov 2017","2017","","","2943","2952","This paper proposes a new high dimensional regression method by merging Gaussian process regression into a variational autoencoder framework. In contrast to other regression methods, the proposed method focuses on the case where output responses are on a complex high dimensional manifold, such as images. Our contributions are summarized as follows: (i) A new regression method estimating high dimensional image responses, which is not handled by existing regression algorithms, is proposed. (ii) The proposed regression method introduces a strategy to learn the latent space as well as the encoder and decoder so that the result of the regressed response in the latent space coincide with the corresponding response in the data space. (iii) The proposed regression is embedded into a generative model, and the whole procedure is developed by the variational autoencoder framework. We demonstrate the robustness and effectiveness of our method through a number of experiments on various visual data regression problems.","1063-6919","978-1-5386-0457-1","10.1109/CVPR.2017.314","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8099797","","Decoding;Visualization;Image reconstruction;Gaussian processes;Image sequences;Data models;Kernel","Gaussian processes;image sequences;learning (artificial intelligence);regression analysis","complex high dimensional manifold;high dimensional image responses;visual data regression problems;variational autoencoded regression;Gaussian process regression;latent space learning;encoder;decoder;image sequences","","8","","44","","9 Nov 2017","","","IEEE","IEEE Conferences"
"Neural Full-Rank Spatial Covariance Analysis for Blind Source Separation","Y. Bando; K. Sekiguchi; Y. Masuyama; A. A. Nugraha; M. Fontaine; K. Yoshii","RIKEN Center for Advanced Intelligence Project (AIP), Tokyo, Japan; RIKEN Center for Advanced Intelligence Project (AIP), Tokyo, Japan; Tokyo Metropolitan University, Tokyo, Japan; RIKEN Center for Advanced Intelligence Project (AIP), Tokyo, Japan; RIKEN Center for Advanced Intelligence Project (AIP), Tokyo, Japan; Kyoto University, Kyoto, Japan","IEEE Signal Processing Letters","30 Aug 2021","2021","28","","1670","1674","This paper describes aneural blind source separation (BSS) method based on amortized variational inference (AVI) of a non-linear generative model of mixture signals. A classical statistical approach to BSS is to fit a linear generative model that consists of spatial and source models representing the inter-channel covariances and power spectral densities of sources, respectively. Although the variational autoencoder (VAE) has successfully been used as a non-linear source model with latent features, it should be pretrained from a sufficient amount of isolated signals. Our method, in contrast, enables the VAE-based source model to be trained only from mixture signals. Specifically, we introduce a neural mixture-to-feature inference model that directly infers the latent features from the observed mixture and integrate it with a neural feature-to-mixture generative model consisting of a full-rank spatial model and a VAE-based source model. All the models are optimized jointly such that the likelihood for the training mixtures is maximized in the framework of AVI. Once the inference model is optimized, it can be used for estimating the latent features of sources included in unseen mixture signals. The experimental results show that the proposed method outperformed the state-of-the-art BSS methods based on linear generative models and was comparable to a method based on supervised learning of the VAE-based sourcemodel.","1558-2361","","10.1109/LSP.2021.3101699","JST ACT-X(grant numbers:JPMJAX200N,NEDO); JSPS KAKENHI(grant numbers:JP19H04137,JP20K21813,JP20H00602,JP20K19833); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506855","Neural source separation;unsupervised training;deep generative models;variational autoencoders","Training;Predictive models;Decoding;Reverberation;Neural networks;Computational modeling;Analytical models","blind source separation;covariance analysis;learning (artificial intelligence)","neural full-rank spatial covariance analysis;aneural blind source separation method;amortized variational inference;nonlinear generative model;linear generative model;spatial source models;inter-channel covariances;nonlinear source model;latent features;VAE-based source model;neural mixture-to-feature inference model;feature-to-mixture generative model;full-rank spatial model;training mixtures;unseen mixture signals;BSS methods","","1","","39","CCBY","4 Aug 2021","","","IEEE","IEEE Journals"
"A Two-class Hyper-spherical Autoencoder for Supervised Anomaly Detection","Y. Kawachi; Y. Koizumi; S. Murata; N. Harada","NTT Media Intelligence Laboratories, Tokyo, Japan; NTT Media Intelligence Laboratories, Tokyo, Japan; NTT Media Intelligence Laboratories, Tokyo, Japan; NTT Media Intelligence Laboratories, Tokyo, Japan","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","3047","3051","Supervised anomaly detection has been a tough problem due to its necessity of special handling of unseen anomalies. In this paper, we present a heuristic implementation of variational auto-encoder with von-Mises Fisher prior applied to a supervised anomaly detector. The closed latent space like sphere is suitable for detecting unseen anomalies because we have a possibility to ""fill"" the space with seen training samples. If it ideally works, the reconstruction error will be high for all unseen anomalies. Experiments show that our model can separate normal and anomaly samples in the spherical latent space. It is also shown that he proposed model improves the performance for seen anomalies without degrading the performance for unseen anomalies.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683790","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683790","Anomaly detection;auto-encoder;von Mises-Fisher distribution","","data mining","supervised anomaly detection;spherical latent space;two-class hyperspherical autoencoder;variational auto-encoder;von-Mises Fisher prior","","7","","28","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Learning Left Main Bifurcation Shape Features with an Autoencoder","N. Chen; R. Gharleghi; A. Sowmya; S. Beier","School of Mechanical and Manufacturing Engineering, University of New South Wales; School of Mechanical and Manufacturing Engineering, University of New South Wales; School of Computer Science and Engineering, University of New South Wales; School of Mechanical and Manufacturing Engineering, University of New South Wales","2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)","26 Apr 2022","2022","","","1","4","Geometric characteristics of the coronary arteries have been suggested as potential markers for disease risk. However, evaluation of such characteristics rely on judgement by human experts, and are thus variable and may lack sophistication. Here we apply recent advances in 3D deep learning to automatically obtain shape representation of the Left Main Bifurcation (LMB) of the coronary artery. We train a Variational Auto-Encoder based on the FoldingNet architecture to encode LMB shape features in a 450-dimension feature vector. The geometric features of patient-specific LMBs can then be manipulated by modifying, combining or interpolating the feature vectors before decoding. We also show that these vectors, on average, perform better than hand-crafted features in predicting measures of adverse blood flow (oscillating shear index or ‘OSI’, relative residence time ‘RRT’ and time averaged wall shear stress ‘TAWSS’) with a R2 goodness of fit value of 84.1% compared to 79.7%. These learned representations can also be used in other downstream predictive modelling tasks where an encoded version of a LMB is needed.","1945-8452","978-1-6654-2923-8","10.1109/ISBI52829.2022.9761591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761591","3D deep learning;Left Main Bifurcation","Point cloud compression;Deep learning;Three-dimensional displays;Shape;Biological system modeling;Bifurcation;Predictive models","bifurcation;blood vessels;cardiovascular system;computational fluid dynamics;diseases;feature extraction;haemodynamics;learning (artificial intelligence);medical image processing;physiological models","judgement;human experts;3D deep learning;shape representation;coronary artery;Variational Auto-Encoder;FoldingNet architecture;LMB shape features;450-dimension feature vector;geometric features;patient-specific LMBs;feature vectors;hand-crafted features;adverse blood flow;wall shear stress TAWSS';learned representations;encoded version;learning Left Main Bifurcation;autoencoder;geometric characteristics;potential markers;disease risk","","","","13","IEEE","26 Apr 2022","","","IEEE","IEEE Conferences"
"Mechanical Anomaly Detection on an Embedded Microcontroller","M. Lord; A. Kaplan","Department of Computer Science, California State University Northridge, Northridge, CA, USA; Department of Computer Science, California State University Northridge, Northridge, CA, USA","2021 International Conference on Computational Science and Computational Intelligence (CSCI)","22 Jun 2022","2021","","","562","568","This paper explores machine learning on an embedded device to detect anomalies with sophisticated low-power neural networks. We leverage this deep learning approach to detect mechanical anomalies as they occur on a top-load washing machine. We collect normal data from balanced laundry loads and abnormal data from unbalanced laundry loads, as they are being washed by the machine. The normal data is then used to train two different neural network models: autoencoder and variational autoencoder. This model is ported to an Arduino Nano microcontroller mounted to the washing machine. Using the autoencoder model, the microcontroller detects unbalanced washing machine loads with 92% accuracy, 90% precision and 99% recall. The battery life for this autoencoder model is 20 hours on 5 V lithium batteries, which is only 14.9% less than the life of a basic LED-blink application on the same platform.","","978-1-6654-5841-2","10.1109/CSCI54926.2021.00159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9799168","anomaly;neural network;autoencoder;VAE","Microcontrollers;Scientific computing;Computational modeling;Neural networks;Detectors;Lithium batteries;IEEE 802.16 Standard","deep learning (artificial intelligence);domestic appliances;mechanical engineering computing;microcontrollers;object detection;washing machines","balanced laundry loads;top-load washing machine;deep learning approach;low-power neural networks;embedded device;machine learning;embedded microcontroller;mechanical anomaly detection;unbalanced washing machine loads;Arduino Nanomicrocontroller;variational autoencoder;unbalanced laundry loads;abnormal data","","","","20","IEEE","22 Jun 2022","","","IEEE","IEEE Conferences"
"End-to-End Text-to-Speech Using Latent Duration Based on VQ-VAE","Y. Yasuda; X. Wang; J. Yamagishd","The Graduate University for Advanced Sciences, Japan; National Institute of Informatics, Japan; The Graduate University for Advanced Sciences, Japan","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","5694","5698","Explicit duration modeling is a key to achieving robust and efficient alignment in text-to-speech synthesis (TTS). We propose a new TTS framework using explicit duration modeling that incorporates duration as a discrete latent variable to TTS and enables joint optimization of whole modules from scratch. We formulate our method based on conditional VQ-VAE to handle discrete duration in a variational autoencoder and provide a theoretical explanation to justify our method. In our framework, a connectionist temporal classification (CTC) -based force aligner acts as the approximate posterior, and text-to-duration works as the prior in the variational autoencoder. We evaluated our proposed method with a listening test and compared it with other TTS methods based on soft-attention or explicit duration modeling. The results showed that our systems rated between soft-attention-based methods (Transformer-TTS, Tacotron2) and explicit duration modeling-based methods (Fastspeech).","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414499","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414499","text-to-speech;duration modeling;variational auto-encoder;vector quantization","Training;Quantization (signal);Conferences;Force;Linguistics;Feature extraction;Acoustics","hidden Markov models;natural language processing;speech coding;speech recognition;speech synthesis","latent duration;robust alignment;efficient alignment;text-to-speech synthesis;TTS framework;incorporates duration;conditional VQ-VAE;discrete duration;variational autoencoder;text-to-duration works;TTS methods;soft-attention-based methods;Transformer-TTS;explicit duration modeling-based methods","","2","","32","IEEE","13 May 2021","","","IEEE","IEEE Conferences"
"SAG-VAE: End-to-end Joint Inference of Data Representations and Feature Relations","C. Wang; C. Deng; V. Ivanov","Department of Computer Science, Rutgers University, New Brunswick, USA; Department of Computer Science, Rutgers University, New Brunswick, USA; Department of Computer Science, Rutgers University, New Brunswick, USA","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","9","The ability to capture relations within data can provide the much needed inductive bias for robust and interpretable Machine Learning algorithms. Variational Autoencoder (VAE) is a promising candidate for such purpose thanks to their power in data representation inference, but its vanilla form and common variations cannot process feature relations. In this paper, inspired by recent advances in relational learning with graph neural networks, we propose the Self-Attention Graph Variational AutoEncoder (SAG-VAE) model which can simultaneously learn feature relations and data representations in an end-to-end manner. The SAG-VAE is trained by jointly inferring the posterior distribution of two types of latent variables, which respectively represent the data and the feature relations. The feature relations are represented as a graph structure, and the presence of each edge is determined by a Gumbel-Softmax distribution. The generative model is accordingly parameterized by a graph neural network with a special attention mechanism we introduced in the paper. Therefore, the SAG-VAE model can generate via graph convolution and be trained via backpropagation. Experiments based on graphs show that SAG-VAE is capable of approximately retrieving edges and links between vertices based entirely on feature observations. Furthermore, experiments on image data illustrate that the learned feature relations can provide the SAG-VAE robustness against perturbations in image reconstruction and sampling. The learned feature relations as graph adjacency matrices are observed to be structured, which provides intuitive interpretability of the models.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9207154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207154","Variational Autoencoer;Graph Neural Network;Relational Learning;Latent Variable Model","Neural networks;Machine learning;Mathematical model;Data models;Feature extraction;Robustness;Backpropagation","backpropagation;graph theory;image reconstruction;learning (artificial intelligence);matrix algebra;neural nets","interpretable machine learning algorithms;data representation inference;relational learning;graph neural network;data representations;SAG-VAE model;learned feature relations;SAG-VAE robustness;robust machine learning algorithms;self-attention graph variational autoencoder model;graph adjacency matrices;Gumbel-Softmax distribution","","","","43","","28 Sep 2020","","","IEEE","IEEE Conferences"
"Learning Graph Embedding With Adversarial Training Methods","S. Pan; R. Hu; S. -F. Fung; G. Long; J. Jiang; C. Zhang","Faculty of Information Technology, Monash University, Clayton, Australia; Centre for Artificial Intelligence, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, Australia; Department of Applied Social Sciences, City University of Hong Kong, Hong Kong; Centre for Artificial Intelligence, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, Australia; Centre for Artificial Intelligence, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, Australia; Centre for Artificial Intelligence, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, Australia","IEEE Transactions on Cybernetics","7 May 2020","2020","50","6","2475","2487","Graph embedding aims to transfer a graph into vectors to facilitate subsequent graph-analytics tasks like link prediction and graph clustering. Most approaches on graph embedding focus on preserving the graph structure or minimizing the reconstruction errors for graph data. They have mostly overlooked the embedding distribution of the latent codes, which unfortunately may lead to inferior representation in many cases. In this article, we present a novel adversarially regularized framework for graph embedding. By employing the graph convolutional network as an encoder, our framework embeds the topological information and node content into a vector representation, from which a graph decoder is further built to reconstruct the input graph. The adversarial training principle is applied to enforce our latent codes to match a prior Gaussian or uniform distribution. Based on this framework, we derive two variants of the adversarial models, the adversarially regularized graph autoencoder (ARGA) and its variational version, and adversarially regularized variational graph autoencoder (ARVGA), to learn the graph embedding effectively. We also exploit other potential variations of ARGA and ARVGA to get a deeper understanding of our designs. Experimental results that compared 12 algorithms for link prediction and 20 algorithms for graph clustering validate our solutions.","2168-2275","","10.1109/TCYB.2019.2932096","Australian Government through the Australian Research Council with Australia Government Department of Health(grant numbers:LP160100630); Australia Research Alliance for Children and Youth and Global Business College Australia(grant numbers:LP150100671); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8822591","Adversarial regularization;graph autoencoder;graph clustering;graph convolutional networks (GCNs);graph embedding;link prediction","Task analysis;Training;Clustering algorithms;Generators;Convolutional codes;Decoding;Data models","convolutional neural nets;graph theory;learning (artificial intelligence);pattern clustering;vectors","Gaussian distribution;uniform distribution;graph-analytics tasks;adversarially regularized variational graph autoencoder;adversarial training principle;graph decoder;graph convolutional network;latent codes;embedding distribution;graph data;graph clustering;link prediction;adversarial training methods","","77","","64","IEEE","2 Sep 2019","","","IEEE","IEEE Journals"
"Mario Plays on a Manifold: Generating Functional Content in Latent Space through Differential Geometry","M. González-Duque; R. B. Palm; S. Hauberg; S. Risi","Creative AI Lab, IT University of Copenhagen; NA; Cognitive Systems, Technical University of Denmark; modl.ai Denmark","2022 IEEE Conference on Games (CoG)","20 Sep 2022","2022","","","385","392","Deep generative models can automatically create content of diverse types. However, there are no guarantees that such content will satisfy the criteria necessary to present it to end-users and be functional, e.g. the generated levels could be unsolvable or incoherent. In this paper we study this problem from a geometric perspective, and provide a method for reliable interpolation and random walks in the latent spaces of Categorical VAEs based on Riemannian geometry. We test our method with “Super Mario Bros” and “The Legend of Zelda” levels, and against simpler baselines inspired by current practice. Results show that the geometry we propose is better able to interpolate and sample, reliably staying closer to parts of the latent space that decode to playable content.","2325-4289","978-1-6654-5989-1","10.1109/CoG51982.2022.9893612","Novo Nordisk; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9893612","Variational Autoencoders;Differential Geometry;Uncertainty Quantification;Deep Generative Models","Geometry;Measurement;Manifolds;Interpolation;Games;Reliability theory;Rendering (computer graphics)","computational geometry;computer games;deep learning (artificial intelligence);differential geometry;random processes","functional content;latent space;differential geometry;deep generative models;geometric perspective;random walks;Riemannian geometry;Super Mario Bros;The Legend of Zelda;variational autoencoders;categorical VAEs;tile-based games","","","","40","IEEE","20 Sep 2022","","","IEEE","IEEE Conferences"
"A Variational Auto-Encoder Model for Stochastic Point Processes","N. Mehrasa; A. A. Jyothi; T. Durand; J. He; L. Sigal; G. Mori",Borealis AI; Borealis AI; Borealis AI; Borealis AI; Borealis AI; Borealis AI,"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","3160","3169","We propose a novel probabilistic generative model for action sequences. The model is termed the Action Point Process VAE (APP-VAE), a variational auto-encoder that can capture the distribution over the times and categories of action sequences. Modeling the variety of possible action sequences is a challenge, which we show can be addressed via the APP-VAE's use of latent representations and non-linear functions to parameterize distributions over which event is likely to occur next in a sequence and at what time. We empirically validate the efficacy of APP-VAE for modeling action sequences on the MultiTHUMOS and Breakfast datasets.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.00328","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8953638","Statistical Learning","","image motion analysis;image representation;image sequences;neural nets;probability;stochastic processes","probabilistic generative model;Action Point Process VAE;action sequences;APP-VAE;variational autoencoder model;stochastic point processes;latent representations;nonlinear functions","","12","","32","","9 Jan 2020","","","IEEE","IEEE Conferences"
"An Improved Variational Auto-Encoder With Reverse Supervision for the Obstacles Recognition of UGVs","A. Yin; F. Zheng; J. Tan; Y. Wang","College of Mechanical Engineering, Chongqing University, Chongqing, China; College of Mechanical Engineering, Chongqing University, Chongqing, China; PetroChina Southwest Oil and Gas Field Company Chongqing Gas Mine, Chongqing, China; College of Mechanical Engineering, Chongqing University, Chongqing, China","IEEE Sensors Journal","19 Apr 2021","2021","21","10","11791","11798","The obstacles detection plays an important role in the field of unmanned ground vehicle (UGV). This article proposes a semi-supervised learning model with reverse supervision based on Variational Auto-Encoder (VAE) to recognize the terrain obstacles of UGVs. The proposed model compresses terrain data to latent space and casts the abnormal observations to invalid white noise in order to perform more accurate fitting on marginal likelihood of normal observations. In addition, the proposed model adopts the convolutional layer instead of fully connected layer of VAE to extract data features. Gaussian Mixed Model (GMM) is used to fit the latent distribution of normal terrain data. The improved VAE could learn the actual potential distribution of target data with the reverse supervision of abnormal data, it can achieve better performance in generating ability and discriminating ability compared with existing generative models. The superiority and effectiveness of the proposed model are illustrated and validated by an application in the shooting range of UGVs. Besides, the proposed model has the promising potential for some other applications, it can be used for military operations, robot rescue, and terrain exploration in dangerous environment, etc.","1558-1748","","10.1109/JSEN.2020.3013668","Key Science and Technology Research Project of Chongqing(grant numbers:cstc2018jszx-cyztzxX0032); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9154436","UGV;VAE;reverse supervision;obstacle detection","Data models;Sensors;Adaptation models;Machine learning;Training;Optimization;Feature extraction","collision avoidance;Gaussian processes;image coding;image recognition;learning (artificial intelligence);mobile robots;path planning;remotely operated vehicles;robot vision;telerobotics","obstacles detection;unmanned ground vehicle;UGV;semisupervised learning model;reverse supervision;terrain obstacles;latent space;abnormal observations;invalid white noise;accurate fitting;convolutional layer;data features;Gaussian Mixed Model;normal terrain data;improved VAE;actual potential distribution;abnormal data;terrain exploration;improved variational autoencoder;obstacles recognition;generative models;GMM","","","","23","IEEE","3 Aug 2020","","","IEEE","IEEE Journals"
"DC-VAE, Fine-grained Anomaly Detection in Multivariate Time-Series with Dilated Convolutions and Variational Auto Encoders","G. G. González; S. M. Tagliafico; A. F. Iie-Fing; G. Gómez; J. Acuña; P. Casas","Iie-Fing Universidad de la República, montevideo, uruguay; Iie-Fing Universidad de la República, montevideo, uruguay; Iie-Fing Universidad de la República, montevideo, uruguay; Iie-Fing Universidad de la República, montevideo, uruguay; Universidad de la República & Telefónica Uruguay, Montevideo, Uruguay; Digital Safety & Security Austrian Institute of Technology, vienna, austria","2022 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)","27 Jun 2022","2022","","","287","293","Due to its unsupervised nature, anomaly detection plays a central role in cybersecurity, in particular on the detection of unknown attacks. A major source of cybersecurity data comes in the form of multivariate time-series (MTS), representing the temporal evolution of multiple, usually correlated measurements. Despite the many approaches available in the literature for time-series anomaly detection, the automatic detection of abnormal events in MTS remains a complex problem. In this paper we introduce DC-VAE, a novel approach to anomaly detection in MTS, leveraging convolutional neural networks (CNNs) and variational auto encoders (VAEs). DC-VAE detects anomalies in time-series data, exploiting temporal information without sacrificing computational and memory resources. In particular, instead of using recursive neural networks, large causal filters, or many layers, DC-VAE relies on dilated convolutions (dc) to capture long and short term phenomena in the data, avoiding complex and less-efficient deep architectures, simplifying learning. We evaluate dc-vae on the detection of anoma-lies on a large-scale, multi-dimensional network monitoring dataset collected at an operational mobile internet service provider (isp), where anomalous events were manually labeled during a time span of 7-months, at a five-minutes granularity. Results show the main properties and advantages introduced by VAEs for time-series anomaly detection, as well as the out-performance of dilated convolutions as compared to standard VAEs for time-series modeling.","2768-0657","978-1-6654-9560-8","10.1109/EuroSPW55150.2022.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9799327","Anomaly Detection;Deep Learning;Multivariate Time-Series;Dilated Convolution;VAE","Web and internet services;Neural networks;Deep architecture;Information filters;Convolutional neural networks;Computer security;Anomaly detection","computer crime;convolutional neural nets;data analysis;Internet;learning (artificial intelligence);time series","anomaly detection;multivariate time-series;dilated convolutions;cybersecurity data;convolutional neural networks;time-series data;variational autoencoders;DC-VAE;mobile Internet service provider;ISP","","","","24","IEEE","27 Jun 2022","","","IEEE","IEEE Conferences"
"Pairwise Context Similarity for Image Retrieval System Using Variational Auto-Encoder","H. Yun; Y. Kim; T. Kang; K. Jung","Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea","IEEE Access","3 Mar 2021","2021","9","","34067","34077","Deep-learning-to-hash models have recently achieved several breakthroughs enabling a fast and efficient image retrieval system. As supervision for deep-learning-to-hash models, pairwise label similarity which considers two images to be identical if their labels are identical plays a crucial role. However, models using only pairwise label similarity cannot incorporate rich contextual information in images because pairwise label similarity solely depends on labels. In this paper, we initially address two major limitations of using the pairwise label similarity as only supervision for the deep-learning-to-hash model. Then, we propose a novel pairwise context similarity to alleviate those limitations. The proposed pairwise context similarity is computed on the latent space of a Variational Auto-Encoder which is trained in an unsupervised fashion that does not utilize any label information. Moreover we propose the strategy of an auxiliary loss for deep-learning-to-hash models that can easily be combined with previous losses using pairwise label similarity without deteriorating the retrieval quality. In our experiments on three standard benchmark datasets, our proposed method achieved high retrieval quality for image retrieval tasks while also showing advantages with regard to the addressed limitations. Also, we empirically prove that our proposed method acts as a proper regularization term during training so that our loss term therefore helps to mitigate overfitting and stabilizes the training curves.","2169-3536","","10.1109/ACCESS.2021.3061765","Samsung Electronics Co., Ltd(grant numbers:IO201208-07852-01); Brain Korea 21 (BK21) FOUR Program of the Education and Research Program for Future Information and Communication Technology (ICT) Pioneers, Seoul National University, in 2021; Automation and Systems Research Institute (ASRI), Seoul National University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9361679","Deep learning to hash;image feature hashing;supervised hashing;pairwise similarity;context similarity","Quantization (signal);Context modeling;Training;Task analysis;Image retrieval;Euclidean distance;Data models","cryptography;deep learning (artificial intelligence);image retrieval;unsupervised learning","pairwise label similarity;deep-learning-to-hash model;pairwise context similarity;image retrieval system;variational autoencoder;unsupervised fashion","","","","44","CCBY","24 Feb 2021","","","IEEE","IEEE Journals"
"Hybrid CAE-VAE for Unsupervised Anomaly Detection in Log File Systems","A. Wadekar; T. Gupta; R. Vijan; F. Kazi","Electrical Department, Veermata Jijabai Technological Institute, Matunga, Mumbai; Electrical Department, Veermata Jijabai Technological Institute, Matunga, Mumbai; Electrical Department, Veermata Jijabai Technological Institute, Matunga, Mumbai; Electrical Department, Veermata Jijabai Technological Institute, Matunga, Mumbai","2019 10th International Conference on Computing, Communication and Networking Technologies (ICCCNT)","30 Dec 2019","2019","","","1","7","Anomaly detection is of paramount importance especially in big data systems since these systems log abruptly changing events which generate consequential outliers in their logs. These logs are highly unstructured in nature, hence traditional machine learning methods fail to detect anomalies. Prominent approaches include supervised techniques which require labelled data for their operation and unsupervised techniques that rely on some error metric. Also supervised methods can only capture anomalies present in the dataset, such an approach fails for any new type of anomaly. Hence, the need for unsupervised learning techniques with an easy to interpret anomaly score arises. In this paper, we propose a solution utilizing a hybrid Convolutional Autoencoder-Variational Autoencoder (CAE-VAE) architecture for discrete event sequences which are obtained by processing log files using log keys derived from individual entries. We evaluate our model on Hadoop Distributed File System (HDFS) logs. Unlike most traditional Autoencoder approaches utilizing reconstruction error for anomaly detection, our proposed model derives a likelihood metric which can be interpreted as an anomaly score. We also present a comparative analysis of our models with a supervised CNN model and an unsupervised CAE model and prove empirically how our model gets better results.","","978-1-5386-5906-9","10.1109/ICCCNT45670.2019.8944863","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944863","CNN;CAE;VAE;Anomaly Detection;Big Data;Log Analysis;CAE-VAE","Hidden Markov models;Anomaly detection;Convolution;Computer architecture;Task analysis;Analytical models;Convolutional codes","Big Data;convolutional neural nets;distributed databases;security of data;unsupervised learning","error metric;unsupervised techniques;supervised techniques;traditional machine learning methods;consequential outliers;big data systems;log File systems;unsupervised anomaly detection;hybrid CAE-VAE;unsupervised CAE model;supervised CNN model;traditional Autoencoder approaches;Hadoop Distributed File System logs;log keys;log files;discrete event sequences;hybrid Convolutional Autoencoder-Variational Autoencoder;anomaly score;unsupervised learning techniques;supervised methods","","3","","28","","30 Dec 2019","","","IEEE","IEEE Conferences"
"A Data-Driven Self-Supervised LSTM-DeepFM Model for Industrial Soft Sensor","L. Ren; T. Wang; Y. Laili; L. Zhang","School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China","IEEE Transactions on Industrial Informatics","14 Jun 2022","2022","18","9","5859","5869","Soft sensor, as an important paradigm for industrial intelligence, is widely used in industrial production to achieve efficient monitoring and prediction of production status including product quality. Data-driven soft sensor methods have attracted attention, which still have challenges because of complex industrial data with diverse characteristics, nonlinear relationships, and massive unlabeled samples. In this article, a data-driven self-supervised long short-term memory–deep factorization machine (LSTM-DeepFM) model is proposed for industrial soft sensor, in which a framework mainly including pretraining and finetuning stages is proposed to explore diverse industrial data characteristics. In the pretraining stage, an LSTM-autoencoder is first unsupervised pretrained. Then, based on two self-supervised mask strategies, LSTM-deep can explore the interdependencies between features as well as the dynamic fluctuation in time series. In the finetuning stage, relying on pretrained representation, the temporal, high-dimensional, and low-dimensional features can be extracted from the LSTM, deep, and FM components, respectively. Finally, experiments on the real-world mining dataset demonstrate that the proposed method achieves state of the art comparing with stacked autoencoder-based models, variational autoencoder-based models, semisupervised parallel DeepFM, etc.","1941-0050","","10.1109/TII.2021.3131471","National Key Research and Development Program of China(grant numbers:2019YFB1703903); National Natural Science Foundation of China(grant numbers:92167108,62173023,61836001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9629345","Deep learning;industrial big data;industrial intelligence;product quality prediction;self-supervised learning;soft sensor","Feature extraction;Soft sensors;Logic gates;Data mining;Time series analysis;Frequency modulation;Data models","deep learning (artificial intelligence);feature extraction;production engineering computing;recurrent neural nets;soft sensors;unsupervised learning","industrial soft sensor;industrial data;LSTM-autoencoder;self-supervised mask strategies;stacked autoencoder-based models;variational autoencoder-based models;data-driven self-supervised LSTM-DeepFM model;industrial intelligence;industrial production;production status monitoring;product quality;data-driven soft sensor methods;data-driven self-supervised long short-term memory;LSLSTM-DeepFM model;deep factorization machine model;feature extraction","","2","","26","CCBY","30 Nov 2021","","","IEEE","IEEE Journals"
"Low-Rank Characteristic Tensor Density Estimation Part II: Compression and Latent Density Estimation","M. Amiridi; N. Kargas; N. D. Sidiropoulos","Department of ECE, University of Virginia, Charlottesville, VA, USA; Amazon, Cambridge, U.K.; Department of ECE, University of Virginia, Charlottesville, VA, USA","IEEE Transactions on Signal Processing","9 Jun 2022","2022","70","","2669","2680","Learning generative probabilistic models is a core problem in machine learning, which presents significant challenges due to the curse of dimensionality. This paper proposes a joint dimensionality reduction and non-parametric density estimation framework, using a novel estimator that can explicitly capture the underlying distribution of appropriate reduced-dimension representations of the input data. The idea is to jointly design a nonlinear dimensionality reducing auto-encoder to model the training data in terms of a parsimonious set of latent random variables, and learn a canonical low-rank tensor model of the joint distribution of the latent variables in the Fourier domain. The proposed latent density model is non-parametric and “universal,” as opposed to the predefined prior that is assumed in variational auto-encoders. Joint optimization of the auto-encoder and the latent density estimator is pursued via a formulation which learns both by minimizing a combination of the negative log-likelihood in the latent domain and the auto-encoder reconstruction loss. We demonstrate that the proposed model achieves very promising results on toy, tabular, and image datasets on regression tasks, sampling, and anomaly detection.","1941-0476","","10.1109/TSP.2022.3158422","NSF(grant numbers:IIS-1704074); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9740538","Statistical learning;probability density function estimation;autoencoder-based generative models;dimensionality reduction;characteristic function (CF);tensors;rank;canonical polyadic decomposition (CPD)","Estimation;Tensors;Data models;Computational modeling;Probabilistic logic;Manifolds;Tutorials","expectation-maximisation algorithm;image coding;image reconstruction;learning (artificial intelligence);minimisation;probability;tensors","latent density estimation;generative probabilistic models;machine learning;joint dimensionality reduction;nonparametric density estimation framework;reduced-dimension representations;nonlinear dimensionality;latent random variables;low-rank tensor model;joint distribution;latent variables;latent density model;joint optimization;latent density estimator;latent domain;autoencoder reconstruction loss;variational autoencoders;low-rank characteristic tensor density estimation","","1","","37","IEEE","23 Mar 2022","","","IEEE","IEEE Journals"
"Winding System for Fishing Simulator with Real Rod","Y. Honda; A. Kawamura","Division of Frontier Informatics, Kyoto Sangyo University, Kyoto, Japan; Division of Frontier Informatics, Kyoto Sangyo University, Kyoto, Japan","2021 20th International Symposium on Communications and Information Technologies (ISCIT)","9 Nov 2021","2021","","","61","66","To enjoy fishing indoors, we study a hardware-type fishing simulator that employs a real fishing rod. In this paper, as the first step of our research, we develop a pull force acquisition system and a winding system that consists of a motor, reel, and controller. The pull force acquisition system obtains an actual fish pull force. The time variation of the pull force represents the pull pattern of the fish. We show that the winding system can reproduce a pull pattern similar to the original pull pattern obtained at the pull force acquisition system. A lot of pull pattern of fish has to be acquired to represent a specific pull pattern to the fish species. It is inefficient to obtain them with fieldwork. We use a variational auto encoder (VAE) to generate multiple pull patterns similar to the original pull pattern. Here we assume that the fish species-specific pull pattern maintains its rough shape of movements. Simulation results showed that VAE generated multiple pull patterns roughly maintaining the original shape.","2643-6175","978-1-6654-4958-8","10.1109/ISCIT52804.2021.9590606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9590606","fishing;fishing-simulator;pull of a fish;real fishing rod;variational autoencoder","Shape;Simulation;Windings;Force;Fish;Information and communication technology;Feedback control","aquaculture;clothing industry;motion control;virtual reality","winding system;fishing indoors;hardware-type fishing simulator;fishing rod;pull force acquisition system;actual fish;original pull pattern;multiple pull patterns;fish species-specific pull pattern","","","","14","IEEE","9 Nov 2021","","","IEEE","IEEE Conferences"
"3D Point Cloud Generation Using Adversarial Training for Large-Scale Outdoor Scene","T. Shinohara; H. Xiu; M. Matsuoka","Department of Architecture and Building Engineering, Tokyo Institute of Technology, Yokohama, Japan; Department of Architecture and Building Engineering, Tokyo Institute of Technology, Yokohama, Japan; Department of Architecture and Building Engineering, Tokyo Institute of Technology, Yokohama, Japan","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2935","2938","Three-dimensional (3D) point clouds are becoming an important part of the geospatial domain. During research on 3D point clouds, deep-learning models have been widely used for the classification and segmentation of 3D point clouds observed by airborne LiDAR. However, most previous studies used discriminative models, whereas few studies used generative models. Specifically, one unsolved problem is the synthesis of large-scale 3D point clouds, such as those observed in outdoor scenes, because of the 3D point clouds' complex geometric structure. In this paper, we propose a generative model for generating large-scale 3D point clouds observed from airborne LiDAR. Generally, because the training process of the famous generative model called generative adversarial network (GAN) is unstable, we combine a variational autoen-coder and GAN to generate a suitable 3D point cloud. We experimentally demonstrate that our framework can generate high-density 3D point clouds by using data from the 2018 IEEE GRSS Data Fusion Contest.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554523","KAKENHI(grant numbers:19H02408); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554523","Generative Adversarial Network;Variational Autoencoder;Deep Learning;Point Clouds;Airborne LiDAR","Training;Solid modeling;Three-dimensional displays;Laser radar;Atmospheric modeling;Geoscience and remote sensing;Generative adversarial networks","geophysical image processing;geophysical signal processing;image classification;image fusion;learning (artificial intelligence);optical radar;remote sensing by laser beam;sensor fusion;terrain mapping","airborne LiDAR;large-scale 3D point clouds;famous generative model;generative adversarial network;suitable 3D point cloud;high-density 3D point clouds;3D point cloud generation;large-scale outdoor scene;three-dimensional point clouds;deep-learning models","","","","16","","12 Oct 2021","","","IEEE","IEEE Conferences"
"Generating Data using Monte Carlo Dropout","K. Miok; D. Nguyen-Doan; D. Zaharie; M. Robnik-Šikonja","Computer Science Department, West University of Timisoara, Romania; Computer Science Department, West University of Timisoara, Romania; Computer Science Department, West University of Timisoara, Romania; Faculty of Computer and Information Science, University of Ljubljana, Slovenia","2019 IEEE 15th International Conference on Intelligent Computer Communication and Processing (ICCP)","16 Jan 2020","2019","","","509","515","For many analytical problems the challenge is to handle huge amounts of available data. However, there are data science application areas where collecting information is difficult and costly, e.g., in the study of geological phenomena, rare diseases, faults in complex systems, insurance frauds, etc. In many such cases, generators of synthetic data with the same statistical and predictive properties as the actual data allow efficient simulations and development of tools and applications. In this work, we propose the incorporation of Monte Carlo Dropout method within Autoencoder (MCD-AE) and Variational Autoencoder (MCD-VAE) as efficient generators of synthetic data sets. As the Variational Autoencoder (VAE) is one of the most popular generator techniques, we explore its similarities and differences to the proposed methods. We compare the generated data sets with the original data based on statistical properties, structural similarity, and predictive similarity. The results obtained show a strong similarity between the results of VAE, MCD-VAE and MCD-AE; however, the proposed methods are faster and can generate values similar to specific selected initial instances.","","978-1-7281-4914-1","10.1109/ICCP48234.2019.8959787","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8959787","","","data analysis;data handling;Monte Carlo methods;neural nets","data generation;data science application areas;geological phenomena;insurance frauds;statistical properties;predictive properties;MCD-AE;structural similarity;predictive similarity;MCD-VAE;variational autoencoder;Monte Carlo dropout method within autoencoder","","5","","28","","16 Jan 2020","","","IEEE","IEEE Conferences"
"Full Graph Autoencoder for One-Class Group Anomaly Detection of IIoT System","Y. Feng; J. Chen; Z. Liu; H. Lv; J. Wang","State Key Laboratory for Manufacturing and Systems Engineering, Xi&#x2019;an Jiaotong University, Xi&#x2019;an, China; State Key Laboratory for Manufacturing and Systems Engineering, Xi&#x2019;an Jiaotong University, Xi&#x2019;an, China; Science and Technology on Liquid Rocket Engine Laboratory, Xi&#x2019;an, China; State Key Laboratory for Manufacturing and Systems Engineering, Xi&#x2019;an Jiaotong University, Xi&#x2019;an, China; Science and Technology on Liquid Rocket Engine Laboratory, Xi&#x2019;an, China","IEEE Internet of Things Journal","","2022","PP","99","1","1","With the increasing automation and integration of equipment, it is urgent to carry out anomaly detection for large-scale system to ensure security, in virtue of Industrial Internet of Things (IIoT). Recently developed intelligent methods focus on component-level diagnosis or detection, resulting in difficulty in the health assessment of system with multisource data coupling. In addition, data-driven methods rarely emphasize the use of knowledge from real physical system. In this paper, we propose a full graph autoencoder to perform one-class group anomaly detection for large-scale IIoT system. The proposed model takes as input data of normal status at training and only comprises several normalized graph convolutional layers, thus it is simple and fast. Different from Euclidean-based methods, the proposed model can handle various irregular structures together. For graph learning, multivariate time series are converted into graph data fused with prior knowledge. To achieve anomaly detection, we propose to reconstruct the full graph for the first time to obtain a reliable anomaly score. Besides, we extend a variational model to fully learn the graph representation. Moreover, a graph augmentation operation is employed to improve the accuracy and robustness. The proposed models are evaluated on two multi-sensor datasets from liquid rocket engine (LRE) systems, and the experimental results demonstrate the effectiveness and generalization on IIoT system.","2327-4662","","10.1109/JIOT.2022.3181737","National Natural Science Foundation of China(grant numbers:51875436); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9792242","Group anomaly detection;graph autoencoder;Industrial Internet of Things (IIoT);multivariate time series (MTS)","Industrial Internet of Things;Anomaly detection;Rockets;Liquids;Engines;Data models;Time series analysis","","","","","","","IEEE","9 Jun 2022","","","IEEE","IEEE Early Access Articles"
"Lode Encoder: AI-constrained co-creativity","D. Bhaumik; A. Khalifa; J. Togelius","Game Innovation Lab New York University, Brooklyn, USA; Game Innovation Lab New York University, Brooklyn, USA; Game Innovation Lab New York University, Brooklyn, USA","2021 IEEE Conference on Games (CoG)","7 Dec 2021","2021","","","01","08","We present Lode Encoder, a gamified mixed-initiative level creation system for the classic platform-puzzle game Lode Runner. The system is built around several autoen-coders which are trained on sets of Lode Runner levels. When fed with the user's design, each autoencoder produces a version of that design which is closer in style to the levels that it was trained on. The Lode Encoder interface allows the user to build and edit levels through “painting” from the suggestions provided by the autoencoders. Crucially, in order to encourage designers to explore new possibilities, the system does not include more traditional editing tools. We report on the system design and training procedure, as well as on the evolution of the system itself and user tests.","2325-4289","978-1-6654-3886-5","10.1109/CoG52621.2021.9619009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9619009","Machine Learning;Variational Autoencoders;Co-Creation;Mixed Initiative;Level Design","Training;Gold;Conferences;Games;Tools;Design tools;Task analysis","computer games;interactive systems;learning (artificial intelligence)","autoencoder;Lode encoder interface;system design;AI-constrained co-creativity;gamified mixed-initiative level creation system;classic platform-puzzle game Lode Runner;Lode Runner levels","","","","29","IEEE","7 Dec 2021","","","IEEE","IEEE Conferences"
"Encoding High-Level Features: An Approach To Robust Transfer Learning","L. Y. E. Ramos Cheret; T. E. A. de Oliveira","Department of Computer Science, Lakehead University, Thunder Bay, Canada; Department of Computer Science, Lakehead University, Thunder Bay, Canada","2022 IEEE International Conference on Omni-layer Intelligent Systems (COINS)","18 Aug 2022","2022","","","1","6","Transfer Learning (TL) plays a vital role in image classification systems based on Deep Convolutional Neural Networks (DCNNs). Systems employing such technique may be susceptible to distortions on images, motivating the development of robust DCNNs capable of facing these problems. Unfortunately, changes in the architecture of DCNNs are sometimes specific to a kind of distortion and result in models that need to be retrained from scratch. This work proposes the use of autoencoders as intermediaries between pre-trained DCNNs and classifiers, delegating the denoising task to this architecture trained to encode feature maps. The classifiers are then trained to map the inputs from the autoencoder latent spaces to their respective classes. Models employing this approach achieved 3% to 4% increase in accuracy and 50% to 70% reduction in loss on the CIFAR10 and CIFAR100 datasets. The results also showed an up to 80% reduction in loss and up to 15% increase in accuracy for images with unseen distortions compared to the classical TL approach. This work improves classification results and increases robustness to distortions in a straightforward manner.","","978-1-6654-8356-8","10.1109/COINS54846.2022.9854982","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9854982","Image Classification;Variational Autoencoder;Transfer Learning;Deep Convolutional Networks;Impulse Noise;Gaussian;JPEG Compression","Training;Adaptation models;Image coding;Sensitivity;Transfer learning;Transform coding;Distortion","convolutional neural nets;deep learning (artificial intelligence);encoding;feature extraction;image classification;image coding;image denoising;learning (artificial intelligence)","image distortion;autoencoders;denoising task;CIFAR100 datasets;image classification systems;pretrained DCNN;high-level features encoding;robust transfer learning;deep convolutional neural networks;CIFAR10 datasets","","","","16","IEEE","18 Aug 2022","","","IEEE","IEEE Conferences"
"Generalized Zero-Shot Learning via Over-Complete Distribution","R. Keshari; R. Singh; M. Vatsa","IIIT-Delhi, India; IIT Jodhpur, India; IIT Jodhpur, India","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","13297","13305","A well trained and generalized deep neural network (DNN) should be robust to both seen and unseen classes. However, the performance of most of the existing supervised DNN algorithms degrade for classes which are unseen in the training set. To learn a discriminative classifier which yields good performance in Zero-Shot Learning (ZSL) settings, we propose to generate an Over-Complete Distribution (OCD) using Conditional Variational Autoencoder (CVAE) of both seen and unseen classes. In order to enforce the separability between classes and reduce the class scatter, we propose the use of Online Batch Triplet Loss (OBTL) and Center Loss (CL) on the generated OCD. The effectiveness of the framework is evaluated using both Zero-Shot Learning and Generalized Zero-Shot Learning protocols on three publicly available benchmark databases, SUN, CUB and AWA2. The results show that generating over-complete distributions and enforcing the classifier to learn a transform function from overlapping to non-overlapping distributions can improve the performance on both seen and unseen classes.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.01331","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157225","","Training;Decoding;Protocols;Databases;Mathematical model;Semantics;Gaussian distribution","neural nets;pattern classification;supervised learning;variational techniques","nonoverlapping distributions;deep neural network;generalized zero shot learning;conditional variational autoencoder;supervised DNN algorithms;over complete distribution;discriminative classifier learning;online batch triplet loss;center loss","","27","","42","","5 Aug 2020","","","IEEE","IEEE Conferences"
"Learning Feature-to-Feature Translator by Alternating Back-Propagation for Generative Zero-Shot Learning","Y. Zhu; J. Xie; B. Liu; A. Elgammal","Department of Computer Science, Rutgers University; Hikvision Research Institute; Department of Computer Science, Rutgers University; Department of Computer Science, Rutgers University","2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","9843","9853","We investigate learning feature-to-feature translator networks by alternating back-propagation as a general-purpose solution to zero-shot learning (ZSL) problems. It is a generative model-based ZSL framework. In contrast to models based on generative adversarial networks (GAN) or variational autoencoders (VAE) that require auxiliary networks to assist the training, our model consists of a single conditional generator that maps class-level semantic features and Gaussian white noise vectors accounting for instance-level latent factors to visual features, and is trained by maximum likelihood estimation. The training process is a simple yet effective alternating back-propagation process that iterates the following two steps: (i) the inferential back-propagation to infer the latent noise vector of each observed example, and (ii) the learning back-propagation to update the model parameters. We show that, with slight modifications, our model is capable of learning from incomplete visual features for ZSL. We conduct extensive comparisons with existing generative ZSL methods on five benchmarks, demonstrating the superiority of our method in not only ZSL performance but also convergence speed and computational cost. Specifically, our model outperforms the existing state-of-the-art methods by a remarkable margin up to 3.1% and 4.0% in ZSL and generalized ZSL settings, respectively.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.00994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9009061","","Visualization;Generators;Training;Computational modeling;Gallium nitride;Semantics;Data models","backpropagation;computer vision;data visualisation;feature extraction;Gaussian noise;maximum likelihood estimation;neural nets;variational techniques;white noise","instance-level latent factors;visual features;generative model-based ZSL framework;computer vision problems;inferential backpropagation;maximum likelihood estimation;generative adversarial networks;generative zero-shot learning problem;feature-to-feature translator learning;Gaussian white noise vectors;variational autoencoders","","24","","68","","27 Feb 2020","","","IEEE","IEEE Conferences"
"Transformer VAE: A Hierarchical Model for Structure-Aware and Interpretable Music Representation Learning","J. Jiang; G. G. Xia; D. B. Carlton; C. N. Anderson; R. H. Miyakawa","School of Computer Science, Carnegie Mellon University; Music X Lab, New York University, Shanghai; Hooktheory, LLC; Hooktheory, LLC; Hooktheory, LLC","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","516","520","Structure awareness and interpretability are two of the most desired properties of music generation algorithms. Structure-aware models generate more natural and coherent music with long-term dependencies, while interpretable models are more friendly for human-computer interaction and co-creation. To achieve these two goals simultaneously, we designed the Transformer Variational AutoEncoder, a hierarchical model that unifies the efforts of two recent breakthroughs in deep music generation: 1) the Music Transformer and 2) Deep Music Analogy. The former learns long-term dependencies using attention mechanism, and the latter learns interpretable latent representations using a disentangled conditional-VAE. We showed that Transformer VAE is essentially capable of learning a context-sensitive hierarchical representation, regarding local representations as the context and the dependencies among the local representations as the global structure. By interacting with the model, we can achieve context transfer, realizing the imaginary situation of ""what if"" a piece is developed following the music flow of another piece.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9054554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054554","Representation learning;VAE;Transformer;music structure","Human computer interaction;Conferences;Signal processing algorithms;Signal processing;Acoustics;Speech processing;Context modeling","knowledge representation;learning (artificial intelligence);music;neural nets;variational techniques","human computer interaction;deep music generation;disentangled conditional-VAE;transformer VAE;context-sensitive hierarchical representation;structure aware music representation learning;interpretable music representation learning;music transformer;transformer variational autoencoder;attention mechanism","","11","","18","","9 Apr 2020","","","IEEE","IEEE Conferences"
"NestedVAE: Isolating Common Factors via Weak Supervision","M. J. Vowels; N. Cihan Camgöz; R. Bowden","Centre for Vision, Speech and Signal Processing University of Surrey, Guildford, UK; Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, UK; Centre for Vision, Speech and Signal Processing University of Surrey, Guildford, UK","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","9199","9209","Fair and unbiased machine learning is an important and active field of research, as decision processes are increasingly driven by models that learn from data. Unfortunately, any biases present in the data may be learned by the model, thereby inappropriately transferring that bias into the decision making process. We identify the connection between the task of bias reduction and that of isolating factors common between domains whilst encouraging domain specific invariance. To isolate the common factors we combine the theory of deep latent variable models with information bottleneck theory for scenarios whereby data may be naturally paired across domains and no additional supervision is required. The result is the Nested Variational AutoEncoder (NestedVAE). Two outer VAEs with shared weights attempt to reconstruct the input and infer a latent space, whilst a nested VAE attempts to reconstruct the latent representation of one image, from the latent representation of its paired image. In so doing, the nested VAE isolates the common latent factors/causes and becomes invariant to unwanted factors that are not shared between paired images. We also propose a new metric to provide a balanced method of evaluating consistency and classifier performance across domains which we refer to as the Adjusted Parity metric. An evaluation of NestedVAE on both domain and attribute invariance, change detection, and learning common factors for the prediction of biological sex demonstrates that NestedVAE significantly outperforms alternative methods.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00922","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157547","","Task analysis;Decoding;Data models;Image reconstruction;Measurement;Computational modeling;Computer vision","decision making;image classification;image representation;learning (artificial intelligence);variational techniques","NestedVAE;outer VAEs;shared weights;latent space;nested VAE attempts;latent representation;paired image;unwanted factors;attribute invariance;unbiased machine learning;decision processes;decision making process;bias reduction;isolating factors;domain specific invariance;nested variational autoencoder;deep latent variable models","","3","","94","","5 Aug 2020","","","IEEE","IEEE Conferences"
"A 3-D-CNN Framework for Hyperspectral Unmixing With Spectral Variability","M. Zhao; S. Shi; J. Chen; N. Dobigeon","School of Marine Science and Technology, Northwestern Polytechnical University, Xi’an, China; School of Marine Science and Technology, Northwestern Polytechnical University, Xi’an, China; Blueye Intelligence, Zhenjiang, China; Institut Universitaire de France (IUF), Paris, France","IEEE Transactions on Geoscience and Remote Sensing","10 Mar 2022","2022","60","","1","14","Hyperspectral unmixing plays an important role in hyperspectral image processing and analysis. It aims to decompose mixed pixels into pure spectral signatures and their associated abundances. The hyperspectral image contains spatial information in neighborhood regions, and spectral signatures existing in the region also have a high correlation. However, most autoencoder (AE)-based unmixing methods are pixel-to-pixel methods and ignore these priors. It is helpful to add spectral–spatial information into unmixing methods. A recent trend to deal with this problem is to use convolutional neural networks (CNNs). Our proposed framework uses 3-D-CNN-based networks to jointly learn spectral–spatial priors. Moreover, previous AE-based unmixing methods use fixed spectral signatures for each pure material. In our work, we use a carefully designed decoder to cope with the endmember variability issue, and variational inference strategy is applied to add uncertainty property into endmembers. To avoid overfitting, we use structured sparsity regularizers to the encoder networks, and  $\ell _{2,1}$ -loss is added to the estimated abundances to guarantee the sparseness. Experimental results on both simulated and real data demonstrate the effectiveness of our proposed method.","1558-0644","","10.1109/TGRS.2022.3141387","NSFC(grant numbers:62171380); Higher Education Discipline Innovation Project(grant numbers:B18041); ANR-3IA Artificial and Natural Intelligence Toulouse Institute (ANITI)(grant numbers:ANITI ANR-19-PI3A-0004); Innovation Foundation for Doctor Dissertation of Northwestern Polytechnical University; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9674908","3-D-convolutional neural network (CNN);endmember variability;hyperspectral imaging;structured sparsity;unmixing;weight uncertainty","Hyperspectral imaging;Task analysis;Correlation;Lighting;Feature extraction;Decoding;Training data","convolutional neural nets;hyperspectral imaging;image processing;learning (artificial intelligence);variational techniques","spectral variability;hyperspectral unmixing;hyperspectral image processing;mixed pixel decomposition;pure spectral signatures;neighborhood regions;autoencoder-based unmixing methods;pixel-to-pixel methods;spectral-spatial information;convolutional neural networks;spectral-spatial priors;endmember variability;3D-CNN framework;AE-based unmixing methods;spatial information;variational inference strategy;uncertainty property;structured sparsity regularizers;encoder networks;l2,1-loss","","1","","61","IEEE","7 Jan 2022","","","IEEE","IEEE Journals"
"Semi-Supervised Analysis of the Electrocardiogram Using Deep Generative Models","S. M. Rasmussen; M. E. K. Jensen; C. S. Meyhoff; E. K. Aasvang; H. B. D. Słrensen","Department of Health Technology, Technical University of Denmark, Kongens Lyngby, Denmark; Cluster for Molecular Imaging, University of Copenhagen, Copenhagen, Denmark; Department of Clinical Medicine, University of Copenhagen, Copen-Hagen, Denmark; Copenhagen Center for Translational Research, Copenhagen University Hospital, Bispebjerg and Frederiksberg, Copenhagen, Denmark; Department of Health Technology, Technical University of Denmark, Kongens Lyngby, Denmark","2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","9 Dec 2021","2021","","","1124","1127","Deep learning has gained increased impact on medical classification problems in recent years, with models being trained to high performance. However neural networks require large amounts of labeled data, which on medical data can be expensive and cumbersome to obtain. We propose a semi-supervised setup using an unsupervised variational autoencoder combined with a supervised classifier to distinguish between atrial fibrillation and non-atrial fibrillation using ECG records from the MIT-BIH Atrial Fibrillation Database. The proposed model was compared to a fully-supervised convolutional neural network at different proportions of labeled and unlabeled data (1%-50% labeled and the remaining unlabeled). The results demonstrate that the semi-supervised approach was superior to the fully-supervised, from using as little as 5% (5,594 samples) labeled data with an accuracy of 98.7%. The work provides proof of concept and demonstrates that the proposed semisupervised setup can train high accuracy models at low amounts of labeled data.","2694-0604","978-1-7281-1179-7","10.1109/EMBC46164.2021.9629915","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9629915","","Deep learning;Training;Databases;Neural networks;Atrial fibrillation;Semisupervised learning;Electrocardiography","convolutional neural nets;deep learning (artificial intelligence);electrocardiography;medical signal processing;pattern classification;signal classification;variational techniques","electrocardiogram;deep generative models;deep learning;medical classification problems;neural networks;medical data;semisupervised setup;unsupervised variational autoencoder;supervised classifier;nonatrial fibrillation;ECG records;MIT-BIH atrial fibrillation database;fully-supervised convolutional neural network;labeled data;unlabeled data;semisupervised approach;high accuracy models","Atrial Fibrillation;Electrocardiography;Humans;Neural Networks, Computer","","","14","IEEE","9 Dec 2021","","","IEEE","IEEE Conferences"
"Learning a Phenotypic-Attribute Attentional Brain Connectivity Embedding for ADHD Classification using rs-fMRI","M. -S. Gao; F. -S. Tsai; C. -C. Lee","Department of Electrical Engineering, National Tsing Hua University, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Taiwan","2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","27 Aug 2020","2020","","","5472","5475","Automated diagnosis of Attention Deficit/Hyperactivity Disorder (ADHD) from brain's functional imaging has gained more interest due to its high prevalence rates among children. While phenotypic information, such as age and gender, is known to be important in diagnosing ADHD and critically affects the representation derived from fMRI brain images, limited studies have integrated phenotypic information when learning discriminative embedding from brain imaging for such an automatic classification task. In this work, we propose to integrate age and gender attributes through attention mechanism that is jointly optimized when learning a brain connectivity embedding using convolutional variational autoencoder derived from resting state functional magnetic resonance imaging (rs-fMRI) data. Our proposed framework achieves a state-of-the-art average of 86.22% accuracy in ADHD vs. typical develop control (TDC) binary classification task evaluated across five public ADHD-200 competition datasets. Furthermore, our analysis points out that there are insufficient linked connections to the brain region of precuneus in the ADHD group.","2694-0604","978-1-7281-1990-8","10.1109/EMBC44109.2020.9175789","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9175789","","Brain;Task analysis;Functional magnetic resonance imaging;Support vector machines;Machine learning;Training","biomedical MRI;brain;learning (artificial intelligence);medical disorders;medical image processing;neurophysiology;variational techniques","phenotypic-attribute attentional brain connectivity embedding;ADHD classification;fMRI brain images;discriminative embedding;automatic classification task;gender attributes;attention mechanism;resting state functional magnetic resonance imaging data;public ADHD-200 competition datasets;attention deficit-hyperactivity disorder;convolutional variational autoencoder;typical develop control binary classification;brain region","Attention;Attention Deficit Disorder with Hyperactivity;Brain;Brain Mapping;Child;Humans;Magnetic Resonance Imaging","","","21","","27 Aug 2020","","","IEEE","IEEE Conferences"
"Unsupervised Deep Spectrum Sensing: A Variational Auto-Encoder Based Approach","J. Xie; J. Fang; C. Liu; L. Yang","National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, Australia; Machine Intelligence Technology, Alibaba DAMO Academy, Hangzhou, China","IEEE Transactions on Vehicular Technology","14 May 2020","2020","69","5","5307","5319","In cognitive radio (CR), the test statistics of most spectrum sensing algorithms are generated from the model-based features such as the signal energy and the eigenvalues from the sample covariance matrix (CM). Despite their low complexity, their detection performance depends very much on the accuracy of the presumed model. Also, these model-based statistics may not be able to exploit the full potential of the signal samples. To this end, the data-driven deep learning-based detectors have been proposed, with test statistics generated directly from signal samples in an automatic manner. However, existing deep learning-based detectors are all supervised learning-based and they usually require a massive amount of labeled training data to achieve decent detection performance. In practical CR scenarios, however, obtaining a large amount of labeled training data may be difficult. To address this issue, in this paper, we propose an unsupervised deep learning based spectrum sensing method named unsupervised deep spectrum sensing (UDSS). The UDSS algorithm requires no prior information such as the noise power or the signal's statistical CM. Moreover, the UDSS only requires a small amount of samples collected in absence of the primary user's (PU) signals ($H_0$ labeled data). Simulation results show that the proposed UDSS algorithm is able to approach the performance of the benchmark deep supervised learning-based spectrum sensing algorithm and outperforms the model-based benchmark algorithms under both Gaussian noise and Laplace noise.","1939-9359","","10.1109/TVT.2020.2982203","National Natural Science Foundation of China(grant numbers:61871091,61934008,61801082); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9043604","Cognitive radio;deep learning;spectrum sensing;unsupervised learning","Deep learning;Clustering algorithms;Training data;Training;Detectors;Unsupervised learning","cognitive radio;covariance matrices;eigenvalues and eigenfunctions;multi-access systems;radio spectrum management;signal detection;signal sampling;statistical analysis;telecommunication computing;unsupervised learning","eigenvalues;Laplace noise;Gaussian noise;variational autoencoder;primary user;UDSS algorithm;unsupervised deep spectrum sensing;unsupervised deep learning;CR scenarios;labeled training data;data-driven deep learning-based detectors;signal samples;model-based statistics;sample covariance matrix;signal energy;model-based features;spectrum sensing algorithms;test statistics","","15","","52","IEEE","20 Mar 2020","","","IEEE","IEEE Journals"
"Adversarial Training of Variational Auto-encoders for Continual Zero-shot Learning(A-CZSL)","S. Ghosh","Aerospace Engineering Department, Indian Institute of Science, Bengaluru, India","2021 International Joint Conference on Neural Networks (IJCNN)","23 Sep 2021","2021","","","1","8","Most existing artificial neural networks(ANNs) fail to learn continually due to catastrophic forgetting, while humans can do the same by maintaining previous tasks' performances. Although storing all the previous data can alleviate the problem, it takes a large memory, infeasible in real-world utilization. We propose a continual zero-shot learning model(A-CZSL) that is more suitable in real-case scenarios to address the issue that can learn sequentially and distinguish classes the model has not seen during training. Further, to enhance the reliability, we develop A -CZSL for a single head continual learning setting where task identity is revealed during the training process but not during the testing. We present a hybrid network that consists of a shared VAE module to hold information of all tasks and task-specific private VAE modules for each task. The model's size grows with each task to prevent catastrophic forgetting of task-specific skills, and it includes a replay approach to preserve shared skills. We demonstrate our hybrid model outperforms the baselines and is effective on several datasets, i.e., CUB, AWA1, AWA2, and aPY. We show our method is superior in class sequentially learning with ZSL(Zero-Shot Learning) and GZSL(Generalized Zero-Shot Learning). The code url is available at the arxiv paper.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9534367","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534367","","Training;Codes;Object detection;Artificial neural networks;Adversarial machine learning;Reliability;Task analysis","learning (artificial intelligence);neural nets","adversarial training;continual zero-shot learning;A-CZSL;catastrophic forgetting;generalized zero-shot learning;variational autoencoders;artificial neural networks","","","","27","IEEE","23 Sep 2021","","","IEEE","IEEE Conferences"
"Improving the Performance of Batch-Constrained Reinforcement Learning in Continuous Action Domains via Generative Adversarial Networks","B. Saglam; O. Dalmaz; K. Gonc; S. S. Kozat","Elektrik ve Elektronik Mühendisliği Bölümü, Bilkent Üniversitesi, Ankara, Türkiye; Elektrik ve Elektronik Mühendisliği Bölümü, Bilkent Üniversitesi, Ankara, Türkiye; Bilgisayar Mühendisliği Bölümü, Bilkent Üniversitesi, Ankara, Türkiye; Elektrik ve Elektronik Mühendisliği Bölümü, Bilkent Üniversitesi, Ankara, Türkiye","2022 30th Signal Processing and Communications Applications Conference (SIU)","29 Aug 2022","2022","","","1","4","The Batch-Constrained Q-learning algorithm is shown to overcome the extrapolation error and enable deep reinforcement learning agents to learn from a previously collected fixed batch of transitions. However, due to conditional Variational Autoencoders (VAE) used in the data generation module, the BCQ algorithm optimizes a lower variational bound and hence, it is not generalizable to environments with large state and action spaces. In this paper, we show that the performance of the BCQ algorithm can be further improved with the employment of one of the recent advances in deep learning, Generative Adversarial Networks. Our extensive set of experiments shows that the introduced approach significantly improves BCQ in all of the control tasks tested. Moreover, the introduced approach demonstrates robust generalizability to environments with large state and action spaces in the OpenAI Gym control suite.","2165-0608","978-1-6654-5092-8","10.1109/SIU55565.2022.9864786","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9864786","deep reinforcement learning;batch-constrained reinforcement learning;offline re-inforcement learning","Deep learning;Extrapolation;Q-learning;Employment;Signal processing algorithms;Aerospace electronics;Signal processing","data analysis;error analysis;extrapolation;neural nets;reinforcement learning","batch-constrained reinforcement learning;continuous action domains;generative adversarial networks;batch-constrained Q-learning algorithm;extrapolation error;deep reinforcement;conditional variational autoencoders;data generation module;BCQ algorithm;action spaces;deep learning","","","","0","IEEE","29 Aug 2022","","","IEEE","IEEE Conferences"
"Device Light Fingerprints Identification Using MCU-Based Deep Learning Approach","C. -W. Hung; J. -R. Wu; C. -H. Lee","Department of Electrical Engineering, National Yunlin University of Science & Technology, Douliou, Taiwan; Department of Electrical Engineering, National Yunlin University of Science & Technology, Douliou, Taiwan; Department of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Hsinchu, Taiwan","IEEE Access","30 Dec 2021","2021","9","","168134","168140","We introduce device identification using the light fingerprint by a MCU-based deep learning approach. At first, we observe that minor differences exist for individual components of lighting equipment. The corresponding difference produces a unique phenomenon in the frequency spectrum. Therefore, we adopt deep learning approaches for developing a mobile phone light fingerprint identification system and implementing it on a low-cost microcontroller platform. The screen light of the mobile phone is analyzed to obtain the features of unique light fingerprints. We utilize the convolutional neural network, the improved multi-class greedy autoencoder and variational autoencoder with domain adaptation techniques to develop the identification algorithm. Finally, the Bayesian optimization technique is used to optimize the hyper-parameters of models for implementing in the microprocessor. The corresponding comparisons are introduced to demonstrate the performance. The multi-class greedy autoencoder algorithm produces results with an overall accuracy rate and abnormal sample detection rate of 99.67% and 99.85%, respectively. Only a single model needs to be added or deleted for updating new authentication data and this does not affect the identification ability of all models. This results in greater flexibility in real-life applications and potential for expansion to other fields, such as smart buildings and automated robots.","2169-3536","","10.1109/ACCESS.2021.3135448","Ministry of Science and Technology, Taiwan(grant numbers:MOST–110-2634-F-009-024,110-2221-E-A49-121-MY2,110-2221-E-150-041,109-2218-E-150-002,109-2221-E-224-023,110-2221-E-224-026); IRIS and IRIS “Intelligent Recognition Industry Service Research Center” from The Featured Areas Research Center Program within the framework of the Higher Education Sprout Project by the Ministry of Education (MOE) in Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9648329","Device identification;light fingerprint;machine learning","Fingerprint recognition;Object recognition;Training;Light sources;Optimization;Mobile handsets;Integrated circuit modeling","Bayes methods;convolutional neural nets;cryptography;deep learning (artificial intelligence);fingerprint identification;greedy algorithms;image coding;microcontrollers;optimisation","MCU-based deep learning approach;lighting equipment;frequency spectrum;deep learning approaches;mobile phone light fingerprint identification system;microcontroller platform;convolutional neural network;variational autoencoder;domain adaptation techniques;Bayesian optimization technique;multiclass greedy autoencoder algorithm;device light fingerprint identification algorithm;screen light fingerprint;smart building;automated robots","","","","20","CCBY","13 Dec 2021","","","IEEE","IEEE Journals"
"Face Synthesis via User Manipulation of Disentangled Latent Representation","N. Nakagawa; R. Togo; T. Ogawa; M. Haseyama","School of Engineering, Hokkaido University; Education and Research Center for Mathematical and Data Science, Hokkaido University; Faculty of Information Science and Technology, Hokkaido University; Faculty of Information Science and Technology, Hokkaido University","2020 IEEE 9th Global Conference on Consumer Electronics (GCCE)","21 Dec 2020","2020","","","692","693","In this paper, we propose a novel face synthesis method whose process can be conditioned not only on labels but also on latent variables as “unknown” labels corresponding to unrevealed factors. We extend Variational Autoencoder (VAE) without any additional networks to introduce conditional generation, disentangled representation, and adversarial learning into one autoencoder. Since previous conditional generative models require the annotation of labels to condition them on, disentanglement, i.e., the unsupervised discovery of generative factors enables users to generate face images more flexibly and more efficiently. Moreover, although generative adversarial networks (GANs) have problems of mode collapse and instability of the learning process, adversarial learning on VAE in an introspective way achieves both the variation of results and the stability of generation. Evaluations on the CelebFaces Attributes Dataset (CelebA) show that our method can generate face images following users' conditioning both on the known and the “unknown” labels.","2378-8143","978-1-7281-9802-6","10.1109/GCCE50665.2020.9291992","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9291992","","Faces;Training;Decoding;Information processing;Conferences;Nose;Neural networks","face recognition;learning (artificial intelligence);neural nets","unknown labels;unrevealed factors;additional networks;conditional generation;disentangled representation;adversarial learning;conditional generative models;unsupervised discovery;generative factors;face images;generative adversarial networks;mode collapse;learning process;VAE;user manipulation;disentangled latent representation;face synthesis method;latent variables;variational autoencoder;CelebFaces attributes dataset;CelebA;GAN","","","","8","","21 Dec 2020","","","IEEE","IEEE Conferences"
"Time-efficient Bayesian Inference for a (Skewed) Von Mises Distribution on the Torus in a Deep Probabilistic Programming Language","O. Rønning; C. Ley; K. V. Mardia; T. Hamelryck","Department of Computer Science, University of Copenhagen, Denmark; Department of Applied Mathematics, Computer Science and Statistics, Ghent University, Belgium; Department of Statistics, University of Oxford, UK; Department of Biology and Department of Computer Science, University of Copenhagen, Denmark","2021 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)","15 Nov 2021","2021","","","1","8","Probabilistic programming languages (PPLs) are at the interface between statistics and the theory of programming languages. PPLs formulate statistical models as stochastic programs that enable automatic inference algorithms and optimization. Pyro [1] and its sibling NumPyro [2] are PPLs built on top of the deep learning frameworks PyTorch [3] and Jax [4], respectively. Both PPLs provide simple, highly similar interfaces for inference using efficient implementations of Hamiltonian Monte Carlo (HMC), the No-U-Turn Sampler (NUTS), and Stochastic Variational Inference (SVI). They automatically generate variational distributions from a model, automatically enumerate discrete variables, and support formulating deep probabilistic models such as variational autoencoders and deep Markov models. The Sine von Mises distribution and its skewed variant are toroidal distributions relevant to protein bioinformatics. They provide a natural way to model the dihedral angles of protein structures, which is important in protein structure prediction, simulation and analysis. We present efficient implementations of the Sine von Mises distribution and its skewing in Pyro and NumPyro, and devise a simulation method that increases efficiency with several orders of magnitude when using parallel hardware (i.e., modern CPUs, GPUs, and TPUs). We demonstrate the use of the skewed Sine von Mises distribution by modeling dihedral angles of proteins using a Bayesian mixture model inferred using NUTS, exploiting NumPyro's facilities for automatic enumeration [5].","","978-1-6654-4521-4","10.1109/MFI52462.2021.9591184","Independent Research Fund Denmark; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9591184","","Proteins;Computer languages;Analytical models;Monte Carlo methods;Biological system modeling;Mixture models;Predictive models","Bayes methods;bioinformatics;biological techniques;deep learning (artificial intelligence);Markov processes;Monte Carlo methods;proteins;stochastic programming","deep learning;Hamiltonian Monte Carlo method;deep probabilistic models;variational autoencoders;deep Markov models;toroidal distributions;protein bioinformatics;dihedral angles;protein structures;skewed Sine von Mises distribution;Bayesian mixture model;probabilistic programming languages;stochastic programs;automatic inference algorithms;optimization;NumPyro;stochastic variational inference;time-efficient Bayesian inference;No-U-Turn Sampler;parallel hardware","","","","28","IEEE","15 Nov 2021","","","IEEE","IEEE Conferences"
"Gate-Layer Autoencoders with Application to Incomplete EEG Signal Recovery","H. El-Fiqi; K. Kasmarik; A. Bezerianos; K. C. Tan; H. A. Abbass","UNSW-Canberra, Canberra, Australia; UNSW-Canberra, Canberra, Australia; National University of Singapore, Singapore; City University of Hong Kong, Kowloon, Hong Kong; UNSW-Canberra, Canberra, Australia","2019 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2019","2019","","","1","8","Autoencoders (AE) have been used successfully as unsupervised learners for inferring latent information, learning hidden features and reducing the dimensionality of the data. In this paper, we propose a new AE architecture: Gate-Layer AE (GLAE). The novelty of GLAE lies in its ability to encourage learning of the relationships among different input variables, which affords it with an inherent ability to recover missing variables from the available ones and to act as a concurrent multi-function approximator.GLAE uses a network architecture that associates each input with a binary gate acting as a switch that turns on or off the flow to each input unit, while synchronising its action with data flow to the network. We test GLAE with different coding sizes and compare its performance against the Classic AE, Denoising AE and Variational AE. The evaluation uses Electroencephalograph (EEG) data with an aim to reconstruct the EEG signal when some data are missing. The results demonstrate GLAE's superior performance in reconstructing EEG signals with up to 25% missing data in an input stream.","2161-4407","978-1-7281-1985-4","10.1109/IJCNN.2019.8852101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852101","","Logic gates;Switches;Electroencephalography;Noise reduction;Encoding;Neural networks","electroencephalography;function approximation;medical signal processing;signal reconstruction;unsupervised learning","EEG signal recovery;hidden features;coding sizes;concurrent multifunction approximator;Electroencephalograph data;data flow;input unit;binary gate;network architecture;Gate-Layer AE;AE architecture;unsupervised learners;Gate-Layer autoencoders","","3","","41","","30 Sep 2019","","","IEEE","IEEE Conferences"
"Multiple Imputation for Biomedical Data using Monte Carlo Dropout Autoencoders","K. Miok; D. Nguyen-Doan; M. Robnik-Šikonja; D. Zaharie","Department of Computer Science, West University of Timisoara, Timisoara, Romania; Department of Computer Science, West University of Timisoara, Timisoara, Romania; Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, Slovenia; Department of Computer Science, West University of Timisoara, Timisoara, Romania","2019 E-Health and Bioengineering Conference (EHB)","28 Jan 2020","2019","","","1","4","Due to complex experimental settings, missing values are common in biomedical data. To handle this issue, many methods have been proposed, from ignoring incomplete instances to various data imputation approaches. With the recent rise of deep neural networks, the field of missing data imputation has oriented towards modelling of the data distribution. This paper presents an approach based on Monte Carlo dropout within (Variational) Autoencoders which offers not only very good adaptation to the distribution of the data but also allows generation of new data, adapted to each specific instance. The evaluation shows that the imputation error and predictive similarity can be improved with the proposed approach.","2575-5145","978-1-7281-2603-6","10.1109/EHB47216.2019.8969940","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8969940","data preprocessing;missing data imputation;deep learning models;Monte Carlo dropout","","data handling;medical administrative data processing;medical computing;Monte Carlo methods;neural nets","biomedical data;complex experimental settings;incomplete instances;data imputation approaches;deep neural networks;data distribution;imputation error;Monte Carlo dropout autoencoders","","2","","29","","28 Jan 2020","","","IEEE","IEEE Conferences"
"Feature-Dependent Graph Convolutional Autoencoders with Adversarial Training Methods","D. Wu; R. Hu; Y. Zheng; J. Jiang; N. Sharma; M. Blumenstein","School of Software, Centre for Artificial Intelligence, University of Technology Sydney, Sydney, NSW, Australia; School of Software Centre for Artificial Intelligence, University of Technology Sydney, Sydney, NSW, Australia; College of Information Engineering, Northwest A&F University, YangLing Shaanxi, China; School of Software, Centre for Artificial Intelligence, University of Technology Sydney, Sydney, NSW, Australia; School of Software, Centre for Artificial Intelligence, University of Technology Sydney, Sydney, NSW, Australia; School of Software, Centre for Artificial Intelligence, University of Technology Sydney, Sydney, NSW, Australia","2019 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2019","2019","","","1","8","Graphs are ubiquitous for describing and modeling complicated data structures, and graph embedding is an effective solution to learn a mapping from a graph to a low-dimensional vector space while preserving relevant graph characteristics. Most existing graph embedding approaches either embed the topological information and node features separately or learn one regularized embedding with both sources of information, however, they mostly overlook the interdependency between structural characteristics and node features when processing the graph data into the models. Moreover, existing methods only reconstruct the structural characteristics, which are unable to fully leverage the interaction between the topology and the features associated with its nodes during the encoding-decoding procedure. To address the problem, we propose a framework using autoencoder for graph embedding (GED) and its variational version (VEGD). The contribution of our work is two-fold: 1) the proposed frameworks exploit a feature-dependent graph matrix (FGM) to naturally merge the structural characteristics and node features according to their interdependency; and 2) the Graph Convolutional Network (GCN) decoder of the proposed framework reconstructs both structural characteristics and node features, which naturally possesses the interaction between these two sources of information while learning the embedding. We conducted the experiments on three real-world graph datasets such as Cora, Citeseer and PubMed to evaluate our framework and algorithms, and the results outperform baseline methods on both link prediction and graph clustering tasks.","2161-4407","978-1-7281-1985-4","10.1109/IJCNN.2019.8852314","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852314","Graph Embedding;Graph Convolutional Neural Networks;Generative Adversarial Network","Decoding;Peer-to-peer computing;Clustering algorithms;Training;Matrix decomposition;Prediction algorithms;Task analysis","convolutional neural nets;graph theory;learning (artificial intelligence);matrix algebra;pattern clustering;vectors","feature-dependent graph matrix;real-world graph datasets;feature-dependent graph convolutional autoencoders;adversarial training methods;complicated data structures;low-dimensional vector space;topological information;regularized embedding;graph embedding approaches;graph convolutional network decoder;graph clustering tasks;link prediction","","1","","29","","30 Sep 2019","","","IEEE","IEEE Conferences"
"Towards a system for automatic traffic sound event detection","M. Chavdar; B. Gerazov; Z. Ivanovski; T. Kartalov","ITEK SYSTEMS, Gevgelija, Macedonia; Faculty of Electrical Engineering and Information Technologies, Ss. Cyril and Methodius University, Skopje, Macedonia; Faculty of Electrical Engineering and Information Technologies, Ss. Cyril and Methodius University, Skopje, Macedonia; Faculty of Electrical Engineering and Information Technologies, Ss. Cyril and Methodius University, Skopje, Macedonia","2020 28th Telecommunications Forum (TELFOR)","11 Jan 2021","2020","","","1","4","Intelligent Traffic Surveillance systems have helped improve road safety through ensuring timely response to events such as traffic accidents and congestion. Our aim is to devise a robust system capable of traffic audio events detection in a real-life environment. At the core of this system is a deep learning model capable of detecting anomalous events and their classification based on their acoustic waveform. We present the results of a series of experiments designed to optimize the architecture of this model based on different algorithms for audio processing. The results show that the designed model has competitive performance to approaches published in literature.","","978-1-6654-0499-0","10.1109/TELFOR51502.2020.9306592","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9306592","Sound event detection;ITS;Traffic surveillance system;Conditional variational autoencoder;Convolutional neural network","Neurons;Training;Surveillance;Neural networks;Mel frequency cepstral coefficient;Event detection;Traffic control","acoustic signal detection;audio signal processing;deep learning (artificial intelligence);intelligent transportation systems;road safety;road traffic;signal classification;surveillance;traffic engineering computing","audio processing;acoustic waveform;robust system;traffic accidents;road safety;intelligent traffic surveillance systems;automatic traffic sound event detection;anomalous event detection;deep learning model;real-life environment","","2","","23","","11 Jan 2021","","","IEEE","IEEE Conferences"
"Unmixing in the presence of nuisances with deep generative models","M. Parente; I. Gemp; I. Durugkar","Dept. of Electrical and Computer Engineering, Univ. of Massachusetts, Amherst, MA; College of Information and Computer Science, Univ. of Massachusetts, Amherst, MA; College of Information and Computer Science, Univ. of Massachusetts, Amherst, MA","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","5189","5192","Spectral datasets acquired for unmixing are noisy and largely unlabeled (with unknown abundances). As a result the ability to accurately predict endmember abundances of surface samples is as important as the capacity to generate spectra from hypothetical abundances, e.g. endmembers from abundances sampled from the corner of a simplex. We construct a deep (semi-supervised) generative model to accomplish both these tasks while making use of the readily available unlabeled spectra and being able to encode environmental and instrumental nuisances. Our main technical contribution is that we train our model both forward and in reverse. The algorithm successfully identifies endmember spectra while isolating photometric effects and imaging errors as nuisances in a real dataset of intimately mixed samples.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8128170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128170","Deep generative models;variational autoencoders;hyperspectral data unmixing","Training;Hyperspectral imaging;Data models;Lighting;Gold;Computational modeling;Imaging","geophysical image processing;learning (artificial intelligence);spectral analysis","instrumental nuisances;endmember spectra;intimately mixed samples;deep generative models;spectral datasets;endmember abundances;surface samples;readily available unlabeled spectra;environmental nuisances","","1","","4","","4 Dec 2017","","","IEEE","IEEE Conferences"
"ChartNavigator: An Interactive Pattern Identification and Annotation Framework for Charts","T. Zhang; H. Feng; W. Chen; Z. Chen; W. Zheng; X. -N. Luo; W. Huang; A. K. H. Tung","the state key lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang, China, 310058 (e-mail: zhangtianye1026@zju.edu.cn); State Key Lab of CAG & CG, Zhejiang University, 12377 Hangzhou, Zhejiang, China, (e-mail: fenghz@zju.edu.cn); Zhejiang University, State Key Lab of CAD&CG, Hangzhou, Zhejiang, China, (e-mail: chenwei@cad.zju.edu.cn); State Key Lab of CAD & CG, Zhejiang University, 12377 Hangzhou, Zhejiang, China, (e-mail: zexianchen@zju.edu.cn); State Key Lab of CAD & CG, Zhejiang University, 12377 Hangzhou, Zhejiang, China, (e-mail: wtzheng@cad.zju.edu.cn); School of Computer and Information Security, Guilin University Of Electronic Technology, Guilin, Guangxi, China, (e-mail: luoxn@guet.edu.cn); DigitalGridResearchInstitute, China Southern Power Grid Co Ltd, 372151 Guangzhou, Guangdong, China, (e-mail: huangwqcsg@163.com); Department of Computer Science, National University of Singapore, Singapore, Singapore, Singapore, 148955 (e-mail: atung@comp.nus.edu.sg)","IEEE Transactions on Knowledge and Data Engineering","","2021","PP","99","1","1","Patterns in charts refer to interesting visual features or forms. Identifying patterns not only helps analysts understand the ‘shape’ of the data but also supports better and faster decision-making. Existing solutions for identifying patterns in charts require a large number of labeled data instances, making it intractable without user supervision. In this paper, we propose ChartNavigator, an interactive pattern identification and annotation framework for unlabeled visualization charts. ChartNavigator leverages a novel chart-sensitive deep factor model to map patterns into a low-dimensional factor representation space, and facilitates rich analysis with the derived representations. We design and implement a visual interface to support efficient identification and annotation of potential patterns in charts. Evaluations with multiple datasets show that our approach outperforms the baseline models in identifying and annotating patterns","1558-2191","","10.1109/TKDE.2021.3094236","National Natural Science Foundation of China(grant numbers:U1866602, 61772456, 61761136020); National Key Research and Development Program of China(grant numbers:2018YFB0904503); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9472937","pattern identification;chart;variational autoencoder;user interaction;visual analysis","Visualization;Data models;Annotations;Data visualization;Solid modeling;Inference algorithms;Estimation","","","","","","","IEEE","2 Jul 2021","","","IEEE","IEEE Early Access Articles"
"Comparison of the Signal Processing Methods to Enhance the Performance of the Signal Reconstruction System with Deep Learning","Y. I. Jang; N. Kyu Kwon","Dept. Electronic Engineering, Yeungnam University, Gyeongsan, Korea; Dept. Electronic Engineering, Yeungnam University, Gyeongsan, Korea","2022 13th Asian Control Conference (ASCC)","20 Jul 2022","2022","","","2082","2086","With a growing number of cardiovascular disease (CVD) cases, the daily heart monitoring method is gaining attention. Doppler radar sensor, one of the contact-free sensors, is expected to be the solution for the situation. However, the existing heart state diagnosis methods are designed to use the electrocardiogram (ECG) as the diagnostic data. To manipulate the medical diagnosis using the DCG, this study proposed the signal reconstruction system which is composed of data preprocessing methods and a deep learning network. The main objective of this system is to generate the synthetic cardiogram signal which contained the heart rate variability (HRV) information that is consistent with the information of the ECG. The HRV information that is capable to use in CVD diagnosis could be provided from DCG by operating this system. In the data preprocessing of the signal reconstruction system, signal processing methods are applied to the cardiogram datasets for elevating the performance of the signal reconstruction system. With the improved consistency of SDNN, DCG is expected to be used as an alternative to ECG that operates contact-free continuous heart state monitoring and diagnosis.","2770-8373","978-89-93215-23-6","10.23919/ASCC56756.2022.9828320","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9828320","biomedical signal;deep learning;variational autoencoder;heartbeat signal;electrocardiogram","Heart;Deep learning;Data preprocessing;Neural networks;Electrocardiography;Signal reconstruction;Doppler radar","cardiology;cardiovascular system;diseases;Doppler radar;electrocardiography;learning (artificial intelligence);medical signal processing;patient diagnosis;patient monitoring;signal reconstruction","signal reconstruction system;ECG;contact-free continuous heart state monitoring;signal processing methods;cardiovascular disease cases;daily heart monitoring method;contact-free sensors;existing heart state diagnosis methods;deep learning network;synthetic cardiogram signal;heart rate variability information","","","","14","","20 Jul 2022","","","IEEE","IEEE Conferences"
"OSTNet: Calibration Method for Optical See-Through Head-Mounted Displays via Non-Parametric Distortion Map Generation","K. Someya; Y. Hiroi; M. Yamada; Y. Itoh",Tokyo Institute of Technology; Keio University; Kyoto University; Tokyo Institute of Technology,"2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","259","260","We propose a spatial calibration method for Optical See-Through Head-Mounted Displays (OST-HMDs) having complex optical distortion such as wide field-of-view (FoV) designs. Viewpoint-dependent non-linear optical distortion makes existing spatial calibration methods either impossible to handle or difficult to compensate without intensive computation. To overcome this issue, we propose OSTNet, a non-parametric data-driven calibration method that creates a generative 2D distortion model for a given six-degree-of-freedom viewpoint pose.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00-34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951967","optical see through head mounted display;calibration;Variational Autoencoder","Optical distortion;Calibration;Cameras;Nonlinear distortion;Two dimensional displays;Decoding","calibration;helmet mounted displays;optical distortion","nonparametric distortion map generation;spatial calibration method;complex optical distortion;field-of-view designs;viewpoint-dependent nonlinear optical distortion;nonparametric data-driven calibration method;generative 2D distortion model;OSTNet","","","","8","","9 Jan 2020","","","IEEE","IEEE Conferences"
"Occluded Face Recovery by Image Retrieval","C. -T. Tu; K. -H. Lee","Department of Applied Mathematics, National Chung Hsing University, Taichung; Dept. of Computer Science and Information Engineering, Tamkang University, New Taipei City","2021 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS)","28 Dec 2021","2021","","","1","2","In this paper, we propose an occluded face recovery framework to improve the face recognition rate for the occlusion case. The occluded facial image of an unseen testing subject is automatically recovered, the generated results are diverse and fit the personal characteristics of the observable regions, and thus can be used to increase the face recognition performance for occlusion cases.","","978-1-6654-1951-2","10.1109/ISPACS51563.2021.9650973","Ministry of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9650973","Image inpainting;Face recognition;Variational Autoencoders;Generative adversarial network","Image recognition;Communication systems;Face recognition;Image retrieval;Signal processing;Data models;Testing","face recognition;feature extraction;gesture recognition;image retrieval","image retrieval;occluded face recovery framework;face recognition;facial image","","","","6","IEEE","28 Dec 2021","","","IEEE","IEEE Conferences"
"Analysis of Image Generation Techniques","A. Chaudhary; A. P. Singh; A. Krishna","Information Technology, Delhi Technological University, New Delhi, India; Information Technology, Delhi Technological University, New Delhi, India; Information Technology, Delhi Technological University, New Delhi, India","2021 3rd International Conference on Advances in Computing, Communication Control and Networking (ICAC3N)","9 Mar 2022","2021","","","913","915","In today’s world machines are getting smarter by the day and generation of images is one such task that can be delegated to the machines and they are performing to near perfection and due to this distinguishing between original images and machine generated images is becoming more and more difficult. In this we are reviewing such methods used for generating images and results or problems related to such methods.","","978-1-6654-3811-7","10.1109/ICAC3N53548.2021.9725629","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9725629","Variational Autoencoders;Generative Adversarial Networks","Image synthesis;Focusing;Computer architecture;Stability analysis;Task analysis","image processing;neural nets","image generation techniques","","","","7","IEEE","9 Mar 2022","","","IEEE","IEEE Conferences"
"Learning Deep Generative Clustering via Mutual Information Maximization","X. Yang; J. Yan; Y. Cheng; Y. Zhang","Department of Computer Science and Engineering, and the MoE Key Laboratory of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai 200240, China.; Department of Computer Science and Engineering, and the MoE Key Laboratory of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: yanjunchi@sjtu.edu.cn); Microsoft Research Laboratory, Redmond, WA 98052 USA.; Microsoft Research Laboratory, Redmond, WA 98052 USA.","IEEE Transactions on Neural Networks and Learning Systems","","2022","PP","99","1","13","Deep clustering refers to joint representation learning and clustering using deep neural networks. Existing methods can be mainly categorized into two types: discriminative and generative methods. The former learns representations for clustering with discriminative mechanisms directly, and the latter estimate the latent distribution of each cluster for generating data points and then infers cluster assignments. Although generative methods have the advantage of estimating the latent distributions of clusters, their performances still significantly fall behind discriminative methods. In this work, we argue that this performance gap might be partly due to the overlap of data distribution of different clusters. In fact, there is little guarantee of generative methods to separate the distributions of different clusters in the data space. To tackle these problems, we theoretically prove that mutual information maximization promotes the separation of different clusters in the data space, which provides a theoretical justification for deep generative clustering with mutual information maximization. Our theoretical analysis directly leads to a model which integrates a hierarchical generative adversarial network and mutual information maximization. Moreover, we further propose three techniques and empirically show their effects to stabilize and enhance the model. The proposed approach notably outperforms other generative models for deep clustering on public benchmarks.","2162-2388","","10.1109/TNNLS.2021.3135375","National Key Research and Development Program of China(grant numbers:2018AAA0100704); Shanghai Municipal Science and Technology Major Project(grant numbers:2021SHZDZX0102); National Natural Science Foundation of China(grant numbers:61972250,72061127003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669125","Deep generative clustering;generative adversarial networks (GANs);mutual information maximization;variational autoencoders (VAEs)","Codes;Mutual information;Data models;Generative adversarial networks;Entropy;Uncertainty;Learning systems","","","","","","","IEEE","4 Jan 2022","","","IEEE","IEEE Early Access Articles"
"A Basic Study on Railway Facility Extraction Using a Single-Shot Multi-Box Detector","M. Nakamura; Y. Aoto; S. Maeda","Department of Electronics and Computer Engineering, Hiroshima Institute of Technology, Japan; Department of Electronics and Computer Engineering, Hiroshima Institute of Technology, Japan; Department of Electronics and Computer Engineering, Hiroshima Institute of Technology, Japan","2019 International Conference on Machine Learning and Cybernetics (ICMLC)","6 Jan 2020","2019","","","1","7","In railway facilities, there are numerous types and electric train-line facilities. It is difficult to visually inspect all of them, so automatic visual inspection is expected. To achieve automatic inspection, it is important to extract and diagnose the target facilities. This study focuses on facilities extraction by utilizing single-shot multi-box detector (SSD), which can be used as a discriminator for human, car and boat object detection, etc. Diagnosis using Local Subspace Classifier (LSC) is proposed. Herein, we present the evaluation results and the issues applying SSD to the equipment called hangers connecting overhead lines. Some diagnosis results are also explained.","2160-1348","978-1-7281-2816-0","10.1109/ICMLC48188.2019.8949296","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8949296","Railway maintenance;Electric train line facilities;Single shot multi-box detector;Local subspace classifier;Auto encoder;Variational autoencoder","","automatic optical inspection;boats;computer vision;feature extraction;object detection;power overhead lines;railway engineering;railway safety;railways","railway facilities;electric train-line facilities;automatic visual inspection;automatic inspection;target facilities;single-shot multibox detector;boat object detection;railway facility extraction","","","","10","","6 Jan 2020","","","IEEE","IEEE Conferences"
"FMNet: Latent Feature-Wise Mapping Network for Cleaning Up Noisy Micro-Doppler Spectrogram","C. Tang; W. Li; S. Vishwakarma; F. Shi; S. J. Julier; K. Chetty","Department of Security and Crime Science, University College London, London, U.K.; Department of Security and Crime Science, University College London, London, U.K.; Department of Security and Crime Science, University College London, London, U.K.; Department of Security and Crime Science, University College London, London, U.K.; Department of Computer Science, University College London, London, U.K.; Department of Security and Crime Science, University College London, London, U.K.","IEEE Transactions on Geoscience and Remote Sensing","7 Feb 2022","2022","60","","1","12","Micro-Doppler signatures contain considerable information about target dynamics. However, the radar sensing systems are easily affected by noisy surroundings, resulting in uninterpretable motion patterns on the micro-Doppler spectrogram ( $\mu $ -DS). Meanwhile, radar returns often suffer from multipath, clutter, and interference. These issues lead to difficulty in, for example, motion feature extraction and activity classification using micro-Doppler signatures. In this article, we propose a latent feature-wise mapping strategy, called feature mapping network (FMNet), to transform measured spectrograms so that they more closely resemble the output from a simulation under the same conditions. Based on measured spectrogram and the matched simulated data, our framework contains three parts: an encoder which is used to extract latent representations/features, a decoder outputs reconstructed spectrogram according to the latent features, and a discriminator minimizes the distance of latent features of measured and simulated data. We demonstrate the FMNet with six activities data and two experimental scenarios, and final results show strong enhanced patterns and can keep actual motion information to the greatest extent. On the other hand, we also propose a novel idea which trains a classifier with only simulated data and predicts new measured samples after cleaning them up with the FMNet. From final classification results, we can see significant improvements.","1558-0644","","10.1109/TGRS.2021.3121211","Opportunistic Passive Radar for Non-Cooperative Contextual Sensing (OPERA) Project through the U.K. Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:EP/R018677/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9583945","Activity classification;adversarial autoencoder (AAE);deep learning (DL);feature mapping;micro-Doppler spectrogram (μ-DS);passive WiFi radar (PWR);variational autoencoder (VAE)","Feature extraction;Training;Spectrogram;Decoding;Task analysis;Motion measurement;Image reconstruction","Doppler radar;feature extraction;image classification;image motion analysis;image reconstruction;radar clutter","FMNet;latent feature-wise mapping network;noisy microDoppler spectrogram;target dynamics;radar sensing systems;noisy surroundings;uninterpretable motion patterns;radar returns;motion feature extraction;activity classification;microDoppler signatures;latent feature-wise mapping strategy;latent features;activities data;actual motion information","","","","35","IEEE","21 Oct 2021","","","IEEE","IEEE Journals"
"Hierarchical Graph Neural Network Based-on Semi-implicit Variational Inference","H. -L. Su; Z. -P. Li; X. -B. Zhu; L. -N. Yang; V. Gribova; V. F. Filaretov; A. Cohn; D. -S. Huang","School of Electronics and Information Engineering, Institute of Machine Learning and Systems Biology, Tongji University, Caoan Road 4800, Shanghai, China; School of Computer, Electronics and Information, Guangxi University, Nanning, China; School of Electronics and Information Engineering, Institute of Machine Learning and Systems Biology, Tongji University, Caoan Road 4800, Shanghai, China; School of Computer, Electronics and Information, Guangxi University, Nanning, China; Institute of Automation and Control Processes, Far Eastern Branch of Russian Academy of Sciences, Russia; Institute of Automation and Control Processes, Far Eastern Branch of Russian Academy of Sciences, Russia; Automated Reasoning in the School of Computing, University of Leeds, England; Institute of Machine Learning and Systems Biology, Tongji University, China","IEEE Transactions on Cognitive and Developmental Systems","","2022","PP","99","1","1","Graph neural network(GNN) has obtained outstanding achievements in relational data. However, these data have uncertain properties, for example, spurious edges may be included. Recently, Variational graph autoencoder(VGAE) has been proposed to solve this problem. However, the distributional assumptions in the variational family restrict the variational inference (VI) flexibility and they define variational families using mean-field, which can not capture complex posterior distributional. To solve the above question, in this paper, we proposed a novel GNN model based on semi-implicit variational inference (SIVI), which can embed the node to the latent space to improve VI flexibility and enhance VI expressiveness with mixing distribution. Specifically, to approximate the true posterior, a variational posterior was given utilizing a semi-implicit hierarchical variational framework, which can model complex posterior. Moreover, an iterative decoder is used to better capture graph properties. Besides, due to the hierarchical structure in our model, it can incorporation neighbour information between nodes. Experiments on multiple data sets, our method has achieved state-of-the-art results compared to other similar methods. Particularly, on the citation dataset Citeseer without features, our method outperforms VGAE by nine percentage.","2379-8939","","10.1109/TCDS.2022.3193398","grants from the National Science Foundation of China(grant numbers:China, Nos. 61732012, 61932008, 62002266, 6207323); Scientific & Technological Base and Talent Special Program of the Guangxi Zhuang Autonomous Region(grant numbers:GuiKe AD18126015); grant of National Key R&D Program of China(grant numbers:No. 2018AAA0100100); ?BAGUI Scholar? Program of Guangxi Province of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9839324","Latent variable;Variation inference;Graph neural network;Semi-implicit model;Hierarchical frame","Graphite;Uncertainty;Graph neural networks;Gaussian distribution;Decoding;Random variables;Proteins","","","","","","","IEEE","25 Jul 2022","","","IEEE","IEEE Early Access Articles"
"Disentangled Human Body Embedding Based on Deep Hierarchical Neural Network","B. Jiang; J. Zhang; J. Cai; J. Zheng","School of Mathematical Sciences, University of Science and Technology of China, Hefei, China; School of Mathematical Sciences, University of Science and Technology of China, Hefei, China; Faculty of IT, Monash University, Clayton, Australia; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore","IEEE Transactions on Visualization and Computer Graphics","30 Jun 2020","2020","26","8","2560","2575","Human bodies exhibit various shapes for different identities or poses, but the body shape has certain similarities in structure and thus can be embedded in a low-dimensional space. This article presents an autoencoder-like network architecture to learn disentangled shape and pose embedding specifically for the 3D human body. This is inspired by recent progress of deformation-based latent representation learning. To improve the reconstruction accuracy, we propose a hierarchical reconstruction pipeline for the disentangling process and construct a large dataset of human body models with consistent connectivity for the learning of the neural network. Our learned embedding can not only achieve superior reconstruction accuracy but also provide great flexibility in 3D human body generation via interpolation, bilinear interpolation, and latent space sampling. The results from extensive experiments demonstrate the powerfulness of our learned 3D human body embedding in various applications.","1941-0506","","10.1109/TVCG.2020.2988476","National Natural Science Foundation of China(grant numbers:61672481); Youth Innovation Promotion Association of the Chinese Academy of Sciences(grant numbers:2018495); NTU Data Science and Artificial Intelligence Research Center (DSAIR)(grant numbers:M4082285); MoE Tier-2(grant numbers:2016-T2-2-065,2017-T2-1-076); National Research Foundation Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9072593","3D body shape;3D human articulated body model;variational autoencoder;deformation representation;hierarchical structure","Shape;Strain;Three-dimensional displays;Biological system modeling;Computational modeling;Solid modeling;Face","image reconstruction;image representation;image sampling;interpolation;learning (artificial intelligence);neural net architecture;shape recognition;solid modelling","deep hierarchical neural network;body shape;low-dimensional space;autoencoder-like network architecture;disentangled shape;deformation-based latent representation learning;hierarchical reconstruction pipeline;3D human body generation;latent space sampling;disentangled human body embedding;pose embedding;bilinear interpolation;interpolation","Algorithms;Computer Graphics;Female;Humans;Image Processing, Computer-Assisted;Imaging, Three-Dimensional;Male;Neural Networks, Computer;Posture","10","","58","IEEE","20 Apr 2020","","","IEEE","IEEE Journals"
"Recurrent Neural Filters: Learning Independent Bayesian Filtering Steps for Time Series Prediction","B. Lim; S. Zohren; S. Roberts","Oxford-Man Institute of Quantitative Finance Department of Engineering Science, University of Oxford, Oxford, UK; Oxford-Man Institute of Quantitative Finance Department of Engineering Science, University of Oxford, Oxford, UK; Oxford-Man Institute of Quantitative Finance Department of Engineering Science, University of Oxford, Oxford, UK","2020 International Joint Conference on Neural Networks (IJCNN)","29 Sep 2020","2020","","","1","8","Despite the recent popularity of deep generative state space models, few comparisons have been made between network architectures and the inference steps of the Bayesian filtering framework - with most models simultaneously approximating both state transition and update steps with a single recurrent neural network (RNN). In this paper, we introduce the Recurrent Neural Filter (RNF), a novel recurrent autoencoder architecture that learns distinct representations for each Bayesian filtering step, captured by a series of encoders and decoders. Testing this on three real-world time series datasets, we demonstrate that the decoupled representations learnt improve the accuracy of one-step-ahead forecasts while providing realistic uncertainty estimates, and also facilitate multistep prediction through the separation of encoder stages.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9206906","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206906","recurrent neural networks;Bayesian filtering;variational autoencoders;multistep forecasting","Predictive models;Time series analysis;Mathematical model;Kalman filters;Bayes methods;Decoding;Standards","Bayes methods;decoding;encoding;estimation theory;filtering theory;inference mechanisms;learning (artificial intelligence);prediction theory;recurrent neural nets;signal representation;time series","inference steps;state transition;single recurrent neural network;recurrent autoencoder architecture;one-step-ahead forecasting;deep generative state space models;recurrent neural filters;time series prediction datasets;independent Bayesian filtering framework;RNF;RNN","","6","","52","","29 Sep 2020","","","IEEE","IEEE Conferences"
"Adversarial Attack Type I: Cheat Classifiers by Significant Changes","S. Tang; X. Huang; M. Chen; C. Sun; J. Yang","MOE Key Laboratory of System Control and Information Processing, Institute of Image Processing and Pattern Recognition and Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, P.R. China; MOE Key Laboratory of System Control and Information Processing, Institute of Image Processing and Pattern Recognition and Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, P.R. China; MOE Key Laboratory of System Control and Information Processing, Institute of Image Processing and Pattern Recognition and Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, P.R. China; MOE Key Laboratory of System Control and Information Processing, Institute of Image Processing and Pattern Recognition and Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, P.R. China; MOE Key Laboratory of System Control and Information Processing, Institute of Image Processing and Pattern Recognition and Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, P.R. China","IEEE Transactions on Pattern Analysis and Machine Intelligence","4 Feb 2021","2021","43","3","1100","1109","Despite the great success of deep neural networks, the adversarial attack can cheat some well-trained classifiers by small permutations. In this paper, we propose another type of adversarial attack that can cheat classifiers by significant changes. For example, we can significantly change a face but well-trained neural networks still recognize the adversarial and the original example as the same person. Statistically, the existing adversarial attack increases Type II error and the proposed one aims at Type I error, which are hence named as Type II and Type I adversarial attack, respectively. The two types of attack are equally important but are essentially different, which are intuitively explained and numerically evaluated. To implement the proposed attack, a supervised variation autoencoder is designed and then the classifier is attacked by updating the latent variables using gradient information. Besides, with pre-trained generative models, Type I attack on latent spaces is investigated as well. Experimental results show that our method is practical and effective to generate Type I adversarial examples on large-scale image datasets. Most of these generated examples can pass detectors designed for defending Type II attack and the strengthening strategy is only efficient with a specific type attack, both implying that the underlying reasons for Type I and Type II attack are different.","1939-3539","","10.1109/TPAMI.2019.2936378","National Natural Science Foundation of China(grant numbers:61977046,61603248,61876107,U1803261); Committee of Science and Technology, Shanghai, China(grant numbers:19510711200); 1000-Talent Plan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807315","Adversarial attack;type I error;supervised variational autoencoder","Neural networks;Training;Aerospace electronics;Toy manufacturing industry;Sun;Face recognition;Task analysis","deep learning (artificial intelligence);image classification","adversarial attack type I;cheat classifiers;deep neural networks;type II error;pre-trained generative models;type II attack;type I adversarial attack;supervised variation autoencoder;latent variables;gradient information;type I adversarial examples;large-scale image datasets;strengthening strategy","","6","","42","IEEE","20 Aug 2019","","","IEEE","IEEE Journals"
"EfficientFi: Toward Large-Scale Lightweight WiFi Sensing via CSI Compression","J. Yang; X. Chen; H. Zou; D. Wang; Q. Xu; L. Xie","School of Electrical and Electronics Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronics Engineering, Nanyang Technological University, Singapore; Department of Electrical Engineering and Computer Sciences, University of California at Berkeley, Berkeley, CA, USA; School of Electrical and Electronics Engineering, Nanyang Technological University, Singapore; Department of Electric Power and Energy Systems, KTH Royal Institute of Technology, Stockholm, Sweden; School of Electrical and Electronics Engineering, Nanyang Technological University, Singapore","IEEE Internet of Things Journal","25 Jul 2022","2022","9","15","13086","13095","WiFi technology has been applied to various places due to the increasing requirement of high-speed Internet access. Recently, besides network services, WiFi sensing is appealing in smart homes since it is device free, cost effective and privacy preserving. Though numerous WiFi sensing methods have been developed, most of them only consider single smart home scenario. Without the connection of powerful cloud server and massive users, large-scale WiFi sensing is still difficult. In this article, we first analyze and summarize these obstacles, and propose an efficient large-scale WiFi sensing framework, namely, EfficientFi. The EfficientFi works with edge computing at WiFi access points and cloud computing at center servers. It consists of a novel deep neural network that can compress fine-grained WiFi channel state information (CSI) at edge, restore CSI at cloud, and perform sensing tasks simultaneously. A quantized autoencoder and a joint classifier are designed to achieve these goals in an end-to-end fashion. To the best of our knowledge, the EfficientFi is the first Internet of Things-cloud-enabled WiFi sensing framework that significantly reduces communication overhead while realizing sensing tasks accurately. We utilized human activity recognition (HAR) and identification via WiFi sensing as two case studies, and conduct extensive experiments to evaluate the EfficientFi. The results show that it compresses CSI data from 1.368 Mb/s to 0.768 kb/s with extremely low error of data reconstruction and achieves over 98% accuracy for HAR.","2327-4662","","10.1109/JIOT.2021.3139958","NTU Presidential Postdoctoral Fellowship, “Adaptive Multimodal Learning for Robust Sensing and Recognition in Smart Cities” Project Fund, in Nanyang Technological University, Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9667414","Channel state information (CSI);deep neural network;discrete representation learning;multitask learning;variational autoencoder;WiFi-based sensing","Sensors;Wireless fidelity;Servers;Cloud computing;Feature extraction;Internet of Things;Deep learning","cloud computing;data compression;deep learning (artificial intelligence);Internet of Things;mobile computing;wireless LAN","EfficientFi;CSI compression;WiFi technology;Internet access;smart homes;cloud server;WiFi access points;WiFi channel state information;Internet of Things-cloud-enabled WiFi sensing framework;human activity recognition;HAR;autoencoder;edge computing;deep neural network","","2","","43","IEEE","3 Jan 2022","","","IEEE","IEEE Journals"
"A Systematic Survey on Music Composition Using Artificial Intelligence","M. Mansoori; R. Murali","Department of Computer Engineering, NMIMS University, Mumbai, India; Department of Computer Engineering, NMIMS University, Mumbai, India","2022 International Conference for Advancement in Technology (ICONAT)","10 Mar 2022","2022","","","1","8","The music industry has seen significant growth in recent years. This growth can be attributed to a high demand of new music; music streaming apps such as Spotify, Soundcloud, Apple Music, etc. which help people discover artists and bands from all over the world; growth in the film industry which uses music in the form of sound effects and soundtracks to set the tone and help the audience feel a range of emotions; and increase in usage of social media apps such as Instagram, Snapchat, TikTok, Twitch etc. To meet this surge in the demand of music, music needs to be composed. Composing music is a complex task which involves taking into consideration harmony, rhythm, texture, and structure. This paper aims to shed light on the various ways music can be composed using artificial intelligence. We look at different architectures of neural networks such as Recurrent Neural Networks (RNNs), Long Short Term Memory networks (LSTMs), Autoencoders, General Adversarial Networks (GANs) and transformers to understand which architecture contributes substantially to the process of composition. We also examine the different datasets used to see how the dataset that a model is trained on affects the composition capabilities of a model as well as different evaluation metrics that can be used to evaluate the composed music.","","978-1-6654-2577-3","10.1109/ICONAT53423.2022.9726088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9726088","Artificial Intelligence;Artificial Neural Network;Composing Music;Generative Adversarial Networks;Long Short Term Memory networks;Music Language Model;Music Pre-diction;Recurrent Neural Networks;Transformers;Variational Autoencoders","Recurrent neural networks;Systematics;Social networking (online);Multimedia Web sites;Music;Transformers;Rhythm","deep learning (artificial intelligence);music;neural net architecture;recurrent neural nets;social networking (online)","music composition;artificial intelligence;music industry;music streaming apps;Apple Music;transformers;Spotify;Soundcloud;film industry;sound effects;soundtracks;social media apps;Instagram;Snapchat;TikTok;Twitch;neural network architecture;recurrent neural network;RNNs;long short term memory network;LSTMs;autoencoders;general adversarial networks;GANs","","","","26","IEEE","10 Mar 2022","","","IEEE","IEEE Conferences"
"Adversarial Regularized Reconstruction for Anomaly Detection and Generation","A. Liguori; G. Manco; F. S. Pisani; E. Ritacco","Institute for High Performance Computing and Networking, National Research Council (ICAR-CNR) Via P. Bucci, Rende, Italy; Institute for High Performance Computing and Networking, National Research Council (ICAR-CNR) Via P. Bucci, Rende, Italy; Department of Computer Engineering, Modeling, Electronics and, Systems, University of Calabria, Italy; Institute for High Performance Computing and Networking, National Research Council (ICAR-CNR) Via P. Bucci, Rende, Italy","2021 IEEE International Conference on Data Mining (ICDM)","24 Jan 2022","2021","","","1204","1209","We propose ARN, a semisupervised anomaly detection and generation method based on adversarial reconstruction. ARN exploits a regularized autoencoder to optimize the reconstruction of variants of normal examples with minimal differences, that are recognized as outliers. The combination of regularization and adversarial reconstruction helps to stabilize the learning process, which results in both realistic outlier generation and substantial detection capability. Experiments on several benchmark datasets show that our model improves the current state-of-the-art by valuable margins because of its ability to model the true boundaries of the data manifold.","2374-8486","978-1-6654-2398-4","10.1109/ICDM51629.2021.00145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679163","Anomaly Detection;Outlier Detection;Anomaly Generation;Outlier Generation;Generative Adversarial Networks;Variational Autoencoders","Manifolds;Conferences;Games;Benchmark testing;Data models;Generators;Bayes methods","data handling;learning (artificial intelligence)","adversarial reconstruction;realistic outlier generation;adversarial regularized reconstruction;ARN;semisupervised anomaly detection;regularized autoencoder;anomaly generation method","","","","36","IEEE","24 Jan 2022","","","IEEE","IEEE Conferences"
"PECGAN: Endpoint Conditioned Trajectory Prediction via Generative Adversarial Network","X. Li; Y. Peng; W. Wu; G. Zhang; L. Zheng","School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Software, Hefei University of Technology, Hefei, China; School of Software, Hefei University of Technology, Hefei, China","2021 China Automation Congress (CAC)","14 Mar 2022","2021","","","7411","7416","Pedestrian trajectory prediction is a key research topic in the field of computer vision and has been widely used in practical applications, such as robot navigation and autonomous driving. Previous studies predict the future trajectory by decoding the learned motion feature via a self-recurrent architecture, which leads to a significant prediction deviation of the endpoint. Therefore, we propose Predicted Endpoint Conditioned Generative Adversarial Network (PECGAN) to predict the future trajectory without significant endpoint deviations. In our model, endpoint prediction is the primary goal which is accomplished through a conditional variables autoencoder. The estimated endpoints, coupled with past trajectories are encoded as the motion feature, and refined by a social interaction module which adopts the self-attention mechanism for message passing. The refined motion features infer the intermediate trajectory more accurately. Experimental results demonstrate that PECGAN can generate a realistic and diverse set of trajectories that respect physical constraints. Our proposed model improves state-of-the-art performance on the Stanford Drone Dataset benchmark and the ETH-UCY benchmark.","2688-0938","978-1-6654-2647-3","10.1109/CAC53003.2021.9727437","National Natural Science Foundation of China; Natural Science Foundation of Anhui Province; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9727437","endpoint prediction;trajectory prediction;social interactions;conditional variational autoencoder;generative adversarial network","Computer vision;Navigation;Message passing;Computer architecture;Benchmark testing;Predictive models;Generative adversarial networks","computer vision;feature extraction;image motion analysis;intelligent robots;learning (artificial intelligence);message passing;mobile robots;pedestrians","PECGAN;Endpoint Conditioned trajectory prediction;pedestrian trajectory prediction;key research topic;computer vision;robot navigation;autonomous driving;future trajectory;learned motion feature;significant prediction deviation;Endpoint Conditioned Generative Adversarial Network;significant endpoint deviations;endpoint prediction;conditional variables autoencoder;estimated endpoints;refined motion features;intermediate trajectory","","","","22","IEEE","14 Mar 2022","","","IEEE","IEEE Conferences"
"Discretionary Lane Change Decision Making using Reinforcement Learning with Model-Based Exploration","S. Zhang; H. Peng; S. Nageshrao; E. Tseng","Mechanical Engineering, University of Michigan; professor Mechanical Engineering, University of Michigan; Ford Motor Company; Ford Motor Company","2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)","17 Feb 2020","2019","","","844","850","Deep reinforcement learning (DRL) techniques have been used to solve a discretionary lane change decision-making problem and are showing promising results. However, since the input information for the discretionary lane change problem is continuous and can be in high dimension, it is an open challenge for DRL to optimize the exploration-exploitation trade-off. Conventional model-less exploration methods lack a systematic way to incorporate additional engineering or model-based knowledge of our application into consideration and as a result, the training can be inefficient and may dwell on a policy, e.g. lane change strategy that is impractical. In previous related work, many used the rule-based safety check policy to guide the exploration and collect input information data. However, it is not guaranteed to get the optimal policy and the performance is dependent on the safety check policy selected. In this paper, we developed an explicit statistical aggregated environment model using a conditional variational auto-encoder and a model-based exploration strategy leveraging it. The agent is guided to explore with surprise-based intrinsic reward derived from the environment model. The result is compared with annealing epsilon-greedy exploration and with rule-based safety check exploration. We demonstrate that the performance of the developed model-based exploration method is comparable with the best rule-based safety check exploration and much better than the epsilon-greedy exploration.","","978-1-7281-4550-1","10.1109/ICMLA.2019.00147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8999036","Reinforcement learning;Autonomous vehicle;Exploration","Decision making;Learning (artificial intelligence);Mathematical model;Machine learning;Safety;Kinematics;Training","automobiles;decision making;intelligent transportation systems;learning (artificial intelligence);learning systems;mobile robots;neurocontrollers;position control;road safety;road traffic;statistical analysis;variational techniques","deep reinforcement learning techniques;DRL;discretionary lane change decision-making problem;discretionary lane change problem;exploration-exploitation trade-off;lane change strategy;input information data;optimal policy;explicit statistical aggregated environment model;surprise-based intrinsic reward;annealing epsilon-greedy exploration;rule-based safety check policy;model-based exploration method;conditional variational autoencoder;rule-based safety check exploration;model-based exploration strategy","","4","","21","","17 Feb 2020","","","IEEE","IEEE Conferences"
"Deep convolutional and recurrent writer","S. Gulshad; J. -H. Kim","School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; School of Electrical Engineering, KAIST, Daejeon, Republic of Korea","2017 International Joint Conference on Neural Networks (IJCNN)","3 Jul 2017","2017","","","2836","2842","This paper proposes a new architecture Deep Convolutional and Recurrent writer (DCRW) for image generation by adapting the deep Recurrent attentive writer (DRAW) architecture which is a sequential variational auto-encoder with a sequential attention mechanism for image generation. The main difference between DRAW and DCRW is that in DCRW we have replaced RNN in encoder with CNN and after replacement attention mechanism have been used for CNN. The reason behind this modification is that CNNs are the state of the art for image processing in deep learning and their basic architecture is inspired from the visual cortex. Further, for the testing of proposed architecture experiments are performed on MNIST handwritten digits data set for generation of images and results are analyzed.","2161-4407","978-1-5090-6182-2","10.1109/IJCNN.2017.7966206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966206","","Decoding;Bayes methods;Recurrent neural networks;Mathematical model;Random variables;Computer architecture","feedforward neural nets;handwritten character recognition;image coding;neural net architecture;recurrent neural nets;variational techniques;visual databases","deep convolutional-and-recurrent writer architecture;image generation;deep recurrent attentive writer architecture;DCRW architecture;sequential variational autoencoder;sequential attention mechanism;DRAW architecture;CNN;image processing;deep learning;visual cortex;MNIST handwritten digit data set","","","","9","","3 Jul 2017","","","IEEE","IEEE Conferences"
"Binarization of Degraded Photographed Document Images- A Variational Denoising Auto Encoder","N. S. Rani; B. N. B J; K. S. K; S. A","Department of Computer Science, Amrita School of Arts and Sciences, Amrita Vishwa Vidyapeetham, Mysuru, India; Department of Computer Science, Amrita School of Arts and Sciences, Amrita Vishwa Vidyapeetham, Mysuru, India; Department of Computer Science, Amrita School of Arts and Sciences, Amrita Vishwa Vidyapeetham, Mysuru, India; Department of Computer Science, Amrita School of Arts and Sciences, Amrita Vishwa Vidyapeetham, Mysuru, India","2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA)","1 Oct 2021","2021","","","119","124","Document image enhancement is one of the prime researches in the area of optical character recognition and computer vision. Preprocessing procedure for a document depends on document layout, aging and document material type. This paper proposes a preprocessing technique for the enhancement of ancient and degraded document images. Initially the degraded patches from the document image is collected and used for learning through a variational de-noising autoencoder followed by document image enhancement. Ground truth images of the degraded patches are trained with the help of an adamax optimizer. A deep learning architecture comprised of five levels of convolution is devised for encoding and decoding process. Down sampling is initially performed in the encoding stage after each level of convolution. Further up sampling is conducted in the decoding stage. Experimentations are conducted on DIBCO (2016, 2013, 2012, 2011, 2010 and 2009) datasets and the results of enhancement are found to be promising with an average RMSE of 0.106 for batch size 1 and 24 epochs.","","978-1-6654-3877-3","10.1109/ICIRCA51532.2021.9544864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9544864","Document binarization;Degraded images;Auto encoders;DIBCO;De-noising","Convolution;Noise reduction;Stochastic processes;Lighting;Computer architecture;Optical imaging;Encoding","document image processing;feature extraction;image classification;image denoising;image enhancement;learning (artificial intelligence);optical character recognition","document image enhancement;ground truth images;degraded patches;degraded photographed document images;variational denoising auto encoder;optical character recognition;computer vision;document layout, aging;ancient document images;degraded document images","","","","32","","1 Oct 2021","","","IEEE","IEEE Conferences"
"Semi-Supervised Multichannel Speech Enhancement With a Deep Speech Prior","K. Sekiguchi; Y. Bando; A. A. Nugraha; K. Yoshii; T. Kawahara","Center for Advanced Intelligence Project (AIP), RIKEN, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology (AIST), Tokyo, Japan; Center for Advanced Intelligence Project (AIP), RIKEN, Tokyo, Japan; Center for Advanced Intelligence Project (AIP), RIKEN, Tokyo, Japan; Graduate School of Informatics, Kyoto University, Kyoto","IEEE/ACM Transactions on Audio, Speech, and Language Processing","27 Nov 2019","2019","27","12","2197","2212","This paper describes a semi-supervised multichannel speech enhancement method that uses clean speech data for prior training. Although multichannel nonnegative matrix factorization (MNMF) and its constrained variant called independent low-rank matrix analysis (ILRMA) have successfully been used for unsupervised speech enhancement, the low-rank assumption on the power spectral densities (PSDs) of all sources (speech and noise) does not hold in reality. To solve this problem, we replace a low-rank speech model with a deep generative speech model, i.e., formulate a probabilistic model of noisy speech by integrating a deep speech model, a low-rank noise model, and a full-rank or rank-1 model of spatial characteristics of speech and noise. The deep speech model is trained from clean speech data in an unsupervised auto-encoding variational Bayesian manner. Given multichannel noisy speech spectra, the full-rank or rank-1 spatial covariance matrices and PSDs of speech and noise are estimated in an unsupervised maximum-likelihood manner. Experimental results showed that the full-rank version of the proposed method was significantly better than MNMF, ILRMA, and the rank-1 version. We confirmed that the initialization-sensitivity and local-optimum problems of MNMF with many spatial parameters can be solved by incorporating the precise speech model.","2329-9304","","10.1109/TASLP.2019.2944348","JST(grant numbers:JPMJER1401); JSPS KAKENHI(grant numbers:19H04137); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861142","Multichannel speech enhancement;deep learning;variational autoencoder;nonnegative matrix factorization","Speech enhancement;Noise measurement;Data models;Probabilistic logic;Maximum likelihood estimation;Time-frequency analysis","blind source separation;covariance matrices;matrix algebra;matrix decomposition;maximum likelihood estimation;neural nets;signal denoising;speech enhancement;supervised learning;unsupervised learning","semisupervised multichannel speech enhancement method;clean speech data;multichannel nonnegative matrix factorization;low-rank matrix analysis;unsupervised speech enhancement;low-rank speech model;deep generative speech model;probabilistic model;deep speech model;low-rank noise model;rank-1 model;unsupervised auto-encoding variational Bayesian manner;multichannel noisy speech spectra","","14","","46","CCBY","7 Oct 2019","","","IEEE","IEEE Journals"
"On the Study of Generative Adversarial Networks for Cross-Lingual Voice Conversion","B. Sisman; M. Zhang; M. Dong; H. Li","Institute for Infocomm Research, A*STAR, Singapore; National University of Singapore, Singapore; Institute for Infocomm Research, A*STAR, Singapore; National University of Singapore, Singapore","2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)","20 Feb 2020","2019","","","144","151","Cross-lingual voice conversion (VC) aims to convert the source speaker's voice to sound like that of the target speaker, when the source and target speakers speak different languages. In this paper, we propose to use Generative Adversarial Networks (GANs) for cross-lingual voice-conversion. We further the studies on Variational Autoencoding Wasserstein GAN (VAW-GAN) and cycle-consistent adversarial network (CycleGAN), that are known to be effective for mono-lingual voice conversion. As cross-lingual voice conversion needs to converts the voice across different phonetic system, it is more challenging than mono-lingual voice conversion. By using VAW-GAN and CycleGAN, we successfully convert the speaker identity while carrying over the source speaker's linguistic content. The proposed idea is unique in the sense that it neither relies on bilingual data and their alignment, nor any external process, such as ASR. Moreover, it works with limited amount of training data of any two languages. To our best knowledge, this is the first comprehensive study of Generative Adversarial Networks in cross-lingual voice conversion. In the experiments, we achieve high-quality converted voice, that performs equally well or better than mono-lingual voice conversion.","","978-1-7281-0306-8","10.1109/ASRU46091.2019.9003939","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003939","cross-lingual voice conversion;generative models;variational autoencoders;generative adversarial networks","Training;Phonetics;Training data;Generative adversarial networks;Gallium nitride;Speech recognition","neural nets;speaker recognition","mono-lingual voice conversion;VAW-GAN;Generative Adversarial Networks;high-quality converted voice;source speaker;target speakers;cross-lingual voice-conversion;Variational Autoencoding Wasserstein GAN;cycle-consistent adversarial network","","13","","46","","20 Feb 2020","","","IEEE","IEEE Conferences"
"Improving Disentangled Representation Learning with the Beta Bernoulli Process","P. Gyawali; Z. Li; C. Knight; S. Ghimire; B. M. Horacek; J. Sapp; L. Wang","Rochester Institute of Technology; Rochester Institute of Technology, NY, USA; Rochester Institute of Technology, NY, USA; Rochester Institute of Technology, NY, USA; Dalhousie University, Halifax, NS, Canada; Dalhousie University, Halifax, Canada; Rochester Institute of Technology, NY, USA","2019 IEEE International Conference on Data Mining (ICDM)","30 Jan 2020","2019","","","1078","1083","To improve the ability of variational auto-encoders (VAE) to disentangle in the latent space, existing works mostly focus on enforcing the independence among the learned latent factors. However, the ability of these models to disentangle often decreases as the complexity of the generative factors increases. In this paper, we investigate the little-explored effect of the modeling capacity of a posterior density on the disentangling ability of the VAE. We note that the independence within and the complexity of the latent density are two different properties we constrain when regularizing the posterior density: while the former promotes the disentangling ability of VAE, the latter - if overly limited - creates an unnecessary competition with the data reconstruction objective in VAE. Therefore, if we preserve the independence but allow richer modeling capacity in the posterior density, we will lift this competition and thereby allow improved independence and data reconstruction at the same time. We investigate this theoretical intuition with a VAE that utilizes a non-parametric latent factor model, the Indian Buffet Process (IBP), as a latent density that is able to grow with the complexity of the data. Across two widely-used benchmark data sets (MNIST and dSprites) and two clinical data sets little explored for disentangled learning, we qualitatively and quantitatively demonstrated the improved disentangling performance of IBP-VAE over the state of the art. In the latter two clinical data sets riddled with complex factors of variations, we further demonstrated that unsupervised disentangling of nuisance factors via IBP-VAE - when combined with a supervised objective - can not only improve task accuracy in comparison to relevant supervised deep architectures, but also facilitate knowledge discovery related to task decision-making.","2374-8486","978-1-7281-4604-1","10.1109/ICDM.2019.00127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8970693","Variational Autoencoder;Non-parametric latent factor model;Disentangled Representation","","data mining;decision making;learning (artificial intelligence)","disentangled representation;variational auto-encoders;posterior density;latent density;data reconstruction;nonparametric latent factor model;Indian Buffet Process;clinical data;disentangled learning;IBP-VAE;unsupervised disentangling;beta Bernoulli process;knowledge discovery;task decision-making","","4","","29","","30 Jan 2020","","","IEEE","IEEE Conferences"
"Generative Graph Convolutional Network for Growing Graphs","D. Xu; C. Ruan; K. Motwani; E. Korpeoglu; S. Kumar; K. Achan","Walmart Labs, Sunnyvale, California, USA; Walmart Labs, Sunnyvale, California, USA; Walmart Labs, Sunnyvale, California, USA; Walmart Labs, Sunnyvale, California, USA; Walmart Labs, Sunnyvale, California, USA; Walmart Labs, Sunnyvale, California, USA","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","3167","3171","Modeling generative process of growing graphs has wide applications in social networks and recommendation systems, where cold start problem leads to new nodes isolated from existing graph. Despite the emerging literature in learning graph representation and graph generation, most of them can not handle isolated new nodes without nontrivial modifications. The challenge arises due to the fact that learning to generate representations for nodes in observed graph relies heavily on topological features, whereas for new nodes only node attributes are available. Here we propose a unified generative graph convolutional network that learns node representations for all nodes adaptively in a generative model framework, by sampling graph generation sequences constructed from observed graph data. We optimize over a variational lower bound that consists of a graph reconstruction term and an adaptive Kullback-Leibler divergence regularization term. We demonstrate the superior performance of our approach on several benchmark citation network datasets.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682360","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682360","Graph representation learning;sequential generative model;variational autoencoder;growing graph","Task analysis;Encoding;Decoding;Standards;Adaptation models;Training;Social networking (online)","convolutional neural nets;graph theory;Internet;learning (artificial intelligence);optimisation;recommender systems;social networking (online)","social networks;recommendation systems;cold start problem;graph representation;node representations;generative model framework;graph generation sequences;graph reconstruction term;generative graph convolutional network;graph data;variational lower bound optimization","","2","","23","","17 Apr 2019","","","IEEE","IEEE Conferences"
"DeVLearn: A Deep Visual Learning Framework for Determining the Location of Temporary Faults in Power Systems","S. Biswas; R. Meyur; V. A. Centeno","Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA","2020 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm)","30 Dec 2020","2020","","","1","6","Frequently recurring transient faults in a transmission network may be indicative of impending permanent failures. Hence, determining their location is a critical task. Large scale deployment of Phasor Measurement Units (PMU) in modern power grids has given utilities access to precise measurements at a high temporal resolution that may be utilized for estimating fault location. This paper proposes a novel image embedding aided deep learning framework called DeVLearn for faulted line location using PMU measurements at generator buses. Inspired by breakthroughs in computer vision, DeVLearn represents measurements (one-dimensional time series data) as two-dimensional unthresholded Recurrent Plot (RP) images. These RP images preserve the temporal relationships present in the original time series and are used to train a deep Variational Auto-Encoder (VAE). The VAE learns the distribution of latent features in the images. Our results show that for faults on two distinct lines in the IEEE 68-bus network, DeVLearn is able to project PMU measurements into a two-dimensional space such that data for faults at different locations separate into well-defined clusters. This compressed representation may then be used with off-the-shelf classifiers for determining fault location. The efficacy of the proposed framework is demonstrated using local voltage magnitude measurements at two generator buses.","","978-1-7281-6127-3","10.1109/SmartGridComm47815.2020.9302969","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302969","fault localization;deep learning;dimensionality reduction;image embedding;variational autoencoders;recurrence plots;CNN","Data models;Time series analysis;Phasor measurement units;Image reconstruction;Smart grids;Generators;Computational modeling","autoregressive processes;fault location;learning (artificial intelligence);phasor measurement;power distribution faults;power grids;power system measurement;power system stability;stochastic processes;time series","high temporal resolution;fault location;deep learning framework;DeVLearn;faulted line location;PMU measurements;generator buses;one-dimensional time series data;two-dimensional unthresholded Recurrent Plot images;RP images;temporal relationships;original time series;deep Variational Auto-Encoder;VAE;IEEE 68-bus network;two-dimensional space;local voltage magnitude measurements;deep visual learning framework;temporary faults;power systems;transient faults;transmission network;permanent failures;scale deployment;Phasor Measurement Units;modern power grids;utilities access;precise measurements","","1","","21","","30 Dec 2020","","","IEEE","IEEE Conferences"
"Diverse and Adjustable Versatile Image Enhancer","W. Kim; A. -D. Nguyen; J. Kim; J. Kim; H. Oh; S. Lee","Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea; Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea; Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea; Microsoft Research Asia, Beijing, China; Division of IT Convergence Engineering, Hansung University, Seoul, South Korea; Department of Radiology, College of Medicine, Yonsei University, Seoul, South Korea","IEEE Access","8 Jun 2021","2021","9","","80883","80896","Enhancing the quality of photographs is a highly subjective process and depends on users’ preferences. Hence, it is often more desired to let users choose their own best from a set of diverse and adjustable enhanced images with astounding quality. However, a system that can satisfy this requirement has not yet been established. While classical algorithms blindly enhance an image by filtering, recent intelligent enhancement systems can only do it with limited styles through learning from a set of single expert-retouched (ER) images. To fill this void, we propose a novel framework, Diverse and adjustable Versatile Image Enhancer (DaVIE), that learns from multiple ER images simultaneously. Thereby, it can output diverse results without being bound to a specific enhancement style while allowing users to freely adjust the level of enhancement. For ease of diversity, we adopt a variational auto-encoder (VAE) that learns stochastic distribution of enhancement styles. By using the VAE, the proposed model provides diversely enhanced images. To establish better control in terms of enhancement level, we propose a more general form of adaptive instance normalization and loss functions, which can afford even extreme image editing. Through rigorous experiments, we demonstrate that the proposed DaVIE framework yields visually pleasing and diverse results. We also show the proposed model quantitatively outperforms existing methods on the MIT-Adobe-5K dataset. Furthermore, through a strict user-study, we show that the users consider the qualities of ER images and machine-retouched images to be similar, with about 35% selection probability for DaVIE enhanced images.","2169-3536","","10.1109/ACCESS.2021.3084339","National Research Foundation of Korea (NRF) through the Korea Government (Ministry of Science and ICT, MSIT)(grant numbers:NRF-2020R1A2C3011697); Yonsei University Research Fund of 2021(grant numbers:2021-22-0001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442782","Diverse image enhancement;adjustable learning;automatic photo enhancement;variational autoencoder;adaptive-instance normalization","Image enhancement;Erbium;Training;Generative adversarial networks;Tools;Aerospace electronics","image enhancement;learning (artificial intelligence);probability","adjustable enhanced images;single expert-retouched images;multiple ER images;enhancement styles;diversely enhanced images;extreme image editing;machine-retouched images;intelligent enhancement systems;diverse and adjustable versatile image enhancer;DaVIE;variational auto-encoder;ER images;VAE;stochastic distribution learning","","","","60","CCBY","27 May 2021","","","IEEE","IEEE Journals"
"Learning modality-invariant representations for speech and images","K. Leidal; D. Harwath; J. Glass","Computer Science and Artificial Intelligence Laboratory Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory Massachusetts Institute of Technology, Cambridge, MA, USA","2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)","25 Jan 2018","2017","","","424","429","In this paper, we explore the unsupervised learning of a semantic embedding space for co-occurring sensory inputs. Specifically, we focus on the task of learning a semantic vector space for both spoken and handwritten digits using the TIDIGITs and MNIST datasets. Current techniques encode image and audio/textual inputs directly to semantic embeddings. In contrast, our technique maps an input to the mean and log variance vectors of a diagonal Gaussian from which sample semantic embeddings are drawn. In addition to encouraging semantic similarity between co-occurring inputs, our loss function includes a regularization term borrowed from variational autoencoders (VAEs) which drives the posterior distributions over embeddings to be unit Gaussian. We can use this regularization term to filter out modality information while preserving semantic information. We speculate this technique may be more broadly applicable to other areas of cross-modality/domain information retrieval and transfer learning.","","978-1-5090-4788-8","10.1109/ASRU.2017.8268967","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268967","Modality invariance;unsupervised speech processing;multimodal language processing;variational methods;regularization","Semantics;Speech;Task analysis;Training;Drives;Mathematical model;Labeling","Gaussian processes;information retrieval;text analysis;unsupervised learning;vectors","learning modality-invariant representations;unsupervised learning;semantic embedding space;sensory inputs;semantic vector space;spoken handwritten digits;diagonal Gaussian;sample semantic embeddings;semantic similarity;regularization term;transfer learning;MNIST dataset;TIDIGIT dataset;VAE;variational autoencoders;cross-modality-domain information retrieval;audio-textual inputs","","11","","16","","25 Jan 2018","","","IEEE","IEEE Conferences"
"Feature Learning for Enhanced Security in the Internet of Things","E. Mattei; C. Dalton; A. Draganov; B. Marin; M. Tinston; G. Harrison; B. Smarrelli; M. Harlacher","Expedition Technology, Inc.; Expedition Technology, Inc.; Expedition Technology, Inc.; Expedition Technology, Inc.; Expedition Technology, Inc.; Expedition Technology, Inc.; Expedition Technology, Inc.; Expedition Technology, Inc.","2019 IEEE Global Conference on Signal and Information Processing (GlobalSIP)","28 Jan 2020","2019","","","1","5","Identifying Internet of Things (IoT) devices by their Radio Frequency (RF) fingerprint has important security implications. As the number of connected devices grows, current authentication mechanisms are becoming more susceptible to device spoofing attacks. To combat this, we exploit hardware imperfections in the RF transmit chain to extract device-specific features that uniquely identify an emitter, providing an additional layer of security. This is accomplished with a complex-valued Variational Autoencoder that has a Gaussian Mixture (GMVAE) prior on the latent variables' marginal distribution. By exploiting sequential information in the RF time-series data, we achieve processing gain by integrating multiple latent-space representations from a single device. We test and analyze the proposed approach on real WiFi data and obtain excellent classification results. We also test the proposed model on an Out-of-Distribution (OOD) detection task.","","978-1-7281-2723-1","10.1109/GlobalSIP45357.2019.8969222","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8969222","Internet of Things;RF fingerprinting;Variational Inference;Deep Learning","","authorisation;Gaussian processes;Internet of Things;learning (artificial intelligence);time series","sequential information;RF time-series data;multiple latent-space representations;feature learning;enhanced security;Internet of Things devices;IoT;radio frequency fingerprint;authentication mechanisms;device spoofing attacks;RF transmit chain;device-specific features;Gaussian Mixture;complex-valued variational autoencoder;out-of-distribution detection task","","4","","11","","28 Jan 2020","","","IEEE","IEEE Conferences"
"A Statistical Comparative Study on Image Reconstruction and Clustering With Novel VAE Cost Function","A. Abdella; I. Uysal","Electrical Engineering Department, University of South Florida, Tampa, USA; Electrical Engineering Department, University of South Florida, Tampa, USA","IEEE Access","10 Feb 2020","2020","8","","25626","25637","Deep clustering achieves unprecedented levels of accuracy with unsupervised feature extraction on rich datasets where the joint statistics of the latent space is learned via highly nonlinear compression. This paper has two separate contributions to this field. First, we conduct an extensive and first-of-its-kind empirical study on the statistical relationship between the clustering accuracy and image reconstruction quality of a state-of-the-art deep clustering topology in the form of a convolutional variational autoencoder (VAE) with a K-means back end. We change the latent variable z at the bottleneck of the network to create different latent dimensions and explore how clustering performance metrics and reconstruction metrics are statistically related. Secondly, based on our data-driven statistical findings, we also propose a novel cost function for the VAE which includes the structural similarity index measure to jointly optimize image quality and latent statistics for improved clustering. The preliminary results show significant increases in clustering accuracy of as much as 10.76% on two popular benchmark datasets. The TensorFlow implementation for the experimental framework can be found here: https://github.com/alla15747/IEEE-Comparitive-Study-VAE-Paper-(Python code will be available at the time of publication).","2169-3536","","10.1109/ACCESS.2020.2971270","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8979378","Auto-encoder (AE);computer vision;convolutional neural network (CNN);deep learning (DL);image quality metrics;variational auto-encoder (VAE)","Image reconstruction;Image quality;Loss measurement;Indexes;Correlation;Brain modeling","data mining;feature extraction;image reconstruction;optimisation;pattern clustering;statistical analysis;unsupervised learning","statistical comparative Study;unprecedented levels;unsupervised feature extraction;joint statistics;latent space;first-of-its-kind empirical study;statistical relationship;clustering accuracy;image reconstruction quality;convolutional variational autoencoder;latent dimensions;clustering performance metrics;reconstruction metrics;data-driven statistical findings;cost function;structural similarity index measure;image quality;latent statistics;improved clustering;deep clustering topology;VAE cost function","","1","","47","CCBY","3 Feb 2020","","","IEEE","IEEE Journals"
"Topic-Aware Automatic Snippet Generation for Resolving Multiple Meaning on Web Search Result","H. Abe; M. Matsuhara; G. Chakraborty; H. Mabuchi","Graduate School of Software and Information Science, wate Prefectural University, Iwate, Japan; Faculty of Software and Information Science, Iwate Prefectural University, Iwate, Japan; Faculty of Software and Information Science, Iwate Prefectural University, Iwate, Japan; Faculty of Software and Information Science, Iwate Prefectural University, Iwate, Japan","2018 9th International Conference on Awareness Science and Technology (iCAST)","1 Nov 2018","2018","","","133","138","In recent years, the amount of information on the Web is growing exponentially with the spread of the Internet. We generally use search engines to search for the intended information. However, the search engine displays the Web pages including the entered search query in list format. It is difficult for the user to find out the intended information if the entered search query is a word whose meaning depends on the situation and location of the user. It needs the intended information to the multiple hidden topics. In this research, we classify Web search results based on each topic. The topic is defined as the latent meaning, and the contents included in the word. Moreover, our method displays automatically generated snippets for each topic with the Web search results to the user. It is easy to find required information from snippets, even though the intended information is ambiguous. It first classifies the Web search results by Latent Dirichlet Allocation (LDA) which is a major topic model method. It then generates the snippets using Conditional Variational AutoEncoder (Conditional VAE) based on the clustering of We search results. It is expected that using LDA for the clustering will group the Web search result according to the latent meanings of the search query. Also, we expect that proper snippets will be generated for each topic by Conditional VAE. In this paper, we show that LDA is effective for the clustering of Web search results. Moreover, the snippets generated by Conditional VAE is able to generate sentences considered each topic.","2325-5994","978-1-5386-5826-0","10.1109/ICAwST.2018.8517190","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517190","Information Retrieval;Web Search Result Clustering;Latent Dirichlet Allocation;Conditional Variational Auto-Encoder;Long Short-Term Memory","Web search;Web pages;Feature extraction;Decoding;Data models;Artificial neural networks;Uniform resource locators","Internet;natural language processing;query processing;search engines","Web search result;intended information;topic-aware automatic snippet generation;search engine;entered search query;Latent Dirichlet Allocation;conditional variational autoencoder;conditional VAE;latent meanings;LDA","","","","14","","1 Nov 2018","","","IEEE","IEEE Conferences"
"Reconstruction Error-Based Decomposition Feature Selection for PolSAR Image","C. Yang; B. Hou; X. Guo; B. Ren; J. Chanussot; S. Wang; L. Jiao","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi’an, Shaanxi, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi’an, Shaanxi, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi’an, Shaanxi, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi’an, Shaanxi, China; Laboratoire Jean Kuntzmann (LJK), Inria, Centre National de la Recherche Scientifique (CNRS), Grenoble Institute of Technology (Grenoble INP), Université Grenoble Alpes, Grenoble, France; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi’an, Shaanxi, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi’an, Shaanxi, China","IEEE Transactions on Geoscience and Remote Sensing","14 Feb 2022","2022","60","","1","19","Target decomposition features are the cornerstone of subsequent analyses for PolSAR images. Generally, adopting single or several decomposition algorithms limits the representation ability for original terrain characteristics. Using all the existing decomposition features, however, will definitely increase computational complexity. Besides, some features even have a negative effect on the following tasks. To address these problems, a sparse variational autoencoder feature selection framework (SVAE-FS) is proposed in this article. In detail, the encoder transforms the original feature set into latent space and then decoder reconstructs the corresponding pseudo set on this latent space. Similarly, a pseudo subset is subsequently obtained by the SVAE. The discrepancy, namely reconstruction error, between the pseudo set and the pseudo subset is taken as an evaluation criterion which reflects the feature representation ability of pseudo subset. Sparse constraint in the encoder makes the representative features stand out. Meanwhile, the linear feature transformation layer of the encoder enables the SVAE to evaluate different scale subsets without repeated training. Finally, a greedy selection approach with search scale  $K$  is proposed to find the suboptimal subset. This procedure not only reduces time consumption, but also ensures the performance of the subset. The selected features are analyzed on four real PolSAR datasets according to the terrain scattering characteristics. Furthermore, these features have achieved competitive performance on three PolSAR image tasks.","1558-0644","","10.1109/TGRS.2021.3125323","Key Scientific Technological Innovation Research Project by the Ministry of Education; National Natural Science Foundation of China(grant numbers:61671350,61771379,61836009); Foundation for Innovative Research Groups of the National Natural Science Foundation of China(grant numbers:61621005); Key Research and Development Program in Shaanxi Province of China(grant numbers:2019ZDLGY03-05); Higher Education Discipline Innovation Project; MIAI@Grenoble Alpes(grant numbers:ANR-19-P3IA-0003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9600819","Feature selection;reconstruction error;sparse variational auto encoder (VAE) (SVAE) feature selection (SVAE-FS);target decomposition","Feature extraction;Task analysis;Scattering;Image reconstruction;Training;Data models;Synthetic aperture radar","feature extraction;image coding;image reconstruction;image representation;radar imaging;synthetic aperture radar;terrain mapping","PolSAR image tasks;terrain scattering characteristics;PolSAR datasets;suboptimal subset;greedy selection approach;linear feature transformation layer;representative features;feature representation ability;latent space;SVAE-FS;sparse variational autoencoder feature selection framework;decomposition features;original terrain characteristics;single decomposition algorithms;subsequent analyses;target decomposition features;reconstruction error-based decomposition feature selection","","","","85","IEEE","4 Nov 2021","","","IEEE","IEEE Journals"
"Unsupervised Hybrid Deep Generative Models for Photovoltaic Synthetic Data Generation","D. A. Rosa de Jesús; P. Mandal; T. Senjyu; S. Kamalasadan","Power and Renewable Energy Systems (PRES) Lab. within the Department of Electrical and Computer Engineering, The University of Texas at El Paso, El Paso, TX, USA; Power and Renewable Energy Systems (PRES) Lab. within the Department of Electrical and Computer Engineering, The University of Texas at El Paso, El Paso, TX, USA; Department of Electrical and Electronics Engineering, University of the Ryukyus, Nishihara, Okinawa, Japan; Energy Production Infrastructure Center, and the Department of Electrical and Computer Engineering, University of North Carolina at Charlotte, Charlotte, NC, USA","2021 IEEE Power & Energy Society General Meeting (PESGM)","20 Dec 2021","2021","","","1","5","This paper contributes to the field of deep generative learning applied to solar photovoltaic (PV) synthetic data generation problems by exploring Deep Generative Model (DGM) that combines Variational Autoencoders (VAE) and Generative Adversarial Networks (GAN), i.e., VAEGAN. We build upon knowledge in the area of deep learning to incorporate our Hybrid Deep Neural Network (HDNN), combining convolutional and Long Short-Term Memory (LSTM) layers at the encoding level for producing robust latent representations and subsequently high-quality synthetic PV data samples. The major advantage of these approaches is that it allows the DGMs to perform better feature extraction as well as to capture the historical trends in data effectively. The simulations on actual data acquired from a real PV system demonstrate the effectiveness of the DGMs to produce high-quality samples for multiple seasons of the year.","1944-9933","978-1-6654-0507-2","10.1109/PESGM46819.2021.9637844","National Science Foundation(grant numbers:2021470,1840424); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9637844","Deep Learning;Generative Adversarial Networks;Solar Photovoltaic;Synthetic Data;Variational Autoen-coders","Photovoltaic systems;Deep learning;Privacy;Generative adversarial networks;Feature extraction;Market research;Data models","convolutional neural nets;deep learning (artificial intelligence);feature extraction;photovoltaic power systems;power engineering computing;recurrent neural nets;solar power stations;unsupervised learning","generative adversarial networks;deep generative learning;hybrid deep neural network;long short-term memory layers;high-quality synthetic PV data samples;unsupervised hybrid deep generative models;variational autoencoders;solar photovoltaic synthetic data generation;DGM;VAE;GAN;HDNN;convolutional layers;LSTM;encoding level;feature extraction","","","","20","IEEE","20 Dec 2021","","","IEEE","IEEE Conferences"
"A novel air quality evaluation method based on AP clustering and VAE model","C. Liang; J. Sheng; Z. Yuxuan; X. Haichao","School of Mechanical and Electric Engineering, Soochow University, Suzhou, China; School of Mechanical and Electric Engineering, Soochow University, Suzhou, China; School of Mechanical and Electric Engineering, Soochow University, Suzhou, China; School of Mechanical and Electric Engineering, Soochow University, Suzhou, China","2018 Chinese Control And Decision Conference (CCDC)","9 Jul 2018","2018","","","2574","2578","At present, we assess the air quality levels based on AQI which requires complex calculations and cannot evaluate the air quality comprehensively and effectively. Our air quality evaluation method not only can cluster air quality data precisely, but also can identify the air quality using unsupervised learning without any prior knowledge. We collect 2600 days' of air pollutants data from Baoding, Suzhou and Sanya which are clustered into 11 categories. A comparison between our clustering results and the air quality levels according to the traditional algorithm has been made. Moreover, we can identify a new air quality data set with the accuracy of about 96.5% based on variational autoencoder (VAE) model. This research will help people assess the air quality with air pollutants indexes more conveniently and scientifically.","1948-9447","978-1-5386-1244-6","10.1109/CCDC.2018.8407559","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8407559","clustering algorithm;air quality level;Variational Auto-Encoder","","air pollution;air quality;environmental science computing;pattern clustering;unsupervised learning","air quality levels;air pollutants data;air pollutants indexes;air quality evaluation;AP clustering;VAE model;air quality data clustering;variational autoencoder model;unsupervised learning","","","","17","","9 Jul 2018","","","IEEE","IEEE Conferences"
"A deep attention-driven model to forecast solar irradiance","A. Dairi; F. Harrou; Y. Sun","Computer Science department Signal, image and speech laboratory (SIMPA) laboratory, University of Science and Technology of Oran-Mohamed Boudiaf (USTO-MB), Oran, Algeria; Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia","2021 IEEE 19th International Conference on Industrial Informatics (INDIN)","11 Oct 2021","2021","","","1","6","Accurately forecasting solar irradiance is indispensable in optimally managing and designing photovoltaic systems. It enables the efficient integration of photovoltaic systems in the smart grid. This paper introduces an innovative deep attention-driven model for solar irradiance forecasting. Notably, an extended version of the variational autoencoder (VAE) is introduced by amalgamating the desirable characteristics of the bidirectional LSTM (BiLSTM) and attention mechanism with the VAE model. Specifically, the introduced approach enables the conventional VAE’s ability to model temporal dependencies by incorporating BiLSTM at the VAE’s encoder side to better extract and learn temporal dependencies embed on the solar irradiance concentration measurements. In addition, the self-attention mechanism is embedded in the VAE’s encoder side following the BiLSTM to highlight pertinent features. The performance of the proposed model is evaluated through comparisons with the recurrent neural network (RNN), gated recurrent unit (GRU), LSTM, and BiLSTM. Measurements of solar irradiance in the US and Turkey are used to evaluate the investigated models. Results confirm the superior performance of the proposed model for solar irradiance forecasting over the other models (i.e., RNN, GRU, LSTM, and BiLSTM).","","978-1-7281-4395-8","10.1109/INDIN45523.2021.9557405","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9557405","Variational auto encoder;self-attention;solar irradiation;forecasting;bidirectional recurrent neural network","Deep learning;Photovoltaic systems;Measurement;Recurrent neural networks;Time series analysis;Predictive models;Logic gates","deep learning (artificial intelligence);photovoltaic power systems;power engineering computing;recurrent neural nets;smart power grids;solar power stations","temporal dependencies;solar irradiance concentration measurements;self-attention mechanism;VAE's encoder side;BiLSTM;solar irradiance forecasting;photovoltaic systems;innovative deep attention-driven model;variational autoencoder;bidirectional LSTM;gated recurrent unit;recurrent neural network;smart grid","","","","44","","11 Oct 2021","","","IEEE","IEEE Conferences"
"Deep Gaussian Mixture-Hidden Markov Model for Classification of EEG Signals","M. Wang; S. Abdelfattah; N. Moustafa; J. Hu","School of Engineering and Information Technology, University of New South Wales Canberra at ADFA, Campbell, ACT, Australia; School of Engineering and Information Technology, University of New South Wales Canberra at ADFA, Campbell, ACT, Australia; School of Engineering and Information Technology, University of New South Wales Canberra at ADFA, Campbell, ACT, Australia; School of Engineering and Information Technology, University of New South Wales Canberra at ADFA, Campbell, ACT, Australia","IEEE Transactions on Emerging Topics in Computational Intelligence","20 Jul 2018","2018","2","4","278","287","Electroencephalography (EEG) signals are complex dynamic phenomena that exhibit nonlinear and nonstationary behaviors. These characteristics tend to undermine the reliability of existing hand-crafted EEG features that ignore time-varying information and impair the performances of classification models. In this paper, we propose a novel method that can automatically capture the nonstationary dynamics of EEG signals for diverse classification tasks. It consists of two components. The first component uses an autoregressive-deep variational autoencoder model for automatic feature extraction, and the second component uses a Gaussian mixture-hidden Markov model for EEG classification with the extracted features. We compare the performance of our proposed method and the state-of-the-art methods in two EEG classification tasks, subject, and event classification. Results show that our approach outperforms the others by averages of 15% ± 6.3 (p-value <; 0.05) and 22% ± 5.7 (p-value <; 0.05) for subject and event classifications, respectively.","2471-285X","","10.1109/TETCI.2018.2829981","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8416796","EEG classification;time-series;deep learning;autoencoder;Gaussian mixture model;hidden Markov model","Electroencephalography;Brain modeling;Hidden Markov models;Feature extraction;Task analysis;Machine learning;Markov processes","electroencephalography;feature extraction;Gaussian processes;hidden Markov models;medical signal processing;signal classification","electroencephalography signals;complex dynamic phenomena;time-varying information;classification models;nonstationary dynamics;diverse classification tasks;autoregressive-deep variational autoencoder model;automatic feature extraction;EEG classification tasks;event classification;deep Gaussian mixture-hidden Markov model;EEG signal classification;hand-crafted EEG features","","30","","37","IEEE","20 Jul 2018","","","IEEE","IEEE Journals"
"Deep Feature Clustering for Seeking Patterns in Daily Harmonic Variations","C. Ge; R. A. de Oliveira; I. Y. -H. Gu; M. H. J. Bollen","Department of Electrical Engineering, Chalmers University of Technology, Gothenburg, Sweden; Electric Power Engineering, Luleå University of Technology, Skellefteå, Sweden; Department of Electrical Engineering, Chalmers University of Technology, Gothenburg, Sweden; Electric Power Engineering, Luleå University of Technology, Skellefteå, Sweden","IEEE Transactions on Instrumentation and Measurement","17 Nov 2020","2021","70","","1","10","This article proposes a novel scheme for analyzing power system measurement data. The main question that we seek answers in this study is on “whether one can find some important patterns that are hidden in the large data of power system measurements such as variational data.” The proposed scheme uses an unsupervised deep feature learning approach by first employing a deep autoencoder (DAE) followed by feature clustering. An analysis is performed by examining the patterns of clusters and reconstructing the representative data sequence for the clustering centers. The scheme is illustrated by applying it to the daily variations of harmonic voltage distortion in a low-voltage network. The main contributions of the article include: 1) providing a new unsupervised deep feature learning approach for seeking possible underlying patterns of power system variation measurements and 2) proposing an effective empirical analysis approach for understanding the measurements through examining the underlying feature clusters and the associated reconstructed data by DAE.","1557-9662","","10.1109/TIM.2020.3016408","Swedish Energy Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9166530","Autoencoder;clustering;deep learning;pattern analysis;power quality;power system harmonics;unsupervised learning","Machine learning;Power quality;Decoding;Training;Power system harmonics;Harmonic analysis;Power system measurements","neural nets;pattern clustering;power engineering computing;power system harmonics;power system measurement;unsupervised learning","empirical analysis approach;associated reconstructed data;harmonic voltage distortion;clustering centers;data sequence;deep autoencoder;unsupervised deep feature learning approach;variational data;power system measurements;power system measurement data;deep feature clustering","","6","","36","IEEE","13 Aug 2020","","","IEEE","IEEE Journals"
"A Novel Group Recommendation Model With Two-Stage Deep Learning","Z. Huang; Y. Liu; C. Zhan; C. Lin; W. Cai; Y. Chen","School of Computer Science, South China Normal University, Guangzhou, China; School of Computer Science, South China Normal University, Guangzhou, China; School of Computer Science, South China Normal University, Guangzhou, China; School of Informatics, Xiamen University, Xiamen, China; Graduate School, Northern Arizona University, Flagstaff, AZ, USA; Research and Development Department, DataGrand Inc., Shenzhen, China","IEEE Transactions on Systems, Man, and Cybernetics: Systems","17 Aug 2022","2022","52","9","5853","5864","Group recommendation has recently drawn a lot of attention to the recommender system community. Currently, several deep learning-based approaches are leveraged to learn preferences of groups for items and predict next items in which groups may be interested. Yet, their recommendation performance is still unsatisfactory due to sparse group–item interactions. To address this challenge, this study presents a novel model, called group recommendation model with two-stage deep learning (GRMTDL), which encompasses two sequential stages: 1) group representation learning (GRL) and 2) group preference learning (GPL). In GRL, we first construct an undirected tripartite graph over group–user–item interactions, and then employ it to accurately learn group semantic features through a spatial-based variational graph autoencoder network. While in GPL, we first introduce a dual PL-network that contains two structure-sharing subnetworks: 1) group PL-network employed for GPL and 2) user PL-network utilized for user preference learning. Then, we design a novel layered transfer learning (LTL) method to learn group preferences by alternately optimizing these two subnetworks. In particular, it can effectively absorb knowledge of user preferences into the process of GPL. Furthermore, extensive experiments on four real-world datasets demonstrate that the proposed GRMTDL model outperforms the state-of-the-art baselines for group recommendation.","2168-2232","","10.1109/TSMC.2021.3131349","National Natural Science Foundation of China(grant numbers:62172166,61772366); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9644586","Deep learning;graph autoencoder;group recommendation;knowledge transferring;representation learning","Semantics;Deep learning;Task analysis;Decision making;Training;Recommender systems;Representation learning","graph theory;learning (artificial intelligence);recommender systems","sequential stages;called group recommendation model;group-item interactions;deep learning-based approaches;recommender system community;two-stage deep learning;novel group recommendation model;GRMTDL model;user preferences;group preferences;transfer learning method;user preference learning;dual PL-network;GPL;spatial-based variational graph autoencoder network;group semantic features;group-user-item interactions","","3","","53","IEEE","10 Dec 2021","","","IEEE","IEEE Journals"
"High-Speed Adder Design Space Exploration via Graph Neural Processes","H. Geng; Y. Ma; Q. Xu; J. Miao; S. Roy; B. Yu","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, SAR; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, SAR; School of Microelectronics, University of Science and Technology of China, Hefei, China; Google, Mountain View, CA, USA; Design and Sign-Off Group-Machine Learning Group, Cadence Design Systems, San Jose, CA, USA; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, SAR","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","18 Jul 2022","2022","41","8","2657","2670","Adders are the primary components in the data-path logic of a microprocessor, and thus, adder design has been always a critical issue in the very large-scale integration (VLSI) industry. However, it is infeasible for designers to obtain optimal adder architecture by exhaustively running EDA flow due to the extremely large design space. Previous arts have proposed the machine learning-based framework to explore the design space. Nevertheless, they fall into suboptimality due to a two-stage flow of the learning process and less efficient nor effective feature representations of prefix adder structures. In this article, we first integrate a variational graph autoencoder and a neural process (NP) into an end-to-end, multibranch framework, which is termed the graph neural process. The former performs automatic feature learning of prefix adder structures, whilst the latter one is designed as an alternative to the Gaussian process. Then, we propose a sequential optimization framework with the graph NP as the surrogate model to explore the Pareto-optimal prefix adder structures with tradeoff among Quality-of-Result (QoR) metrics, such as power, area, and delay. The experimental results show that compared with state-of-the-art methodologies, our framework can achieve a much better Pareto frontier in multiple QoR metric spaces with fewer design-flow evaluations.","1937-4151","","10.1109/TCAD.2021.3114262","HiSilicon Technologies Company, ACCESS–AI Chip Center for Emerging Smart Systems, Hong Kong SAR; The Research Grants Council of Hong Kong SAR(grant numbers:CUHK14209420); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9542936","Design space exploration;graph autoencoder;graph neural process;high speed adder;neural process;sequential model-based optimization","Adders;Very large scale integration;Space exploration;Delays;Tools;Physical design;Gaussian processes","adders;electronic engineering computing;Gaussian processes;graph theory;integrated circuit design;learning (artificial intelligence);logic design;optimisation;VLSI","high-speed adder design space exploration;graph neural process;primary components;data-path logic;large-scale integration industry;optimal adder architecture;EDA flow;two-stage flow;learning process;efficient nor effective feature representations;variational graph autoencoder;multibranch framework;performs automatic feature learning;Gaussian process;sequential optimization framework;graph NP;Pareto-optimal prefix adder structures;multiple QoR metric spaces;fewer design-flow evaluations;microprocessor;very large-scale integration;VLSI industry;machine learning-based framework;design space;prefix adder structures;automatic feature learning;quality-of-result;Pareto frontier","","2","","48","IEEE","21 Sep 2021","","","IEEE","IEEE Journals"
"Improving Generative Modelling in VAEs Using Multimodal Prior","V. Abrol; P. Sharma; A. Patra","Mathematical Institute, University of Oxford, Oxford, U.K.; Department of Engineering Science, University of Oxford, Oxford, U.K.; Department of Engineering Science, University of Oxford, Oxford, U.K.","IEEE Transactions on Multimedia","25 Jun 2021","2021","23","","2153","2161","In this paper we propose a conditional generative modelling (CGM) approach for unsupervised disentangled representation learning using variational autoencoder (VAE). CGM employs a multimodal/categorical conditional prior distribution in the latent space to learn global uncertainty in data by modelling the variations at local level. Thus, the proposed framework enforces the model to independently estimate the inherent patterns within each category, which improves the interpretability of the latent representations learned by the VAE model. The evidence lower bound objective for training the generative model is maximized using a mutual information criterion between the global latent categorical variable and the encoded inputs. Further, the approach has a built-in mechanism for bounding the information flow between the encoder and the decoder which addresses the problems of posterior collapse in conventional VAE models. Experiments on a variety of datasets demonstrate that our objective can learn disentangled representations and the proposed approach achieves competitive results on various task such as generative modelling, image classification and image denoising.","1941-0077","","10.1109/TMM.2020.3008053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9136917","Generative modelling;autoencoders;matching network;representation learning","Object oriented modeling;Training;Mutual information;Decoding;Kernel;Data models;Uncertainty","data handling;image classification;image denoising;image representation;learning (artificial intelligence);neural net architecture;unsupervised learning","CGM;unsupervised disentangled representation;variational autoencoder;conditional prior distribution;latent space;latent representations;conventional VAE models;conditional generative modelling","","2","","56","IEEE","8 Jul 2020","","","IEEE","IEEE Journals"
"Contextual Bandit Guided Data Farming for Deep Neural Networks in Manufacturing Industrial Internet","Y. Zeng; P. Shojaee; S. H. Akhter Faruqui; A. Alaeddini; R. Jin","Grado Department of Industrial and Systems Engineering, Virginia Tech, Blacksburg, USA; Grado Department of Industrial and Systems Engineering, Virginia Tech, Blacksburg, USA; Department of Radiology, Northwestern University, Evanston, USA; Department of Mechanical Engineering, University of Texas at San Antonio, San Antonio, USA; Grado Department of Industrial and Systems Engineering, Virginia Tech, Blacksburg, USA","2022 IEEE 5th International Conference on Industrial Cyber-Physical Systems (ICPS)","18 Jul 2022","2022","","","1","6","Deep Neural Networks (DNNs) have shown superior performance in supervised learning in Industrial Internet applications, such as quality modeling, virtual inspection, etc. However, the performance of DNNs relies on large and high quality data sets with sufficient sample sizes and appropriate distributions. Additionally, collecting and labeling large data sets can be labor-intensive and may fall short of meeting the online computational needs, including the fact that more samples in training may not always improve the modeling performance. Inspired by the theory of Design of Experiments, we propose a Contextual Bandit-based Representation Design (CBRD) to generate data suitable for training DNNs. The CBRD combines the offline experimental design criteria as the arms of a contextual bandit model for DNN training in a joint and interactive way for online batch data. A low-dimensional representation of the input design space learned by variational autoencoder is used to generate new samples. The integration of VAE and contextual bandit enables the generation of samples adaptive to modeling performance. A real case study of Aerosol® Jet Printing process is used to demonstrate the merits of the CBRD method.","","978-1-6654-9770-1","10.1109/ICPS51978.2022.9816900","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9816900","Deep Neural Network;Data Farming;Manufac-turing Industrial Internet;Varational Autoencoder","Training;Deep learning;Printing;Adaptation models;Computational modeling;Neural networks;Supervised learning","data handling;deep learning (artificial intelligence);design of experiments;ink jet printing;Internet;production engineering computing;supervised learning","deep neural networks;manufacturing Industrial Internet;supervised learning;CBRD;offline experimental design criteria;contextual bandit model;DNN training;online batch data;low-dimensional representation;contextual bandit guided data farming;contextual bandit-based representation design;design of experiments;aerosol jet printing process;variational autoencoder","","","","30","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"Informative Feature Disentanglement for Unsupervised Domain Adaptation","W. Deng; L. Zhao; Q. Liao; D. Guo; G. Kuang; D. Hu; M. Pietikäinen; L. Liu","State Key Laboratory of Complex Electromagnetic Environment Effects on Electronics, and Information System, College of Electronic Science, National University of Defense technology, Changsha, China; State Key Laboratory of Complex Electromagnetic Environment Effects on Electronics, and Information System, College of Electronic Science, National University of Defense technology, Changsha, China; Department of Computer Science, and Technology, Harbin Institute of Technology, Shenzhen, China; College of System Engineering, National University of Defense Technology, Changsha, China; State Key Laboratory of Complex Electromagnetic Environment Effects on Electronics, and Information System, College of Electronic Science, National University of Defense technology, Changsha, China; College of Intelligent Science, National University of Defense Technology, Changsha, China; Center for Machine Vision, and Signal analysis, University of Oulu, Oulu, Finland; Center for Machine Vision, and Signal analysis, University of Oulu, Oulu, Finland","IEEE Transactions on Multimedia","11 May 2022","2022","24","","2407","2421","Unsupervised Domain Adaptation (UDA) aims at learning a classifier for an unlabeled target domain by transferring knowledge from a labeled source domain with a related but different distribution. The strategy of aligning the two domains in latent feature space via metric discrepancy or adversarial learning has achieved considerable progress. However, these existing approaches mainly focus on adapting the entire image and ignore the bottleneck that occurs when forced adaptation of uninformative domain-specific variations undermines the effectiveness of learned features. To address this problem, we propose a novel component called Informative Feature Disentanglement (IFD), which is equipped with the adversarial network or the metric discrepancy model, respectively. Accordingly, the new network architectures, named IFDAN and IFDMN, enable informative feature refinement before the adaptation. The proposed IFD is designed to disentangle informative features from the uninformative domain-specific variations, which are produced by a Variational Autoencoder (VAE) with lateral connections from the encoder to the decoder. We cooperatively apply the IFD to conduct supervised disentanglement for the source domain and unsupervised disentanglement for the target domain. In this way, informative features are disentangled from the domain-specific details before the adaptation. Extensive experimental results on three gold-standard domain adaptation datasets, e.g., Office31, Office-Home and VisDA-C, demonstrate the effectiveness of the proposed IFDAN and IFDMN models for UDA.","1941-0077","","10.1109/TMM.2021.3080516","National Natural Science Foundation of China(grant numbers:62022091,61872379,71701205,61701508,62036013); Academy of Finland(grant numbers:331883); Natural Science Foundation of Hunan Province(grant numbers:2018JJ3613); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9437964","Domain Adaptation;deep learning;deep convolutional neural network;autoencoder;transfer learning;unsupervised learning","Task analysis;Measurement;Feature extraction;Wheels;Image reconstruction;Image color analysis;Adaptation models","feature extraction;image classification;neural nets;unsupervised learning","unlabeled target domain;labeled source domain;IFD;metric discrepancy model;informative feature refinement;informative features;supervised disentanglement;unsupervised disentanglement;informative feature disentanglement;UDA;unsupervised domain adaptation;adversarial network;network architectures;IFDAN;IFDMN;uninformative domain-specific variations;variational autoencoder;VAE","","","","88","CCBY","20 May 2021","","","IEEE","IEEE Journals"
"Identifying Latent Stochastic Differential Equations","A. Hasan; J. M. Pereira; S. Farsiu; V. Tarokh","Department of Biomedical Engineering, Duke University, Durham, NC, USA; Oden Institute for Computational Engineering and Sciences, University of Texas at Austin, Austin, TX, USA; Department of Biomedical Engineering, Duke University, Durham, NC, USA; Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA","IEEE Transactions on Signal Processing","7 Jan 2022","2022","70","","89","104","We present a method for learning latent stochastic differential equations (SDEs) from high dimensional time series data. Given a high-dimensional time series generated from a lower dimensional latent unknown Itô process, the proposed method learns the mapping from ambient to latent space, and the underlying SDE coefficients, through a self-supervised learning approach. Using the framework of variational autoencoders, we consider a conditional generative model for the data based on the Euler-Maruyama approximation of SDE solutions. Furthermore, we use recent results on identifiability of latent variable models to show that the proposed model can recover not only the underlying SDE coefficients, but also the original latent variables, up to an isometry, in the limit of infinite data. We validate the method through several simulated video processing tasks, where the underlying SDE is known, and through real world datasets.","1941-0476","","10.1109/TSP.2021.3131723","Office of Naval Research(grant numbers:N00014-18-1-224); National Science Foundation Graduate Research Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9632430","Stochastic differential equations;autoencoder;latent space;identifiablity;data-driven discovery","Differential equations;Indium tin oxide;Data models;Biological system modeling;Tools;Time series analysis;Mathematical models","approximation theory;differential equations;neural nets;stochastic processes;supervised learning;time series;video signal processing","high dimensional time series data;lower dimensional latent unknown Itô process;SDE coefficients;self-supervised learning approach;conditional generative model;Euler-Maruyama approximation;SDE solutions;latent variable models;simulated video processing tasks;latent stochastic differential equation identification;variational autoencoder","","","","35","IEEE","1 Dec 2021","","","IEEE","IEEE Journals"
"MUGL: Large Scale Multi Person Conditional Action Generation with Locomotion","S. Maheshwari; D. Gupta; R. K. Sarvadevabhatla","Centre for Visual Information Technology, IIIT Hyderabad, Hyderabad, India; Centre for Visual Information Technology, IIIT Hyderabad, Hyderabad, India; Centre for Visual Information Technology, IIIT Hyderabad, Hyderabad, India","2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)","15 Feb 2022","2022","","","747","755","We introduce MUGL, a novel deep neural model for large-scale, diverse generation of single and multi-person pose-based action sequences with locomotion. Our controllable approach enables variable-length generations customizable by action category, across more than 100 categories. To enable intra/inter-category diversity, we model the latent generative space using a Conditional Gaussian Mixture Variational Autoencoder. To enable realistic generation of actions involving locomotion, we decouple local pose and global trajectory components of the action sequence. We incorporate duration-aware feature representations to enable variable-length sequence generation. We use a hybrid pose sequence representation with 3D pose sequences sourced from videos and 3D Kinect-based sequences of NTU-RGBD-120. To enable principled comparison of generation quality, we employ suitably modified strong baselines during evaluation. Although smaller and simpler compared to baselines, MUGL provides better quality generations, paving the way for practical and controllable large-scale human action generation.","2642-9381","978-1-6654-0915-5","10.1109/WACV51458.2022.00082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9706923","Action and Behavior Recognition Deep Learning -> Neural Generative Models; Autoencoders; GANs; Motion Processing","Computer vision;Three-dimensional displays;Shape;Aerospace electronics;Rendering (computer graphics);Skeleton;Trajectory","convolutional neural nets;deep learning (artificial intelligence);feature extraction;Gaussian processes;image motion analysis;image representation;image sequences;pose estimation;video signal processing","variable-length generations;latent generative space;action sequence;variable-length sequence generation;sequence representation;3D pose sequences;3D Kinect-based sequences;MUGL;large-scale human action generation;deep neural model;large scale multiperson conditional action generation;duration-aware feature representations;conditional Gaussian mixture variational autoencoder","","","","40","IEEE","15 Feb 2022","","","IEEE","IEEE Conferences"
"Election Tally Sheets Processing System","J. I. Toledo; A. Fornés; J. Cucurull; J. Lladós","Scytl Secure Electronic Voting, Barcelona, Spain; Scytl Secure Electronic Voting, Barcelona, Spain; Scytl Secure Electronic Voting, Barcelona, Spain; Scytl Secure Electronic Voting, Barcelona, Spain","2016 12th IAPR Workshop on Document Analysis Systems (DAS)","13 Jun 2016","2016","","","364","368","In paper based elections, manual tallies at polling station level produce myriads of documents. These documents share a common form-like structure and a reduced vocabulary worldwide. On the other hand, each tally sheet is filled by a different writer and on different countries, different scripts are used. We present a complete document analysis system for electoral tally sheet processing combining state of the art techniques with a new handwriting recognition subprocess based on unsupervised feature discovery with Variational Autoencoders and sequence classification with BLSTM neural networks. The whole system is designed to be script independent and allows a fast and reliable results consolidation process with reduced operational cost.","","978-1-5090-1792-8","10.1109/DAS.2016.37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7490145","Electoral documents;electronic voting;document analysis system;feature learning;autoencoders","Handwriting recognition;Nominations and elections;Training;Text analysis;Recurrent neural networks;Databases","document image processing;handwriting recognition;image classification;neural nets;unsupervised learning","election tally sheets processing system;paper based election;document analysis system;handwriting recognition subprocess;unsupervised feature discovery;variational autoencoder;sequence classification;BLSTM neural network","","","1","18","","13 Jun 2016","","","IEEE","IEEE Conferences"
"iVAE: An Improved Deep Learning Structure for EEG Signal Characterization and Reconstruction","Z. Chen; N. Ono; M. Altaf-Ul-Amin; S. Kanaya; M. Huang","Nara Insitute of Science and Technology, Nara, Japan; Nara Insitute of Science and Technology, Nara, Japan; Nara Insitute of Science and Technology, Nara, Japan; Nara Insitute of Science and Technology, Nara, Japan; Nara Insitute of Science and Technology, Nara, Japan","2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","13 Jan 2021","2020","","","1909","1913","Due to the inherent variability such as inter-users anatomical variability and the inter-systems differences, the design of new EEG-based index and a reliable model for sleep stages classification is still the main topic in sleep science. The unsupervised deep learning framework-variational autoencoder (VAE) which can capture the major characteristics of the input by imposing a Gaussian prior distribution on the latent features is suitable in EEG characterization and reconstruction. Although vanilla VAE and convolutional autoencoder (CAE) have been tried, it has yet been discussed that whether a deep structure or a multi-scale structure is more appropriate. In this paper, we constructed a shallow iVAE model, which will capture the multi-scale features of the spectrogram of EEG by replacing the main structure in encoder and decoder with the inception-like structure. By comparing with the vanilla VAE and the CAE, a more accurate reconstruction and a better classification using the latent features of the iVAE can be confirmed.","","978-1-7281-6215-7","10.1109/BIBM49941.2020.9313107","Japan Society for the Promotion of Science; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9313107","EEG;spectrogram;VAE;Inception","Sleep;Two dimensional displays;Electroencephalography;Spectrogram;Brain modeling;Feature extraction;Decoding","convolutional neural nets;electroencephalography;medical signal processing;signal classification;signal reconstruction;sleep;unsupervised learning","sleep stages classification;Gaussian prior distribution;unsupervised deep learning;vanilla VAE;convolutional autoencoder;CAE;inception-like structure;EEG signal reconstruction;shallow iVAE;variational autoencoder;interusers anatomical variability","","3","","22","","13 Jan 2021","","","IEEE","IEEE Conferences"
"DeepGalaxy: Deducing the Properties of Galaxy Mergers from Images Using Deep Neural Networks","M. X. Cai; J. Bédorf; V. A. Saletore; V. Codreanu; D. Podareanu; A. Chaibi; P. X. Qian","SURF Corporative, Amsterdam, The Netherlands; minds.ai, CA, Santa Cruz, USA; Intel Corporation, OR, Hillsboro, USA; SURF Corporative, Amsterdam, The Netherlands; SURF Corporative, Amsterdam, The Netherlands; Intel Corporation, Paris, France; Leiden University, Leiden, The Netherlands","2020 IEEE/ACM Fourth Workshop on Deep Learning on Supercomputers (DLS)","21 Dec 2020","2020","","","56","62","Galaxy mergers, the dynamical process during which two galaxies collide, are among the most spectacular phenomena in the Universe. During this process, the two colliding galaxies are tidally disrupted, producing significant visual features that evolve as a function of time. These visual features contain valuable clues for deducing the physical properties of the galaxy mergers. In this work, we propose DeepGalaxy, a visual analysis framework trained to predict the physical properties of galaxy mergers based on their morphology. Based on an encoder-decoder architecture, DeepGalaxy encodes the input images to a compressed latent space z, and determines the similarity of images according to the latent-space distance. DeepGalaxy consists of a fully convolutional autoencoder (FCAE) which generates activation maps at its 3D latent-space, and a variational autoencoder (VAE) which compresses the activation maps into a 1D vector, and a classifier that generates labels from the activation maps. The backbone of the FCAE can be fully customized according to the complexity of the images. DeepGalaxy demonstrates excellent scaling performance on parallel machines. On the Endeavour supercomputer, the scaling efficiency exceeds 0.93 when trained on 128 workers, and it maintains above 0.73 when trained with 512 workers. Without having to carry out expensive numerical simulations, DeepGalaxy makes inferences of the physical properties of galaxy mergers directly from images, and thereby achieves a speedup factor of ~105.","","978-1-6654-2245-1","10.1109/DLS51937.2020.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9297124","classification;image searching;high performance computing;astrophysics;galaxy mergers","Training;Corporate acquisitions;Data models;Morphology;Image resolution;Training data;Supercomputers","astronomical image processing;convolutional neural nets;data visualisation;deep learning (artificial intelligence);galaxies;image classification;neural net architecture;parallel machines","galaxy mergers;DeepGalaxy;activation maps;physical properties;colliding galaxies;visual features;deep neural networks;visual analysis framework;fully convolutional autoencoder;Endeavour supercomputer;encoder-decoder architecture;3D latent-space;variational autoencoder;parallel machines","","2","","28","","21 Dec 2020","","","IEEE","IEEE Conferences"
"Uncovering the Folding Landscape of RNA Secondary Structure Using Deep Graph Embeddings","E. Castro; A. Benz; A. Tong; G. Wolf; S. Krishnaswamy","Comp. Biol. and Bioinf. Program, Yale University, New Haven, CT, USA; Dept. of Mathematics, Yale University, New Haven, CT, USA; Dept. of Computer Science, Yale University, New Haven, CT, USA; Dept. of Math. and Stat, Univ. de Montréal; Mila, Montreal, Canada; Depts. of Genetics & Comp. Sci, Yale University, New Haven, CT, USA","2020 IEEE International Conference on Big Data (Big Data)","19 Mar 2021","2020","","","4519","4528","Biomolecular graph analysis has recently gained much attention in the emerging field of geometric deep learning. Here we focus on organizing biomolecular graphs in ways that expose meaningful relations and variations between them. We propose a geometric scattering autoencoder (GSAE) network for learning such graph embeddings. Our embedding network first extracts rich graph features using the recently proposed geometric scattering transform. Then, it leverages a semi-supervised variational autoencoder to extract a low-dimensional embedding that retains the information in these features that enable prediction of molecular properties as well as characterize graphs. We show that GSAE organizes RNA graphs both by structure and energy, accurately reflecting b istable R NA s tructures. A lso, the model is generative and can sample new folding trajectories.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9378305","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378305","graph embedding;molecular structures;self-supervised learning","Training;RNA;Scattering;Transforms;Molecular biophysics;Feature extraction;Space exploration","biology computing;graph theory;macromolecules;molecular biophysics;RNA;unsupervised learning","folding landscape;RNA secondary structure;deep graph embeddings;biomolecular graph analysis;geometric deep learning;biomolecular graphs;meaningful relations;geometric scattering autoencoder network;embedding network;geometric scattering;semisupervised variational autoencoder;low-dimensional embedding;characterize graphs;GSAE organizes RNA;folding trajectories;rich graph features","","1","","37","","19 Mar 2021","","","IEEE","IEEE Conferences"
"Incorporating Real-World Noisy Speech in Neural-Network-Based Speech Enhancement Systems","Y. Xia; B. Xu; A. Kumar","Dept. of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Facebook Reality Labs Research, Redmond, WA, USA; Facebook Reality Labs Research, Redmond, WA, USA","2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)","3 Feb 2022","2021","","","564","570","Supervised speech enhancement relies on parallel databases of degraded speech signals and their clean reference signals during training. This setting prohibits the use of real-world degraded speech data that may better represent the scenarios where such systems are used. In this paper, we explore methods that enable supervised speech enhancement systems to train on real-world degraded speech data. Specifically, we propose a semi-supervised approach for speech enhancement in which we first train a modified vector-quantized variational autoencoder that solves a source separation task. We then use this trained autoencoder to further train an enhancement network using real-world noisy speech data by computing a triplet-based unsupervised loss function. Experiments show promising results for incorporating real-world data in training speech enhancement systems.","","978-1-6654-3739-4","10.1109/ASRU51503.2021.9688176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9688176","speech enhancement;self-supervised learning;real-world data;triplet loss","Training;Source separation;Databases;Conferences;Training data;Speech enhancement;Noise measurement","learning (artificial intelligence);neural nets;source separation;speech enhancement","neural-network-based speech enhancement systems;parallel databases;degraded speech signals;clean reference signals;supervised speech enhancement systems;semisupervised approach;modified vector-quantized variational autoencoder;trained autoencoder;enhancement network;real-world noisy speech data;triplet-based unsupervised loss function;real-world data;training speech enhancement systems","","1","","22","IEEE","3 Feb 2022","","","IEEE","IEEE Conferences"
"Latent Representation Learning and Manipulation for Privacy-Preserving Sensor Data Analytics","O. Hajihassani; O. Ardakanian; H. Khazaei","University of Alberta, Edmonton, Canada; University of Alberta, Edmonton, Canada; York University, Toronto, Canada","2020 IEEE Second Workshop on Machine Learning on Edge in Sensor Systems (SenSys-ML)","9 Jun 2020","2020","","","7","12","The rapid deployment of sensor systems in homes and work environments, and new applications of machine learning at the edge have posed an enormous and unprecedented threat to privacy. In this paper we investigate the ability of existing deep neural network models trained in an adversarial fashion to enhance privacy without sacrificing data utility, and propose a re-identification attack that could effectively hinder them from hiding private data. This highlights an important problem with anonymization techniques that rely on adversarial training. To address this problem, we perform deterministic and probabilistic arithmetic operations in the learned latent variable space of a variational autoencoder and show empirically that it makes the anonymized data less susceptible to the proposed re-identification attack. Our experiments on a Human Activity Recognition data set confirm that the proposed deterministic manipulation of the latent variables outperforms the state-of-the-art anonymizing autoencoders, reducing the accuracy of a gender identification model by an additional 16% without noticeably affecting the accuracy of the activity recognition model. Moreover, the accuracy of the gender re-identification model is further reduced by 16.25% on average thanks to the proposed probabilistic manipulation.","","978-1-7281-9996-2","10.1109/SenSysML50931.2020.00009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9111809","","Training;Representation learning;Deep learning;Privacy;Data privacy;Data analysis;Neural networks","data analysis;data privacy;learning (artificial intelligence);neural nets","privacy-preserving sensor data analytics;sensor systems;work environments;machine learning;unprecedented threat;deep neural network models;data utility;re-identification attack;private data;anonymization techniques;adversarial training;arithmetic operations;learned latent variable space;variational autoencoder;anonymized data;human activity recognition data;deterministic manipulation;activity recognition model;gender re-identification model;probabilistic manipulation;anonymizing autoencoders","","","","15","","9 Jun 2020","","","IEEE","IEEE Conferences"
"Deep Generative Model for Spatial–Spectral Unmixing With Multiple Endmember Priors","S. Shi; L. Zhang; Y. Altmann; J. Chen","Center of Intelligent Acoustics and Immersive Communications, School of Marine Science and Technology, Northwestern Polytechnical University, Xi’an, China; Center of Intelligent Acoustics and Immersive Communications, School of Marine Science and Technology, Northwestern Polytechnical University, Xi’an, China; School of Engineering and Physical Sciences, Heriot Watt University, Edinburgh, U.K; Center of Intelligent Acoustics and Immersive Communications, School of Marine Science and Technology, Northwestern Polytechnical University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","3 May 2022","2022","60","","1","14","Spectral unmixing is an effective tool to mine information at the subpixel level from complex hyperspectral images. To consider the spatially correlated materials distributions in the scene, many algorithms unmix the data in a spatial–spectral fashion; however, existing models are usually unable to model spectral variability simultaneously. In this article, we present a variational autoencoder-based deep generative model for spatial–spectral unmixing (DGMSSU) with endmember variability, by linking the generated endmembers to the probability distributions of endmember bundles extracted from the hyperspectral imagery via discriminators. Besides the convolutional autoencoder-like architecture that can only model the spatial information within the regular patch inputs, DGMSSU is able to alternatively choose graph convolutional networks or self-attention mechanism modules to handle the irregular but more flexible data—superpixel. Experimental results on a simulated dataset, as well as two well-known real hyperspectral images, show the superiority of our proposed approach in comparison with other state-of-the-art spatial–spectral unmixing methods. Compared to the conventional unmixing methods that consider the endmember variability, our proposed model generates more accurate endmembers on each subimage by the adversarial training process. The codes of this work will be available at https://github.com/shuaikaishi/DGMSSU for the sake of reproducibility.","1558-0644","","10.1109/TGRS.2022.3168712","Royal Academy of Engineering through the Research Fellowship Scheme(grant numbers:RF201617/16/31); NSFC(grant numbers:62171380); Higher Education Discipline Innovation Project(grant numbers:B18041); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9759362","Deep neural network;endmember variability;graph convolution;self-attention;spatial-spectral model;spectral unmixing","Hyperspectral imaging;Decoding;Data models;Covariance matrices;Convolution;Atmospheric modeling;Linear matrix inequalities","feature extraction;geophysical image processing;hyperspectral imaging;image resolution;neural nets;probability;remote sensing;spectral analysis","spectral variability;variational autoencoder-based deep generative model;endmember variability;convolutional autoencoder-like architecture;spatial information;hyperspectral images;spatially correlated materials distributions;endmember prior;spatial-spectral unmixing methods;superpixel;graph convolutional networks;self-attention mechanism modules","","","","59","IEEE","18 Apr 2022","","","IEEE","IEEE Journals"
"Towards Transferable Speech Emotion Representation: On Loss Functions for Cross-Lingual Latent Representations","S. Das; N. Nadine Lønfeldt; A. Katrine Pagsberg; L. H. Clemmensen","Department of Applied Mathematics and Computer Science, Technical University of Denmark; Child and Adolescent Mental Health Center, Copenhagen University Hospital, Capital Region; Department of Clinical Medicine, Faculty of Health, Copenhagen University; Department of Applied Mathematics and Computer Science, Technical University of Denmark","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","6452","6456","In recent years, speech emotion recognition (SER) has been used in wide ranging applications, from healthcare to the commercial sector. In addition to signal processing approaches, methods for SER now also use deep learning techniques which provide transfer learning possibilities. However, generalizing over languages, corpora and recording conditions is still an open challenge. In this work we address this gap by exploring loss functions that aid in transferability, specifically to non-tonal languages. We propose a variational autoencoder (VAE) with KL annealing and a semi-supervised VAE to obtain more consistent latent embedding distributions across data sets. To ensure transferability, the distribution of the latent embedding should be similar across non-tonal languages (data sets). We start by presenting a low-complexity SER based on a denoising-autoencoder, which achieves an unweighted classification accuracy of over 52.09% for four-class emotion classification. This performance is comparable to that of similar baseline methods. Following this, we employ a VAE, the semi-supervised VAE and the VAE with KL annealing to obtain a more regularized latent space. We show that while the DAE has the highest classification accuracy among the methods, the semi-supervised VAE has a comparable classification accuracy and a more consistent latent embedding distribution over data sets.1","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746450","cross-lingual;latent representation;loss functions;speech emotion recognition (SER);transfer learning","Deep learning;Emotion recognition;Annealing;Transfer learning;Speech recognition;Medical services;Signal processing","acoustic signal processing;deep learning (artificial intelligence);emotion recognition;natural language processing;semi-supervised learning (artificial intelligence);signal classification;signal denoising;signal representation;speech processing;speech recognition","nontonal languages;variational autoencoder;KL annealing;semisupervised VAE;low-complexity SER;denoising-autoencoder;four-class emotion classification;cross-lingual latent representations;speech emotion recognition;deep learning;transfer learning;transferable speech emotion representation;latent embedding distribution;transferable SER;signal processing","","","","32","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Applying Deep Learning to Balancing Network Intrusion Detection Datasets","P. -J. Chuang; D. -Y. Wu","Department of Electrical and Computer Engineering, Tamkang University, Tamsui, Taiwan 25137; Department of Electrical and Computer Engineering, Tamkang University, Tamsui, Taiwan 25137","2019 IEEE 11th International Conference on Advanced Infocomm Technology (ICAIT)","19 Dec 2019","2019","","","213","217","In this investigation, we apply deep learning to generate a desirable data generation model which helps to balance the network intrusion detection datasets and enhance the detection performance. The basic idea is to adopt deep variational autoencoders to generate new data and adjust the imbalance of datasets into more favorable balanced datasets. We then use the generated balanced datasets to reduce the deviation of classifiers (incurred by data imbalance) in training and, as a result, to enhance the performance of intrusion detection. As experimental results exhibit, in comparison to unbalanced datasets, balanced datasets can practically lead to better classification accuracy, especially when facing unknown attacks. Balanced datasets also help to solve the over-fitting problem (due to imbalance of datasets) in intrusion detection model training, to ensure that the trained intrusion detection model will not misjudge new types of data - even if they are not in the training dataset.","","978-1-7281-4778-9","10.1109/ICAIT.2019.8935927","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8935927","network intrusion detection;deep learning;balanced datasets;performance evaluation","Encoding;Training;Data models;Gaussian distribution;Decoding;Deep learning;Training data","learning (artificial intelligence);neural nets;pattern classification;security of data","deep variational autoencoders;data imbalance;intrusion detection model training;network intrusion detection datasets;deep learning;data generation model;classifiers","","8","","14","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Classification of ECG signals by dot Residual LSTM Network with data augmentation for anomaly detection","Z. A. Nazi; A. Biswas; M. A. Rayhan; T. Azad Abir","Dept. of Electronics and Communication Engineering, Khulna University of Engineering & Technology, Khulna, Bangladesh; Dept. of Electronics and Communication Engineering, Khulna University of Engineering & Technology, Khulna, Bangladesh; Dept. of Electronics and Communication Engineering, Khulna University of Engineering & Technology, Khulna, Bangladesh; Dept. of Electronics and Communication Engineering, Khulna University of Engineering & Technology, Khulna, Bangladesh","2019 22nd International Conference on Computer and Information Technology (ICCIT)","19 Mar 2020","2019","","","1","5","Classification of ECG signals is of great importance for the detection of cardiac dysfunction. Recurrent Neural Network family has been greatly successful for time series related problems. In this paper, we compare different RNN variants and propose dot Residual LSTM network for ECG classification. Here, we use extracted features both from time and frequency domain with the network to improve the classification performance. A data generation scheme was developed with Conditional variational autoencoder (CVAE) and LSTM to increase training samples. A comparative analysis was studied to assess the performance of the model. The proposed dot Res LSTM achieved maximum accuracy of 80.00% and F1 score of 0.85. Furthermore, the model achieved maximum F1 score of 0.87 with augmented data. The study is expected to be useful in automatic cardiac diagnosis research.","","978-1-7281-5842-6","10.1109/ICCIT48885.2019.9038287","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9038287","RNN;LSTM;ECG Classification;CVAE;Data Augmentation","","data analysis;electrocardiography;feature extraction;medical signal processing;recurrent neural nets;time series;time-frequency analysis","recurrent neural network;time series related problems;RNN variants;ECG classification;time-frequency domain;data generation scheme;dot Res LSTM;ECG signals classification;data augmentation;anomaly detection;dot residual LSTM network;cardiac dysfunction detection;feature extraction;conditional variational autoencoder;CVAE;automatic cardiac diagnosis research","","4","","24","","19 Mar 2020","","","IEEE","IEEE Conferences"
"Method to Annotate Arrhythmias by Deep Network","W. Lu; J. Shuai; S. Gu; J. Xue","Digital, General Electric, Shanghai, China; Healthcare, General Electric, Shanghai, China; Healthcare, General Electric, Shanghai, China; Healthcare, General Electric, Wauwatosa, WI, US","2018 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)","3 Jun 2019","2018","","","1848","1851","This study targets to automatically annotate on arrhythmia by deep network. The investigated types include sinus rhythm, asystole (Asys); supraventricular tachycardia (Tachy); ventricular flutter or fibrillation (VF/VFL); ventricular tachycardia (VT). Methods: 13s limb lead ECG chunks from MIT malignant ventricular arrhythmia database (VFDB) and MIT normal sinus rhythm database were partitioned into subsets for 5-fold cross validation. These signals were resampled to 200Hz, filtered to remove baseline wandering, projected to 2D gray spectrum and then fed into a deep network with brand-new structure. In this network, a feature vector for a single time point was retrieved by residual layers, from which latent representation was extracted by variational autoencoder (VAE). These front portions were trained to meet a certain threshold in loss function, then fixed while training procedure switched to remaining bidirectional recurrent neural network (RNN), the very portions to predict an arrhythmia category. Attention windows were polynomial lumped on RNN outputs for learning from details to outlines. And over sampling was employed for imbalanced data. The trained model was wrapped into docker image for deployment in edge or cloud. Conclusion: Promising sensitivities were achieved in four arrhythmias and good precision rates in two ventricular arrhythmias were also observed. Moreover, it was proven that latent representation by VAE, can significantly boost the speed of convergence and accuracy.","","978-1-5386-7975-3","10.1109/Cybermatics_2018.2018.00307","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8726776","","Two dimensional displays;Training;Electrocardiography;Rhythm;Sensitivity;Databases;Feature extraction","cardiology;cloud computing;electrocardiography;filtering theory;learning (artificial intelligence);medical signal detection;medical signal processing;recurrent neural nets;signal classification","2D gray spectrum;deep network;latent representation;bidirectional recurrent neural network;arrhythmia category;ventricular arrhythmias;supraventricular tachycardia;ventricular flutter;ventricular tachycardia;5-fold cross validation;MIT normal sinus rhythm database;limb lead ECG chunks;arrhythmias annotation;ventricular fibrillation;VF-VFL;VT;MIT malignant ventricular arrhythmia database;VFDB;baseline wandering removal;brand-new structure;feature vector;variational autoencoder;VAE;RNN;attention windows;docker image;cloud;edge computing;polynomial lumped","","3","","8","","3 Jun 2019","","","IEEE","IEEE Conferences"
"Translating Visual Art Into Music","M. Müller-Eberstein; N. van Noord","University of Amsterdam, Amsterdam, Netherlands; University of Amsterdam","2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)","5 Mar 2020","2019","","","3117","3120","The Synesthetic Variational Autoencoder (SynVAE) introduced in this research is able to learn a consistent mapping between visual and auditive sensory modalities in the absence of paired datasets. A quantitative evaluation on MNIST as well as the Behance Artistic Media dataset (BAM) shows that SynVAE is capable of retaining sufficient information content during the translation while maintaining cross-modal latent space consistency. In a qualitative evaluation trial, human evaluators were furthermore able to match musical samples with the images which generated them with accuracies of up to 73%.","2473-9944","978-1-7281-5023-9","10.1109/ICCVW.2019.00378","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022359","Machine Learning;Computer Vision and Pattern Recognition;Cross Modal Translation;Human Computer Interaction;Multimedia;Audio Processing;Art","Visualization;Image reconstruction;Task analysis;Decoding;Art;Measurement;Mutual information","image coding","SynVAE;visual modalities;auditive sensory modalities;MNIST;cross-modal latent space consistency;qualitative evaluation trial;musical samples;behance artistic media dataset;synesthetic variational autoencoder;BAM YXC0-00790-A066","","3","","9","","5 Mar 2020","","","IEEE","IEEE Conferences"
"End-to-End Learned Image Compression with Augmented Normalizing Flows","Y. -H. Ho; C. -C. Chan; W. -H. Peng; H. -M. Hang","Computer Science Dept., Pervasive AI Research (PAIR) Labs, National Chiao Tung University, Taiwan; Computer Science Dept., Pervasive AI Research (PAIR) Labs, National Chiao Tung University, Taiwan; Computer Science Dept., Pervasive AI Research (PAIR) Labs, National Chiao Tung University, Taiwan; Electronics Engineering Dept., Pervasive AI Research (PAIR) Labs, National Chiao Tung University, Taiwan","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","1 Sep 2021","2021","","","1931","1935","This paper presents a new attempt at using augmented normalizing flows (ANF) for lossy image compression. ANF is a specific type of normalizing flow models that augment the input with an independent noise, allowing a smoother transformation from the augmented input space to the latent space. Inspired by the fact that ANF can offer greater expressivity by stacking multiple variational autoencoders (VAE), we generalize the popular VAE-based compression framework by the autoencoding transforms of ANF. When evaluated on Kodak dataset, our ANF-based model provides 3.4% higher BD-rate saving as compared with a VAE-based baseline that implements hyper-prior with mean prediction. Interestingly, it benefits even more from the incorporation of a post-processing network, showing 11.8% rate saving as compared to 6.0% with the baseline plus post-processing.","2160-7516","978-1-6654-4899-4","10.1109/CVPRW53098.2021.00220","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9522788","","Computer vision;Image coding;Conferences;Stacking;Low-pass filters;Transforms;Predictive models","data compression;image coding;learning (artificial intelligence);video coding","augmented normalizing flows;lossy image compression;normalizing flow models;smoother transformation;augmented input space;latent space;multiple variational autoencoders;popular VAE-based compression framework;autoencoding transforms;ANF-based model;VAE-based baseline","","1","","10","","1 Sep 2021","","","IEEE","IEEE Conferences"
"Binary- and Multi-class Network Intrusion Detection with Adaptive Synthetic Sampling and Deep Learning","J. -R. Jiang; C. -L. Li","National Central University, Taoyuan, Taiwan; National Central University, Taoyuan, Taiwan","2021 IEEE International Conference on Consumer Electronics-Taiwan (ICCE-TW)","18 Nov 2021","2021","","","1","2","Intrusion detection system (IDS) is becoming more and more important for detecting network intrusions, anomalies or attacks. This paper proposes a method that first uses adaptive synthetic (ADASYN) sampling to oversample data in small-size class, then uses deep learning models, such as the variational autoencoder (VAE), long short-term memory (LSTM) network, and deep neural network (DNN), for network intrusion detection. The well-known NSL-KDD dataset is applied to evaluate the effectiveness and superiority of the proposed method.","2575-8284","978-1-6654-3328-0","10.1109/ICCE-TW52618.2021.9603206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9603206","","Deep learning;Adaptation models;Adaptive systems;Conferences;Neural networks;Network intrusion detection;Data models","deep learning (artificial intelligence);pattern classification;recurrent neural nets;sampling methods;security of data","adaptive synthetic sampling;intrusion detection system;deep learning;long short-term memory network;deep neural network;ADASYN;IDS;variational autoencoder","","1","","11","IEEE","18 Nov 2021","","","IEEE","IEEE Conferences"
"Automatic Assessment of Open Street Maps Database Quality using Aerial Imagery","B. Repasky; D. T. Payne; D. A. Dick","STELarLab Lockheed Martin Australia, Australian Institute for Machine Learning University of Adelaide; STELarLab Lockheed Martin Australia; Australian Institute for Machine Learning University of Adelaide","2020 Digital Image Computing: Techniques and Applications (DICTA)","1 Mar 2021","2020","","","1","3","Open data initiatives such as OpenStreetMap (OSM) are a powerful crowd sourced approach to data collection. However due to their crowd-sourced nature the quality of the database heavily depends on the enthusiasm and determination of the public. We propose a novel method based on variational autoencoder generative adversarial networks (VAE-GAN) together with an information theoretic measure of database quality based on the expected discrimination information between the original image and labels generated from OSM data. Experiments on overhead aerial imagery and segmentation masks generated from OSM data show that our proposed discrimination information measure is a promising measure to regional database quality in OSM.","","978-1-7281-9108-9","10.1109/DICTA51227.2020.9363412","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9363412","","Training;Image segmentation;Databases;Digital images;Particle measurements;Generative adversarial networks;Open data","cartography;geographic information systems;image segmentation;Internet;neural nets;visual databases","variational autoencoder generative adversarial networks;VAE-GAN;information theoretic measure;OSM data;discrimination information measure;regional database quality;open data initiatives;OpenStreetMap database quality;aerial imagery","","","","10","","1 Mar 2021","","","IEEE","IEEE Conferences"
"Learning VAE with Categorical Labels for Generating Conditional Handwritten Characters","K. Goto; N. Inoue",Tokyo Institute of Technology; Tokyo Institute of Technology,"2021 17th International Conference on Machine Vision and Applications (MVA)","19 Aug 2021","2021","","","1","5","The variational autoencoder (VAE) has succeeded in learning disentangled latent representations from data without supervision. Well disentangled representations can express interpretable semantic value, which is useful for various tasks, including image generation. However, the conventional VAE model is not suitable for data generation with specific category labels because it is challenging to acquire categorical information as latent variables. Therefore, we propose a framework for learning label representations in a VAE by using supervised categorical labels associated with data. Through experiments, we show that this framework is useful for generating data belonging to a specific category. Furthermore, we found that our framework successfully disentangled latent factors from similar data of different classes.","","978-4-901122-20-7","10.23919/MVA51890.2021.9511404","Japan Science and Technology Agency(grant numbers:JPMJAX1905); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9511404","","Image synthesis;Machine vision;Semantics;Data models;Task analysis","handwritten character recognition;image coding;image representation;learning (artificial intelligence);pattern classification","conditional handwritten characters;variational autoencoder;disentangled latent representations;disentangled representations;interpretable semantic value;image generation;conventional VAE model;data generation;specific category labels;categorical information;latent variables;label representations;supervised categorical labels;latent factors","","","","12","","19 Aug 2021","","","IEEE","IEEE Conferences"
"Domain Knowledge Assisted Training Dataset Generation for Metasurface Designs","Z. We; Z. Zhou; Y. Zhang; P. Li; J. Ren; Y. Yin; G. F. Perdersen; M. Shen",NA; NA; NA; NA; NA; NA; NA; NA,"2021 IEEE MTT-S International Wireless Symposium (IWS)","10 Aug 2021","2021","","","1","3","Domain knowledge assisted training dataset generation for deep learning aided metasurface designs is investigated. By combining the domain knowledge of metasurface from the designer and the advanced machine learning (ML) technique, an efficient training dataset generation approach has been successfully achieved. Unlike most existing metasurface generative designs that allow for arbitrary target pattern generation, which results in a time-consuming or even nonconvergence model training process, the proposed method takes the full advantages of the prior knowledge from designer to reduce the target solution space greatly, leading to reduced design cycles and higher explainabilities of the designs. The proposed ML model combines generative adversarial network (GAN) and variational autoencoder (VAE) as an encoder to transfer the original data into the latent space, which greatly improves the design efficiency as demonstrated in the validation results.","","978-1-6654-3527-7","10.1109/IWS52775.2021.9499612","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9499612","deep learning;domain knowledge assisted;metasurfaces;dataset generation","Training;Wireless communication;Deep learning;Design methodology;Tools;Metasurfaces;Generative adversarial networks","computational electromagnetics;deep learning (artificial intelligence)","arbitrary target pattern generation;nonconvergence model training process;reduced design cycles;design efficiency;domain knowledge assisted training dataset generation;deep learning aided metasurface designs;machine learning;training dataset generation;metasurface generative designs;variational autoencoder;generative adversarial network","","","","9","","10 Aug 2021","","","IEEE","IEEE Conferences"
"Generative Deep Learning Model for a Multi-Level Nano-Optic Broadband Power Splitter","Y. Tang; K. Kojima; T. Koike-Akino; Y. Wang; P. Wu; M. Tahersima; D. Jha; K. Parsons; M. Qi","School of Electrical and Computer Engineering and Birck Nanotechnology Center, Purdue University, West Lafayette, IN, USA; Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, USA; Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, USA; Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, USA; Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, USA; Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, USA; Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, USA; Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, USA; School of Electrical and Computer Engineering and Birck Nanotechnology Center, Purdue University, West Lafayette, IN, USA","2020 Optical Fiber Communications Conference and Exhibition (OFC)","4 May 2020","2020","","","1","3","A novel Conditional Variational Autoencoder (CVAE) model with the adversarial censoring is presented to help to generate the 550nm broad bandwidth (1250nm to 1800nm) power splitter with arbitrary splitting ratio.","","978-1-9435-8071-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9083040","","","integrated optics;learning (artificial intelligence);nanophotonics;optical beam splitters","generative deep learning model;multilevel nanooptic broadband power splitter;conditional variational autoencoder model;adversarial censoring;arbitrary splitting ratio;wavelength 1250.0 nm to 1800.0 nm","","","","8","","4 May 2020","","","IEEE","IEEE Conferences"
"Subjective Quality Optimized Efficient Image Compression","X. Wang; T. Chen; Z. Ma","Vision Lab, Nanjing University; Vision Lab, Nanjing University; Vision Lab, Nanjing University","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","1 Sep 2021","2021","","","1911","1915","In this paper, we propose an efficient image compression framework that is optimized for subjective quality. Our framework is mainly based on the NLAIC (NonLocal Attention Optimized Image Coding) model which applied Variational Autoencoder (VAE) and non-local attention module to end-to-end image compression. This work makes two major contributions to the NLAIC framework. First, our models are optimized for subjective-friendly loss functions rather than conventional MSE (Mean Squared Error) or MS-SSIM (Multiscale Structural Similarity) which was widely used in previous works. Second, we introduce block-based inference mechanism to reduce the running memory consumption of the image compression network, and suggest a partial post-processing step to alleviate block artifacts caused by block-based inference in a lightweight computational fashion. Experiments have proved that the image reconstructed by our method can preserve more texture details than models trained for optimal MSE or MS-SSIM and also present capability for high-throughput decoding.","2160-7516","978-1-6654-4899-4","10.1109/CVPRW53098.2021.00216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9522879","","Measurement;Computer vision;Image coding;Inference mechanisms;Conferences;Memory management;Distortion","data compression;image coding;image reconstruction;image texture;inference mechanisms;mean square error methods;neural nets;optimisation","end-to-end image compression;NLAIC framework;subjective-friendly loss functions;MS-SSIM;block-based inference;NLAIC model;nonlocal attention module;nonlocal attention optimized image coding;subjective quality optimized efficient image compression;variational autoencoder;mean squared error;multiscale structural similarity","","","","16","","1 Sep 2021","","","IEEE","IEEE Conferences"
"Feasibility of ECG Reconstruction From Minimal Lead Sets Using Convolutional Neural Networks","M. Matyschik; H. Mauranen; P. Bonizzi; J. Karel","Maastricht University, Maastricht, the Netherlands; Maastricht University, Maastricht, the Netherlands; Maastricht University, Maastricht, the Netherlands; Maastricht University, Maastricht, the Netherlands","2020 Computing in Cardiology","10 Feb 2021","2020","","","1","4","Electrocardiography is a commonly applied method of measuring the electrical activity of the heart. The standard 12-lead electrocardiogram (ECG) provides sufficient information to allow various heart conditions to be diagnosed. Despite its relative ease of use, the standard ECG procedure could benefit from a reduction of leads which may allow for continuous monitoring, for example via a wearable device. In this study, we first investigated the use of variational autoencoders (VAEs) to assess what the most representative leads of the standard 12-lead system are. As the VAE learns to compress the ECG data, it focuses on the parts of the input that is important for the reconstruction. This information is then used to assess which leads are the most useful for a reconstruction task in general. Precordial leads V2, V3 and V4 are shown to contain the most information in the 12-lead ECG data. We then investigated the use of a convolutional neural network (CNN) architecture capable of learning patient-specific models to accurately impute 11 missing ECG signals from a single available lead. Our design is unconventional in that it keeps a two-dimensional structure throughout the fully connected layers. We show that this design outperforms the traditional one-dimensional structure and that these architectures can be affected by the presence of symptoms in recorded heart signals.","2325-887X","978-1-7281-7382-5","10.22489/CinC.2020.164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9344131","","Heart;Wearable computers;Computer architecture;Electrocardiography;Lead;Task analysis;Standards","convolutional neural nets;electrocardiography;learning (artificial intelligence);medical signal processing;patient monitoring","ECG data;convolutional neural network architecture;recorded heart signals;ECG reconstruction;convolutional neural networks;electrical activity;12-lead electrocardiogram;heart conditions;standard ECG procedure;continuous monitoring;wearable device;variational autoencoders;VAE;precordial leads","","","","9","","10 Feb 2021","","","IEEE","IEEE Conferences"
"Transformer-based Image Compression","M. Lu; P. Guo; H. Shi; C. Cao; Z. Ma",Nanjing University; Nanjing University; Jiangsu Longyuan Zhenhua Marine Engineering Co.; Jiangsu Longyuan Zhenhua Marine Engineering Co.; Nanjing University,"2022 Data Compression Conference (DCC)","4 Jul 2022","2022","","","469","469","A Transformer-based Image Compression (TIC) approach is developed which reuses the canonical variational autoencoder (VAE) architecture with paired main and hyper encoder-decoders [1], as shown in Fig. 1a. Both main and hyper encoders are comprised of a sequence of neural transformation units (NTUs) to analyse and aggregate important information for more compact representation of input image, while the decoders mirror the encoder-side operations to generate pixel-domain im-age reconstruction from the compressed bitstream. Each NTU is consist of a Swin Transformer Block (STB) [2] and a convolutional layer (Conv) to best embed both long-range and short-range information; In the meantime, a causal attention module (CAM) is devised for adaptive context modeling of latent features to utilize both hyper and autoregressive priors. The TIC rivals with state-of-the-art approaches including deep convolutional neural networks (CNNs) based learnt image coding (LIC) methods and handcrafted rules-based intra profile of recently-approved Versatile Video Coding (VVC) standard, and requires much less model parameters, e.g., up to 45% reduction to leading-performance LIC.","2375-0359","978-1-6654-7893-9","10.1109/DCC52660.2022.00080","National Natural Science Foundation of China(grant numbers:62022038,U20A20184); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9810760","","Video coding;Convolutional codes;Image coding;Data compression;Transformers;Decoding;Mirrors","convolutional neural nets;data compression;image coding;learning (artificial intelligence);video coding","hyper encoder-decoders;hyper encoders;neural transformation units;compact representation;input image;encoder-side operations;compressed bitstream;swin transformer block;short-range information;autoregressive priors;TIC rivals;deep convolutional neural networks;canonical variational autoencoder architecture;transformer-based image compression approach;pixel-domain image reconstruction;versatile video coding;CNN based learnt image coding methods;VVC standard;long-range information","","","","2","IEEE","4 Jul 2022","","","IEEE","IEEE Conferences"
"Design of AI-Enhanced Drug Lead Optimization Workflow for HPC and Cloud","C. -C. Yang; G. Domeniconi; L. Zhang; G. Cong","IBM T.J. Watson Research Center, NY, USA; IBM Research Zürich, Rüschlikon, Switzerland; IBM T.J. Watson Research Center, NY, USA; IBM T.J. Watson Research Center, NY, USA","2020 IEEE International Conference on Big Data (Big Data)","19 Mar 2021","2020","","","5861","5863","Drug discovery is a costly process of searching for new candidate medications. Among its various stages, lead optimization easily consumes more than half of the pre-clinical budget. We propose an automated lead optimization workflow that uses data mining methods in components such as execution of molecular simulations, feature extraction, and clustering with convolutional variational autoencoder. The end-to-end execution produces protein-ligand binding affinity of atoms in the lead molecule which serves as metrics for identifying modifiable atoms. In contrast to known methods, our method provides new hints for drug modification hotspots which can be used to improve drug efficacy. Our workflow can potentially reduce the lead optimization turnaround time from months/years to several days compared with the conventional labor-intensive process and thus will become a valuable tool for medical researchers.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9378387","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378387","Drug discovery;lead optimization;intelligent workflow;data mining;machine learning","Drugs;Proteins;Lead;Big Data;Tools;Software;Optimization","data mining;drugs;feature extraction;molecular biophysics;proteins","conventional labor-intensive process;AI-enhanced drug lead optimization workflow;drug discovery;costly process;candidate medications;pre-clinical budget;automated lead optimization workflow;data mining methods;molecular simulations;convolutional variational autoencoder;end-to-end execution;lead molecule;drug modification hotspots;drug efficacy;lead optimization turnaround time","","","","10","","19 Mar 2021","","","IEEE","IEEE Conferences"
"Reducing Scan Duration and Radiation Dose in Cerebral CT Perfusion Imaging Using a Recurrent Neural Network","M. D. Moghari; A. Sanaat; N. Young; K. Moore; R. R. Fulton; H. Zaidi; A. Kyme","School of Biomedical Engineering, University of Sydney, NSW, Australia; Division of Nuclear Medicine & Molecular Imaging, Geneva University Hospital, Geneva, Switzerland; Department of Radiology, Westmead Hospital, Sydney, Australia; Department of Radiology, Westmead Hospital, Sydney, Australia; Faculty of Medicine and Health, University of Sydney, Sydney, Australia; Division of Nuclear Medicine & Molecular Imaging, Geneva University Hospital, Geneva, Switzerland; School of Biomedical Engineering, University of Sydney, NSW, Australia","2021 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC)","9 Sep 2022","2021","","","1","3","Cerebral CT Perfusion (CTP) imaging is widely used for diagnosis and treatment decisions in acute stroke. The ability to reduce the scan duration is desirable but may lead to truncation of the contrast agent concentration measurements and inaccurate image-based stroke analysis. In this study, we present a novel application of a Stochastic Adversarial Video Prediction approach to reduce the acquisition time of CTP imaging. A variational autoencoder (VAE) and generative adversarial networks (GANs) VAE-GANs in a recurrent framework was implemented to predict the last 18 image frames (38 s) from the first 15 image frames (22 s). The model was trained on 65 CTP studies and tested on 10 studies. The results clearly show that prediction is possible. However, as expected, there was gradual degradation of average image quality metrics from early (measured) frames to late (predicted) frames: peak signal-to-noise ratio (PNSR) and structural similarity index (SSIM) decreased by 10.98 dB (from 47.48 dB to 36.5 dB) and 0.061 (from 0.997 to 0.936), respectively, and root mean squared error (RMSE) increased by 0.011 (from 0.004 to 0.015). Quantitative assessment of the hemodynamic maps showed that cerebral blood flow was easiest to predict and time-to-peak map was most difficult. The method potentially enables scan time and radiation dose to be reduced by 62% and 55%, respectively, but further investigation is needed to determine the impact on the quality of CTP images and resulting hemodynamic maps.","2577-0829","978-1-6654-2113-3","10.1109/NSS/MIC44867.2021.9875896","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9875896","CTP imaging;Recurrent neural network;Deep learning;Scan duration reduction;Radiation dose reduction","Image quality;Degradation;Recurrent neural networks;PSNR;Computed tomography;Measurement uncertainty;Stochastic processes","blood vessels;brain;computerised tomography;haemodynamics;haemorheology;medical image processing;recurrent neural nets","scan duration;radiation dose;cerebral CT perfusion imaging;recurrent neural network;acute stroke;contrast agent concentration measurements;CTP imaging;generative adversarial networks;image quality metrics;cerebral blood flow;hemodynamic maps;stochastic adversarial video prediction;image-based stroke analysis;variational autoencoder;time 38.0 s;time 22.0 s","","","","8","IEEE","9 Sep 2022","","","IEEE","IEEE Conferences"
"Information Dropout: Learning Optimal Representations Through Noisy Computation","A. Achille; S. Soatto","Department of Computer Science, University of California, Los Angeles, CA; Department of Computer Science, University of California, Los Angeles, CA","IEEE Transactions on Pattern Analysis and Machine Intelligence","2 Nov 2018","2018","40","12","2897","2905","The cross-entropy loss commonly used in deep learning is closely related to the defining properties of optimal representations, but does not enforce some of the key properties. We show that this can be solved by adding a regularization term, which is in turn related to injecting multiplicative noise in the activations of a Deep Neural Network, a special case of which is the common practice of dropout. We show that our regularized loss function can be efficiently minimized using Information Dropout, a generalization of dropout rooted in information theoretic principles that automatically adapts to the data and can better exploit architectures of limited capacity. When the task is the reconstruction of the input, we show that our loss function yields a Variational Autoencoder as a special case, thus providing a link between representation learning, information theory and variational inference. Finally, we prove that we can promote the creation of optimal disentangled representations simply by enforcing a factorized prior, a fact that has been observed empirically in recent work. Our experiments validate the theoretical intuitions behind our method, and we find that Information Dropout achieves a comparable or better generalization performance than binary dropout, especially on smaller models, since it can automatically adapt the noise to the structure of the network, as well as to the test sample.","1939-3539","","10.1109/TPAMI.2017.2784440","Office of Naval Research; Air Force Office of Scientific Research; Army Research Office; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8253482","Representation learning;deep learning;information bottleneck;nuisances;invariants;minimality","Neural networks;Deep learning;Bayes methods;Machine learning;Information theory;Noise measurement;Learning systems","entropy;image processing;learning (artificial intelligence);neural nets;statistical analysis","noisy computation;cross-entropy loss;deep learning;injecting multiplicative noise;regularized loss function;representation learning;information theory;optimal disentangled representations;binary dropout;deep neural network;information dropout;learning optimal representations;variational autoencoder;variational inference","","80","","27","OAPA","10 Jan 2018","","","IEEE","IEEE Journals"
"Stochastic Imputation and Uncertainty-Aware Attention to EHR for Mortality Prediction","E. Jun; A. W. Mulyadi; H. -I. Suk","Department of Brain and Cognitive Engineering, Korea University, Seoul, Republic of Korea; Department of Brain and Cognitive Engineering, Korea University, Seoul, Republic of Korea; Department of Brain and Cognitive Engineering, Korea University, Seoul, Republic of Korea","2019 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2019","2019","","","1","7","Electronic health records (EHR) have become an important source of a patient data but characterized by a variety of missing values. Using the variational inference of Bayesian framework, variational autoencoder (VAE), a deep generative model, has been shown to be efficient and accurate to capture the latent structure of complex high-dimensional data. Recently, it has been used for missing data imputation. In this paper, we propose a general framework that incorporates effective missing data imputation using VAE and multivariate time series prediction. We utilize the uncertainty obtained from the generative network of the VAE and employ uncertainty-aware attention in imputing the missing values. We evaluated the performance of our architecture on real-world clinical dataset (MIMIC-III) for in-hospital mortality prediction task. Our results showed higher performance than other competing methods in mortality prediction task.","2161-4407","978-1-7281-1985-4","10.1109/IJCNN.2019.8852132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852132","Missing data imputation;Electronic health records;Bayesian framework;Deep learning","Uncertainty;Data models;Bayes methods;Predictive models;Time series analysis;Mathematical model;Estimation","Bayes methods;belief networks;data analysis;electronic health records;hospitals;medical computing;neural nets;time series","VAE;uncertainty-aware attention;in-hospital mortality prediction task;stochastic imputation;EHR;electronic health records;patient data;variational inference;Bayesian framework;variational autoencoder;deep generative model;multivariate time series prediction;missing data imputation;MIMIC-III","","10","","17","","30 Sep 2019","","","IEEE","IEEE Conferences"
"Multi-Task Learning Aided Joint Constellation Design and Multiuser Detection for GF-NOMA","Z. Ma; W. Wu; F. Gao; X. S. Shen","Department of Automation, Tsinghua University, Beijing, China; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada; Department of Automation, Tsinghua University, Beijing, China; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada","ICC 2021 - IEEE International Conference on Communications","6 Aug 2021","2021","","","1","6","This paper aims to investigate the joint optimization of multidimensional constellation design (MCD) and multiuser detection (MUD) for grant-free non-orthogonal multiple access (GF-NOMA). We first formulate the joint optimization problem and derive its explicit expression using variational inference. Due to the intractability of the joint optimization problem, we then resort to deep learning (DL) and approximate the optimal solution in an end-to-end manner. Specifically, we develop a novel variational autoencoder based network, such that the distribution of the multidimensional constellations can be accessed and optimized. We also design a multi-task learning architecture on the decoder side to deal with the complex coupling among signal streams, by taking the MUD process as multiple distinctive yet related tasks. The derivation of the loss function for network training is presented, and simulation results are provided to validate the superior performance of the proposed method over conventional approaches.","1938-1883","978-1-7281-7122-7","10.1109/ICC42927.2021.9500861","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9500861","","Multiuser detection;Training;Deep learning;Couplings;NOMA;Simulation;Conferences","approximation theory;decoding;deep learning (artificial intelligence);multi-access systems;multiuser detection;optimisation;telecommunication computing","multitask learning aided joint constellation design;multiuser detection;GF-NOMA;multidimensional constellation design;grant-free nonorthogonal multiple access;joint optimization problem;variational inference;deep learning;novel variational autoencoder based network;multitask learning architecture;MCD;decoder side;complex coupling;signal streams;MUD process;loss function;network training","","","","19","IEEE","6 Aug 2021","","","IEEE","IEEE Conferences"
"LCBM: A Multi-View Probabilistic Model for Multi-Label Classification","S. Sun; D. Zong","School of Computer Science and Technology, East China Normal University, Shanghai, China; School of Computer Science and Technology, East China Normal University, Shanghai, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","1 Jul 2021","2021","43","8","2682","2696","Multi-label classification is an important research topic in machine learning, for which exploiting label dependencies is an effective modeling principle. Recently, probabilistic models have shown great potential in discovering dependencies among labels. In this paper, motivated by the recent success of multi-view learning to improve the generalization performance, we propose a novel multi-view probabilistic model named latent conditional Bernoulli mixture (LCBM) for multi-label classification. LCBM is a generative model taking features from different views as inputs, and conditional on the latent subspace shared by the views a Bernoulli mixture model is adopted to build label dependencies. Inside each component of the mixture, the labels have a weak correlation which facilitates computational convenience. The mean field variational inference framework is used to carry out approximate posterior inference in the probabilistic model, where we propose a Gaussian mixture variational autoencoder (GMVAE) for effective posterior approximation. We further develop a scalable stochastic training algorithm for efficiently optimizing the model parameters and variational parameters, and derive an efficient prediction procedure based on greedy search. Experimental results on multiple benchmark datasets show that our approach outperforms other state-of-the-art methods under various metrics.","1939-3539","","10.1109/TPAMI.2020.2974203","National Natural Science Foundation of China(grant numbers:61673179); Shanghai Knowledge Service Platform Project(grant numbers:ZF1213); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9000714","Multi-view learning;multi-label classification;Bernoulli mixture;probabilistic model;variational autoencoder","Probabilistic logic;Task analysis;Prediction algorithms;Support vector machines;Kernel;Training;Semantics","learning (artificial intelligence);pattern classification;probability","LCBM;multilabel classification;exploiting label dependencies;effective modeling principle;multiview learning;novel multiview probabilistic model;latent conditional Bernoulli mixture;generative model;Bernoulli mixture model;model parameters","","2","","49","IEEE","17 Feb 2020","","","IEEE","IEEE Journals"
"Wavelet Loss Function for Auto-Encoder","Q. Zhu; H. Wang; R. Zhang","School of Communication and Information Engineering, Shanghai University, Shanghai, China; School of Communication and Information Engineering, Shanghai University, Shanghai, China; School of Communication and Information Engineering, Shanghai University, Shanghai, China","IEEE Access","17 Feb 2021","2021","9","","27101","27108","In the field of image generation, especially for auto-encoder models, how to extract better features and obtain better quality reconstruction samples by modifying network structure and training algorithms has always been the focus of attention. For example, Variational Auto-Encoder (VAE), which is a very popular auto-encoder model, is a theoretically rigorously derived image generation model. For commonly used auto-encoders, such as VAE, Regularized Auto-Encoder (RAE), and Wasserstein Auto-Encoder (WAE), the mean square error (MSE) is all used as the loss function of the reconstructed process, which makes the blur problem of the reconstruction samples unavoidable. Especially for larger-sized images, the blur phenomenon is more obvious. To solve this problem, Perceptual Loss Function is used in some cases. Although it can improve the image quality to a certain extent, the amount of calculation is large and the image quality improvement in auto-encoder is also relatively limited. For this reason, we try to propose a new loss function, Wavelet loss function, to better generate and reconstruct images. Wavelet transform is applied to the reconstructed image loss function of the auto-encoder, and the frequency characteristics of the decomposed image are used to constrain it. We conducted comparative experiments on two larger-size image datasets (FaceSrub, COIL20) and a small-size image dataset (Fashion_MNIST), and proved the effectiveness of the wavelet loss function. At the same time, we propose a new image quality index: wavelet high-frequency signal-to-noise ratio (WHF-SNR), which can better measure the quality of the reconstructed image of the auto-encoder.","2169-3536","","10.1109/ACCESS.2021.3058604","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9351990","Auto-encoder;reconstruct;generate;wavelet;loss function","Wavelet transforms;Image reconstruction;Training;Image quality;Indexes;Image synthesis;Feature extraction","image coding;image reconstruction;mean square error methods;wavelet transforms","wavelet transform;WHF-SNR;wavelet high-frequency signal-to-noise ratio;COIL20;FaceSrub;Fashion_MNIST;blur phenomenon;MSE;mean square error;VAE;RAE;variational autoencoder;image quality index;larger-size image datasets;reconstructed image loss function;image quality improvement;Perceptual Loss Function;Wasserstein autoencoder;regularized autoencoder;image generation model;wavelet loss function","","","","16","CCBY","10 Feb 2021","","","IEEE","IEEE Journals"
"Semi-supervised Deep Dynamic Probabilistic Latent Variable Model for Multi-mode Process Soft Sensor Application","L. Yao; B. Shen; L. Cui; J. Zheng; Z. Ge","School of Mathematics, Hangzhou Normal University, Hangzhou, China; School of Mathematics, Hangzhou Normal University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, China","IEEE Transactions on Industrial Informatics","","2022","PP","99","1","11","Nonlinear and multimode characteristics commonly ap-pear in modern industrial process data with increasing complexity and dynamics, which have brought challenges to soft sensor modeling. To solve these issues, a dynamic mixture variation-al autoencoder regression (DMVAER) model is first proposed in this paper to handle the multi-mode industrial process modeling with dynamic features. Furthermore, to deal with the partially labeled process data with rare quality values and large-scale unlabeled samples, a semi-supervised mixture variational autoencoder regression (ssDMVAER) model is proposed, where a corresponding semi-supervised data sequence division scheme is introduced to make full use of the information in both labeled and unlabeled data. Finally, to verify the feasibility and effectiveness of the proposed methods, the models are applied to a numerical case and a methanation furnace case. Results show that the proposed methods have superior soft sensing performance, compared with the state-of-the-art methods.","1941-0050","","10.1109/TII.2022.3183211","National Natural Science Foundation of China (NSFC)(grant numbers:62003300,62103362,92167106); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9797056","Dynamic model;Semi-supervised learning;Mixture Variational Autoencoder;Soft Sensor;Multimode Process Modeling;Deep Learning","Data models;Logic gates;Adaptation models;Soft sensors;Mathematical models;Numerical models;Informatics","","","","","","","IEEE","15 Jun 2022","","","IEEE","IEEE Early Access Articles"
"Motion-Variational Recurrent Neural Network for Character Garment Simulation","M. Yanning; Q. Na; Z. Qing","Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China","2021 6th International Conference on Intelligent Computing and Signal Processing (ICSP)","26 Apr 2021","2021","","","1359","1363","We propose an efficient real-time character garment animation simulation method based on deep learning. Given a character model and garment model, we create a database with character animations and corresponding garment animations for training. For garment mesh with many vertices, we use an autoencoder to extract low-dimensional features in subspace, which greatly reduces computational cost. Then we build an animation inference network designed based on VRNN. The state of the previous frame and the motion of the character are used together to update hidden state. At runtime, input the character animation to the animation inference model to get the garment feature, and decode it into the vertex position of the garment model. This method aims at the specific issue of character garment animation and observes its high correlation with character motion. It can calculate the vertex animation of a complex garment model in a few milliseconds.","","978-1-6654-0413-6","10.1109/ICSP51882.2021.9408913","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9408913","Cloth Simulation;Computer Animation;Deep Learning","Deep learning;Training;Runtime;Computational modeling;Clothing;Signal processing;Animation","clothing;computer animation;computer simulation;deep learning (artificial intelligence);feature extraction;inference mechanisms;recurrent neural nets;solid modelling","motion-variational recurrent neural network;character garment simulation;deep learning;character animation;garment mesh;animation inference network;animation inference model;character motion;vertex animation;garment animations","","","","21","","26 Apr 2021","","","IEEE","IEEE Conferences"
"A Comparative Study of Deep-Learning-Based Semi-Supervised Device-Free Indoor Localization","K. M. Chen; R. Y. Chang","Research Center for Information Technology Innovation, Academia Sinica, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taiwan","2021 IEEE Global Communications Conference (GLOBECOM)","2 Feb 2022","2021","","","1","6","Real-time device-free indoor localization is a key technology for many Internet of Things (IoT) applications. Fingerprinting-based localization schemes rely on the database constructed from an offline site survey. Constructing a fully labeled database is expensive, and therefore a fingerprinting-based method requiring only a small amount of labeled data and a large amount of unlabeled data (i.e., semi-supervised) is highly useful. In this paper, we consider semi-supervised fingerprinting techniques based on the classic, generative model-based variational auto-encoder (VAE) and generative adversarial network (GAN). We conduct a comparative study of VAE and GAN in three real-world environments. Experimental results reveal that GAN generally outperforms VAE with various amounts of labeled data. Insights into how different generative mechanisms of these schemes, as well as environmental effects, affect the performance are provided.","","978-1-7281-8104-2","10.1109/GLOBECOM46510.2021.9685548","Academia Sinica; Ministry of Science and Technology, Taiwan(grant numbers:MOST 109-2221-E-001-013-MY3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9685548","Indoor localization;deep learning;semi-supervised learning;variational auto-encoder (VAE);generative adversarial network (GAN);channel state information (CSI)","Location awareness;Performance evaluation;Databases;Fingerprint recognition;Semisupervised learning;Generative adversarial networks;Mathematical models","deep learning (artificial intelligence);indoor navigation;indoor radio;Internet of Things;semi-supervised learning (artificial intelligence);telecommunication computing","VAE;deep-learning-based semisupervised device-free indoor localization;device-free indoor localization;Internet of Things applications;fingerprinting-based localization schemes;offline site survey;unlabeled data;semisupervised fingerprinting techniques;generative adversarial network;GAN;generative model-based variational autoencoder","","1","","25","IEEE","2 Feb 2022","","","IEEE","IEEE Conferences"
"3D U-Net Brain Tumor Segmentation Using VAE Skip Connection","K. Li; L. Kong; Y. Zhang","School of Information Science and Engineering, Southeast University, Nanjing, China; School of Information Science and Engineering, Southeast University, Nanjing, China; State Key Lab. for Novel Software Technology, Nanjing University, Nanjing, China","2020 IEEE 5th International Conference on Image, Vision and Computing (ICIVC)","26 Aug 2020","2020","","","97","101","In clinical practice, the determination of the location, shape, and size of brain tumor can greatly assist the diagnosis, monitoring, and treatment of brain tumor. Therefore, accurate and reliable automatic brain tumor segmentation algorithm is of great significance for clinical diagnosis and treatment. With the rapid development of deep learning technology, more and more efficient image segmentation algorithms have also been applied in this field. It has been proven that U-Net model combined with variational auto-encoder can help to effectively regularize the shared encoder and thereby improve the performance. Based on the VAE-U-Net model, this paper proposes a structure called VAE skip connection. By fusing the position information contained in VAE branch into U-Net decoding stage, the network can retain more high-resolution detail information. In addition, we integrate ShakeDrop regularization into the networks to further alleviate the overfitting problem. The experimental results show that the networks after adding VAE skip connection and ShakeDrop can achieve competitive results on the BraTS 2018 dataset.","","978-1-7281-6661-2","10.1109/ICIVC50857.2020.9177441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9177441","deep learning;brain tumor segmentation;magnetic resonance imaging;U-Net;variational auto-encoder;ShakeDrop","Image segmentation;Tumors;Decoding;Three-dimensional displays;Magnetic resonance imaging;Semantics;Computer architecture","biomedical MRI;brain;image segmentation;learning (artificial intelligence);medical image processing;neurophysiology;tumours","ShakeDrop regularization;U-Net decoding;variational autoencoder;3D U-net brain tumor segmentation;VAE branch;VAE-U-Net model;image segmentation;deep learning;clinical diagnosis;brain tumor segmentation algorithm;VAE skip connection","","1","","18","","26 Aug 2020","","","IEEE","IEEE Conferences"
"CoNet: Co-Embedding by Reinforcing Graph Feature and Topology Information","H. Tang; X. Liang; Y. Guo; B. Wu; X. Zheng","School of Information, Renmin University of China; School of Information, Renmin University of China; School of Information, Renmin University of China; School of Information, Renmin University of China; School of Information, Renmin University of China","2022 IEEE International Conference on Multimedia and Expo (ICME)","26 Aug 2022","2022","","","01","06","Sparsity and smoothness are two main factors that affect the performance of Graph Convolutional Networks (GCNs). Sparsity ensures that models have the first-class generalization ability, while smoothness benefits to reduce noise and make edges reliable. As real-world graphs are often incom-plete and noisy, most GCNs learn node embeddings only acting them as ground-truth information, which unavoidably lead to suboptimal solutions. This paper proposes a co-embedding network (CoNet), jointly learns embeddings by fusing the global and local dependencies to capture the uni-versal and intrinsic properties. We proposed NodeNet and EdgeNet modules, which aggregate global node information and refine local topology structure respectively. Moreover, we further introduce two piplines of variational auto-encoders to fuse the intermediate latent variables of each module to ob-tain co-embeddings via Knowledge Distillation strategy. Ex-tensive experiments on multiple benchmarks show that our proposed approach achieves better performance than existing methods on the graph node classification task.","1945-788X","978-1-6654-8563-0","10.1109/ICME52920.2022.9859630","National Natural Science Foundation of China(grant numbers:62072463,71531012); National Social Science Foundation of China(grant numbers:18ZDA309); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9859630","Graph node classification;Network em-bedding;Variational auto-encoder;Knowledge Distillation","Network topology;Fuses;Aggregates;Benchmark testing;Topology;Reliability;Noise measurement","convolutional neural nets;graph theory;pattern classification","suboptimal solutions;co-embedding network;CoNet;global dependencies;local dependencies;universal properties;intrinsic properties;global node information;local topology structure;graph node classification task;graph convolutional networks;GCN;first-class generalization ability;smoothness benefits;real-world graphs;node embeddings;ground-truth information;variational autoencoders;EdgeNet modules;refine local topology structure;knowledge distillation strategy","","","","26","IEEE","26 Aug 2022","","","IEEE","IEEE Conferences"
"Learning Distribution Independent Latent Representation for 3D Face Disentanglement","Z. Zhang; C. Yu; H. Li; J. Sun; F. Liu","School of Mathematics and Statistics, Xi’an Jiaotong University; School of Mathematics and Statistics, Xi’an Jiaotong University; School of Mathematics and Statistics, Xi’an Jiaotong University; School of Mathematics and Statistics, Xi’an Jiaotong University; School of Mathematics and Statistics, Xi’an Jiaotong University","2020 International Conference on 3D Vision (3DV)","19 Jan 2021","2020","","","848","857","Learning disentangled 3D face shape representation is beneficial to face attribute transfer, generation and recognition, etc. In this paper, we propose a novel distribution independence-based method to learn to decompose 3D face shapes. Specifically, we design a variational auto-encoder with Graph Convolutional Network (GCN), namely Mesh-Encoder, to model the distributions of identity and expression representations via variational inference. To disentangle facial expression and identity, we eliminate correlation of the two distributions, and enforce them to be independent by adversarial training. Extensive experiments show that the proposed approach can achieve state-of-the-art results in 3D face shape decomposition and expression transfer. Though focusing on disentanglement, our method also achieves the reconstruction accuracies comparable to the state-of-the-art 3D face reconstruction methods.","2475-7888","978-1-7281-8128-8","10.1109/3DV50981.2020.00095","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9320455","","Three-dimensional displays;Faces;Shape;Face recognition;Solid modeling;Generative adversarial networks;Image reconstruction","convolutional neural nets;face recognition;graph theory;image reconstruction;image representation;inference mechanisms;learning (artificial intelligence);solid modelling","Mesh-Encoder;expression representations;variational inference;facial expression;expression transfer;state-of-the-art 3D face reconstruction methods;learning distribution independent latent representation;3D face disentanglement;3D face shape representation;face attribute transfer;graph convolutional network;variational autoencoder;distribution independence-based method;GCN;3D face shape decomposition","","1","","35","","19 Jan 2021","","","IEEE","IEEE Conferences"
"A Style Transfer Approach to Source Separation","S. Venkataramani; E. Tzinis; P. Smaragdis","Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Computer Science, University of Illinois at Urbana-Champaign; Department of Computer Science, University of Illinois at Urbana-Champaign","2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)","23 Dec 2019","2019","","","170","174","Training neural networks for source separation involves presenting a mixture recording at the input of the network and updating network parameters in order to produce an output that resembles the clean source. Consequently, supervised source separation depends on the availability of paired mixture-clean training examples. In this paper, we interpret source separation as a style transfer problem. We present a variational auto-encoder network that exploits the commonality across the domain of mixtures and the domain of clean sounds and learns a shared latent representation across the two domains. Using these cycle-consistent variational auto-encoders, we learn a mapping from the mixture domain to the domain of clean sounds and perform source separation without explicitly supervising with paired training examples.","1947-1629","978-1-7281-1123-0","10.1109/WASPAA.2019.8937203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937203","Style transfer;source separation;unsupervised learning;domain translation;deep learning;neural networks;consistency loss","Source separation;Training;Neural networks;Gallium nitride;Spectrogram;Generative adversarial networks;Music","acoustic signal processing;learning (artificial intelligence);matrix decomposition;neural nets;source separation","supervised source separation;paired mixture-clean training examples;style transfer problem;variational auto-encoder network;clean sounds;mixture domain;style transfer approach;neural networks;mixture recording;network parameters updating;clean source;cycle-consistent variational autoencoders","","1","","32","","23 Dec 2019","","","IEEE","IEEE Conferences"
"Variable Rate Image Compression with Content Adaptive Optimization","T. Guo; J. Wang; Z. Cui; Y. Feng; Y. Ge; B. Bai","Huawei Technologies, Beijing, China; Huawei Technologies, Beijing, China; Huawei Technologies, Beijing, China; Huawei Technologies, Beijing, China; Huawei Technologies, Beijing, China; Huawei Technologies, Beijing, China","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","533","537","In this paper, we propose a variable rate image compression framework for low bit-rate image compression task. Unlike most of the variational auto-encoder (VAE) based methods, our proposal is able to achieve continuously variable rate in a single model by introducing a pair of gain units into VAE. Besides, a content adaptive optimization is applied to adapt the latent representation to the specific content while keeping the parameters of the network and the predictive model fixed. After that, due to the variable rate characteristics of our method, each image can be compressed into any quality level through a unified codec. Finally, an efficient rate control algorithm is designed to find the optimal bit allocation scheme under the constraint of the low rate challenge.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150865","","Image coding;Quantization (signal);Decoding;Adaptation models;Optimization;Training;Transform coding","data compression;image coding;image representation;optimisation;prediction theory","rate control algorithm;optimal bit allocation scheme;content adaptive optimization;variable rate image compression framework;low bit-rate image compression task;predictive model;variational autoencoder based methods;VAE based methods","","6","","21","","28 Jul 2020","","","IEEE","IEEE Conferences"
"Aligning Discriminative and Representative Features: An Unsupervised Domain Adaptation Method for Building Damage Assessment","Y. Li; W. Hu; H. Li; H. Dong; B. Zhang; Q. Tian","School of Information Science and Technology, North China University of Technology, Beijing, China; School of Information Science and Technology, North China University of Technology, Beijing, China; Unmanned Systems Research Institute, Beihang University, Beijing, China; School of Information Science and Technology, North China University of Technology, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Information Science and Technology, North China University of Technology, Beijing, China","IEEE Transactions on Image Processing","5 May 2020","2020","29","","6110","6122","Building assessment is highly prioritized during rescue operations and damage relief after hurricane disasters. Although machine learning has made remarkable improvement in building damage classification, it remains challenging because classifiers must be trained using a massive amount of labeled data. Furthermore, data labeling is labor intensive, costly, and unavailable after a disaster. To address this issue, we propose an unsupervised domain adaptation method with aligned discriminative and representative features (ADRF), which leverage a substantial amount of labeled data of relevant disaster scenes for new classification tasks. The remote sensing imageries of different disasters are collected using different sensors, viewpoints, times, even at various places. Compared with the public datasets used in the domain adaptation community, the remote sensing imageries are more complicated which exhibit characteristics of lower discrimination between categories and higher diversity within categories. As a result, pursuing domain invariance is a huge challenge. To achieve this goal, we build a framework with ADRF to improve the discriminative and representative capability of the extracted features to facilitate the classification task. The ADRF framework consists of three pipelines: a classifier for the labeled data of the source domain and one autoencoder each for the source and target domains. The latent variables of autoencoders are forced to observe unit Gaussian distributions by minimizing the maximum mean discrepancy (MMD), whereas the marginal distributions of both domains are aligned via the MMD. As a case study, two challenging transfer tasks using the hurricane Sandy, Maria, and Irma datasets are investigated. Experimental results demonstrate that ADRF achieves overall accuracy of 71.6% and 84.1% in the transfer tasks from dataset Sandy to dataset Maria and dataset Irma, respectively.","1941-0042","","10.1109/TIP.2020.2988175","Beijing Natural Science Foundation(grant numbers:4182020); National Key R&D Program of China(grant numbers:2017YFB1201104); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9076800","Building damage assessment;domain adaptation;MMD;transfer learning;variational autoencoder","Feature extraction;Task analysis;Buildings;Remote sensing;Adaptation models;Training;Machine learning","disasters;emergency management;feature extraction;Gaussian distribution;geophysical image processing;image classification;pattern classification;remote sensing;unsupervised learning","representative features;unsupervised domain adaptation method;damage assessment;building assessment;rescue operations;damage relief;hurricane disasters;building damage classification;classifier;data labeling;aligned discriminative features;relevant disaster scenes;classification task;remote sensing imageries;domain adaptation community;lower discrimination;domain invariance;discriminative capability;representative capability;ADRF framework;source domain;target domains;challenging transfer tasks","","6","","46","IEEE","23 Apr 2020","","","IEEE","IEEE Journals"
"Deep and Machine Learning Approaches for Anomaly-Based Intrusion Detection of Imbalanced Network Traffic","R. Abdulhammed; M. Faezipour; A. Abuzneid; A. AbuMallouh","Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, USA; Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, USA; Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, USA; Computer Science Department, Manhattan College, Riverdale, NY, USA","IEEE Sensors Letters","15 Jan 2019","2019","3","1","1","4","Recently, cybersecurity threats have increased dramatically, and the techniques used by the attackers continue to evolve and become ingenious during the attack. Moreover, the complexity and frequent occurrence of imbalanced class distributions in most datasets indicate the need for extra research efforts. The objective of this article is to utilize various techniques for handling imbalanced datasets to build an effective intrusion detection system from the up-to-date Coburg Intrusion Detection Dataset-001 (CIDDS-001) dataset. The effectiveness of sampling methods on CIDDS-001 is carefully studied and experimentally evaluated through deep neural networks, random forest, voting, variational autoencoder, and stacking machine learning classifiers. The proposed system was able to detect attacks with up to 99.99% accuracy when handling the imbalanced class distribution with fewer samples, making it more convenient in real-time data fusion problems that target data classification.","2475-1472","","10.1109/LSENS.2018.2879990","University of Bridgeport Seed Money Grant(grant numbers:UB-SMG 2018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8526292","Anomaly detection;deep neural network (DNN);imbalanced network traffic;random forest (RF);variational autoencoder (VAE)","Machine learning;Forestry;Intrusion detection;Measurement;Sensors;Data integration;Neural networks","","","","64","","19","IEEE","7 Nov 2018","","","IEEE","IEEE Journals"
"ST-Trader: A Spatial-Temporal Deep Neural Network for Modeling Stock Market Movement","X. Hou; K. Wang; C. Zhong; Z. Wei","Department of Computer Science, New Jersey Institute of Technology, Newark, NJ, USA; School of Business, Stevens Institute of Technology, Hoboken, NJ, USA; Department of Computer Science, New Jersey Institute of Technology, Newark, NJ, USA; Department of Computer Science, New Jersey Institute of Technology, Newark, NJ, USA","IEEE/CAA Journal of Automatica Sinica","5 Apr 2021","2021","8","5","1015","1024","Stocks that are fundamentally connected with each other tend to move together. Considering such common trends is believed to benefit stock movement forecasting tasks. However, such signals are not trivial to model because the connections among stocks are not physically presented and need to be estimated from volatile data. Motivated by this observation, we propose a framework that incorporates the inter-connection of firms to forecast stock prices. To effectively utilize a large set of fundamental features, we further design a novel pipeline. First, we use variational autoencoder (VAE) to reduce the dimension of stock fundamental information and then cluster stocks into a graph structure (fundamentally clustering). Second, a hybrid model of graph convolutional network and long-short term memory network (GCN-LSTM) with an adjacency graph matrix (learnt from VAE) is proposed for graph-structured stock market forecasting. Experiments on minute-level U.S. stock market data demonstrate that our model effectively captures both spatial and temporal signals and achieves superior improvement over baseline methods. The proposed model is promising for other applications in which there is a possible but hidden spatial dependency to improve time-series prediction.","2329-9274","","10.1109/JAS.2021.1003976","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9395542","Graph convolution network;long-short term memory network;stock market forecasting;variational autoencoder (VAE)","Convolution;Neural networks;Predictive models;Market research;Data models;Stock markets;Forecasting","graph theory;neural nets;pricing;recurrent neural nets;stock markets;time series","volatile data;stock prices;fundamental features;VAE;stock fundamental information;cluster stocks;graph structure;fundamentally clustering;hybrid model;graph convolutional network;long-short term memory network;adjacency graph matrix;graph-structured stock market forecasting;stock market data;spatial signals;temporal signals;possible but hidden spatial dependency;ST-trader;spatial-temporal deep neural network;modeling stock market movement;common trends;stock movement forecasting tasks","","11","","55","","5 Apr 2021","","","IEEE","IEEE Journals"
"Facial Expression Retargeting From Human to Avatar Made Easy","J. Zhang; K. Chen; J. Zheng","School of Mathematical Sciences, University of Science and Technology of China, Hefei, Anhui, China; School of Mathematical Sciences, University of Science and Technology of China, Hefei, Anhui, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Visualization and Computer Graphics","30 Dec 2021","2022","28","2","1274","1287","Facial expression retargeting from humans to virtual characters is a useful technique in computer graphics and animation. Traditional methods use markers or blendshapes to construct a mapping between the human and avatar faces. However, these approaches require a tedious 3D modeling process, and the performance relies on the modelers’ experience. In this article, we propose a brand-new solution to this cross-domain expression transfer problem via nonlinear expression embedding and expression domain translation. We first build low-dimensional latent spaces for the human and avatar facial expressions with variational autoencoder. Then we construct correspondences between the two latent spaces guided by geometric and perceptual constraints. Specifically, we design geometric correspondences to reflect geometric matching and utilize a triplet data structure to express users’ perceptual preference of avatar expressions. A user-friendly method is proposed to automatically generate triplets for a system allowing users to easily and efficiently annotate the correspondences. Using both geometric and perceptual correspondences, we trained a network for expression domain translation from human to avatar. Extensive experimental results and user studies demonstrate that even nonprofessional users can apply our method to generate high-quality facial expression retargeting results with less time and effort.","1941-0506","","10.1109/TVCG.2020.3013876","National Natural Science Foundation of China(grant numbers:61672481); Youth Innovation Promotion Association of the Chinese Academy of Sciences(grant numbers:2018495); Zhejiang Lab(grant numbers:2019NB0AB03); Data Science and Artificial Intelligence Research Centre, Nanyang Technological University(grant numbers:04INS000518C130); Ministry of Education - Singapore(grant numbers:MoE 2017-T2-1- 076); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157962","Facial expression retargeting;variational autoencoder;deformation transfer;cross domain translation;triplet","Avatars;Three-dimensional displays;Strain;Animation;Shape;Solid modeling;Machine learning","avatars;computer animation;data structures;face recognition;learning (artificial intelligence);video signal processing","expression domain translation;low-dimensional latent spaces;human expressions;avatar facial expressions;geometric constraints;perceptual constraints;design geometric correspondences;users;avatar expressions;user-friendly method;perceptual correspondences;high-quality facial expression;facial expression retargeting;avatar made easy;human faces;avatar faces;tedious 3D modeling process;modelers;cross-domain expression transfer problem;nonlinear expression embedding","Computer Graphics;Facial Expression;Humans;User-Computer Interface","8","","52","IEEE","4 Aug 2020","","","IEEE","IEEE Journals"
"Differentially Private Mixture of Generative Neural Networks","G. Acs; L. Melis; C. Castelluccia; E. De Cristofaro","BME-HIT, CrySyS Lab; University College London; INRIA; University College London","2017 IEEE International Conference on Data Mining (ICDM)","18 Dec 2017","2017","","","715","720","Generative models are used in an increasing number of applications that rely on large amounts of contextually rich information about individuals. Owing to possible privacy violations, however, publishing or sharing generative models is not always viable. In this paper, we introduce a novel solution for privately releasing generative models and entire high-dimensional datasets produced by these models. We model the generator distribution of the training data by a mixture of k generative neural networks. These are trained together and collectively learn the generator distribution of a dataset. Data is divided into k clusters, using a novel differentially private kernel k-means, then each cluster is given to separate generative neural networks, such as Restricted Boltzmann Machines or Variational Autoencoders, which are trained only on their own cluster using differentially private gradient descent. We evaluate our approach using the MNIST dataset and a large Call Detail Records dataset, showing that it produces realistic synthetic samples, which can also be used to accurately compute arbitrary number of counting queries.","2374-8486","978-1-5386-3835-4","10.1109/ICDM.2017.81","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8215544","differential privacy;generative neural networks;Restricted Boltzmann Machines;Variational Autoencoders;kernel k-means;clustering","Data models;Kernel;Data privacy;Privacy;Neural networks;Training;Standards","data privacy;gradient methods;learning (artificial intelligence);neural nets;pattern clustering;query processing","differentially private mixture;generative models;publishing;high-dimensional datasets;generator distribution;separate generative neural networks;differentially private gradient descent;privacy violations;data training;generative neural networks;differentially private kernel k-means","","7","","25","","18 Dec 2017","","","IEEE","IEEE Conferences"
"U-IMG2DSM: Unpaired Simulation of Digital Surface Models With Generative Adversarial Networks","M. E. Paoletti; J. M. Haut; P. Ghamisi; N. Yokoya; J. Plaza; A. Plaza","Department of Technology of Computers and Communications, Hyperspectral Computing Laboratory, Escuela Politécnica, University of Extremadura, Cáceres, Spain; Department of Technology of Computers and Communications, Hyperspectral Computing Laboratory, Escuela Politécnica, University of Extremadura, Cáceres, Spain; Helmholtz-Zentrum Dresden-Rossendorf, Helmholtz Institute Freiberg for Resource Technology, Freiberg, Germany; RIKEN Center for Advanced Intelligence Project, RIKEN, Tokyo, Japan; Department of Technology of Computers and Communications, Hyperspectral Computing Laboratory, Escuela Politécnica, University of Extremadura, Cáceres, Spain; Department of Technology of Computers and Communications, Hyperspectral Computing Laboratory, Escuela Politécnica, University of Extremadura, Cáceres, Spain","IEEE Geoscience and Remote Sensing Letters","23 Jun 2021","2021","18","7","1288","1292","High-resolution digital surface models (DSMs) provide valuable height information about the Earth's surface, which can be successfully combined with other types of remotely sensed data in a wide range of applications. However, the acquisition of DSMs with high spatial resolution is extremely time-consuming and expensive with their estimation from a single optical image being an ill-possed problem. To overcome these limitations, this letter presents a new unpaired approach to obtain DSMs from optical images using deep learning techniques. Specifically, our new deep neural model is based on variational autoencoders (VAEs) and generative adversarial networks (GANs) to perform image-to-image translation, obtaining DSMs from optical images. Our newly proposed method has been tested in terms of photographic interpretation, reconstruction error, and classification accuracy using three well-known remotely sensed data sets with very high spatial resolution (obtained over Potsdam, Vaihingen, and Stockholm). Our experimental results demonstrate that the proposed approach obtains satisfactory reconstruction rates that allow enhancing the classification results for these images. The source code of our method is available from: https://github.com/mhaut/UIMG2DSM.","1558-0571","","10.1109/LGRS.2020.2997295","Spanish Ministry(grant numbers:FPU15/02090); Junta de Extremadura(grant numbers:GR18060); European Union(grant numbers:734541- EXPOSURE); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9108295","Digital surface models (DSMs);generative adversarial networks (GANs);image-to-image problems;optical imaging;variational autoencoder (VAEs)","Optical imaging;Gallium nitride;Optical sensors;Data models;Surface topography;Adaptive optics;Optical network units","feature extraction;geophysical image processing;image classification;image reconstruction;image segmentation;learning (artificial intelligence);neural nets;remote sensing;terrain mapping","DSMs;valuable height information;Earth's surface;high spatial resolution;single optical image;ill-possed problem;unpaired approach;optical images;deep learning techniques;deep neural model;generative adversarial networks;image-to-image translation;remotely sensed data sets;u-IMG2DSM;unpaired simulation;high-resolution digital surface models","","6","","24","IEEE","4 Jun 2020","","","IEEE","IEEE Journals"
"An Interpretable Generative Model for Handwritten Digits Synthesis","Y. Zhu; S. Suri; P. Kulkarni; Y. Chen; J. Duan; C. . -C. J. Kuo","University of Southern California, Los Angeles, CA, USA; IIIT, Delhi, India; Indian Institute of Technology, Mumbai, Mumbai, India; University of Southern California, Los Angeles, CA, USA; University of Southern California, Los Angeles, CA, USA; University of Southern California, Los Angeles, CA, USA","2019 IEEE International Conference on Image Processing (ICIP)","26 Aug 2019","2019","","","1910","1914","An interpretable generative model for handwritten digits synthesis is proposed in this work. Modern image generative models such as the variational autoencoder (VAE) are trained by backpropagation (BP). The training process is complex, and its underlying mechanism is not transparent. Here, we present an explainable generative model using a feedforward design methodology without BP. Being similar to VAEs, it has an encoder and a decoder. For the encoder design, we derive principal-component-analysis-based (PCA-based) transform kernels using the covariance of its inputs. This process converts input images of correlated pixels to uncorrelated spectral components, which play the same role as latent variables in a VAE system. For the decoder design, we convert randomly generated spectral components to synthesized images through the inverse PCA transform. A subject test is conducted to compare the quality of digits generated using the proposed method and the VAE method. They offer comparable perceptual quality yet our model can be obtained at much lower complexity.","2381-8549","978-1-5386-6249-6","10.1109/ICIP.2019.8803129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8803129","Generative model;feedforward Design;variational autoencoder (VAE);explainable machine learning;principal component analysis (PCA)","Principal component analysis;Transforms;Image synthesis;Decoding;Kernel;Training;Image reconstruction","backpropagation;feedforward;handwritten character recognition;neural nets;principal component analysis;spectral analysis","handwritten digits synthesis;modern image generative models;BP;training process;feedforward design methodology;encoder design;uncorrelated spectral components;VAE system;decoder design;VAE method;PCA-based transform kernels;principal component analysis-based transform kernels","","5","","31","","26 Aug 2019","","","IEEE","IEEE Conferences"
"Class-Incremental Learning With Deep Generative Feature Replay for DNA Methylation-Based Cancer Classification","E. Batbaatar; K. H. Park; T. Amarbayasgalan; K. Davagdorj; L. Munkhdalai; V. -H. Pham; K. H. Ryu","Database/Bioinformatics Laboratory, School of Electrical and Computer Engineering, Chungbuk National University, Cheongju, Republic of Korea; Database/Bioinformatics Laboratory, School of Electrical and Computer Engineering, Chungbuk National University, Cheongju, Republic of Korea; Database/Bioinformatics Laboratory, School of Electrical and Computer Engineering, Chungbuk National University, Cheongju, Republic of Korea; Database/Bioinformatics Laboratory, School of Electrical and Computer Engineering, Chungbuk National University, Cheongju, Republic of Korea; Database/Bioinformatics Laboratory, School of Electrical and Computer Engineering, Chungbuk National University, Cheongju, Republic of Korea; Faculty of Information Technology, Ton Duc Thang University, Ho Chi Minh City, Vietnam; Faculty of Information Technology, Ton Duc Thang University, Ho Chi Minh City, Vietnam","IEEE Access","2 Dec 2020","2020","8","","210800","210815","Developing lifelong learning algorithms are mandatory for computational systems biology. Recently, many studies have shown how to extract biologically relevant information from high-dimensional data to understand the complexity of cancer by taking the benefit of deep learning (DL). Unfortunately, new cancer growing up into the hundred types that make systems difficult to classify them efficiently. In contrast, the current state-of-the-art continual learning (CL) methods are not designed for the dynamic characteristics of high-dimensional data. And data security and privacy are some of the main issues in the biomedical field. This article addresses three practical challenges for class-incremental learning (Class-IL) such as data privacy, high-dimensionality, and incremental learning problems. To solve this, we propose a novel continual learning approach, called Deep Generative Feature Replay (DGFR), for cancer classification tasks. DGFR consists of an incremental feature selection (IFS) and a scholar network (SN). IFS is used for selecting the most significant CpG sites from high-dimensional data. We investigate different dimensions to find an optimal number of selected CpG sites. SN employs a deep generative model for generating pseudo data without accessing past samples and a neural network classifier for predicting cancer types. We use a variational autoencoder (VAE), which has been successfully applied to this research field in previous works. All networks are sequentially trained on multiple tasks in the Class-IL setting. We evaluated the proposed method on the publicly available DNA methylation data. The experimental results show that the proposed DGFR achieves a significantly superior quality of cancer classification tasks with various state-of-the-art methods in terms of accuracy.","2169-3536","","10.1109/ACCESS.2020.3039624","National Research Foundation of Korea (NRF); Ministry of Science, ICT, and Future Planning, through the Basic Science Research Program(grant numbers:NRF-2019K2A9A2A06020672,2020R1A2B5B02001717); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9265181","Computational biology;deep learning;class-incremental learning;continual learning;deep generative model;variational autoencoder;DNA methylation;cancer classification","Cancer;DNA;Task analysis;Data models;Computational modeling;Feature extraction;Biological system modeling","biology computing;cancer;data privacy;DNA;genetics;learning (artificial intelligence);molecular biophysics;neural nets;pattern classification","deep generative feature replay;incremental feature selection;continual learning approach;incremental learning problems;high-dimensionality;data privacy;data security;current state-of-the-art continual;deep learning;high-dimensional data;biologically relevant information;computational systems biology;lifelong learning algorithms;DNA methylation-based cancer classification;class-incremental learning;cancer classification tasks;DGFR;publicly available DNA methylation data;Class-IL setting;cancer types;pseudodata;deep generative model","","4","","86","CCBY","20 Nov 2020","","","IEEE","IEEE Journals"
"Deep Generative Modelling: A Comparative Review of VAEs, GANs, Normalizing Flows, Energy-Based and Autoregressive Models","S. Bond-Taylor; A. Leach; Y. Long; C. G. Willcocks","Department of Computer Science, Durham University, Durham, U.K.; Department of Computer Science, Durham University, Durham, U.K.; Department of Computer Science, Durham University, Durham, U.K.; Department of Computer Science, Durham University, Durham, U.K.","IEEE Transactions on Pattern Analysis and Machine Intelligence","4 Oct 2022","2022","44","11","7327","7347","Deep generative models are a class of techniques that train deep neural networks to model the distribution of training samples. Research has fragmented into various interconnected approaches, each of which make trade-offs including run-time, diversity, and architectural restrictions. In particular, this compendium covers energy-based models, variational autoencoders, generative adversarial networks, autoregressive models, normalizing flows, in addition to numerous hybrid approaches. These techniques are compared and contrasted, explaining the premises behind each and how they are interrelated, while reviewing current state-of-the-art advances and implementations.","1939-3539","","10.1109/TPAMI.2021.3116668","MRC Innovation Fellowship(grant numbers:MR/S003916/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555209","Deep learning;generative models;energy-based models;variational autoencoders;generative adversarial networks;autoregressive models;normalizing flows","Data models;Training;Computational modeling;Analytical models;Generative adversarial networks;Predictive models;Neurons","","","Algorithms;Neural Networks, Computer","4","","265","CCBY","30 Sep 2021","","","IEEE","IEEE Journals"
"Anomaly Detection for Visual Quality Control of 3D-Printed Products","L. Tonnaer; J. Li; V. Osin; M. Holenderski; V. Menkovski","Eindhoven University of Technology, Eindhoven, The Netherlands; Eindhoven University of Technology, Eindhoven, The Netherlands; Signify, Eindhoven, The Netherlands; Eindhoven University of Technology, Eindhoven, The Netherlands; Eindhoven University of Technology, Eindhoven, The Netherlands","2019 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2019","2019","","","1","8","We present a method for detection of surface defects in images of 3D-printed products that enables automated visual quality control. The data characterising this problem is typically high-dimensional (high-resolution images), imbalanced (defects are relatively rare), and has few labelled examples. We approach these challenges by formulating the problem as probabilistic anomaly detection, where we use Variational Autoencoders (VAE) to estimate the probability density of non-faulty products. We train the VAE in an unsupervised manner on images of non-faulty products only. A successful model will then assign high likelihood to unseen images of non-faulty products, and lower likelihood to images displaying defects. We test this method on anomaly detection scenarios using the MNIST dataset, as well as on images of 3D-printed products. The demonstrated performance is related to the capability of the model to closely estimate the density distribution of the non-faulty (expected) data. For both datasets we present empirical results that the likelihood estimated with a convolutional VAE can separate the normal and anomalous data. Moreover we show how the reconstruction capabilities of VAEs are highly informative for human observers towards localising potential anomalies, which can aid the quality control process.","2161-4407","978-1-7281-1985-4","10.1109/IJCNN.2019.8852372","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852372","anomaly detection;deep learning;visual quality control;variational autoencoder","Anomaly detection;Data models;Visualization;Quality control;Image reconstruction;Estimation;Neural networks","image processing;probability;production control;quality control;unsupervised learning","nonfaulty products;unseen images;anomaly detection scenarios;3D-printed products;quality control process;visual quality control;surface defects;high-resolution images;probabilistic anomaly detection;VAE","","4","","18","","30 Sep 2019","","","IEEE","IEEE Conferences"
"Generative Adversarial Networks (GAN) based Anomaly Detection in Industrial Software Systems","T. Kumarage; S. Ranathunga; C. Kuruppu; N. D. Silva; M. Ranawaka","Department of Computer Science and Engineering, University of Moratuwa, Katubedda, Sri Lanka; Department of Computer Science and Engineering, University of Moratuwa, Katubedda, Sri Lanka; Department of Computer Science and Engineering, University of Moratuwa, Katubedda, Sri Lanka; Department of Computer Science and Engineering, University of Moratuwa, Katubedda, Sri Lanka; Department of Computer Science and Engineering, University of Moratuwa, Katubedda, Sri Lanka","2019 Moratuwa Engineering Research Conference (MERCon)","29 Aug 2019","2019","","","43","48","Adopting an accurate anomaly detection mechanism is crucial for industrial software systems in order to prevent system outages that can deteriorate system availability. However, employing a supervised machine learning technique to detect anomalies in large production scale industrial software systems is highly impractical due to the requirement of annotated data. This raises the need for comprehensive semi-supervised and unsupervised anomaly detection mechanisms. This paper presents the application of Generative Adversarial Network (GAN) based models to detect system anomalies using semi-supervised one-class learning. We show that the use of a variant of GAN known as bidirectional GAN (BiGAN) gives augmented results when compared to the traditional GAN based anomaly detection, for the selected industrial system. Moreover, the experiments clearly show that the performance of the BiGAN has a direct correlation with the dimensions of the dataset used for training. The BiGAN even tends to outperform the well-established semi-supervised One-class SVM classifier and a prominent generative network for semi-supervised anomaly detection, Variational Autoencoders (VAEs) when the size of the feature space increases.","","978-1-7281-3632-5","10.1109/MERCon.2019.8818750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8818750","anomaly detection;industrial software systems;generative adversarial network;variational autoencoders;GAN;BiGAN;VAE","Anomaly detection;Generative adversarial networks;Software systems;Hidden Markov models;Gallium nitride;Generators;Support vector machines","neural nets;production engineering computing;security of data;supervised learning;unsupervised learning","semisupervised one-class learning;unsupervised anomaly detection;supervised machine learning;generative adversarial networks;bidirectional GAN;production scale industrial software systems;semisupervised anomaly detection;BiGAN","","3","","37","","29 Aug 2019","","","IEEE","IEEE Conferences"
"Learning Discriminative Latent Features for Generalized Zero-and Few-Shot Learning","Y. Huang; Z. Deng; T. Wu","School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China","2020 IEEE International Conference on Multimedia and Expo (ICME)","9 Jun 2020","2020","","","1","6","Generalized zero-shot learning (GZSL) for image classification is a challenging task since not only training examples from novel classes are absent, but also classification performance is judged on both seen and unseen classes. This setting is vital in realistic scenarios where the vast labeled data are not easily available. Some existing methods for GZSL utilize latent features learned through variational autoencoder (VAE) for recognizing novel classes, while few have solved the problem that image features have large intra-class variance affecting the quality of latent features. Hence we propose to match the soul samples to shorten the variance regularized by the pre-trained classifiers, which enables the VAE to generate much more discriminative latent features to train the softmax classifier. We evaluate our method on four benchmark datasets, i.e. CUB, SUN, AWAI, AWA2, and experimental results demonstrate that our model achieves the new state-of-the-art in generalized zero-shot and few-shot learning settings.","1945-788X","978-1-7281-1331-9","10.1109/ICME46284.2020.9102802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9102802","Variational autoencoder;intra-class variations;discriminative latent features;generalized zero-shot learning;generalized few-shot learning","Semantics;Task analysis;Visualization;Decoding;Training;Sun;Image recognition","feature extraction;image classification;learning (artificial intelligence);object recognition","VAE;discriminative latent features;few-shot learning settings;generalized zero-shot learning;image classification;GZSL;image features;intraclass variance;pre-trained classifiers","","2","","20","","9 Jun 2020","","","IEEE","IEEE Conferences"
"Deep Learning Based Scalable Inference of Uncertain Opinions","X. Zhao; F. Chen; J. -H. Cho","Computer Science Department, University at Albany, SUNY, Albany, NY, USA; Computer Science Department, University at Albany, SUNY, Albany, NY, USA; Department of Computer, Science Virginia Tech, Falls Church, VA, USA","2018 IEEE International Conference on Data Mining (ICDM)","30 Dec 2018","2018","","","807","816","Subjective Logic (SL) is one of well-known belief models that can explicitly deal with uncertain opinions and infer unknown opinions based on a rich set of operators of fusing multiple opinions. Due to high simplicity and applicability, SL has been popularly applied in a variety of decision making in the area of cybersecurity, opinion models, and/or trust / social network analysis. However, SL has been facing an issue of scalability to deal with a large-scale network data. In addition, SL has shown a bounded prediction accuracy due to its inherent parametric nature by treating heterogeneous data and network structure homogeneously based on the assumption of a Bayesian network. In this work, we take one step further to deal with uncertain opinions for unknown opinion inference. We propose a deep learning (DL)-based opinion inference model while node-level opinions are still formalized based on SL. The proposed DL-based opinion inference model handles node-level opinions explicitly in a large-scale network using graph convoluational network (GCN) and variational autoencoder (VAE) techniques. We adopted the GCN and VAE due to their powerful learning capabilities in dealing with a large-scale network data without parametric fusion operators and/or Bayesian network assumption. This work is the first that leverages the merits of both DL (i.e., GCN and VAE) and a belief model (i.e., SL) where each node level opinion is modeled by the formalism of SL while GCN and VAE are used to achieve non-parametric learning with low complexity. By mapping the node-level opinions modeled by the GCN to their equivalent Beta PDFs (probability density functions), we develop a network-driven VAE to maximize prediction accuracy of unknown opinions while significantly reducing algorithmic complexity. We validate our proposed DL-based algorithm using real-world datasets via extensive simulation experiments for comparative performance analysis.","2374-8486","978-1-5386-9159-5","10.1109/ICDM.2018.00096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594905","Uncertainty;Subjective Logic;Graphical Convolutional Network (GCN);Variational Autoencoder (VAE);Network Mining","Uncertainty;Data models;Bayes methods;Complexity theory;Prediction algorithms;Deep learning;Predictive models","Bayes methods;belief networks;convolutional neural nets;data analysis;inference mechanisms;learning (artificial intelligence)","SL;GCN;node-level opinions;network-driven VAE;uncertain opinions;large-scale network data;heterogeneous data;deep learning-based opinion inference model;belief model;Bayesian network;trust-social network analysis;deep learning based scalable inference;subjective logic;decision making;cybersecurity;graph convoluational network;Beta PDFs;probability density functions","","2","","22","","30 Dec 2018","","","IEEE","IEEE Conferences"
"Automatic Feature Extraction of Channel Gains of Wireless Body Area Network using Convolutional Neural Networks","S. Sano; T. Aoyagi","School of Engineering, Tokyo Institute of Technology, Tokyo, Japan; School of Engineering, Tokyo Institute of Technology, Tokyo, Japan","2020 14th International Symposium on Medical Information Communication Technology (ISMICT)","30 Jul 2020","2020","","","1","5","The channels of wireless body area networks (WBANs) are affected by human motion. Focusing on this characteristic of the WBAN channel, human motion classification and transmission power control have been investigated. Feature extraction of the WBAN channels is an important process for human motion classification. It is desirable that feature extraction is determined automatically. This is because it's difficult to select appropriate features by hand considering various factors affecting to the WBAN channels such as positions of transceivers, antennas, surrounding environment, etc. In this paper, an automatic feature extraction of the WBAN channel gains using convolutional neural networks (CNNs) is investigated. First, a human motion classifier is constructed using CNN. The accuracy rate of the classifier is evaluated and the relationship between the vector extracted by CNN and the features used in previous research is examined. Next, Feature extraction of the channel gains using variational autoencoders (VAEs) is performed. The relationship between latent variables extracted by VAE and human motion is examined. Through these considerations, an automatic feature extraction of the WBAN channel gains based on CNN is shown.","2326-8301","978-1-7281-6617-9","10.1109/ISMICT48699.2020.9152732","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9152732","wireless body area network;human motion classification;feature extraction;convolutional neural network;variational autoencoder","Feature extraction;Training;Body area networks;Wireless communication;Thigh;Correlation;Wrist","","","","2","","10","","30 Jul 2020","","","IEEE","IEEE Conferences"
"Manifold for Machine Learning Assurance","T. Byun; S. Rayadurgam","University of Minnesota, Minneapolis, Minnesota; University of Minnesota, Minneapolis, Minnesota","2020 IEEE/ACM 42nd International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)","8 Apr 2021","2020","","","97","100","The increasing use of machine-learning (ML) enabled systems in critical tasks fuels the quest for novel verification and validation techniques yet grounded in accepted system assurance principles. In traditional system development, model-based techniques have been widely adopted, where the central premise is that abstract models of the required system provide a sound basis for judging its implementation. We posit an analogous approach for ML systems using an ML technique that extracts from the high-dimensional training data implicitly describing the required system, a low-dimensional underlying structure-a manifold. It is then harnessed for a range of quality assurance tasks such as test adequacy measurement, test input generation, and runtime monitoring of the target ML system. The approach is built on variational autoencoder, an unsupervised method for learning a pair of mutually near-inverse functions between a given high-dimensional dataset and a low-dimensional representation. Preliminary experiments establish that the proposed manifold-based approach, for test adequacy drives diversity in test data, for test generation yields fault-revealing yet realistic test cases, and for run-time monitoring provides an independent means to assess trustability of the target system's output.","","978-1-4503-7126-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9397537","machine learning testing;neural networks;variational autoencoder","Manifolds;Software testing;Training data;Machine learning;Test pattern generators;Task analysis;Monitoring","data handling;learning (artificial intelligence);program testing;software quality","machine learning assurance;model-based techniques;ML systems;high-dimensional training data;quality assurance tasks;low-dimensional representation;manifold-based approach","","2","","16","","8 Apr 2021","","","IEEE","IEEE Conferences"
"Lifelong Teacher-Student Network Learning","F. Ye; A. G. Bors","Department of Computer Science, University of York, York, U.K.; Department of Computer Science, University of York, York, U.K.","IEEE Transactions on Pattern Analysis and Machine Intelligence","14 Sep 2022","2022","44","10","6280","6296","A unique cognitive capability of humans consists in their ability to acquire new knowledge and skills from a sequence of experiences. Meanwhile, artificial intelligence systems are good at learning only the last given task without being able to remember the databases learnt in the past. We propose a novel lifelong learning methodology by employing a Teacher-Student network framework. While the Student module is trained with a new given database, the Teacher module would remind the Student about the information learnt in the past. The Teacher, implemented by a Generative Adversarial Network (GAN), is trained to preserve and replay past knowledge corresponding to the probabilistic representations of previously learnt databases. Meanwhile, the Student module is implemented by a Variational Autoencoder (VAE) which infers its latent variable representation from both the output of the Teacher module as well as from the newly available database. Moreover, the Student module is trained to capture both continuous and discrete underlying data representations across different domains. The proposed lifelong learning framework is applied in supervised, semi-supervised and unsupervised training.","1939-3539","","10.1109/TPAMI.2021.3092677","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9465640","Lifelong representation learning;variational autoencoders;generative adversarial nets;teacher -student framework","Task analysis;Training;Data models;Generative adversarial networks;Probabilistic logic;Neural networks;Linear programming","artificial intelligence;cognition;computer aided instruction;continuing professional development;learning (artificial intelligence)","lifelong Teacher-Student Network learning;artificial intelligence systems;databases learnt;Teacher-Student network framework;Student module;given database;Teacher module;information learnt;Generative Adversarial Network;learnt databases;newly available database","Algorithms;Artificial Intelligence;Education, Continuing;Humans;Learning;Students","2","","63","IEEE","25 Jun 2021","","","IEEE","IEEE Journals"
"Learning-Aided Physical Layer Attacks Against Multicarrier Communications in IoT","A. Nooraiepour; W. U. Bajwa; N. B. Mandayam","Department of Electrical and Computer Engineering, WINLAB, Rutgers University, North Brunswick, NJ, USA; Department of Electrical and Computer Engineering, WINLAB, Rutgers University, North Brunswick, NJ, USA; Department of Electrical and Computer Engineering, WINLAB, Rutgers University, North Brunswick, NJ, USA","IEEE Transactions on Cognitive Communications and Networking","5 Mar 2021","2021","7","1","239","254","Internet-of-Things (IoT) devices that are limited in power and processing capabilities are susceptible to physical layer (PHY) spoofing (signal exploitation) attacks owing to their inability to implement a full-blown protocol stack for security. The overwhelming adoption of multicarrier techniques such as orthogonal frequency division multiplexing (OFDM) for the PHY layer makes IoT devices further vulnerable to PHY spoofing attacks. These attacks which aim at injecting bogus/spurious data into the receiver, involve inferring transmission parameters and finding PHY characteristics of the transmitted signals so as to spoof the received signal. Non-contiguous (NC) OFDM systems have been argued to have low probability of exploitation (LPE) characteristics against classic attacks based on cyclostationary analysis, and the corresponding PHY has been deemed to be secure. However, with the advent of machine learning (ML) algorithms, adversaries can devise data-driven attacks to compromise such systems. It is in this vein that PHY spoofing performance of adversaries equipped with supervised and unsupervised ML tools are investigated in this paper. The supervised ML approach is based on estimation/classification utilizing deep neural networks (DNN) while the unsupervised one employs variational autoencoders (VAEs). In particular, VAEs are shown to be capable of learning representations from NC-OFDM signals related to their PHY characteristics such as frequency pattern and modulation scheme, which are useful for PHY spoofing. In addition, a new metric based on the disentanglement principle is proposed to measure the quality of such learned representations. Simulation results demonstrate that the performance of the spoofing adversaries highly depends on the subcarriers' allocation patterns used at the transmitter. Particularly, it is shown that utilizing a random subcarrier occupancy pattern precludes the adversary from spoofing and secures NC-OFDM systems against ML-based attacks.","2332-7731","","10.1109/TCCN.2020.2990657","NSF(grant numbers:ACI-1541069); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9079875","Physical layer security;deep learning;OFDM;variational autoencoders","OFDM;Transmitters;Receivers;Tools;Security;Wireless communication;Modulation","computer network security;Internet of Things;neural nets;OFDM modulation;probability;unsupervised learning","data-driven attacks;PHY spoofing performance;supervised ML tools;unsupervised ML tools;NC-OFDM signals;PHY characteristics;learned representations;spoofing adversaries;ML-based attacks;physical layer attacks;multicarrier communications;internet-of-Things devices;physical layer spoofing attacks;signal exploitation;full-blown protocol stack;multicarrier techniques;PHY layer;IoT devices;PHY spoofing attacks;inferring transmission parameters;transmitted signals;received signal;noncontiguous OFDM systems;exploitation characteristics;machine learning algorithms","","2","","26","IEEE","28 Apr 2020","","","IEEE","IEEE Journals"
"Audio-Visual Autoencoding for Privacy-Preserving Video Streaming","H. Xu; Z. Cai; D. Takabi; W. Li","Department of Computer Science, Georgia State University, Atlanta, GA, USA; Department of Computer Science, Georgia State University, Atlanta, GA, USA; Department of Computer Science, Georgia State University, Atlanta, GA, USA; Department of Computer Science, Georgia State University, Atlanta, GA, USA","IEEE Internet of Things Journal","24 Jan 2022","2022","9","3","1749","1761","The demand of sharing video streaming extremely increases due to the proliferation of Internet of Things (IoT) devices in recent years, and the explosive development of artificial intelligent (AI) detection techniques has made visual privacy protection more urgent and difficult than ever before. Although a number of approaches have been proposed, their essential drawbacks limit the effect of visual privacy protection in real applications. In this article, we propose a cycle vector-quantized variational autoencoder (cycle-VQ-VAE) framework to encode and decode the video with its extracted audio, which takes the advantage of multiple heterogeneous data sources in the video itself to protect individuals’ privacy. In our cycle-VQ-VAE framework, a fusion mechanism is designed to integrate the video and its extracted audio. Particularly, the extracted audio works as the random noise with a nonpatterned distribution, which outperforms the noise that follows a patterned distribution for hiding visual information in the video. Under this framework, we design two models, including the frame-to-frame (F2F) model and video-to-video (V2V) model, to obtain privacy-preserving video streaming. In F2F, the video is processed as a sequence of frames; while, in V2V, the relations between frames are utilized to deal with the video, greatly improving the performance of privacy protection, video compression, and video reconstruction. Moreover, the video streaming is compressed in our encoding process, which can resist side-channel inference attack during video transmission and reduce video transmission time. Through the real-data experiments, we validate the superiority of our models (F2F and V2V) over the existing methods in visual privacy protection, visual quality preservation, and video transmission efficiency. The codes of our model implementation and more experimental results are now available at https://github.com/ahahnut/cycle-VQ-VAE.","2327-4662","","10.1109/JIOT.2021.3089080","U.S. National Science Foundation(grant numbers:1741277,1829674,1704287,1912753,2011845); Microsoft Investigator Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9453730","Audio-visual;privacy;video streaming;vector quantized variational autoencoder (VQ-VAE)","Streaming media;Privacy;Visualization;Internet of Things;Cryptography;Predictive models;Generative adversarial networks","data compression;data privacy;encoding;image coding;Internet of Things;vector quantisation;video coding;video signal processing;video streaming;video surveillance","video reconstruction;video transmission time;visual privacy protection;visual quality preservation;video transmission efficiency;audio-visual autoencoding;privacy-preserving video streaming;artificial intelligent detection techniques;cycle vector-quantized;individuals;cycle-VQ-VAE framework;extracted audio works;visual information;video-to-video model;V2V;video compression","","1","","56","IEEE","14 Jun 2021","","","IEEE","IEEE Journals"
"An Efficient Deep Learning System for Epileptic Seizure Prediction","A. M. Abdelhameed; M. Bayoumi","Department of Electrical and Computer Engineering, University of Louisiana, Lafayette, Louisiana, USA; Department of Electrical and Computer Engineering, University of Louisiana, Lafayette, Louisiana, USA","2021 IEEE International Symposium on Circuits and Systems (ISCAS)","27 Apr 2021","2021","","","1","5","Predicting epilepsy ahead of its occurrence has been an arduous job for scientists for a long time. Epileptic patients are still endeavoring to find a prosperous way to evade seizures to improve the quality of their lives. In this paper, we propose a novel deep learning system for epileptic seizure prediction using multi-channel electroencephalogram (EEG) recordings from the scalp of human brains. The proposed system is patient-specific and is predicated on the classification between the interictal and preictal brain states for the epileptic patient. The system uses a two-dimensional convolutional variational autoencoder and trains it once in a supervised way for automatic feature learning and classification. Within a prediction window of up to one hour, our proposed system achieved an average sensitivity of 94.45% and 0.06FP/h average false prediction rate which makes it one of the most efficient among state-of-the-art methods.","2158-1525","978-1-7281-9201-7","10.1109/ISCAS51556.2021.9401347","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9401347","EEG signals;automatic features learning;epileptic seizure prediction;variational autoencoders;supervised learning;deep learning;classification","Deep learning;Training;Sensitivity;Convolution;Semisupervised learning;Electroencephalography;Task analysis","brain;electroencephalography;feature extraction;learning (artificial intelligence);medical disorders;medical signal processing;neurophysiology","predicting epilepsy;arduous job;epileptic patient;deep learning system;epileptic seizure prediction;multichannel electroencephalogram recordings;interictal;preictal brain states;automatic feature learning;prediction window","","1","","29","","27 Apr 2021","","","IEEE","IEEE Conferences"
"Generative Approach Using Soft-Labels to Learn Uncertainty in Predicting Emotional Attributes","K. Sridhar; W. -C. Lin; C. Busso","Multimodal Signal Processing (MSP), The University of Texas at Dallas, Richardson, TX, USA; Multimodal Signal Processing (MSP), The University of Texas at Dallas, Richardson, TX, USA; Multimodal Signal Processing (MSP), The University of Texas at Dallas, Richardson, TX, USA","2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII)","15 Nov 2021","2021","","","1","8","This paper presents a novel speech emotion recognition (SER) method to capture the uncertainty in predicting emotional attributes using the true distribution of scores provided by annotators as ground truth (i.e., soft-labels). Reliable, generalizable, and scalable SER systems are important in areas such as healthcare, customer service, security, and defense. A barrier to build these systems is the lack of quality labels due to the expensive annotation process, leading to poor generalization. To address this limitation, this study proposes a semi-supervised generative modeling approach using a variational autoencoder (VAE) with an emotional regressor at the bottleneck trained with soft-labels of emotional attributes. We demonstrate that estimating uncertainties in predicting emotional attribute scores is possible with soft-labels. We analyze the benefits of uncertainty estimation with a reject option formulation, where the model can abstain from predicting emotion when it is less confident. At 60% test coverage, we achieve relative improvements in concordance correlation coefficient (CCC) up to 16.85% for valence, 7.12% for arousal, and 8.01% for dominance. Furthermore, we propose an uncertainty transfer learning strategy where uncertainties learned from one attribute are used as a sample re-ordering criterion for another attribute, achieving additional improvements in prediction performance for valence. We also demonstrate the generalization power of our method in comparison to other uncertainty estimating methods using cross-corpus evaluations. Finally, we demonstrate that our method has lower computational complexity than alternative approaches.","2156-8111","978-1-6654-0019-0","10.1109/ACII52823.2021.9597461","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9597461","Generative Models;Variational Autoencoder;Speech Emotion Recognition;Emotional Attributes","Training;Emotion recognition;Uncertainty;Computational modeling;Transfer learning;Speech recognition;Predictive models","emotion recognition;learning (artificial intelligence);speech recognition","emotional regressor;soft-labels;emotional attribute scores;uncertainty estimation;uncertainty transfer learning strategy;prediction performance;uncertainty estimating methods;generative approach;predicting emotional attributes;speech emotion recognition method;reliable SER systems;scalable SER systems;quality labels;expensive annotation process;semisupervised generative modeling approach;generalizable SER systems;concordance correlation coefficient","","1","","30","IEEE","15 Nov 2021","","","IEEE","IEEE Conferences"
"A Review of Video Generation Approaches","R. Bhagwatkar; S. Bachu; K. Fitter; A. Kulkarni; S. Chiddarwar","Visvesvaraya National Institute of Technology, Nagpur, India; Visvesvaraya National Institute of Technology, Nagpur, India; Visvesvaraya National Institute of Technology, Nagpur, India; Visvesvaraya National Institute of Technology, Nagpur, India; Visvesvaraya National Institute of Technology, Nagpur, India","2020 International Conference on Power, Instrumentation, Control and Computing (PICC)","1 Mar 2021","2020","","","1","5","Generating videos from some initial frames is an appealing field of research in deep learning. There exists an ever expanding foray of approaches to generate long-range and realistic video frame series. Generating videos can help predict trajectories and even model object movements, to enhance autonomous robots. However, there are only a few comprehensive studies that review various approaches on the basis of their relative advantages, disadvantages, and evolution. Hence, this paper presents a detailed overview of Deep Learning based approaches employed to tackle the complex problem of video generation. The approaches involve Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs) and even the Transformer model. Finally, the performance of all the approaches are examined and compared on the BAIR Robot Pushing dataset.","","978-1-7281-7590-4","10.1109/PICC51425.2020.9362485","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9362485","Video Generation;Deep Learning;Generative Adversarial Networks;Variational Autoencoders;Transformer","Deep learning;Instruments;Predictive models;Generative adversarial networks;Trajectory;Task analysis;Videos","learning (artificial intelligence);mobile robots;video signal processing","video generation approaches;generating videos;initial frames;deep learning;realistic video frame series;model object movements;Generative Adversarial Networks","","1","","40","","1 Mar 2021","","","IEEE","IEEE Conferences"
"Enhanced Sampling of Nucleic Acids’ Structures Using Deep-Learning-Derived Biasing Forces","E. O. Salawu","Machine Learning Solutions Lab. Amazon Web Services (AWS), Washington, DC Metro Area, USA","2020 IEEE Symposium Series on Computational Intelligence (SSCI)","5 Jan 2021","2020","","","1648","1654","The conformation spaces (CS) of macromolecules and their associated dynamics are of vital importance in the understanding of many biochemical functions as well as diseases and in the developments of drugs for curing or managing disease conditions. While the exploration of the CS is generally easier for molecules with fewer atoms (such as ligands and short peptides), achieving the same for larger molecules (such as nucleic acids and proteins) beyond a narrow local equilibrium is non-trivial and sometimes computationally prohibitive. In this work, we present Deep Enhanced Sampling of Nucleic Acids' Structures Using Deep-Learning-Derived Biasing Forces (DESNA, pronounced DES-na), that combines variational autoencoder, a special deep neural network (DNN), and molecular dynamics (MD) simulations to create a robust technique for enhanced sampling, in which DNN-learned latent space is used for inferring appropriate biasing potentials for guiding the MD simulations. The results obtained show that DESNA performs better than conventional MD simulations and efficiently samples wider CS than conventional MD simulations even when DESNA is allowed to run for as short as 10% of the length of conventional MD simulations. This suggests that DESNA is at least 10 times more efficient that conventional MD simulations in its sampling of CS of molecules.","","978-1-7281-2547-3","10.1109/SSCI47803.2020.9308559","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308559","Deep neural network;variational autoencoder;conformation space;molecular dynamics;nucleic acids;DNA","Biological system modeling;Training;Mathematical model;Computational modeling;Gaussian distribution;Diseases;Proteins","biochemistry;biology computing;diseases;learning (artificial intelligence);macromolecules;molecular biophysics;molecular configurations;molecular dynamics method;neural nets;proteins","nucleic acid structures;disease conditions;proteins;narrow local equilibrium;DESNA;deep neural network;DNN-learned latent space;biasing potentials;MD simulations;CS;deep-learning-derived biasing forces;deep enhanced sampling","","1","","47","","5 Jan 2021","","","IEEE","IEEE Conferences"
"The Layout Generation Algorithm of Graphic Design Based on Transformer-CVAE","M. Guo; D. Huang; X. Xie","School of Electronic and Computer Engineering, Peking University, Shenzhen, China; Microsoft Research Asia, Beijing, China; School of Electronic Engineering and Computer Science, Peking University, Beijing, China","2021 International Conference on Signal Processing and Machine Learning (CONF-SPML)","15 Feb 2022","2021","","","219","224","Graphic design is ubiquitous in people's daily lives. For graphic design, the most time-consuming task is laying out various components in the interface. Repetitive manual layout design will waste a lot of time for professional graphic designers. Existing templates are usually rudimentary and not suitable for most designs, reducing efficiency and limiting creativity. This paper implemented the Transformer model and conditional variational autoencoder (CVAE) to the graphic design layout generation task. It proposed an end-to-end graphic design layout generation model named LayoutT-CVAE. We also proposed element disentanglement and feature-based disentanglement strategies and introduce new graphic design principles and similarity metrics into the model, which significantly increased the controllability and interpretability of the deep model. Compared with the existing state-of-art models, the layout generated by ours performs better on many metrics.","","978-1-6654-1734-1","10.1109/CONF-SPML54095.2021.00049","Microsoft Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9707050","Variational autoencoder (VAE);Graphic design;Layout generation;Transformer;Deep learning","Measurement;Limiting;Layout;Signal processing algorithms;Manuals;Machine learning;Transformers","CAD;computer graphics;feature extraction","layout generation algorithm;Transformer-CVAE;repetitive manual layout design;professional graphic designers;graphic design layout generation task;end-to-end graphic design layout generation model;element disentanglement;feature-based disentanglement strategies;graphic design principles","","1","","21","IEEE","15 Feb 2022","","","IEEE","IEEE Conferences"
"Semantic Preserving Hash Coding Through VAE-GAN","G. Jin; D. Zhang; F. Dai; J. Guo; Y. Ma; Y. Zhang","University of Chinese Academy of Sciences; National Computer Network Emergency Response Technical Team, Coordination Center of China; Institute of Computing Technology, Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences","2018 25th IEEE International Conference on Image Processing (ICIP)","6 Sep 2018","2018","","","1997","2001","This paper proposes a novel framework for fast image retrieval. The proposed framework combines variational autoencoder with generative adversarial network to generate content preserving images for learning-based hashing. By accepting real image and systhesized image in a pairwise form, a semantic perserving binary mapping model is learned using pairwise ranking loss under an adversarial generative process. Extensive experiments on several benchmark datasets demonstrate that the proposed method shows substantial improvement over the state-of-the-art hashing methods.","2381-8549","978-1-4799-7061-2","10.1109/ICIP.2018.8451744","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8451744","Image retrieval;Learning to Hash;Variational autoencoder;Generative adversarial network","Semantics;Generators;Machine learning;Training;Binary codes;Gallium nitride;Image generation","","","","","","25","","6 Sep 2018","","","IEEE","IEEE Conferences"
"Unsupervised Network Anomaly Detection by Learning on 2D Data Representations","S. Casarin; S. Baldoni; M. Carli; P. Zanuttigh; F. Battisti","Department of Information Engineering, University of Padova, Padua, Italy; DIIEM Roma Tre University, Rome, Italy; DIIEM Roma Tre University, Rome, Italy; Department of Information Engineering, University of Padova, Padua, Italy; Department of Information Engineering, University of Padova, Padua, Italy","2022 9th Swiss Conference on Data Science (SDS)","14 Oct 2022","2022","","","53","58","Cyber Physical Systems are currently employed in several applications such as healthcare, transport, energy, and industrial systems. However, their communication capability exposes them to several network-level threats. Therefore, ensuring the security of Cyber Physical Systems has become an urgent and vital need. To address this issue, in this work we present a deep learning-based anomaly detection system which exploits a 2D representation of the network traffic. More specifically, we propose to employ an integral transformation of the 2D repre-sentation and a Variational Autoencoder to model the nominal system behavior and identify anomalies under the hypothesis that anomalous samples can not be accurately reconstructed by the model trained on normal data. The achieved results show the effectiveness of the proposed method and pave the way for further research in this direction.","","978-1-6654-6847-3","10.1109/SDS54800.2022.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9911980","Anomaly Detection;Cyber Physical Systems;Variational Autoencoder","Adaptation models;Telecommunication traffic;Medical services;Data science;Data models;Behavioral sciences;Security","","","","","","13","IEEE","14 Oct 2022","","","IEEE","IEEE Conferences"
"Few-Shot User-Definable Radar-Based Hand Gesture Recognition at the Edge","G. Mauro; M. Chmurski; L. Servadei; M. Pegalajar-Cuellar; D. P. Morales-Santos","Department of Electronic and Computer Technology, University of Granada, Granada, Spain; Department of Microelectronics and Computer Science, Lodz University of Technology, Łódź, Poland; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electronic and Computer Technology, University of Granada, Granada, Spain; Department of Electronic and Computer Technology, University of Granada, Granada, Spain","IEEE Access","21 Mar 2022","2022","10","","29741","29759","Technological advances and scalability are leading Human-Computer Interaction (HCI) to evolve towards intuitive forms, such as through gesture recognition. Among the various interaction strategies, radar-based recognition is emerging as a touchless, privacy-secure, and versatile solution in different environmental conditions. Classical radar-based gesture HCI solutions involve deep learning but require training on large and varied datasets to achieve robust prediction. Innovative self-learning algorithms can help tackling this problem by recognizing patterns and adapt from similar contexts. Yet, such approaches are often computationally expensive and hardly integrable into hardware-constrained solutions. In this paper, we present a gesture recognition algorithm which is easily adaptable to new users and contexts. We exploit an optimization-based meta-learning approach to enable gesture recognition in learning sequences. This method targets at learning the best possible initialization of the model parameters, simplifying training on new contexts when small amounts of data are available. The reduction in computational cost is achieved by processing the radar sensed data of gestures in the form of time maps, to minimize the input data size. This approach enables the adaptation of simple convolutional neural network (CNN) to new hand poses, thus easing the integration of the model into a hardware-constrained platform. Moreover, the use of a Variational Autoencoders (VAE) to reduce the gestures’ dimensionality leads to a model size decrease of an order of magnitude and to half of the required adaptation time. The proposed framework, deployed on the Intel® Neural Compute Stick 2 (NCS 2), leads to an average accuracy of around 84% for unseen gestures when only one example per class is utilized at training time. The accuracy increases up to 92.6% and 94.2% when three and five samples per class are used.","2169-3536","","10.1109/ACCESS.2022.3155124","ITEA3 Unleash Potentials in Simulation (UPSIM); German Federal Ministry of Education and Research (BMBF)(grant numbers:19006); Austrian Research Promotion Agency (FFG); Rijksdienst voor Ondernemend Nederland (Rvo); Innovation Fund Denmark (IFD); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9722880","Artificial neural networks;edge computing;FMCW;intel neural compute stick;knowledge transfer;meta learning;human computer interaction;radar;variational autoencoder","Adaptation models;Task analysis;Computational modeling;Human computer interaction;Training;Gesture recognition;Radar","gesture recognition;human computer interaction;learning (artificial intelligence);neural nets","shot user-definable radar;Human-Computer Interaction;intuitive forms;interaction strategies;radar-based recognition;touchless privacy-secure;versatile solution;classical radar-based gesture HCI solutions;deep learning;innovative self-learning algorithms;similar contexts;hardware-constrained solutions;gesture recognition algorithm;optimization-based meta-learning approach;learning sequences;simplifying training;computational cost;input data size;hardware-constrained platform;required adaptation time;Neural Compute Stick 2;unseen gestures;training time","","","","69","CCBY","28 Feb 2022","","","IEEE","IEEE Journals"
"SECT: A Successively Conditional Transformer for Controllable Paraphrase Generation","T. Xue; Y. Zhao; C. Yang; G. Liu; X. Li","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Computer Science Department, University of Illinois at Urbana-Champaign, Illinois, USA; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","2022 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2022","2022","","","1","8","Paraphrase generation has consistently been a challenging area in the field of NLP. Despite the considerable achievements made by previous work, existing methods lack a flexible way to include multiple controllable attributes to enhance the diversity of paraphrased sentences. To overcome this challenge, we propose a Successively Conditional Transformer (SECT) to tackle this task. SECT is based on a combination of Conditional Variational AutoEncoder (CVAE) and Transformer framework to generate diversified words. More specifically, our SECT deploys multi-head attention and memory gate mechanism to keep the interaction between each of the attributes and the corresponding encoder layer hidden state. To address the problem of absorbing flexible attributes, we apply a successive structure to our SECT, which enables the framework to couple the CVAE latent variables with the encoder layer hidden states progressively. In addition, our SECT is trained by minimizing a tailor-designed loss for producing paraphrased sentences as required. Finally, we conduct extensive experiments to substantiate the validity and effectiveness of our proposed model. The results show that SECT significantly outperforms the existing state-of-the-art approaches and generates more diverse paraphrased sentences.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9892042","National Natural Science Foundation of China(grant numbers:U21B2020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9892042","paraphrase generation;conditional variational autoencoder;transformer;successive structure","Neural networks;Logic gates;Transformers;Decoding;Task analysis","","","","","","45","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"Vehicular Trajectory Classification and Traffic Anomaly Detection in Videos Using a Hybrid CNN-VAE Architecture","K. Kumaran Santhosh; D. P. Dogra; P. P. Roy; A. Mitra","School of Electrical Sciences, Indian Institute of Technology Bhubaneswar, Odisha, India; School of Electrical Sciences, Indian Institute of Technology Bhubaneswar, Odisha, India; Department of Computer Science and Engineering, Indian Institute of Technology, Roorkee, India; Centre of Excellence in Artificial Intelligence (AI), Indian Institute of Technology Kharagpur, Kharagpur, India","IEEE Transactions on Intelligent Transportation Systems","10 Aug 2022","2022","23","8","11891","11902","Visual surveillance has become indispensable in the evolution of Intelligent Transportation Systems (ITS). Video object trajectories are key to many of the visual surveillance applications. Classifying varying length time series data such as video object trajectories using conventional neural networks, can be challenging. In this paper, we propose trajectory classification and anomaly detection using a hybrid Convolutional Neural Network (CNN) and Variational Autoencoder (VAE) architecture. First, we introduce a high level features for varying length object trajectories using color gradient representation. In the next stage, a semi-supervised way to annotate moving object trajectories extracted using Temporally Incremental Gravitational Model (TIGM) is used for class labeling. For training, anomalous trajectories are identified using t-Distributed Stochastic Neighbor Embedding (t-SNE). Finally, a hybrid CNN-VAE architecture has been proposed for trajectory classification and anomaly detection. The results obtained using publicly available surveillance video datasets reveal that the proposed method can successfully identify traffic anomalies such as violations in lane driving, sudden speed variations, abrupt termination of vehicle during movement, and vehicles moving in wrong directions. The accuracy of trajectory classification improves by a margin of 1-6% against popular neural networks-based classifiers across various datasets using the proposed high-level features. The gradient representation also improves the anomaly detection accuracy significantly (30-35%). Code and dataset can be found at https://github.com/santhoshkelathodi/CNN-VAE.","1558-0016","","10.1109/TITS.2021.3108504","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9531567","Convolutional neural network;deep learning;variational autoencoder;Dirichlet process mixture model;visual surveillance;trajectory classification;traffic anomaly detection","Trajectory;Image color analysis;Videos;Anomaly detection;Convolutional neural networks;Feature extraction;Training data","feature extraction;image classification;image motion analysis;image representation;learning (artificial intelligence);neural nets;object detection;pattern classification;surveillance;telecommunication traffic;time series;traffic engineering computing;video signal processing;video surveillance","vehicular trajectory classification;traffic anomaly detection;hybrid CNN-VAE architecture;Intelligent Transportation Systems;video object trajectories;visual surveillance applications;length time series data;conventional neural networks;high level features;length object trajectories;moving object trajectories;anomalous trajectories;publicly available surveillance video datasets;traffic anomalies;popular neural networks-based classifiers;high-level features;anomaly detection accuracy","","","","46","IEEE","8 Sep 2021","","","IEEE","IEEE Journals"
"Comparative Analysis of Machine Learning Techniques for Island Heightmap Generation","D. Demergis","College of Science and Mathematics Rowan University, Glassboro, NJ, USA","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","8","Traditional approaches to terrain heightmap generation rely on geometric methods to generate a matrix of elevation values using noise functions. More advanced approaches attempt to model the natural processes that shape landmasses in the real world, such as wind, moisture, and rainfall. This survey leverages recent advancements in image generation using generative machine learning models in order to evaluate their effectiveness in this problem space. A variational autoencoder (VAE), generative adversarial network (GAN), and PixelCNN network are trained on real-world island heightmap data and produce realistic island terrain. The author compares the results in terms of image quality and “closeness” to the original real images, and evaluates the trade-off between quality and training/generation speed.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533580","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533580","machine learning;generative models;deep learning;variational autoencoder;generative adversarial network;PixelCNN;PixelRNN;terrain generation;landscape generation;heightmap;image synthesis","Training;Image quality;Analytical models;Shape;Neural networks;Moisture;Machine learning","data visualisation;image texture;learning (artificial intelligence);rendering (computer graphics);terrain mapping","machine learning techniques;island heightmap generation;geometric methods;elevation values;noise functions;advanced approaches;natural processes;shape landmasses;survey leverages recent advancements;image generation;generative machine learning models;problem space;generative adversarial network;PixelCNN network;real-world island heightmap data;realistic island terrain;image quality;original real images;trade-off between quality;comparative analysis","","","","10","","20 Sep 2021","","","IEEE","IEEE Conferences"
"Classification and Authentication of Mineral Water Samples using Electronic Tongue and Deep Neural Networks","S. K. Damarla; X. Zhu; M. Kundu","Department of Chemical and Materials Engineering, University of Alberta, Canada; Department of Information Sciences and Technology, Donghua University, China; Department of Chemical Engineering, National Institute of Technology, Rourkela, India","2021 IEEE Third International Conference on Cognitive Machine Intelligence (CogMI)","13 Apr 2022","2021","","","11","16","Supervised multiclass classifiers based on deep neural networks (one-dimensional convolutional neural network (1D-CNN) and long short-term network (LSTM)) are developed to classify and authenticate mineral water samples of commercial brands (Aquafina, Bisleri, Oasis, Kingfisher, Dolphin and McDowell) available in Indian market. Electronic tongue based experiments are conducted to generate output waveforms (current signals) of the water samples of the six brands. Since the data obtained via the experiments are not adequate to train the deep neural networks, Variational Autoencoder (VAE) is used to generate additional current signals for each of the six brands. New database consisting of the experimental data and data generated using VAE is utilized to train and test the classifiers. Classification accuracies obtained by the LSTM and 1D-CNN models are 83.33% and 66.66%, respectively.","","978-1-6654-1621-4","10.1109/CogMI52975.2021.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9750296","electronic tongue;long short-term network;convolutional neural network;Variational Autoencoder;multiclass classifier","Deep learning;Tongue;Databases;Neural networks;Authentication;Data models;Minerals","image classification;learning (artificial intelligence);minerals;neural nets;pattern classification","mineral water samples;deep neural networks;supervised multiclass classifiers;short-term network;electronic tongue based experiments","","","","15","IEEE","13 Apr 2022","","","IEEE","IEEE Conferences"
"Pitch-Timbre Disentanglement Of Musical Instrument Sounds Based On Vae-Based Metric Learning","K. Tanaka; R. Nishikimi; Y. Bando; K. Yoshii; S. Morishima","Waseda University, Japan; Kyoto University, Japan; National Institute of Advanced Industrial Science and Technology (AIST), Japan; Kyoto University, Japan; Waseda Research Institute for Science and Engineering, Japan","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","111","115","This paper describes a representation learning method for disentangling an arbitrary musical instrument sound into latent pitch and timbre representations. Although such pitch-timbre disentanglement has been achieved with a variational autoencoder (VAE), especially for a predefined set of musical instruments, the latent pitch and timbre representations are outspread, making them hard to interpret. To mitigate this problem, we introduce a metric learning technique into a VAE with latent pitch and timbre spaces so that similar (different) pitches or timbres are mapped close to (far from) each other. Specifically, our VAE is trained with additional contrastive losses so that the latent distances between two arbitrary sounds of the same pitch or timbre are minimized, and those of different pitches or timbres are maximized. This training is performed under weak supervision that uses only whether the pitches and timbres of two sounds are the same or not, instead of their actual values. This improves the generalization capability for unseen musical instruments. Experimental results show that the proposed method can find better-structured disentangled representations with pitch and timbre clusters even for unseen musical instruments.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414059","Disentangled representation learning;variational autoencoder;metric learning;pitch and timbre modeling","Training;Instruments;Conferences;Supervised learning;Aerospace electronics;Signal processing;Extraterrestrial measurements","acoustic signal processing;audio signal processing;learning (artificial intelligence);music;musical instruments;pattern clustering;signal classification","timbre clusters;unseen musical instruments;pitch-timbre disentanglement;musical instrument sounds;vae-based metric learning;representation learning method;arbitrary musical instrument sound;latent pitch;timbre representations;metric learning technique;timbre spaces;timbres;arbitrary sounds;different pitches;better-structured disentangled representations","","","","31","IEEE","13 May 2021","","","IEEE","IEEE Conferences"
"Zero-Shot Learning With Attentive Region Embedding and Enhanced Semantics","Y. Liu; Y. Dang; X. Gao; J. Han; L. Shao","Ministry of Education, Key Laboratory of Computer Network and Information Integration, Southeast University, Nanjing, China; School of Telecommunications Engineering, Xidian University, Xi’an, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; Department of Computer Science, Aberystwyth University, Aberystwyth, U.K.; Terminus Group, China","IEEE Transactions on Neural Networks and Learning Systems","","2022","PP","99","1","12","The performance of zero-shot learning (ZSL) can be improved progressively by learning better features and generating pseudosamples for unseen classes. Existing ZSL works typically learn feature extractors and generators independently, which may shift the unseen samples away from their real distribution and suffers from the domain bias problem. In this article, to tackle this challenge, we propose a variational autoencoder (VAE)-based framework, that is, joint Attentive Region Embedding with Enhanced Semantics (AREES), which is tailored to advance the zero-shot recognition. Specifically, AREES is end-to-end trainable and consists of three network branches: 1) attentive region embedding is used to learn the semantic-guided visual features by the attention mechanism (AM); 2) a decomposition structure and a semantic pivot regularization are used to extract enhanced semantics; and 3) a multimodal VAE (mVAE) with the cross-reconstruction loss and the distribution alignment loss is used to obtain a shared latent embedding space of visual features and semantics. Finally, features’ extraction and features’ generation are optimized together in AREES to address the domain shift problem to a large extent. The comprehensive evaluations on six benchmarks, including the ImageNet, demonstrate the superiority of the proposed model over its state-of-the-art counterparts.","2162-2388","","10.1109/TNNLS.2022.3202014","National Natural Science Foundation of China(grant numbers:61906141,62036007,62176195,U21A20514); China Postdoctoral Science Foundation(grant numbers:2019M653564); Open Research Fund of the Key Laboratory of Advanced Theory and Application in Statistics and Data Science, Ministry of Education, East China Normal University; Open Project Program of the State Key Laboratory of CAD&CG, Zhejiang University(grant numbers:A2223); Open Project Program of the State Key Laboratory of Virtual Reality Technology and Systems, Beihang University(grant numbers:VRLAB2021B02); Open Project Program from the Key Laboratory of Cryptologic Technology and Information Security, Ministry of Education, Shandong University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9881214","Attention mechanism (AM);domain shift;enhanced semantics;variational autoencoder (VAE);zero-shot learning (ZSL)","Semantics;Visualization;Feature extraction;Task analysis;Whales;Data models;Training","","","","","","","IEEE","7 Sep 2022","","","IEEE","IEEE Early Access Articles"
"Visual Perception for Autonomous Driving inspired by Convergence-Divergence Zones","A. Plebe; M. Da Lio","Dept. of Information Engineering and Computer Science, University of Trento, Italy; Dept. of Industrial Engineering, University of Trento, Italy","2019 11th International Symposium on Image and Signal Processing and Analysis (ISPA)","17 Oct 2019","2019","","","204","208","Visual perception is, by large, the main source of information used by humans when driving. Therefore, it is natural and appropriate to rely heavily on vision analysis for autonomous driving, as done in most projects. However, there is a significant difference between the common approach of vision in autonomous driving, and visual perceptions in humans when driving. Essentially, image analysis is often regarded as an isolated and autonomous module, which high level output drives the control modules of the vehicle. The direction here presented is different, we try to take inspiration from the brain architecture that makes humans so effective in learning tasks as complex as the one of driving. There are two key theories about biological perception grounding our development. The first is the view of the thinking activity as a simulation of perceptions and action, as theorized by Hesslow. The second is the Convergence-Divergence Zones (CDZs) mechanism of mental simulation connecting the process of extracting features from a visual scene, to the inverse process of imagining a scene content by decoding features stored in memory. We will show how our model, based on semi-supervised variational autoencoder, is a rather faithful implementation of these two basic neurocognitive theories.","1849-2266","978-1-7281-3140-5","10.1109/ISPA.2019.8868473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868473","mental imagery;deep learning;autonomous driving;variational autoencoder","Decoding;Visualization;Computational modeling;Automobiles;Autonomous vehicles;Lighting;Signal processing","brain;cognition;computer vision;feature extraction;image texture;learning (artificial intelligence);traffic engineering computing;visual perception","autonomous module;high level output drives;visual scene;visual perception;autonomous driving;vision analysis;isolated module;convergence-divergence zones mechanism;biological perception","","","","23","","17 Oct 2019","","","IEEE","IEEE Conferences"
"Dynamic Narrowing of VAE Bottlenecks Using GECO and L0 Regularization","C. De Boom; S. Wauthier; T. Verbelen; B. Dhoedt","Department of Information Technology, IDLab, Ghent University, Ghent, Belgium; Department of Information Technology, IDLab, Ghent University, Ghent, Belgium; Department of Information Technology, IDLab, Ghent University, Ghent, Belgium; Department of Information Technology, IDLab, Ghent University, Ghent, Belgium","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","8","When designing variational autoencoders (VAEs) or other types of latent space models, the dimensionality of the latent space is typically defined upfront. In this process, it is possible that the number of dimensions is under- or overprovisioned for the application at hand. In case the dimensionality is not predefined, this parameter is usually determined using time- and resource-consuming cross-validation. For these reasons we have developed a technique to shrink the latent space dimensionality of VAEs automatically and on-the-fty during training using Generalized ELBO with Constrained Optimization (GECO) and the $L_{0}$-Augment-REINFORcE-Merge ($L_{0}$-ARM) gradient estimator. The GECO optimizer ensures that we are not violating a predefined upper bound on the reconstruction error. This paper presents the algorithmic details of our method along with experimental results on five different datasets. We find that our training procedure is stable and that the latent space can be pruned effectively without violating the GECO constraints.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533671","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533671","Variational autoencoder;VAE;latent space reduction;GECO;$L_{0}$ regularization;ARM","Training;Upper bound;Heuristic algorithms;Neural networks;Tools;Decoding;Task analysis","gradient methods;learning (artificial intelligence);neural nets;optimisation","resource-consuming cross-validation;latent space dimensionality;GECO optimizer;GECO constraints;dynamic narrowing;VAE bottlenecks;L0 Regularization;generalized ELBO with constrained optimization;L0-Augment-REINFORcE-Merge gradient estimator","","","","25","","20 Sep 2021","","","IEEE","IEEE Conferences"
"Self-attention Based Text Matching Model with Generative Pre-training","X. Zhang; F. Lei; S. Yu","School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China","2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)","15 Mar 2022","2021","","","84","91","Text matching is an important method to judge the semantic similarity of different sentences. Improving the efficiency and accuracy of text matching is the most focus in the field of information matching. In recent years, deep learning has been widely applied to text matching tasks and achieved good results. However, the different models have different limitations, such as CNN cannot learn global semantic information well, RNN cannot be parallelized well, and large pre-training language models have too many parameters to be deployed on hardware well. To address these problems, this paper propose a self-attention based text matching model with generative pre-training. Self-attention mechanism is adopted to learn the semantic information between words in a sentence, and can achieve better parallelization. We use the deep separable convolution model to obtain local features. In the pretraining stage of this model, a generative model variational autoencoder is used to learn the semantic relationship between similar sentences. And in the downstream text matching model, we employ Siamese Network structure, combine depth-wise separable convolutions and self-attention mechanism for feature extraction, and use attention mechanism for text interaction, in which the parameters in the pre-training phase will be shared. At last, we evaluate our model on three datasets: LCQMC, QQP, and a securities dataset. Experiment results show that our method achieves pretty good performance.","","978-1-6654-2174-4","10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9730379","deep learning;text matching;variational autoencoder;depth-wise separable convolutions;self-attention","Convolution;Computational modeling;Semantics;Feature extraction;Information retrieval;Data models;Hardware","","","","","","33","IEEE","15 Mar 2022","","","IEEE","IEEE Conferences"
"Deep Learning-Based Path Loss Model in Urban Environments using Image-to-Image Translation","R. -T. Juang","Department of Electronic Engineering, Feng Chia University, Taichung, Taiwan, ROC","IEEE Transactions on Antennas and Propagation","","2022","PP","99","1","1","Ray-tracing techniques offer accurate predictions on path loss but suffer from high computational complexity. To have a fast and accurate path loss prediction, this paper applies a deep learning-based image-to-image translation technique to construct a path loss model in urban environments. The proposed method combines a variational autoencoder with a generative adversarial network to translate images from the domain of street map to the domain of path loss. It is trained in a supervised manner using paired samples, where the input is the street map with 3-D building information and the output is the path loss in the area obtained from the ray-tracing model. Based on a realistic digital map of urban Taipei city, simulation results show that the proposed model outperforms conventional ones when operating at the 3.5 GHz frequency band. The standard deviation of prediction error is reduced by over 62%. Besides prediction accuracy, the proposed model has the advantage of low computational complexity over ray-tracing techniques. Hence, it has great potential for the deployment of unmanned aerial vehicle-mounted base stations (UAV-BS) for future communication systems. In this future work, the optimal UAV mobility can be determined upon the rapid evaluation of the UAV-BS coverage using the proposed model.","1558-2221","","10.1109/TAP.2022.3209229","Ministry of Science and Technology, Taiwan(grant numbers:109-2222-E-035-003-MY2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9906574","generative adversarial network;image-to-image translation;path loss model;variational autoencoder","Computational modeling;Predictive models;Loss measurement;Buildings;Urban areas;5G mobile communication;Ray tracing","","","","","","","IEEE","30 Sep 2022","","","IEEE","IEEE Early Access Articles"
"Monolith to Microservices: VAE-Based GNN Approach with Duplication Consideration","K. Sooksatra; R. Maharjan; T. Cerny","Department of Computer Science, Baylor University, Waco, Texas, United States; Department of Computer Science, Baylor University, Waco, Texas, United States; Department of Computer Science, Baylor University, Waco, Texas, United States","2022 IEEE International Conference on Service-Oriented System Engineering (SOSE)","13 Oct 2022","2022","","","1","10","With the rise of cloud computing, many applications have been implemented into microservices to fully utilize cloud computing for scalability and maintainability purposes. However, there are some traditional monolith applications that developers would like to partition into microservices. Unfortunately, it is difficult to find a solution when considering multiple factors (i.e., the strong dependency in each cluster and how often different microservices communicate with each other). Further, because we allow duplications of classes in multiple microservices to reduce the communications between them, the number of duplicated classes is also another important factor for maintainability. Therefore, we need to use machine learning algorithms to approximate a good solution due to the infeasibility of finding the optimal solution. We apply the variational autoencoder to extract features of classes and use the fuzzy c means to group the classes into microservices according to their extracted features. As a result, our approach outperforms the other baselines in some significant metrics. Also, when we allow duplication, we find that it is helpful in terms of reducing the overhead of communications between microservices.","2642-6587","978-1-6654-7534-1","10.1109/SOSE55356.2022.00007","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9912614","Microservices;Machine learning;Clustering;Graph neural networks;Variational autoencoder","Measurement;Cloud computing;Machine learning algorithms;Service-oriented systems engineering;Scalability;Microservice architectures;Feature extraction","","","","","","23","IEEE","13 Oct 2022","","","IEEE","IEEE Conferences"
"Laser based optical wireless communications for Internet of Things (IoT) Application","Y. C. Manie; C. -K. Yao; T. -Y. Yeh; Y. -C. Teng; P. -C. Peng","department of Electro-Optical Engineering, National Taipei University of Technology, Taipei, Taiwan; department of Electro-Optical Engineering, National Taipei University of Technology, Taipei, Taiwan; department of Electro-Optical Engineering, National Taipei University of Technology, Taipei, Taiwan; department of Electro-Optical Engineering, National Taipei University of Technology, Taipei, Taiwan; department of Electro-Optical Engineering, National Taipei University of Technology, Taipei, Taiwan","IEEE Internet of Things Journal","","2022","PP","99","1","1","Internet of things (IoT) is enabled by the integration of communication and sensor systems that are used to collect important information from objects around the world. In this paper, we proposed the integration of laser-based optical wireless communication (OWC) with fiber sensor system for IoT applications. OWC can be utilized in a harsh environment to send and receive communication and sensor signals in a wireless means. Moreover, fiber sensors are important to achieve real-time, accurate, and smart monitoring in IoT applications. As compared to mechanical and electrical sensors, optical fiber sensors have numerous benefits, including tolerance to electromagnetic interference (EMI), small size, lightweight, high bandwidth, low cost, provide distributed sensing, high sensitivity, and electronic devices are not required at the sensor point. Moreover, we proposed a deep variational autoencoder (DVAE) model to estimate the strain changes and peak wavelength of multiple FBG sensors using only the spectrum of FBGs obtained from the real experiment. The result showed that our proposed DVAE model can estimate the strain changes and peak wavelength of FBGs with low root mean squared error (RMSE) and high estimation accuracy. Furthermore, the performance of the proposed integration of OWC with the fiber sensor system achieves a clear eye diagram and excellent bit error rate (BER) curve.","2327-4662","","10.1109/JIOT.2022.3190619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9828385","Internet of things (IoT);optical wireless communication;deep variational autoencoder (DVAE)","Optical fiber sensors;Optical fibers;Internet of Things;Optical fiber communication;Wireless communication;Optical fiber cables;Optical network units","","","","","","","IEEE","13 Jul 2022","","","IEEE","IEEE Early Access Articles"
"Generative Neural Network Channel Modeling for Millimeter-Wave UAV Communication","W. Xia; S. Rangan; M. Mezzavilla; A. Lozano; G. Geraci; V. Semkin; G. Loianno","NYU Tandon School of Engineering, Brooklyn, USA.; NYU Tandon School of Engineering, Brooklyn, USA.; NYU Tandon School of Engineering, Brooklyn, USA.; Univ. Pompeu Fabra, Barcelona.; Univ. Pompeu Fabra, Barcelona.; VTT Technical Research Centre of Finland Ltd, Finland.; NYU Tandon School of Engineering, Brooklyn, USA.","IEEE Transactions on Wireless Communications","","2022","PP","99","1","1","The millimeter wave bands are being increasingly considered for wireless communication to unmanned aerial vehicles (UAVs). Critical to this undertaking are statistical channel models that describe the distribution of constituent parameters in scenarios of interest. This paper presents a general modeling methodology based on data-training a generative neural network. The proposed generative model has a two-stage structure that first predicts the link state (line-of-sight, non-line-of-sight, or outage), and subsequently feeds this state into a conditional variational autoencoder (VAE) that generates the path losses, delays, and angles of arrival and departure for all the propagation paths. The methodology is demonstrated for 28 GHz air-to-ground channels between UAVs and a cellular system in representative urban environments, with training datasets produced through ray tracing. The demonstration extends to both standard base stations (installed at street level and downtilted) as well as dedicated base stations (mounted on rooftops and uptilted). The proposed approach is able to capture complex statistical relations in the data and it significantly outperforms standard 3GPP models, even after refitting the parameters of those models to the data.","1558-2248","","10.1109/TWC.2022.3176480","H2020 European Research Council(grant numbers:694974); Instituci Catalana de Recerca i Estudis Avanats; National Institute of Standards and Technology; la Caixa Foundation; National Science Foundation(grant numbers:1302336,1547332,1564142,1824434); Semiconductor Research Corporation; Academy of Finland; Ministerio de Economa y Competitividad(grant numbers:RTI2018-101040); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9782737","UAV;drone;mmWave communication;5G;cellular network;air to ground;channel model;ray tracing;variational autoencoder;generative neural network;3GPP","Wireless communication;3GPP;Channel models;Artificial neural networks;Predictive models;Delays;Data models","","","","","","","IEEE","26 May 2022","","","IEEE","IEEE Early Access Articles"
"Manifold Learning-Supported Estimation of Relative Transfer Functions For Spatial Filtering","A. Brendel; J. Zeitler; W. Kellermann","Multimedia Communications and Signal Processing, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Multimedia Communications and Signal Processing, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Multimedia Communications and Signal Processing, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","8792","8796","Many spatial filtering algorithms used for voice capture in, e.g., teleconferencing applications, can benefit from or even rely on knowledge of Relative Transfer Functions (RTFs). Accordingly, many RTF estimators have been proposed which, however, suffer from performance degradation under acoustically adverse conditions or need prior knowledge on the properties of the interfering sources. While state-of-the-art RTF estimators ignore prior knowledge about the acoustic enclosure, audio signal processing algorithms for teleconferencing equipment are often operating in the same or at least a similar acoustic enclosure, e.g., a car or an office, such that training data can be collected. In this contribution, we use such data to train Variational Autoencoders (VAEs) in an unsupervised manner and apply the trained VAEs to enhance imprecise RTF estimates. Furthermore, a hybrid between classic RTF estimation and the trained VAE is investigated. Comprehensive experiments with real-world data confirm the efficacy for the proposed method.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746045","Manifold learning;variational autoencoder;relative transfer function;spatial filtering;unsupervised learning","Manifolds;Teleconferencing;Transfer functions;Estimation;Training data;Signal processing algorithms;Filtering algorithms","acoustic signal processing;audio signal processing;learning (artificial intelligence);spatial filters;speech processing;teleconferencing;transfer functions","manifold learning-supported estimation;Relative Transfer Functions;spatial filtering algorithms;voice capture;teleconferencing applications;performance degradation;acoustically adverse conditions;interfering sources;state-of-the-art RTF estimators;acoustic enclosure;teleconferencing equipment;training data;trained VAE;imprecise RTF estimates;classic RTF estimation","","","","32","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Non-Invasive Anomaly Diagnosis for Hydro Electrical Generators Rotor Inter-Turn Short-Circuit Detection Using Stray Flux and the VAE","H. Bechara; R. Zemouri; A. Tahan; B. Kedjar; A. Merkhouf; K. Al-Haddad","Department of Electrical Engineering, École de Technologie Supérieure, Montreal; IREQ-Institut de Recherche d’Hydro-Quebec, Varennes, Canada; Department of Mechanical Engineering, École de Technologie Supérieure, Montreal; Department of Electrical Engineering, École de Technologie Supérieure, Montreal; IREQ-Institut de Recherche d’Hydro-Quebec, Varennes, Canada; Department of Electrical Engineering, École de Technologie Supérieure, Montreal","2022 International Conference on Electrical Machines (ICEM)","13 Oct 2022","2022","","","1855","1861","This paper presents an overview of a new approach for the diagnosis of synchronous generators based on the stray flux along with the Variational AutoEncoder technique (VAE). A full study on the use of the VAE to detect the rotor inter-turn short-circuit fault of the salient-pole synchronous machine has been conducted. Real data were measured on a salient-pole synchronous hydro-electrical generator with a rating of 325 MVA and 56 poles. Synthetic data from simulated defects were added to the real data and used to train and test the VAE. Moreover, it is shown that adding faulty signals with different severities into the training database had led to a better clustering result. Furthermore, the sensitivity of the VAE to faulty signals and its ability to separate them from healthy signals have shown that the VAE is a promising technique for fault diagnosis based on the stray flux.","2381-4802","978-1-6654-1432-6","10.1109/ICEM51905.2022.9910797","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9910797","Diagnosis;Fault detection;Hydro-electrical generators;Non-invasive fault detection;Rotor inter-turn short-circuits;Stray flux;Variational autoencoder","Fault diagnosis;Training;Sensitivity;Databases;Fault detection;Rotors;Generators","","","","","","33","IEEE","13 Oct 2022","","","IEEE","IEEE Conferences"
"Deep Generative Networks Coupled With Evidential Reasoning for Dynamic User Preferences Using Short Texts","D. -V. Vo; T. -T. Tran; K. Shirai; V. -N. Huynh","Faculty of Computing Fundamentals, FPT University, Ho Chi Minh City, Vietnam; School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea; Japan Advanced Institute of Science and Technology (JAIST), Nomi, Ishikawa, Japan; Japan Advanced Institute of Science and Technology (JAIST), Nomi, Ishikawa, Japan","IEEE Transactions on Knowledge and Data Engineering","","2022","PP","99","1","16","Seeking an efficient solution for the problem of dynamic user preferences on social networks is challenging because the input data are <italic>short texts</italic> and user preferences usually <italic>change</italic> over time. This work proposes a novel framework that tackles these challenges based on deep neural networks and the Dempster-Shafer theory of evidence. The framework consists of three primary phases: (1) learning the hidden space of user texts; (2) word generation and mass inference; and (3) mass combination and keyword extraction. In the first phase, user texts are grouped into small batches according to timestamps. Each batch is used for separately training two types of neural networks, the Variational Autoencoder (VAE) and the Generative Adversarial Network (GAN). In the second phase, the generators in the trained VAE and GAN work independently as two <italic>experts</italic> to generate bunches of tokens for modeling user preferences. Each bunch is considered as one piece of evidence, and is transformed into the so-called mass function in Dempster-Shafer theory by maximum a posterior estimation. In the final phase, Dempster’s rule of combination is utilized for fusing the two independent pieces of evidence into an overall mass. This mass is used for extracting top keywords to form the user preferences within a specific time span. The experiments on short text datasets verified that the proposed method outperforms baseline models on many evaluation metrics. Additionally, the output of the proposed framework could be used for visualization, which is useful in many practical applications.","1558-2191","","10.1109/TKDE.2022.3188497","US Office of Naval Research Global(grant numbers:N62909-19-1-2031); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9833343","Dempster-shafer theory;mass function;variational autoencoder;generative adversarial network;user preference;user profile;user profile visualization","Social networking (online);Generative adversarial networks;Vocabulary;Generators;Task analysis;Semantics;Numerical models","","","","","","","IEEE","19 Jul 2022","","","IEEE","IEEE Early Access Articles"
"A deep learning algorithm for predicting protein-protein interactions with nonnegative latent factorization","L. Wang; L. Hu","The school of computer, Dongguan University of Technology, Dongguan, China; Chinese Academy of Sciences, Xinjiang Technical Institute of Physics and Chemistry, Urumqi, China","2021 International Conference on Cyber-Physical Social Intelligence (ICCSI)","23 Mar 2022","2021","","","1","6","Protein-protein interaction (PPI) networks play an essential role in the study of proteomics. Given the fact that known PPI data are extremely incomplete, high-throughput technologies have been developed to significantly increase the amount of PPI data, but they are prone to generate false positive PPIs and accordingly affect the performance of computational prediction algorithms. To overcome this problem, we propose a novel deep learning algorithm for predicting PPIs with symmetric nonnegative latent factorization (SNLF). In particular, we first improve the quality of PPI data by applying an established SNLF model. Quasi-Sequence-Order is then used to encode proteins based on the modality of their sequence information. Principal component analysis is utilized to generate the features of proteins in a more compact manner. After that, we adopt graph variational autoencoder to learn the embedding of each protein by considering protein features and network topology. Finally, the embeddings of proteins are concatenated in pairs as input to train a simple feedforward neural network for prediction. Experiments have been performed on five different PPI datasets by comparing the performance of our algorithm with the state-of-the-art prediction algorithms, and the results demonstrate that the proposed model is promising in predicting PPIs.","","978-1-6654-2621-3","10.1109/ICCSI53130.2021.9736228","National Natural Science Foundation of China(grant numbers:62102086); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9736228","graph variational autoencoder;nonnegative latent factorization;protein-protein interaction;prediction","Proteins;Deep learning;Network topology;Proteomics;Predictive models;Prediction algorithms;Feature extraction","bioinformatics;biology computing;data analysis;feedforward neural nets;graph theory;learning (artificial intelligence);matrix decomposition;molecular biophysics;neural nets;principal component analysis;proteins;proteomics;statistical analysis","state-of-the-art prediction algorithms;deep learning algorithm;protein-protein interactions;protein-protein interaction networks;known PPI data;high-throughput technologies;false positive PPIs;computational prediction algorithms;symmetric nonnegative latent factorization;established SNLF model;QuasiSequence-Order;encode proteins;protein features;simple feedforward neural network;different PPI datasets","","","","49","IEEE","23 Mar 2022","","","IEEE","IEEE Conferences"
"An Efficient Deep Learning Approach for Plant Disease Detection","J. Thirunavukkarasu; K. J. Oindrilla; M. Sangeetha; E. Swetha","Computer Science and Engineering, Sri Sai Ram Institute of Technology, Chennai, India; Computer Science and Engineering, Sri Sai Ram Institute of Technology, Chennai, India; Computer Science and Engineering, Sri Sai Ram Institute of Technology, Chennai, India; Computer Science and Engineering, Sri Sai Ram Institute of Technology, Chennai, India","2022 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)","14 Oct 2022","2022","","","1","7","During the stages in which plants are growing, they are more likely to be infected by a variety of diseases. Because of insufficient laboratory facilities and a dependance on the knowledge of specialists, initial plant disease identification is a time-consuming process. If the diseases are not discovered in their early stages, then it is possible that they will have a negative impact on the overall yield, which will lead to a reduction in the profits made by the farmers. Several studies have discussed various state-of-the-art systems that are based on Deep Learning as well as Machine Learning methodologies in an effort to find a solution to this issue. On the other hand, the majority of such systems either employ large numbers of input variables or even have poor accuracy in their classifications. In this paper, an innovative combined approach for automatic detection of plant diseases is proposed. The model is based on Variational Autoencoder (VAE) networks and Convolutional Neural Networks (CNN). Techniques for the automated detection of plant diseases offer a number of benefits, including the simplification of the lengthy process of observing large agricultural farms and the identification of disease symptoms at an early stage. In this work, the proposed combined approach is utilized to detect the disease known as Bacterial Spot that is present in plants by utilizing the leaf images of those plants. The proposed method achieves an accuracy rate of 98.85 percent when used for testing and 99.17 percent when used for training.","","978-1-6654-7413-9","10.1109/ICSES55317.2022.9914063","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9914063","Convolutional neural network;Deep learning;Intelligent models;Plant disease;Variational Autoencoder","Deep learning;Training;Microorganisms;Plants (biology);Input variables;Computational modeling;Neural networks","","","","","","12","IEEE","14 Oct 2022","","","IEEE","IEEE Conferences"
"Predictive maintenance based on anomaly detection using deep learning for air production unit in the railway industry","N. Davari; B. Veloso; R. P. Ribeiro; P. M. Pereira; J. Gama","LIAAD-INESC TEC, Porto, Portugal; LIAAD-INESC TEC, University Portucalense, Portugal; LIAAD-INESC TEC, University of Porto, Portugal; LIAAD-INESC TEC, Porto, Portugal; LIAAD-INESC TEC, University of Porto, Portugal","2021 IEEE 8th International Conference on Data Science and Advanced Analytics (DSAA)","20 Oct 2021","2021","","","1","10","Predictive maintenance methods assist early detection of failures and errors in machinery before they reach critical stages. This study proposes a data-driven predictive maintenance framework for the air production unit (APU) system of a train of Metro do Porto by deep learning based on a sparse autoencoder (SAE) network that efficiently detects abnormal data and considerably reduces the false alarm rate. Several analog and digital sensors installed on the APU system allow the detection of behavioral changes and deviations from the normal pattern by analyzing the collected data. We implemented two versions of the SAE network in which we inputted analog sensors data and digital sensors data, and the experimental results show that the failures due to air leakage problems are predicted by analog sensors data while other types of failures are identified by digital sensors data. A low pass filter is applied to the output of the SAE network, and a sequence of abnormal data is used as an alarm for the APU system failure. Performance indicators of the SAE network with digital sensors data, in terms of F1 Score, Recall, and Precision, are respectively, about 33.6%, 42%, and 28% better than those of the SAE network with analog sensors data. For comparison purposes, we also implemented a variational autoencoder (VAE). The results show that SAE performance is better than that of VAE by 14%, 77%, and 37% respectively, for Recall, Precision and F1 Score.","","978-1-6654-2099-0","10.1109/DSAA53316.2021.9564181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9564181","Failure detection;Predictive maintenance;Air production unit;Sparse autoencoder;Time series","Deep learning;Low-pass filters;Production;Sensor phenomena and characterization;Feature extraction;Sensor systems;Real-time systems","deep learning (artificial intelligence);low-pass filters;maintenance engineering;neural nets;production engineering computing;railway industry","air production unit system;deep learning;sparse autoencoder network;SAE network;analog sensors data;digital sensors data;air leakage problems;APU system failure;anomaly detection;data-driven predictive maintenance framework;railway industry","","1","","28","IEEE","20 Oct 2021","","","IEEE","IEEE Conferences"
"Unsupervised detection of individual atrophy in Alzheimer's disease","S. Jin; P. Zou; Y. Han; J. Jiang","Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China; Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China; Center of Alzheimer’s Disease, Institute for Brain Disorders, Beijing, China; Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China","2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","9 Dec 2021","2021","","","2647","2650","Background: To realize precision medicine, it is important to realize the detection of the individual atrophy of Alzheimer's disease (AD) patients. Our objective is to find individual brain regions of interest (ROIs) in AD patients via an unsupervised deep learning network.Methods: This study used structural Magnetic Resonance Imaging (sMRI) scans with the 732 healthy control (HC) subjects and 202 AD patients from the Alzheimer’s disease Neuroimaging Initiative (ADNI), and the 105 HC subjects were collected at the Xuanwu Hospital. An unsupervised deep learning network based on Adversarial Autoencoders (AAE) was proposed to delineate the individual atrophy of AD patients. In the proposed model, Variational Autoencoders (VAE) and Generative Adversarial Networks (GAN) were combined to learn the potential distribution and train a generator. In this step, the 530 HCs from ADNI were applied as the training dataset and the 105 HCs from Xuanwu Hospital were applied as an external validation dataset. The structural similarity (SSIM) was used to judge the robustness of the proposed model. Then, ROIs of the 202 AD patients were detected. In order to verify the clinical performance of these ROIs, other 202 HCs were selected from ADNI and a multilayer perceptron (MLP) was used to classify AD versus HC by 5 folder cross-validation. In the comparative experiments, we compared our model with three other previous models.Results: The SSIM reached 0.86 in both training and external validation datasets. Eventually, the classification accuracy of our model achieved 0.94±0.02. In the meanwhile, the classification accuracies were 0.89±0.01, 0.85±0.04 and 0.91±0.03 for the three previous methods.Conclusion: Our deep learning model could detect individual atrophy in AD patients. It may be a useful tool for AD diagnosis in clinics.","2694-0604","978-1-7281-1179-7","10.1109/EMBC46164.2021.9630103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9630103","Atrophy detection;Alzheimer’s disease;Magnetic Resonance Imaging;Adversarial autoencoders;Multilayer perceptron","Atrophy;Deep learning;Training;Hospitals;Biological system modeling;Tools;Generative adversarial networks","biomedical MRI;brain;diseases;image classification;learning (artificial intelligence);medical image processing;multilayer perceptrons;neurophysiology;patient diagnosis;pattern classification","unsupervised detection;individual atrophy;individual brain regions;ROIs;AD patients;unsupervised deep learning network;structural Magnetic Resonance Imaging;732 healthy control subjects;ADNI;105 HC subjects;Xuanwu Hospital;Adversarial Autoencoders;Generative Adversarial Networks;530 HCs;105 HCs;external validation dataset;202 HCs;external validation datasets;deep learning model","Alzheimer Disease;Atrophy;Brain;Humans;Magnetic Resonance Imaging;Neuroimaging","","","11","","9 Dec 2021","","","IEEE","IEEE Conferences"
"Core-GAE: Toward Generation of IoT Networks","Q. Luo; D. Yu; Y. Zheng; H. Sheng; X. Cheng","School of Computer Science and Technology, Shandong University, Qingdao, China; School of Computer Science and Technology, Shandong University, Qingdao, China; School of Computer Science and Technology, Shandong University, Qingdao, China; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Technology, Shandong University, Qingdao, China","IEEE Internet of Things Journal","7 Jun 2022","2022","9","12","9241","9248","To realize simulation experiments in large-scale Internet of Things (IoT) networks, this work studies the utilization of deep graph generative models to generate IoT networks, which can provide an economic approach facilitating IoT to meet the requirements of real-time performance, interoperability, energy efficiency, and coexistence. In IoT, nodes have different attributes, different connection ways with surrounding nodes, and different compactness of the region, which pose great challenges for network generation. By leveraging the properties of  $k$ -core and variational autoencoder during network generation, we propose a variable graph autoencoder called Core-GAE incorporating the coreness of nodes. In contrast to previous graph generative models, Core-GAE can preserve the local proximity similarity and maintain the global structural features simultaneously when learning the structural features of graphs. All three of the tasks we experimented with on four data sets show that Core-GAE exhibits better performance than previous ones.","2327-4662","","10.1109/JIOT.2021.3085882","National Key Research and Development Program of China(grant numbers:2019YFB2102600); NSFC(grant numbers:61971269,61832012); Shandong University Multidisciplinary Research and Innovation Team of Young Scholars(grant numbers:2020QNQT017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9446508","Core decomposition;deep generative model;graph autoencoder;Internet of Things (IoT) network","Internet of Things;Decoding;Mathematical model;Biological system modeling;Task analysis;Training;Real-time systems","deep learning (artificial intelligence);energy conservation;graph theory;Internet of Things;open systems;power aware computing;software performance evaluation","Core-GAE;deep graph generative models;variable graph autoencoder;IoT network generation;Internet of Things network generation;structural graph feature;k-core properties;real-time performance;interoperability;energy efficiency;coexistence","","","","52","IEEE","3 Jun 2021","","","IEEE","IEEE Journals"
"The Multiclass Fault Diagnosis of Wind Turbine Bearing Based on Multisource Signal Fusion and Deep Learning Generative Model","L. Zhang; H. Zhang; G. Cai","Key Laboratory of Modern Power System Simulation and Control and Renewable Energy Technology, Ministry of Education, Northeast Electric Power University, Jilin, China; Key Laboratory of Modern Power System Simulation and Control and Renewable Energy Technology, Ministry of Education, Northeast Electric Power University, Jilin, China; Key Laboratory of Modern Power System Simulation and Control and Renewable Energy Technology, Ministry of Education, Northeast Electric Power University, Jilin, China","IEEE Transactions on Instrumentation and Measurement","8 Jun 2022","2022","71","","1","12","Low fault diagnosis accuracy in case of insufficient and imbalanced samples is a major problem in the wind turbine fault diagnosis. The imbalance of samples refers to the large difference in the number of samples of different categories or the lack of a certain fault sample, which requires good learning of the characteristics of a small number of samples. Sample generation in the deep learning generation model can effectively solve this problem. In this study, we proposed a novel multiclass wind turbine bearing fault diagnosis strategy based on the conditional variational generative adversarial network (CVAE-GAN) model combining multisource signals fusion. This strategy converts multisource 1-D vibration signals into 2-D signals, and the multisource 2-D signals were fused by using wavelet transform. The CVAE-GAN model was developed by merging the variational autoencoder (VAE) with the generative adversarial network (GAN). The VAE encoder was introduced as the front end of the GAN generator. The sample label was introduced as the model input to improve the model’s training efficiency. Finally, the sample set was used to train encoder, generator, and discriminator in the CVAE-GAN model to supplement the number of the fault samples. In the classifier, the sample set is used to do experimental analysis under various sample circumstances. The results show that the proposed strategy can increase wind turbine bearing fault diagnostic accuracy in complex scenarios.","1557-9662","","10.1109/TIM.2022.3178483","International Science and Technology Cooperation Project of Jilin Province Science and Technology Department(grant numbers:20210402080GH); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9783155","Conditional variational generative adversarial network (CVAE-GAN);deep learning;image processing;multisource signal fusion;wavelet transform;wind turbine multiclass fault diagnosis","Fault diagnosis;Wind turbines;Generative adversarial networks;Generators;Feature extraction;Training;Transforms","fault diagnosis;learning (artificial intelligence);machine bearings;vibrations;wavelet transforms;wind turbines","insufficient imbalanced samples;wind turbine fault diagnosis;fault sample;good learning;sample generation;deep learning generation model;multiclass wind turbine bearing fault diagnosis strategy;conditional variational generative adversarial network;multisource signals fusion;1-D vibration signals;CVAE-GAN model;GAN generator;sample label;model input;sample circumstances;wind turbine bearing fault diagnostic accuracy;multiclass fault diagnosis;multisource signal fusion;deep learning generative model;low fault diagnosis accuracy","","","","34","IEEE","27 May 2022","","","IEEE","IEEE Journals"
"A Closer Look at Disentangling in β-VAE","H. Sikka; W. Zhong; J. Yin; C. Pehlevant","School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; Department of Physics, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Physics, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA","2019 53rd Asilomar Conference on Signals, Systems, and Computers","30 Mar 2020","2019","","","888","895","In many data analysis tasks, it is beneficial to learn representations where each dimension is statistically independent and thus disentangled from the others. If data generating factors are also statistically independent, disentangled representations can be formed by Bayesian inference of latent variables. We examine a generalization of the Variational Autoencoder (VAE), β-VAE, for learning such representations using variational inference. β -VAE enforces conditional independence of its bottleneck neurons controlled by its hyperparameter β. This condition is in general not compatible with the statistical independence of latents. By providing analytical and numerical arguments, we show that this incompatibility leads to a non-monotonic inference performance in β -VAE with a finite optimal β .","2576-2303","978-1-7281-4300-2","10.1109/IEEECONF44664.2019.9048921","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9048921","Autoencoder;Bayesian Inference","Data models;Decoding;Analytical models;Numerical models;Covariance matrices;Probabilistic logic;Training","belief networks;data analysis;inference mechanisms;learning (artificial intelligence);statistical analysis","β-VAE;data analysis tasks;disentangled representations;Bayesian inference;latent variables;variational inference;nonmonotonic inference;statistical independence","","1","","25","","30 Mar 2020","","","IEEE","IEEE Conferences"
"Learning Diverse Image Colorization","A. Deshpande; J. Lu; M. -C. Yeh; M. J. Chong; D. Forsyth",University of Illinois at Urbana Champaign; University of Illinois at Urbana Champaign; University of Illinois at Urbana Champaign; University of Illinois at Urbana Champaign; University of Illinois at Urbana Champaign,"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","9 Nov 2017","2017","","","2877","2885","Colorization is an ambiguous problem, with multiple viable colorizations for a single grey-level image. However, previous methods only produce the single most probable colorization. Our goal is to model the diversity intrinsic to the problem of colorization and produce multiple colorizations that display long-scale spatial co-ordination. We learn a low dimensional embedding of color fields using a variational autoencoder (VAE). We construct loss terms for the VAE decoder that avoid blurry outputs and take into account the uneven distribution of pixel colors. Finally, we build a conditional model for the multi-modal distribution between grey-level image and the color field embeddings. Samples from this conditional model result in diverse colorization. We demonstrate that our method obtains better diverse colorizations than a standard conditional variational autoencoder (CVAE) model, as well as a recently proposed conditional generative adversarial network (cGAN).","1063-6919","978-1-5386-0457-1","10.1109/CVPR.2017.307","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8099790","","Image color analysis;Decoding;Colored noise;Standards;Training;Computed tomography","image colour analysis;learning (artificial intelligence);statistical distributions","multiple viable colorizations;single grey-level image;low dimensional embedding;color field embeddings;diverse colorization;standard conditional variational autoencoder model;diverse image colorization learning;long-scale spatial coordination;pixel color distribution;multimodal distribution;blurry outputs","","65","","31","","9 Nov 2017","","","IEEE","IEEE Conferences"
"Learning Latent Distribution for Distinguishing Network Traffic in Intrusion Detection System","L. Vu; V. L. Cao; Q. U. Nguyen; D. N. Nguyen; D. T. Hoang; E. Dutkiewicz","Le Quy Don Technical University, Hanoi, Vietnam; Le Quy Don Technical University, Hanoi, Vietnam; Le Quy Don Technical University, Hanoi, Vietnam; School of Electrical and Data Engineering, University of Technology Sydney, Australia; School of Electrical and Data Engineering, University of Technology Sydney, Australia; School of Electrical and Data Engineering, University of Technology Sydney, Australia","ICC 2019 - 2019 IEEE International Conference on Communications (ICC)","15 Jul 2019","2019","","","1","6","We develop a novel deep learning model, Multidistributed Variational AutoEncoder (MVAE), for the network intrusion detection. To make the traffic more distinguishable, MVAE introduces the label information of data samples into the Kullback-Leibler (KL) term of the loss function of Variational AutoEncoder (VAE). This label information allows MVAEs to force/partition network data samples into different classes with different regions in the latent feature space. As a result, the network traffic samples are more distinguishable in the new representation space (i.e., the latent feature space of MVAE), thereby improving the accuracy in detecting intrusions. To evaluate the efficiency of the proposed solution, we carry out intensive experiments on two popular network intrusion datasets, i.e., NSL-KDD and UNSWNB15 under four conventional classifiers including Gaussian Naive Bayes (GNB), Support Vector Machine (SVM), Decision Tree (DT), and Random Forest (RF). The experimental results demonstrate that our proposed approach can significantly improve the accuracy of intrusion detection algorithms up to 24.6% compared to the original one (using area under the curve metric).","1938-1883","978-1-5386-8088-9","10.1109/ICC.2019.8762015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762015","","Logic gates;Boolean functions;Qubit;Scalability;Input variables;Explosions","Bayes methods;decision trees;Gaussian processes;random forests;security of data;support vector machines","latent distribution;deep learning model;MVAE;network intrusion detection;Kullback-Leibler term;latent feature space;multidistributed variational autoencoder;Gaussian Naive Bayes;Support Vector Machine;Decision Tree;Random Forest","","17","","24","","15 Jul 2019","","","IEEE","IEEE Conferences"
"Topic-Enhanced Capsule Network for Multi-Label Emotion Classification","H. Fei; D. Ji; Y. Zhang; Y. Ren","School of Cyber Science and Engineering, Wuhan University, Wuhan, China; School of Cyber Science and Engineering, Wuhan University, Wuhan, China; School of Engineering, Westlake University, Hangzhou, China; Laboratory of Language Engineering and Computing, Guangdong University of Foreign Studies, Guangzhou, China","IEEE/ACM Transactions on Audio, Speech, and Language Processing","23 Jun 2020","2020","28","","1839","1848","Identifying multiple emotions in a piece of text is an important research topic in the NLP community.Existing methods usually model the task as a multi-label classification problem, while these work has two issues. First, these methods fail to leverage the topic information of the text, which has been shown to be effective for sentiment analysis task. Second, different parts of the text can contribute differently to predicting different emotion labels, so the proposed model needs to capture effective features for each corresponding emotion, which is not considered by existing models. To tackle these problems, we propose a topic-enhanced capsule network, which contains two main parts: a variational autoencoder and a capsule module, for multi-label emotion detection task. Specifically, the variational autoencoder can learn the latent topic information of the text, and the capsule module can capture rich features for corresponding emotion. Experimental results on two benchmark datasets show that the proposed model achieves the current best performance, outperforming previous methods and strong baselines by a large margin.","2329-9304","","10.1109/TASLP.2020.3001390","National Natural Science Foundation of China(grant numbers:61702121,61772378); National Philosophy Social Science Major Bidding Project(grant numbers:11&zd189); Research Foundation of Ministry of Education of China(grant numbers:18JZD015); Key Project of State Language Commission of China(grant numbers:ZDI135-112); Guangdong Basic and Applied Basic Research Foundation of China(grant numbers:2020A151501705); Bidding Project of GDUFS Laboratory of Language Engineering and Computing(grant numbers:LEC2018ZBKT004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9113297","Information extraction;emotion detection;neural networks;topic model;sentiment analysis","Task analysis;Predictive models;Speech processing;Routing;Feature extraction;Motion pictures;Decoding","emotion recognition;feature extraction;learning (artificial intelligence);pattern classification;sentiment analysis","latent topic information;multilabel emotion detection task;capsule module;variational autoencoder;emotion labels;sentiment analysis task;multilabel classification problem;NLP community;multilabel emotion classification;topic-enhanced capsule network","","12","","58","IEEE","10 Jun 2020","","","IEEE","IEEE Journals"
"Parallel Tacotron: Non-Autoregressive and Controllable TTS","I. Elias; H. Zen; J. Shen; Y. Zhang; Y. Jia; R. J. Weiss; Y. Wu",Google; Google; Google; Google; Google; Google; Google,"ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","5709","5713","Although neural end-to-end text-to-speech models can synthesize highly natural speech, there is still room for improvements to its efficiency and naturalness. This paper proposes a non-autoregressive neural text-to-speech model augmented with a variational autoencoder-based residual encoder. This model, called Parallel Tacotron, is highly parallelizable during both training and inference, allowing efficient synthesis on modern parallel hardware. The use of the variational autoencoder relaxes the one-to-many mapping nature of the text-to-speech problem and improves naturalness. To further improve the naturalness, we use lightweight convolutions, which can efficiently capture local contexts, and introduce an iterative spectrogram loss inspired by iterative refinement. Experimental results show that Parallel Tacotron matches a strong autoregressive baseline in subjective evaluations with significantly decreased inference time.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414718","Neural TTS;non-autoregressive;VAE;self-attention","Training;Convolution;Conferences;Natural languages;Hardware;Acoustics;Decoding","autoregressive processes;computational complexity;iterative methods;learning (artificial intelligence);neural nets;speech processing;speech synthesis;text analysis","modern parallel hardware;mapping nature;text-to-speech problem;strong autoregressive baseline;controllable TTS;neural end-to-end text-to-speech models;highly natural speech;nonautoregressive neural text-to-speech model;variational autoencoder-based residual encoder;called Parallel Tacotron","","9","","42","","13 May 2021","","","IEEE","IEEE Conferences"
"A machine learning methodology for inferring network S-parameters in the presence of variability","X. Ma; M. Raginsky; A. C. Cangellaris","Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL; University of Illinois at Urbana-Champaign, Urbana, IL, US; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL","2018 IEEE 22nd Workshop on Signal and Power Integrity (SPI)","2 Jul 2018","2018","","","1","4","This paper proposes the use of Variational Autoencoders, a generative modeling technique, for the problem of inferring S-parameters of linear multiport networks in the presence of manufacturing variability. The Variational Autoencoder learns the underlying data generation process and yields a generative network that can approximately mimic the probability distribution of the training data. The generated samples can be used for subsequent statistical simulations. A post-processing step, applying Vector Fitting to the predicted S-parameters, constrains the model to a finite-order rational function form and enforces appropriate physical constraints. The method is validated through its application to a coupled micro strip transmission line.","","978-1-5386-2299-5","10.1109/SaPIW.2018.8401643","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8401643","Bayes methods;inference algorithms;integrated circuit interconnections;statistical analysis;unsupervised learning","Scattering parameters;Standards;Integrated circuit modeling;Training data;Predictive models;Integrated circuit interconnections","approximation theory;electronic engineering computing;learning (artificial intelligence);microstrip lines;multiport networks;probability;rational functions;vectors","linear multiport networks;manufacturing variability;Variational Autoencoder;probability distribution;subsequent statistical simulations;post-processing step;predicted S-parameters;finite-order rational function form;network S-parameters;data generation process;machine learning;Vector Fitting;micro strip transmission line","","4","","13","","2 Jul 2018","","","IEEE","IEEE Conferences"
"SVAE-WGAN-Based Soft Sensor Data Supplement Method for Process Industry","S. Gao; S. Qiu; Z. Ma; R. Tian; Y. Liu","College of Computer Science and Engineering, Northwest Normal University, Lanzhou, China; College of Computer Science and Engineering, Northwest Normal University, Lanzhou, China; College of Computer Science and Engineering, Northwest Normal University, Lanzhou, China; College of Computer Science and Engineering, Northwest Normal University, Lanzhou, China; College of Computer Science and Engineering, Northwest Normal University, Lanzhou, China","IEEE Sensors Journal","29 Dec 2021","2022","22","1","601","610","Challenges of process industry, which is characterized as hugeness of process variables in complexity of industrial environment, can be tackled effectively by the use of soft sensor technology. However, how to supplement the dataset with effective data supplement method under harsh industrial environment is a key issue for the enhancement of prediction accuracy in soft-sensing model. Aimed at this problem, a SVAE-WGAN based soft sensor data supplement method is proposed for process industry. Firstly, deep features are extracted with the stacking of the variational autoencoder (SVAE). Secondly, a generation model is constructed with the combination of stacked variational autoencoder (SVAE) and Wasserstein generative adversarial network (WGAN). Thirdly, the proposed model is optimized with training of dataset in industrial process. Finally, the proposed model is evaluated with abundant experimental tests in terms of MSE, RMSE and MAE. It is shown in the results that the proposed SVAE-WGAN generation network is significantly better than that of the traditional VAE, GAN and WGAN generation network in case of industrial steam volume dataset. Specially, the proposed method is more effective than the latest reference VA-WGAN generation network in terms of RMSE, which is enhanced about 9.08% at most. Moreover, the prediction precision of soft sensors could be improved via the supplement of the training samples.","1558-1748","","10.1109/JSEN.2021.3128562","National Natural Science Foundation of China(grant numbers:71961028); Lanzhou Science and Technology Planning Projects(grant numbers:2018-01-58,2017-4-101); Innovation Ability Promotion Project of Gansu Universities(grant numbers:2019B-038); Backbone Fund of Youth Teachers’ Capability Promotion(grant numbers:NWNU-LKQN2020-14); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9615202","Soft sensor;data supplement;Wasserstein generative adversarial network;SVAE-WGAN","Data models;Training;Generative adversarial networks;Mathematical models;Industries;Predictive models;Decoding","data handling;learning (artificial intelligence);manufacturing processes;mean square error methods;neural nets;production engineering computing;soft sensors","SVAE-WGAN-based soft sensor data supplement method;process industry;process variables;soft sensor technology;harsh industrial environment;soft-sensing model;industrial process;SVAE-WGAN generation network;industrial steam volume dataset;stacked variational autoencoder;Wasserstein generative adversarial network;deep feature extraction;RMSE;MAE","","2","","30","IEEE","16 Nov 2021","","","IEEE","IEEE Journals"
"Robot Multimodal Anomaly Diagnosis by Learning Time-lagged Complex Dynamics","L. Yang; W. Yan; Z. Xu; H. Wu","Guangdong Provincial Key Laboratory of Electronic Information Products Reliability Technology, Guangzhou, China; Institute of Intelligent Manufacturing, Guangdong Academy of Sciences, Guangzhou, China; Institute of Intelligent Manufacturing, Guangdong Academy of Sciences, Guangzhou, China; Institute of Intelligent Manufacturing, Guangdong Academy of Sciences, Guangzhou, China","2021 IEEE International Conference on Real-time Computing and Robotics (RCAR)","31 Aug 2021","2021","","","509","514","Robots are prone to making anomalies when performing manipulation tasks in unstructured environments, it is often desirable that robots can detect, diagnose them, and then effectively provides prior experiences for rapidly adapting the robot anomalous behaviors. The traditional methods on anomaly diagnosis are to focus on univariate time series and ignore the modality correlation and time-dependent, which can't be applied in a Human-robot collaborative (HRC) system that is integrated with multiple sensors for improving autonomy and safety. The variability and temporal consistency of multimodal sensory data exacerbate anomaly diagnosis still an open problem in robotics. Here we propose a novel method of multimodal anomaly diagnosis by learning the time-lagged dynamics of anomalies detected during an HRC task. Specifically, a time-lagged variational auto-encoder model ($tlVAE$) is first proposed to compress complex multivariate dynamics into simpler manifolds, and the manifolds are used to fitting a dynamic time warping-based K-nearest neighbors model for anomaly diagnosis in a multi-classes classification scheme. A real-robot anomaly dataset is presented to evaluate the significance and effectiveness in extracting underlying time-dependent patterns, results indicate that the efficiency and precision of diagnosis can be improved by introducing a sparse representation of the multivariate sample. Meanwhile, we compare the accuracy of anomaly diagnosis with several commonly used sparse representation methods, including Principal Component Analysis (PCA), Time-lagged Independent Component Analysis (TICA), Autoencoder (AE) as well as Variational Autoencoder (VAE). The resulting anomaly diagnosis accuracy of 97.6% across 7 kinds of anomalies, which outperformed all the baselines.","","978-1-6654-3678-6","10.1109/RCAR52367.2021.9517597","National Science Foundation of China(grant numbers:61950410758); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9517597","","Manifolds;Time series analysis;Independent component analysis;Robot sensing systems;Sensor systems;Real-time systems;Sensors","human-robot interaction;learning (artificial intelligence);pattern classification;principal component analysis;time series","robot multimodal anomaly diagnosis;time-lagged complex dynamics;manipulation tasks;robot anomalous behaviors;univariate time series;modality correlation;human-robot collaborative system;multimodal sensory data;robotics;complex multivariate dynamics;dynamic time;real-robot anomaly dataset;time-dependent patterns;time-lagged independent component analysis;anomaly diagnosis accuracy;time-lagged variational autoencoder model","","","","22","","31 Aug 2021","","","IEEE","IEEE Conferences"
"L-Verse: Bidirectional Generation Between Image and Text","T. Kim; G. Song; S. Lee; S. Kim; Y. Seo; S. Lee; S. H. Kim; H. Lee; K. Bae",LG AI Research; LG AI Research; LG AI Research; LG AI Research; LG AI Research; LG AI Research; LG AI Research; LG AI Research; LG AI Research,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","16505","16515","Far beyond learning long-range interactions of natural language, transformers are becoming the de-facto standard for many vision tasks with their power and scalability. Especially with cross-modal tasks between image and text, vector quantized variational autoencoders (VQ-VAEs) are widely used to make a raw RGB image into a sequence of feature vectors. To better leverage the correlation between image and text, we propose L-Verse, a novel architecture consisting of feature-augmented variational autoencoder (AugVAE) and bidirectional auto-regressive transformer (BiART) for image-to-text and text-to-image generation. Our AugVAE shows the state-of-the-art reconstruction performance on ImageNetlK validation set, along with the robustness to unseen images in the wild. Unlike other models, BiART can distinguish between image (or text) as a conditional reference and a generation target. L-Verse can be directly used for image-to-text or text-to-image generation without any finetuning or extra object detection framework. In quantitative and qualitative experiments, L-Verse shows impressive results against previous methods in both image-to-text and text-to-image generation on MS-COCO Captions. We furthermore assess the scalability of L-Verse architecture on Conceptual Captions and present the initial result of bidirectional vision-language representation learning on general domain.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01603","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879208","Vision + language; Image and video synthesis and generation; Representation learning; Scene analysis and understanding","Representation learning;Training;Scalability;Computer architecture;Transformers;Robustness;Pattern recognition","computer vision;feature extraction;image classification;image colour analysis;image reconstruction;image representation;learning (artificial intelligence);natural languages;object detection;regression analysis;vector quantisation","or text;unseen images;text-to-image generation;image-to-text;bidirectional auto-regressive transformer;L-Verse;raw RGB image;vector quantized variational autoencoders","","","","53","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Research on Intrusion Detection Method Based on Generative Adversarial Network","J. Zhang; Y. Zhao","College for Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; College for Information Science and Technology, Beijing University of Chemical Technology, Beijing, China","2021 International Conference on Big Data Analysis and Computer Science (BDACS)","23 Aug 2021","2021","","","264","268","Intrusion detection technology has always been a hot topic in the field of network security research. Now different types of intrusion traffic in the real network environment are imbalanced, which lead to poor recognition rate of classification models when dealing with rare attack types with few training samples. In order to solve the above problems, a new VAE-GAN model is proposed by combining VAE with GAN and optimizing the loss function to generate high-quality intrusion samples more efficiently and stably. In the training phase, original samples and generated samples are mixed as the input of classifiers. The experimental results show that the proposed VAE-GAN model has stronger stability and faster model convergence speed in the process of generating data. For small-sample data, the Recall and F1-score are significantly improved by using the generated samples of VAE-GAN model as the training set of classifiers.","","978-1-6654-2561-2","10.1109/BDACS53596.2021.00065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9516484","Intrusion detection;samples class imbalance;Generative Adversarial Network;Variational Auto-Encoder;Deep learning","Training;Computer science;Intrusion detection;Generative adversarial networks;Data models;Stability analysis;Security","computer network security;Internet;learning (artificial intelligence);neural nets","VAE-GAN model;faster model convergence speed;small-sample data;intrusion detection method;generative adversarial network;intrusion detection technology;network security research;intrusion traffic;network environment;recognition rate;classification models;rare attack types;training samples;high-quality intrusion samples;training phase;loss function;F1-score;variational autoencoder","","","","8","","23 Aug 2021","","","IEEE","IEEE Conferences"
"Solving the data imbalance problem in network intrusion detection : A MP-CVAE based method","H. Li; Z. Wang; H. Meng; Z. Zhou","School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Mathematics, Southwest Jiaotong University, Chengdu, China; School of Mathematics, Southwest Jiaotong University, Chengdu, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China","2022 10th International Workshop on Signal Design and Its Applications in Communications (IWSDA)","6 Sep 2022","2022","","","1","5","In the area of network intrusion detection, harmful cyber-attacks are usually rare when compared to normal samples, which makes feature extraction and intrusion detection difficult. Increasing the amount of the anomalous samples through data generation can effectively relieve class imbalance, and thus significantly improve the classifier's performance. Variational Autoencoder (VAE) is an effective data generation model that assumes that the latent variables satisfy one prior distribution and creates new data by decoding the latent variables sampled from the distribution. This assumption is reasonable for unsu-pervised learning. However, when multiple types of attack data have obvious distribution differences, using the traditional VAE may cause various types of generated data to be mixed together. To solve this problem, we propose an improved generation model based on the conditional variational autoencoder, which encodes different types of samples into Gaussian distributions with significant difference to strengthen the discrimination between different classes in the data generation process. A series of experiments based on fitted data and real data, such as NSL-KDD, CIC-IDS2017, and CSE-CIC-IDS2018, demonstrate the effectiveness of this method.","2150-3699","978-1-6654-5298-4","10.1109/IWSDA50346.2022.9870444","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870444","intrusion detection;imbalanced data;data augmentation;CVAE","Conferences;Network intrusion detection;Telecommunication traffic;Gaussian distribution;Feature extraction;Data models;Decoding","Bayes methods;feature extraction;Gaussian distribution;learning (artificial intelligence);natural language processing;neural nets;pattern classification;security of data;statistical analysis","data imbalance problem;network intrusion detection;MP-CVAE based method;feature extraction;anomalous samples;class imbalance;effective data generation model;latent variables;conditional variational autoencoder;Gaussian distributions;data generation process;NSL-KDD data;CIC-IDS2017 data;CSE-CIC-IDS2018 data","","","","19","IEEE","6 Sep 2022","","","IEEE","IEEE Conferences"
"Reconstruction of 3D CT from A Single X-ray Projection View Using CVAE-GAN","L. Jiang; M. Zhang; R. Wei; B. Liu; X. Bai; F. Zhou","Image Processing Center, Beihang University, Beijing, China; Image Processing Center, Beihang University, Beijing, China; Chinese Cancer Center, Chinese Academy of Medical Sciences, Beijing, China; Image Processing Center, Beihang University, Beijing, China; Image Processing Center, Beihang University, Beijing, China; Image Processing Center, Beihang University, Beijing, China","2021 IEEE International Conference on Medical Imaging Physics and Engineering (ICMIPE)","14 Feb 2022","2021","","","1","6","Computed tomography can provide a 3D view of the patient's internal anatomy. However, traditional CT reconstruction methods require hundreds of X-ray projections through a full rotational scan of the body, which cannot be performed on a typical X-ray machine. In order to deal with the impact of organ movement caused by respiration in radiotherapy on the accuracy of radiotherapy, we propose to reconstruct CT from a single X-ray projection view using the conditional variational autoencoder. Conditional variational autoencoder encodes the features of a 2D X-ray projection. The decoder decodes the hidden variables encoded by the encoder and increase data dimension from 2D (X-rays) to 3D (CT) to generates a corresponding 3D CT. In addition, we use the discriminator to distinguish the generated 3D CT from the real 3D CT to make the generated 3D CT more realistic. We demonstrate the feasibility of the approach with 3D CT of two patients with lung cancer.","","978-1-6654-2608-4","10.1109/ICMIPE53131.2021.9698875","National Key R&D Program of China(grant numbers:2018YFA0704100,2018YFA0704101); National Natural Science Foundation of China(grant numbers:61601012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9698875","CT reconstruction;X-ray projection;VAE;GAN","Three-dimensional displays;Computed tomography;Reconstruction algorithms;Decoding;Task analysis;Motion control;Image reconstruction","cancer;computerised tomography;image reconstruction;lung;medical image processing;radiation therapy","conditional variational autoencoder;generated 3D CT;single X-ray projection view;patient;traditional CT reconstruction methods;typical X-ray machine;radiotherapy","","","","14","IEEE","14 Feb 2022","","","IEEE","IEEE Conferences"
"Epileptic Seizures Prediction Based on Unsupervised Learning for Feature Extraction","R. Wang; L. Wang; P. He; Y. Cui; D. Wu","Chongqing Key Laboratory of Ubiquitous Sensing and Networking, Chongqing, China; Chongqing Key Laboratory of Ubiquitous Sensing and Networking, Chongqing, China; Chongqing Key Laboratory of Ubiquitous Sensing and Networking, Chongqing, China; Chongqing Key Laboratory of Ubiquitous Sensing and Networking, Chongqing, China; Chongqing Key Laboratory of Ubiquitous Sensing and Networking, Chongqing, China","ICC 2022 - IEEE International Conference on Communications","11 Aug 2022","2022","","","4643","4648","Epilepsy is one of the most common neurological diseases in the world. Feature extraction of electroencephalogram (EEG) is very important for predicting epileptic seizures. Conventional technologies of EEG signals analysis mostly utilized supervised learning methods with a mass of labeled data. However, annotating data is a time-consuming and expensive process. In this paper, we propose a novel unsupervised feature learning method based on variational autoencoder, namely, residual convolution variational autoencoder (RCVAE), which aims to improve the accuracy of epileptic seizure prediction. RCVAE automatically extracts important features and reconstructs the spatiotemporal EEG signal, reducing the learning difficulty with residual network structure. In addition, this work also utilizes the Pearson correlation coefficient and the reconstructed loss function, which are used to evaluate the quality of the reconstructed signal. Finally, the performance of the proposed model is verified on the CHBMIT dataset, the accuracy rate is up to 96.17%, and the false alarm rate is only 0.015.","1938-1883","978-1-5386-8347-7","10.1109/ICC45855.2022.9838303","Chongqing Municipal Education Commission; Natural Science Foundation of Chongqing; Natural Science Foundation of Chongqing; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9838303","Epilepsy prediction;feature extraction;unsupervised learning;residual learning","Representation learning;Correlation coefficient;Supervised learning;Epilepsy;Predictive models;Feature extraction;Brain modeling","diseases;electroencephalography;feature extraction;learning (artificial intelligence);medical disorders;medical signal processing;neurophysiology;signal classification;unsupervised learning","novel unsupervised feature learning method;residual convolution variational autoencoder;RCVAE;epileptic seizure prediction;reconstructs;spatiotemporal EEG signal;learning difficulty;residual network structure;reconstructed signal;epileptic seizures prediction;unsupervised learning;feature extraction;common neurological diseases;EEG signals analysis;supervised learning methods","","","","20","IEEE","11 Aug 2022","","","IEEE","IEEE Conferences"
"Task-Generic Hierarchical Human Motion Prior using VAEs","J. Li; R. Villegas; D. Ceylan; J. Yang; Z. Kuang; H. Li; Y. Zhao",USC Institute for Creative Technologies; Adobe Research; Adobe Research; Adobe Research; USC Institute for Creative Technologies; UC Berkeley; USC Institute for Creative Technologies,"2021 International Conference on 3D Vision (3DV)","6 Jan 2022","2021","","","771","781","A deep generative model that describes human motions can benefit a wide range of fundamental computer vision and graphics tasks, such as providing robustness to video-based human pose estimation, predicting complete body movements for motion capture systems during occlusions, and assisting key frame animation with plausible movements. In this paper, we present a method for learning complex human motions independent of specific tasks using a combined global and local latent space to facilitate coarse and fine-grained modeling. Specifically, we propose a hierarchical motion variational autoencoder (HM-VAE) that consists of a 2-level hierarchical latent space. While the global latent space captures the overall global body motion, the local latent space enables to capture the refined poses of the different body parts. We demonstrate the effectiveness of our hierarchical motion variational autoencoder in a variety of tasks including video-based human pose estimation, motion completion from partial observations, and motion synthesis from sparse key-frames. Even though, our model has not been trained for any of these tasks specifically, it provides superior performance than task-specific alternatives. Our general-purpose human motion prior model can fix corrupted human body animations and generate complete movements from incomplete observations.","2475-7888","978-1-6654-2688-6","10.1109/3DV53792.2021.00086","Arm; Arm; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9665881","","Training;Interpolation;Three-dimensional displays;Motion estimation;Pose estimation;Predictive models;Animation","computer animation;computer vision;image motion analysis;image sequences;learning (artificial intelligence);pose estimation;video signal processing","task-generic hierarchical human motion;deep generative model;fundamental computer vision;graphics tasks;video-based human pose estimation;motion capture systems;key frame animation;local latent space;fine-grained modeling;hierarchical motion variational autoencoder;HM-VAE;global latent space;global body motion;motion completion;motion synthesis;sparse key-frames;human motion prior model;human body animations","","","","57","IEEE","6 Jan 2022","","","IEEE","IEEE Conferences"
"Drug-Drug Interactions Prediction Based on Drug Embedding and Graph Auto-Encoder","S. Purkayastha; I. Mondal; S. Sarkar; P. Goyal; J. K. Pillai","Department of Computer Science and Engineering, IIT Kharagpur; Department of Computer Science and Engineering, IIT Kharagpur; Department of Computer Science and Engineering, IIT Kharagpur; Department of Computer Science and Engineering, IIT Kharagpur; Excelra Knowledge Solutions, Hyderabad","2019 IEEE 19th International Conference on Bioinformatics and Bioengineering (BIBE)","27 Dec 2019","2019","","","547","552","Identification of potential Drug-Drug Interactions (DDI) for newly developed drugs is essential in public healthcare. Computational methods of DDI prediction rely on known interactions to learn possible interaction between drug pairs whose interactions are unknown. Past work has used various similarity measures of drugs to predict DDIs. In this paper, we propose an effective approach to DDI Prediction using rich drug representations utilizing multiple knowledge sources. We have used the Drug-Target Interaction (DTI) Network to learn an embedding of drugs by using the metapath2vec algorithm. We have also used drug representation gained from the rich chemical structure representation of drugs using Variational Auto-Encoder. The DDI prediction problem is modeled as a link prediction problem in the DDI network containing known interactions. We represent the nodes in the DDI network as their embeddings. We apply a link prediction algorithm based on Graph Auto-Encoders to predict additional edges in this network, which are potential interactions. We have evaluated our approach on three benchmark DDI datasets, namely DrugBank, SemMedDB, and BioSNAP. Experimental results demonstrate that the proposed method outperforms the prior methods in terms of several performance metrics (AUC, AUPR, and F1-score) on all the datasets. Furthermore, we have also evaluated the role of the individual type of drug representation embeddings in boosting up the performance of DDI Prediction.","2471-7819","978-1-7281-4617-1","10.1109/BIBE.2019.00104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941958","Drug-drug interaction, Representation learning, Knowledge graph embeddings, Structural Representation","Drugs;Chemicals;Knowledge engineering;Prediction algorithms;Diffusion tensor imaging;Task analysis;Semantics","biology computing;data mining;drugs;graph theory;learning (artificial intelligence)","drug pairs;drug representations;variational autoencoder;drug representation embeddings;benchmark DDI datasets;link prediction algorithm;DDI network;DDI prediction problem;drug-target interaction network;known interactions;graph autoencoder;drug-drug interaction prediction","","4","","24","","27 Dec 2019","","","IEEE","IEEE Conferences"
"Heterogeneous Software Defect Prediction using Generative Models","B. Jain; S. Patidar; D. Sudershan","Delhi Technological University, Delhi, India; Delhi Technological University, Delhi, India; Delhi Technological University, Delhi, India","2022 IEEE 11th International Conference on Communication Systems and Network Technologies (CSNT)","8 Jun 2022","2022","","","367","372","It is widely known that one of the most helpful phases in SDLC is Software Defect Prediction (SDP). SDP can tell which modules have the highest chances to have bugs and companies can then devote suitable time in analysing those modules. SDP can be extremely helpful but it can be very difficult to predict buggy modules. Recently many studies have shown how in cases where enough data is not present, defect data from different projects can be used; this is called cross-project defect prediction (CPDP). However most of these studies require Homogeneous data for prediction i.e. our source dataset and target dataset must have the same parameters. Many times, especially for newer startups, previous data is not present for defect prediction, in such a case we want to be able to predict defects with data from other projects. We have trained and compared the performance of three models namely a GAN, Variational Autoencoder, and Adversarial Autoencoder for quickly transferring lessons learned about defect prediction among different datasets.","2329-7182","978-1-6654-8038-3","10.1109/CSNT54456.2022.9787607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9787607","Defect Prediction;Cross Project;Autoencoder;Datasets","Communication systems;Conferences;Computer bugs;Static VAr compensators;Companies;Predictive models;Generative adversarial networks","","","","","","21","IEEE","8 Jun 2022","","","IEEE","IEEE Conferences"
"Exploring Dimensionality Reduction Techniques for Efficient Surrogate-Assisted optimization","S. Ullah; D. A. Nguyen; H. Wang; S. Menzel; B. Sendhoff; T. Bäck","Leiden Institute of Advanced Computer Science (LIACS), Leiden University, Netherlands; Leiden Institute of Advanced Computer Science (LIACS), Leiden University, Netherlands; CNRS, LIP6, Sorbonne Université, Paris, France; Honda Research Institute Europe GmbH (HRI-EU), Offenbach/Main, Germany; Honda Research Institute Europe GmbH (HRI-EU), Offenbach/Main, Germany; Leiden Institute of Advanced Computer Science (LIACS), Leiden University, Netherlands","2020 IEEE Symposium Series on Computational Intelligence (SSCI)","5 Jan 2021","2020","","","2965","2974","Constructing surrogate models of high dimensional optimization problems is challenging due to the computational complexity involved. This paper empirically investigates the practicality of major dimensionality reduction techniques for encapsulating the high dimensional design space into compact representations. Such low dimensional representations of the design space can be utilized for constructing the surrogate models efficiently. Based on historical mainstays and recent developments in deep learning, we study four dimensionality reduction techniques in this paper, namely Principal Component Analysis, Kernel Principal Component Analysis, Autoencoders and Variational Autoencoders. We evaluate and compare these techniques based on quality assessments of the corresponding low dimensional surrogate models on a diverse range of test cases. These test cases are defined on combinations of three dimensionsalities, ten well-known benchmark problems from the continuous optimization domain and two surrogate modeling techniques, namely Kriging and Polynomials. Our results clearly demonstrate the superiority of Autoencoders and Principal Component Analysis on the criteria of modeling accuracy and global optimality respectively.","","978-1-7281-2547-3","10.1109/SSCI47803.2020.9308465","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308465","dimensionality reduction;surrogate-assisted optimization;machine learning;deep latent-variable models;principal component analysis","Principal component analysis;Optimization;Data models;Computational modeling;Kernel;Vegetation;Decoding","computational complexity;deep learning (artificial intelligence);optimisation;polynomials;principal component analysis","low dimensional surrogate models;surrogate modeling techniques;dimensionality reduction techniques;efficient surrogate-assisted optimization;high dimensional optimization problems;high dimensional design space;low dimensional representations;Kernel Principal Component Analysis;computational complexity;deep learning;variational autoencoder;quality assessments;polynomials","","2","","44","","5 Jan 2021","","","IEEE","IEEE Conferences"
"DECA: Deep viewpoint-Equivariant human pose estimation using Capsule Autoencoders","N. Garau; N. Bisagno; P. Bródka; N. Conci","University of Trento, Povo, Trento, TN; University of Trento, Povo, Trento, TN; University of Trento, Povo, Trento, TN; University of Trento, Povo, Trento, TN","2021 IEEE/CVF International Conference on Computer Vision (ICCV)","28 Feb 2022","2021","","","11657","11666","Human Pose Estimation (HPE) aims at retrieving the 3D position of human joints from images or videos. We show that current 3D HPE methods suffer a lack of viewpoint equivariance, namely they tend to fail or perform poorly when dealing with viewpoints unseen at training time. Deep learning methods often rely on either scale-invariant, translation-invariant, or rotation-invariant operations, such as max-pooling. However, the adoption of such procedures does not necessarily improve viewpoint generalization, rather leading to more data-dependent methods. To tackle this issue, we propose a novel capsule autoencoder network with fast Variational Bayes capsule routing, named DECA. By modeling each joint as a capsule entity, combined with the routing algorithm, our approach can preserve the joints’ hierarchical and geometrical structure in the feature space, independently from the viewpoint. By achieving viewpoint equivariance, we drastically reduce the network data dependency at training time, resulting in an improved ability to generalize for unseen viewpoints. In the experimental validation, we outperform other methods on depth images from both seen and unseen viewpoints, both top-view, and front-view. In the RGB domain, the same network gives state-of-the-art results on the challenging viewpoint transfer task, also establishing a new framework for top-view HPE. The code can be found at https://github.com/mmlab-cv/DECA.","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.01147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9710795","Gestures and body pose;3D from a single image and shape-from-x;Detection and localization in 2D and 3D;Efficient training and inference methods;Optimization and learning methods;Vision applications and systems","Training;Deep learning;Computer vision;Three-dimensional displays;Codes;Pose estimation;Routing","","","","1","","38","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"Comparison of Semi-supervised Deep Neural Networks for Anomaly Detection in Industrial Processes","G. S. Chadha; A. Rabbani; A. Schwung","Department of Automation Technology, South Westphalia University of Applied Sciences, Soest, Germany; Department of Automation Technology, South Westphalia University of Applied Sciences, Soest, Germany; Department of Automation Technology, South Westphalia University of Applied Sciences, Soest, Germany","2019 IEEE 17th International Conference on Industrial Informatics (INDIN)","30 Jan 2020","2019","1","","214","219","Anomaly detection methods are used for fast and reliable detection of abnormal events in industrial processes. The early detection of anomalies can avoid critical process breakdowns and hence can increase the overall productivity of the system. The availability of labelled datasets for all the possible faulty scenarios is generally not possible, as most of the industrial systems operate in a non-faulty condition. Deep learning architectures that can be trained in an unsupervised setting such as deep autoencoders, denoising autoencoder and variational autoencoder provide an appropriate solution to this problem of unlabelled data for industrial anomaly detection. We investigate and compare the applicability of these architectures on the benchmark Tennessee Eastman fault detection study. The deep architectures are trained to model only the normal operating condition with its threshold set by kernel density estimation. A detailed comparison from the experimental results shows superior anomaly detection capabilities of the variational autoencoder as compared to the other methods.","2378-363X","978-1-7281-2927-3","10.1109/INDIN41052.2019.8972172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8972172","Semi-supervised learning;Anomaly detection;autoencoders;deep learning","","chemical industry;fault diagnosis;learning (artificial intelligence);neural nets;production engineering computing","semisupervised deep neural networks;industrial processes;deep learning architectures;unsupervised setting;industrial anomaly detection;Tennessee Eastman fault detection","","9","","29","","30 Jan 2020","","","IEEE","IEEE Conferences"
"On the Road With 16 Neurons: Towards Interpretable and Manipulable Latent Representations for Visual Predictions in Driving Scenarios","A. Plebe; M. D. Lio","Department of Information Engineering and Computer Science, University of Trento, Trento, Italy; Department of Industrial Engineering, University of Trento, Trento, Italy","IEEE Access","7 Oct 2020","2020","8","","179716","179734","This paper proposes a strategy for visual perception in the context of autonomous driving. Humans, when not distracted or drunk, are still the best drivers you can currently find. For this reason, we take inspiration from two theoretical ideas about the human mind and its neural organization. The first idea concerns how the brain uses structures of neuron ensembles that expand and compress information to extract abstract concepts from visual experience and code them into compact representations. The second idea suggests that these neural perceptual representations are not neutral but functional to predicting the future state of affairs in the environment. Similarly, the prediction mechanism is not neutral but oriented to the planning of future action. We identify within the deep learning framework two artificial counterparts of the aforementioned neurocognitive theories. We find a correspondence between the first theoretical idea and the architecture of convolutional autoencoders, while we translate the second theory into a training procedure that learns compact representations which are not neutral but oriented to driving tasks, from two distinct perspectives. From a static perspective, we force separate groups of neural units in the compact representations to represent specific concepts crucial to the driving task distinctly. From a dynamic perspective, we bias the compact representations to predict how the current road scenario will change in the future. We successfully learn compact representations that use as few as 16 neural units for each of the two basic driving concepts we consider: cars and lanes. We maintain the two concepts separated in the latent space to facilitate the interpretation and manipulation of the perceptual representations. The source code for this paper is available at https://github.com/3lis/rnn_vae.","2169-3536","","10.1109/ACCESS.2020.3028185","Horizon 2020 Dreams4Cars Research and Innovation Action, European Commission(grant numbers:731593); Deep Learning Laboratory from the ProM Facility funded by the Fondazione Cassa di Risparmio di Trento e Rovereto, Italy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9210618","Autonomous driving;convergence-divergence zones;deep learning;predictive brain;variational autoencoder","Task analysis;Neurons;Roads;Computational modeling;Autonomous vehicles;Visualization;Machine learning","brain;cognition;driver information systems;learning (artificial intelligence);neural nets;neurophysiology;visual perception","neurons;visual predictions;visual perception;autonomous driving;theoretical idea;neural organization;visual experience;compact representations;neural perceptual representations;prediction mechanism;deep learning framework;driving task;current road scenario;neural units;basic driving concepts","","3","","84","CCBY","1 Oct 2020","","","IEEE","IEEE Journals"
"Accuracy-Aware Compression of Channel Impulse Responses using Deep Learning","T. Altstidl; S. Kram; O. Herrmann; M. Stahlke; T. Feigl; C. Mutschler","Machine Learning and Data Analytics Lab, Friedrich-Alexander-University Erlangen-Nürnberg (FAU), Germany; Precise Positioning and Analytics Department, Fraunhofer Institute for Integrated Circuits IIS, Nürnberg, Germany; Precise Positioning and Analytics Department, Fraunhofer Institute for Integrated Circuits IIS, Nürnberg, Germany; Precise Positioning and Analytics Department, Fraunhofer Institute for Integrated Circuits IIS, Nürnberg, Germany; Precise Positioning and Analytics Department, Fraunhofer Institute for Integrated Circuits IIS, Nürnberg, Germany; Precise Positioning and Analytics Department, Fraunhofer Institute for Integrated Circuits IIS, Nürnberg, Germany","2021 International Conference on Indoor Positioning and Indoor Navigation (IPIN)","4 Jan 2022","2021","","","1","8","Ultra-wideband (UWB) systems based on Channel State Information (CSI) estimate the position of mobile nodes within an environment by using Channel Impulse Responses (CIRs) of multiple stationary nodes. These contain spatial information caused by environment interactions such as reflections and scattering. To estimate positions from CSI of stationary nodes, we must transmit them to a centralized node. This introduces considerable communication overhead.We present a large-scale study to determine whether CSI can be compressed into a small set of underlying latent variables that describe the most valuable information. We evaluate multiple neural network architectures containing encoding (compressing) and decoding (reconstructing) components and compare them to the state-of-the-art compression techniques Discrete Cosine Transform (DCT) and Discrete Wavelet Transform (DWT). We show that fully connected autoencoders achieve the lowest error, outperforming both DCT and DWT. Further experiments prove that the reconstructed CSI can be used for positioning with only mild performance deterioration at a compression of >97% and even when trained on a different environment.","2471-917X","978-1-6654-0402-0","10.1109/IPIN51156.2021.9662545","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9662545","Compression;Channel Impulse Response;Channel State Information;DCT;DWT;(Variational) Autoencoder","Training;Neural networks;Scattering;Transforms;Reflection;Discrete wavelet transforms;Decoding","data compression;discrete cosine transforms;discrete wavelet transforms;image coding;learning (artificial intelligence);neural nets;transient response;ultra wideband radar;wavelet transforms","accuracy-aware compression;Channel Impulse Responses;deep learning;ultra-wideband systems;Channel State Information;mobile nodes;multiple stationary nodes;spatial information;environment interactions;reflections;centralized node;considerable communication overhead;multiple neural network architectures;encoding;compressing;state-of-the-art compression techniques Discrete Cosine Transform;Discrete Wavelet Transform;reconstructed CSI;different environment","","","","50","IEEE","4 Jan 2022","","","IEEE","IEEE Conferences"
"Echocardiography Segmentation With Enforced Temporal Consistency","N. Painchaud; N. Duchateau; O. Bernard; P. -M. Jodoin","Univ Lyon, INSA-Lyon, Université Claude Bernard Lyon 1, UJMSaint Etienne, CNRS, Inserm, CREATIS UMR 5220, U1294, Lyon, France; Institut Universitaire de France (IUF), Paris, France; Univ Lyon, INSA-Lyon, Université Claude Bernard Lyon 1, UJMSaint Etienne, CNRS, Inserm, CREATIS UMR 5220, U1294, Lyon, France; Department of Computer Science, University of Sherbrooke, Sherbrooke, QC, Canada","IEEE Transactions on Medical Imaging","30 Sep 2022","2022","41","10","2867","2878","Convolutional neural networks (CNN) have demonstrated their ability to segment 2D cardiac ultrasound images. However, despite recent successes according to which the intra-observer variability on end-diastole and end-systole images has been reached, CNNs still struggle to leverage temporal information to provide accurate and temporally consistent segmentation maps across the whole cycle. Such consistency is required to accurately describe the cardiac function, a necessary step in diagnosing many cardiovascular diseases. In this paper, we propose a framework to learn the 2D+time apical long-axis cardiac shape such that the segmented sequences can benefit from temporal and anatomical consistency constraints. Our method is a post-processing that takes as input segmented echocardiographic sequences produced by any state-of-the-art method and processes it in two steps to (i) identify spatio-temporal inconsistencies according to the overall dynamics of the cardiac sequence and (ii) correct the inconsistencies. The identification and correction of cardiac inconsistencies relies on a constrained autoencoder trained to learn a physiologically interpretable embedding of cardiac shapes, where we can both detect and fix anomalies. We tested our framework on 98 full-cycle sequences from the CAMUS dataset, which are available alongside this paper. Our temporal regularization method not only improves the accuracy of the segmentation across the whole sequences, but also enforces temporal and anatomical consistency.","1558-254X","","10.1109/TMI.2022.3173669","NSERC Discovery Grants’ Program; Natural Sciences and Engineering Research Council (NSERC) Canada Graduate Scholarships-Doctoral Program; Fonds de recherche du Québec-Nature et technologies (FRQNT) Doctoral Scholarships Program; LABEX PRIMES(grant numbers:ANR-11-LABX-0063); “Investissements d’Avenir” operated by the French National Research Agency (ANR); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9771186","Deep learning;CNN;variational autoencoder;cardiac segmentation;ultrasound;left ventricle;myocardium","Image segmentation;Shape;Echocardiography;Annotations;Encoding;Magnetic resonance imaging;Cardiac function","","","Echocardiography;Heart;Humans;Image Processing, Computer-Assisted;Neural Networks, Computer;Observer Variation","","","37","IEEE","9 May 2022","","","IEEE","IEEE Journals"
"The Method of Disentangled and Interpretable Representations for Speech Enhancement","K. Zhao; Y. Yang; Y. Wang; H. Wang","Information and Communication Engineering School, Communication University of China, Beijing, China; Key Laboratory of Media Audio & Video (Communication University of China), Ministry of Education, Beijing, China; Key Laboratory of Media Audio & Video (Communication University of China), Ministry of Education, Beijing, China; State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China","2021 IEEE 5th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)","5 Apr 2021","2021","5","","1339","1343","We study the problem of speech enhancement in monophonic and variety noisy conditions. Most speech enhancement models have successfully mapped noisy speech features to clean speech features through the deep network. However, analyzation of sequence data multi-scale information still has great challenges, which is important for the speech signal. In this paper, we present an end-to-end hierarchical model , combining factorized hierarchical autoencoder (FHVAE) and independently recurrent neural network (indRNN) structures, which learns disentangled and interpretable representations from speech data in unsupervision way. Compared to other end-to-end models, this encoder can be used to capture the features of speech linguistic and background noise, then encode them into latent variables at different levels. And speech enhancement is achieved by manipulating latent variables of noise conditions. The objective evaluation results demonstrate that the proposed model has better improvements than classic methods, and the training time is shorter than the others.","2689-6621","978-1-7281-8028-1","10.1109/IAEAC50856.2021.9390768","Communication University of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9390768","speech enhancement;unsupervised learning;variational autoencoder;independently recurrent neural network","Training;Recurrent neural networks;Interference;Speech enhancement;Linguistics;Linear programming;Noise measurement","feature extraction;learning (artificial intelligence);neural nets;recurrent neural nets;speech enhancement;speech recognition","disentangled representations;interpretable representations;monophonic variety noisy conditions;speech enhancement models;noisy speech features;clean speech features;sequence data multiscale information;speech signal;end-to-end hierarchical model;speech data;end-to-end models;speech linguistic;background noise","","","","24","","5 Apr 2021","","","IEEE","IEEE Conferences"
"Semi-supervised deep generative models for change detection in very high resolution imagery","C. Connors; R. R. Vatsavai","Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","1063","1066","Increasing population, rapid urbanization, quest for biofuels, pollution, diseases, and adverse climate changes are some of the major drivers behind the changing surface of our planet. Timely monitoring and assessment of these changes, along with dissemination of accurate information, is important for policy makers, city planners, and humanitarian relief workers. Advances in remote sensing technologies have led to acquisition of very high resolution remote sensing imagery in the past decade. This data is highly useful for the aforementioned applications, and machine learning technology can be used to identify and quantify the changed regions. In this study we explore a semi-supervised deep generative model for change detection in very high resolution multispectral and bitemporal imagery. We constructed an auxiliary variational autoencoder that infers class labels without incurring high sample complexity costs. The resulting classifier was able to produce accurate predictions of real changes over images that appear significantly different due to environmental conditions (not real changes) while utilizing only a small set of labeled samples.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127139","Deep generative models;autoencoders","Remote sensing;Neural networks;Biological system modeling;Data models;Image resolution;Climate change;Semisupervised learning","geophysical image processing;image classification;learning (artificial intelligence);remote sensing","policy makers;humanitarian relief workers;remote sensing technologies;high resolution remote sensing imagery;machine learning technology;semisupervised deep generative model;change detection;bitemporal imagery;high sample complexity costs;high resolution imagery;rapid urbanization;adverse climate changes","","2","","11","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Multi-Agent Variational Occlusion Inference Using People as Sensors","M. Itkina; Y. -J. Mun; K. Driggs-Campbell; M. J. Kochenderfer","Aeronautics and Astronautics Department, Stanford University, USA; Electrical and Computer Engineering Department, University of Illinois at Urbana-Champaign, USA; Electrical and Computer Engineering Department, University of Illinois at Urbana-Champaign, USA; Aeronautics and Astronautics Department, Stanford University, USA","2022 International Conference on Robotics and Automation (ICRA)","12 Jul 2022","2022","","","4585","4591","Autonomous vehicles must reason about spatial occlusions in urban environments to ensure safety without being overly cautious. Prior work explored occlusion inference from observed social behaviors of road agents, hence treating people as sensors. Inferring occupancy from agent behaviors is an inherently multimodal problem; a driver may behave similarly for different occupancy patterns ahead of them (e.g., a driver may move at constant speed in traffic or on an open road). Past work, however, does not account for this multimodality, thus neglecting to model this source of aleatoric uncertainty in the relationship between driver behaviors and their environment. We propose an occlusion inference method that characterizes observed behaviors of human agents as sensor measurements, and fuses them with those from a standard sensor suite. To capture the aleatoric uncertainty, we train a conditional variational autoencoder with a discrete latent space to learn a multimodal mapping from observed driver trajectories to an occupancy grid representation of the view ahead of the driver. Our method handles multi-agent scenarios, combining measurements from multiple observed drivers using evidential theory to solve the sensor fusion problem. Our approach is validated on a cluttered, real-world intersection, outperforming baselines and demonstrating real-time capable performance. Our code is available at https://github.com/sisl/MultiAgentVariationalOcclusionInferenc","","978-1-7281-9681-7","10.1109/ICRA46639.2022.9811774","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9811774","","Uncertainty;Roads;Urban areas;Sensor fusion;Sensor phenomena and characterization;Real-time systems;Cognition","","","","1","","41","IEEE","12 Jul 2022","","","IEEE","IEEE Conferences"
"Conditional Variational Capsule Network for Open Set Recognition","Y. Guo; G. Camporese; W. Yang; A. Sperduti; L. Ballan","Department of Mathematics ""Tullio Levi-Civita"", University of Padova, Italy; Department of Mathematics ""Tullio Levi-Civita"", University of Padova, Italy; National University of Defense Technology, China; Department of Mathematics ""Tullio Levi-Civita"", University of Padova, Italy; Department of Mathematics ""Tullio Levi-Civita"", University of Padova, Italy","2021 IEEE/CVF International Conference on Computer Vision (ICCV)","28 Feb 2022","2021","","","103","111","In open set recognition, a classifier has to detect unknown classes that are not known at training time. In order to recognize new categories, the classifier has to project the input samples of known classes in very compact and separated regions of the features space for discriminating samples of unknown classes. Recently proposed Capsule Networks have shown to outperform alternatives in many fields, particularly in image recognition, however they have not been fully applied yet to open-set recognition. In capsule networks, scalar neurons are replaced by capsule vectors or matrices, whose entries represent different proper-ties of objects. In our proposal, during training, capsules features of the same known class are encouraged to match a pre-defined gaussian, one for each class. To this end, we use the variational autoencoder framework, with a set of gaussian priors as the approximation for the posterior distribution. In this way, we are able to control the compactness of the features of the same class around the center of the gaussians, thus controlling the ability of the classifier in detecting samples from unknown classes. We conducted several experiments and ablation of our model, obtaining state of the art results on different datasets in the open set recognition and unknown detection tasks.","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9710093","Recognition and classification;Datasets and evaluation;Machine learning architectures and formulations;Optimization and learning methods;Transfer/Low-shot/Semi/Unsupervised Learning","Training;Computer vision;Image recognition;Computational modeling;Neurons;Probabilistic logic;Feature extraction","","","","","","34","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"Deep Neural Network Based Energy Disaggregation","T. Sirojan; B. T. Phung; E. Ambikairajah","School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, Australia; School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, Australia; School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, Australia","2018 IEEE International Conference on Smart Energy Grid Engineering (SEGE)","21 Oct 2018","2018","","","73","77","In smart electricity grids, energy disaggregation significantly contributes to better demand side management, load forecasting and energy savings via estimating appliance level energy consumption from the aggregated smart meter data. This paper proposes a deep neural network based system by combining convolutional neural networks and variational auto-encoders for energy disaggregation. Domestic Appliance-Level Electricity dataset (UK-DALE) is used along with the standard error measures such as Mean Absolute Error (MAE) and Signal Aggregate Error (SAE) in order to evaluate the proposed system performance. Test results show that the proposed system improves the state-of-the-art performance by 44% and 19% based on SAE and MAE respectively.","2575-2693","978-1-5386-6410-0","10.1109/SEGE.2018.8499441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8499441","energy disaggregation;deep learning;pattern recognition;non-intrusive load monitoring;convolutional neural networks;variational autoencoders","Microwave filters;Convolution;Neural networks;Energy consumption;Hidden Markov models;Standards;Decoding","domestic appliances;energy conservation;energy consumption;feedforward neural nets;load forecasting;power engineering computing;smart meters;smart power grids","Signal Aggregate Error;energy disaggregation;smart electricity grids;load forecasting;energy savings;appliance level energy consumption;aggregated smart meter data;deep neural network based system;convolutional neural networks;Domestic Appliance-Level Electricity dataset;UK-DALE;MAE;SAE;mean absolute error","","18","","21","","21 Oct 2018","","","IEEE","IEEE Conferences"
"Speaker Augmentation for Low Resource Speech Recognition","C. Du; K. Yu","MoE Key Lab of Artificial Intelligence SpeechLab, Shanghai Jiao Tong University, China; MoE Key Lab of Artificial Intelligence SpeechLab, Shanghai Jiao Tong University, China","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","7719","7723","Text-to-speech synthesis (TTS) has been used as a data augmentation approach for automatic speech recognition (ASR), leveraging additional texts for ASR training. However, in low resource tasks, usually only a limited number of speakers are available, leading to the lack of speaker variations in synthetic speech. In this paper, we propose a novel speaker augmentation approach which can synthesize data with sufficient speaker and text diversity. Here, an end-to-end TTS system is trained with speaker representations from a variational auto-encoder (VAE), which enables TTS to synthesize speech from unseen new speakers via sampling from the trained latent distribution. As a new type of data augmentation approach, speaker augmentation can be combined with traditional feature augmentation approaches, such as SpecAugment. Experiments on a switchboard task show that, given 50 hours of data, the proposed speaker augmentation with SpecAugment significantly reduces word error rate (WER) by 30% relative compared to the system without any data augmentation, and about 18% relative compared to the system with SpecAugment.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9053139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9053139","Low resource;speech recognition;speech synthesis;variational autoencoder","Training;Error analysis;Conferences;Switches;Signal processing;Speech synthesis;Task analysis","speaker recognition;speech synthesis","low resource speech recognition;text-to-speech synthesis;data augmentation approach;automatic speech recognition;additional texts;ASR training;low resource tasks;speaker variations;synthetic speech;novel speaker augmentation approach;text diversity;end-to-end TTS system;speaker representations;unseen new speakers;time 50.0 hour","","6","","23","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Learning a Generative Motion Model From Image Sequences Based on a Latent Motion Matrix","J. Krebs; H. Delingette; N. Ayache; T. Mansi","Siemens Healthineers, Digital Technology and Innovation, Princeton, NJ, USA; Inria, Epione Team, Université Côte d’Azur, Sophia Antipolis, France; Inria, Epione Team, Université Côte d’Azur, Sophia Antipolis, France; Siemens Healthineers, Digital Technology and Innovation, Princeton, NJ, USA","IEEE Transactions on Medical Imaging","30 Apr 2021","2021","40","5","1405","1416","We propose to learn a probabilistic motion model from a sequence of images for spatio-temporal registration. Our model encodes motion in a low-dimensional probabilistic space - the motion matrix - which enables various motion analysis tasks such as simulation and interpolation of realistic motion patterns allowing for faster data acquisition and data augmentation. More precisely, the motion matrix allows to transport the recovered motion from one subject to another simulating for example a pathological motion in a healthy subject without the need for inter-subject registration. The method is based on a conditional latent variable model that is trained using amortized variational inference. This unsupervised generative model follows a novel multivariate Gaussian process prior and is applied within a temporal convolutional network which leads to a diffeomorphic motion model. Temporal consistency and generalizability is further improved by applying a temporal dropout training scheme. Applied to cardiac cine-MRI sequences, we show improved registration accuracy and spatio-temporally smoother deformations compared to three state-of-the-art registration algorithms. Besides, we demonstrate the model's applicability for motion analysis, simulation and super-resolution by an improved motion reconstruction from sequences with missing frames compared to linear and cubic interpolation.","1558-254X","","10.1109/TMI.2021.3056531","French Government, through the 3IA Côte d’Azur Investments in the Future Project; National Research Agency (ANR)(grant numbers:ANR-19-P3IA-0002,AAP Santé 06 2017-260); DGA-DSH; Inria Sophia Antipolis-Méditerranée, NEF Computation Cluster; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9344838","Motion model;deformable registration;conditional variational autoencoder;Gaussian process;latent variable model;motion interpolation;motion simulation;tracking","Strain;Deformable models;Probabilistic logic;Tracking;Image sequences;Gaussian processes;Data models","biomedical MRI;cardiology;data acquisition;Gaussian processes;image motion analysis;image reconstruction;image registration;image sequences;interpolation;learning (artificial intelligence);medical image processing;motion estimation;spatiotemporal phenomena","diffeomorphic motion model;generalizability;temporal dropout training scheme;cine-MRI sequences;registration accuracy;state-of-the-art registration algorithms;improved motion reconstruction;generative motion model;image sequences;latent motion matrix;probabilistic motion model;spatio-temporal registration;low-dimensional probabilistic space;motion analysis tasks;interpolation;realistic motion patterns;faster data acquisition;data augmentation;recovered motion;pathological motion;healthy subject;inter-subject registration;conditional latent variable model;unsupervised generative model;temporal convolutional network","Algorithms;Image Processing, Computer-Assisted;Magnetic Resonance Imaging;Magnetic Resonance Imaging, Cine;Motion","1","","47","IEEE","2 Feb 2021","","","IEEE","IEEE Journals"
"A Study on New Product Recommendation Using Multi-Label CVAE for Fresh Flowers","A. Kitasato; G. Kumoi; M. Goto","Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Japan; School of Creative Science and Engineering, Waseda University, Tokyo, Japan; School of Creative Science and Engineering, Waseda University, Tokyo, Japan","2021 IEEE 12th International Workshop on Computational Intelligence and Applications (IWCIA)","30 Nov 2021","2021","","","1","7","In recent years, it has become very popular to use purchase history data on e-commerce sites for marketing measures to increase sales. Under such a situation, this paper considers measures using the purchase history data of a company providing delivering services of fresh flower products through an e-commerce site. This site deals mainly with fresh flowers, and the majority of items are purchased for gifts. The demands of flower gifts are usually strongly related with certain events, such as birthday, Mother’s day, opening celebration, etc. Since each customer often makes purchase only at certain event when purchasing a flower gift, and it is important to encourage them to make purchases at other events from marketing viewpoint. In addition, the appearance of fresh flowers is important, so product recommendation with product images is necessary. It is relatively easy to develop floral gifts because they consist of certain patterns such as types of fresh flowers and shapes such as bouquets. However, there is no development of product which quantitatively uses purchase history information, The purpose of this research is, therefore, to generate product images that are preferred by customers in another event, considering the characteristics of product images purchased in individual event, where it is also possible to create new product images that are not contained in existing items. The proposed model is based on Conditional Variational Auto Encoader (CVAE) and can generate image outputs by inputting product images as multi-labels of events and attributes such as age and gender of customers that greatly affect product selection. Then, after learning a generator model, we consider to analyze what kinds of new products a customer with certain attributes who purchased at certain event would newly prefer at other events by changing the labels. Furthermore, in this study, we demonstrate the validity of the model by analyzing an actual data set.","1883-3977","978-1-6654-4425-5","10.1109/IWCIA52852.2021.9626021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9626021","Conditional Variational Autoencoder;Fresh Flower;Image Generation","Analytical models;Shape;Image synthesis;Conferences;Computational modeling;Generators;Data models","consumer behaviour;electronic commerce;marketing;purchasing;retail data processing","new product recommendation;multilabel CVAE;fresh flowers;purchase history data;e-commerce site;fresh flower products;flower gift;product images;purchase history information;product selection","","","","14","","30 Nov 2021","","","IEEE","IEEE Conferences"
"Transfer Learning-aided Fault Detection for Traction Drive Systems of High-Speed Trains","C. Cheng; X. Li; P. Xie; X. Yang","Changchun University of Technology, 177552 Changchun, China; Changchun University of Technology, 177552 Changchun, Jilin Province, China; , Changchun, Jilin Province, China; , Jiangmen, Guangdong Province, China","IEEE Transactions on Artificial Intelligence","","2022","PP","99","1","1","Long-term operation may lead to performance degradation of the traction drive systems. It will naturally increase the difficulty of fault detection (FD). To ensure the safe and stable operation of the traction drive system, datadriven FD has received considerable attention, especially deep learning methods. By exploiting the idea of transfer learning, this paper proposes a new FD method for traction converter faults in traction drive systems of high-speed trains. Its structure consists of a federal neural network based on a variational auto-encoder (VAE). The significant advantages of the proposed FD method based on transfer learning are summarized as follows: (1) FD is still valid for the systems with performance degradation. (2) It can also realize the FD function even if the physical model and related parameters are not provided. (3) The proposed framework can adaptively adjust the model parameters by storing and reusing the prior knowledge in the neural network. Finally, the effectiveness of proposed method is demonstrated through the platform of traction drive control system (TDCS).","2691-4581","","10.1109/TAI.2022.3177387","Department of Science and Technology of Jilin Province(grant numbers:20200401127GX); China Scholarship Council(grant numbers:202008440198); National Natural Science Foundation of China(grant numbers:61903047,U20A20186); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9781336","Fault detection;transfer learning;performance degradation;variational autoencoder;federal neural network","Degradation;Transfer learning;Neural networks;Artificial intelligence;Circuit faults;Gaussian distribution;Fault detection","","","","","","","IEEE","24 May 2022","","","IEEE","IEEE Early Access Articles"
"Long-short Memory with Feature Representation by Latent-variable Model for Industrial Soft Sensor","L. Kong; C. Yang; W. Wang","Zhejiang University NGICS Platform College of Control Science and Engineering, Zhejiang University, Hangzhou, China; Zhejiang University NGICS Platform College of Control Science and Engineering, Zhejiang University, Hangzhou, China; Zhejiang University NGICS Platform College of Control Science and Engineering, Zhejiang University, Hangzhou, China","2021 China Automation Congress (CAC)","14 Mar 2022","2021","","","1780","1784","In modern industry, soft sensor of quality variables is essential for the safety, stability, and optimization of the processes. However, it is very hard to construct accurate soft sensor models in the horrible industrial environment. Firstly, the complex nonlinearity and variability are widespread in industrial process data. In order to extract useful information efficiently, feature representation is needed. As a probabilistic latent-variable model, variational auto-encoder (VAE) can map the observed data to the latent variable space and represent features in data robustly. Hence, the VAE is used as a feature extractor in this article. In order to solve KL vanishing in the standard VAE, a weighted VAE is developed to control the process of training. Besides, dynamic feature is also an important characteristic that should be considered in the process industry. To capture the temporal dependence in the time series, a long-short memory is utilized in this article, which can deal with the data in sequence and is used as a regressor. Finally, a long-short memory with feature representation by latent-variable model is proposed, which takes into account the nonlinearity, dynamics, and variability simultaneously. In order to prove the feasibility of the designed method, experiments were carried out on the real blast furnace ironmaking process. Through comparison with other methods, it is proved that this model can improve the prediction accuracy.","2688-0938","978-1-6654-2647-3","10.1109/CAC53003.2021.9728032","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9728032","Long short-term memory;weighted variational autoencoder;feature representation;soft sensor;industrial process","Industries;Training;Soft sensors;Time series analysis;Process control;Predictive models;Feature extraction","","","","","","18","IEEE","14 Mar 2022","","","IEEE","IEEE Conferences"
"A Hybrid Deep Learning Model for Water Supply Time Series Data Prediction","J. Teng; K. Sheng","School of Computer and Information, Hefei University of Technology, Hefei, China; School of Computer and Information, Hefei University of Technology, Hefei, China","2022 7th International Conference on Computer and Communication Systems (ICCCS)","15 Aug 2022","2022","","","180","186","With the development of intelligent water services, accurate prediction of water supply data plays a vital role in water supply safety and security. At the same time, it is important to ensure ecological water, water for people's livelihood and industrial water. Therefore, a hybrid multi-step prediction model called VMD-ConvGRUAE is proposed. By combining variational modal decomposition (VMD) and deep autoencoder model based on convolutional long short-term memory (ConvLSTM) and gated recurrent unit (GRU) for water supply prediction. In the proposed VMD-ConvGRUAE model, VMD is used to decompose the original water supply data into modal components with different trends and then combine the deep encoder-decoder network structure to predict the component data, and add the predicted results of each component to obtain the predicted value. Experiments on real water supply datasets, using the MAE evaluation metrics as an example, compared with several other baseline methods, the VMD-ConvGRUAE model has a 4.34% to 65.27% improvement in prediction accuracy, which verifies the validity of the model.","","978-1-6654-5060-7","10.1109/ICCCS55155.2022.9846132","Research and Development; Manufacturing Institute; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9846132","smart water;water supply prediction;variational modal decomposition;encoder-decoder;time series","Training;Biological system modeling;Computational modeling;Time series analysis;Predictive models;Market research;Feature extraction","learning (artificial intelligence);neural nets;recurrent neural nets;time series;water supply","hybrid deep learning model;water supply time series data prediction;intelligent water services;water supply safety;security;ecological water;industrial water;hybrid multistep prediction model;deep autoencoder model;water supply prediction;VMD-ConvGRUAE model;original water supply data;deep encoder-decoder network structure;component data;water supply datasets;prediction accuracy","","","","20","IEEE","15 Aug 2022","","","IEEE","IEEE Conferences"
"Truly Unsupervised Acoustic Word Embeddings Using Weak Top-down Constraints in Encoder-decoder Models","H. Kamper","E&E Engineering, Stellenbosch University, South Africa","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","6535","3539","We investigate unsupervised models that can map a variable-duration speech segment to a fixed-dimensional representation. In settings where unlabelled speech is the only available resource, such acoustic word embeddings can form the basis for ""zero-resource"" speech search, discovery and indexing systems. Most existing unsupervised embedding methods still use some supervision, such as word or phoneme boundaries. Here we propose the encoder-decoder correspondence autoencoder (EncDec-CAE), which, instead of true word segments, uses automatically discovered segments: an unsupervised term discovery system finds pairs of words of the same unknown type, and the EncDec-CAE is trained to reconstruct one word given the other as input. We compare it to a standard encoder-decoder autoencoder (AE), a variational AE with a prior over its latent embedding, and downsampling. EncDec-CAE outperforms its closest competitor by 29% relative in average precision on two languages in a word discrimination task.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683639","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683639","Acoustic word embeddings;zero-resource speech processing;unsupervised learning;query-by-example","Acoustics;Decoding;Training;Task analysis;Standards;Speech processing;Recurrent neural networks","decoding;speech processing;speech recognition;unsupervised learning","standard encoder-decoder autoencoder;latent embedding;EncDec-CAE;word discrimination task;weak top-down constraints;encoder-decoder models;unsupervised models;variable-duration speech segment;fixed-dimensional representation;unlabelled speech;speech search;indexing systems;encoder-decoder correspondence autoencoder;word segments;unsupervised term discovery system;unsupervised embedding methods;unsupervised acoustic word embeddings;zero-resource speech search","","15","","40","","17 Apr 2019","","","IEEE","IEEE Conferences"
"A Semi-supervised Generalized VAE Framework for Abnormality Detection using One-Class Classification","R. Sharma; S. Mashkaria; S. P. Awate","IITB-Monash Research Academy, Mumbai; Computer Science and Engineering Department, Indian Institute of Technology Bombay, Mumbai; Computer Science and Engineering Department, Indian Institute of Technology Bombay, Mumbai","2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)","15 Feb 2022","2022","","","1302","1310","Abnormality detection is a one-class classification (OCC) problem where the methods learn either a generative model of the inlier class (e.g., in the variants of kernel principal component analysis) or a decision boundary to encapsulate the inlier class (e.g., in the one-class variants of the support vector machine). Learning schemes for OCC typically train on data solely from the inlier class, but some recent OCC methods have proposed semi-supervised extensions that also leverage a small amount of training data from outlier classes. Other recent methods extend existing principles to employ deep neural network (DNN) models for learning (for the inlier class) either latent-space distributions or autoencoders, but not both. We propose a semi-supervised variational formulation, leveraging generalized-Gaussian (GG) models leading to data-adaptive, robust, and uncertainty-aware distribution modeling in both latent space and image space. We propose a reparameterization for sampling from the latent-space GG to enable backpropagation-based optimization. Results on many publicly available real-world image sets and a synthetic image set show the benefits of our method over existing methods.","2642-9381","978-1-6654-0915-5","10.1109/WACV51458.2022.00137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9706660","Object Detection/Recognition/Categorization Deep Learning -> Neural Generative Models;Autoencoders;GANs;Medical Imaging/Imaging for Bioinformatics/Biological and Cell Microscopy","Training;Support vector machines;Deep learning;Computer vision;Shape;Neural networks;Training data","backpropagation;learning (artificial intelligence);neural nets;pattern classification;principal component analysis;support vector machines","outlier classes;deep neural network models;inlier class;semisupervised variational formulation;generalized-Gaussian models;semisupervised generalized VAE framework;abnormality detection;one-class classification problem;methods learn;one-class variants;recent OCC methods;semisupervised extensions","","","","34","IEEE","15 Feb 2022","","","IEEE","IEEE Conferences"
"Artificial Neural Network Based Test Escape Screening Using Generative Model","M. Shintani; M. Inoue; Y. Nakamura","Graduate School of Science and Technology, Nara Institute of Science and Technology, Ikoma, 8916-5 Takayama-cho, Japan; Graduate School of Science and Technology, Nara Institute of Science and Technology, Ikoma, 8916-5 Takayama-cho, Japan; Renesas Electronics Corporation, Tokyo, 5-20-1 Josuihon-cho Kodaira-shi, Japan","2018 IEEE International Test Conference (ITC)","24 Jan 2019","2018","","","1","8","In test of large scale integration (LSI) circuit, test escape is always regarded as a critical issue since significant cost is imposed to manufacturing cost. In this paper, we propose a novel outlier screening method for test escape. The proposed method exploits variational autoencoder (VAE) that is widely used to design complex generative model in artificial neural network field. While a typical autoencoder (AE) simply extracts features of training data, the VAE does it as probability distribution, and thus it can avoid potential risk of overfitting by using the probability distributions as a regularizer. Moreover, the proposed method effectively detects test escapes by utilizing the probability distributions as likelihood function of good chips. Through experiments using an industrial production test data, we demonstrate that the proposed method detects test escapes more than approximately 8.5 times as compared to that using a conventional AE-based method.","2378-2250","978-1-5386-8382-8","10.1109/TEST.2018.8624821","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8624821","","Feature extraction;Training data;Neural networks;Large scale integration;Training;Neurons;Production","electronic engineering computing;fault diagnosis;feature extraction;integrated circuit testing;large scale integration;neural nets;probability;production testing","probability distribution;industrial production test data;artificial neural network based test escape screening;complex generative model;large scale integration circuit;outlier screening method;LSI circuit;variational autoencoder;VAE;probability distributions;feature extraction","","5","","39","","24 Jan 2019","","","IEEE","IEEE Conferences"
"Social Influence Prediction with Train and Test Time Augmentation for Graph Neural Networks","H. Bo; R. McConville; J. Hong; W. Liu","Department of Computer Science, University of Bristol, Bristol, UK; Department of Engineering Mathematics, University of Bristol, Bristol, UK; Department of Computer Science and Creative Technologies, University of the West of England, Bristol, UK; Department of Engineering Mathematics, University of Bristol, Bristol, UK","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","8","Data augmentation has been widely used in machine learning for natural language processing and computer vision tasks to improve model performance. However, little research has studied data augmentation on graph neural networks, particularly using augmentation at both train- and test-time. Inspired by the success of augmentation in other domains, we have designed a method for social influence prediction using graph neural networks with train- and test-time augmentation, which can effectively generate multiple augmented graphs for social networks by utilising a variational graph autoencoder in both scenarios. We have evaluated the performance of our method on predicting user influence on multiple social network datasets. Our experimental results show that our end-to-end approach, which jointly trains a graph autoencoder and social influence behaviour classification network, can outperform state-of-the-art approaches, demonstrating the effectiveness of train-and test-time augmentation on graph neural networks for social influence prediction. We observe that this is particularly effective on smaller graphs.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533437","graph neural networks;social network analysis;social influence analysis;augmentation","Training;Computer vision;Social networking (online);Computational modeling;Prediction methods;Graph neural networks;Natural language processing","computer vision;graph theory;learning (artificial intelligence);natural language processing;neural nets;social networking (online)","social influence prediction;test time augmentation;graph neural networks;data augmentation;natural language processing;computer vision tasks;test-time augmentation;multiple augmented graphs;social networks;variational graph autoencoder;multiple social network datasets","","2","","31","IEEE","20 Sep 2021","","","IEEE","IEEE Conferences"
"Unsupervised Doppler Radar Based Activity Recognition for e-Healthcare","Y. Karayaneva; S. Sharifzadeh; W. Li; Y. Jing; B. Tan","Faculty of Engineering, Environment and Computing, Coventry University, Coventry, U.K.; Faculty of Engineering, Environment and Computing, Coventry University, Coventry, U.K.; Department of Security and Crime Science, University College London, London, U.K.; Faculty of Engineering, Environment and Computing, Coventry University, Coventry, U.K.; Faculty of Informaon Technology and Communicaon Sciences, Tampere University, Tampere, Finland","IEEE Access","29 Apr 2021","2021","9","","62984","63001","Passive radio frequency (RF) sensing and monitoring of human daily activities in elderly care homes is an emerging topic. Micro-Doppler radars are an appealing solution considering their non-intrusiveness, deep penetration, and high-distance range. Unsupervised activity recognition using Doppler radar data has not received attention, in spite of its importance in case of unlabelled or poorly labelled activities in real scenarios. This study proposes two unsupervised feature extraction methods for the purpose of human activity monitoring using Doppler-streams. These include a local Discrete Cosine Transform (DCT)-based feature extraction method and a local entropy-based feature extraction method. In addition, a novel application of Convolutional Variational Autoencoder (CVAE) feature extraction is employed for the first time for Doppler radar data. The three feature extraction architectures are compared with the previously used Convolutional Autoencoder (CAE) and linear feature extraction based on Principal Component Analysis (PCA) and 2DPCA. Unsupervised clustering is performed using K-Means and K-Medoids. The results show the superiority of DCT-based method, entropy-based method, and CVAE features compared to CAE, PCA, and 2DPCA, with more than 5%-20% average accuracy. In regards to computation time, the two proposed methods are noticeably much faster than the existing CVAE. Furthermore, for high-dimensional data visualisation, three manifold learning techniques are considered. The methods are compared for the projection of raw data as well as the encoded CVAE features. All three methods show an improved visualisation ability when applied to the encoded CVAE features.","2169-3536","","10.1109/ACCESS.2021.3074088","DataDriven Research Innovation DDRI Coventry University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9406586","Activity recognition;data visualization;Doppler radar;health and safety;DCT analysis;unsupervised learning","Feature extraction;Doppler radar;Principal component analysis;Data visualization;Activity recognition;Discrete cosine transforms;Unsupervised learning","convolutional neural nets;discrete cosine transforms;Doppler radar;entropy;feature extraction;geriatrics;gesture recognition;health care;medical signal processing;pattern clustering;principal component analysis;radar signal processing;unsupervised learning","unsupervised Doppler radar based activity recognition;human daily activities;elderly care homes;MicroDoppler radars;high-distance range;unsupervised activity recognition;unlabelled labelled activities;unsupervised feature extraction methods;human activity monitoring;local entropy-based feature extraction method;feature extraction architectures;linear feature extraction;2DPCA;unsupervised clustering;DCT-based method;entropy-based method;high-dimensional data visualisation;encoded CVAE features;local discrete cosine transform-based feature extraction method;convolutional variational autoencoder feature extraction;e-healthcare","","1","","70","CCBY","19 Apr 2021","","","IEEE","IEEE Journals"
"Dreaming: Model-based Reinforcement Learning by Latent Imagination without Reconstruction","M. Okada; T. Taniguchi","Digitan & AI Technology Center, Technology Division, Panasonic Corporation, Japan; College of Information Science and Engineering, Ritsumeikan University, Japan","2021 IEEE International Conference on Robotics and Automation (ICRA)","18 Oct 2021","2021","","","4209","4215","In the present paper, we propose a decoder-free extension of Dreamer, a leading model-based reinforcement learning (MBRL) method from pixels. Dreamer is a sample- and cost-efficient solution to robot learning, as it is used to train latent state-space models based on a variational autoencoder and to conduct policy optimization by latent trajectory imagination. However, this autoencoding based approach often causes object vanishing, in which the autoencoder fails to perceives key objects for solving control tasks, and thus significantly limiting Dreamer's potential. This work aims to relieve this Dreamer's bottleneck and enhance its performance by means of removing the decoder. For this purpose, we firstly derive a likelihood- free and InfoMax objective of contrastive learning from the evidence lower bound of Dreamer. Secondly, we incorporate two components, (i) independent linear dynamics and (ii) the random crop data augmentation, to the learning scheme so as to improve the training performance. In comparison to Dreamer and other recent model-free reinforcement learning methods, our newly devised Dreamer with InfoMax and without generative decoder (Dreaming) achieves the best scores on 5 difficult simulated robotics tasks, in which Dreamer suffers from object vanishing.","2577-087X","978-1-7281-9077-8","10.1109/ICRA48506.2021.9560734","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9560734","","Training;Service robots;Crops;Reinforcement learning;Robot learning;Decoding;Trajectory","image segmentation;neural nets;reinforcement learning;robot programming","decoder-free extension;robot learning;latent state-space models;variational autoencoder;latent trajectory imagination;object vanishing;Dreamer;model free reinforcement learning method;InfoMax;Dreaming;image region","","1","","37","IEEE","18 Oct 2021","","","IEEE","IEEE Conferences"
"A Deep Embedded Framework for Spitzoid Neoplasm Classification Using DNA Methylation Data","R. Del Amor; A. Colomer; C. Monteagudo; M. J. G. ‡; J. L. García-Giménez; V. Naranjo","Instituto de Investigación e Innovación en Bioingeniería, I3B, Universitat Politècnica de València, Valencia, Spain; Instituto de Investigación e Innovación en Bioingeniería, I3B, Universitat Politècnica de València, Valencia, Spain; Pathology Department, Hospital Clínico Universitario de Valencia, Universidad de Valencia, Valencia, Spain; Consorcio Centro de Investigación Biomédica en Red, Instituto de Salud Carlos III, Instituto de Investigación Sanitaria INCLIVA, Valencia, Spain; Bioinformatics and Computational Diagnostics Unit EpiDisease S.L., Valencia, Spain; Instituto de Investigación e Innovación en Bioingeniería, I3B, Universitat Politècnica de València, Valencia, Spain","2021 29th European Signal Processing Conference (EUSIPCO)","8 Dec 2021","2021","","","1271","1275","Spitzoid melanocytic tumors (SMT) are a group of neoplasms that represent a formidable diagnostic challenge for dermatopathologists. DNA methylation (DNAm) is a well-defined epigenetic factor that has an important role in the development of these lesions. In this work, we propose different deep-learning-based approaches to address the Spitzoid neoplasms detection from DNAm. We use an autoencoder and a variational autoencoder for dimensionality reduction with a subsequently supervised classification. Additionally, we present a deep embedded refined clustering algorithm able to optimize the latent space at the same time that the non-supervised classification task is performed. This novel approach in DNAm supposes a step forward in the SMT detection as suggest the obtained results $\mathbf{(acc =0.9)}$. Additionally, making use of the resulting model, we present a subspace-prototypical-based approach for the prognostic prediction of uncertain malignant potential samples, which is nowadays the hottest open area in SMT detection.","2076-1465","978-9-0827-9706-0","10.23919/EUSIPCO54536.2021.9616137","European Union's Framework Programme for Research and Innovation(grant numbers:860627); Generalitat Valenciana (GVA)(grant numbers:A100); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616137","Dimensionality reduction;deep embedded refined clustering;DNA methylation;Spitzoid neoplasms","Signal processing algorithms;DNA;Signal processing;Predictive models;Prediction algorithms;Classification algorithms;Lesions","biology computing;cancer;convolutional neural nets;deep learning (artificial intelligence);DNA;genetics;medical computing;pattern classification;pattern clustering;tumours","epigenetic factor;lesions;Spitzoid neoplasms detection;DNAm;variational autoencoder;dimensionality reduction;subsequently supervised classification;deep embedded refined clustering algorithm;latent space;nonsupervised classification task;SMT detection;subspace-prototypical-based approach;deep embedded framework;Spitzoid neoplasm classification;DNA methylation data;Spitzoid melanocytic tumors;dermatopathologists","","","","23","","8 Dec 2021","","","IEEE","IEEE Conferences"
"Deep Learning Models for Strawberry Yield and Price Forecasting Using Satellite Images","M. S. Gastli; L. Nassar; F. Karray","Department of Electrical & Computer Engineering, University of Waterloo, Waterloo, Canada; Department of Electrical & Computer Engineering, University of Waterloo, Waterloo, Canada; Department of Electrical & Computer Engineering, University of Waterloo, Waterloo, Canada","2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","6 Jan 2022","2021","","","1790","1796","Forecasting crop yields and prices is crucial for both global food security and providing farmers with valuable information to avoid a price crash. This work proposes a hybrid deep learning model that uses satellite images to forecast strawberry yield along with farmers’ prices, applied in three counties in California. For tractability, a dimensionality reduction technique is applied by converting the images to histograms representing the pixel frequency. The models tested are Convolutional Neural Network (CNN), Variational AutoEncoder (VAE), CNN-Long Short-Term Memory (CNN-LSTM), Stacked AutoEncoder (SAE), and a voting ensemble of CNN-LSTM and SAE. It is found that the proposed voting ensemble of CNN-LSTM and SAE is the best at forecasting the daily strawberry yields and prices in all three counties. Based on an aggregated performance measure (AGM), the voting ensemble model outperforms the models suggested in literature with up to 70% forecasting improvement compared to the CNN model and up to 22% improvement over the CNN-LSTM model.","2577-1655","978-1-6654-4207-7","10.1109/SMC52423.2021.9658728","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9658728","","Deep learning;Dimensionality reduction;Histograms;Satellites;Time series analysis;Crops;Predictive models","convolutional neural nets;crops;feature extraction;learning (artificial intelligence);recurrent neural nets","strawberry yield;price forecasting;satellite images;forecasting crop yields;global food security;hybrid deep learning model;dimensionality reduction technique;pixel frequency;convolutional neural network;CNN-long short-term memory;SAE;daily strawberry yields;voting ensemble model;forecasting improvement;CNN model;CNN-LSTM model;variational autoencoder","","","","31","IEEE","6 Jan 2022","","","IEEE","IEEE Conferences"
"Disentangling Latent Hands for Image Synthesis and Pose Estimation","L. Yang; A. Yao","University of Bonn, Germany; National University of Singapore, Singapore","2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","9869","9878","Hand image synthesis and pose estimation from RGB images are both highly challenging tasks due to the large discrepancy between factors of variation ranging from image background content to camera viewpoint. To better analyze these factors of variation, we propose the use of disentangled representations and a disentangled variational autoencoder (dVAE) that allows for specific sampling and inference of these factors. The derived objective from the variational lower bound as well as the proposed training strategy are highly flexible, allowing us to handle cross-modal encoders and decoders as well as semi-supervised learning scenarios. Experiments show that our dVAE can synthesize highly realistic images of the hand specifiable by both pose and image background content and also estimate 3D hand poses from RGB images with accuracy competitive with state-of-the-art on two public benchmarks.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.01011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8953433","Face;Gesture;and Body Pose;Image and Video Synthesis; Representation Learning","","cameras;image coding;image colour analysis;image representation;image sampling;pose estimation;stereo image processing;supervised learning","semisupervised learning;realistic images;image background;RGB images;pose estimation;hand image synthesis;camera viewpoint;disentangled representations;disentangled variational autoencoder","","45","","40","","9 Jan 2020","","","IEEE","IEEE Conferences"
"Anomaly Detection Based on Zero-Shot Outlier Synthesis and Hierarchical Feature Distillation","A. Ramírez Rivera; A. Khan; I. E. I. Bekkouch; T. S. Sheikh","Institute of Computing, University of Campinas, Campinas, Brazil; Institute of Data Science and Artificial Intelligence, Innopolis University, Innopolis, Russia; Institute of Data Science and Artificial Intelligence, Innopolis University, Innopolis, Russia; Institute of Data Science and Artificial Intelligence, Innopolis University, Innopolis, Russia","IEEE Transactions on Neural Networks and Learning Systems","5 Jan 2022","2022","33","1","281","291","Anomaly detection suffers from unbalanced data since anomalies are quite rare. Synthetically generated anomalies are a solution to such ill or not fully defined data. However, synthesis requires an expressive representation to guarantee the quality of the generated data. In this article, we propose a two-level hierarchical latent space representation that distills inliers’ feature descriptors [through autoencoders (AEs)] into more robust representations based on a variational family of distributions (through a variational AE) for zero-shot anomaly generation. From the learned latent distributions, we select those that lie on the outskirts of the training data as synthetic-outlier generators. Also, we synthesize from them, i.e., generate negative samples without seen them before, to train binary classifiers. We found that the use of the proposed hierarchical structure for feature distillation and fusion creates robust and general representations that allow us to synthesize pseudo outlier samples. Also, in turn, train robust binary classifiers for true outlier detection (without the need for actual outliers during training). We demonstrate the performance of our proposal on several benchmarks for anomaly detection.","2162-2388","","10.1109/TNNLS.2020.3027667","Brazilian National Council for Scientific and Technological Development (CNPq)(grant numbers:307425/2017-7); São Paulo Research Foundation (FAPESP)(grant numbers:2019/07257-3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9228891","Feature extraction;unsupervised learning","Feature extraction;Anomaly detection;Probabilistic logic;Training;Data models;Uncertainty;Task analysis","feature extraction;learning (artificial intelligence);neural nets;pattern classification","hierarchical feature distillation;anomaly detection;unbalanced data;two-level hierarchical latent space representation;robust representations;zero-shot anomaly generation;learned latent distributions;training data;synthetic-outlier generators;hierarchical structure;pseudooutlier samples;train robust binary classifiers;outlier detection;zero-shot outlier synthesis;autoencoders;variational AE","","6","","83","IEEE","16 Oct 2020","","","IEEE","IEEE Journals"
"Model-Induced Generalization Error Bound for Information-Theoretic Representation Learning in Source-Data-Free Unsupervised Domain Adaptation","B. Yang; H. -W. Yeh; T. Harada; P. C. Yuen","Department of Computer Science, Hong Kong Baptist University, Hong Kong; Machine Intelligence Laboratory, The University of Tokyo, Tokyo, Japan; RIKEN Center for Advanced Intelligence Project (AIP), Tokyo, Japan; Department of Computer Science, Hong Kong Baptist University, Hong Kong","IEEE Transactions on Image Processing","9 Dec 2021","2022","31","","419","432","Many unsupervised domain adaptation (UDA) methods have been developed and have achieved promising results in various pattern recognition tasks. However, most existing methods assume that raw source data are available in the target domain when transferring knowledge from the source to the target domain. Due to the emerging regulations on data privacy, the availability of source data cannot be guaranteed when applying UDA methods in a new domain. The lack of source data makes UDA more challenging, and most existing methods are no longer applicable. To handle this issue, this paper analyzes the cross-domain representations in source-data-free unsupervised domain adaptation (SF-UDA). A new theorem is derived to bound the target-domain prediction error using the trained source model instead of the source data. On the basis of the proposed theorem, information bottleneck theory is introduced to minimize the generalization upper bound of the target-domain prediction error, thereby achieving domain adaptation. The minimization is implemented in a variational inference framework using a newly developed latent alignment variational autoencoder (LA-VAE). The experimental results show good performance of the proposed method in several cross-dataset classification tasks without using source data. Ablation studies and feature visualization also validate the effectiveness of our method in SF-UDA.","1941-0042","","10.1109/TIP.2021.3130530","National Natural Science Foundation of China (NSFC)(grant numbers:62102098); Hong Kong Research Grants Council General Research Fund(grant numbers:RGC/HKBU12200518); Japan Science and Technology Agency (JST) Advanced Intelligence Project (AIP) Acceleration Research(grant numbers:JPMJCR20U3); Japan Society for the Promotion of Science (JSPS) KAKENHI(grant numbers:JP19H01115); Basic Research Grant (Super AI) of the Institute for AI and Beyond, The University of Tokyo, as well as the Science and Technology Planning Project of Guangdong(grant numbers:2019A050510041); Science and Technology Planning Project of Guangzhou(grant numbers:202103000034,202002020090); scholarship organized by Japan-Taiwan Exchange Association; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9640468","Unsupervised domain adaptation (UDA);information theory;representation learning","Adaptation models;Data models;Upper bound;Predictive models;Optimization;Computational modeling;Data privacy","data privacy;information theory;pattern classification;pattern recognition;unsupervised learning","model-induced generalization error bound;information-theoretic representation learning;source-data-free unsupervised domain adaptation;raw source data;data privacy;cross-domain representations;SF-UDA;target-domain prediction error;trained source model;latent alignment variational autoencoder;LA-VAE","","","","55","IEEE","7 Dec 2021","","","IEEE","IEEE Journals"
"Hybrid Machine Learning for Anomaly Detection in Industrial Time-Series Measurement Data","A. Terbuch; P. O’Leary; P. Auer","Chair of Automation, University of Leoben, Leoben, Austria; Chair of Automation, University of Leoben, Leoben, Austria; Chair of Information Technology, University of Leoben, Leoben, Austria","2022 IEEE International Instrumentation and Measurement Technology Conference (I2MTC)","30 Jun 2022","2022","","","1","6","This paper presents a parallel hybrid machine learning system for the identification of anomalies in large sets of multivariate time-series (MVTS) measurement data. The goal is to achieve a more reliable detection of anomalies in safety relevant applications. Key performance indicators (KPI) are used as a measure for predicted possible sources of error. Whereas, a long short-term memory (LSTM-VAE) variational autoencoder is used to model the system behavior; the variational portion ensures the statistical uncertainty of the data is taken into account during training of the network. Combined in a parallel hybrid manner this provides a more reliable anomaly detection. The proposed structure is validated with a case study relating to a ground improvement process for building foundations. The data consists of large sets of real-time multi-variate time-series sensor data, emanating from the instrumented drilling rig. The performance of the LSTM-VAE is optimized using a genetic algorithm to select the optimal values for the hyperparameters. The implemented framework will also support future research into hybrid learning systems applied to real-time machine data analysis.","2642-2077","978-1-6654-8360-5","10.1109/I2MTC48687.2022.9806663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9806663","Hybrid Learning;Outlier Detection;Time Series","Training;Uncertainty;Key performance indicator;Machine learning;Real-time systems;Loss measurement;Behavioral sciences","data analysis;genetic algorithms;learning (artificial intelligence);oil drilling;production engineering computing;recurrent neural nets;sensor fusion;time series","industrial time-series measurement data;parallel hybrid machine learning system;multivariate time-series measurement data;key performance indicators;short-term memory;LSTM-VAE;system behavior;anomaly detection;multivariate time-series sensor data;KPI;long short-term memory;variational autoencoder;genetic algorithm;statistical uncertainty;drilling rig","","","","27","IEEE","30 Jun 2022","","","IEEE","IEEE Conferences"
"Disentangling Correlated Speaker and Noise for Speech Synthesis via Data Augmentation and Adversarial Factorization","W. -N. Hsu; Y. Zhang; R. J. Weiss; Y. -A. Chung; Y. Wang; Y. Wu; J. Glass",Massachusetts Institute of Technology; Google; Google; Massachusetts Institute of Technology; Google; Google; Massachusetts Institute of Technology,"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","5901","5905","To leverage crowd-sourced data to train multi-speaker text-to-speech (TTS) models that can synthesize clean speech for all speakers, it is essential to learn disentangled representations which can independently control the speaker identity and background noise in generated signals. However, learning such representations can be challenging, due to the lack of labels describing the recording conditions of each training example, and the fact that speakers and recording conditions are often correlated, e.g. since users often make many recordings using the same equipment. This paper proposes three components to address this problem by: (1) formulating a conditional generative model with factorized latent variables, (2) using data augmentation to add noise that is not correlated with speaker identity and whose label is known during training, and (3) using adversarial factorization to improve disentanglement. Experimental results demonstrate that the proposed method can disentangle speaker and noise attributes even if they are correlated in the training data, and can be used to consistently synthesize clean speech for all speakers. Ablation studies verify the importance of each proposed component.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683561","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683561","text-to-speech synthesis;variational autoencoder;adversarial training;data augmentation","","learning (artificial intelligence);speaker recognition;speech synthesis","clean speech;correlated speaker;speech synthesis;multispeaker text-to-speech models;disentangled representations;speaker identity;background noise;generated signals;recording conditions;conditional generative model;factorized latent variables;disentanglement;training data;crowd-sourced data;data augmentation;adversarial factorization","","31","","30","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Fault Classification in High-Dimensional Complex Processes Using Semi-Supervised Deep Convolutional Generative Models","T. Ko; H. Kim","Department of Industrial and Systems Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Industrial and Systems Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea","IEEE Transactions on Industrial Informatics","22 Jan 2020","2020","16","4","2868","2877","In complex industrial processes, process fault detection and classification constitute an important task for reducing production costs and improving product quality. Most existing methods for fault classification assume that sufficient labeled data are available for training. However, label acquisition is costly and laborious in practice, whereas abundant unlabeled data are often available. To make effective use of a large amount of unlabeled data for fault classification, we propose in this article a new approach using semi-supervised deep generative models, allowing the complex relationship between high-dimensional process data and the process status to be modeled. In particular, to consider the temporal correlation and intervariable correlation in multivariate time series process data collected from multiple sensors, we propose two semi-supervised deep generative models incorporating convolutional neural networks. The proposed models are assessed on data from the Tennessee Eastman benchmark process. The results demonstrate the superior performances of the proposed models compared with competing methods.","1941-0050","","10.1109/TII.2019.2941486","National Research Foundation of Korea; Korea Government (MSIT)(grant numbers:2018R1C1B6004511); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8839597","Convolutional auxiliary deep generative model;multivariate time series;semi-supervised convolutional variational autoencoder;Tennessee Eastman process;unlabeled data","Data models;Time series analysis;Feature extraction;Sensors;Correlation;Task analysis","convolutional neural nets;fault diagnosis;learning (artificial intelligence);pattern classification;process monitoring;production engineering computing;time series","fault classification;high-dimensional complex processes;semisupervised deep convolutional generative models;complex industrial processes;process fault detection;production costs;improving product quality;sufficient labeled data;label acquisition;abundant unlabeled data;semisupervised deep generative models;complex relationship;high-dimensional process data;process status;multivariate time series process data;Tennessee Eastman benchmark process","","19","","24","IEEE","16 Sep 2019","","","IEEE","IEEE Journals"
"Unsupervised Anomaly Detection in IoT Systems for Smart Cities","Y. Guo; T. Ji; Q. Wang; L. Yu; G. Min; P. Li","Department of Electrical Engineering, Computer Science, Case Western Reserve University, Cleveland, OH, US; Department of Electrical Engineering, Computer Science, Case Western Reserve University, Cleveland, OH, US; Department of Electrical Engineering, Computer Science, Case Western Reserve University, Cleveland, OH, US; Department of Electrical Engineering, Computer Science, Case Western Reserve University, Cleveland, OH, US; Department of Mathematics, Computer Science, College of Engineering, Mathematics, Physical Sciences, University of Exeter, U.K.; Department of Electrical Engineering, Computer Science, Case Western Reserve University, Cleveland, OH, US","IEEE Transactions on Network Science and Engineering","31 Dec 2020","2020","7","4","2231","2242","Anomaly detection is critical in the Internet of Things (IoT) systems due to its wide applications for building smart cities, such as quality control in manufacturing, intrusion detection in system security, fault detection in system monitoring. Many existing schemes are problem specific and supervised approaches, which require domain knowledge and tremendous data labeling efforts. In this paper, we investigate unsupervised anomaly detection on multidimensional time series data in IoT systems, and develops a GRU-based Gaussian Mixture VAE scheme, called GGM-VAE. In particular, we employ Gated Recurrent Unit (GRU) cells to discover the correlations among time series data, and use Gaussian Mixture priors in the latent space to characterize the multimodal data. Several previous works assume simple distributions for Gaussian Mixture priors, resulting in insufficient ability to fully capture the data patterns. To overcome this issue, we design a model selection mechanism during the training process under the guidance of Bayesian Inference Criterion (BIC) to find the model which can well estimate the distribution in the Gaussian Mixture latent space. We conduct extensive simulations on four datasets and observe that our proposed scheme outperforms the state-of-the-art anomaly detection schemes and achieves up to 47.88% improvement in F1 scores on average.","2327-4697","","10.1109/TNSE.2020.3027543","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9208761","Gated Recurrent Unit (GRU);Gaussian Mixture Model (GMM);iot;unsupervised anomaly detection;Variational Autoencoder(VAE);smart cities.","Anomaly detection;Time series analysis;Image reconstruction;Training;Decoding;Internet of Things;Smart cities","Bayes methods;data handling;feature selection;Gaussian processes;Internet of Things;public administration;smart cities;time series;unsupervised learning","unsupervised anomaly detection;IoT systems;smart cities;Internet of Things systems;data labeling;multidimensional time series data;gated recurrent unit;multimodal data;GRU based Gaussian mixture VAE;GGM-VAE;model selection;Bayesian inference criterion","","12","","34","IEEE","29 Sep 2020","","","IEEE","IEEE Journals"
"Knowledge Extraction from XCSR Based on Dimensionality Reduction and Deep Generative Models","M. Tadokoro; S. Hasegawa; T. Tatsumi; H. Sato; K. Takadama","The University of Electro-Communications, Tokyo, Japan; The University of Electro-Communications, Tokyo, Japan; The University of Electro-Communications, Tokyo, Japan; The University of Electro-Communications, Tokyo, Japan; The University of Electro-Communications, Tokyo, Japan","2019 IEEE Congress on Evolutionary Computation (CEC)","8 Aug 2019","2019","","","1883","1890","This paper proposes a novel learning classifier system (LCS) framework named ELSDeCS (Encoding, Learning, Sampling, and Decoding Classifier System) which can employ any dimensionality reduction method as pre-processing of learning and has its own components for extracting interpretable rule representations. We also propose two LCSs as examples of ELSDeCS. The first is DCAXCSR2, which is a revised version of the conventional system, and the second is VAEXCSR, which employs a deep generative model for dimensionality reduction. The experimental results on a classification task of handwritten digits show that only VAEXCSR can extract useful rule representations thanks to its robustness of decoding newly generated samples.","","978-1-7281-2153-6","10.1109/CEC.2019.8790119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8790119","data mining;XCS;variational autoencoder;interpretability","Decoding;Dimensionality reduction;Task analysis;Genetic algorithms;Image reconstruction;Encoding;Classification algorithms","data mining;information retrieval;learning (artificial intelligence);pattern classification","knowledge extraction;XCSR;deep generative model;LCS;ELSDeCS;dimensionality reduction method;DCAXCSR2;VAEXCSR;learning classifier system;interpretable rule representation extraction;encoding learning sampling and decoding classifier system;data mining;handwritten digit classification","","10","","12","","8 Aug 2019","","","IEEE","IEEE Conferences"
"A Unified Federated Learning Framework for Wireless Communications: towards Privacy, Efficiency, and Security","H. Wen; Y. Wu; C. Yang; H. Duan; S. Yu","School of Computer Science and Engineering, University of Electronic Science and Technology of China, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, China; National Key Lab on Communication, University of Electronic Science and Technology of China, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, China; School of Computer Science, University of Technology Sydney, Australia","IEEE INFOCOM 2020 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)","10 Aug 2020","2020","","","653","658","Training high-quality machine learning models on distributed systems is a critical issue to achieve edge intelligence in wireless communications. Conventional data-driven machine learning approaches are infeasible due to non-IID data caused by privacy issues and the limited communication resources in wireless networks. Besides, considering the complex user identities, the training process also faces the challenges of Byzantine devices, which can inject poisoning information into models. In this paper, we propose a two-step federated learning framework, robust federated augmentation and distillation (RFA-RFD), to enable privacy-preserving, communication-efficient, and Byzantine-tolerant on-device machine learning in wireless communications. RFA is a method to tackle the problem of non-IID local data, which firstly trains local data generators on edge devices, then trains a global generator in the cloud server according to the IID dataset generated by the uploaded local generators, and finally, devices rectify non-IID dataset by downloading the global generator. After obtaining IID local data in edge devices, RFD is implemented to improve the performance of local models, in which devices only share the local information of models' outputs to reduce communication overhead. By employing a detection and discard mechanism in both RFA and RFD, our framework achieves robustness to the influence of Byzantine devices. Experiments show the effectiveness of RFA-RFD on preserving privacy, correcting non-IID data, reducing communication overhead, and resisting Byzantine devices, without much loss of accuracy compared with existing state-of-the-art methods.","","978-1-7281-8695-5","10.1109/INFOCOMWKSHPS50562.2020.9162672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9162672","Federated learning;data augmentation;distillation;conditional variational autoencoder;communication efficient;privacy preserving;Byzantine robustness","Training;Generators;Servers;Robustness;Machine learning;Data privacy;Data models","data privacy;distributed processing;learning (artificial intelligence)","wireless communications;edge intelligence;data-driven machine learning;privacy issues;communication resources;wireless networks;Byzantine devices;robust federated augmentation;RFA-RFD;Byzantine-tolerant on-device machine;local data generators;edge devices;unified federated learning;high-quality machine learning;non-IID local data","","9","","19","","10 Aug 2020","","","IEEE","IEEE Conferences"
"Blind Image Deconvolution Using Deep Generative Priors","M. Asim; F. Shamshad; A. Ahmed","Department of Electrical Engineering, Information Technology University, Lahore, Pakistan; Department of Electrical Engineering, Information Technology University, Lahore, Pakistan; Department of Electrical Engineering, Information Technology University, Lahore, Pakistan","IEEE Transactions on Computational Imaging","11 Nov 2020","2020","6","","1493","1506","This article proposes a novel approach to regularize the ill-posed and non-linear blind image deconvolution (blind deblurring) using deep generative networks as priors. We employ two separate pretrained generative networks - given lower-dimensional Gaussian vectors as input, one of the generative models samples from the distribution of sharp images, while the other from that of the blur kernels. To deblur, we find a sharp image and a blur kernel in the range of the respective generators that best explain the blurred image. Our experiments show promising deblurring results on images even under large blurs, and heavy measurement noise. Generative models often manifest a representation error to fit arbitrary samples from the learned distribution. This may be due to multiple factors such as mode collapse, architectural choices, or training caveats. To improve the generalizability of the proposed approach, we present a modification of the proposed scheme that governs the deblurring process under both generative, and classical priors. Training generative models is computationally expensive on larger and more diverse image datasets. Our experiments also show that even an untrained structured (convolutional) network acts as an image prior. We leverage this fact to deblur diverse/complex images for which a trained generative network might not be available.","2333-9403","","10.1109/TCI.2020.3032671","British Machine Vision Conference; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9250553","Blind image deblurring;deep image prior;generative adversarial networks;variational autoencoders","Kernel;Image restoration;Neural networks;Generators;Deconvolution;Convolution","deconvolution;Gaussian noise;image restoration;learning (artificial intelligence);neural nets","complex images;convolutional network;image prior;learned distribution;nonlinear blind image deconvolution;blind deblurring;deep generative priors;untrained structured network;image datasets;blurred image;blur kernel;sharp images;lower-dimensional Gaussian vectors;deep generative networks","","9","","58","IEEE","6 Nov 2020","","","IEEE","IEEE Journals"
"MDMaaS: Medical-Assisted Diagnosis Model as a Service With Artificial Intelligence and Trust","K. Guo; S. Ren; M. Z. A. Bhuiyan; T. Li; D. Liu; Z. Liang; X. Chen","School of Computer Science and Engineering, Central South University, Changsha, China; School of Computer Science and Engineering, Central South University, Changsha, China; Department of Computer and Infor-mation Sciences, Fordham University, Bronx, USA; School of Computer Science and Engineering, Central South University, Changsha, China; School of Computer Science and Engineering, Central South University, Changsha, China; School of Computer Science and Engineering, Central South University, Changsha, China; Department of Dermatology, Xiangya Hospital, Central South University, Changsha, China","IEEE Transactions on Industrial Informatics","22 Jan 2020","2020","16","3","2102","2114","Artificial intelligence has achieved great success in the field of medical-assisted diagnosis, and a deep learning technology plays a very important role in medical image recognition. However, it usually takes medical institutions extra time, energy, and cost to obtain a credible and efficient deep learning model, which is not conducive to a wide range of applications, including medical image recognition and medical decision making. In this article, we propose a novel medical-assisted diagnosis model as a service (MDMaaS). Medical institutions can obtain and use the medical-assisted diagnosis models from the service providers directly; a model training and a model application in machine learning are assigned to a service provider and a consumer, respectively. We have designed a model acquisition method based on the conventional samples and small samples for MDMaaS providers, and we have also developed a trustworthy model-based recommendation method for MDMaaS consumers, which would help the medical institutions to obtain the reliable medical-assisted diagnosis models quickly and efficiently. Based on the MDMaaS, extensive experiments are performed to verify the effectiveness of the proposed method.","1941-0050","","10.1109/TII.2019.2937547","National Natural Science Foundation of China(grant numbers:61672535,61502540); Natural Science Foundation of Hunan Province(grant numbers:2019JJ20025,2019JJ40406); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8815887","Deep learning;medical-assisted diagnosis;trust recommendation;variational autoencoder","Medical diagnostic imaging;Computational modeling;Deep learning;Cloud computing;Training;Medical services","decision making;image recognition;learning (artificial intelligence);medical image processing;recommender systems;trusted computing","medical decision making;MDMaaS;service provider;trustworthy model-based recommendation method;artificial intelligence;medical image recognition;medical institutions;credible learning model;efficient deep learning model;medical-assisted diagnosis model as a service;model acquisition method","","6","","33","IEEE","27 Aug 2019","","","IEEE","IEEE Journals"
"Vae-Space: Deep Generative Model of Voice Fundamental Frequency Contours","K. Tanaka; H. Kameoka; K. Morikawa","NTT Communication Science Laboratories, NTT Corporation, Japan; NTT Communication Science Laboratories, NTT Corporation, Japan; Graduate School of informatics, Nagoya University, japan","2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 Sep 2018","2018","","","5779","5783","Modeling the speech generation process can provide flexible and interpretable ways to generate intended synthetic speech. In this paper, we present a deep generative model of fundamental frequency (F0) contours of normal speech and singing voices. The generative model we propose in this paper 1) is able to accurately decompose an F0 contour into the sum of phrase and accent components of the Fujisaki model, a mathematical model describing the control mechanism of vocal fold vibration, without an iterative algorithm, and 2) can represent/generate F0 contours of both normal speech and singing voices reasonably well.","2379-190X","978-1-5386-4658-8","10.1109/ICASSP.2018.8461569","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8461569","Deep generative model;voice contour;singing voice;variational autoencoder;gated convolutional network","Hidden Markov models;Logic gates;Decoding;Computational modeling;Data models;Mathematical model;Parameter estimation","convolution;feedforward neural nets;iterative methods;speech processing;speech synthesis","deep generative model;voice fundamental frequency contours;speech generation process;intended synthetic speech;normal speech;singing voices;Fujisaki model;vocal fold vibration;F0 contour;VAE-space;iterative algorithm","","5","","18","","13 Sep 2018","","","IEEE","IEEE Conferences"
"Video Face Clustering With Self-Supervised Representation Learning","V. Sharma; M. Tapaswi; M. S. Sarfraz; R. Stiefelhagen","Massachusetts Institute of Technology, Cambridge, USA; Inria, Paris, France; Department of Informatics, Institute for Anthropomatics and Robotics, Computer Vision for Human-Computer Interaction Lab, Karlsruhe Institute of Technology, Karlsruhe, Germany; Department of Informatics, Institute for Anthropomatics and Robotics, Computer Vision for Human-Computer Interaction Lab, Karlsruhe Institute of Technology, Karlsruhe, Germany","IEEE Transactions on Biometrics, Behavior, and Identity Science","30 Mar 2020","2020","2","2","145","157","Characters are a key component of understanding the story conveyed in TV series and movies. With the rise of advanced deep face models, identifying face images may seem like a solved problem. However, as face detectors get better, clustering and identification need to be revisited to address increasing diversity in facial appearance. In this paper, we propose unsupervised methods for feature refinement with application to video face clustering. Our emphasis is on distilling the essential information, identity, from the representations obtained using deep pre-trained face networks. We propose a self-supervised Siamese network that can be trained without the need for video/track based supervision, that can also be applied to image collections. We evaluate our methods on three video face clustering datasets. Thorough experiments including generalization studies show that our methods outperform current state-of-the-art methods on all datasets. The datasets and code are available at https://github.com/vivoutlaw/SSIAM.","2637-6407","","10.1109/TBIOM.2019.2947264","German Research Foundation (DFG) funded PLUMCOT Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8873682","Video understanding;video face clustering;selfsupervised learning;representation learning;Siamese networks;variational autoencoders","Face;Training data;Hidden Markov models;TV;Motion pictures;Training;Analytical models","face recognition;feature extraction;image classification;image representation;neural nets;object detection;pattern clustering;unsupervised learning;video signal processing","self-supervised representation learning;deep face models;face images;face detectors;clustering identification;self-supervised Siamese network;video face clustering;deep pretrained face networks;facial appearance;unsupervised methods;feature refinement;image collections","","4","","71","IEEE","17 Oct 2019","","","IEEE","IEEE Journals"
"A Zynq-Based Flexible ADC Architecture Combining Real-Time Data Streaming and Transient Recording","A. R. Garola; G. Manduchi; M. Gottardo; R. Cavazzana; M. Recchia; C. Taliercio; A. Luchetta","Consorzio RFX (CNR, ENEA, INFN, Universitá Degli Studi di Padova, Acciaierie Venete SpA), Padua, Italy; Consorzio RFX (CNR, ENEA, INFN, Universitá Degli Studi di Padova, Acciaierie Venete SpA), Padua, Italy; Consorzio RFX (CNR, ENEA, INFN, Universitá Degli Studi di Padova, Acciaierie Venete SpA), Padua, Italy; Consorzio RFX (CNR, ENEA, INFN, Universitá Degli Studi di Padova, Acciaierie Venete SpA), Padua, Italy; Consorzio RFX (CNR, ENEA, INFN, Universitá Degli Studi di Padova, Acciaierie Venete SpA), Padua, Italy; Consorzio RFX (CNR, ENEA, INFN, Universitá Degli Studi di Padova, Acciaierie Venete SpA), Padua, Italy; Consorzio RFX (CNR, ENEA, INFN, Universitá Degli Studi di Padova, Acciaierie Venete SpA), Padua, Italy","IEEE Transactions on Nuclear Science","15 Feb 2021","2021","68","2","245","249","The RFX-mod2 Nuclear Fusion experiment is an upgrade of RFX-mod, which was shutdown in 2016. Among the other improvements in the machine structure and diagnostics, a larger number of electromagnetic probes (EMs) is foreseen to provide more information about plasma instabilities and to allow an improved real-time plasma control. An analog-to-digital converter (ADC) architecture able to provide, at the same time, both transient recording and real-time streaming, as well as field-programmable gate array (FPGA)-based time integration of the inputs, is foreseen in RFX-mod2. Transient recording provides full-speed data acquisition (up to 1 MSample/s) by recording data in local memory and reading memory content after the plasma discharge. Real-time streaming of the subsampled data is required for active control. The chosen technology is based on the XILINX Zynq architecture that provides, in the same chip, a multicore Advanced RISC Machines (ARM) processor tightly coupled to an FPGA. Time-critical functions are carried out by the FPGA, such as the management of the circular data buffer, low-pass filtering for subsampling of the samples to be streamed, and digital integration. Other functions are carried out by the processor, such as the management of the configuration setting, received via Transmission Control Protocol (TCP)/IP or Hypertext Transfer Protocol (HTTP), the data readout of acquired samples in transient recording buffers, and network data streaming of data collected for active real-time plasma control.","1558-1578","","10.1109/TNS.2020.3035146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9246516","Data imputation;data integration;field-programmable gate array (FPGA);missing data;neural networks;plasma diagnostic;quantized networks;real-time control;sparse regularization;variational autoencoders","Field programmable gate arrays;Real-time systems;Plasmas;Transient analysis;Timing;Clocks;Probes","analogue-digital conversion;data acquisition;field programmable gate arrays;multiprocessing systems;reduced instruction set computing;transport protocols","Zynq-based flexible ADC architecture;machine structure;electromagnetic probes;plasma instabilities;real-time plasma control;analog-to-digital converter architecture;field-programmable gate array-based time integration;FPGA;full-speed data acquisition;reading memory content;plasma discharge;subsampled data;active control;XILINX Zynq architecture;time-critical functions;circular data buffer;digital integration;data readout;transient recording buffers;RFX-mod2 nuclear fusion experiment;local memory content;multicore advanced RISC machines processor;transmission control protocol;hypertext transfer protocol;network data streaming","","4","","14","IEEE","2 Nov 2020","","","IEEE","IEEE Journals"
"P3GM: Private High-Dimensional Data Release via Privacy Preserving Phased Generative Model","S. Takagi; T. Takahashi; Y. Cao; M. Yoshikawa",LINE Corporation; LINE Corporation; Kyoto University; Kyoto University,"2021 IEEE 37th International Conference on Data Engineering (ICDE)","22 Jun 2021","2021","","","169","180","How can we release a massive volume of sensitive data while mitigating privacy risks? Privacy-preserving data synthesis enables the data holder to outsource analytical tasks to an untrusted third party. The state-of-the-art approach for this problem is to build a generative model under differential privacy, which offers a rigorous privacy guarantee. However, the existing method cannot adequately handle high dimensional data. In particular, when the input dataset contains a large number of features, the existing techniques require injecting a prohibitive amount of noise to satisfy differential privacy, which results in the outsourced data analysis meaningless. To address the above issue, this paper proposes privacy-preserving phased generative model (P3GM), which is a differentially private generative model for releasing such sensitive data. P3GM employs the two-phase learning process to make it robust against the noise, and to increase learning efficiency (e.g., easy to converge). We give theoretical analyses about the learning complexity and privacy loss in P3GM. We further experimentally evaluate our proposed method and demonstrate that P3GM significantly outperforms existing solutions. Compared with the state-of-the-art methods, our generated samples look fewer noises and closer to the original data in terms of data diversity. Besides, in several data mining tasks with synthesized data, our model outperforms the competitors in terms of accuracy.","2375-026X","978-1-7281-9184-3","10.1109/ICDE51399.2021.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9458927","differential privacy;variational autoencoder;generative model;privacy preserving data synthesis","Training;Dimensionality reduction;Differential privacy;Privacy;Solid modeling;Estimation;Data models","data analysis;data mining;data privacy;learning (artificial intelligence);outsourcing","privacy loss;P3GM;data diversity;data mining tasks;synthesized data;private high-dimensional data release;privacy preserving phased generative model;sensitive data;mitigating privacy risks;privacy-preserving data synthesis;data holder;differential privacy;rigorous privacy guarantee;high dimensional data;outsourced data analysis meaningless;differentially private generative model;two-phase learning process;learning complexity","","3","","40","IEEE","22 Jun 2021","","","IEEE","IEEE Conferences"
"Investigating Deep Learning Based Breast Cancer Subtyping Using Pan-Cancer and Multi-Omic Data","F. Cristovao; S. Cascianelli; A. Canakoglu; M. Carman; L. Nanni; P. Pinoli; M. Masseroli","Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy","IEEE/ACM Transactions on Computational Biology and Bioinformatics","3 Feb 2022","2022","19","1","121","134","Breast Cancer comprises multiple subtypes implicated in prognosis. Existing stratification methods rely on the expression quantification of small gene sets. Next Generation Sequencing promises large amounts of omic data in the next years. In this scenario, we explore the potential of machine learning and, particularly, deep learning for breast cancer subtyping. Due to the paucity of publicly available data, we leverage on pan-cancer and non-cancer data to design semi-supervised settings. We make use of multi-omic data, including microRNA expressions and copy number alterations, and we provide an in-depth investigation of several supervised and semi-supervised architectures. Obtained accuracy results show simpler models to perform at least as well as the deep semi-supervised approaches on our task over gene expression data. When multi-omic data types are combined together, performance of deep models shows little (if any) improvement in accuracy, indicating the need for further analysis on larger datasets of multi-omic data as and when they become available. From a biological perspective, our linear model mostly confirms known gene-subtype annotations. Conversely, deep approaches model non-linear relationships, which is reflected in a more varied and still unexplored set of representative omic features that may prove useful for breast cancer subtyping.","1557-9964","","10.1109/TCBB.2020.3042309","Data-Driven Genomic Computing; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9280414","Deep learning;genomics;multi-omics;semi supervised learning;variational autoencoder","Gene expression;Deep learning;Genomics;Breast cancer;Bioinformatics;Data models;Task analysis","bioinformatics;biological organs;cancer;data handling;deep learning (artificial intelligence);genetics;genomics;medical diagnostic computing;molecular biophysics;RNA;semi-supervised learning (artificial intelligence)","breast cancer subtyping;pan-cancer;omic data;machine learning;deep learning;noncancer data;semisupervised settings;deep semisupervised approaches;gene expression data;multiomic data types;deep models;known gene-subtype annotations","Breast Neoplasms;DNA Copy Number Variations;Deep Learning;Female;Humans;Machine Learning;Supervised Machine Learning","2","","34","IEEE","3 Dec 2020","","","IEEE","IEEE Journals"
"DeSIRe: Deep Signer-Invariant Representations for Sign Language Recognition","P. M. Ferreira; D. Pernes; A. Rebelo; J. S. Cardoso","Ciência e Tecnologia, Universidade Portucalense, Porto, Portugal; Ciência e Tecnologia, Universidade Portucalense, Porto, Portugal; Ciência e Tecnologia, Universidade Portucalense, Porto, Portugal; Ciência e Tecnologia, Universidade Portucalense, Porto, Portugal","IEEE Transactions on Systems, Man, and Cybernetics: Systems","17 Aug 2021","2021","51","9","5830","5845","As a key technology to help bridging the gap between deaf and hearing people, sign language recognition (SLR) has become one of the most active research topics in the human-computer interaction field. Although several SLR methodologies have been proposed, the development of a real-world SLR system is still a very challenging task. One of the main challenges is related to the large intersigner variability that exists in the manual signing process of sign languages. To address this problem, we propose a novel end-to-end deep neural network that explicitly models highly discriminative signer-independent latent representations from the input data. The key idea of our model is to learn a distribution over latent representations, conditionally independent of signer identity. Accordingly, the learned latent representations will preserve as much information as possible about the signs, and discard signer-specific traits that are irrelevant for recognition. By imposing such regularization in the representation space, the result is a truly signer-independent model which is robust to different and new test signers. The experimental results demonstrate the effectiveness of the proposed model in several SLR databases.","2168-2232","","10.1109/TSMC.2019.2957347","European Regional Development Fund through the Operational Programme for Competitiveness and Internationalisation—COMPETE 2020 Programme; National Funds through the Portuguese Funding Agency, Fundação para a Ciência e a Tecnologia(grant numbers:POCI-01-0145-FEDER-030707); Ph.D.(grant numbers:SFRH/BD/102177/2014,SFRH/BD/129600/2017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937777","Deep neural networks;generative models;representation learning;signer-independent sign language recognition;variational autoencoders (VAEs)","Assistive technology;Gesture recognition;Neural networks;Measurement;Auditory system;Task analysis;Hidden Markov models","digital signatures;gesture recognition;handicapped aids;image representation;learning (artificial intelligence);neural nets;sign language recognition","sign language recognition;active research topics;human-computer interaction field;SLR methodologies;real-world SLR system;manual signing process;sign languages;end-to-end deep neural network;explicitly models;signer-independent latent representations;signer identity;learned latent representations;signer-specific traits;representation space;truly signer-independent model;different test signers;new test signers;SLR databases;deep signer-invariant representations;deaf hearing people","","2","","47","IEEE","20 Dec 2019","","","IEEE","IEEE Journals"
"Automatic Fault Detection for Marine Diesel Engine Degradation in Autonomous Ferry Crossing Operation","A. L. Ellefsen; X. Cheng; F. T. Holmeset; V. Æsøy; H. Zhang; S. Ushakov","Department of Ocean Operations and Civil Engineering, Norwegian University of Science and Technology, Aalesund, Norway; Department of Ocean Operations and Civil Engineering, Norwegian University of Science and Technology, Aalesund, Norway; Department of Ocean Operations and Civil Engineering, Norwegian University of Science and Technology, Aalesund, Norway; Department of Ocean Operations and Civil Engineering, Norwegian University of Science and Technology, Aalesund, Norway; Department of Ocean Operations and Civil Engineering, Norwegian University of Science and Technology, Aalesund, Norway; Department of Marine Technology, Norwegian University of Science and Technology, Trondheim, Norway","2019 IEEE International Conference on Mechatronics and Automation (ICMA)","29 Aug 2019","2019","","","2195","2200","The maritime industry generally anticipates having semi-autonomous ferries in commercial use on the west coast of Norway by the end of this decade. In order to schedule maintenance operations of critical components in a secure and cost-effective manner, a reliable prognostics and health management system is essential during autonomous operations. Any remaining useful life prediction obtained from such system should depend on an automatic fault detection algorithm. In this study, an unsupervised reconstruction-based fault detection algorithm is used to predict faults automatically in a simulated autonomous ferry crossing operation. The benefits of the algorithm are confirmed on data sets of real-operational data from a marine diesel engine collected from a hybrid power lab. During the ferry crossing operation, the engine is subjected to drastic changes in operational loads. This increases the difficulty of the algorithm to detect faults with high accuracy. Thus, to support the algorithm, three different feature selection processes on the input data is compared. The results suggest that the algorithm achieves the highest prediction accuracy when the input data is subjected to feature selection based on sensitivity analysis.","2152-744X","978-1-7281-1699-0","10.1109/ICMA.2019.8816600","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8816600","Automatic fault detection;feature selection;marine diesel engine;prognostics and health management;variational autoencoder","Prediction algorithms;Feature extraction;Fault detection;Diesel engines;Degradation;Decoding","condition monitoring;diesel engines;fault diagnosis;maintenance engineering;reliability;remaining life assessment;ships","marine diesel engine degradation;maritime industry;semiautonomous ferries;maintenance operations;critical components;reliable prognostics;health management system;autonomous operations;remaining useful life prediction;automatic fault detection algorithm;unsupervised reconstruction-based fault detection algorithm;data sets;real-operational data;autonomous ferry crossing operation;Norway","","2","","21","","29 Aug 2019","","","IEEE","IEEE Conferences"
"Continual Learning Through One-Class Classification Using VAE","F. Wiewel; A. Brendle; B. Yang","Institute of Signal Processing and System Theory, University of Stuttgart, Germany; Institute of Signal Processing and System Theory, University of Stuttgart, Germany; Institute of Signal Processing and System Theory, University of Stuttgart, Germany","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","3307","3311","Artificial neural networks (ANNs) suffer from catastrophic forgetting, a sharp decrease in performance on previously learned tasks, when trained on a new task without constant rehearsal. In this paper, we propose a new method for overcoming this phenomenon based on one-class classification. It is not only able to incrementally learn new but also detect unknown classes. This is a desirable property, since it enables the detection of new and unknown classes in a stream of data and adaption to a changing environment. Experiments on commonly used continual learning setups show competitive results and verify the concept.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9054743","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054743","Continual Learning;One-class Classification;Variational Autoencoder;Deep Generative Replay","Conferences;Artificial neural networks;Signal processing;Benchmark testing;Acoustics;Task analysis;Speech processing","learning (artificial intelligence);neural nets;pattern classification","continual learning;one-class classification;VAE;artificial neural networks;catastrophic forgetting","","2","","19","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Modeling and Synthesis of Breast Cancer Optical Property Signatures With Generative Models","A. Pardo; S. S. Streeter; B. W. Maloney; J. A. Gutiérrez-Gutiérrez; D. M. McClatchy; W. A. Wells; K. D. Paulsen; J. M. López-Higuera; B. W. Pogue; O. M. Conde","Instituto de Investigación Sanitaria Valdecilla (IDIVAL), Santander, Spain; Thayer School of Engineering, Dartmouth College, Hanover, NH, USA; Thayer School of Engineering, Dartmouth College, Hanover, NH, USA; Instituto de Investigación Sanitaria Valdecilla (IDIVAL), Santander, Spain; Radiation-Drug Treatment Design Lab, Massachusetts General Hospital, Boston, MA, USA; Geisel School of Medicine, Dartmouth College, Hanover, NH, USA; Thayer School of Engineering, Dartmouth College, Hanover, NH, USA; Centros de Investigación Biomédica en Red en Bioingeniería, Biomateriales y Nanomedicina (CIBER-BBN), Zaragoza, Spain; Thayer School of Engineering, Dartmouth College, Hanover, NH, USA; Centros de Investigación Biomédica en Red en Bioingeniería, Biomateriales y Nanomedicina (CIBER-BBN), Zaragoza, Spain","IEEE Transactions on Medical Imaging","1 Jun 2021","2021","40","6","1687","1701","Is it possible to find deterministic relationships between optical measurements and pathophysiology in an unsupervised manner and based on data alone? Optical property quantification is a rapidly growing biomedical imaging technique for characterizing biological tissues that shows promise in a range of clinical applications, such as intraoperative breast-conserving surgery margin assessment. However, translating tissue optical properties to clinical pathology information is still a cumbersome problem due to, amongst other things, inter- and intrapatient variability, calibration, and ultimately the nonlinear behavior of light in turbid media. These challenges limit the ability of standard statistical methods to generate a simple model of pathology, requiring more advanced algorithms. We present a data-driven, nonlinear model of breast cancer pathology for real-time margin assessment of resected samples using optical properties derived from spatial frequency domain imaging data. A series of deep neural network models are employed to obtain sets of latent embeddings that relate optical data signatures to the underlying tissue pathology in a tractable manner. These self-explanatory models can translate absorption and scattering properties measured from pathology, while also being able to synthesize new data. The method was tested on a total of 70 resected breast tissue samples containing 137 regions of interest, achieving rapid optical property modeling with errors only limited by current semi-empirical models, allowing for mass sample synthesis and providing a systematic understanding of dataset properties, paving the way for deep automated margin assessment algorithms using structured light imaging or, in principle, any other optical imaging technique seeking modeling. Code is available.","1558-254X","","10.1109/TMI.2021.3064464","National Cancer Institute, US National Institutes of Health(grant numbers:R01 CA192803,F31 CA196308); Spanish Ministry of Science and Innovation(grant numbers:FIS2010-19860); Spanish Ministry of Science, Innovation and Universities(grant numbers:TEC2016-76021-C2-2-R,PID2019-107270RB-C21); Spanish Ministry of Economy, Industry and Competitiveness and Instituto de Salud Carlos III(grant numbers:DTS17-00055); Instituto de Investigación Sanitaria Valdecilla (IDIVAL)(grant numbers:INNVAL16/02,INNVAL18/23); Spanish Ministry of Education, Culture, and Sports with Ph.D.(grant numbers:FPU16/05705); Fondo Europeo de Desarrollo Regional (FEDER) Funds; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9371720","Biomedical optical imaging;breast cancer;tissue optical properties;modeling;pathology;deep learning;dimensionality reduction;variational autoencoder;convolutional neural networks","Optical imaging;Nonlinear optics;Biomedical optical imaging;Imaging;Adaptive optics;Pathology;Optical scattering","biological tissues;biomedical optical imaging;bio-optics;cancer;deep learning (artificial intelligence);gynaecology;mammography;medical image processing;neural nets;surgery","latent embeddings;spatial frequency domain imaging;deep automated margin assessment;resected breast tissue;tissue pathology;deep neural network models;real-time margin assessment;breast cancer pathology;nonlinear model;tissue optical properties;intraoperative breast-conserving surgery margin assessment;biological tissues;biomedical imaging;unsupervised manner;generative models;breast cancer optical property signatures;optical imaging;structured light imaging;mass sample synthesis;semiempirical models","Algorithms;Breast Neoplasms;Calibration;Female;Humans;Neural Networks, Computer;Optical Imaging","1","","54","IEEE","8 Mar 2021","","","IEEE","IEEE Journals"
"Detecting Out-of-Distribution Data in Wireless Communications Applications of Deep Learning","J. Liu; T. Oyedare; J. -M. Park","Department of Electrical and Computer Engineering, Virginia Tech, Arlington, VA, USA; Department of Electrical and Computer Engineering, Virginia Tech, Arlington, VA, USA; Department of Electrical and Computer Engineering, Virginia Tech, Arlington, VA, USA","IEEE Transactions on Wireless Communications","8 Apr 2022","2022","21","4","2476","2487","Deep learning-based classification algorithms offer no performance guarantees when deployed on testing data not generated by the same process as the training data. Such out-of-distribution (OOD) data often cause classification errors that are hard to detect since they do not generate explicit errors in the model. In real-world applications, there is no way to ensure that the testing data and the training data are drawn from the same or sufficiently similar distributions. This problem is especially challenging in wireless communications applications. Because the radio propagation channel is highly dynamic, it is very difficult to ensure that a deep learning model is not tested on OOD data. In this paper, we propose a novel deep learning model called FOOD (Feature representation for detecting OOD data) to detect OOD data in wireless communications applications. FOOD incorporates a new model architecture to detect OOD data accurately and minimizes the instances of normal data being recognized as OOD. We evaluated the performance of FOOD extensively using transmitter classification and modulation recognition tasks, with both experimental datasets and simulation-generated datasets. As far as we know, this is the first systematic study on the impact and detection of OOD data in deep learning-based wireless communications applications.","1558-2248","","10.1109/TWC.2021.3112663","NSF(grant numbers:1563832,1822173); Industry Affiliates of the Broadband Wireless Access and Applications Center (BWAC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9546673","Deep learning;out-of-distribution;variational autoencoder;transmitter classification;modulation recognition","Wireless communication;Data models;Training data;Training;Deep learning;Testing;Feature extraction","deep learning (artificial intelligence);pattern classification;radiowave propagation;telecommunication computing;wireless channels","out-of-distribution data;deep learning-based classification algorithms;wireless communications;classification errors;radio propagation channel;FOOD;feature representation for detecting ood data;OOD data detection;model architecture;performance evaluation;transmitter classification;modulation recognition;simulation-generated datasets","","1","","42","IEEE","22 Sep 2021","","","IEEE","IEEE Journals"
"Cross-VAE: Towards Disentangling Expression from Identity For Human Faces","H. Wu; J. Jia; L. Xie; G. Qi; Y. Shi; Q. Tian","Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Huawei Noah’s Ark Lab; Futurewei Technologies; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Huawei Noah’s Ark Lab","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","4087","4091","Facial expression and identity are two independent yet intertwined components for representing a face. For facial expression recognition, identity can contaminate the training procedure by providing tangled but irrelevant information. In this paper, we propose to learn clearly disentangled and discriminative features that are invariant of identities for expression recognition. However, such disentanglement normally requires annotations of both expression and identity on one large dataset, which is often unavailable. Our solution is to extend conditional VAE to a crossed version named Cross-VAE, which is able to use partially labeled data to disentangle expression from identity. We emphasis the following novel characteristics of our Cross-VAE: (1) It is based on an independent assumption that the two latent representations' distributions are orthogonal. This ensures both encoded representations to be disentangled and expressive. (2) It utilizes a symmetric training procedure where the output of each encoder is fed as the condition of the other. Thus two partially labeled sets can be jointly used. Extensive experiments show that our proposed method is capable of encoding expressive and disentangled features for facial expression. Compared with the baseline methods, our model shows an improvement of 3.56% on average in terms of accuracy.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9053608","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9053608","Facial expression recognition;Disentangle;Variational Autoencoder","Training;Face recognition;Speech recognition;Solids;Encoding;Task analysis;Speech processing","emotion recognition;face recognition;feature extraction;learning (artificial intelligence);neural nets","symmetric training procedure;latent representation distributions;disentangling expression;cross-VAE;discriminative features;clearly disentangled features;facial expression recognition;human faces;expressive features;disentangle expression;conditional VAE","","1","","31","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Dynamic Surface Animation using Generative Networks","J. Regateiro; A. Hilton; M. Volino","Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, UK; Centre for Vision, Speech and Signal Processing University of Surrey; Centre for Vision, Speech and Signal Processing University of Surrey","2019 International Conference on 3D Vision (3DV)","31 Oct 2019","2019","","","376","385","This paper presents techniques to animate realistic human-like motion using a compressed learnt model from 4D volumetric performance capture data. Sequences of 4D dynamic geometry representing a human performing an arbitrary motion are encoded through a generative network into a compact space representation, whilst maintaining the original properties, such as, surface dynamics. An animation framework is proposed which computes an optimal motion graph using the novel capabilities of compression and generative synthesis properties of the network. This approach significantly reduces the memory space requirements, improves quality of animation, and facilitates the interpolation between motions. The framework optimises the number of transitions in the graph with respect to the shape and motion of the dynamic content. This generates a compact graph structure with low edge connectivity, and maintains realism when transitioning between motions. Finally, it demonstrates that generative networks facilitate the computation of novel poses, and provides a compact motion graph representation of captured dynamic shape enabling real-time interactive animation and interpolation of novel poses to smoothly transition between motions.","2475-7888","978-1-7281-3131-3","10.1109/3DV.2019.00049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886095","Animation;Variational autoencoder;Generative Network;Motion graphs;Geometry Representation","Dynamics;Three-dimensional displays;Animation;Shape;Geometry;Decoding;Vehicle dynamics","computational geometry;computer animation;graph theory","arbitrary motion;4D dynamic geometry;4D volumetric performance capture data;compressed learnt model;dynamic surface animation;real-time interactive animation;captured dynamic shape;compact motion graph representation;compact graph structure;dynamic content;memory space requirements;generative synthesis properties;optimal motion graph;animation framework;surface dynamics;compact space representation;generative network","","1","","38","","31 Oct 2019","","","IEEE","IEEE Conferences"
"Attributed Network Embedding with Community Preservation","T. Huang; L. Zhou; L. Wang; G. Du; K. Lü","School of Information, Yunnan University, Kunming, China; School of Information, Yunnan University, Kunming, China; School of Information, Yunnan University, Kunming, China; School of Information, Yunnan University, Kunming, China; Brunel University, Uxbridge, UK","2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA)","20 Nov 2020","2020","","","334","343","Network embedding (NE) is a method that maps nodes in a network into a low-dimensional and continuous vector space while maintains inherent features of the network. Most existing algorithms for NE focus on one or two of the aspects of topological structure, node attributes or community structure information, but without integrating the three in a unified framework. In this study, we develop a deep neural network-based framework for Attributed Network Embedding with Community Preservation (ANECP), which simultaneously incorporates the topological structure, node attributes as well as community structure together to obtain the low-dimensional distributed representations of nodes in the network. The use of deep neural networks captures the underlying high non-linearity in both topology and attribute information, while the incorporation of the community structure resolves the issues of data sparsity from microscopic perspective. Consequently, the obtained node representations can preserve proximity and discriminative. We conducted experimental studies using six real-world datasets. The experimental results show that proposed ANECP has superior performance over the existing methods.","","978-1-7281-8206-3","10.1109/DSAA49011.2020.00047","National Natural Science Foundation of China; Natural Science Foundation of Yunnan Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9260090","Network embedding;topological structure;node attribute;community structure;conditional variational autoencoder","Neural networks;Manganese;Topology;Radio frequency;OWL;Network topology;Microscopy","graph theory;network theory (graphs);neural nets;vectors","attributed network embedding with community preservation;node representations;attribute information;deep neural network-based framework;community structure information;node attributes;topological structure;NE focus;continuous vector space;low-dimensional vector space;maps nodes","","1","","41","","20 Nov 2020","","","IEEE","IEEE Conferences"
"Disentangling and Learning Robust Representations with Natural Clustering","J. Antoran; A. Miguel","ViVoLab, University of Zaragoza, Zaragoza, Spain; ViVoLab, University of Zaragoza, Zaragoza, Spain","2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)","17 Feb 2020","2019","","","694","699","Learning representations that disentangle the underlying factors of variability in data is an intuitive way to achieve generalization in deep models. In this work, we address the scenario where generative factors present a multimodal distribution due to the existence of class distinction in the data. We propose N-VAE, a model which is capable of separating factors of variation which are exclusive to certain classes from factors that are shared among classes. This model implements an explicitly compositional latent variable structure by defining a class-conditioned latent space and a shared latent space. We show its usefulness for detecting and disentangling class-dependent generative factors as well as its capacity to generate artificial samples which contain characteristics unseen in the training data.","","978-1-7281-4550-1","10.1109/ICMLA.2019.00125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8999205","Representation Learning;Dimensionality reduction;Disentangling;Natural Clustering;Variational Autoencoders","Image reconstruction;Decoding;Data models;Azimuth;Manifolds;Standards;Neural networks","learning (artificial intelligence);neural nets;pattern clustering;statistical distributions","class-dependent generative factors;natural clustering;class-conditioned latent space;latent variable structure;N-VAE;class distinction;multimodal distribution;deep models;representations learning","","1","","19","","17 Feb 2020","","","IEEE","IEEE Conferences"
"Improving Emotional Speech Synthesis by Using SUS-Constrained VAE and Text Encoder Aggregation","F. Yang; J. Luan; Y. Wang","Xiaomi Corporation, Beijing, China; Xiaomi Corporation, Beijing, China; Xiaomi Corporation, Beijing, China","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","8302","8306","Learning emotion embedding from reference audio is a straightforward approach for multi-emotion speech synthesis in encoder-decoder systems. But how to get better emotion embedding and how to inject it into TTS acoustic model more effectively are still under investigation. In this paper, we propose an innovative constraint to help VAE extract emotion embedding with better cluster cohesion. Besides, the obtained emotion embedding is used as query to aggregate latent representations of all encoder layers via attention. Moreover, the queries from encoder layers themselves are also helpful. Experiments prove the proposed methods can enhance the encoding of comprehensive syntactic and semantic information and produce more expressive emotional speech.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746994","emotional TTS;variational autoencoder;emotion embedding;encoder aggregation","Conferences;Aggregates;Semantics;Syntactics;Speech enhancement;Signal processing;Encoding","decoding;emotion recognition;speech processing;speech synthesis","emotional speech synthesis;SUS-constrained VAE;text encoder;learning emotion;reference audio;multiemotion speech synthesis;encoder-decoder systems;emotion embedding;TTS acoustic model;VAE extract emotion;encoder layers;encoding;expressive emotional speech","","","","21","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Generating Responses With a Given Syntactic Pattern in Chinese Dialogues","Y. Zhou; X. Zheng; X. Huang","School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20 Sep 2021","2021","29","","2888","2898","Recently, many efforts have been devoted to generating responses expressing a specific emotion or relating to a given topic in a controlled manner. However, limited attention has been given to generating responses with a specified syntactic pattern, which makes it possible to imitate someone's way of speaking in dialogue. To fulfill this goal, we propose two models to generate syntax-aware responses: a gross-constraint and a specific-constraint model. The former controls the syntactic patterns of generated responses at sentence-level, while the latter works at smaller language units, such as words or phrases, being capable of manipulating the syntactic structures of responses in a more subtle manner. The extensive experimental results on two different datasets show that both the two models not only can generate meaningful responses with a specific and coherent structure but also improve on the diversity of generated responses, with similar gains in readability, relevance, and diversity as measured by human judges.","2329-9304","","10.1109/TASLP.2021.3110124","Shanghai Municipal Science and Technology(grant numbers:2021SHZDZX0103); National Natural Science Foundation of China(grant numbers:62076068); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9531490","Controlled text generation;stylized dialogue response generation;syntactic patterns;variational autoencoder;deep neural networks","Syntactics;Process control;Speech processing;Computer architecture;Chatbots;Training;Task analysis","computational linguistics;human computer interaction;natural language processing;text analysis","readability;generated responses;syntactic patterns;syntax-aware responses","","","","53","IEEE","8 Sep 2021","","","IEEE","IEEE Journals"
"Dynamic Co-Embedding Model for Temporal Attributed Networks","S. Tang; Z. Meng; S. Liang","Guangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou, China; School of Computing Science, University of Glasgow, Glasgow, U.K.; Department of Machine Learning, Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi, United Arab Emirates","IEEE Transactions on Neural Networks and Learning Systems","","2022","PP","99","1","15","In this article, we study the problem of embedding temporal attributed networks, with the goal of which is to learn dynamic low-dimensional representations over time for temporal attributed networks. Existing temporal network embedding methods only learn the representations for nodes, which are unable to capture the dynamic affinities between nodes and attributes. Moreover, existing co-embedding methods that learn the static embeddings of both nodes and attributes cannot be naturally utilized to obtain their dynamic embeddings for temporal attributed networks. To address these issues, we propose the dynamic co-embedding model for temporal attributed networks (DCTANs) based on the dynamic stochastic state–space framework. Our model captures the dynamics of a temporal attributed network by modeling the abstract belief states representing the condition of the nodes and attributes of current time step, and predicting the transitions between temporal abstract states of two successive time steps. Our model is able to learn embeddings for both nodes and attributes based on their belief states at each time step of the temporal attributed network, while the state transition tendency for predicting the future network can be tracked and the affinities between nodes and attributes can be preserved. Experimental results on real-world networks demonstrate that our model achieves substantial performance gains in several static and dynamic graph mining applications compared with the state-of-the-art static and dynamic models.","2162-2388","","10.1109/TNNLS.2022.3193564","National Natural Science Foundation of China(grant numbers:61906219); MBZUAI-WIS Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9844659","Dynamic co-embedding;network embedding;temporal attributed network;variational autoencoder (VAE)","Task analysis;Predictive models;Stochastic processes;Analytical models;Codes;Network analyzers;Correlation","","","","","","","IEEE","28 Jul 2022","","","IEEE","IEEE Early Access Articles"
"XCSR with VAE using Gaussian Distribution Matching: From Point to Area Matching in Latent Space for Less-overlapped Rule Generation in Observation Space","N. Yatsu; H. Shiraishi; H. Sato; K. Takadama","The University of Electro-Communications, Tokyo, Japan; The University of Electro-Communications, Tokyo, Japan; The University of Electro-Communications, Tokyo, Japan; The University of Electro-Communications, Tokyo, Japan","2022 IEEE Congress on Evolutionary Computation (CEC)","6 Sep 2022","2022","","","1","8","This paper focuses on the matching mechanism of Learning Classifier System (LCS) in a continuous space and proposes a novel matching mechanism based on Gaussian distribution. This mechanism can match the “area” instead of the “point (one value)” in the continuous space unlike the conventional LCS such as XCSR (XCS with Continuous-Valued Inputs). Such an area matching contributes to generating the rules (called classifiers) with less-overlapped with other rules. Concretely, the proposed area matching mechanism employed in XCSR using VAE can generate appropriate classifiers for latent variables with high-dimensional inputs by VAE and create a human-interpretable observation space of human-interpretable classifiers. Since the latent variable in VAE is followed by Gaus-sian distribution, the following three matching mechanisms are compared: (i) the (single) point matching that selects the classifier which condition covers the mean of Gaussian distribution M; (ii) the multiple points matching that selects the classifier which condition covers the data sampled from Gaussian distribution (M, u); and (iii) the area matching that selects the classifier which condition roughly covers a certain area of Gaussian distribution (M, o). Through the intensive experiments on the high dimension maze problem, the following implications have been revealed: (1) the point matching in XCSR with VAE generates the ambiguous classifiers which conditions are overlapped with the other classifiers with the different action; (2) the sampling multiple points matching in XCSR with VAE has a potential of generating the less-overlapped classifiers by improving the data set through sampling. (3) the proposed area matching can generate the less-overlapped classifiers with the same learning steps, which corresponds to the time of the point matching.","","978-1-6654-6708-7","10.1109/CEC55065.2022.9870349","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870349","variational autoencoder;data mining","Image color analysis;Evolutionary computation;Gaussian distribution","Gaussian distribution;image matching;learning (artificial intelligence);pattern classification","XCSR;VAE;Gaussian distribution matching;area matching;latent space;less-overlapped rule generation;Learning Classifier System;continuous space;novel matching mechanism;Continuous-Valued Inputs;appropriate classifiers;human-interpretable observation space;human-interpretable classifiers;Gaus-sian distribution;selects;classifier which condition;Gaussian distribution M;point matching;ambiguous classifiers;sampling multiple points;less-overlapped classifiers","","","","11","IEEE","6 Sep 2022","","","IEEE","IEEE Conferences"
"Comparison of Anomaly Detectors: Context Matters","V. Škvára; J. Francå; M. Zorek; T. Pevný; V. Šmídl","Department of Computer Science, Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic; Department of Computer Science, Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic; Department of Computer Science, Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic; Department of Computer Science, Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic; Department of Computer Science, Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic","IEEE Transactions on Neural Networks and Learning Systems","1 Jun 2022","2022","33","6","2494","2507","Deep generative models are challenging the classical methods in the field of anomaly detection nowadays. Every newly published method provides evidence of outperforming its predecessors, sometimes with contradictory results. The objective of this article is twofold: to compare anomaly detection methods of various paradigms with a focus on deep generative models and identification of sources of variability that can yield different results. The methods were compared on popular tabular and image datasets. We identified that the main sources of variability are the experimental conditions: 1) the type of dataset (tabular or image) and the nature of anomalies (statistical or semantic) and 2) strategy of selection of hyperparameters, especially the number of available anomalies in the validation set. Methods perform differently in different contexts, i.e., under a different combination of experimental conditions together with computational time. This explains the variability of the previous results and highlights the importance of careful specification of the context in the publication of a new method. All our code and results are available for download.","2162-2388","","10.1109/TNNLS.2021.3116269","Grantova agentura Ceske Republiky (GACR)(grant numbers:GA18-21409S); Ministerstvo skolstvi, mladeze a telovychovy (MSMT)(grant numbers:CZ.02.1.01/0.0/0.0/16_019/0000765,SGS18/188/OHK4/3T/14); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9569766","Anomaly detection;generative adversarial network (GAN);generative models;normalizing flows;variational autoencoder (VAE)","Anomaly detection;Detectors;Training;Semantics;Biological system modeling;Optimization;Birds","object detection;statistical analysis","anomaly detectors;deep generative models;classical methods;anomaly detection methods;image datasets;tabular dataset;statistical anomaly;semantic anomaly","","","","98","IEEE","13 Oct 2021","","","IEEE","IEEE Journals"
"Joint Graph Attention and Asymmetric Convolutional Neural Network for Deep Image Compression","Z. Tang; H. Wang; X. Yi; Y. Zhang; S. Kwong; C. . -C. J. Kuo","Frontiers Science Center for Intelligent Autonomous Systems, Shanghai, P. R. China; Frontiers Science Center for Intelligent Autonomous Systems, Shanghai, P. R. China; Frontiers Science Center for Intelligent Autonomous Systems, Shanghai, P. R. China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, P. R. China; Department of Computer Science, City University of Hong Kong, Hong Kong, P. R. China; Ming-Hsieh Department of Electrical Engineering, Signal and Image Processing Institute, University of Southern California, Los Angeles, CA, USA","IEEE Transactions on Circuits and Systems for Video Technology","","2022","PP","99","1","1","Recent deep image compression methods have achieved prominent progress by using nonlinear modeling and powerful representation capabilities of neural networks. However, most existing learning-based image compression approaches employ customized convolutional neural network (CNN) to utilize visual features by treating all pixels equally, neglecting the effect of local key features. Meanwhile, the convolutional filters in CNN usually express the local spatial relationship within the receptive field and seldom consider the long-range dependencies from distant locations. This results in the long-range dependencies of latent representations not being fully compressed. To address these issues, an end-to-end image compression method is proposed by integrating graph attention and asymmetric convolutional neural network (ACNN). Specifically, ACNN is used to strengthen the effect of local key features and reduce the cost of model training. Graph attention is introduced into image compression to address the bottleneck problem of CNN in modeling long-range dependencies. Meanwhile, regarding the limitation that existing attention mechanisms for image compression hardly share information, we propose a self-attention approach which allows information flow to achieve reasonable bit allocation. The proposed self-attention approach is in compliance with the perceptual characteristics of human visual system, as information can interact with each other via attention modules. Moreover, the proposed self-attention approach takes into account channel-level relationship and positional information to promote the compression effect of rich-texture regions. Experimental results demonstrate that the proposed method achieves state-of-the-art rate-distortion performances after being optimized by MS-SSIM compared to recent deep compression models on the benchmark datasets of Kodak and Tecnick. The project page with the source code can be found in https://mic.tongji.edu.cn.","1558-2205","","10.1109/TCSVT.2022.3199472","Shanghai Innovation Action Project of Science and Technology(grant numbers:20511100700); Shanghai Municipal Science and Technology Major Project(grant numbers:2021SHZDZX0100); Hong Kong Innovation and Technology Commission (InnoHK Project CIMDA) and Hong Kong GRF-RGC General Research Fund(grant numbers:11203820,11209819); National Natural Science Foundation of China(grant numbers:61976159); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9858899","Image compression;graph attention network;asymmetric convolutional neural network;self-attention;variational autoencoder","Image coding;Convolution;Convolutional neural networks;Training;Kernel;Visualization;Rate-distortion","","","","","","","IEEE","17 Aug 2022","","","IEEE","IEEE Early Access Articles"
"Toward Discriminating and Synthesizing Motion Traces Using Deep Probabilistic Generative Models","F. Zhou; X. Liu; K. Zhang; G. Trajcevski","School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; 360 AI Security Research Labs, University of Electronic Science and Technology of China, Chengdu, China; Department of Decision, Operations and Information Technologies, University of Maryland, College Park, MD, USA; Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, USA","IEEE Transactions on Neural Networks and Learning Systems","2 Jun 2021","2021","32","6","2401","2414","Mining knowledge from human mobility, such as discriminating motion traces left by different anonymous users, also known as the trajectory-user linking (TUL) problem, is an important task in many applications requiring location-based services (LBSs). However, it inevitably raises an issue that may be aggravated by TUL, i.e., how to defend against location attacks (e.g., deanonymization and location recovery). In this work, we present a Semisupervised Trajectory- User Linking model with Interpretable representation and Gaussian mixture prior (STULIG)-a novel deep probabilistic framework for jointly learning disentangled representation of user trajectories in a semisupervised manner and tackling the location recovery problem. STULIG characterizes multiple latent aspects of human trajectories and their labels into separate latent variables, which can be then used to interpret user check-in styles and improve the performance of trace classification. It can also generate synthetic yet plausible trajectories, thus protecting users' actual locations while preserving the meaningful mobility information for various machine learning tasks. We analyze and evaluate STULIG's ability to learn disentangled representations, discriminating human traces and generating realistic motions on several real-world mobility data sets. As demonstrated by extensive experimental evaluations, in addition to outperforming the state-of-the-art methods, our method provides intuitive explanations of the classification and generation and sheds lights on the interpretable mobility mining.","2162-2388","","10.1109/TNNLS.2020.3005325","National Natural Science Foundation of China(grant numbers:61602097,61472064); NSF(grant numbers:1213038); Division of Computer and Network Systems (CNS)(grant numbers:1646107); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9165954","Disentangled representation;location privacy;trace discrimination;variational autoencoder (VAE)","Trajectory;Data models;Hidden Markov models;Computational modeling;Task analysis;Data privacy;Machine learning","data mining;data privacy;Gaussian processes;learning (artificial intelligence);mobile computing;probability","toward discriminating;synthesizing motion traces;deep probabilistic generative models;mining knowledge;human mobility;different anonymous users;trajectory-user linking problem;TUL;location-based services;location attacks;Semisupervised Trajectory- User Linking model;Interpretable representation;Gaussian mixture;disentangled representation;user trajectories;semisupervised manner;location recovery problem;multiple latent aspects;human trajectories;separate latent variables;trace classification;synthetic yet plausible trajectories;meaningful mobility information;machine learning tasks;STULIG's ability;human traces;generating realistic motions;real-world mobility data sets;sheds lights;interpretable mobility mining","","","","67","IEEE","12 Aug 2020","","","IEEE","IEEE Journals"
"Generative Text Convolutional Neural Network for Hierarchical Document Representation Learning","C. Wang; B. Chen; Z. Duan; W. Chen; H. Zhang; M. Zhou","National Lab of Radar Signal Processing, Collaborative Innovation Center of Information Sensing and Understanding, Xidian University, Xi&#x2019;an, Shaanxi, China; National Lab of Radar Signal Processing, Collaborative Innovation Center of Information Sensing and Understanding, Xidian University, Xi&#x2019;an, Shaanxi, China; National Lab of Radar Signal Processing, Collaborative Innovation Center of Information Sensing and Understanding, Xidian University, Xi&#x2019;an, Shaanxi, China; National Lab of Radar Signal Processing, Collaborative Innovation Center of Information Sensing and Understanding, Xidian University, Xi&#x2019;an, Shaanxi, China; Department of Population Health Sciences, Weill Cornell Medicine, NY, USA; McCombs School of Business, The University of Texas at Austin, TX, USA","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2022","PP","99","1","17","For document analysis, existing methods often resort to the document representation that either discards the word order information or projects each word into a low-dimensional dense embedding vector. However, confined by the data’s sparsity and high-dimensionality, limited effort has been made to explore the semantic structures underlying the document representation that formulates each document as a sequence of one-hot vectors, especially in the probabilistic modeling literature. To construct a probabilistic generative model for this type of document representation, we first develop convolutional Poisson factor analysis (CPFA) that not only utilizes the sparse property of data but also enables model parallelism. Through interleaving probabilistic Dirichlet-gamma pooling layers with learnable parameters, we extend the shallow CPFA into a generative text convolutional neural network (GTCNN), which captures richer semantic information with multiple probabilistic convolutional layers and can be coupled with existing deep topic models to alleviate their loss of word order. For efficient and scalable model inference, we not only develop both a parallel upward-downward Gibbs sampler and SG-MCMC based algorithm for training GTCNN, but also construct a hierarchical Weibull convolutional inference network for fast out-of-sample prediction. Experimental results on document representation learning tasks demonstrate the effectiveness of the proposed methods.","1939-3539","","10.1109/TPAMI.2022.3192319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9833334","Document analysis;deep topic models;probabilistic convolutional generative models;variational autoencoder","Probabilistic logic;Computational modeling;Semantics;Analytical models;Task analysis;Vocabulary;Data models","","","","","","","IEEE","19 Jul 2022","","","IEEE","IEEE Early Access Articles"
"Individualizing Head-Related Transfer Functions for Binaural Acoustic Applications","N. H. Zandi; A. M. El-Mohandes; R. Zheng","McMaster University, Hamilton, Canada; Mansoura University, Mansoura, Egypt; McMaster University, Hamilton, Canada","2022 21st ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)","18 Jul 2022","2022","","","105","117","A Head Related Transfer Function (HRTF) characterizes how a hu-man ear receives sounds from a point in space, and depends on the shapes of one's head, pinna, and torso. Accurate estimations of HRTFs for human subjects are crucial in enabling binaural acoustic applications such as sound localization and 3D sound spatialization. Unfortunately, conventional approaches for HRTF estimation rely on specialized devices or lengthy measurement processes. This work proposes a novel lightweight method for HRTF individual-ization that can be implemented using commercial-off-the-shelf components and performed by average users in home settings. The proposed method has two key components: a generative neural network model that can be individualized to predict HRTFs of new subjects from sparse measurements, and a lightweight measurement procedure that collects HRTF data from spatial locations. Exten-sive experiments using a public dataset and in house measurement data from 10 subjects of different ages and genders, show that the individualized models significantly outperform a baseline model in the accuracy of predicted HRTFs. To further demonstrate the advantages of individualized HRTFs, we implement two prototype applications for binaural localization and acoustic spatialization. We find that the performance of a localization model is improved by 15° after trained with individualized HRTFs. Furthermore, in hearing tests, the success rate of correctly identifying the azimuth direction of incoming sounds increases by 183% after individualization.","","978-1-6654-9624-7","10.1109/IPSN54338.2022.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9826065","Head-Related Transfer Function (HRTF);Conditional Variational AutoEncoder (CVAE);Binaural Localization;Sound Spatialization","Location awareness;Torso;Acoustic applications;Neural networks;Data acquisition;Transfer functions;Estimation","acoustic signal processing;audio signal processing;hearing;neural nets;transfer functions","localization model;acoustic spatialization;binaural localization;baseline model;individualized models;house measurement data;spatial locations;HRTF data;lightweight measurement procedure;sparse measurements;generative neural network model;commercial-off-the-shelf components;HRTF individualization;HRTF estimation;3D sound spatialization;sound localization;human subjects;human ear;Head Related Transfer Function;binaural acoustic applications","","","","55","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"Deep Masking Generative Network For Irregularly Sampled Multivariate Time Series","Z. Liu; H. Wang; Y. Zhang; X. Wang","University of Science and Technology of China, Hefei, P. R. China; University of Science and Technology of China, Hefei, P. R. China; University of Science and Technology of China, Hefei, P. R. China; Southwestern University of Finance and Economics, Chengdu, P. R. China","2021 4th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)","4 Oct 2021","2021","","","296","300","Irregularly sampled multivariate time series data arise naturally in many application domain where they present a significant challenge to standard deep learning models, because they do not naturally yield a fixed-dimensional representation. In this paper, we propose a new deep learning framework named Deep Masking Generative Network from the perspective of missing data. And we introduce masking layer and unmasking layer to convert the sampled multivariate time series data into a fixed dimensional temporal representation and obtain the sampled values at any time point respectively. To process continuous time series data efficiently, we further propose continuous convolution layers with tunable kernel width. We investigate the performance of our framework on classification tasks using real datasets. Experiments show that our model performs better than a range of baseline while offering significantly faster training times.","","978-1-6654-1322-0","10.1109/PRAI53619.2021.9551049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9551049","Irregularly sampled multivariate time-series;Generative network;Variational autoencoder;Continuous convolution","Deep learning;Training;Convolution;Time series analysis;Feature extraction;Data models;Data mining","deep learning (artificial intelligence);pattern classification;time series","data classification;deep masking generative network;training times;continuous convolution layers;continuous time series data;sampled values;fixed dimensional temporal representation;unmasking layer;deep learning framework;fixed-dimensional representation;irregularly sampled multivariate time series data","","","","23","IEEE","4 Oct 2021","","","IEEE","IEEE Conferences"
"Trace Data Analytics with Knowledge Distillation : DM: Big Data Management and Mining","J. Lee; W. Xiong; W. Jang","Samsung Display America Lab Samsung Electronics, San Jose, CA, United States; Samsung Display America Lab Samsung Electronics, San Jose, CA, United States; Display Research Center Samsung Display, Yong-In, Korea","2020 31st Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC)","3 Sep 2020","2020","","","1","8","In this paper, we propose the “trace data analytics” for classifying fault conditions from multivariate time series sensor signals using well-known deep CNN models. In our approach, multiple sensor signals are converted into two dimensional representations using the proposed conversion methods to optimize the classification performance. Many studies on the prediction of manufacturing results using sensor signals have been conducted in the field of fault detection and classification for display and semiconductor manufacturing processes. It is challenging to apply machine learning to real-life manufacturing problems due to practical limitations, class imbalance and data insufficiency, which also make it difficult to produce a generalized model. To overcome these challenges, we propose using omni-supervised learning but with a new approach to knowledge distillation that ensembles predictions from multiple instantiations of a CNN model of synthetically generated data samples from a deep generative model. Our experiment results show that the fault classification accuracy improves substantially by applying trace data analytics to manufacturing data from display fabrication lines. The results also show that the quality of trained CNN models using the proposed knowledge distillation is maintained steadily and stably.","2376-6697","978-1-7281-5876-1","10.1109/ASMC49169.2020.9185292","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9185292","Fault classification;Semi-supervised learning;Variational autoencoder;display manufacturing;knowledge distillation","Data models;Predictive models;Manufacturing;Task analysis;Machine learning;Training;Data analysis","Big Data;data analysis;data mining;fault diagnosis;learning (artificial intelligence);manufacturing processes;neural nets;pattern classification;production engineering computing;time series","multiple sensor signals;deep CNN models;multivariate time series sensor signals;classifying fault conditions;trained CNN models;manufacturing data;trace data analytics;fault classification accuracy;deep generative model;synthetically generated data samples;CNN model;knowledge distillation;data insufficiency;class imbalance;real-life manufacturing problems;semiconductor manufacturing processes;fault detection","","","","21","","3 Sep 2020","","","IEEE","IEEE Conferences"
"Nondestructive inspection technology for plant steel structures using magneto-optical images using deep generative models","R. Hashimoto; T. Itaya; H. Nishimura; S. Fukuchi; H. Kato; J. Ito; K. Nakagawa","Department of Electrical and Electronic Engineering; Department of Electronic and Information Engineering, National Institute of Technology (KOSEN), Suzuka College, Suzuka, Mie, Japan; Department of Electrical and Electronic Engineering; Department of Electrical and Electronic Engineering; Advanced Engineering Course of Science and Technology, for Innovation National Institute of Technology (KOSEN), Suzuka College, Suzuka, Mie, Japan; Advanced Engineering Course of Science and Technology, for Innovation National Institute of Technology (KOSEN), Suzuka College, Suzuka, Mie, Japan; Advanced Engineering Course of Science and Technology, for Innovation National Institute of Technology (KOSEN), Suzuka College, Suzuka, Mie, Japan","2021 6th International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS)","29 Dec 2021","2021","6","","10","15","Measures against deterioration of infrastructures that were built during the high economic growth period are facing significant challenges with regard to the maintenance of infrastructures in Japan. The development of optimal nondestructive sensing and imaging technology according to the material and structure of buildings is underway to contribute to efficient and reliable maintenance of infrastructures. However, owing to the large number of materials and structures used for buildings, as well as the types of defects to be targeted, many basic studies are yet to reach the stage of practical use. In this study, we developed a magneto-optical (MO) sensor in order to visualize a “crack” in the plant steel structure and automatically detected the defects in the plant steel structure by performing deep learning on the MO image obtained. As a pretreatment for detecting anomalies in defects using the AI, we focused on the nondestructive inspection using MO imaging and performed an unprecedented image filter processing. As a result, automatically evaluation the several types of MO images using AI, the accuracy of defection identification was improved.","2189-8723","978-1-7281-6714-5","10.1109/ICIIBMS52876.2021.9651658","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9651658","artificial intelligence;variational autoencoder;nondestructive inspection;magneto-optical imaging","Visualization;Biological system modeling;Buildings;Materials reliability;Inspection;Maintenance engineering;Robot sensing systems","building materials;buildings (structures);crack detection;deep learning (artificial intelligence);image processing;image sensors;inspection;magneto-optical sensors;maintenance engineering;nondestructive testing;steel;structural engineering computing","plant steel structure;unprecedented image filter processing;nondestructive inspection technology;magneto-optical images;deep generative models;high economic growth period;optimal nondestructive sensing;building materials;infrastructures maintenance;Japan;magneto-optical sensor;crack visualization;defects detection;deep learning;AI","","","","10","IEEE","29 Dec 2021","","","IEEE","IEEE Conferences"
"Situation-Aware Multivariate Time Series Anomaly Detection Through Active Learning and Contrast VAE-Based Models in Large Distributed Systems","Z. Li; Y. Zhao; Y. Geng; Z. Zhao; H. Wang; W. Chen; H. Jiang; A. Vaidya; L. Su; D. Pei","Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; eBay Inc., San Jose, CA, USA; Department of Computer Science and Technology, Tsinghua University, Beijing, China; eBay Inc., San Jose, CA, USA; Department of Computer Science and Technology, Tsinghua University, Beijing, China; eBay Inc., San Jose, CA, USA; eBay Inc., San Jose, CA, USA; eBay Inc., San Jose, CA, USA; Department of Computer Science and Technology, Tsinghua University, Beijing, China","IEEE Journal on Selected Areas in Communications","19 Aug 2022","2022","40","9","2746","2765","The massive amounts of monitoring data in network applications bring an urgent need for intelligent operation in large distributed systems. The key problem is precisely detecting anomalies in multivariate time series (MTS) monitoring metrics with the awareness of different application scenarios. Unsupervised MTS anomaly detection methods aim at detecting data anomalies from historical MTS without considering the out-of-band information (including user feedback and background information like code deployment status), which leads to poor performance in practice. To take advantage of the out-of-band information, we propose ACVAE, an MTS anomaly detection algorithm through active learning and contrast VAE-based detection models, which simultaneously learns MTS data’s normal and anomalous patterns for anomaly detection. We also use a learnable prior to capture system status from the background information. Moreover, we propose a query model for VAE-based methods, which can learn to query labels of the most useful instances to train the detection model. We evaluate our algorithm on three different monitoring situations in eBay’s search back-end systems. ACVAE achieves a range F1 score of 0.68~0.96 with only 3% labels, significantly outperforming the best competing methods by 0.18~0.50, and even better than a supervised ensemble method designed by domain experts in eBay.","1558-0008","","10.1109/JSAC.2022.3191341","National Key Research and Development Program of China(grant numbers:2019YFB1802504); State Key Program of National Natural Science of China(grant numbers:62072264); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9844802","Anomaly detection;out-of-band information;multivariate time series;active learning;variational autoencoder","Anomaly detection;Measurement;Monitoring;Time series analysis;Task analysis;Data models;Business","data mining;learning (artificial intelligence);pattern classification;security of data;time series","MTS anomaly detection algorithm;active learning;contrast VAE-based detection models;background information;query model;VAE-based methods;detection model;different monitoring situations;eBay's search back-end systems;situation-aware multivariate time series;contrast VAE-based models;distributed systems;network applications;data anomalies;out-of-band information;including user feedback;code deployment status","","","","60","IEEE","29 Jul 2022","","","IEEE","IEEE Journals"
"KGGen: A Generative Approach for Incipient Knowledge Graph Population","H. Chen; C. Zhang; J. Li; P. S. Yu; N. Jing","College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; Amazon, Seattle, WA, USA; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China; Department of Computer Science, University of Illinois at Chicago, Chicago, USA; College of Electronic Science and Technology, National University of Defense Technology, Changsha, China","IEEE Transactions on Knowledge and Data Engineering","1 Apr 2022","2022","34","5","2254","2267","Knowledge graph is becoming an indispensable resource that offers structured information for numerous AI applications. However, the knowledge graph often suffers from its incompleteness. Building a complete, high-quality knowledge graph is time-consuming and requires significant human annotation efforts. In this paper, we study the Knowledge Graph Population task, which aims at extending the scale of structured knowledge, with a special focus on reducing data preparation and annotation efforts. Previous works mainly based on discriminative methods build classifiers and verify candidate triplets that are extracted from texts, which heavily rely on the quality of data collection and co-occurrance of entities in the text. However, such methods fail to generalize on entity pairs that are not highly co-occurred, and fail to discover entity pairs that are not co-occurred at all in the given text corpus. We introduce a generative perspective to approach this task and define each relationship by learning the data distribution that embodies the core common properties for relational reasoning. A generative model KGGen is proposed, which samples from the learned data distribution for each relation and can generate triplets regardless of entity pair co-occurrence in the text corpus. To further improve the generation quality while alleviate human annotation efforts, adversarial learning is adopted to not only encourage generating high quality triplets, but also give model the ability to automatically assess the generation quality. Quantitative and qualitative experimental results conducted on two real-world generic knowledge graphs show that the proposed model KGGen generates novel and meaningful triplets with improved efficiency and less human annotation comparing with the state-of-the-art approaches.","1558-2191","","10.1109/TKDE.2020.3014166","National Natural Science Foundation of China(grant numbers:41871284,61806211,U19A2058); National Science Foundation(grant numbers:III-1526499,III-1763325,III-1909323,SaTC-1930941); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9158381","Knowledge graph population;generative adversarial learning;variational autoencoder;deep bidirectional transformers","Bit error rate;Sociology;Statistics;Decoding;Task analysis;Generators;Training","learning (artificial intelligence);pattern classification;semantic networks;text analysis","generative approach;knowledge graph population;data preparation;data collection;entity pairs;KGGen;data distribution learning;triplets generation;text corpus","","","","56","IEEE","4 Aug 2020","","","IEEE","IEEE Journals"
"GenRadar: Self-Supervised Probabilistic Camera Synthesis Based on Radar Frequencies","C. Ditzel; K. Dietmayer","Institute of Measurement, Control and Microtechnology, Ulm, Germany; Institute of Measurement, Control and Microtechnology, Ulm, Germany","IEEE Access","9 Nov 2021","2021","9","","148994","149042","Autonomous systems require a continuous and dependable environment perception for navigation and decision-making, which is best achieved by combining different sensor types. Radar continues to function robustly in compromised circumstances in which cameras become impaired, guaranteeing a steady inflow of information. Yet, camera images provide a more intuitive and readily applicable impression of the world. This work combines the complementary strengths of both sensor types in a unique self-learning fusion approach for a probabilistic scene reconstruction in adverse surrounding conditions. After reducing the memory requirements of both high-dimensional measurements through a decoupled stochastic self-supervised compression technique, the proposed algorithm exploits similarities and establishes correspondences between both domains at different feature levels during training. Then, at inference time, relying exclusively on radio frequencies, the model successively predicts camera constituents in an autoregressive and self-contained process. These discrete tokens are finally transformed back into an instructive view of the respective surrounding, allowing to visually perceive potential dangers for important tasks downstream.","2169-3536","","10.1109/ACCESS.2021.3120202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9570339","Radar signal processing;computer vision;sensor fusion;deep learning;machine learning;variational autoencoder;self-supervised learning;annotation-free learning;scene understanding","Radar;Cameras;Radar imaging;Robot sensing systems;Probabilistic logic;Task analysis;Signal processing algorithms","feature extraction;image classification;image fusion;image reconstruction;image sensors;image sequences;navigation;object detection;robot vision;stochastic processes;supervised learning","feature levels;inference time;radio frequencies;autoregressive self-contained process;GenRadar;radar frequencies;autonomous systems;continuous environment perception;navigation;decision-making;camera images;readily applicable impression;unique self-learning fusion approach;probabilistic scene reconstruction;memory requirements;high-dimensional measurements;self-supervised compression technique;self-supervised probabilistic camera synthesis","","","","85","CCBY","14 Oct 2021","","","IEEE","IEEE Journals"
"OpenNIG - Open Neural Image Generator","A. -M. Avram; L. Morogan; S. -A. Toma","University Politehnica of Bucharest, UPB, Bucharest, Romania; Military Technical Academy Ferdinand I, MTA, Bucharest, Romania; Military Technical Academy Ferdinand I, MTA, Bucharest, Romania","2020 13th International Conference on Communications (COMM)","16 Jul 2020","2020","","","177","181","Generative models are statistical models that learn a true underlying data distribution from samples using unsupervised learning, aiming to generate new data points with some variation. In this paper, we introduce OpenNIG (Open Neural Image Generator), an open-source neural networks toolkit for image generation. It offers the possibility to easily train, validate and test state of the art models. The framework also contains a module that enables the user to directly download and process some of the most common databases used in deep learning. OpenNIG is freely available via GitHub.","","978-1-7281-5611-8","10.1109/COMM48946.2020.9142009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9142009","image generation;deep convolutional generative adversarial networks;deep convolutional variational autoencoder;generative models","Training;Generators;Gallium nitride;Data models;Machine learning;Tools;Neural networks","image recognition;neural nets;public domain software;statistical analysis;unsupervised learning","OpenNIG;Open Neural Image Generator;generative models;statistical models;data distribution;unsupervised learning;open-source neural networks toolkit;image generation;deep learning","","","","16","","16 Jul 2020","","","IEEE","IEEE Conferences"
"Learning to Disentangle Inter-Subject Anatomical Variations in Electrocardiographic Data","P. K. Gyawali; J. V. Murkute; M. Toloubidokhti; X. Jiang; B. M. Horacek; J. L. Sapp; L. Wang","Stanford University, Stanford, CA, USA; Rochester Institute of Technology, USA; Rochester Institute of Technology, USA; Rochester Institute of Technology, USA; School of Biomedical Engineering, Dalhousie University, Canada; School of Biomedical Engineering, Dalhousie University, Canada; Rochester Institute of Technology, USA","IEEE Transactions on Biomedical Engineering","21 Jan 2022","2022","69","2","860","870","Objective: This work investigates the possibility of disentangled representation learning of inter-subject anatomical variations within electrocardiographic (ECG) data. Methods: Since ground truth anatomical factors are generally not known in clinical ECG for assessing the disentangling ability of the models, the presented work first proposes the SimECG data set, a 12-lead ECG data set procedurally generated with a controlled set of anatomical generative factors. Second, to perform such disentanglement, the presented method evaluates and compares deep generative models with latent density modeled by nonparametric Indian Buffet Process to account for the complex generative process of ECG data. Results: In the simulated data, the experiments demonstrate, for the first time, concrete evidence of the possibility to disentangle key generative anatomical factors within ECG data in separation from task-relevant generative factors. We achieve a disentanglement score of 92.1% while disentangling five anatomical generative factors and the task-relevant generative factor. In both simulated and real-data experiments, this work further provides quantitative evidence for the benefit of disentanglement learning on the downstream clinical task of localizing the origin of ventricular activation. Overall, the presented method achieves an improvement of around 18.5%, and 11.3% for the simulated dataset, and around 7.2%, and 3.6% for the real dataset, over baseline CNN, and standard generative model, respectively. Conclusion: These results demonstrate the importance as well as the feasibility of the disentangled representation learning of inter-subject anatomical variations within ECG data. Significance: This work suggests the important research direction to deal with the well-known challenge posed by the presence of significant inter-subject variations during an automated analysis of ECG data.","1558-2531","","10.1109/TBME.2021.3108164","National Institute of Health; National Heart, Lung, and Blood Institute(grant numbers:R15HL140500,R01HL145590); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9525273","Disentangled representation learning;generative models;variational autoencoder;India Buffet process;electrocardiograms","Electrocardiography;Heart;Task analysis;Data models;Torso;Solid modeling;Geometry","electrocardiography;learning (artificial intelligence);medical signal processing;statistical analysis","inter-subject anatomical variations;electrocardiographic data;disentangled representation learning;ground truth anatomical factors;clinical ECG;disentangling ability;SimECG data;12-lead ECG data;anatomical generative factors;deep generative models;complex generative process;task-relevant generative factor;disentanglement learning;standard generative model;inter-subject variations;baseline CNN","Electrocardiography;Heart Ventricles;Learning;Machine Learning","","","48","IEEE","30 Aug 2021","","","IEEE","IEEE Journals"
"Learned Image Compression With Separate Hyperprior Decoders","Z. Zan; C. Liu; H. Sun; X. Zeng; Y. Fan","State Key Laboratory of ASIC & System, College of Microelectronics, Fudan University, Shanghai, China; State Key Laboratory of ASIC & System, College of Microelectronics, Fudan University, Shanghai, China; JST, PRESTO, Kawaguchi, Japan; State Key Laboratory of ASIC & System, College of Microelectronics, Fudan University, Shanghai, China; State Key Laboratory of Mobile Network and Mobile Multimedia Technology, ZTE Corporation, Shenzhen, China","IEEE Open Journal of Circuits and Systems","22 Nov 2021","2021","2","","627","632","Learned image compression techniques have achieved considerable development in recent years. In this paper, we find that the performance bottleneck lies in the use of a single hyperprior decoder, in which case the ternary Gaussian model collapses to a binary one. To solve this, we propose to use three hyperprior decoders to separate the decoding process of the mixed parameters in discrete Gaussian mixture likelihoods, achieving more accurate parameters estimation. Experimental results demonstrate the proposed method optimized by MS-SSIM achieves on average 3.36% BD-rate reduction compared with state-of-the-art approach. The contribution of the proposed method to the coding time and FLOPs is negligible.","2644-1225","","10.1109/OJCAS.2021.3125354","National Natural Science Foundation of China(grant numbers:62031009); Shanghai Science and Technology Committee (STCSM)(grant numbers:19511104300); Alibaba Innovative Research (AIR) Program; Innovation Program of Shanghai Municipal Education Commission; Fudan University-CIOMP Joint Fund(grant numbers:FC2019-001); Fudan-ZTE Joint Lab; JST, PRESTO, Japan(grant numbers:JPMJPR19M5); Pioneering Project of Academy for Engineering and Technology Fudan University(grant numbers:gyy2021-001); National Key Research and Development Program of China(grant numbers:2019YFB2204403); JSPS KAKENHI(grant numbers:21K17770); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623333","Learned image compression;variational autoencoder;convolutional neural networks;Gaussian mixture model","Convolutional neural networks;Image coding;Parameter estimation;Costs;Circuits and systems;Mixture models;Decoding;Gaussian processes","data compression;decoding;Gaussian processes;image coding;maximum likelihood estimation;parameter estimation","accurate parameters estimation;BD-rate reduction;separate hyperprior decoders;learned image compression techniques;single hyperprior decoder;ternary Gaussian model;decoding process;mixed parameters;discrete Gaussian mixture;MS-SSIM;FLOP;coding time","","","","27","CCBY","22 Nov 2021","","","IEEE","IEEE Journals"
"Semisupervised Training of Deep Generative Models for High-Dimensional Anomaly Detection","Q. Xie; P. Zhang; B. Yu; J. Choi","Department of Computer Science and Engineering, Ulsan National Institute of Science and Technology, Ulsan, South Korea; Graduate School of Artificial Intelligence, KAIST, Daejeon, South Korea; Graduate School of Artificial Intelligence, KAIST, Daejeon, South Korea; Graduate School of Artificial Intelligence, KAIST, Daejeon, South Korea","IEEE Transactions on Neural Networks and Learning Systems","1 Jun 2022","2022","33","6","2444","2453","Abnormal behaviors in industrial systems may be early warnings on critical events that may cause severe damages to facilities and security. Thus, it is important to detect abnormal behaviors accurately and timely. However, the anomaly detection problem is hard to solve in practice, mainly due to the rareness and the expensive cost to get the labels of the anomalies. Deep generative models parameterized by neural networks have achieved state-of-the-art performance in practice for many unsupervised and semisupervised learning tasks. We present a new deep generative model, Latent Enhanced regression/classification Deep Generative Model (LEDGM), for the anomaly detection problem with multidimensional data. Instead of using two-stage decoupled models, we adopt an end-to-end learning paradigm. Instead of conditioning the latent on the class label, LEDGM conditions the label prediction on the learned latent so that the optimization goal is more in favor of better anomaly detection than better reconstruction that the previously proposed deep generative models have been trained for. Experimental results on several synthetic and real-world small- and large-scale datasets demonstrate that LEDGM can achieve improved anomaly detection performance on multidimensional data with very sparse labels. The results also suggest that both labeled anomalies and labeled normal are valuable for semisupervised learning. Generally, our results show that better performance can be achieved with more labeled data. The ablation experiments show that both the original input and the learned latent provide meaningful information for LEDGM to achieve high performance.","2162-2388","","10.1109/TNNLS.2021.3095150","Institute of Information and Communications Technology Planning and Evaluation (IITP) grant funded by the Korea Government (MSIT)(grant numbers:2017-0-01779,2019-0-00075); Korea Evaluation Institute of Industrial Technology (KEIT) grant funded by the Korea Government (MOTIE)(grant numbers:20005062); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9492295","Anomaly detection;deep generative models;semisupervised learning;variational autoencoder (VAE)","Anomaly detection;Data models;Semisupervised learning;Generative adversarial networks;Training;Generators;Unsupervised learning","data handling;neural nets;optimisation;pattern classification;regression analysis;semi-supervised learning (artificial intelligence);unsupervised learning","high-dimensional anomaly detection;abnormal behavior detection;unsupervised learning;semisupervised learning;two-stage decoupled models;end-to-end learning paradigm;labeled anomalies;neural networks;semisupervised training;latent enhanced regression-classification deep generative model;LEDGM;multidimensional data;label prediction;optimization goal","Learning;Neural Networks, Computer;Supervised Machine Learning","","","37","CCBYNCND","21 Jul 2021","","","IEEE","IEEE Journals"
"MTSVAE: A Traffic Data Imputation Model Considering Different Periodic Temporal and Global Spatial Features","Anonymous Authors",NA,"2022 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2022","2022","","","1","8","Traffic data is widely applied in ITS and is required to be complete. Due to detector failures or signal interference, traffic data missing is inevitable. Therefore, it's necessary to deal with traffic data imputation problem. This paper mainly solves the following two problems: 1) Although there are so many algorithms about traffic data imputation, few VAE based algorithms can model different periodic dependencies of traffic data. 2) In traffic data imputation, exploring the complex temporal distribution of the incomplete traffic data plays a significant role in traffic data imputation, but ignored by most researchers. What's more, exploring the global spatial features of incomplete data is also an important problem. In this paper, we propose an end-to-end model MTSVAE which can model different periodic dependencies of traffic data respectively (i.e. hourly-periodic, daily-periodic and weekly-periodic dependencies), to deal with the problem of traffic data imputation. Furthermore, Feature Encoding is put forward in MTSVAE to learn spatial-temporal dependencies of the original data. In Feature Encoding, there are three main components: BiconvGRUI is applied to model the complex temporal distribution of the incomplete traffic data, multi-layers 2D gated convolution are utilized to capture spatial global features of incomplete data, and dual-self-attention mechanism is employed to capture the dynamic spatial-temporal correlations of traffic data. Experiments on three public traffic datasets have proved that our model outperforms most existing data imputation algorithms.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9891988","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9891988","Traffic data imputation;Variational autoencoder;ConvGRU;Attention mechanism;2D gated convolution","Convolution;Heuristic algorithms;Neural networks;Interference;Detectors;Logic gates;Feature extraction","","","","","","21","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"l-mix: a latent-level instance mixup regularization for robust self-supervised speaker representation learning","W. H. Kang; J. Alam; A. Fathan","Computer Research Institute of Montreal, Montreal, Quebec, Canada; Computer Research Institute of Montreal, Montreal, Quebec, Canada; Computer Research Institute of Montreal, Montreal, Quebec, Canada","IEEE Journal of Selected Topics in Signal Processing","","2022","PP","99","1","11","Over the recent years, various self-supervised embedding learning methods for deep speaker verification were proposed. The performance of the self-supervised learning framework highly depends on the data augmentation technique, but due to the sensitive nature of speaker information within the speech signal, most speaker embedding training relies on simple augmentations such as additive noise or simulated reverberation. Thus while the conventional self-supervised speaker embedding systems can yield minimum within-utterance variability, their capability to generalize to out-of-set utterance is limited. In order to alleviate this problem, we investigate the utilization of the instance mix (i-mix) regularization for training a self-supervised speaker embedding system. Moreover, we propose a new mixup strategy that applies i-mix on the latent space, instead of the raw acoustic feature domain. In this paper, the i-mix and the proposed l-mix strategy were incorporated into the self-supervised angular prototypical and softmax-based objective functions and were evaluated on the VoxCeleb dataset. From the experimental results, we observe that the self-supervised embedding network can benefit greatly from the i-mix and l-mix strategies in terms of training stability and speaker verification performance.","1941-0484","","10.1109/JSTSP.2022.3196562","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9850385","speaker verification;speaker embedding;representation learning;variational autoencoder;i-mix regularization","Training;Task analysis;Computer architecture;Feature extraction;Speech recognition;Self-supervised learning;Standards","","","","","","","IEEE","4 Aug 2022","","","IEEE","IEEE Early Access Articles"
"Generative Feature Extraction From Sentinel 1 and 2 Data for Prediction of Forest Aboveground Biomass in the Italian Alps","P. Naik; M. Dalponte; L. Bruzzone","Department of Information Engineering and Computer Science, University of Trento, Trento, Italy; Research and Innovation Center, Fondazione Edmund Mach, San Michele all'Adige, Italy; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","21 Jun 2022","2022","15","","4755","4771","Aboveground biomass (AGB) is an important forest attribute directly linked to the forest carbon pool. The use of satellite remote sensing (RS) data has increased for AGB prediction due to their large footprint and low-cost availability. However, they have been limited due to saturation effect that leads to low prediction precision. In this article, we propose an innovative and dynamic architecture based on generative neural network that extracts target oriented generative features for predicting forest AGB using satellite RS data. These features are more resilient to mixed forest types and geographical conditions as compared to the traditional features and models. The effectiveness of the proposed features was assessed by experiments performed using multispectral, synthetic aperture radar, and combined dual-source datasets. The proposed model achieved best performance in terms of precision, model agreement, and overfitting as compared to the other conventional models for all analyzed datasets. The t-distributed stochastic neighbor embedding scatterplots of the generative features clearly show one dimension of the feature space associated with the target AGB. Feature importance analysis indicated that the produced generative features were more significant than the conventional analytical features. Also, the model provided a robust framework for homogeneous fusion of multisensor features from satellite RS data for predicting AGB.","2151-1535","","10.1109/JSTARS.2022.3179027","European Commission(grant numbers:INEA/CEF/ICT/A2018/1815462); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9785720","Aboveground biomass (AGB);feature extraction;feature fusion;generative features;variational autoencoder","Forestry;Feature extraction;Synthetic aperture radar;Data models;Vegetation;Satellite broadcasting;Mathematical models","forestry;neural nets;synthetic aperture radar;vegetation mapping","model agreement;feature space;target AGB;feature importance analysis;produced generative features;conventional analytical features;multisensor features;satellite RS data;predicting AGB;generative feature extraction;sentinel 1;Sentinel 2 data;forest aboveground biomass;italian alps;important forest;forest carbon pool;satellite remote sensing;AGB prediction;low-cost availability;saturation effect;low prediction precision;innovative architecture;dynamic architecture;generative neural network;forest AGB;mixed forest types;traditional features;multispectral aperture radar;synthetic aperture radar;dual-source datasets","","","","76","CCBY","30 May 2022","","","IEEE","IEEE Journals"
"Enhancement of Unsupervised Object Detection using Supervised Method","D. Basak; D. Ramani; G. Singh","Department of Computer Science and Engineering, National Institute of Technology, Warangal, Telangana, India; Department of Computer Science and Engineering, National Institute of Technology, Warangal, Telangana, India; Department of Computer Science and Engineering, National Institute of Technology, Warangal, Telangana, India","2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)","15 Oct 2020","2020","","","1","9","Reasoning in terms of objects is a critical skill for any intelligent agent. To reason in terms of objects, an agent needs a method for discovering and detecting objects in the visual world. This is achieved through unsupervised object detection. Unsupervised object detection involves the identification of a large number of objects within images, without any supervision or labels. This area has received significantly less attention as compared to its supervised counterpart, which has achieved human-level accuracy. In a lot of cases, labeling each object in the image is impractical and requires a lot of labor. While unsupervised techniques are suitable for the task of object localization, the learner cannot identify the classes of the localized objects unless it is explicitly specified. Combining supervised learning techniques with unsupervised learning techniques can improve the performance of existing algorithms for both detection and classification. In this paper, we have studied a state-of-the-art unsupervised object detection approach and extended it for object classification, by combining it with supervised techniques.","","978-1-7281-6851-7","10.1109/ICCCNT49239.2020.9225318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9225318","Unsupervised Object Detection;Variational Autoencoder (VAE);Evidence Lower Bound (ElBO);Attend-Infer-Repeat (AIR);Spatially Invariant Attend-Infer-Repeat (SPAIR);Spatial Transformer Network (STN)","Computer architecture;Object detection;Task analysis;Microprocessors;Image reconstruction;Training;Object recognition","image classification;learning (artificial intelligence);object detection;pattern classification;unsupervised learning","unsupervised techniques;object localization;localized objects;unsupervised learning techniques;state-of-the-art unsupervised object detection approach;object classification;supervised method;discovering detecting objects","","","","17","","15 Oct 2020","","","IEEE","IEEE Conferences"
"Hyperspectral Unmixing with Spectral Variability Using Endmember Guided Probabilistic Generative Deep Learning","R. B. Lyngdoh; R. Dave; S. S. Anand; T. Ahmad; A. Misra","Space Applications Centre (ISRO), Ahmedabad, Gujarat, India; Anand Agricultural University, Anand, Gujarat, India; Space Applications Centre (ISRO), Ahmedabad, Gujarat, India; Space Applications Centre (ISRO), Ahmedabad, Gujarat, India; Space Applications Centre (ISRO), Ahmedabad, Gujarat, India","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1768","1771","Spectral signatures of the pure constituent materials vary across the hyperspectral image (HSI) due to variable illumination, atmospheric conditions, and intrinsic variability. Using a single endmember to represent the target material (or endmember) with high spectral variability will lead to errors in estimating abundance. Therefore, we propose a probabilistic generative network (PGM-Net) architecture to learn the spectral variability from the HSI (hereinafter referred to as endmember-guided-probabilistic-model-network, EGPGM-Net). The PGM-Net is guided by endmember-network (E-Net) using the parameter sharing strategy. Experimental analysis was carried out on benchmark datasets to compare the performance of the proposed method with the state-of-the-art methods. Moreover, we have also demonstrated the application of EGPGM-Net for estimating the abundance of red and black soil over sparsely vegetated areas using airborne-visible-and -infrared -imaging-spectrometer-next-generation (AVIRISNG) sensor. The quantitative analysis reveals that the proposed method consistently achieves a better unmixing performance than other linear-mixing and deep learning based models in terms of spectral-angle-distance (SAD) and abunance-root-mean-square error (aRMSE). The proposed semi-supervised approach accurately delineated the abundances of red soil, black soil, crop residue, built-up areas and bituminous roads.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884522","Hyperspectral Image;AVIRIS-NG;Red Soil;Black Soil;Variational autoencoder;Unmixing","Deep learning;Statistical analysis;Roads;Crops;Vegetation mapping;Estimation;Soil","deep learning (artificial intelligence);geophysical image processing;hyperspectral imaging;infrared imaging;mean square error methods;probability;semi-supervised learning (artificial intelligence);soil;spectral analysis;vegetation","hyperspectral unmixing;endmember guided probabilistic generative deep learning;spectral signatures;hyperspectral image;HSI;variable illumination;atmospheric conditions;intrinsic variability;spectral variability;endmember-guided-probabilistic-model-network;parameter sharing;black soil;imaging-spectrometer-next-generation sensor;spectral-angle-distance;EGPGM-net;PGM-net;probabilistic generative network architecture;red soil;sparsely vegetated areas;airborne-visible-and-infrared-imaging-spectrometer-next-generation sensor;AVIRISNG;SAD;abunance-root-mean-square error;aRMSE;semisupervised approach;crop residue;bituminous roads","","","","15","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Disentangled Representation Learning for OCTA Vessel Segmentation with Limited Training Data","Y. Liu; A. Carass; L. Zuo; Y. He; S. Han; L. Gregori; S. Murray; R. Mishra; J. Lei; P. A. Calabresi; S. Saidha; J. L. Prince","Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA; Laboratory of Behavioral Neuroscience, National Institute on Aging, National Institute of Health, Baltimore, MD, USA; Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA; Ophthalmology Department, First Affiliated Hospital of Xi&#x2019;an Jiaotong University, Xi&#x2019;an, China; Department of Neurology, Johns Hopkins Hospital, Baltimore, MD, USA; Department of Neurology, Johns Hopkins Hospital, Baltimore, MD, USA; Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA","IEEE Transactions on Medical Imaging","","2022","PP","99","1","1","Optical coherence tomography angiography (OCTA) is an imaging modality that can be used for analyzing retinal vasculature. Quantitative assessment of <italic>en face</italic> OCTA images requires accurate segmentation of the capillaries. Using deep learning approaches for this task faces two major challenges. First, acquiring sufficient manual delineations for training can take hundreds of hours. Second, OCTA images suffer from numerous contrast-related artifacts that are currently inherent to the modality and vary dramatically across scanners. We propose to solve both problems by learning a disentanglement of an anatomy component and a local contrast component from paired OCTA scans. With the contrast removed from the anatomy component, a deep learning model that takes the anatomy component as input can learn to segment vessels with a limited portion of the training images being manually labeled. Our method demonstrates state-of-the-art performance for OCTA vessel segmentation.","1558-254X","","10.1109/TMI.2022.3193029","National Institutes of Health(grant numbers:R01EY032284,R01NS082347); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9834971","Angiography;OCT;OCTA;Variational autoencoder;Vessel segmentation","Image segmentation;Manuals;Training;Decoding;Faces;Three-dimensional displays;Image reconstruction","","","","","","","CCBYNCND","21 Jul 2022","","","IEEE","IEEE Early Access Articles"
"MoEVC: A Mixture of Experts Voice Conversion System With Sparse Gating Mechanism for Online Computation Acceleration","Y. -T. Chang; Y. -H. Yang; Y. -H. Peng; S. -S. Wang; T. -S. Chi; Y. Tsao; H. -M. Wang","Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Academia Sinica, Institute of Information Science, Taiwan; Academia Sinica, Research Center for Information Technology Innovation, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Taiwan; Academia Sinica, Research Center for Information Technology Innovation, Taiwan; Academia Sinica, Institute of Information Science, Taiwan","2021 12th International Symposium on Chinese Spoken Language Processing (ISCSLP)","1 Mar 2021","2021","","","1","5","Owing to the recent advancements in deep learning technology, the performance of voice conversion (VC) in terms of quality and similarity has significantly improved. However, complex computation is generally required for deep-learning-based VC systems. This can cause a notable latency, which limits the deployment of such VC systems in real-world applications. Therefore, increasing the efficiency of online computing has become an important task. In this study, we propose a novel mixture-of-experts (MoE) based VC system, termed MoEVC. The MoEVC system uses a gating mechanism to assign weights to feature maps to increase VC performance. In addition, applying sparse constraints on the gating mechanism can skip some convolution processes through elimination of redundant feature maps, thereby accelerating online computing. Experimental results show that by using proper sparse constraints, we can effectively reduce the FLOPs (floating-point operations) count by 70%, while improving VC performance in both objective evaluation and human subjective listening tests.","","978-1-7281-6994-1","10.1109/ISCSLP49672.2021.9362072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9362072","Voice conversion;variational autoencoder;non-parallel VC;fully convolutional network;mixture of experts","Deep learning;Convolution;Computational modeling;Predictive models;Acceleration;Task analysis","feature extraction;filtering theory;learning (artificial intelligence);signal classification;sparse matrices;speech processing","MoEVC system;VC performance;redundant feature maps;online computing;sparse constraints;experts voice conversion system;sparse gating mechanism;online computation acceleration;deep learning technology;complex computation;deep-learning-based VC systems;notable latency;real-world applications;mixture-of-experts based VC system","","","","42","","1 Mar 2021","","","IEEE","IEEE Conferences"
"Regularized Sequential Latent Variable Models with Adversarial Neural Networks","J. Huang; M. Xiao","the Division of Information Science and Engineering, KTH Royal Institute of Technology, Stockholm, Sweden; the Division of Information Science and Engineering, KTH Royal Institute of Technology, Stockholm, Sweden","2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA)","25 Jan 2022","2021","","","834","839","The highly structured sequential data, such as from speech and handwriting, often contain complex relationships between the underlaying variational factors and the observed data. This paper will present different ways of using high level latent random variables in RNN to model the variability in the sequential data. We have developed the two-steps training algorithms of such RNN model under the VAE (Variational Autoencoder) principle. We proposed novel approach of using adversarial training to regularize the latent variable distributions in the variational RNN model. Contrary to competing approaches, our approach has theoretical optimum in the model training and provides better model training stability. Our approach also improves the posterior approximation in the variational inference network by a separated adversarial training step. Numerical results simulated from TIMIT speech data show that reconstruction loss and evidence lower bound converge to the same level and adversarial training loss converges to 0.","","978-1-6654-4337-1","10.1109/ICMLA52953.2021.00138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9680153","GAN;autoencoder;variatonal recurrent model","Training;Conferences;Neural networks;Machine learning;Approximation algorithms;Stability analysis;Data models","","","","","","26","","25 Jan 2022","","","IEEE","IEEE Conferences"
"Collaborative Generative Adversarial Network for Recommendation Systems","Y. Tong; Y. Luo; Z. Zhang; S. Sadiq; P. Cui","The University of Queensland, Australia; The University of Queensland, Australia; The University of Queensland, Australia; The University of Queensland, Australia; Tsinghua University, China","2019 IEEE 35th International Conference on Data Engineering Workshops (ICDEW)","1 Jul 2019","2019","","","161","168","Recommendation systems have been a core part of daily Internet life. Conventional recommendation models hardly defend adversaries due to the natural noise like misclicking. Recent researches on GAN-based recommendation systems can improve the robustness of the learning models, yielding the state-of-the-art performance. The basic idea is to adopt an interplay minimax game on two recommendation systems by picking negative samples as fake items and employ reinforcement learning policy. However, such strategy may lead to mode collapse and result in high vulnerability to adversarial perturbations on its model parameters. In this paper, we propose a new collaborative framework, namely Collaborative Generative Adversarial Network (CGAN), which adopts Variational Auto-encoder (VAE) as the generator and performs adversarial training in the continuous embedding space. The formulation of CGAN has two advantages: 1) its auto-encoder takes the role of generator to mimic the true distribution of users preferences over items by capturing subtle latent factors underlying user-item interactions; 2) the adversarial training in continuous space enhances models robustness and performance. Extensive experiments conducted on two real-world benchmark recommendation datasets demonstrate the superior performance of our CGAN in comparison with the state-of-the-art GAN-based methods.","2473-3490","978-1-7281-0890-2","10.1109/ICDEW.2019.00-16","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8750926","Collaborative Filter;Adversarial Training;Autoencoder, Recommendation Systems","Generative adversarial networks;Generators;Training;Gallium nitride;Robustness;Collaboration;Feature extraction","game theory;Internet;learning (artificial intelligence);minimax techniques;recommender systems","adversaries;GAN-based recommendation systems;learning models;reinforcement learning policy;adversarial perturbations;model parameters;collaborative framework;CGAN;real-world benchmark recommendation datasets;Internet;adversarial training;GAN-based methods;collaborative generative adversarial network;variational auto-encoder;continuous embedding space;user preferences;minimax game","","4","","23","","1 Jul 2019","","","IEEE","IEEE Conferences"
"Review of Deep Learning Algorithms and Architectures","A. Shrestha; A. Mahmood","Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, USA; Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, USA","IEEE Access","29 Apr 2019","2019","7","","53040","53065","Deep learning (DL) is playing an increasingly important role in our lives. It has already made a huge impact in areas, such as cancer diagnosis, precision medicine, self-driving cars, predictive forecasting, and speech recognition. The painstakingly handcrafted feature extractors used in traditional learning, classification, and pattern recognition systems are not scalable for large-sized data sets. In many cases, depending on the problem complexity, DL can also overcome the limitations of earlier shallow networks that prevented efficient training and abstractions of hierarchical representations of multi-dimensional training data. Deep neural network (DNN) uses multiple (deep) layers of units with highly optimized algorithms and architectures. This paper reviews several optimization methods to improve the accuracy of the training and to reduce training time. We delve into the math behind training algorithms used in recent deep networks. We describe current shortcomings, enhancements, and implementations. The review also covers different types of deep architectures, such as deep convolution networks, deep residual networks, recurrent neural networks, reinforcement learning, variational autoencoders, and others.","2169-3536","","10.1109/ACCESS.2019.2912200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8694781","Machine learning algorithm;optimization;artificial intelligence;deep neural network architectures;convolution neural network;backpropagation;supervised and unsupervised learning","Deep learning;Training;Computer architecture;Feature extraction;Recurrent neural networks;Feedforward neural networks","learning (artificial intelligence);neural nets;optimisation","cancer diagnosis;precision medicine;self-driving cars;predictive forecasting;speech recognition;painstakingly handcrafted feature extractors;pattern recognition systems;large-sized data sets;multidimensional training data;deep neural network;optimization methods;deep architectures;deep convolution networks;deep residual networks;recurrent neural networks;reinforcement learning;deep learning algorithms;classification systems;DL;variational autoencoders","","349","1","96","OAPA","22 Apr 2019","","","IEEE","IEEE Journals"
"Semisupervised Deep Reinforcement Learning in Support of IoT and Smart City Services","M. Mohammadi; A. Al-Fuqaha; M. Guizani; J. -S. Oh","Department of Computer Science, Western Michigan University, Kalamazoo, MI, USA; Department of Computer Science, Western Michigan University, Kalamazoo, MI, USA; Department of Electrical and Computer Engineering, University of Idaho, Moscow, ID, USA; Department of Civil and Construction Engineering, Western Michigan University, Kalamazoo, MI, USA","IEEE Internet of Things Journal","10 Apr 2018","2018","5","2","624","635","Smart services are an important element of the smart cities and the Internet of Things (IoT) ecosystems where the intelligence behind the services is obtained and improved through the sensory data. Providing a large amount of training data is not always feasible; therefore, we need to consider alternative ways that incorporate unlabeled data as well. In recent years, deep reinforcement learning (DRL) has gained great success in several application domains. It is an applicable method for IoT and smart city scenarios where auto-generated data can be partially labeled by users' feedback for training purposes. In this paper, we propose a semisupervised DRL model that fits smart city applications as it consumes both labeled and unlabeled data to improve the performance and accuracy of the learning agent. The model utilizes variational autoencoders as the inference engine for generalizing optimal policies. To the best of our knowledge, the proposed model is the first investigation that extends DRL to the semisupervised paradigm. As a case study of smart city applications, we focus on smart buildings and apply the proposed model to the problem of indoor localization based on Bluetooth low energy signal strength. Indoor localization is the main component of smart city services since people spend significant time in indoor environments. Our model learns the best action policies that lead to a close estimation of the target locations with an improvement of 23% in terms of distance to the target and at least 67% more received rewards compared to the supervised DRL model.","2327-4662","","10.1109/JIOT.2017.2712560","NPRP from the Qatar National Research Fund (a member of Qatar Foundation)(grant numbers:# [7-1113-1-199]); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7945258","Bluetooth low energy indoor localization;deep learning;deep reinforcement learning (DRL);indoor positioning;Internet of Things (IoT);IoT smart services;reinforcement learning;semisupervised deep reinforcement learning;smart city","Learning (artificial intelligence);Smart cities;Hidden Markov models;Internet of Things;Games;Data models;Smart buildings","Bluetooth;indoor radio;Internet of Things;learning (artificial intelligence);smart cities","IoT;sensory data;training data;deep reinforcement learning;application domains;smart city scenarios;semisupervised DRL model;smart city applications;labeled data;unlabeled data;learning agent;smart buildings;smart city services;supervised DRL model;Internet of Things ecosystems;variational autoencoders;inference engine;indoor localization;Bluetooth low energy signal strength","","202","","42","IEEE","9 Jun 2017","","","IEEE","IEEE Journals"
"Dual Motion GAN for Future-Flow Embedded Video Prediction","X. Liang; L. Lee; W. Dai; E. P. Xing",Carnegie Mellon University; Carnegie Mellon University; Petuum Inc.; Petuum Inc.,"2017 IEEE International Conference on Computer Vision (ICCV)","25 Dec 2017","2017","","","1762","1770","Future frame prediction in videos is a promising avenue for unsupervised video representation learning. Video frames are naturally generated by the inherent pixel flows from preceding frames based on the appearance and motion dynamics in the video. However, existing methods focus on directly hallucinating pixel values, resulting in blurry predictions. In this paper, we develop a dual motion Generative Adversarial Net (GAN) architecture, which learns to explicitly enforce future-frame predictions to be consistent with the pixel-wise flows in the video through a dual-learning mechanism. The primal future-frame prediction and dual future-flow prediction form a closed loop, generating informative feedback signals to each other for better video prediction. To make both synthesized future frames and flows indistinguishable from reality, a dual adversarial training method is proposed to ensure that the future-flow prediction is able to help infer realistic future-frames, while the future-frame prediction in turn leads to realistic optical flows. Our dual motion GAN also handles natural motion uncertainty in different pixel locations with a new probabilistic motion encoder, which is based on variational autoencoders. Extensive experiments demonstrate that the proposed dual motion GAN significantly outperforms state-of-the-art approaches on synthesizing new video frames and predicting future flows. Our model generalizes well across diverse visual scenes and shows superiority in unsupervised video representation learning.","2380-7504","978-1-5386-1032-9","10.1109/ICCV.2017.194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8237456","","Gallium nitride;Generators;Probabilistic logic;Training;Learning systems;Predictive models;Computer architecture","image motion analysis;image representation;image sequences;probability;unsupervised learning;video coding","dual adversarial training method;realistic optical flows;natural motion uncertainty;video frames;unsupervised video representation learning;future-flow embedded video prediction;dual motion Generative Adversarial Net architecture;dual-learning mechanism;dual future-flow prediction;dual motion GAN architecture;probabilistic motion encoder;variational autoencoders","","170","","37","","25 Dec 2017","","","IEEE","IEEE Conferences"
"Generalized Zero-Shot Learning via Synthesized Examples","V. K. Verma; G. Arora; A. Mishra; P. Rai","Indian Institute of Technology, Kanpur; Indian Institute of Technology, Kanpur; Indian Institute of Technology, Madras; Indian Institute of Technology, Kanpur","2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition","16 Dec 2018","2018","","","4281","4289","We present a generative framework for generalized zero-shot learning where the training and test classes are not necessarily disjoint. Built upon a variational autoencoder based architecture, consisting of a probabilistic encoder and a probabilistic conditional decoder, our model can generate novel exemplars from seen/unseen classes, given their respective class attributes. These exemplars can subsequently be used to train any off-the-shelf classification model. One of the key aspects of our encoder-decoder architecture is a feedback-driven mechanism in which a discriminator (a multivariate regressor) learns to map the generated exemplars to the corresponding class attribute vectors, leading to an improved generator. Our model's ability to generate and leverage examples from unseen classes to train the classification model naturally helps to mitigate the bias towards predicting seen classes in generalized zero-shot learning settings. Through a comprehensive set of experiments, we show that our model outperforms several state-of-the-art methods, on several benchmark datasets, for both standard as well as generalized zero-shot learning.","2575-7075","978-1-5386-6420-9","10.1109/CVPR.2018.00450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8578548","","Generators;Training;Predictive models;Computer architecture;Probabilistic logic;Decoding;Image reconstruction","encoding;learning (artificial intelligence);pattern classification;regression analysis;vectors","generalized zero-shot learning;generative framework;variational autoencoder based architecture;probabilistic encoder;probabilistic conditional decoder;seen/unseen classes;off-the-shelf classification model;encoder-decoder architecture;class attributes;feedback-driven mechanism;class attribute vectors;multivariate regressor","","117","1","36","","16 Dec 2018","","","IEEE","IEEE Conferences"
"Learning Sampling Distributions for Robot Motion Planning","B. Ichter; J. Harrison; M. Pavone","Department of Aeronautics and Astronautics, Stanford University, Stanford, CA; Department of Mechanical Engineering, Stanford University, Stanford, CA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA","2018 IEEE International Conference on Robotics and Automation (ICRA)","13 Sep 2018","2018","","","7087","7094","A defining feature of sampling-based motion planning is the reliance on an implicit representation of the state space, which is enabled by a set of probing samples. Traditionally, these samples are drawn either probabilistically or deterministically to uniformly cover the state space. Yet, the motion of many robotic systems is often restricted to “small” regions of the state space, due to e.g. differential constraints or collision-avoidance constraints. To accelerate the planning process, it is thus desirable to devise non-uniform sampling strategies that favor sampling in those regions where an optimal solution might lie. This paper proposes a methodology for nonuniform sampling, whereby a sampling distribution is learned from demonstrations, and then used to bias sampling. The sampling distribution is computed through a conditional variational autoencoder, allowing sample generation from the latent space conditioned on the specific planning problem. This methodology is general, can be used in combination with any sampling-based planner, and can effectively exploit the underlying structure of a planning problem while maintaining the theoretical guarantees of sampling-based approaches. Specifically, on several planning problems, the proposed methodology is shown to effectively learn representations for the relevant regions of the state space, resulting in an order of magnitude improvement in terms of success rate and convergence to the optimal cost.","2577-087X","978-1-5386-3081-5","10.1109/ICRA.2018.8460730","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8460730","","Planning;Robots;Probabilistic logic;Manifolds;Collision avoidance;Feature extraction;Acceleration","collision avoidance;mobile robots;sampling methods","robot motion planning;sampling-based motion planning;collision-avoidance;variational autoencoder;bias sampling","","103","","34","","13 Sep 2018","","","IEEE","IEEE Conferences"
"Combining Noise-to-Image and Image-to-Image GANs: Brain MR Image Augmentation for Tumor Detection","C. Han; L. Rundo; R. Araki; Y. Nagano; Y. Furukawa; G. Mauri; H. Nakayama; H. Hayashi","Department of Radiology, University of Cambridge, Cambridge, U.K.; Department of Informatics, Systems and Communication, University of Milano-Bicocca, Milan, Italy; Machine Perception and Robotics Group, Graduate School of Engineering, Chubu University, Kasugai, Japan; Machine Perception Group, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Psychiatry, Jikei University School of Medicine, Tokyo, Japan; Department of Informatics, Systems and Communication, University of Milano-Bicocca, Milan, Italy; International Research Center for Neurointelligence (WPI-IRCN), Institutes for Advanced Study, The University of Tokyo, Tokyo, Japan; Department of Advanced Information Technology, Human Interface Laboratory, Kyushu University, Fukuoka, Japan","IEEE Access","4 Nov 2019","2019","7","","156966","156977","Convolutional Neural Networks (CNNs) achieve excellent computer-assisted diagnosis with sufficient annotated training data. However, most medical imaging datasets are small and fragmented. In this context, Generative Adversarial Networks (GANs) can synthesize realistic/diverse additional training images to fill the data lack in the real image distribution; researchers have improved classification by augmenting data with noise-to-image (e.g., random noise samples to diverse pathological images) or image-to-image GANs (e.g., a benign image to a malignant one). Yet, no research has reported results combining noise-to-image and image-to-image GANs for further performance boost. Therefore, to maximize the DA effect with the GAN combinations, we propose a two-step GAN-based DA that generates and refines brain Magnetic Resonance (MR) images with/without tumors separately: (i) Progressive Growing of GANs (PGGANs), multi-stage noise-to-image GAN for high-resolution MR image generation, first generates realistic/diverse 256×256 images; (ii) Multimodal UNsupervised Image-to-image Translation (MUNIT) that combines GANs/Variational AutoEncoders or SimGAN that uses a DA-focused GAN loss, further refines the texture/shape of the PGGAN-generated images similarly to the real ones. We thoroughly investigate CNN-based tumor classification results, also considering the influence of pre-training on ImageNet and discarding weird-looking GAN-generated images. The results show that, when combined with classic DA, our two-step GAN-based DA can significantly outperform the classic DA alone, in tumor detection (i.e., boosting sensitivity 93.67% to 97.48%) and also in other medical imaging tasks.","2169-3536","","10.1109/ACCESS.2019.2947606","Qdai-jump Research Program; Japan Society for the Promotion of Science(grant numbers:JP17K12752); Japan Agency for Medical Research and Development(grant numbers:JP18lk1010028); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869751","Data augmentation;synthetic image generation;GANs;brain MRI;tumor detection","Gallium nitride;Training;Tumors;Generative adversarial networks;Medical diagnostic imaging;Image synthesis","biomedical MRI;brain;convolutional neural nets;image classification;image coding;image resolution;image segmentation;image texture;learning (artificial intelligence);medical image processing;tumours","medical imaging datasets;image distribution;diverse pathological images;benign image;GAN combinations;two-step GAN-based DA;high-resolution MR image generation;multimodal unsupervised image-to-image translation;GAN-generated images;medical imaging tasks;brain magnetic resonance images;image-to-image GAN;brain MR image augmentation;tumor detection;convolutional neural networks;computer-assisted diagnosis;generative adversarial networks;multistage noise-to-image GAN;GAN-variational autoencoders;SimGAN;PGGAN-generated image texture;CNN-based tumor classification;ImageNet","","66","","53","CCBY","16 Oct 2019","","","IEEE","IEEE Journals"
"Zero-VAE-GAN: Generating Unseen Features for Generalized and Transductive Zero-Shot Learning","R. Gao; X. Hou; J. Qin; J. Chen; L. Liu; F. Zhu; Z. Zhang; L. Shao","School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; Inception Institute of Artificial Intelligence, Abu Dhabi, UAE; Inception Institute of Artificial Intelligence, Abu Dhabi, UAE; Inception Institute of Artificial Intelligence, Abu Dhabi, UAE; Inception Institute of Artificial Intelligence, Abu Dhabi, UAE; School of Computer Science and Technology, Soochow University, Suzhou, China; Inception Institute of Artificial Intelligence, Abu Dhabi, UAE","IEEE Transactions on Image Processing","29 Jan 2020","2020","29","","3665","3680","Zero-shot learning (ZSL) is a challenging task due to the lack of unseen class data during training. Existing works attempt to establish a mapping between the visual and class spaces through a common intermediate semantic space. The main limitation of existing methods is the strong bias towards seen class, known as the domain shift problem, which leads to unsatisfactory performance in both conventional and generalized ZSL tasks. To tackle this challenge, we propose to convert ZSL to the conventional supervised learning by generating features for unseen classes. To this end, a joint generative model that couples variational autoencoder (VAE) and generative adversarial network (GAN), called Zero-VAE-GAN, is proposed to generate high-quality unseen features. To enhance the class-level discriminability, an adversarial categorization network is incorporated into the joint framework. Besides, we propose two self-training strategies to augment unlabeled unseen features for the transductive extension of our model, addressing the domain shift problem to a large extent. Experimental results on five standard benchmarks and a large-scale dataset demonstrate the superiority of our generative model over the state-of-the-art methods for conventional, especially generalized ZSL tasks. Moreover, the further improvement of the transductive setting demonstrates the effectiveness of the proposed self-training strategies.","1941-0042","","10.1109/TIP.2020.2964429","National Natural Science Foundation of China(grant numbers:61872286,61672365,61701391); National Key R&D Program of China(grant numbers:2017YFF0107700); Natural Science Basic Research Plan in Shaanxi Province of China(grant numbers:2018JM6092); Fundamental Research Funds for the Central Universities(grant numbers:JZ2019HGPA0102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8957359","Zero-shot learning;generative model;self-training","Semantics;Task analysis;Training;Gallium nitride;Visualization;Image reconstruction;Data models","image representation;learning (artificial intelligence);neural nets","visual spaces;class spaces;class-level discriminability enhancement;high-quality unseen feature generation;variational autoencoder;supervised learning;intermediate semantic space;generalized zero-shot learning;transductive zero-shot learning;zero-VAE-GAN;unseen class data;transductive extension;self-training strategies;adversarial categorization network;generative adversarial network;joint generative model;generalized ZSL tasks;domain shift problem","","44","1","93","IEEE","13 Jan 2020","","","IEEE","IEEE Journals"
"A Privacy-Preserving-Framework-Based Blockchain and Deep Learning for Protecting Smart Power Networks","M. Keshk; B. Turnbull; N. Moustafa; D. Vatsalan; K. -K. R. Choo","School of Engineering and Information Technology, University of New South Wales, Canberra, Australia; School of Engineering and Information Technology, University of New South Wales, Canberra, Australia; School of Engineering and Information Technology, University of New South Wales, Canberra, Australia; Information Security and Privacy Group, Data61-CSIRO, Eveleigh, Australia; Department of Information Systems and Cyber Security, University of Texas at San Antonio, San Antonio, USA","IEEE Transactions on Industrial Informatics","29 Apr 2020","2020","16","8","5110","5118","Modern power systems depend on cyber-physical systems to link physical devices and control technologies. A major concern in the implementation of smart power networks is to minimize the risk of data privacy violation (e.g., by adversaries using data poisoning and inference attacks). In this article, we propose a privacy-preserving framework to achieve both privacy and security in smart power networks. The framework includes two main modules: a two-level privacy module and an anomaly detection module. In the two-level privacy module, an enhanced-proof-of-work-technique-based blockchain is designed to verify data integrity and mitigate data poisoning attacks, and a variational autoencoder is simultaneously applied for transforming data into an encoded format for preventing inference attacks. In the anomaly detection module, a long short-term memory deep learning technique is used for training and validating the outputs of the two-level privacy module using two public datasets. The results highlight that the proposed framework can efficiently protect data of smart power networks and discover abnormal behaviors, in comparison to several state-of-the-art techniques.","1941-0050","","10.1109/TII.2019.2957140","University of New South Wales(grant numbers:PS51776); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918446","Anomaly detection;blockchain;cyber-physical system (CPS);deep learning;privacy preservation;proof of work (PoW)","Data privacy;Machine learning;Power systems;Anomaly detection;Privacy","computer network security;cryptocurrencies;cyber-physical systems;data integrity;data privacy;distributed databases;learning (artificial intelligence);neural nets","data integrity;inference attacks;anomaly detection module;two-level privacy module;privacy-preserving-framework-based blockchain;modern power systems;cyber-physical systems;physical devices;data privacy violation;enhanced-proof-of-work-technique-based blockchain;data poisoning attacks mitigation;variational autoencoder;long short-term memory deep learning technique;smart power networks data protection","","44","","28","IEEE","2 Dec 2019","","","IEEE","IEEE Journals"
"Modeling Facial Geometry Using Compositional VAEs","T. Bagautdinov; C. Wu; J. Saragih; P. Fua; Y. Sheikh","Ecole Polytechnique Federale de Lausanne; Pacebook Reality Labs, Pittsburgh; Pacebook Reality Labs, Pittsburgh; Ecole Polytechnique Federale de Lausanne; Pacebook Reality Labs, Pittsburgh","2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition","16 Dec 2018","2018","","","3877","3886","We propose a method for learning non-linear face geometry representations using deep generative models. Our model is a variational autoencoder with multiple levels of hidden variables where lower layers capture global geometry and higher ones encode more local deformations. Based on that, we propose a new parameterization of facial geometry that naturally decomposes the structure of the human face into a set of semantically meaningful levels of detail. This parameterization enables us to do model fitting while capturing varying level of detail under different types of geometrical constraints.","2575-7075","978-1-5386-6420-9","10.1109/CVPR.2018.00408","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8578506","","Face;Geometry;Deformable models;Shape;Three-dimensional displays;Data models;Solid modeling","face recognition;image representation;learning (artificial intelligence)","human face;compositional VAEs;nonlinear face geometry representations;deep generative models;variational autoencoder;facial geometry modeling;geometrical constraints","","38","","39","","16 Dec 2018","","","IEEE","IEEE Conferences"
"Monocular 3D Human Pose Estimation by Generation and Ordinal Ranking","S. Sharma; P. T. Varigonda; P. Bindal; A. Sharma; A. Jain","Max Planck Institute for Informatics, Saarbrücken; Axogyan AI, Bangalore; Indian Institute of Technology, Bombay; Axogyan AI, Bangalore; Axogyan AI, Bangalore","2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","2325","2334","Monocular 3D human-pose estimation from static images is a challenging problem, due to the curse of dimensionality and the ill-posed nature of lifting 2D-to-3D. In this paper, we propose a Deep Conditional Variational Autoencoder based model that synthesizes diverse anatomically plausible 3D-pose samples conditioned on the estimated 2D-pose. We show that CVAE-based 3D-pose sample set is consistent with the 2D-pose and helps tackling the inherent ambiguity in 2D-to-3D lifting. We propose two strategies for obtaining the final 3D pose- (a) depth-ordering/ordinal relations to score and weight-average the candidate 3D-poses, referred to as OrdinalScore, and (b) with supervision from an Oracle. We report close to state-of-the-art results on two benchmark datasets using OrdinalScore, and state-of-the-art results using the Oracle. We also show that our pipeline yields competitive results without paired image-to-3D annotations. The training and evaluation code is available at https://github.com/ssfootball04/generative_pose.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.00241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9008113","","Three-dimensional displays;Two dimensional displays;Training;Estimation;Solid modeling;Decoding;Heating systems","learning (artificial intelligence);neural nets;pose estimation;solid modelling;stereo image processing","monocular 3D human pose estimation;image-to-3D annotations;deep conditional variational autoencoder based model;ordinal ranking;static images;3D-pose samples;CVAE-based 3D-pose sample set;2D-to-3D lifting;depth-ordering/ordinal relations;OrdinalScore","","38","","48","","27 Feb 2020","","","IEEE","IEEE Conferences"
"VV-Net: Voxel VAE Net With Group Convolutions for Point Cloud Segmentation","H. -Y. Meng; L. Gao; Y. -K. Lai; D. Manocha","University of Maryland, College Park, MD, USA; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Beijing, China; School of Computer Science & Informatics, Cardiff University, Cardiff, UK; University of Maryland, College Park, MD, USA","2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","8499","8507","We present a novel algorithm for point cloud segmentation. Our approach transforms unstructured point clouds into regular voxel grids, and further uses a kernel-based interpolated variational autoencoder (VAE) architecture to encode the local geometry within each voxel. Traditionally, the voxel representation only comprises Boolean occupancy information which fails to capture the sparsely distributed points within voxels in a compact manner. In order to handle sparse distributions of points, we further employ radial basis functions (RBF) to compute a local, continuous representation within each voxel. Our approach results in a good volumetric representation that effectively tackles noisy point cloud datasets and is more robust for learning. Moreover, we further introduce group equivariant CNN to 3D, by defining the convolution operator on a symmetry group acting on Z3 and its isomorphic sets. This improves the expressive capacity without increasing parameters, leading to more robust segmentation results. We highlight the performance on standard benchmarks and show that our approach outperforms state-of-the-art segmentation algorithms on the ShapeNet and S3DIS datasets.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.00859","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010292","","Three-dimensional displays;Feature extraction;Convolution;Robustness;Machine learning;Semantics;Task analysis","Boolean algebra;computer vision;convolutional neural nets;geometry;image representation;image segmentation;interpolation;learning (artificial intelligence);radial basis function networks","VV-net;group convolutions;point cloud segmentation;voxel grids;kernel-based interpolated variational autoencoder architecture;local geometry;voxel representation;Boolean occupancy information;volumetric representation;group equivariant CNN;voxel VAE Net;radial basis functions","","37","","31","","27 Feb 2020","","","IEEE","IEEE Conferences"
"Anticipating Many Futures: Online Human Motion Prediction and Generation for Human-Robot Interaction","J. Bütepage; H. Kjellström; D. Kragic","Authors are with the Robotics, Perception and Learning Lab (RPL), Sweden; Authors are with the Robotics, Perception and Learning Lab (RPL), Sweden; Authors are with the Robotics, Perception and Learning Lab (RPL), Sweden","2018 IEEE International Conference on Robotics and Automation (ICRA)","13 Sep 2018","2018","","","4563","4570","Fluent and safe interactions of humans and robots require both partners to anticipate the others' actions. The bottleneck of most methods is the lack of an accurate model of natural human motion. In this work, we present a conditional variational autoencoder that is trained to predict a window of future human motion given a window of past frames. Using skeletal data obtained from RGB depth images, we show how this unsupervised approach can be used for online motion prediction for up to 1660 ms. Additionally, we demonstrate online target prediction within the first 300-500 ms after motion onset without the use of target specific training data. The advantage of our probabilistic approach is the possibility to draw samples of possible future motion patterns. Finally, we investigate how movements and kinematic cues are represented on the learned low dimensional manifold.","2577-087X","978-1-5386-3081-5","10.1109/ICRA.2018.8460651","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8460651","","Trajectory;Task analysis;Robot kinematics;Predictive models;Computational modeling;Training data","human-robot interaction;image coding;image colour analysis;image motion analysis;image representation;probability;robot vision","motion patterns;kinematic cues;natural human motion;human-robot interaction;online human motion prediction;target prediction;RGB depth images;skeletal data;conditional variational autoencoder;time 300.0 ms to 500.0 ms","","32","","24","","13 Sep 2018","","","IEEE","IEEE Conferences"
"LayoutVAE: Stochastic Scene Layout Generation From a Label Set","A. A. Jyothi; T. Durand; J. He; L. Sigal; G. Mori",Borealis AI; Borealis AI; Borealis AI; Borealis AI; Borealis AI,"2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","9894","9903","Recently there is an increasing interest in scene generation within the research community. However, models used for generating scene layouts from textual description largely ignore plausible visual variations within the structure dictated by the text. We propose LayoutVAE, a variational autoencoder based framework for generating stochastic scene layouts. LayoutVAE is a versatile modeling framework that allows for generating full image layouts given a label set, or per label layouts for an existing image given a new label. In addition, it is also capable of detecting unusual layouts, potentially providing a way to evaluate layout generation problem. Extensive experiments on MNIST-Layouts and challenging COCO 2017 Panoptic dataset verifies the effectiveness of our proposed framework.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.00999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010959","","Layout;Stochastic processes;Semantics;Image generation;Gallium nitride;Predictive models;Three-dimensional displays","object detection","LayoutVAE;label set;textual description;plausible visual variations;variational autoencoder based framework;image layouts;label layouts;stochastic scene layout generation;MNIST-layouts","","31","","31","","27 Feb 2020","","","IEEE","IEEE Conferences"
"Binge Watching: Scaling Affordance Learning from Sitcoms","X. Wang; R. Girdhar; A. Gupta","The Robotics Institute, Carnegie Mellon University; The Robotics Institute, Carnegie Mellon University; The Robotics Institute, Carnegie Mellon University","2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","9 Nov 2017","2017","","","3366","3375","In recent years, there has been a renewed interest in jointly modeling perception and action. At the core of this investigation is the idea of modeling affordances. However, when it comes to predicting affordances, even the state of the art approaches still do not use any ConvNets. Why is that? Unlike semantic or 3D tasks, there still does not exist any large-scale dataset for affordances. In this paper, we tackle the challenge of creating one of the biggest dataset for learning affordances. We use seven sitcoms to extract a diverse set of scenes and how actors interact with different objects in the scenes. Our dataset consists of more than 10K scenes and 28K ways humans can interact with these 10K images. We also propose a two-step approach to predict affordances in a new scene. In the first step, given a location in the scene we classify which of the 30 pose classes is the likely affordance pose. Given the pose class and the scene, we then use a Variational Autoencoder (VAE) [23] to extract the scale and deformation of the pose. The VAE allows us to sample the distribution of possible poses at test time. Finally, we show the importance of large-scale data in learning a generalizable and robust model of affordances.","1063-6919","978-1-5386-0457-1","10.1109/CVPR.2017.359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8099842","","Semantics;Videos;Three-dimensional displays;TV;Robots;Manuals","image classification;learning (artificial intelligence);pose estimation","affordance learning;variational autoencoder","","29","","46","","9 Nov 2017","","","IEEE","IEEE Conferences"
"Generating 3D People in Scenes Without People","Y. Zhang; M. Hassan; H. Neumann; M. J. Black; S. Tang","Institute of Neural Information Processing, Ulm University, Germany; Max Planck Institute for Intelligent Systems, Tübingen, Germany; Institute of Neural Information Processing, Ulm University, Germany; Max Planck Institute for Intelligent Systems, Tübingen, Germany; ETH Zürich, Switzerland","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","6193","6203","We present a fully automatic system that takes a 3D scene and generates plausible 3D human bodies that are posed naturally in that 3D scene. Given a 3D scene without people, humans can easily imagine how people could interact with the scene and the objects in it. However, this is a challenging task for a computer as solving it requires that (1) the generated human bodies to be semantically plausible within the 3D environment (e.g. people sitting on the sofa or cooking near the stove), and (2) the generated human-scene interaction to be physically feasible such that the human body and scene do not interpenetrate while, at the same time, body-scene contact supports physical interactions. To that end, we make use of the surface-based 3D human model SMPL-X. We first train a conditional variational autoencoder to predict semantically plausible 3D human poses conditioned on latent scene representations, then we further refine the generated 3D bodies using scene constraints to enforce feasible physical interaction. We show that our approach is able to synthesize realistic and expressive 3D human bodies that naturally interact with 3D environment. We perform extensive experiments demonstrating that our generative framework compares favorably with existing methods, both qualitatively and quantitatively. We believe that our scene-conditioned 3D human generation pipeline will be useful for numerous applications; e.g. to generate training data for human pose estimation, in video games and in VR/AR. Our project page for data and code can be seen at: {https://vlg.inf.ethz.ch/projects/PSI/}.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00623","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157097","","Three-dimensional displays;Semantics;Shape;Solid modeling;Cameras;Biological system modeling;Pose estimation","image motion analysis;image representation;neural nets;pose estimation;solid modelling","3D human poses;conditional variational autoencoder;SMPL-X;surface-based 3D human model;3D scene;human pose estimation;scene-conditioned 3D human generation pipeline;3D human bodies;scene constraints;latent scene representations;physical interactions;body-scene contact;human-scene interaction","","26","","57","","5 Aug 2020","","","IEEE","IEEE Conferences"
"Bringing Old Photos Back to Life","Z. Wan; B. Zhang; D. Chen; P. Zhang; D. Chen; J. Liao; F. Wen",City University of Hong Kong; Microsoft Research Asia; Microsoft Cloud + AI; University of Science and Technology of China; Microsoft Research Asia; City University of Hong Kong; Microsoft Research Asia,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","2744","2754","We propose to restore old photos that suffer from severe degradation through a deep learning approach. Unlike conventional restoration tasks that can be solved through supervised learning, the degradation in real photos is complex and the domain gap between synthetic images and real old photos makes the network fail to generalize. Therefore, we propose a novel triplet domain translation network by leveraging real photos along with massive synthetic image pairs. Specifically, we train two variational autoencoders (VAEs) to respectively transform old photos and clean photos into two latent spaces. And the translation between these two latent spaces is learned with synthetic paired data. This translation generalizes well to real photos because the domain gap is closed in the compact latent space. Besides, to address multiple degradations mixed in one old photo, we design a global branch with a partial nonlocal block targeting to the structured defects, such as scratches and dust spots, and a local branch targeting to the unstructured defects, such as noises and blurriness. Two branches are fused in the latent space, leading to improved capability to restore old photos from multiple defects. The proposed method outperforms state-of-the-art methods in terms of visual quality for old photos restoration.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156748","","Image restoration;Degradation;Zirconium;Image color analysis;Fading channels;Task analysis;Image resolution","image coding;image denoising;image restoration;image texture;learning (artificial intelligence)","local branch;VAE;variational autoencoders;deep learning approach;old photo restoration;latent space;clean photos;massive synthetic image pairs;triplet domain translation network;domain gap","","25","","59","IEEE","5 Aug 2020","","","IEEE","IEEE Conferences"
"Differentially Private Mixture of Generative Neural Networks","G. Acs; L. Melis; C. Castelluccia; E. De Cristofaro","CrySyS Lab, BME-HIT, Budapest, Hungary; University College London, London, United Kingdom; INRIA, Rennes, France; University College London, London, United Kingdom","IEEE Transactions on Knowledge and Data Engineering","30 Apr 2019","2019","31","6","1109","1121","Generative models are used in a wide range of applications building on large amounts of contextually rich information. Due to possible privacy violations of the individuals whose data is used to train these models, however, publishing or sharing generative models is not always viable. In this paper, we present a novel technique for privately releasing generative models and entire high-dimensional datasets produced by these models. We model the generator distribution of the training data with a mixture of k generative neural networks. These are trained together and collectively learn the generator distribution of a dataset. Data is divided into k clusters, using a novel differentially private kernel k-means, then each cluster is given to separate generative neural networks, such as Restricted Boltzmann Machines or Variational Autoencoders, which are trained only on their own cluster using differentially private gradient descent. We evaluate our approach using the MNIST dataset, as well as call detail records and transit datasets, showing that it produces realistic synthetic samples, which can also be used to accurately compute arbitrary number of counting queries.","1558-2191","","10.1109/TKDE.2018.2855136","Alan Turing Institute(grant numbers:EP/N510129/1); Hungarian Academy of Sciences; Budapest University of Technology and Economics(grant numbers:BME FIKP-MI/FM); French National Research Agency(grant numbers:ANR-15-IDEX-02); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8410021","Differential privacy;generative networks;neural networks","Data models;Privacy;Data privacy;Training;Neural networks;Kernel;Machine learning","Boltzmann machines;data privacy;learning (artificial intelligence);pattern clustering","generative models;high-dimensional datasets;k generative neural networks;differentially private gradient descent;differentially private mixture;generative neural networks;novel differentially private kernel k-mean clustering;restricted Boltzmann machines;variational autoencoders;MNIST dataset;training data generator distribution","","25","","60","IEEE","11 Jul 2018","","","IEEE","IEEE Journals"
"Generating Diverse and Natural Text-to-Speech Samples Using a Quantized Fine-Grained VAE and Autoregressive Prosody Prior","G. Sun; Y. Zhang; R. J. Weiss; Y. Cao; H. Zen; A. Rosenberg; B. Ramabhadran; Y. Wu",University of Cambridge; Google Inc.; Google Inc.; Google Inc.; Google Inc.; Google Inc.; Google Inc.; Google Inc.,"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","6699","6703","Recent neural text-to-speech (TTS) models with fine-grained latent features enable precise control of the prosody of synthesized speech. Such models typically incorporate a fine-grained variational autoencoder (VAE) structure, extracting latent features at each input token (e.g., phonemes). However, generating samples with the standard VAE prior often results in unnatural and discontinuous speech, with dramatic prosodic variation between tokens. This paper proposes a sequential prior in a discrete latent space which can generate more naturally sounding samples. This is accomplished by discretizing the latent features using vector quantization (VQ), and separately training an autoregressive (AR) prior model over the result. We evaluate the approach using listening tests, objective metrics of automatic speech recognition (ASR) performance, and measurements of prosody attributes. Experimental results show that the proposed model significantly improves the naturalness in random sample generation. Furthermore, initial experiments demonstrate that randomly sampling from the proposed model can be used as data augmentation to improve the ASR performance.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9053436","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9053436","text-to-speech;Tacotron 2;fine-grained VAE","Training;Measurement;Vector quantization;Feature extraction;Data models;Speech processing;Standards","neural nets;speech processing;speech recognition;statistical analysis;text analysis;vector quantisation","natural text-to-speech samples;quantized fine-grained VAE;autoregressive prosody;text-to-speech models;fine-grained latent features;fine-grained variational autoencoder structure;standard VAE;unnatural speech;discontinuous speech;dramatic prosodic variation;discrete latent space;naturally sounding samples;vector quantization;autoregressive prior model;automatic speech recognition;prosody attributes;random sample generation;data augmentation;diverse text-to-speech samples","","23","","29","","9 Apr 2020","","","IEEE","IEEE Conferences"
"A Stochastic Conditioning Scheme for Diverse Human Motion Prediction","S. Aliakbarian; F. Sadat Saleh; M. Salzmann; L. Petersson; S. Gould","Data61, CSIRO; Australian National University; ACRV; CVLab, EPFL; Data61, CSIRO; ACRV","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","5222","5231","Human motion prediction, the task of predicting future 3D human poses given a sequence of observed ones, has been mostly treated as a deterministic problem. However, human motion is a stochastic process: Given an observed sequence of poses, multiple future motions are plausible. Existing approaches to modeling this stochasticity typically combine a random noise vector with information about the previous poses. This combination, however, is done in a deterministic manner, which gives the network the flexibility to learn to ignore the random noise. Alternatively, in this paper, we propose to stochastically combine the root of variations with previous pose information, so as to force the model to take the noise into account. We exploit this idea for motion prediction by incorporating it into a recurrent encoder-decoder network with a conditional variational autoencoder block that learns to exploit the perturbations. Our experiments on two large-scale motion prediction datasets demonstrate that our model yields high-quality pose sequences that are much more diverse than those from state-of-the-art stochastic motion prediction techniques.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00527","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157240","","Perturbation methods;Stochastic processes;Decoding;Training;Predictive models;Task analysis;Diversity reception","image coding;image motion analysis;learning (artificial intelligence);perturbation theory;pose estimation;recurrent neural nets;stochastic processes","perturbations;pose information;human motion prediction;stochastic motion prediction techniques;deterministic problem;stochastic conditioning scheme;large-scale motion prediction datasets;conditional variational autoencoder block;recurrent encoder-decoder network;multiple future motions;stochastic process","","22","","43","","5 Aug 2020","","","IEEE","IEEE Conferences"
"Geometric Disentanglement for Generative Latent Shape Models","T. Aumentado-Armstrong; S. Tsogkas; A. Jepson; S. Dickinson","University of Toronto; University of Toronto; Vector Institute for AI; Samsung AI Center, Toronto","2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","8180","8189","Representing 3D shapes is a fundamental problem in artificial intelligence, which has numerous applications within computer vision and graphics. One avenue that has recently begun to be explored is the use of latent representations of generative models. However, it remains an open problem to learn a generative model of shapes that is interpretable and easily manipulated, particularly in the absence of supervised labels. In this paper, we propose an unsupervised approach to partitioning the latent space of a variational autoencoder for 3D point clouds in a natural way, using only geometric information, that builds upon prior work utilizing generative adversarial models of point sets. Our method makes use of tools from spectral geometry to separate intrinsic and extrinsic shape information, and then considers several hierarchical disentanglement penalties for dividing the latent space in this manner. We also propose a novel disentanglement penalty that penalizes the predicted change in the latent representation of the output,with respect to the latent variables of the initial shape. We show that the resulting latent representation exhibits intuitive and interpretable behaviour, enabling tasks such as pose transfer that cannot easily be performed by models with an entangled representation.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.00827","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010824","","Shape;Three-dimensional displays;Computational modeling;Quaternions;Task analysis;Gallium nitride;Geometry","computational geometry;computer vision;image representation;neural nets;shape recognition;solid modelling;statistical analysis;supervised learning;unsupervised learning","latent variables;interpretable behaviour;geometric disentanglement;generative latent shape models;3D shapes;artificial intelligence;computer vision;open problem;supervised labels;unsupervised approach;latent space;spectral geometry;variational autoencoder;latent representation;hierarchical disentanglement penalties;extrinsic shape information;separate intrinsic shape information;generative adversarial models;geometric information;3D point clouds","","22","","59","","27 Feb 2020","","","IEEE","IEEE Conferences"
"Symbolic Music Genre Transfer with CycleGAN","G. Brunner; Y. Wang; R. Wattenhofer; S. Zhao","Department of Information Technology and Electrical Engineering, ETH Zürich, Switzerland; Department of Information Technology and Electrical Engineering, ETH Zürich, Switzerland; Department of Information Technology and Electrical Engineering, ETH Zürich, Switzerland; Department of Information Technology and Electrical Engineering, ETH Zürich, Switzerland","2018 IEEE 30th International Conference on Tools with Artificial Intelligence (ICTAI)","16 Dec 2018","2018","","","786","793","Deep generative models such as Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) have recently been applied to style and domain transfer for images, and in the case of VAEs, music. GAN-based models employing several generators and some form of cycle consistency loss have been among the most successful for image domain transfer. In this paper we apply such a model to symbolic music and show the feasibility of our approach for music genre transfer. Evaluations using separate genre classifiers show that the style transfer works well. In order to improve the fidelity of the transformed music, we add additional discriminators that cause the generators to keep the structure of the original music mostly intact, while still achieving strong genre transfer. Visual and audible results further show the potential of our approach. To the best of our knowledge, this paper represents the first application of GANs to symbolic music domain transfer.","2375-0197","978-1-5386-7449-9","10.1109/ICTAI.2018.00123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576121","deep learning;neural networks;music;midi;style;genre;domain;transfer;cnn;gan;cyclegan","Generators;Gallium nitride;Music;Feature extraction;Generative adversarial networks;Neural networks;Standards","image capture;learning (artificial intelligence);music","symbolic music genre transfer;deep generative models;VAEs;GANs;image domain transfer;style transfer;generative adversarial networks;genre classifiers;variational autoencoders;CycleGAN","","21","","38","","16 Dec 2018","","","IEEE","IEEE Conferences"
"Towards visual ego-motion learning in robots","S. Pillai; J. J. Leonard","CSAIL, MIT; MIT","2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","14 Dec 2017","2017","","","5533","5540","Many model-based Visual Odometry (VO) algorithms have been proposed in the past decade, often restricted to the type of camera optics, or the underlying motion manifold observed. We envision robots to be able to learn and perform these tasks, in a minimally supervised setting, as they gain more experience. To this end, we propose a fully trainable solution to visual ego-motion estimation for varied camera optics. We propose a visual ego-motion learning architecture that maps observed optical flow vectors to an ego-motion density estimate via a Mixture Density Network (MDN). By modeling the architecture as a Conditional Variational Autoencoder (C-VAE), our model is able to provide introspective reasoning and prediction for ego-motion induced scene-flow. Additionally, our proposed model is especially amenable to bootstrapped ego-motion learning in robots where the supervision in ego-motion estimation for a particular camera sensor can be obtained from standard navigation-based sensor fusion strategies (GPS/INS and wheel-odometry fusion). Through experiments, we show the utility of our proposed approach in enabling the concept of self-supervised learning for visual ego-motion estimation in autonomous robots.","2153-0866","978-1-5386-2682-5","10.1109/IROS.2017.8206441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8206441","","Cameras;Estimation;Optics;Visualization;Robot vision systems;Robustness","cameras;distance measurement;Global Positioning System;image motion analysis;image recognition;image sequences;learning (artificial intelligence);mobile robots;motion control;motion estimation;path planning;robot vision;sensor fusion","robots;Visual Odometry algorithms;underlying motion manifold;visual ego-motion estimation;varied camera optics;visual ego-motion learning architecture;optical flow vectors;ego-motion density estimate;ego-motion induced scene-flow;self-supervised learning;VO;Conditional Variational Autoencoder;C-VAE;Mixture Density Network;MDN;introspective reasoning;ego-motion estimation;autonomous robots;GPS;INS;wheel-odometry fusion","","20","","30","","14 Dec 2017","","","IEEE","IEEE Conferences"
"LiveSketch: Query Perturbations for Guided Sketch-Based Visual Search","J. Collomosse; T. Bui; H. Jin","Creative Intelligence Lab, Adobe Research; Centre for Vision Speech and Signal Processing, University of Surrey; Creative Intelligence Lab, Adobe Research","2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","2874","2882","LiveSketch is a novel algorithm for searching large image collections using hand-sketched queries. LiveSketch tackles the inherent ambiguity of sketch search by creating visual suggestions that augment the query as it is drawn, making query specification an iterative rather than one-shot process that helps disambiguate users' search intent. Our technical contributions are: a triplet convnet architecture that incorporates an RNN based variational autoencoder to search for images using vector (stroke-based) queries; real-time clustering to identify likely search intents (and so, targets within the search embedding); and the use of backpropagation from those targets to perturb the input stroke sequence, so suggesting alterations to the query in order to guide the search. We show improvements in accuracy and time-to-task over contemporary baselines using a 67M image corpus.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.00299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8953583","Recognition: Detection;Categorization;Retrieval;Document Analysis ; Vision Applications and Systems","","backpropagation;image matching;image retrieval;pattern clustering;recurrent neural nets;search problems","LiveSketch;query perturbations;guided sketch-based visual search;image collections;hand-sketched queries;sketch search;query specification;triplet convnet architecture;search embedding;67M image corpus;RNN;variational autoencoder;image searching;backpropagation","","17","","40","","9 Jan 2020","","","IEEE","IEEE Conferences"
"A Hybrid Strategy for the Discovery and Design of Photonic Structures","Z. Liu; L. Raju; D. Zhu; W. Cai","School of Electrical and Computer Engineering, Georgia institute of Technology, Atlanta, USA; School of Electrical and Computer Engineering, Georgia institute of Technology, Atlanta, USA; School of Electrical and Computer Engineering, Georgia institute of Technology, Atlanta, USA; School of Electrical and Computer Engineering, Georgia institute of Technology, Atlanta, USA","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","11 Mar 2020","2020","10","1","126","135","Metasurfaces and metamaterials are playing a growing role in the control of electromagnetic waves in the application of communication, display, and sensing technologies. However, designing photonic structures as the building blocks of these systems is typically a tedious trial-and-error process that requires extensive simulations with iterative sweeps in a multi-dimensional parameter space. To circumvent this conventional approach and substantially expedite the discovery and development of photonic structures, here we develop a framework leveraging both a deep generative model and a modified evolution strategy to automate the inverse design of engineered photonic materials and devices. The capacity of the proposed methodology is tested through the application to a case study, where metasurfaces in either continuous or discrete topologies are generated in response to customer-defined spectra at the input. Through a variational autoencoder, all potential patterns of unit structures are encoded into a continuous latent space. An evolution strategy is applied to vectors in the latent space to identify an optimized vector whose corresponding metasurface fulfills the design objective. The evaluation shows that over 95% accuracy can be achieved for all the unit patterns of the metasurfaces in the test dataset. Our scheme requires no prior knowledge of the geometry of the photonic structures, and, in principle, allows joint optimization of the dimensional parameters. As such, our work represents an efficient, on-demand, and automated approach for the inverse design of photonic structures with subwavelength features.","2156-3365","","10.1109/JETCAS.2020.2970080","Office of Naval Research(grant numbers:N00014-17-1-2555); National Science Foundation(grant numbers:ECCS-1609567); National Science Foundation(grant numbers:DGE-1650044); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8972468","Photonics;Metasurfaces;metamaterials;deep learning;neural networks;evolutionary algorithms","Photonics;Training;Topology;Optimization;Neural networks;Image reconstruction","evolutionary computation;iterative methods;optical metamaterials;vectors","photonic structures;metasurfaces;multidimensional parameter space;modified evolution strategy;inverse design;engineered photonic materials;unit structures;optimized vector;tedious trial-and-error process;iterative sweeps;customer-defined spectra;variational autoencoder;unit patterns;test dataset;dimensional parameters;subwavelength features","","17","","36","IEEE","28 Jan 2020","","","IEEE","IEEE Journals"
"Future Frame Prediction Using Convolutional VRNN for Anomaly Detection","Y. Lu; K. M. Kumar; S. s. Nabavi; Y. Wang","University of Manitoba, Winnipeg, MB, Canada; University of Manitoba, Winnipeg, MB, Canada; University of Manitoba, Winnipeg, MB, Canada; University of Manitoba, Winnipeg, MB, Canada","2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)","25 Nov 2019","2019","","","1","8","Anomaly detection in videos aims at reporting anything that does not conform the normal behaviour or distribution. However, due to the sparsity of abnormal video clips in real life, collecting annotated data for supervised learning is exceptionally cumbersome. Inspired by the practicability of generative models for semi-supervised learning, we propose a novel sequential generative model based on variational autoencoder (VAE) for future frame prediction with convolutional LSTM (ConvLSTM). To the best of our knowledge, this is the first work that considers temporal information in future frame prediction based anomaly detection framework from the model perspective. Our experiments demonstrate that our approach is superior to the state-of-the-art methods on three benchmark datasets.","2643-6213","978-1-7281-0990-9","10.1109/AVSS.2019.8909850","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8909850","","Anomaly detection;Videos;Predictive models;Feature extraction;Adaptive optics;Training;Testing","convolutional neural nets;recurrent neural nets;supervised learning;video signal processing","frame prediction;convolutional VRNN;abnormal video clips;supervised learning;semisupervised learning;convolutional LSTM;anomaly detection;equential generative model;variational autoencoder","","17","","33","","25 Nov 2019","","","IEEE","IEEE Conferences"
"Video Instance Segmentation Tracking With a Modified VAE Architecture","C. -C. Lin; Y. Hung; R. Feris; L. He",IBM Research AI; Rutgers University; IBM Research AI; Rutgers University,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","13144","13154","We propose a modified variational autoencoder (VAE) architecture built on top of Mask R-CNN for instance-level video segmentation and tracking. The method builds a shared encoder and three parallel decoders, yielding three disjoint branches for predictions of future frames, object detection boxes, and instance segmentation masks. To effectively solve multiple learning tasks, we introduce a Gaussian Process model to enhance the statistical representation of VAE by relaxing the prior strong independent and identically distributed (iid) assumption of conventional VAEs and allowing potential correlations among extracted latent variables. The network learns embedded spatial interdependence and motion continuity in video data and creates a representation that is effective to produce high-quality segmentation masks and track multiple instances in diverse and unstructured videos. Evaluation on a variety of recently introduced datasets shows that our model outperforms previous methods and achieves the new best in class performance.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.01316","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157192","","Task analysis;Decoding;Proposals;Motion segmentation;Object segmentation;Target tracking;Image segmentation","convolutional neural nets;Gaussian processes;image motion analysis;image segmentation;learning (artificial intelligence);object detection;statistical analysis;video signal processing","diverse videos;high-quality segmentation masks;motion continuity;spatial interdependence;statistical representation;Gaussian process model;multiple learning tasks;instance segmentation masks;object detection boxes;parallel decoders;instance-level video segmentation;Mask R-CNN;modified variational autoencoder architecture;modified VAE architecture;video instance segmentation tracking;unstructured videos","","16","","70","","5 Aug 2020","","","IEEE","IEEE Conferences"
"Lossy Point Cloud Geometry Compression via End-to-End Learning","J. Wang; H. Zhu; H. Liu; Z. Ma","School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China","IEEE Transactions on Circuits and Systems for Video Technology","3 Dec 2021","2021","31","12","4909","4923","This paper presents a novel end-to-end Learned Point Cloud Geometry Compression (a.k.a., Learned-PCGC) system, leveraging stacked Deep Neural Networks (DNN) based Variational AutoEncoder (VAE) to efficiently compress the Point Cloud Geometry (PCG). In this systematic exploration, PCG is first voxelized, and partitioned into non-overlapped 3D cubes, which are then fed into stacked 3D convolutions for compact latent feature and hyperprior generation. Hyperpriors are used to improve the conditional probability modeling of entropy-coded latent features. A Weighted Binary Cross-Entropy (WBCE) loss is applied in training while an adaptive thresholding is used in inference to remove false voxels and reduce the distortion. Objectively, our method exceeds the Geometry-based Point Cloud Compression (G-PCC) algorithm standardized by the Moving Picture Experts Group (MPEG) with a significant performance margin, e.g., at least 60% BD-Rate (Bjöntegaard Delta Rate) savings, using common test datasets, and other public datasets. Subjectively, our method has presented better visual quality with smoother surface reconstruction and appealing details, in comparison to all existing MPEG standard compliant PCC methods. Our method requires about 2.5 MB parameters in total, which is a fairly small size for practical implementation, even on embedded platform. Additional ablation studies analyze a variety of aspects (e.g., thresholding, kernels, etc) to examine the generalization, and application capacity of our Learned-PCGC. We would like to make all materials publicly accessible at https://njuvision.github.io/PCGCv1/ for reproducible research.","1558-2205","","10.1109/TCSVT.2021.3051377","National Natural Science Foundation of China(grant numbers:62022038,U20A20184,62001213); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321375","Point cloud compression;geometry;3D convolution;classification;end-to-end learning","Three-dimensional displays;Image coding;Geometry;Two dimensional displays;Transform coding;Octrees;Transforms","convolution;data compression;deep learning (artificial intelligence);entropy;feature extraction;geometry;image reconstruction;image segmentation;probability;video coding","stacked 3D convolutions;compact latent feature;hyperprior generation;conditional probability modeling;entropy-coded latent features;weighted binary cross-entropy loss;Moving Picture Experts Group;BD-rate savings;Bjöntegaard Delta Rate;MPEG standard compliant PCC methods;lossy point cloud geometry compression;end-to-end learning;learned-PCGC system;stacked deep neural networks based variational autoencoder;VAE;nonoverlapped 3D cubes;adaptive thresholding;false voxel removal;surface reconstruction","","16","","57","IEEE","13 Jan 2021","","","IEEE","IEEE Journals"
"Human Pose Forecasting via Deep Markov Models","S. Toyer; A. Cherian; T. Han; S. Gould",The Australian National University; The Australian National University; The Australian National University; The Australian National University,"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)","21 Dec 2017","2017","","","1","8","Human pose forecasting is an important problem in computer vision with applications to human-robot interaction, visual surveillance, and autonomous driving. Usually, forecasting algorithms use 3D skeleton sequences and are trained to forecast for a few milliseconds into the future. Long-range forecasting is challenging due to the difficulty of estimating how long a person continues an activity. To this end, our contributions are threefold: (i) we propose a generative framework for poses using variational autoencoders based on Deep Markov Models (DMMs); (ii) we evaluate our pose forecasts using a pose-based action classifier, which we argue better reflects the subjective quality of pose forecasts than distance in coordinate space; (iii) last, for evaluation of the new model, we introduce a 480,000-frame video dataset called Ikea Furniture Assembly (Ikea FA), which depicts humans repeatedly assembling and disassembling furniture. We demonstrate promising results for our approach on both Ikea FA and the existing NTU RGB+D dataset.","","978-1-5386-2839-3","10.1109/DICTA.2017.8227441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8227441","","Forecasting;Predictive models;Pose estimation;Markov processes;Visualization;Robot kinematics","computer vision;image classification;image motion analysis;image sequences;Markov processes;object tracking;pose estimation;video coding","long-range forecasting;Deep Markov Models;human pose forecasting;computer vision;3D skeleton sequences;variational autoencoders;pose-based action classifier;video dataset;Ikea Furniture Assembly;Ikea FA;NTU RGB+D dataset","","15","","44","IEEE","21 Dec 2017","","","IEEE","IEEE Conferences"
"An Empirical Evaluation of Deep Learning for Network Anomaly Detection","R. K. Malaiya; D. Kwon; S. C. Suh; H. Kim; I. Kim; J. Kim","Computer Science Department, Texas A&M University-Commerce, Commerce, TX, USA; Department of Math, CSCI, and Physics, Rockford University, Rockford, IL, USA; Computer Science Department, Texas A&M University-Commerce, Commerce, TX, USA; Information Security Research Division, ETRI, Daejeon, South Korea; Information Security Research Division, ETRI, Daejeon, South Korea; Computer Science Department, Texas A&M University-Commerce, Commerce, TX, USA","IEEE Access","7 Oct 2019","2019","7","","140806","140817","Deep learning has been widely studied in many technical domains such as image analysis and speech recognition, with its benefits that effectively deal with complex and high-dimensional data. Our preliminary experiments show a high degree of non-linearity from the network connection data, which explains why it is hard to improve the performance of identifying network anomalies by using conventional learning methods (e.g., Adaboosting, SVM, and Random Forest). In this study, we design and examine deep learning models constructed based on Fully Connected Networks (FCNs), Variational AutoEncoder (VAE), and Sequence-to-Sequence (Seq2Seq) structures. For the extensive evaluation, we employ a broad range of the public datasets with unique characteristics. Our experimental results confirm the feasibility of deep learning-based network anomaly detection, with the improved performance compared to the conventional learning techniques. In particular, the detection model based on Seq2Seq with LSTM is highly promising, consistently yielding over 99% of accuracy to identify network anomalies from the entire datasets employed in the evaluation.","2169-3536","","10.1109/ACCESS.2019.2943249","Institute for Information and communications Technology Promotion; Korean Government (MSIP)(grant numbers:2016-0-00078); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846674","Network anomaly detection;traffic analysis;deep learning;neural networks;sequence-to-sequence;performance evaluation","Deep learning;Anomaly detection;Support vector machines;Neural networks;Security;Learning systems;Training","learning (artificial intelligence);recurrent neural nets;security of data","image analysis;speech recognition;high-dimensional data;network connection data;network anomalies;deep learning models;fully connected networks;Seq2Seq;learning techniques;detection model;sequence-to-sequence structures;network anomaly detection;variational autoencoder;LSTM","","14","","45","CCBY","23 Sep 2019","","","IEEE","IEEE Journals"
"A Hierarchical Grocery Store Image Dataset With Visual and Semantic Labels","M. Klasson; C. Zhang; H. Kjellström","KTH Royal Institute of Technology, Stockholm, Sweden; Microsoft Research, Cambridge, United Kingdom; KTH Royal Institute of Technology, Stockholm, Sweden","2019 IEEE Winter Conference on Applications of Computer Vision (WACV)","7 Mar 2019","2019","","","491","500","Image classification models built into visual support systems and other assistive devices need to provide accurate predictions about their environment. We focus on an application of assistive technology for people with visual impairments, for daily activities such as shopping or cooking. In this paper, we provide a new benchmark dataset for a challenging task in this application - classification of fruits, vegetables, and refrigerated products, e.g. milk packages and juice cartons, in grocery stores. To enable the learning process to utilize multiple sources of structured information, this dataset not only contains a large volume of natural images but also includes the corresponding information of the product from an online shopping website. Such information encompasses the hierarchical structure of the object classes, as well as an iconic image of each type of object. This dataset can be used to train and evaluate image classification models for helping visually impaired people in natural environments. Additionally, we provide benchmark results evaluated on pretrained convolutional neural networks often used for image understanding purposes, and also a multi-view variational autoencoder, which is capable of utilizing the rich product information in the dataset.","1550-5790","978-1-7281-1975-5","10.1109/WACV.2019.00058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658240","","Visualization;Training;Task analysis;Dairy products;Adaptation models;Computational modeling;Computer vision","convolutional neural nets;electronic commerce;handicapped aids;image classification;learning (artificial intelligence);retail data processing;Web sites","iconic image;image classification models;visually impaired people;hierarchical grocery store image dataset;visual labels;semantic labels;visual support systems;assistive devices;assistive technology;visual impairments;natural images;hierarchical structure;image understanding;online shopping Web Site;convolutional neural networks;multiview variational autoencoder","","14","","47","","7 Mar 2019","","","IEEE","IEEE Conferences"
"S3VAE: Self-Supervised Sequential VAE for Representation Disentanglement and Data Generation","Y. Zhu; M. R. Min; A. Kadav; H. P. Graf","Department of Computer Science, Rutgers University; NEC Labs America; NEC Labs America; NEC Labs America","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","6537","6546","We propose a sequential variational autoencoder to learn disentangled representations of sequential data (e.g., videos and audios) under self-supervision. Specifically, we exploit the benefits of some readily accessible supervision signals from input data itself or some off-the-shelf functional models and accordingly design auxiliary tasks for our model to utilize these signals. With the supervision of the signals, our model can easily disentangle the representation of an input sequence into static factors and dynamic factors (i.e., time-invariant and time-varying parts). Comprehensive experiments across videos and audios verify the effectiveness of our model on representation disentanglement and generation of sequential data, and demonstrate that, our model with self-supervision performs comparable to, if not better than, the fully-supervised model with ground truth labels, and outperforms state-of-the-art unsupervised models by a large margin.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00657","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157480","","Videos;Data models;Task analysis;Visualization;Dynamics;Computational modeling;Three-dimensional displays","image representation;image sequences;neural nets;unsupervised learning;video signal processing","data generation;sequential variational autoencoder;readily accessible supervision signals;off-the-shelf functional models;time-varying part;representation disentanglement;self-supervision performs;fully-supervised model;unsupervised models;S3VAE;self-supervised sequential VAE;time-invariant part","","14","","55","","5 Aug 2020","","","IEEE","IEEE Conferences"
"A Neural Framework for Retrieval and Summarization of Source Code","Q. Chen; M. Zhou","Ministry of Education, School of Electronics Engineering and Computer Science, Peking University Key Laboratory of High Confidence Software Technologies, China; Ministry of Education, School of Electronics Engineering and Computer Science, Peking University Key Laboratory of High Confidence Software Technologies, China","2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE)","17 Feb 2020","2018","","","826","831","Code retrieval and summarization are two tasks often employed by software developers to reuse code that spreads over online repositories. In this paper, we present a neural framework that allows bidirectional mapping between source code and natural language to improve these two tasks. Our framework, BVAE, is designed to have two Variational AutoEncoders (VAEs) to model bimodal data: C-VAE for source code and L-VAE for natural language. Both VAEs are trained jointly to reconstruct their input as much as possible with regularization that captures the closeness between the latent variables of code and description. BVAE could learn semantic vector representations for both code and description and generate completely new descriptions for arbitrary code snippets. We design two instance models of BVAE for retrieval and summarization tasks respectively and evaluate their performance on a benchmark which involves two programming languages: C# and SQL. Experiments demonstrate BVAE's potential on the two tasks.","2643-1572","978-1-4503-5937-5","10.1145/3238147.3240471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9000013","Code retrieval;code summarization;neural framework","","information retrieval;learning (artificial intelligence);neural nets;software engineering;source code (software);SQL","neural framework;source code;natural language;BVAE;VAEs;L-VAE;code snippets;programming languages;SQL;variational autoencoders;code retrieval;code summarization tasks;semantic vector representations;software developers","","13","","30","","17 Feb 2020","","","IEEE","IEEE Conferences"
"BiTraP: Bi-Directional Pedestrian Trajectory Prediction With Multi-Modal Goal Estimation","Y. Yao; E. Atkins; M. Johnson-Roberson; R. Vasudevan; X. Du","Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Aerospace Engineering Department, University of Michigan, Ann Arbor, MI, USA; Department of Naval Architecture and Marine Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Naval Architecture and Marine Engineering, University of Michigan, Ann Arbor, MI, USA","IEEE Robotics and Automation Letters","25 Feb 2021","2021","6","2","1463","1470","Pedestrian trajectory prediction is an essential task in robotic applications such as autonomous driving and robot navigation. State-of-the-art trajectory predictors use a conditional variational autoencoder (CVAE) with recurrent neural networks (RNNs) to encode observed trajectories and decode multi-modal future trajectories. This process can suffer from accumulated errors over long prediction horizons (≥2 seconds). This letter presents BiTraP, a goal-conditioned bi-directional multi-modal trajectory prediction method based on the CVAE. BiTraP estimates the goal (end-point) of trajectories and introduces a novel bidirectional decoder to improve longer-term trajectory prediction accuracy. Extensive experiments show that BiTraP generalizes to both first-person view (FPV) and bird's-eye view (BEV) scenarios and outperforms state-of-the-art results by ~10-50%. We also show that different choices of non-parametric versus parametric target models in the CVAE directly influence the predicted multimodal trajectory distributions. These results provide guidance on trajectory predictor design for robotic applications such as collision avoidance and navigation systems. Our code is available at: https://github.com/umautobots/bidireaction-trajectory-prediction.","2377-3766","","10.1109/LRA.2021.3056339","Ford Motor Company; Ford-UM Alliance(grant numbers:N028603); Federal Highway Administration(grant numbers:693JJ319000009); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9345445","Computer vision for automation;human and humanoid motion analysis and synthesis;deep learning methods;multi-modal trajectory prediction;goal-conditioned prediction","Trajectory;Bidirectional control;Predictive models;Decoding;Estimation;Robots;Collision avoidance","collision avoidance;mobile robots;navigation;pedestrians;recurrent neural nets","BiTraP;CVAE;predicted multimodal trajectory distributions;trajectory predictor design;robotic applications;bi-directional pedestrian trajectory prediction;multimodal goal estimation;autonomous driving;robot navigation;trajectory predictors;conditional variational autoencoder;recurrent neural networks;observed trajectories;decode multimodal future trajectories;long prediction horizons;goal-conditioned bi-directional multimodal trajectory prediction method;longer-term trajectory prediction accuracy","","12","","45","IEEE","2 Feb 2021","","","IEEE","IEEE Journals"
"CALC2.0: Combining Appearance, Semantic and Geometric Information for Robust and Efficient Visual Loop Closure","N. Merrill; G. Huang","Dept. of Computer and Information Sciences and Dept. of Mechanical Engineering, University of Delaware, Newark, DE; Dept. of Computer and Information Sciences and Dept. of Mechanical Engineering, University of Delaware, Newark, DE","2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","28 Jan 2020","2019","","","4554","4561","Traditional attempts for loop closure detection typically use hand-crafted features, relying on geometric and visual information only, whereas more modern approaches tend to use semantic, appearance or geometric features extracted from deep convolutional neural networks (CNNs). While these approaches are successful in many applications, they do not utilize all of the information that a monocular image provides, and many of them, particularly the deep-learning based methods, require user-chosen thresholding to actually close loops - which may impact generality in practical applications. In this work, we address these issues by extracting all three modes of information from a custom deep CNN trained specifically for the task of place recognition. Our network is built upon a combination of a semantic segmentator, Variational Autoencoder (VAE) and triplet embedding network. The network is trained to construct a global feature space to describe both the visual appearance and semantic layout of an image. Then local keypoints are extracted from maximally-activated regions of low-level convolutional feature maps, and keypoint descriptors are extracted from these feature maps in a novel way that incorporates ideas from successful hand-crafted features. These keypoints are matched globally for loop closure candidates, and then used as a final geometric check to refute false positives. As a result, the proposed loop closure detection system requires no touchy thresholding, and is highly robust to false positives - achieving better precision-recall curves than the state-of-the-art NetVLAD, and with real-time speeds.","2153-0866","978-1-7281-4004-9","10.1109/IROS40897.2019.8968159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8968159","","","convolutional neural nets;feature extraction;image coding;image matching;image recognition;image segmentation;learning (artificial intelligence);object detection;robot vision","visual loop closure;geometric information;visual information;geometric features;deep convolutional neural networks;monocular image;deep-learning based methods;user-chosen thresholding;CNN;semantic segmentator;global feature space;visual appearance;semantic layout;low-level convolutional feature maps;loop closure detection system;CALC2.0;hand-crafted features;place recognition;variational autoencoder;triplet embedding network;VAE;NetVLAD","","12","","19","","28 Jan 2020","","","IEEE","IEEE Conferences"
"Learning from Noisy Web Data with Category-Level Supervision","L. Niu; Q. Tang; A. Veeraraghavan; A. Sabharwal","Department of Electrical and Computer Engineering, Rice University; Department of Computer Science and Technology, Tsinghua University; Department of Electrical and Computer Engineering, Rice University; Department of Electrical and Computer Engineering, Rice University","2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition","16 Dec 2018","2018","","","7689","7698","Learning from web data is increasingly popular due to abundant free web resources. However, the performance gap between webly supervised learning and traditional supervised learning is still very large, due to the label noise of web data as well as the domain shift between web data and test data. To fill this gap, most existing methods propose to purify or augment web data using instance-level supervision, which generally requires heavy annotation. Instead, we propose to address the label noise and domain shift by using more accessible category-level supervision. In particular, we build our deep probabilistic framework upon variational autoencoder (VAE), in which classification network and VAE can jointly leverage category-level hybrid information. Then, we extend our method for domain adaptation followed by our low-rank refinement strategy. Extensive experiments on three benchmark datasets demonstrate the effectiveness of our proposed method.","2575-7075","978-1-5386-6420-9","10.1109/CVPR.2018.00802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8578900","","Training;Semantics;Noise measurement;Supervised learning;Probabilistic logic;Visualization;Anomaly detection","image classification;Internet;learning (artificial intelligence);probability","noisy web data;webly supervised learning;label noise;instance-level supervision;accessible category-level supervision;deep probabilistic framework;variational autoencoder;classification network;category-level hybrid information;low-rank refinement strategy","","12","","57","","16 Dec 2018","","","IEEE","IEEE Conferences"
"StructEdit: Learning Structural Shape Variations","K. Mo; P. Guerrero; L. Yi; H. Su; P. Wonka; N. J. Mitra; L. J. Guibas",Stanford University; Adobe Research; Google Research; UC San Diego; KAUST; University College London; Stanford University; Facebook AI Research,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","8856","8865","Learning to encode differences in the geometry and (topological) structure of the shapes of ordinary objects is key to generating semantically plausible variations of a given shape, transferring edits from one shape to another, and for many other applications in 3D content creation. The common approach of encoding shapes as points in a high-dimensional latent feature space suggests treating shape differences as vectors in that space. Instead, we treat shape differences as primary objects in their own right and propose to encode them in their own latent space. In a setting where the shapes themselves are encoded in terms of fine-grained part hierarchies, we demonstrate that a separate encoding of shape deltas or differences provides a principled way to deal with inhomogeneities in the shape space due to different combinatorial part structures, while also allowing for compactness in the representation, as well as edit abstraction and transfer. Our approach is based on a conditional variational autoencoder for encoding and decoding shape deltas, conditioned on a source shape. We demonstrate the effectiveness and robustness of our approach in multiple shape modification and generation tasks, and provide comparison and ablation studies on the PartNet dataset, one of the largest publicly available 3D datasets.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00888","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156421","","Shape;Three-dimensional displays;Strain;Silicon;Geometry;Decoding;Encoding","decoding;graph theory;learning (artificial intelligence)","geometry;topological structure;3D datasets;PartNet dataset;decoding shape deltas;generation tasks;multiple shape modification;source shape;conditional variational autoencoder;combinatorial part structures;shape space;fine-grained part hierarchies;primary objects;shape differences;high-dimensional latent feature space;encoding shapes;3D content creation;semantically plausible variations;ordinary objects;structural shape","","10","","52","","5 Aug 2020","","","IEEE","IEEE Conferences"
"PLACE: Proximity Learning of Articulation and Contact in 3D Environments","S. Zhang; Y. Zhang; Q. Ma; M. J. Black; S. Tang",ETH Zürich; ETH Zürich; Max Planck Institute for Intelligent Systems; Max Planck Institute for Intelligent Systems; ETH Zürich,"2020 International Conference on 3D Vision (3DV)","19 Jan 2021","2020","","","642","651","High fidelity digital 3D environments have been proposed in recent years, however, it remains extremely challenging to automatically equip such environment with realistic human bodies. Existing work utilizes images, depth or semantic maps to represent the scene, and parametric human models to represent 3D bodies. While being straightforward, their generated human-scene interactions are often lack of naturalness and physical plausibility. Our key observation is that humans interact with the world through body-scene contact. To synthesize realistic human-scene interactions, it is essential to effectively represent the physical contact and proximity between the body and the world. To that end, we propose a novel interaction generation method, named PLACE (Proximity Learning of Articulation and Contact in 3D Environments), which explicitly models the proximity between the human body and the 3D scene around it. Specifically, given a set of basis points on a scene mesh, we leverage a conditional variational autoencoder to synthesize the minimum distances from the basis points to the human body surface. The generated proximal relationship exhibits which region of the scene is in contact with the person. Furthermore, based on such synthesized proximity, we are able to effectively obtain expressive 3D human bodies that interact with the 3D scene naturally. Our perceptual study shows that PLACE significantly improves the state-of-the-art method, approaching the realism of real human-scene interaction. We believe our method makes an important step towards the fully automatic synthesis of realistic 3D human bodies in 3D scenes. The code and model are available for research at https://sanweiliti. github.io/PLACE/PLACE.html.","2475-7888","978-1-7281-8128-8","10.1109/3DV50981.2020.00074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9320325","human scene interaction;3D scene;proximity learning;generating 3D human;deep learning;3D vision;computer vision","Three-dimensional displays;Solid modeling;Biological system modeling;Encoding;Semantics;Affordances;Two dimensional displays","computer animation;human computer interaction;learning (artificial intelligence);mesh generation;natural scenes;neural nets;realistic images;solid modelling","high fidelity digital 3D environments;parametric human models;body-scene contact;physical contact;scene mesh;human body surface;expressive 3D human bodies;realistic 3D human bodies;proximal relationship;interaction generation method;proximity learning of articulation and contact in 3D environments;realistic human-scene interaction;conditional variational autoencoder","","10","","44","","19 Jan 2021","","","IEEE","IEEE Conferences"
"Online Anomalous Trajectory Detection with Deep Generative Sequence Modeling","Y. Liu; K. Zhao; G. Cong; Z. Bao",Nanyang Technological University; University of Auckland; Nanyang Technological University; RMIT University,"2020 IEEE 36th International Conference on Data Engineering (ICDE)","27 May 2020","2020","","","949","960","Detecting anomalous trajectory has become an important and fundamental concern in many real-world applications. However, most of the existing studies 1) cannot handle the complexity and variety of trajectory data and 2) do not support efficient anomaly detection in an online manner. To this end, we propose a novel model, namely Gaussian Mixture Variational Sequence AutoEncoder (GM-VSAE), to tackle these challenges. Our GM-VSAE model is able to (1) capture complex sequential information enclosed in trajectories, (2) discover different types of normal routes from trajectories and represent them in a continuous latent space, and (3) support efficient online detection via trajectory generation. Our experiments on two real-world datasets demonstrate that GM-VSAE is more effective than the state-of-the-art baselines and is efficient for online anomalous trajectory detection.","2375-026X","978-1-7281-2903-7","10.1109/ICDE48307.2020.00087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9101353","","Trajectory;Anomaly detection;Global Positioning System;Public transportation;Computational modeling;Recurrent neural networks;Data models","Gaussian processes;learning (artificial intelligence);mixture models;security of data","online anomalous trajectory detection;deep generative Sequence modeling;trajectory data;efficient anomaly detection;Gaussian Mixture Variational Sequence AutoEncoder;GM-VSAE model;trajectory generation;real-world datasets","","10","","39","","27 May 2020","","","IEEE","IEEE Conferences"
"3-D Context Entropy Model for Improved Practical Image Compression","Z. Guo; Y. Wu; R. Feng; Z. Zhang; Z. Chen","CAS Key Laboratory of Technology in Geo-spatial Information Processing and Application System, University of Science and Technology of China; CAS Key Laboratory of Technology in Geo-spatial Information Processing and Application System, University of Science and Technology of China; CAS Key Laboratory of Technology in Geo-spatial Information Processing and Application System, University of Science and Technology of China; CAS Key Laboratory of Technology in Geo-spatial Information Processing and Application System, University of Science and Technology of China; CAS Key Laboratory of Technology in Geo-spatial Information Processing and Application System, University of Science and Technology of China","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","520","523","In this paper, we present our image compression framework designed for CLIC 2020 competition. Our method is based on Variational AutoEncoder (VAE) architecture which is strengthened with residual structures. In short, we make three noteworthy improvements here. First, we propose a 3-D context entropy model which can take advantage of known latent representation in current spatial locations for better entropy estimation. Second, a light-weighted residual structure is adopted for feature learning during entropy estimation. Finally, an effective training strategy is introduced for practical adaptation with different resolutions. Experiment results indicate our image compression method achieves 0.9775 MS-SSIM on CLIC validation set and 0.9809 MS-SSIM on test set.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150755","","Context modeling;Solid modeling;Image coding;Entropy;Training;Transforms;Image resolution","data compression;entropy codes;estimation theory;image coding;image representation;image resolution;learning (artificial intelligence);stereo image processing","entropy estimation;light-weighted residual structure;image compression framework;CLIC 2020 competition;variational autoencoder architecture;residual structures;3D context entropy model;VAE architecture;feature learning;MS-SSIM","","10","","15","","28 Jul 2020","","","IEEE","IEEE Conferences"
"The Good, the Bad and the Bait: Detecting and Characterizing Clickbait on YouTube","S. Zannettou; S. Chatzis; K. Papadamou; M. Sirivianos","Department of Electrical Engineering, Cyprus University of Technology, Limassol, Cyprus; Department of Electrical Engineering, Cyprus University of Technology, Limassol, Cyprus; Department of Electrical Engineering, Cyprus University of Technology, Limassol, Cyprus; Department of Electrical Engineering, Cyprus University of Technology, Limassol, Cyprus","2018 IEEE Security and Privacy Workshops (SPW)","6 Aug 2018","2018","","","63","69","The use of deceptive techniques in user-generated video portals is ubiquitous. Unscrupulous uploaders deliberately mislabel video descriptors aiming at increasing their views and subsequently their ad revenue. This problem, usually referred to as ""clickbait,"" may severely undermine user experience. In this work, we study the clickbait problem on YouTube by collecting metadata for 206k videos. To address it, we devise a deep learning model based on variational autoencoders that supports the diverse modalities of data that videos include. The proposed model relies on a limited amount of manually labeled data to classify a large corpus of unlabeled data. Our evaluation indicates that the proposed model offers improved performance when compared to other conventional models. Our analysis of the collected data indicates that YouTube recommendation engine does not take into account clickbait. Thus, it is susceptible to recommending misleading videos to users.","","978-1-5386-8276-0","10.1109/SPW.2018.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8424634","Clickbait;YouTube;Deep Learning","YouTube;Machine learning;Entertainment industry;Metadata;Engines;Correlation","learning (artificial intelligence);meta data;recommender systems;social networking (online);video signal processing","deep learning model;variational autoencoders;YouTube recommendation engine;misleading videos;deceptive techniques;unscrupulous uploaders;video descriptors;user experience;clickbait problem;video portals;ubiquitous","","10","","37","","6 Aug 2018","","","IEEE","IEEE Conferences"
"Asymmetric Gained Deep Image Compression With Continuous Rate Adaptation","Z. Cui; J. Wang; S. Gao; T. Guo; Y. Feng; B. Bai","Huawei Technologies, Beijing, China; Huawei Technologies, Beijing, China; Huawei Technologies, Beijing, China; Huawei Technologies, Beijing, China; Huawei Technologies, Beijing, China; Huawei Technologies, Beijing, China","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","2 Nov 2021","2021","","","10527","10536","With the development of deep learning techniques, the combination of deep learning with image compression has drawn lots of attention. Recently, learned image compression methods had exceeded their classical counterparts in terms of rate-distortion performance. However, continuous rate adaptation remains an open question. Some learned image compression methods use multiple networks for multiple rates, while others use one single model at the expense of computational complexity increase and performance degradation. In this paper, we propose a continuously rate adjustable learned image compression framework, Asymmetric Gained Variational Autoencoder (AG-VAE). AG-VAE utilizes a pair of gain units to achieve discrete rate adaptation in one single model with a negligible additional computation. Then, by using exponential interpolation, continuous rate adaptation is achieved without compromising performance. Besides, we propose the asymmetric Gaussian entropy model for more accurate entropy estimation. Exhaustive experiments show that our method achieves comparable quantitative performance with SOTA learned image compression methods and better qualitative performance than classical image codecs. In the ablation study, we confirm the usefulness and superiority of gain units and the asymmetric Gaussian entropy model.","2575-7075","978-1-6654-4509-2","10.1109/CVPR46437.2021.01039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9578818","","Degradation;Deep learning;Training;Adaptation models;Interpolation;Image coding;Codecs","computational complexity;data compression;deep learning (artificial intelligence);image classification;image coding;interpolation;rate distortion theory","deep learning techniques;rate-distortion performance;computational complexity;performance degradation;continuously rate adjustable learned image compression framework;asymmetric Gaussian entropy model;classical image codecs;asymmetric gained variational autoencoder;asymmetric gained deep image compression;SOTA learned image compression methods","","9","","43","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Imitative Non-Autoregressive Modeling for Trajectory Forecasting and Imputation","M. Qi; J. Qin; Y. Wu; Y. Yang","Baidu Research, China; Inception Institute of Artificial Intelligence, UAE; ReLER, University of Technology Sydney, Australia; ReLER, University of Technology Sydney, Australia","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","12733","12742","Trajectory forecasting and imputation are pivotal steps towards understanding the movement of human and objects, which are quite challenging since the future trajectories and missing values in a temporal sequence are full of uncertainties, and the spatial-temporally contextual correlation is hard to model. Yet, the relevance between sequence prediction and imputation is disregarded by existing approaches. To this end, we propose a novel imitative non-autoregressive modeling method to simultaneously handle the trajectory prediction task and the missing value imputation task. Specifically, our framework adopts an imitation learning paradigm, which contains a recurrent conditional variational autoencoder (RC-VAE) as a demonstrator, and a non-autoregressive transformation model (NART) as a learner. By jointly optimizing the two models, RC-VAE can predict the future trajectory and capture the temporal relationship in the sequence to supervise the NART learner. As a result, NART learns from the demonstrator and imputes the missing value in a non autoregressive strategy. We conduct extensive experiments on three popular datasets, and the results show that our model achieves state-of-the-art performance across all the datasets.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.01275","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156400","","Trajectory;Predictive models;Task analysis;Forecasting;Decoding;Training;TV","autoregressive processes;learning (artificial intelligence);least squares approximations","temporal relationship;NART learner;nonautoregressive strategy;trajectory forecasting;pivotal steps;human objects;temporal sequence;spatial-temporally contextual correlation;sequence prediction;trajectory prediction task;missing value imputation task;imitation learning paradigm;recurrent conditional variational autoencoder;RC-VAE;nonautoregressive transformation model;imitative nonautoregressive modeling","","9","","52","","5 Aug 2020","","","IEEE","IEEE Conferences"
"Millimeter Wave Channel Modeling via Generative Neural Networks","W. Xia; S. Rangan; M. Mezzavilla; A. Lozano; G. Geraci; V. Semkin; G. Loianno","NYU Tandon School of Engineering, Brooklyn, NY, USA; NYU Tandon School of Engineering, Brooklyn, NY, USA; NYU Tandon School of Engineering, Brooklyn, NY, USA; VTT Technical Research Centre of Finland Ltd, Finland; VTT Technical Research Centre of Finland Ltd, Finland; Univ. Pompeu Fabra, Barcelona, Spain; NYU Tandon School of Engineering, Brooklyn, NY, USA","2020 IEEE Globecom Workshops (GC Wkshps","5 Mar 2021","2020","","","1","6","Statistical channel models are instrumental to design and evaluate wireless communication systems. In the millimeter wave bands, such models become acutely challenging; they must capture the delay, directions, and path gains, for each link and with high resolution. This paper presents a general modeling methodology based on training generative neural networks from data. The proposed generative model consists of a two-stage structure that first predicts the state of each link (line-of-sight, non-line-of-sight, or outage), and subsequently feeds this state into a conditional variational autoencoder that generates the path losses, delays, and angles of arrival and departure for all its propagation paths. Importantly, minimal prior assumptions are made, enabling the model to capture complex relationships within the data. The methodology is demonstrated for 28GHz air-to-ground channels in an urban environment, with training datasets produced by means of ray tracing.","","978-1-7281-7307-8","10.1109/GCWkshps50303.2020.9367420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9367420","","Training;Atmospheric modeling;Urban areas;Millimeter wave technology;Predictive models;Delays;Millimeter wave communication","computer networks;learning (artificial intelligence);millimetre wave propagation;neural nets;ray tracing;statistical analysis;wireless channels","millimeter wave channel modeling;air-to-ground channels;propagation paths;delays;conditional variational autoencoder;nonline-of-sight;line-of-sight;two-stage structure;generative model;generative neural networks;millimeter wave bands;wireless communication systems;statistical channel models","","8","","33","IEEE","5 Mar 2021","","","IEEE","IEEE Conferences"
"Semi-Supervised Source Localization with Deep Generative Modeling","M. J. Bianco; S. Gannot; P. Gerstoft","Marine Physical Laboratory, UCSD, CA, USA; Faculty of Engineering, Bar-Ilan University, Israel; Marine Physical Laboratory, UCSD, CA, USA","2020 IEEE 30th International Workshop on Machine Learning for Signal Processing (MLSP)","20 Oct 2020","2020","","","1","6","We propose a semi-supervised localization approach based on deep generative modeling with variational autoencoders (VAE). Localization in reverberant environments remains a challenge, which machine learning (ML) has shown promise in addressing. Even with large data volumes, the number of labels available for supervised learning in reverberant environments is usually small. We address this issue by perform semi-supervised learning (SSL) with convolutional VAEs. The VAE is trained to generate the phase of relative transfer functions (RTFs), in parallel with a DOA classifier, on both labeled and unlabeled RTF samples. The VAE-SSL approach is compared with SRP-PHAT and fully-supervised CNNs. We find that VAE-SLL can outperform both SRP-PHAT and CNN in label-limited scenarios.","1551-2541","978-1-7281-6662-9","10.1109/MLSP49062.2020.9231825","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9231825","Source localization;semi-supervised learning;generative modeling;deep learning","Convolution;Acoustics;Direction-of-arrival estimation;Convolutional codes;Semisupervised learning;Reverberation;Microphones","convolutional neural nets;direction-of-arrival estimation;learning (artificial intelligence);pattern classification;reverberation;transfer functions","reverberant environments;semisupervised learning;convolutional VAEs;labeled RTF samples;unlabeled RTF samples;fully-supervised CNNs;VAE-SLL;semisupervised source localization;deep generative modeling;variational autoencoders;machine learning;data volumes;supervised learning;semisupervised localization;DOA classifier","","8","","32","","20 Oct 2020","","","IEEE","IEEE Conferences"
"Reference Based Face Super-Resolution","Z. -S. Liu; W. -C. Siu; Y. -L. Chan","Center of Multimedia Signal Processing, The Hong Kong Polytechnic University, Hong Kong; Center of Multimedia Signal Processing, The Hong Kong Polytechnic University, Hong Kong; Center of Multimedia Signal Processing, The Hong Kong Polytechnic University, Hong Kong","IEEE Access","19 Sep 2019","2019","7","","129112","129126","Despite the great progress of image super-resolution in recent years, face super-resolution has still much room to explore good visual quality while preserving original facial attributes for larger up-scaling factors. This paper investigates a new research direction in face super-resolution, called Reference based face Super-Resolution (RefSR), in which a reference facial image containing genuine attributes is provided in addition to the low-resolution images for super-resolution. We focus on transferring the key information extracted from reference facial images to the super-resolution process to guarantee the content similarity between the reference and super-resolution image. We propose a novel Conditional Variational AutoEncoder model for this Reference based Face Super-Resolution (RefSR-VAE). By using the encoder to map the reference image to the joint latent space, we can then use the decoder to sample the encoder results to super-resolve low-resolution facial images to generate super-resolution images with good visual quality. We create a benchmark dataset on reference based face super-resolution (RefSR-Face) for general research use, which contains reference images paired with low-resolution images of various pose, emotions, ages and appearance. Both objective and subjective evaluations were conducted, which demonstrate the great potential of using reference images for face super-resolution. By comparing it with state-of-the-art super-resolution approaches, our proposed approach also achieves superior performance.","2169-3536","","10.1109/ACCESS.2019.2934078","Hong Kong Polytechnic University; Hong Kong Polytechnic University(grant numbers:PolyU 152208/17E); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8792098","Face super-resolution;deep feature extraction;style transfer","Face;Image resolution;Signal resolution;Gallium nitride;Image reconstruction;Visualization;Distortion","face recognition;feature extraction;image coding;image resolution;image sampling","super-resolution image;reference image;low-resolution images;state-of-the-art super-resolution approaches;image super-resolution;reference facial image;super-resolution process;low-resolution facial images;visual quality;up-scaling factors;reference based face super-resolution;conditional variational autoencoder model;RefSR-VAE;benchmark dataset","","7","","50","CCBY","8 Aug 2019","","","IEEE","IEEE Journals"
"Geometrically Editable Face Image Translation With Adversarial Networks","S. Jiang; Z. Tao; Y. Fu","Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Department of Computer Science and Engineering, Santa Clara University, Santa Clara, CA, USA; Khoury College of Computer Science, Northeastern University, Boston, MA, USA","IEEE Transactions on Image Processing","12 Feb 2021","2021","30","","2771","2783","Recently, image-to-image translation has received increasing attention, which aims to map images in one domain to another specific one. Existing methods mainly solve this task via a deep generative model that they focus on exploring the bi-directional or multi-directional relationship between specific domains. Those domains are often categorized by attribute-level or class-level labels, which do not incorporate any geometric information in learning process. As a result, existing methods are incapable of editing geometric contents during translation. They also neglect to utilize higher-level and instance-specific information to further guide the training process, leading to a great deal of unrealistic synthesized images of low fidelity, especially for face images. To address these challenges, we formulate the general image translation problem as multi-domain mappings in both geometric and attribute directions within an image set that shares a same latent vector. Particularly, we propose a novel Geometrically Editable Generative Adversarial Networks (GEGAN) model to solve this problem for face images by leveraging facial semantic segmentation to explicitly guide its geometric editing. In details, input face images are encoded to their latent representations via a variational autoencoder, a segmentor network is designed to impose semantic information on the generated images, and multi-scale regional discriminators are employed to force the generator to pay attention to the details of key components. We provide both quantitative and qualitative evaluations on CelebA dataset to demonstrate our ability of the geometric modification and our improvement in image fidelity.","1941-0042","","10.1109/TIP.2021.3052084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9336328","Image translation;geometric editing;spatial constraints;segmentor network;generative models;adversarial training","Image segmentation;Faces;Generators;Semantics;Task analysis;Generative adversarial networks;Training","deep learning (artificial intelligence);face recognition;image representation;image segmentation;vectors","unrealistic synthesized images;multidomain mappings;image set;geometric editing;segmentor network;semantic information;multiscale regional discriminators;geometric modification;image fidelity;image-to-image translation;deep generative model;attribute-level labels;class-level labels;geometric information;learning process;geometric contents;instance-specific information;geometrically editable generative adversarial networks;geometrically editable face image translation;latent vector;GEGAN;facial semantic segmentation;latent representations;variational autoencoder;CelebA dataset","","6","","51","IEEE","26 Jan 2021","","","IEEE","IEEE Journals"
"StyleMeUp: Towards Style-Agnostic Sketch-Based Image Retrieval","A. Sain; A. K. Bhunia; Y. Yang; T. Xiang; Y. -Z. Song","iFlyTek-Surrey Joint Research Centre on Artificial Intelligence; SketchX, CVSSP, University of Surrey, United Kingdom; iFlyTek-Surrey Joint Research Centre on Artificial Intelligence; iFlyTek-Surrey Joint Research Centre on Artificial Intelligence; iFlyTek-Surrey Joint Research Centre on Artificial Intelligence","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","2 Nov 2021","2021","","","8500","8509","Sketch-based image retrieval (SBIR) is a cross-modal matching problem which is typically solved by learning a joint embedding space where the semantic content shared between photo and sketch modalities are preserved. However, a fundamental challenge in SBIR has been largely ignored so far, that is, sketches are drawn by humans and considerable style variations exist amongst different users. An effective SBIR model needs to explicitly account for this style diversity, crucially, to generalise to unseen user styles. To this end, a novel style-agnostic SBIR model is proposed. Different from existing models, a cross-modal variational autoencoder (VAE) is employed to explicitly disentangle each sketch into a semantic content part shared with the corresponding photo, and a style part unique to the sketcher. Importantly, to make our model dynamically adaptable to any unseen user styles, we propose to meta-train our cross-modal VAE by adding two style-adaptive components: a set of feature transformation layers to its encoder and a regulariser to the disentangled semantic content latent code. With this meta-learning framework, our model can not only disentangle the cross-modal shared semantic content for SBIR, but can adapt the disentanglement to any unseen user style as well, making the SBIR model truly style-agnostic. Extensive experiments show that our style-agnostic model yields state-of-the-art performance for both category-level and instance-level SBIR.","2575-7075","978-1-6654-4509-2","10.1109/CVPR46437.2021.00840","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9577644","","Adaptation models;Computer vision;Codes;Computational modeling;Semantics;Image retrieval;Pattern recognition","content-based retrieval;feature extraction;human computer interaction;image matching;image retrieval;learning (artificial intelligence);solid modelling","instance-level SBIR;cross-modal matching problem;joint embedding space;considerable style variations;effective SBIR model;style diversity;unseen user style;novel style-agnostic SBIR model;cross-modal variational autoencoder;semantic content part;style part;cross-modal VAE;style-adaptive components;disentangled semantic content latent code;cross-modal shared semantic content;SBIR model;style-agnostic model yields state-of-the-art performance;style-agnostic sketch-based image retrieval","","6","","64","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Online Fault Detection in Autonomous Ferries: Using Fault-Type Independent Spectral Anomaly Detection","A. Listou Ellefsen; P. Han; X. Cheng; F. T. Holmeset; V. Æsøy; H. Zhang","Department of Ocean Operations and Civil Engineering, Mechatronics Laboratory, Norwegian University of Science and Technology, Alesund, Norway; Department of Ocean Operations and Civil Engineering, Mechatronics Laboratory, Norwegian University of Science and Technology, Alesund, Norway; Department of Ocean Operations and Civil Engineering, Mechatronics Laboratory, Norwegian University of Science and Technology, Alesund, Norway; Department of Ocean Operations and Civil Engineering, Mechatronics Laboratory, Norwegian University of Science and Technology, Alesund, Norway; Department of Ocean Operations and Civil Engineering, Mechatronics Laboratory, Norwegian University of Science and Technology, Alesund, Norway; Department of Ocean Operations and Civil Engineering, Mechatronics Laboratory, Norwegian University of Science and Technology, Alesund, Norway","IEEE Transactions on Instrumentation and Measurement","14 Sep 2020","2020","69","10","8216","8225","Enthusiasm for ship autonomy is flourishing in the maritime industry. In this context, data-driven prognostics and health management (PHM) systems have emerged as the optimal way to improve operational reliability and system safety. However, further research is needed to enhance the essential actions relating to such a system. Fault detection is the first and most crucial action of any data-driven PHM system. In this article, we propose a fault-type independent spectral anomaly detection algorithm for marine diesel engine degradation in autonomous ferries. The benefits of the algorithm are verified on three fault types where the nature of degradation differs. Both normal operation data and faulty degradation data have been collected from a marine diesel engine using two different engine load profiles. These profiles aim to replicate real autonomous ferry crossing operations, environmental conditions that the ferry may encounter. First, the data are subjected to a feature selection process to remove irrelevant and redundant features. Then, a multiregime normalization method is performed on the data to merge the engine loads into one context. Finally, a variational autoencoder is trained to estimate velocity and acceleration calculations of the anomaly score. Generic and dynamic threshold limits are simultaneously established to detect the fault time step online. The algorithm achieved an accuracy of 97.66% in the final test when the acceleration was used as the fault detector. The results suggest that the algorithm is independent of fault types with different nature of degradation related to the marine diesel engine.","1557-9662","","10.1109/TIM.2020.2994012","Department of Ocean Operations and Civil Engineering, Norwegian University of Science and Technology(grant numbers:90329106); Digital Twins for Vessel Life Cycle Service and the Research Council of Norway(grant numbers:280703); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097190","Autonomous ferry;marine diesel engine;multiregime normalization;online fault detection;prognostics and health management (PHM)","Fault detection;Degradation;Anomaly detection;Heuristic algorithms;Prognostics and health management;Diesel engines;Acceleration","condition monitoring;data analysis;diesel engines;failure analysis;fault diagnosis;feature selection;marine systems;mechanical engineering computing;neural nets;reliability;ships","online fault detection;ship autonomy;maritime industry;operational reliability;data-driven PHM system;fault-type independent spectral anomaly detection algorithm;marine diesel engine degradation;faulty degradation data;autonomous ferry crossing operations;engine loads;fault detector;prognostics and health management system;system safety;environmental conditions;feature selection process;multiregime normalization method;variational autoencoder;velocity calculation;acceleration calculation;dynamic threshold limit;generic threshold limit","","6","","25","CCBY","20 May 2020","","","IEEE","IEEE Journals"
"A study on dementia detection method with stroke data using anomaly detection","K. Kawanishi; H. Kawanaka; H. Takase; S. Tsuruoka","Graduate School of Eng., Mie University, Mie, Japan; Graduate School of Eng., Mie University, Mie, Japan; Graduate School of Eng., Mie University, Mie, Japan; Graduate School of Eng., Mie University, Mie, Japan","2017 6th International Conference on Informatics, Electronics and Vision & 2017 7th International Symposium in Computational Medical and Health Technology (ICIEV-ISCMHT)","19 Apr 2018","2017","","","1","4","Increasing the number of elderly persons who have dementia, this is one of the severe social problems in Japan. According to the report published by the Ministry of Health, Labor and Welfare, the number of elderly persons with dementia will be around five million in 2015. This report indicates that early detection and prevention of dementia is essential. From viewpoints of early detection of dementia, the most problem is the limitation of test contents and the difficulty of taking a dementia check test on a daily basis. To solve these problems, the authors focus on drawing test using a tablet terminal to develop a dementia detection system, which can be adapted to various drawing contents including digits, characters, and pictures for increasing of dementia screening opportunity. It is, however, difficult to collect sufficient data to build the system because there are many subtypes of dementia. From this background, this position paper discusses an unsupervised anomaly detection method using healthy data only, and also aim to propose a system that gives the probability of being dementia (or other sicknesses) based on the differences from the data of healthy cases. As the first step of this study, we discuss the possibility of a dementia detection method using Variational Autoencoder.","","978-1-5386-1023-7","10.1109/ICIEV.2017.8338566","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8338566","","Dementia;Feature extraction;Anomaly detection;Senior citizens;Robots;Data models;Acceleration","diseases;geriatrics;medical diagnostic computing;security of data","early detection;dementia check test;dementia detection system;dementia screening opportunity;unsupervised anomaly detection method;dementia detection method;elderly persons;severe social problems;Ministry of Health, Labor and Welfare;dementia prevention;tablet terminal;variational autoencoder;stroke data","","5","","24","","19 Apr 2018","","","IEEE","IEEE Conferences"
"Visual Anomaly Detection in Event Sequence Data","S. Guo; Z. Jin; Q. Chen; D. Gotz; H. Zha; N. Cao","Department of Software Engineering, East China Normal University; College of Design and Innovation, Tongji University; College of Design and Innovation, Tongji University; School of Information and Library Science, University of North Carolina at Chapel Hill; Department of Software Engineering, East China Normal University; College of Design and Innovation, Tongji University","2019 IEEE International Conference on Big Data (Big Data)","24 Feb 2020","2019","","","1125","1130","Anomaly detection is a common analytical task that aims to identify rare cases that differ from the typical cases that make up the majority of a dataset. When applied to the analysis of event sequence data, the task of anomaly detection can be complex because the sequential and temporal nature of such data results in diverse definitions and flexible forms of anomalies. This, in turn, increases the difficulty in interpreting detected anomalies. In this paper, we propose an unsupervised anomaly detection algorithm based on Variational AutoEncoders (VAE) to estimate underlying normal progressions for each given sequence represented as occurrence probabilities of events along the sequence progression. Events in violation of their occurrence probability are identified as abnormal. We also introduce a visualization system, EventThread3 (ET3, to support interactive exploration and interpretations of anomalies within the context of normal sequence progressions in the dataset through comprehensive one-to-many sequence comparison. Finally, we quantitatively evaluate the performance of our anomaly detection algorithm and demonstrate the effectiveness of our system through a case study.","","978-1-7281-0858-2","10.1109/BigData47090.2019.9005687","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005687","data visualization;visual analytics;event sequence data;anomaly detection","Anomaly detection;Data visualization;Interactive systems;Probability;Data security","data visualisation;interactive systems;probability;security of data","visual anomaly detection;event sequence data;unsupervised anomaly detection algorithm;occurrence probability;sequence progression;visualization system;EventThread3;variational autoencoders","","5","","30","IEEE","24 Feb 2020","","","IEEE","IEEE Conferences"
"Visualization Assessment: A Machine Learning Approach","X. Fu; Y. Wang; H. Dong; W. Cui; H. Zhang",Wuhan University; Microsoft Research; Microsoft Research; Microsoft Research; Microsoft Research,"2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","126","130","Researchers assess visualizations from multiple aspects, such as aesthetics, memorability, engagement, and efficiency. However, these assessments are mostly carried out through user studies. There is a lack of automatic visualization assessment approaches, which hinders further applications like visualization recommendation, indexing, and generation. In this paper, we propose automating the visualization assessment process with modern machine learning approaches. We utilize a semi-supervised learning method, which first employs Variational Autoencoder (VAE) to learn effective features from visualizations, subsequently training machine learning models for different assessment tasks. Then, we can automatically assess new visualization images by predicting their scores or rankings with the trained model. To evaluate our method, we run two different assessment tasks, namely, aesthetics and memorability, on different visualization datasets. Experiments show that our method can learn effective visual features and achieves good performance on these assessment tasks.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933570","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933570","Visualization;automated design;visualization assessment;presentation","Task analysis;Visualization;Machine learning;Feature extraction;Data visualization;Training;Predictive models","data visualisation;supervised learning","visual features;automatic visualization assessment approaches;visualization recommendation;visualization assessment process;semisupervised learning method;machine learning models;visualization images;variational autoencoder","","5","","34","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Utilizing Deep Architecture Networks of VAE in Software Fault Prediction","Y. Sun; L. Xu; Y. Li; L. Guo; Z. Ma; Y. Wang","Institute of Information Engineering, Key Laboratory of Space Utilization, Beijing, China; Technology and Engineering Center for Space Utilization Chinese Academy of Sciences, Key Laboratory of Space Utilization, Beijing, China; Technology and Engineering Center for Space Utilization Chinese Academy of Sciences, Key Laboratory of Space Utilization, Beijing, China; Technology and Engineering Center for Space Utilization Chinese Academy of Sciences, Key Laboratory of Space Utilization, Beijing, China; Technology and Engineering Center for Space Utilization Chinese Academy of Sciences, Key Laboratory of Space Utilization, Beijing, China; Institute of Information Engineering, Academy of Sciences, Beijing, China","2018 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Ubiquitous Computing & Communications, Big Data & Cloud Computing, Social Computing & Networking, Sustainable Computing & Communications (ISPA/IUCC/BDCloud/SocialCom/SustainCom)","21 Mar 2019","2018","","","870","877","No matter how experienced the programmers are, it is very hard for them to avoid software fault in software projects. How to predict fault in order to reduce risk and enhance the reliability of software is an important challenge in software engineering. With successful application of deep learning in the field of image processing, voice and natural language, it is time to study how to apply deep learning technology in the field of software fault prediction. In this paper, we adopt deep learning technique of Variational Autoencoder(VAE) for software fault prediction. VAE has the ability to generate new samples according to the distribution of original data, which has been used to generate new images. How to use VAE to predict fault of software is studied in this paper. As we known, there is a problem of imbalanced data in software fault prediction. There always exist less data to indicate failure module and much more data to represent non-failure module. How to classify the data in this situation is an issue worthy of study. In this paper, we utilize the ability of generating new samples to produce failure data in order to balance the failure and non-failure samples. We design the structure of VAE by MLP to fit for the data dimension of software fault and the model of VAE is realized on GPU TITAN X. Five typical classifiers are adopted to verify that our idea of using VAE is effective for software fault prediction in practice.","","978-1-7281-1141-4","10.1109/BDCloud.2018.00129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8672311","Deep Learning;VAE;Imbalanced data;software fault prediction","Software;Deep learning;Decoding;Measurement;Neural networks;Gaussian distribution;Support vector machines","graphics processing units;learning (artificial intelligence);pattern classification;software architecture;software fault tolerance","VAE;software fault prediction;deep architecture networks;software projects;software engineering;variational autoencoder;nonfailure module;MLP;GPU TITAN X","","5","","41","","21 Mar 2019","","","IEEE","IEEE Conferences"
"Leveraging Image-to-image Translation Generative Adversarial Networks for Face Aging","E. Pantraki; C. Kotropoulos; A. Lanitis","Department of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Multimedia and Graphic Arts, Cyprus University of Technology, Limassol, Cyprus","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","8370","8374","Here, face images of a specific age class are translated to images of different age classes in an unsupervised manner that enables training on independent sets of images for each age class. In order to learn pairwise translations between age classes, we adopt the UNsupervised Image-to-image Translation framework that employs Variational AutoEncoders and Generative Adversarial Networks. By mapping face images of different age classes to shared latent representations, the most personalized and abstract facial characteristics are preserved. To effectively diffuse age class information, a pyramid of local, neighbour, and global encoders is employed so that the latent representations progressively cover an increased age range. The proposed framework is applied to the FGNET aging database and compared to state-of-the-art techniques and the ground truth. Appealing experimental results demonstrate the ability of the proposed method to efficiently capture both intense and subtle aging effects.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682965","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682965","face aging;adversarial training;latent space;image-to-image-translation;pyramid","Face;Aging;Training;Gallium nitride;Decoding;Linear programming;Encoding","face recognition;image representation;neural nets","Image-to-image Translation Generative Adversarial Networks;face aging;face images;specific age class;pairwise translations;latent representations;FGNET aging database;subtle aging effects;age class information;unsupervised Image-to-image Translation framework;variational autoencoders","","5","","21","","17 Apr 2019","","","IEEE","IEEE Conferences"
"CodeVIO: Visual-Inertial Odometry with Learned Optimizable Dense Depth","X. Zuo; N. Merrill; W. Li; Y. Liu; M. Pollefeys; G. Huang","Institute of Cyber-System and Control, Zhejiang University; Robot Perception and Navigation Group, University of Delaware; Inceptio Technology, Shanghi, China; Institute of Cyber-System and Control, Zhejiang University; Microsoft Mixed Reality and Artificial Intelligence Lab, Zürich; Robot Perception and Navigation Group, University of Delaware","2021 IEEE International Conference on Robotics and Automation (ICRA)","18 Oct 2021","2021","","","14382","14388","In this work, we present a lightweight, tightly-coupled deep depth network and visual-inertial odometry (VIO) system, which can provide accurate state estimates and dense depth maps of the immediate surroundings. Leveraging the proposed lightweight Conditional Variational Autoencoder (CVAE) for depth inference and encoding, we provide the network with previously marginalized sparse features from VIO to increase the accuracy of initial depth prediction and generalization capability. The compact representation of dense depth, termed depth code, can be updated jointly with navigation states in a sliding window estimator in order to provide the dense local scene geometry. We additionally propose a novel method to obtain the CVAE’s Jacobian which is shown to be more than an order of magnitude faster than previous works, and we additionally leverage First-Estimate Jacobian (FEJ) to avoid recalculation. As opposed to previous works that rely on completely dense residuals, we propose to only provide sparse measurements to update the depth code and show through careful experimentation that our choice of sparse measurements and FEJs can still significantly improve the estimated depth maps. Our full system also exhibits state-of-the-art pose estimation accuracy, and we show that it can run in real-time with single-thread execution while utilizing GPU acceleration only for the network and code Jacobian.","2577-087X","978-1-7281-9077-8","10.1109/ICRA48506.2021.9560792","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9560792","","Jacobian matrices;Geometry;Codes;Automation;Navigation;Conferences;Pose estimation","distance measurement;feature extraction;geometric codes;graphics processing units;image coding;Jacobian matrices;optimisation;pose estimation","visual-inertial odometry;learned optimizable dense depth;tightly-coupled deep depth network;accurate state estimates;dense depth maps;lightweight Conditional Variational Autoencoder;depth inference;encoding;marginalized sparse features;initial depth prediction;generalization capability;compact representation;navigation states;sliding window estimator;dense local scene geometry;CVAE;sparse measurements;estimated depth maps;estimation accuracy;CodeVIO;depth code","","4","","27","IEEE","18 Oct 2021","","","IEEE","IEEE Conferences"
"Continuous Melody Generation via Disentangled Short-Term Representations and Structural Conditions","K. Chen; G. Xia; S. Dubnov","Department of Music, UC San Diego; Music X Lab, NYU Shanghai; Department of Music, UC San Diego","2020 IEEE 14th International Conference on Semantic Computing (ICSC)","12 Mar 2020","2020","","","128","135","Automatic music generation is an interdisciplinary research topic that combines computational creativity and semantic analysis of music to create automatic machine improvisations. An important property of such a system is allowing the user to specify conditions and desired properties of the generated music. In this paper we designed a model for composing melodies given a user specified symbolic scenario combined with a previous music context. We add manual labeled vectors denoting external music quality in terms of chord function that provides a low dimensional representation of the harmonic tension and resolution. Our model is capable of generating long melodies by regarding 8-beat note sequences as basic units, and shares consistent rhythm pattern structure with another specific song. The model contains two stages and requires separate training where the first stage adopts a Conditional Variational Autoencoder (C-VAE) to build a bijection between note sequences and their latent representations, and the second stage adopts long short-term memory networks (LSTM) with structural conditions to continue writing future melodies. We further exploit the disentanglement technique via C-VAE to allow melody generation based on pitch contour information separately from conditioning on rhythm patterns. Finally, we evaluate the proposed model using quantitative analysis of rhythm and the subjective listening study. Results show that the music generated by our model tends to have salient repetition structures, rich motives, and stable rhythm patterns. The ability to generate longer and more structural phrases from disentangled representations combined with semantic scenario specification conditions shows a broad application of our model.","2325-6516","978-1-7281-6332-1","10.1109/ICSC.2020.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9031528","automatic music generation;semantic applications in music;representation learning;deep learning;content analysis on multimedia","Rhythm;Zirconium;Writing;Task analysis;Encoding;Decoding","music;recurrent neural nets","music context;manual labeled vectors;external music quality;chord function;low dimensional representation;harmonic tension;8-beat note sequences;conditional variational autoencoder;C-VAE;long short-term memory networks;structural conditions;disentanglement technique;salient repetition structures;semantic scenario specification conditions;continuous melody generation;disentangled short-term representations;automatic music generation;computational creativity;semantic analysis;automatic machine improvisations;user specified symbolic scenario;rhythm pattern structure","","4","","25","","12 Mar 2020","","","IEEE","IEEE Conferences"
"Cross-View Gait Recognition with Deep Universal Linear Embeddings","S. Zhang; Y. Wang; A. Li","State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","2 Nov 2021","2021","","","9091","9100","Gait is considered an attractive biometric identifier for its non-invasive and non-cooperative features compared with other biometric identifiers such as fingerprint and iris. At present, cross-view gait recognition methods always establish representations from various deep convolutional networks for recognition and ignore the potential dynamical information of the gait sequences. If assuming that pedestrians have different walking patterns, gait recognition can be performed by calculating their dynamical features from each view. This paper introduces the Koopman operator theory to gait recognition, which can find an embedding space for a global linear approximation of a nonlinear dynamical system. Furthermore, a novel framework based on convolutional variational autoencoder and deep Koopman embedding is proposed to approximate the Koopman operators, which is used as dynamical features from the linearized embedding space for cross-view gait recognition. It gives solid physical interpretability for a gait recognition system. Experiments on a large public dataset, OU-MVLP, prove the effectiveness of the proposed method.","2575-7075","978-1-6654-4509-2","10.1109/CVPR46437.2021.00898","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9578019","","Legged locomotion;Visualization;Linear approximation;Feature extraction;Solids;Nonlinear dynamical systems;Task analysis","approximation theory;biometrics (access control);feature extraction;gait analysis;image recognition;nonlinear dynamical systems","biometric identifiers;cross-view gait recognition methods;deep convolutional networks;potential dynamical information;gait sequences;dynamical features;global linear approximation;nonlinear dynamical system;deep Koopman embedding;linearized embedding space;gait recognition system;deep universal linear embeddings;attractive biometric identifier;Koopman operator theory;convolutional variational autoencoder","","4","","50","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Study of Pre-Processing Defenses Against Adversarial Attacks on State-of-the-Art Speaker Recognition Systems","S. Joshi; J. Villalba; P. Żelasko; L. Moro-Velázquez; N. Dehak","Center for Language and Speech Processing (CLSP), Johns Hopkins University, Baltimore, MD, USA; Human Language Technology Center of Excellence, Johns Hopkins University, Baltimore, MD, USA; Human Language Technology Center of Excellence, Johns Hopkins University, Baltimore, MD, USA; Center for Language and Speech Processing (CLSP), Johns Hopkins University, Baltimore, MD, USA; Human Language Technology Center of Excellence, Johns Hopkins University, Baltimore, MD, USA","IEEE Transactions on Information Forensics and Security","19 Oct 2021","2021","16","","4811","4826","Adversarial examples are designed to fool the speaker recognition (SR) system by adding a carefully crafted human-imperceptible noise to the speech signals. Posing a severe security threat to state-of-the-art SR systems, it becomes vital to deep-dive and study their vulnerabilities. Moreover, it is of greater importance to propose countermeasures that can protect the systems against these attacks. Addressing these concerns, we first investigated how state-of-the-art x-vector based SR systems are affected by white-box adversarial attacks, i.e., when the adversary has full knowledge of the system. x-Vector based SR systems are evaluated against white-box adversarial attacks common in the literature like fast gradient sign method (FGSM), basic iterative method (BIM)–a.k.a. iterative-FGSM–, projected gradient descent (PGD), and Carlini-Wagner (CW) attack. To mitigate against these attacks, we investigated four pre-processing defenses which do not need adversarial examples during training. The four pre-processing defenses–viz. randomized smoothing, DefenseGAN, variational autoencoder (VAE), and Parallel WaveGAN vocoder (PWG) are compared against the baseline defense of adversarial training. Performing powerful adaptive white-box adversarial attack (i.e., when the adversary has full knowledge of the system, including the defense), our conclusions indicate that SR systems were extremely vulnerable under BIM, PGD, and CW attacks. Among the proposed pre-processing defenses, PWG combined with randomized smoothing offers the most protection against the attacks, with accuracy averaging 93% compared to 52% in the undefended system and an absolute improvement >90% for BIM attacks with  $L_\infty >0.001$  and CW attack.","1556-6021","","10.1109/TIFS.2021.3116438","Defense Advanced Research Projects Agency (DARPA)(grant numbers:HR001119S0026-GARD-FP-052); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9551961","Speaker recognition;x-vectors;adversarial attacks;adversarial defenses","Training;Psychoacoustic models;Speaker recognition;Robustness;Neural networks;Smoothing methods;Perturbation methods","gradient methods;iterative methods;security of data;speaker recognition;telecommunication security","PWG;Parallel WaveGAN vocoder;VAE;variational autoencoder;DefenseGAN;randomized smoothing;x-vector based SR systems;BIM attacks;CW attack;pre-processing defenses;Carlini-Wagner attack;state-of-the-art speaker recognition systems;adversarial attacks","","4","","80","IEEE","29 Sep 2021","","","IEEE","IEEE Journals"
"Neural Video Coding Using Multiscale Motion Compensation and Spatiotemporal Context Model","H. Liu; M. Lu; Z. Ma; F. Wang; Z. Xie; X. Cao; Y. Wang","School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; OPPO, Inc., Nanjing, China; OPPO, Inc., Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; Faculty of Electrical and Computer Engineering, Tandon School of Engineering, New York University, New York, NY, USA","IEEE Transactions on Circuits and Systems for Video Technology","3 Aug 2021","2021","31","8","3182","3196","Over the past two decades, traditional block-based video coding has made remarkable progress and spawned a series of well-known standards such as MPEG-4, H.264/AVC and H.265/HEVC. On the other hand, deep neural networks (DNNs) have shown their powerful capacity for visual content understanding, feature extraction and compact representation. Some previous works have explored the learnt video coding algorithms in an end-to-end manner, which show the great potential compared with traditional methods. In this paper, we propose an end-to-end deep neural video coding framework (NVC), which uses variational autoencoders (VAEs) with joint spatial and temporal prior aggregation (PA) to exploit the correlations in intra-frame pixels, inter-frame motions and inter-frame compensation residuals, respectively. Novel features of NVC include: 1) To estimate and compensate motion over a large range of magnitudes, we propose an unsupervised multiscale motion compensation network (MS-MCN) together with a pyramid decoder in the VAE for coding motion features that generates multiscale flow fields, 2) we design a novel adaptive spatiotemporal context model for efficient entropy coding for motion information, 3) we adopt nonlocal attention modules (NLAM) at the bottlenecks of the VAEs for implicit adaptive feature extraction and activation, leveraging its high transformation capacity and unequal weighting with joint global and local information, and 4) we introduce multi-module optimization and a multi-frame training strategy to minimize the temporal error propagation among P-frames. NVC is evaluated for the low-delay causal settings and compared with H.265/HEVC, H.264/AVC and the other learnt video compression methods following the common test conditions, demonstrating consistent gains across all popular test sequences for both PSNR and MS-SSIM distortion metrics.","1558-2205","","10.1109/TCSVT.2020.3035680","National Natural Science Foundation of China(grant numbers:62022038); China Scholarship Council(grant numbers:201906190086); OPPO Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9247134","Neural video coding;neural network;multiscale motion compensation;pyramid decoder;multiscale compressed flows;nonlocal attention;spatiotemporal priors;temporal error propagation","Video coding;Motion compensation;Encoding;Bit rate;Decoding;Image coding;Spatiotemporal phenomena","data compression;feature extraction;image sequences;motion compensation;neural nets;optimisation;spatiotemporal phenomena;video coding","spatiotemporal context model;block-based video coding;MPEG-4;deep neural networks;visual content understanding;end-to-end deep neural video coding framework;NVC;VAE;temporal prior aggregation;intra-frame pixels;inter-frame motions;inter-frame compensation residuals;unsupervised multiscale motion compensation network;motion features;multiscale flow fields;motion information;implicit adaptive feature extraction;joint global information;local information;multiframe training strategy;P-frames;learnt video compression methods;variational autoencoders;MS-MCN;temporal error propagation","","4","","50","IEEE","3 Nov 2020","","","IEEE","IEEE Journals"
"Determined Audio Source Separation with Multichannel Star Generative Adversarial Network","L. Li; H. Kameoka; S. Makino","University of Tsukuba, Japan; NTT Communication Science Laboratories, NTT Corporation, Japan; University of Tsukuba, Japan","2020 IEEE 30th International Workshop on Machine Learning for Signal Processing (MLSP)","20 Oct 2020","2020","","","1","6","This paper proposes a multichannel source separation approach, which uses a star generative adversarial network (StarGAN) to model power spectrograms of sources. Various studies have shown the significant contributions of a precise source model to the performance improvement in audio source separation, which indicates the importance of developing a better source model. In this paper, we explore the potential of StarGAN for modeling source spectrograms and investigate the effectiveness of the StarGAN source model in determined multichannel source separation by incorporating it into a frequency-domain independent component analysis (ICA) framework. The experimental results reveal that the proposed StarGAN-based method outperformed conventional methods that use non-negative matrix factorization (NMF) or a variational autoencoder (VAE) for source spectrogram modeling.","1551-2541","978-1-7281-6662-9","10.1109/MLSP49062.2020.9231555","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9231555","Multichannel audio signal processing;determined source separation;star generative adversarial network (StarGAN);spectrogram modeling;deep generative model","Spectrogram;Gallium nitride;Data models;Generators;Generative adversarial networks;Training;Indexes","audio signal processing;frequency-domain analysis;independent component analysis;matrix decomposition;neural nets;source separation","StarGAN source model;StarGAN-based method;source spectrogram modeling;audio source separation;multichannel star generative adversarial network;multichannel source separation approach;nonnegative matrix factorization;frequency-domain ICA framework;frequency-domain independent component analysis framework;VAE;variational autoencoder;NMF","","4","","29","","20 Oct 2020","","","IEEE","IEEE Conferences"
"OpenWGL: Open-World Graph Learning","M. Wu; S. Pan; X. Zhu","Dept. of Computer & Electrical Engineering and Computer Science, Florida Atlantic University, Boca Raton, USA; Faculty of Information Technology, Monash University, Melbourne, Australia; Dept. of Computer & Electrical Engineering and Computer Science, Florida Atlantic University, Boca Raton, USA","2020 IEEE International Conference on Data Mining (ICDM)","9 Feb 2021","2020","","","681","690","In traditional graph learning tasks, such as node classification, learning is carried out in a closed-world setting where the number of classes and their training samples are provided to help train models, and the learning goal is to correctly classify unlabeled nodes into classes already known. In reality, due to limited labeling capability and dynamic evolving of networks, some nodes in the networks may not belong to any existing/seen classes, and therefore cannot be correctly classified by closed-world learning algorithms. In this paper, we propose a new open-world graph learning paradigm, where the learning goal is to not only classify nodes belonging to seen classes into correct groups, but also classify nodes not belonging to existing classes to an unseen class. The essential challenge of the open-world graph learning is that (1) unseen class has no labeled samples, and may exist in an arbitrary form different from existing seen classes; and (2) both graph feature learning and prediction should differentiate whether a node may belong to an existing/seen class or an unseen class. To tackle the challenges, we propose an uncertain node representation learning approach, using constrained variational graph autoencoder networks, where the label loss and class uncertainty loss constraints are used to ensure that the node representation learning are sensitive to unseen class. As a result, node embedding features are denoted by distributions, instead of deterministic feature vectors. By using a sampling process to generate multiple versions of feature vectors, we are able to test the certainty of a node belonging to seen classes, and automatically determine a threshold to reject nodes not belonging to seen classes as unseen class nodes. Experiments on real-world networks demonstrate the algorithm performance, comparing to baselines. Case studies and ablation analysis also show the rationale of our design for open-world graph learning.","2374-8486","978-1-7281-8316-9","10.1109/ICDM50108.2020.00077","NSF(grant numbers:IIS-1763452,CNS-1828181,IIS-2027339); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9338284","graph neural networks;open-world learning;node classification;graph learning","Training;Uncertainty;Heuristic algorithms;Classification algorithms;Labeling;Data mining;Task analysis","graph theory;knowledge representation;learning (artificial intelligence);neural nets;pattern classification;sampling methods;statistical distributions;uncertainty handling","unseen class;node embedding features distribution;open-world graph learning;OpenWGL;sampling process;feature vectors;ablation analysis;node classification;real-world networks;class uncertainty loss constraints;label loss;constrained variational graph autoencoder networks;uncertain node representation learning approach","","4","","34","","9 Feb 2021","","","IEEE","IEEE Conferences"
"A Deep Learning Assisted Method for Measuring Uncertainty in Activity Recognition with Wearable Sensors","A. Akbari; R. Jafari","Department of Biomedical Engineering, Texas A&M University, College Station, TX, USA; Department of Electrical and Computer Engineering, Texas A&M University, College Station, TX, USA","2019 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)","12 Sep 2019","2019","","","1","5","For human activity recognition with wearable sensors, understanding the uncertainty in the classifier decision is necessary to predict sensor failures and design active learning paradigms. Although deep learning models have shown promising results in recognizing human activities from sensor data, it is still challenging to estimate their uncertainty in producing decisions. In this paper, we propose a Bayesian deep convolutional neural network with stochastic latent variables that allows us to estimate both aleatoric (data dependent) and epistemic (model dependent) uncertainties in recognition task. We put a distribution over the latent variables of the model, which are the features that are automatically extracted by the convolutional layers, and show how the inference can be approximated by combining a variational autoencoder with a typical deep neural network classifier. We also leverage Dropout Bayesian neural network to approximate the model uncertainty. The experimental results on a publicly available dataset of human activity recognition with wearable sensors show how each uncertainty (i.e., aleatoric and epistemic) measure is sensitive against different sources of uncertainty namely noisy as well as novel data. Moreover, the uncertainty for the samples that are misclassified by the model is significantly higher on average than the samples that are correctly classified.","2641-3604","978-1-7281-0848-3","10.1109/BHI.2019.8834505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8834505","activity recognition;uncertainty estimation;active learning;deep learning;wearable sensor","Uncertainty;Feature extraction;Mathematical model;Activity recognition;Wearable sensors;Neural networks;Deep learning","approximation theory;Bayes methods;belief networks;convolutional neural nets;image classification;learning (artificial intelligence);stochastic processes","Bayesian neural network;human activity recognition;wearable sensors;deep learning assisted method;active learning paradigms;deep learning models;sensor data;Bayesian deep convolutional neural network;stochastic latent variables;human activities recognition;deep neural network classifier;sensor failure prediction;variational autoencoder","","4","","10","","12 Sep 2019","","","IEEE","IEEE Conferences"
"Generation of Diverse Stages in Turn-Based Role-Playing Game using Reinforcement Learning","S. Nam; K. Ikeda","School of Information Science, JAIST, Ishikawa, Japan; School of Information Science, JAIST, Ishikawa, Japan","2019 IEEE Conference on Games (CoG)","26 Sep 2019","2019","","","1","8","In this study, procedural content generation (PCG) using reinforcement learning (RL) is focused. PCG is defined as the generation of game content tailored to the defined evaluation function using RL models, which is one of the examples of PCG via machine learning. Compared to other generation content areas such as computer vision and natural language process, generative models such as variational autoencoders, PixelCNN, and generative adversarial networks exhibit some difficulties for applications to the game area because during the development of a new game, the content data used for training is typically not sufficient. Hence, RL is considered to be used as a method for PCG. In particular, the stage of turn-based RPG is selected as our research target because it comprises discrete sections, and its parameters were closely related; hence, it is a challenge to generate desirable stages, and the main goal is to generate various stages guided by the designed evaluation function. Two RL models, Deep Q-Network and Deep Deterministic Policy Gradient, respectively, are selected, and the generated stages are evaluated as 0.78 and 0.85 by our designed function, respectively. By the application of the stochastic noise policy, diverse stages are successfully obtained, and those diversities are evaluated by the parameter mse and the different number of valid strategies.","2325-4289","978-1-7281-1884-0","10.1109/CIG.2019.8848090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848090","","","computer games;learning (artificial intelligence);stochastic processes","turn-based role-playing game;reinforcement learning;procedural content generation;PCG;game content;RL models;machine learning;generation content areas;generative models;variational autoencoders;generative adversarial networks;game area;turn-based RPG;deep Q-network;deep deterministic policy gradient;stochastic noise policy","","4","","17","","26 Sep 2019","","","IEEE","IEEE Conferences"
"Channel-Recurrent Autoencoding for Image Modeling","W. Shang; K. Sohn; Y. Tian",University of Amsterdam; NEC Labs; Facebook AI Research,"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)","7 May 2018","2018","","","1195","1204","Despite recent successes in synthesizing faces and bedrooms, existing generative models struggle to capture more complex image types (Figure 1), potentially due to the oversimplification of their latent space constructions. To tackle this issue, building on Variational Autoencoders (VAEs), we integrate recurrent connections across channels to both inference and generation steps, allowing the high-level features to be captured in global-to-local, coarse-to-fine manners. Combined with adversarial loss, our channel-recurrent VAE-GAN (crVAE-GAN) outperforms VAE-GAN in generating a diverse spectrum of high resolution images while maintaining the same level of computational efficacy. Our model produces interpretable and expressive latent representations to benefit downstream tasks such as image completion. Moreover, we propose two novel regularizations, namely the KL objective weighting scheme over time steps and mutual information maximization between transformed latent variables and the outputs, to enhance the training.","","978-1-5386-4886-5","10.1109/WACV.2018.00136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354240","","Training;Gallium nitride;Image reconstruction;Image generation;Computational modeling;Standards;Birds","feature extraction;image representation;image resolution","oversimplification;latent space constructions;Variational Autoencoders;VAEs;recurrent connections;inference;generation steps;high-level features;coarse-to-fine manners;adversarial loss;channel-recurrent VAE-GAN;crVAE-GAN;diverse spectrum;high resolution images;latent representations;image completion;time steps;transformed latent variables;complex image types;generative models struggle;bedrooms;faces;image modeling;channel-recurrent autoencoding","","3","","46","","7 May 2018","","","IEEE","IEEE Conferences"
"Using Latent Representations of Muscle Activation Patterns to Mitigate Myoelectric Interface Noise","Y. Teh; L. J. Hargrove","Department of Biomedical Engineering, Regenstein Center for Bionic Medicine at the Shirley Ryan AbilityLab, Northwestern University, Chicago, IL, USA; Department of Physical Medicine and Rehabilitation and Biomedical Engineering, Regenstein Center for Bionic Medicine, Shirley Ryan AbilityLab, Northwestern University, Chicago, IL, USA","2021 10th International IEEE/EMBS Conference on Neural Engineering (NER)","2 Jun 2021","2021","","","1148","1151","Myoelectric controllers for upper limb prostheses are susceptible to signal disturbances across practical conditions. In particular, electrode liftoff or wire breakage introduce interface noise that, even if only present in a single channel, is detrimental to controller performance. We trained a supervised denoising variational autoencoder to learn a low-dimensional subspace underlying muscle activation patterns that was robust to noise in single EMG channels. Two latent space classifiers, which used the deep learning model, and two conventional LDA-based classifiers were used to classify wrist and hand gestures from clean and synthetically corrupted EMG signals. The baseline LDA classifier, trained on clean data only, suffered a marked increase in errors when evaluated on the corrupted data. The second LDA classifier, trained on clean and corrupted data, improved robustness to noise. Regardless, both latent space methods significantly outperformed both LDA methods in classifying clean and corrupted data. These results highlight that interface noise has adverse effects on current pattern recognition controllers but that deep learning inspired latent space classifiers can mitigate these effects and achieve highly accurate movement classification.","1948-3554","978-1-7281-4337-8","10.1109/NER49283.2021.9441396","National Institutes of Health NIH(grant numbers:R01HD094861); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9441396","prosthesis;myoelectric control;pattern recognition;neural networks;latent representation","Wrist;Deep learning;Noise reduction;Wires;Aerospace electronics;Muscles;Electromyography","biomechanics;electromyography;feature extraction;image denoising;learning (artificial intelligence);medical control systems;medical signal processing;muscle;pattern classification;pattern recognition;prosthetics","latent representations;mitigate myoelectric interface noise;myoelectric controllers;upper limb prostheses;practical conditions;electrode liftoff;single channel;controller performance;supervised denoising variational autoencoder;low-dimensional subspace underlying muscle activation patterns;single EMG channels;latent space classifiers;deep learning model;conventional LDA-based classifiers;wrist;hand gestures;clean corrupted EMG signals;synthetically corrupted EMG signals;baseline LDA classifier;clean data;corrupted data;improved robustness;latent space methods;current pattern recognition controllers","","3","","18","","2 Jun 2021","","","IEEE","IEEE Conferences"
"Low-rate Image Compression with Super-resolution Learning","W. Gao; L. Tao; L. Zhou; D. Yang; X. Zhang; Z. Guo","School of Electronic and Computer Engineering, Shenzhen Graduate School, Peking University, Shenzhen, China; School of Electronic and Computer Engineering, Shenzhen Graduate School, Peking University, Shenzhen, China; School of Electronic and Computer Engineering, Shenzhen Graduate School, Peking University, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China; School of Electronic and Computer Engineering, Shenzhen Graduate School, Peking University, Shenzhen, China; School of Electronic and Computer Engineering, Shenzhen Graduate School, Peking University, Shenzhen, China","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","607","610","In this paper, we propose an end-to-end learned image compression framework for low-rate scenarios. Based on variational autoencoder, our method features a pair of compact-resolution and super-resolution networks, a set of hyper and main codec networks, and a conditional context model. The learning process of this framework is facilitated with integrated non-local attention modules and phase congruency priors. Multiple models are obtained from training with different hyper-parameters, and are jointly used in the image-level model selection process for rate control, which ensures that the bit rate constraint of the CLIC challenge is satisfied. Experimental results demonstrate that the proposed method can achieve an averaged multi-scale structural similarity (MS-SSIM) score of 0.9648 with bit rate consumption of 0.1499 bits per pixel, which outperforms the BPG image coding method significantly.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150923","","Image coding;Image resolution;Bit rate;Training;Codecs;Pattern recognition;Conferences","data compression;feature extraction;image coding;image resolution;learning (artificial intelligence);neural nets","BPG image coding method;bit rate consumption;bit rate constraint;rate control;image-level model selection process;different hyper-parameters;phase congruency priors;integrated nonlocal attention modules;learning process;conditional context model;main codec networks;super-resolution networks;compact-resolution;variational autoencoder;low-rate scenarios;end-to-end learned image compression framework;super-resolution learning;low-rate image compression","","3","","15","IEEE","28 Jul 2020","","","IEEE","IEEE Conferences"
"Style-Conditioned Music Generation","Y. -Q. Lim; C. S. Chan; F. Y. Loo","Centre of Image & Signal Processing, Fac.Comp. Sci. & Info.Tech., University of Malaya, Malaysia; Centre of Image & Signal Processing, Fac.Comp. Sci. & Info.Tech., University of Malaya, Malaysia; Department of Music, University of Malaya, Malaysia","2020 IEEE International Conference on Multimedia and Expo (ICME)","9 Jun 2020","2020","","","1","6","Recent works have shown success in generating music using a Variational Autoencoder (VAE). However, we found out that the style of the generated music is usually governed or limited by the training dataset. In this work, we proposed a new formulation to the VAE that allows users to condition on the style of the generated music. Technically, our VAE consists of two latent spaces- content and style space to encode the content and style of a song separately. Each style is represented by a continuous style embedding, unlike previous works which mostly used discrete or one-hot style labels. We trained our model on public datasets that made up of Bach chorales and western folk tunes. Empirically, as well as from music theory point of view, we show that our proposed model can generate better music samples of each style than a baseline model. The source code and generated samples are available at https: //git;hub. com/daQuincy /DeepMu sicvSt; yle.","1945-788X","978-1-7281-1331-9","10.1109/ICME46284.2020.9102870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9102870","music synthesis;deep learning;style transfer","Decoding;Training;Music;Gallium nitride;Data models;Bars;Machine learning","encoding;music;neural nets","music theory point of view;western folk tunes;Bach chorales;style space;variational autoencoder;music samples;one-hot style labels;continuous style embedding;latent spaces- content;VAE;style-conditioned music generation","","3","","28","","9 Jun 2020","","","IEEE","IEEE Conferences"
"Improving Automatic Jazz Melody Generation by Transfer Learning Techniques","H. -T. Hung; C. -Y. Wang; Y. -H. Yang; H. -M. Wang","Taiwan AI Labs, Taipei, Taiwan; Taiwan AI Labs, Taipei, Taiwan; Research Center for IT Innovation, Academia Sinica, Taipei, Taiwan; Institute of Information Science, Academia Sinica, Taipei, Taiwan","2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","5 Mar 2020","2019","","","339","346","In this paper, we tackle the problem of transfer learning for Jazz automatic generation. Jazz is one of representative types of music, but the lack of Jazz data in the MIDI format hinders the construction of a generative model for Jazz. Transfer learning is an approach aiming to solve the problem of data insufficiency, so as to transfer the common feature from one domain to another. In view of its success in other machine learning problems, we investigate whether, and how much, it can help improve automatic music generation for under-resourced musical genres. Specifically, we use a recurrent variational autoencoder as the generative model, and use a genre-unspecified dataset as the source dataset and a Jazz-only dataset as the target dataset. Two transfer learning methods are evaluated using six levels of source-to-target data ratios. The first method is to train the model on the source dataset, and then fine-tune the resulting model parameters on the target dataset. The second method is to train the model on both the source and target datasets at the same time, but add genre labels to the latent vectors and use a genre classifier to improve Jazz generation. Our subjective evaluation shows that both methods outperform the baseline method that uses Jazz data only for training by a large margin. Among the two methods, the first method seems to perform better. Our evaluation also shows the limits of existing objective metrics in evaluating the performance of music generation models.","2640-0103","978-1-7281-3248-8","10.1109/APSIPAASC47483.2019.9023224","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9023224","","Task analysis;Music;Data models;Machine learning;Training;Bars;Decoding","learning (artificial intelligence);music;pattern classification","automatic Jazz melody generation;transfer learning techniques;Jazz automatic generation;generative model;data insufficiency;machine learning problems;automatic music generation;under-resourced musical genres;recurrent variational autoencoder;genre-unspecified dataset;transfer learning methods;source-to-target data ratios;genre labels;genre classifier;Jazz generation;music generation models","","3","","27","","5 Mar 2020","","","IEEE","IEEE Conferences"
"BDTwin: An Integrated Framework for Enhancing Security and Privacy in Cybertwin-Driven Automotive Industrial Internet of Things","R. Kumar; P. Kumar; R. Tripathi; G. P. Gupta; S. Garg; M. M. Hassan","Department of Information Technology, National Institute of Technology Raipur, Raipur, India; Information Technology, National Institute of Technology Raipur, Raipur, India; Information Technology, National Institute of Technology Raipur, Raipur, India; Information Technology, National Institute of Technology Raipur, Raipur, India; Electrical Engineering Department, École de Technologie Supérieure, Université du Québec, Montreal, Canada; College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia","IEEE Internet of Things Journal","7 Sep 2022","2022","9","18","17110","17119","The rapid development of the automotive Industrial Internet of Things requires secure networking infrastructure toward digitalization. Cybertwin (CT) is a next-generation networking architecture that serves as a communication, and digital asset owner, and can make the Vehicle-to-Everything (V2X) network flexible and secure. However, CT itself can publish end users’ digital assets to other entities as a service, making data security and privacy major obstacles in the realization of V2X applications. Motivated from the aforementioned discussion, this article presents BDTwin, a blockchain and deep-learning-based integrated framework to enhance security and privacy in CT-driven V2X applications. Specifically, a blockchain scheme is designed to ensure secure communication among vehicles, roadside units, CT-edge server, and cloud server using a smart contract-based enhance-Proof-of-Work (ePoW) and Zero Knowledge Proof (ZKP)-based verification process. Smart contracts are used to enforce rules and regulations that govern the behavior of V2X entities in a nondeniable and automated manner. In a deep-learning scheme, an autoregressive-deep variational autoencoder model is combined with attention-based bidirectional long short-term memory (A-BLSTM) for automatic feature extraction and attack detection by analyzing CT-edge servers data in a V2X environment. Security analysis and experimental results using two different sources, ToN-IoT and CICIDS-2017 show the superiority of the proposed BDTwin framework over some baseline and recent state-of-the-art techniques.","2327-4662","","10.1109/JIOT.2021.3122021","King Saud University, Riyadh, Saudi Arabia, through the Researchers Supporting Project(grant numbers:RSP-2021/18); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9583667","Cybertwin (CT);deep learning;Industrial Internet of Things (IIoT);intrusion detection system (IDS);privacy preservation;Vehicle to Everything (V2X)","Blockchains;Servers;Security;Vehicle-to-everything;Smart contracts;Industrial Internet of Things;Cloud computing","blockchains;cloud computing;computer network security;data privacy;deep learning (artificial intelligence);digital signatures;feature extraction;Internet of Things;mobile computing;vehicular ad hoc networks","networking infrastructure;next-generation networking architecture;digital asset owner;data security;deep-learning-based integrated framework;CT-driven V2X applications;blockchain scheme;secure communication;cloud server;smart contracts;autoregressive-deep variational autoencoder model;attention-based bidirectional long short-term memory;CT-edge servers data;BDTwin framework;cybertwin-driven automotive industrial Internet of Things;A-BLSTM;V2X environment;security analysis;ToN-IoT;CICIDS-2017;vehicle-to-everything network;smart contract-based enhance-proof-of-work;ePoW;zero knowledge proof-based verification process;ZKP-based verification process","","3","","38","IEEE","21 Oct 2021","","","IEEE","IEEE Journals"
"On the use of generative deep neural networks to synthesize artificial multichannel EEG signals","O. Özdenizci; D. Erdoğmuş","Institute of Theoretical Computer Science, Graz University of Technology, Graz, Austria; Department of Electrical and Computer Engineering, Cognitive Systems Laboratory, Northeastern University, Boston, MA, USA","2021 10th International IEEE/EMBS Conference on Neural Engineering (NER)","2 Jun 2021","2021","","","427","430","Recent promises of generative deep learning lately brought interest to its potential uses in neural engineering. In this paper we firstly review recently emerging studies on generating artificial electroencephalography (EEG) signals with deep neural networks. Subsequently, we present our feasibility experiments on generating condition-specific multichannel EEG signals using conditional variational autoencoders. By manipulating real resting-state EEG epochs, we present an approach to synthetically generate time-series multichannel signals that show spectro-temporal EEG patterns which are expected to be observed during distinct motor imagery conditions.","1948-3554","978-1-7281-4337-8","10.1109/NER49283.2021.9441381","NSF(grant numbers:IIS-1149570,CNS-1544895,IIS-1715858); DHHS(grant numbers:90RE5017-02-01); NIH(grant numbers:R01DC009834); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9441381","","Deep learning;Electric potential;Systematics;Image color analysis;Neural networks;Layout;Neural engineering","electroencephalography;learning (artificial intelligence);medical signal processing;neural nets","generative deep neural networks;artificial multichannel EEG signals;recent promises;generative deep learning;neural engineering;artificial electroencephalography signals;feasibility experiments;condition-specific multichannel EEG signals;conditional variational autoencoders;manipulating real resting-state EEG epochs;time-series multichannel signals;distinct motor imagery conditions","","3","","24","","2 Jun 2021","","","IEEE","IEEE Conferences"
"Out-of-Distribution Detection in Multi-Label Datasets using Latent Space of β-VAE","V. K. Sundar; S. Ramakrishna; Z. Rahiminasab; A. Easwaran; A. Dubey",The authors have equally contributed towards this work; The authors have equally contributed towards this work; Nanyang Technological University; Nanyang Technological University; Vanderbilt University,"2020 IEEE Security and Privacy Workshops (SPW)","18 Dec 2020","2020","","","250","255","Learning Enabled Components (LECs) are widely being used in a variety of perceptions based autonomy tasks like image segmentation, object detection, end-to-end driving, etc. These components are trained with large image datasets with multimodal factors like weather conditions, time-of-day, traffic-density, etc. The LECs learn from these factors during training, and while testing if there is variation in any of these factors, the components get confused resulting in low confidence predictions. Those images with factor values, not seen, during training are commonly referred to as Out-of-Distribution (OOD). For safe autonomy, it is important to identify the OOD images, so that a suitable mitigation strategy can be performed. Classical one-class classifiers like SVM and SVDD are used to perform OOD detection. However, multiple labels attached to images in these datasets restrict the direct application of these techniques. We address this problem using the latent space of the β -Variational Autoencoder ( β -VAE). We use the fact that compact latent space generated by an appropriately selected β - VAE will encode the information about these factors in a few latent variables, and that can be used for quick and computationally inexpensive detection. We evaluate our approach on the nuScenes dataset, and our results show the latent space of β - VAE is sensitive to encode changes in the values of the generative factor.","","978-1-7281-9346-5","10.1109/SPW50608.2020.00057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283847","VAE;Disentanglement;KL-divergence;Out-of-Distribution","Training;Support vector machines;Object detection;Security;Task analysis;Testing;Meteorology","feature extraction;image processing;learning (artificial intelligence);neural nets","β -variational autoencoder;autonomy tasks;LECs;learning enabled components;β-VAE;multilabel datasets;out-of-distribution detection;latent variables;OOD detection;mitigation strategy;OOD images","","3","","15","","18 Dec 2020","","","IEEE","IEEE Conferences"
"CausalVAE: Disentangled Representation Learning via Neural Structural Causal Models","M. Yang; F. Liu; Z. Chen; X. Shen; J. Hao; J. Wang","University College London, London, United Kingdom; Noah’s Ark Lab, Huawei, Shenzhen, China; Noah’s Ark Lab, Huawei, Shenzhen, China; The Hong Kong University of Science and Technology, Hong Kong, China; Noah’s Ark Lab, Huawei, Shenzhen, China; University College London, London, United Kingdom","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","2 Nov 2021","2021","","","9588","9597","Learning disentanglement aims at finding a low dimensional representation which consists of multiple explanatory and generative factors of the observational data. The framework of variational autoencoder (VAE) is commonly used to disentangle independent factors from observations. However, in real scenarios, factors with semantics are not necessarily independent. Instead, there might be an underlying causal structure which renders these factors dependent. We thus propose a new VAE based framework named CausalVAE, which includes a Causal Layer to transform independent exogenous factors into causal endogenous ones that correspond to causally related concepts in data. We further analyze the model identifiabitily, showing that the proposed model learned from observations recovers the true one up to a certain degree. Experiments are conducted on various datasets, including synthetic and real word benchmark CelebA. Results show that the causal representations learned by CausalVAE are semantically interpretable, and their causal relationship as a Directed Acyclic Graph (DAG) is identified with good accuracy. Furthermore, we demonstrate that the proposed CausalVAE model is able to generate counterfactual data through ""do-operation"" to the causal factors.","2575-7075","978-1-6654-4509-2","10.1109/CVPR46437.2021.00947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9578520","","Analytical models;Directed acyclic graph;Computer vision;Semantics;Transforms;Benchmark testing;Data models","directed graphs;learning (artificial intelligence);neural nets","CausalVAE model;counterfactual data;variational autoencoder;VAE based framework;Causal Layer;CausalVAE;neural structural causal models;CelebA synthetic word benchmark","","3","","36","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Multivariate Financial Time-Series Prediction With Certified Robustness","H. Li; Y. Cui; S. Wang; J. Liu; J. Qin; Y. Yang","School of Labor Economics, Capital University of Economies and Business, Beijing, China; Agriculture Information Institute, Chinese Academy of Agricultural Sciences, Beijing, China; CSIRO, Canberra, Australia; Agriculture Information Institute, Chinese Academy of Agricultural Sciences, Beijing, China; Faculty of Business and Economics, University of Melbourne, Melbourne, Australia; Faculty of Science, The University of British Columbia, Vancouver, Canada","IEEE Access","18 Jun 2020","2020","8","","109133","109143","The futures market's forecasts are significant to investors and policymakers, where the application of deep learning approaches to finance has received a great deal of attention. In this study, we propose a multivariate financial time-series forecasting method. Our model addresses the long- and short-term features, multimodal and non-stationarity nature of multivariate time-series by incorporating the improved deep neural networks and certified noise injection. Specifically, multimodal variational autoencoder is used to extract deep high-level features of multivariate time-series, Long- and Short- Term recurrent neural network is applied for multivariate time-series forecasting, and certified noise injection mechanism, inspired by differential privacy, is proposed to improve the robustness and accuracy of prediction. Extensive empirical results on real-world agricultural commodity futures price time series and relevant external data demonstrate that our model achieves better performance over that of several state-of-the-art baseline methods.","2169-3536","","10.1109/ACCESS.2020.3001287","Innovation Program of Agricultural Information Institute, Chinese Academy of Agricultural Sciences(grant numbers:2020CX043); Fundamental Research Funds of Chinese Academy of Agricultural Sciences(grant numbers:Y2020PT14); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9113475","Futures prices;deep neural networks;prediction;multivariate;Gaussian noise","Time series analysis;Feature extraction;Differential privacy;Logic gates;Sensitivity;Robustness;Predictive models","agriculture;financial data processing;learning (artificial intelligence);pricing;recurrent neural nets;time series","differential privacy;multivariate financial time-series forecasting;agricultural commodity;noise injection mechanism;recurrent neural network;multimodal variational autoencoder;deep neural networks;deep learning","","3","","37","CCBY","10 Jun 2020","","","IEEE","IEEE Journals"
"Stacking VAE and GAN for Context-aware Text-to-Image Generation","C. Zhang; Y. Peng","Institute of Computer Science and Technology, Peking University, Beijing, China; Institute of Computer Science and Technology, Peking University, Beijing, China","2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)","21 Oct 2018","2018","","","1","5","Generating high-quality images based on text descriptions is an appealing research topic, which has widespread applications in various fields. However, it is quite challenging since that images and language descriptions in real world are noisy with great variability. Most existing text-to-image methods aim to generate images in a holistic manner, which ignore the difference between images' foreground and background, resulting in that objects in images are easily disturbed by the background. Moreover, they commonly ignore the complementarity of different kinds of generative models. In this paper, we propose a context-aware approach to perform text-to-image generation, which separates background and foreground for generating high-quality images, as well as utilizes complementarity between Variational Autoencoder (VAE) and Generative Adversarial Network (GAN) for robust text-to-image generation. First, context-aware conditional VAE is proposed to capture images' basic layout and color based on text, which pays different attention on the background and foreground of images for effective text-image alignment. Then, conditional GAN is adopted for refining the generation of VAE, which recovers lost details and corrects the defects for realistic image generation. Attributed to such stacked VAE-GAN structure, two kinds of generative models can boost each other for more effective and stable text-to-image generation. Experimental results on 2 widely-used datasets empirically verify the effectiveness of our proposed approach.","","978-1-5386-5321-0","10.1109/BigMM.2018.8499439","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8499439","text-to-image;context-aware learning;deep generative model","Gallium nitride;Generative adversarial networks;Image generation;Generators;Layout;Image color analysis;Decoding","image colour analysis;image reconstruction;neural nets;text analysis;ubiquitous computing","high-quality image generation;text-to-image methods;generative adversarial network;variational autoencoder;conditional GAN;effective text-image alignment;context-aware conditional VAE;robust text-to-image generation;language descriptions;text descriptions;context-aware text-to-image generation;stable text-to-image generation;effective text-to-image generation;stacked VAE-GAN structure","","3","","27","","21 Oct 2018","","","IEEE","IEEE Conferences"
"P2TIF: A Blockchain and Deep Learning Framework for Privacy-Preserved Threat Intelligence in Industrial IoT","P. Kumar; R. Kumar; G. P. Gupta; R. Tripathi; G. Srivastava","National Institute of Technology Raipur, Raipur, India; National Institute of Technology Raipur, Raipur, India; National Institute of Technology Raipur, Raipur, India; National Institute of Technology Raipur, Raipur, India; Research Centre for Interneural Computing, China Medical University, Taichung, Taiwan","IEEE Transactions on Industrial Informatics","14 Jun 2022","2022","18","9","6358","6367","The industrial Internet of Things (IIoT) is a fast-growing network of Internet-connected sensing and actuating devices aimed to enhance manufacturing and industrial operations. This interconnection generates a high volume of data over the IIoT network and raises serious security (e.g., the rapid evolution of hacking techniques), privacy (e.g., adversaries performing data poisoning and inference attacks), and scalability issues. To mitigate the aforementioned challenges, this article presents, a new privacy-preserved threat intelligence framework (P2TIF) to protect confidential information and to identify cyber-threats in IIoT environments. There are two major elements in the proposed P2TIF framework. First, a scalable blockchain module that enables secure communication of IIoT data and prevents data poisoning attacks. Second, a deep learning module that transforms actual data into a new format and protects data from inference attacks using a deep variational autoencoder (DVAE) technique. The encoded data are then employed by a threat detection system using attention-based deep gated recurrent neural network (A-DGRNN) to recognize malicious patterns in IIoT environments. The proposed framework is validated using two different network data sources, i.e., ToN-IoT and IoT-Botnet. Security analysis and experimental results revealed the high efficiency and scalability of the proposed P2TIF framework.","1941-0050","","10.1109/TII.2022.3142030","Mathematical Research Impact Centric Support; Science and Engineering Research Board(grant numbers:MTR/2019/001285); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678009","Blockchain;deep learning (DL);industrial Internet of Things (IIoT);privacy-preservation;threat intelligence (TI)","Industrial Internet of Things;Blockchains;Security;Deep learning;Scalability;Computational modeling;Transforms","computer network security;data privacy;deep learning (artificial intelligence);Internet of Things;invasive software;recurrent neural nets","industrial IoT;Internet-connected sensing;industrial operations;IIoT network;hacking techniques;inference attacks;scalability issues;privacy-preserved threat intelligence framework;cyber-threats;IIoT environments;P2TIF framework;scalable blockchain module;secure communication;IIoT data;data poisoning attacks;deep learning module;deep variational autoencoder technique;encoded data;threat detection system;network data sources;attention-based deep gate recurrent neural network","","3","","35","IEEE","11 Jan 2022","","","IEEE","IEEE Journals"
"q-VAE for Disentangled Representation Learning and Latent Dynamical Systems","T. Kobayashis","Division of Information Science, Nara Institute of Science and Technology, Ikoma, Japan","IEEE Robotics and Automation Letters","27 Jul 2020","2020","5","4","5669","5676","A variational autoencoder (VAE) derived from Tsallis statistics called q-VAE is proposed. In the proposed method, a standard VAE is employed to statistically extract latent space hidden in sampled data, and this latent space helps make robots controllable in feasible computational time and cost. To improve the usefulness of the latent space, this letter focuses on disentangled representation learning, e.g., β-VAE, which is the baseline for it. Starting from a Tsallis statistics perspective, a new lower bound for the proposed q-VAE is derived to maximize the likelihood of the sampled data, which can be considered an adaptive β-VAE with deformed Kullback-Leibler divergence. To verify the benefits of the proposed q-VAE, a benchmark task to extract the latent space from the MNIST dataset was performed. The results demonstrate that the proposed q-VAE improved disentangled representation while maintaining the reconstruction accuracy of the data. In addition, it relaxes the independency condition between data, which is demonstrated by learning the latent dynamics of nonlinear dynamical systems. By combining disentangled representation, the proposed q-VAE achieves stable and accurate long-term state prediction from the initial state and the action sequence.","2377-3766","","10.1109/LRA.2020.3010206","JSPS KAKENHI; Scientific Research (B)(grant numbers:20H04265); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9143393","Novel deep learning methods;model learning for control","Feature extraction;Aerospace electronics;Standards;Robots;Machine learning;Decoding;Gaussian distribution","learning (artificial intelligence)","disentangled representation learning;latent dynamical systems;standard VAE;latent space;sampled data;computational time;Tsallis statistics perspective;adaptive β-VAE;q-VAE improved disentangled representation;latent dynamics;long-term state prediction;variational autoencoder","","3","","35","IEEE","17 Jul 2020","","","IEEE","IEEE Journals"
"Anonysign: Novel Human Appearance Synthesis for Sign Language Video Anonymisation","B. Saunders; N. C. Camgoz; R. Bowden",University of Surrey; University of Surrey; University of Surrey,"2021 16th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2021)","12 Jan 2022","2021","","","1","8","The visual anonymisation of sign language data is an essential task to address privacy concerns raised by large-scale dataset collection. Previous anonymisation techniques have either significantly affected sign comprehension or required manual, labour-intensive work. In this paper, we formally introduce the task of Sign Language Video Anonymisation (SLVA) as an automatic method to anonymise the visual appearance of a sign language video whilst retaining the meaning of the original sign language sequence. To tackle SLVA, we propose Anonysign, a novel automatic approach for visual anonymisation of sign language data. We first extract pose information from the source video to remove the original signer appearance. We next generate a photo-realistic sign language video of a novel appearance from the pose sequence, using image-to-image translation methods in a conditional variational autoencoder framework. An approximate posterior style distribution is learnt, which can be sampled from to synthesise novel human appearances. In addition, we propose a novel style loss that ensures style consistency in the anonymised sign language videos. We evaluate ANONYSIGN for the SLVA task with extensive quantitative and qualitative experiments highlighting both realism and anonymity of our novel human appearance synthesis. In addition, we formalise an anonymity perceptual study as an evaluation criteria for the SLVA task and showcase that video anonymisation using ANONYSIGN retains the original sign language content.","","978-1-6654-3176-7","10.1109/FG52635.2021.9666984","EPSRC(grant numbers:EP/R03298X/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9666984","","Training;Visualization;Data privacy;Face recognition;Conferences;Gesture recognition;Manuals","computer animation;data privacy;feature extraction;handicapped aids;image classification;image sequences;neural nets;pose estimation;sign language recognition;video signal processing","Anonysign;source video;original signer appearance;photo-realistic sign language video;ANONYSIGN;SLVA task;affected sign comprehension;visual appearance;original sign language sequence;human appearance synthesis;sign language video anonymisation;privacy concerns;large-scale dataset collection;sign language data visual anonymisation;pose information extraction;image-to-image translation methods;conditional variational autoencoder framework;approximate posterior style distribution;style consistency;anonymity perceptual study","","3","","47","IEEE","12 Jan 2022","","","IEEE","IEEE Conferences"
"Generative Model for Zero-Shot Sketch-Based Image Retrieval","V. K. Verma; A. Mishra; A. Mishra; P. Rai",IIT-Kanpur; IIT-Guwahati; IIT-Madras; IIT-Kanpur,"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","9 Apr 2020","2019","","","704","713","We present a probabilistic model for Sketch-Based Image Retrieval (SBIR) where, at retrieval time, we are given sketches from novel classes, that were not present at training time. Existing SBIR methods, most of which rely on learning class-wise correspondences between sketches and images, typically work well only for previously seen sketch classes, and result in poor retrieval performance on novel classes. To address this, we propose a generative model that learns to generate images, conditioned on a given novel class sketch. This enables us to reduce the SBIR problem to a standard image-to-image search problem. Our model is based on an inverse auto-regressive flow based variational autoencoder, with a feedback mechanism to ensure robust image generation. We evaluate our model on two very challenging datasets, Sketchy, and TU Berlin, with novel train-test split. The proposed approach significantly outperforms various baselines on both the datasets.","2160-7516","978-1-7281-2506-0","10.1109/CVPRW.2019.00097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9025475","","Computational modeling;Image retrieval;Standards;Training;Jacobian matrices;Search problems;Image generation","autoregressive processes;image retrieval;learning (artificial intelligence);neural nets;probability;search problems","class-wise correspondence learning;train-test split;TU Berlin dataset;Sketchy dataset;feedback mechanism;inverse auto-regressive flow based variational autoencoder,;robust image generation;standard image-to-image search problem;SBIR problem;sketch classes;SBIR methods;training time;retrieval time;probabilistic model;zero-shot sketch-based image retrieval;generative model","","3","","56","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Class-Incremental Learning with Generative Classifiers","G. M. van de Ven; Z. Li; A. S. Tolias","Computational and Biological Learning Lab, University of Cambridge, Cambridge, United Kingdom; Center for Neuroscience and Artificial Intelligence, Baylor College of Medicine, Houston, Texas, USA; Department of Electrical and Computer Engineering, Rice University, Houston, Texas, USA","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","1 Sep 2021","2021","","","3606","3615","Incrementally training deep neural networks to recognize new classes is a challenging problem. Most existing class-incremental learning methods store data or use generative replay, both of which have drawbacks, while ‘rehearsal-free’ alternatives such as parameter regularization or bias-correction methods do not consistently achieve high performance. Here, we put forward a new strategy for class-incremental learning: generative classification. Rather than directly learning the conditional distribution p(y|x), our proposal is to learn the joint distribution p(x, y), factorized as p(x|y)p(y), and to perform classification using Bayes’ rule. As a proof-of-principle, here we implement this strategy by training a variational autoencoder for each class to be learned and by using importance sampling to estimate the likelihoods p(x|y). This simple approach performs very well on a diverse set of continual learning benchmarks, outperforming generative replay and other existing baselines that do not store data.","2160-7516","978-1-6654-4899-4","10.1109/CVPRW53098.2021.00400","Advanced Research Projects Agency; Intelligence Advanced Research Projects Activity; Interior Business Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9522984","","Training;Learning systems;Deep learning;Computer vision;Monte Carlo methods;Conferences;Benchmark testing","learning (artificial intelligence);neural nets;pattern classification","generative classifiers;deep neural networks;generative replay;rehearsal-free alternatives;bias-correction methods;generative classification;continual learning benchmarks;class-incremental learning methods;conditional distribution;Bayes rule;variational autoencoder","","3","","56","IEEE","1 Sep 2021","","","IEEE","IEEE Conferences"
"Informed Information Theoretic Model Predictive Control","R. Kusumoto; L. Palmieri; M. Spies; A. Csiszar; K. O. Arras","ISW, University of Stuttgart, Germany; Robert Bosch GmbH, Corporate Research, Stuttgart, Germany; Robert Bosch GmbH, Center for Artificial Intelligence, Stuttgart, Germany; ISW, University of Stuttgart, Germany; Robert Bosch GmbH, Corporate Research, Stuttgart, Germany","2019 International Conference on Robotics and Automation (ICRA)","12 Aug 2019","2019","","","2047","2053","The problem of minimizing cost in nonlinear control systems with uncertainties or disturbances remains a major challenge. Model predictive control (MPC), and in particular sampling-based MPC has recently shown great success in complex domains such as aggressive driving with highly nonlinear dynamics. Sampling-based methods rely on a prior distribution to generate samples in the first place. Obviously, the choice of this distribution highly influences efficiency of the controller. Existing approaches such as sampling around the control trajectory of the previous time step perform suboptimally, especially in multi-modal or highly dynamic settings. In this work, we therefore propose to learn models that generate samples in low-cost areas of the state-space, conditioned on the environment and on contextual information of the task to solve. By using generative models as an informed sampling distribution, our approach exploits guidance from the learned models and at the same time maintains robustness properties of the MPC methods. We use Conditional Variational Autoencoders (CVAE) to learn distributions that imitate samples from a training dataset containing optimized controls. An extensive evaluation in the autonomous navigation domain suggests that replacing previous sampling schemes with our learned models considerably improves performance in terms of path quality and planning efficiency.","2577-087X","978-1-5386-6027-0","10.1109/ICRA.2019.8793945","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8793945","","Task analysis;Optimal control;Trajectory;Decoding;Robots;Planning;Cost function","nonlinear control systems;nonlinear dynamical systems;optimal control;optimisation;predictive control;robust control;sampling methods","informed sampling distribution;optimized controls;informed information theoretic model predictive control;nonlinear control systems;uncertainties;highly nonlinear dynamics;contextual information;generative models;trajectory control;sampling-based MPC methods;robustness properties;conditional variational autoencoders;autonomous navigation domain","","3","","26","","12 Aug 2019","","","IEEE","IEEE Conferences"
"Self-Supervised Audio-Visual Feature Learning for Single-Modal Incremental Terrain Type Clustering","R. Ishikawa; R. Hachiuma; H. Saito","Department of Information and Computer Science, Keio University, Yokohama, Japan; Department of Information and Computer Science, Keio University, Yokohama, Japan; Department of Information and Computer Science, Keio University, Yokohama, Japan","IEEE Access","30 Apr 2021","2021","9","","64346","64357","The key to an accurate understanding of terrain is to extract the informative features from the multi-modal data obtained from different devices. Sensors, such as RGB cameras, depth sensors, vibration sensors, and microphones, are used as the multi-modal data. Many studies have explored ways to use them, especially in the robotics field. Some papers have successfully introduced single-modal or multi-modal methods. However, in practice, robots can be faced with extreme conditions; microphones do not work well in crowded scenes, and an RGB camera cannot capture terrains well in the dark. In this paper, we present a novel framework using the multi-modal variational autoencoder and the Gaussian mixture model clustering algorithm on image data and audio data for terrain type clustering by forcing the features to be closer together in the feature space. Our method enables the terrain type clustering even if one of the modalities (either image or audio) is missing at the test-time. We evaluated the clustering accuracy with a conventional multi-modal terrain type clustering method and we conducted ablation studies to show the effectiveness of our approach.","2169-3536","","10.1109/ACCESS.2021.3075582","JST-Mirai Program, Japan(grant numbers:JPMJMI19B2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9416486","Self-supervised;terrain type clustering;multi-modal learning","Feature extraction;Robots;Sensors;Data mining;Training;Visualization;Testing","audio signal processing;feature extraction;Gaussian processes;geophysical image processing;image colour analysis;learning (artificial intelligence);pattern clustering;terrain mapping;video signal processing","informative feature extraction;multimodal data;RGB camera;depth sensors;vibration sensors;microphones;robotics field;multimodal variational autoencoder;image data;audio data;feature space;multimodal terrain type clustering method;self-supervised audio-visual feature learning;single-modal incremental terrain type clustering","","2","","57","CCBY","26 Apr 2021","","","IEEE","IEEE Journals"
"Towards Zero-Shot Learning with Fewer Seen Class Examples","V. K. Verma; A. Mishra; A. Pandey; H. A. Murthy; P. Rai","Department of CSE, IIT Kanpur; Department of CSE, IIT Madras; Department of CSE, IIT Madras; Department of CSE, IIT Madras; Department of CSE, IIT Kanpur","2021 IEEE Winter Conference on Applications of Computer Vision (WACV)","14 Jun 2021","2021","","","2240","2250","We present a meta-learning based generative model for zero-shot learning (ZSL) towards a challenging setting when the number of training examples from each seen class is very few. This setup contrasts with the conventional ZSL approaches, where training typically assumes the availability of a sufficiently large number of training examples from each of the seen classes. The proposed approach leverages meta-learning to train a deep generative model that integrates variational autoencoder and generative adversarial networks. We propose a novel task distribution where meta-train and meta-validation classes are disjoint to simulate the ZSL behaviour in training. Once trained, the model can generate synthetic examples from seen and unseen classes. Synthesize samples can then be used to train the ZSL framework in a supervised manner. The meta-learner enables our model to generates high-fidelity samples using only a small number of training examples from seen classes. We conduct extensive experiments and ablation studies on four benchmark datasets of ZSL and observe that the proposed model outperforms state-of-the-art approaches by a significant margin when the number of examples per seen class is very small.","2642-9381","978-1-6654-0477-8","10.1109/WACV48630.2021.00229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9423081","","Training;Computer vision;Computational modeling;Conferences;Computer architecture;Benchmark testing;Generative adversarial networks","deep learning (artificial intelligence);neural nets","deep generative model;generative adversarial networks;ZSL behaviour;ZSL framework;zero-shot learning;meta-learning based generative model;ZSL approach;variational autoencoder","","2","","60","","14 Jun 2021","","","IEEE","IEEE Conferences"
"Semi-supervised Synthesis of High-Resolution Editable Textures for 3D Humans","B. Chaudhuri; N. Sarafianos; L. Shapiro; T. Tung","University of Washington; Facebook Reality Labs Research, Sausalito; University of Washington; Facebook Reality Labs Research, Sausalito","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","2 Nov 2021","2021","","","7987","7996","We introduce a novel approach to generate diverse high fidelity texture maps for 3D human meshes in a semi-supervised setup. Given a segmentation mask defining the layout of the semantic regions in the texture map, our network generates high-resolution textures with a variety of styles, that are then used for rendering purposes. To accomplish this task, we propose a Region-adaptive Adversarial Variational AutoEncoder (ReAVAE) that learns the probability distribution of the style of each region individually so that the style of the generated texture can be controlled by sampling from the region-specific distributions. In addition, we introduce a data generation technique to augment our training set with data lifted from single-view RGB inputs. Our training strategy allows the mixing of reference image styles with arbitrary styles for different regions, a property which can be valuable for virtual try-on AR/VR applications. Experimental results show that our method synthesizes better texture maps compared to prior work while enabling independent layout and style controllability.","2575-7075","978-1-6654-4509-2","10.1109/CVPR46437.2021.00790","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9577897","","Training;Surface reconstruction;Three-dimensional displays;Layout;Semantics;Rendering (computer graphics);Probability distribution","image colour analysis;image resolution;image segmentation;image texture;learning (artificial intelligence);mesh generation;probability;rendering (computer graphics);solid modelling;stereo image processing;virtual reality","semisupervised synthesis;high-resolution editable textures;diverse high fidelity texture maps;3D human meshes;semisupervised setup;segmentation mask;high-resolution textures;rendering purposes;probability distribution;generated texture;region-specific distributions;data generation technique;single-view RGB inputs;reference image styles;arbitrary styles;style controllability;region-adaptive adversarial variational autoencoder;ReAVAE;virtual try-on AR/VR applications","","2","","52","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Learning A Wafer Feature With One Training Sample","Y. J. Zeng; L. -C. Wang; C. J. Shan; N. Sumikawa","University of California, Santa Barbara, Santa Barbara, California; University of California, Santa Barbara, Santa Barbara, California; IE3A, Inc., Los Angeles, California; NXP Semiconductor, Chandler, AZ","2020 IEEE International Test Conference (ITC)","20 Jan 2021","2020","","","1","10","In this work, we consider learning a wafer plot recognizer where only one training sample is available. We introduce an approach called Manifestation Learning to enable the learning. The underlying technology utilizes the Variational AutoEncoder (VAE) approach to construct a so-called Manifestation Space. The training sample is projected into this space and the recognition is achieved through a pre-trained model in the space. Using wafer probe test data from an automotive product line, this paper explains the learning approach, its feasibility and limitation.","2378-2250","978-1-7281-9113-3","10.1109/ITC44778.2020.9325254","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9325254","","Training;Semiconductor device modeling;Decoding;Software;Software algorithms;Noise reduction;Tensors","learning (artificial intelligence)","training sample;wafer probe test data;learning approach;wafer feature;wafer plot recognizer;variational autoencoder approach;manifestation space;manifestation learning;VAE","","2","","25","","20 Jan 2021","","","IEEE","IEEE Conferences"
"Fast Sparse Connectivity Network Adaption via Meta-Learning","B. Jin; K. Cheng; Y. Qu; L. Zhang; K. Xiao; X. Lu; X. Wei","Dalian University of Technology, Dalian, China; Dalian University of Technology, Dalian, China; Dalian University of Technology, Dalian, China; Dongbei University of Finance and Economics, Dalian, China; Stony Brook University, New York, United States; Business Intelligence Lab, Baidu Research, Beijing, China; Dalian University of Technology, Dalian, China","2020 IEEE International Conference on Data Mining (ICDM)","9 Feb 2021","2020","","","232","241","Partial correlation-based connectivity networks can describe the direct connectivity between features while avoiding spurious effects, and hence they can be implemented in diagnosing complex dynamic multivariate systems. However, existing studies mainly focus on single systems that are ill-equipped for incremental learning. Moreover, related methods estimate temporal connectivity network by imposing only sparse regularization without integrating pattern priors (e.g., inter-system shared pattern and intra-system intrinsic pattern), which have been proven effective in limiting noise interference. To this end, we develop an adaptive connectivity estimation model that incorporates prior patterns, namely Sparse Adaptive Meta-Learning Connectivity Network (SAMCN). Specifically, our model extends ideas of the gradient-based meta-learning to capture inter-system shared prior information by generating fast adaptive initialization parameters for the connectivity matrix. Then, a sparse variational autoencoder is proposed to generate a weight matrix for sparse regularization penalty in reweighted LASSO, which helps extract intra-system intrinsic patterns (local manifold structure). Experimental results on both synthetic data and real-world datasets demonstrate that our method is capable of adequately capturing the aforementioned pattern priors. Further, experiments from corresponding classification tasks validate the strength of the prior pattern-aware features connectivity network in resulting in better classification performance.","2374-8486","978-1-7281-8316-9","10.1109/ICDM50108.2020.00032","National Natural Science Foundation of China(grant numbers:61772110,61877008,71731003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9338278","Connectivity Network, Dynamic System, Sparse Network, Meta-Learning","Manifolds;Adaptation models;Adaptive systems;Estimation;Medical services;Sparse matrices;Task analysis","gradient methods;learning (artificial intelligence);learning systems;multivariable systems;neural nets;pattern classification;sparse matrices","fast Sparse Connectivity Network adaption;partial correlation-based connectivity networks;incremental learning;inter-system shared pattern;adaptive connectivity estimation model;prior patterns;Sparse Adaptive Meta-Learning Connectivity Network;gradient-based meta-learning;inter-system shared prior information;fast adaptive initialization parameters;connectivity matrix;sparse variational autoencoder;sparse regularization penalty;intra-system intrinsic patterns;complex dynamic multivariate system diagnosis;noise interference limitation;SAMCN;weight matrix;reweighted LASSO","","2","","28","","9 Feb 2021","","","IEEE","IEEE Conferences"
"Efficient Evaluation of Activation Functions over Encrypted Data","P. Thaine; S. Gorbunov; G. Penn","Department of Computer Science, University of Toronto, Toronto, Canada; Cheriton School of Computer Science, University of Waterloo, Waterloo, Canada; Department of Computer Science, University of Toronto, Toronto, Canada","2019 IEEE Security and Privacy Workshops (SPW)","19 Sep 2019","2019","","","57","63","We describe a method for approximating any bounded activation function given encrypted input data. The utility of our method is exemplified by simulating it within two typical machine learning tasks: namely, a Variational Autoencoder that learns a latent representation of MNIST data, and an MNIST image classifier.","","978-1-7281-3508-3","10.1109/SPW.2019.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8844617","machine learning;homomorphic encryption;security;privacy;non-polynomial function;activation function","Servers;Indexes;Encryption;Computer science;Machine learning","cryptography;image classification;learning (artificial intelligence)","activation functions;encrypted data;bounded activation function;encrypted input data;MNIST data;machine learning tasks;variational autoencoder;MNIST image classifier","","2","","33","","19 Sep 2019","","","IEEE","IEEE Conferences"
"A Flow-Based Neural Network for Time Domain Speech Enhancement","M. Strauss; B. Edler","International Audio Laboratories Erlangen, A joint institution of the Friedrich-Alexander-University Erlangen-Nürnberg (FAU) and Fraunhofer IIS, Erlangen, Germany; International Audio Laboratories Erlangen, A joint institution of the Friedrich-Alexander-University Erlangen-Nürnberg (FAU) and Fraunhofer IIS, Erlangen, Germany","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","5754","5758","Speech enhancement involves the distinction of a target speech signal from an intrusive background. Although generative approaches using Variational Autoencoders or Generative Adversarial Networks (GANs) have increasingly been used in recent years, normalizing flow (NF) based systems are still scarse, despite their success in related fields. Thus, in this paper we propose a NF framework to directly model the enhancement process by density estimation of clean speech utterances conditioned on their noisy counterpart. The WaveGlow model from speech synthesis is adapted to enable direct enhancement of noisy utterances in time domain. In addition, we demonstrate that nonlinear input companding benefits the model performance by equalizing the distribution of input samples. Experimental evaluation on a publicly available dataset shows comparable results to current state-of-the-art GAN-based approaches, while surpassing the chosen baselines using objective evaluation metrics.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9413999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9413999","speech enhancement;normalizing flows;deep learning;generative modeling","Adaptation models;Neural networks;Estimation;Speech enhancement;Tools;Signal processing;Generative adversarial networks","gallium compounds;speech enhancement;speech synthesis","flow-based neural network;time domain speech enhancement;target speech signal;intrusive background;generative approaches;Variational Autoencoders;Generative Adversarial Networks;normalizing flow based systems;NF framework;enhancement process;density estimation;clean speech utterances;noisy counterpart;WaveGlow model;speech synthesis;direct enhancement;noisy utterances;nonlinear input companding;current state-of-the-art GAN-based approaches","","2","","36","","13 May 2021","","","IEEE","IEEE Conferences"
"Encrypt DNS Traffic: Automated Feature Learning Method for Detecting DNS Tunnels","S. Ding; D. Zhang; J. Ge; X. Yuan; X. Du","School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China","2021 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)","22 Dec 2021","2021","","","352","359","In recent years, attacks on the DNS continue to proliferate due to the lack of security mechanisms. DNS over HTTPS (DoH) is a standard developed for encrypting plaintext DNS to protect user privacy, but attackers may use this protocol to bypass enterprise firewalls and exfiltrate private data through the establishment of DNS tunnels. Traditional DNS tunnel detection methods based on packet inspection are no longer applicable because of DNS encryption. Although popular machine learning methods are widely used, it require expert knowledge to extract statistical feature sets which are complicated. In order to solve the problem of detecting encrypted DNS tunnels, we propose an end-to-end anomaly detection model based on a variational autoencoder which incorporates the attention mechanism. By modeling the raw flow sequence data at the flow-level, we use bidirectional GRU-based network to automatically learn the feature representations and detect anomalies via reconstruction error. We conducted experiments on the public dataset, which contains raw normal DoH traffic and abnormal DNS tunnel traffic. The results show that our model achieves excellent performance, and has the ability to identify unknown DNS tunnels.","","978-1-6654-3574-1","10.1109/ISPA-BDCloud-SocialCom-SustainCom52081.2021.00056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9644728","Encrypted DNS tunnels;DNS over HTTPS;Deep learning;Anomaly detection","Deep learning;Representation learning;Protocols;Firewalls (computing);Neural networks;Inspection;Feature extraction","computer network security;cryptography;data privacy;feature extraction;Internet;learning (artificial intelligence);neural nets;statistical analysis;telecommunication traffic","detection methods;DNS encryption;popular machine learning methods;end-to-end anomaly detection model;unknown DNS tunnels;encrypt DNS traffic;automated feature learning method;plaintext DNS;traditional DNS;DNS over HTTPS;abnormal DNS tunnel traffic;feature representations;variational autoencoder;attention mechanism;reconstruction error","","2","","33","IEEE","22 Dec 2021","","","IEEE","IEEE Conferences"
"Generating Mesh-based Shapes From Learned Latent Spaces of Point Clouds with VAE-GAN","C. Kingkan; K. Hashimoto","Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan","2018 24th International Conference on Pattern Recognition (ICPR)","29 Nov 2018","2018","","","308","313","We study the problem of mesh-based object generation. We propose a framework that generates mesh-based objects from point clouds in an end-to-end manner by using a combination of variational autoencoder and generative adversarial network. Instead of converting point cloud to other representations like voxels before input into the network, our network directly consumes the point cloud and generates the corresponding 3D object. Given point clouds of objects, our network encodes local and global geometry structures of point clouds into latent representations. These latent vectors are then leveraged to generate the implicit surface representations of objects corresponding to those point clouds. Here, the implicit surface representation is Signed Distance Function (SDF) which preserves the inside-outside information of objects. Then we can easily reconstruct polygon mesh surfaces of objects. This could be very helpful in a situation where there is a need of 3D shapes and only point clouds of objects are available. Experiments demonstrate that our network which makes use of both local and global geometry structure can generate high-quality mesh-based objects from corresponding point clouds. We also show that using PointNet-like structure as an encoder can help to achieve better results.","1051-4651","978-1-5386-3788-3","10.1109/ICPR.2018.8546232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8546232","","Three-dimensional displays;Generators;Shape;Generative adversarial networks;Solid modeling;Gallium nitride;Image reconstruction","computational geometry;encoding;image reconstruction;image representation;learning (artificial intelligence);mesh generation;solid modelling","point cloud;mesh-based shapes;mesh-based object generation;generative adversarial network;surface representation;variational autoencoder;voxels;signed distance function;SDF;reconstruct polygon mesh surfaces;VAE-GAN;global geometry structures;local geometry structures;latent vectors","","2","","30","","29 Nov 2018","","","IEEE","IEEE Conferences"
"Standard Deep Generative Models for Density Estimation in Configuration Spaces: A Study of Benefits, Limits and Challenges","R. Gieselmann; F. T. Pokorny","RPL, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; RPL, EECS, KTH Royal Institute of Technology, Stockholm, Sweden","2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","10 Feb 2021","2020","","","5238","5245","Deep Generative Models such as Generative Adversarial Networks (GAN) and Variational Autoencoders (VAE) have found multiple applications in Robotics, with recent works suggesting the potential use of these methods as a generic solution for the estimation of sampling distributions for motion planning in parameterized sets of environments. In this work we provide a first empirical study of challenges, benefits and drawbacks of utilizing vanilla GANs and VAEs for the approximation of probability distributions arising from sampling-based motion planner path solutions. We present an evaluation on a sequence of simulated 2D configuration spaces of increasing complexity and a 4D planar robot arm scenario and find that vanilla GANs and VAEs both outperform classical statistical estimation by an n-dimensional histogram in our chosen scenarios. We furthermore highlight differences in convergence and noisiness between the trained models and propose and study a benchmark sequence of planar C-space environments parameterized by opened or closed doors. In this setting, we find that the chosen geometrical embedding of the parameters of the family of considered C-spaces is a key performance contributor that relies heavily on human intuition about C-space structure at present. We discuss some of the challenges of parameter selection and convergence for applying this approach with an out-of-the box GAN and VAE model.","2153-0866","978-1-7281-6212-6","10.1109/IROS45743.2020.9340994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9340994","","Two dimensional displays;Estimation;Generative adversarial networks;Probability distribution;Planning;Standards;Convergence","control engineering computing;neural nets;path planning;probability;sampling methods;statistical distributions","configuration spaces;VAE;motion planning;probability distributions;sampling-based motion planner path solutions;statistical estimation;planar C-space environments;geometrical embedding;C-space structure;box GAN;density estimation;standard deep generative models;variational autoencoders;4D planar robot arm","","1","","24","","10 Feb 2021","","","IEEE","IEEE Conferences"
"An Uncertainty Estimation Framework for Risk Assessment in Deep Learning-based AFib Classification","J. Belen; S. Mousavi; A. Shamsoshoara; F. Afghah","School of Informatics, Computing and Cyber Systems, Northern Arizona University, Flagstaff, AZ; School of Informatics, Computing and Cyber Systems, Northern Arizona University, Flagstaff, AZ; School of Informatics, Computing and Cyber Systems, Northern Arizona University, Flagstaff, AZ; School of Informatics, Computing and Cyber Systems, Northern Arizona University, Flagstaff, AZ","2020 54th Asilomar Conference on Signals, Systems, and Computers","3 Jun 2021","2020","","","960","964","Atrial Fibrillation (AF) is among one of the most common types of heart arrhythmia afflicting more than 3 million people in the U.S. alone. AF is estimated to be the cause of death of 1 in 4 individuals. Recent advancements in Artificial Intelligence (AI) algorithms have led to the capability of reliably detecting AF from ECG signals. While these algorithms can accurately detect AF with high precision, the discrete and deterministic classifications mean that these networks are likely to erroneously classify the given ECG signal. This paper proposes a variational autoencoder classifier network that provides an uncertainty estimation of the network's output in addition to reliable classification accuracy. This framework can increase physicians' trust in using AI-based AF detection algorithms by providing them with a confidence score which reflects how uncertain the algorithm is about a case and recommending them to put more attention to the cases with a lower confidence score. The uncertainty is estimated by conducting multiple passes of the input through the network to build a distribution; the mean of the standard deviations is reported as the network's uncertainty. Our proposed network obtains 97.64% accuracy in addition to reporting the uncertainty1.","2576-2303","978-0-7381-3126-9","10.1109/IEEECONF51394.2020.9443466","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9443466","","Uncertainty;Estimation;Electrocardiography;Rhythm;Classification algorithms;Reliability;Risk management","diseases;electrocardiography;learning (artificial intelligence);medical signal processing;neural nets;pattern classification;signal classification","uncertainty estimation framework;risk assessment;deep learning-based AFib classification;Atrial Fibrillation;common types;heart arrhythmia;3 million people;Artificial Intelligence algorithms;ECG signals;discrete classifications mean;deterministic classifications mean;given ECG signal;variational autoencoder classifier network;reliable classification accuracy;AF detection algorithms","","1","","22","","3 Jun 2021","","","IEEE","IEEE Conferences"
"Multi-View Mouse Social Behaviour Recognition With Deep Graphic Model","Z. Jiang; F. Zhou; A. Zhao; X. Li; L. Li; D. Tao; X. Li; H. Zhou","School of Computing and Communications, Lancaster University, Lancaster, U.K.; School of Informatics, University of Leicester, Leicester, U.K.; Department of Information Science and Engineering, Ocean University of China, Qingdao, China; Department of Cardiovascular Sciences, University of Leicester, Leicester, U.K.; School of Computing, University of Kent, Canterbury, U.K.; JD Explore Academy, JD.com, Beijing, China; School of Artificial Intelligence, Optics and Electronics (iOPEN), Northwestern Polytechnical University, Xi’an, China; School of Informatics, University of Leicester, Leicester, U.K.","IEEE Transactions on Image Processing","11 Jun 2021","2021","30","","5490","5504","Home-cage social behaviour analysis of mice is an invaluable tool to assess therapeutic efficacy of neurodegenerative diseases. Despite tremendous efforts made within the research community, single-camera video recordings are mainly used for such analysis. Because of the potential to create rich descriptions for mouse social behaviors, the use of multi-view video recordings for rodent observations is increasingly receiving much attention. However, identifying social behaviours from various views is still challenging due to the lack of correspondence across data sources. To address this problem, we here propose a novel multi-view latent-attention and dynamic discriminative model that jointly learns view-specific and view-shared sub-structures, where the former captures unique dynamics of each view whilst the latter encodes the interaction between the views. Furthermore, a novel multi-view latent-attention variational autoencoder model is introduced in learning the acquired features, enabling us to learn discriminative features in each view. Experimental results on the standard CRMI13 and our multi-view Parkinson's Disease Mouse Behaviour (PDMB) datasets demonstrate that our proposed model outperforms the other state of the arts technologies, has lower computational cost than the other graphical models and effectively deals with the imbalanced data problem.","1941-0042","","10.1109/TIP.2021.3083079","Royal Society-Newton Advanced Fellowship(grant numbers:NA160342); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9444134","Social behaviour analysis;multi-view;dynamic discriminative model;Parkinson’s disease (PD)","Mice;Feature extraction;Hidden Markov models;Computational modeling;Graphical models;Cameras;Video recording","cameras;diseases;feature extraction;learning (artificial intelligence);video recording;video signal processing","multiview Mouse social;deep graphic model;home-cage social behaviour analysis;single-camera video recordings;mouse social behaviors;multiview video recordings;social behaviours;novel multiview latent-attention;dynamic discriminative model;view-specific;view-shared sub-structures;variational autoencoder model;multiview Parkinson's Disease Mouse;graphical models","Animals;Behavior, Animal;Deep Learning;Female;Humans;Image Processing, Computer-Assisted;Mice;Mice, Inbred C57BL;Parkinsonian Disorders;Social Behavior;Video Recording","1","","64","IEEE","28 May 2021","","","IEEE","IEEE Journals"
"NIM: Modeling and Generation of Simulation Inputs Via Generative Neural Networks","W. Cen; E. A. Herbert; P. J. Haas","College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, USA","2020 Winter Simulation Conference (WSC)","29 Mar 2021","2020","","","584","595","We present Neural Input Modeling (NIM), a generative-neural-network framework that exploits modern data-rich environments to automatically capture simulation input distributions and then generate samples from them. Experiments show that our prototype architecture NIM-VL, which uses a novel variational-autoencoder architecture with LSTM components, can accurately, and with no prior knowledge, automatically capture a range of complex stochastic processes and efficiently generate sample paths. Moreover, we show that the outputs from a queueing model with (known) complex inputs are statistically close to outputs from the same queueing model but with the inputs learned via NIM. Known distributional properties such as i.i.d. structure and nonnegativity can be exploited to increase accuracy and speed. NIM can thus help overcome one of the key barriers to simulation for non-experts.","1558-4305","978-1-7281-9499-8","10.1109/WSC48552.2020.9383966","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9383966","","Neural networks;Stochastic processes;Prototypes","approximation theory;computer simulation;learning (artificial intelligence);neural nets;queueing theory;stochastic processes","generative-neural-network framework;modern data-rich environments;simulation input distributions;prototype architecture NIM-VL;novel variational-autoencoder architecture;LSTM components;complex stochastic processes;sample paths;queueing model;complex inputs;known distributional properties;simulation inputs;neural input modeling","","1","","16","","29 Mar 2021","","","IEEE","IEEE Conferences"
"Automatic Classification of 2D Partial Discharge from Generator On-Line Measurement","C. Hudon; M. Lévesque; O. Kokoko; N. Amyot; R. Zemouri","Institut de recherche IREQ Hydro-Québec, Varennes, Canada; Institut de recherche IREQ Hydro-Québec, Varennes, Canada; Institut de recherche IREQ Hydro-Québec, Varennes, Canada; Institut de recherche IREQ Hydro-Québec, Varennes, Canada; CEDRIC laboratory, Conservatoire National des Arts et Métiers (CNAM), Paris, France","2021 IEEE Electrical Insulation Conference (EIC)","29 Nov 2021","2021","","","8","12","Quantification of on-line Partial Discharge (PD) measurements is a challenge in the industry for several reasons, amongst them: instrumental characteristics, type of sensors, location of the sensors in the machine (line terminals, parallel circuits, neutral point) and the measurement procedure used. PD can be measured in picocoulombs, in millivolts or in dB and is most commonly displayed in 2D or 3D representation. All of these variations make comparison difficult and partially explains why no acceptable PD level has yet been defined for generator diagnostics. Another problem is to select the best parameter for quantification: maximum PD amplitude, discharge current, repetition rate, number of pulses … The former is one of the most common one, but it often neglects the identification of the discharge source causing the PD signal. Differentiation between PD sources is not straightforward and cannot only rely on simple quantification rules. In the present work, a methodology to automatically recognize individual PD sources from 2D PDA files was implemented using deep learning techniques. A Deep Convolutional Variational Autoencoder (DCVAE) was used to help PD experts through an iterative process in separating PDA files in different classes representing each type of PD sources (symmetric, positive asymmetry, negative asymmetry, gap type discharges …). The approach was tested on the entire Hydro-Quebec database of about 33 000 files and each group of files associated with each PD source was then selected to carry out independent discharge rate as a function of amplitude analysis. The statistics of each group were thereafter compared between themselves, but also with statistical analysis of data including the global PD activity when no PD source separation is done.","2576-6791","978-1-6654-1564-4","10.1109/EIC49891.2021.9612391","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9612391","Partial discharge;generator;quantification;artificial intelligence;deep learning","Partial discharges;Partial discharge measurement;Three-dimensional displays;Handheld computers;Databases;Fault location;Sensor phenomena and characterization","insulation testing;learning (artificial intelligence);machine insulation;machine testing;partial discharge measurement;partial discharges;power engineering computing;statistical analysis","automatic classification;on-line partial discharge measurements;generator diagnostics;PD amplitude;discharge current;discharge source;deep convolutional variational autoencoder;independent discharge rate;PD source separation;generator on-line measurement;2D partial discharge;deep learning;statistical analysis;amplitude analysis;Hydro-Quebec database;gap type discharges;negative asymmetry discharges;positive asymmetry discharges","","1","","7","IEEE","29 Nov 2021","","","IEEE","IEEE Conferences"
"Machine Learning-Based Automatic Generation of eFuse Configuration in NAND Flash Chip","J. Kim; J. Lee; S. Yoo","Department of CSE, Seoul National University, Seoul, Korea; Flash Product and Technology, Samsung Electronics Company, Hwaseong, Korea; Department of CSE, Seoul National University, Seoul, Korea","2019 IEEE International Test Conference (ITC)","17 Feb 2020","2019","","","1","9","Post fabrication process is becoming more and more important as memory technology becomes complex, in the bid to satisfy target performance and yield across diverse business domains, such as servers, PCs, automotive, mobiles, and embedded devices, etc. Electronic fuse adjustment (eFuse optimization and trimming) is a traditional method used in the post fabrication processing of memory chips. Engineers adjust eFuse to compensate for wafer inter-chip variations or guarantee the operating characteristics, such as reliability, latency, power consumption, and I/O bandwidth. These require highly skilled expert engineers and yet take significant time. This paper proposes a novel machine learning-based method of automatic eFuse configuration to meet the target NAND flash operating characteristics. The proposed techniques can maximally reduce the expert engineer's workload. The techniques consist of two steps: initial eFuse generation and eFuse optimization. In the first step, we apply the variational autoencoder (VAE) method to generate an initial eFuse configuration that will probably satisfy the target characteristics. In the second step, we apply the genetic algorithm (GA), which attempts to improve the initial eFuse configuration and finally achieve the target operating characteristics. We evaluate the proposed techniques with Samsung 64-Stacked vertical NAND (VNAND) in mass production. The automatic eFuse configuration takes only two days to complete the implementation.","2378-2250","978-1-7281-4823-6","10.1109/ITC44170.2019.9000162","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9000162","NAND Flash;eFuse;Chip Optimization;Machine Learning;VAE;Genetic Algorithm","","electric fuses;flash memories;genetic algorithms;learning (artificial intelligence);NAND circuits;neural nets","diverse business domains;embedded devices;electronic fuse adjustment;eFuse optimization;post fabrication processing;memory chips;wafer inter-chip variations;automatic eFuse configuration;initial eFuse generation;variational autoencoder method;target characteristics;Samsung 64-Stacked vertical NAND;machine learning;NAND flash chip;memory technology;automatic generation;NAND flash operating characteristics;skilled expert engineers;VAE method","","1","","19","","17 Feb 2020","","","IEEE","IEEE Conferences"
"PrimA6D: Rotational Primitive Reconstruction for Enhanced and Robust 6D Pose Estimation","M. -H. Jeon; A. Kim","Department of Robotics Program, KAIST, Daejeon, South Korea; Department of Civil and Environmental Engineering, KAIST, Daejeon, South Korea","IEEE Robotics and Automation Letters","6 Jul 2020","2020","5","3","4955","4962","In this letter, we introduce a rotational primitive prediction based 6D object pose estimation using a single image as an input. We solve for the 6D object pose of a known object relative to the camera using a single image with occlusion. Many recent state-of-the-art (SOTA) two-step approaches have exploited image keypoints extraction followed by PnP regression for pose estimation. Instead of relying on bounding box or keypoints on the object, we propose to learn orientation-induced primitive so as to achieve the pose estimation accuracy regardless of the object size. We leverage a Variational AutoEncoder (VAE) to learn this underlying primitive and its associated keypoints. The keypoints inferred from the reconstructed primitive image are then used to regress the rotation using PnP. Lastly, we compute the translation in a separate localization module to complete the entire 6D pose estimation. When evaluated over public datasets, the proposed method yields a notable improvement over the LINEMOD, the Occlusion LINEMOD, and the YCB-Video dataset. We further provide a synthetic-only trained case presenting comparable performance to the existing methods which require real images in the training phase.","2377-3766","","10.1109/LRA.2020.3004322","MOLIT, Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9123683","Perception for grasping and manipulation;deep learning for visual perception","Image reconstruction;Pose estimation;Training;Decoding;Cameras;Three-dimensional displays;Generative adversarial networks","feature extraction;image reconstruction;learning (artificial intelligence);neural nets;pose estimation;regression analysis","PnP regression;YCB-Video dataset;occlusion LINEMOD;variational autoencoder;image keypoints extraction;robust 6D pose estimation;rotational primitive prediction;rotational primitive reconstruction;PrimA6D;reconstructed primitive image;object size;pose estimation accuracy","","1","","28","IEEE","23 Jun 2020","","","IEEE","IEEE Journals"
"Towards the Identification of Histology Based Subtypes in Prostate Cancer","A. Chatrian; K. Sirinukunwattana; C. Verrill; J. Rittscher","Department of Engineering Science, Institute of Biomedical Engineering, University of Oxford, Oxford; Department of Engineering Science, Institute of Biomedical Engineering, University of Oxford, Oxford; Nuffield Department of Surgical Sciences and Oxford NIHR Biomedical Research Centre (BRC), University of Oxford, John Radcliffe Hospital, Oxford; Department of Engineering Science, Institute of Biomedical Engineering, University of Oxford, Oxford","2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)","11 Jul 2019","2019","","","948","952","With the advent of deep neural networks (DNNs), methods of semantic segmentation in histology have improved to a degree that it now possible to analyse morphological features that are not easily accessible to human interpretation. Such features may be used to stratify tissue subtypes in health and disease. A major obstacle is that DNNs require a large amount of data to achieve high performance and generalise to new patients. Such a requirement is unsuitable for exploratory investigations that only have access to small patient cohorts. In this work, we demonstrate how variational autoencoders and generative adversarial networks can be combined to generate realistic histology images suitable for training semantic segmentation models, resulting in a novel data-augmentation method for histology. Subsequently, we analyse if such models can be used to identify subpopulations of prostate glands with different molecular profiles. If successful, this development will ultimately lead to the discovery of novel disease relevant histology-based subtypes. We demonstrate that morphological features derived from the H&E images alone are sufficient to identify expression of a clinical biomarker in prostate glands.","1945-8452","978-1-5386-3641-1","10.1109/ISBI.2019.8759199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759199","Digital Histopathology;Prostate gland segmentation;Data Augmentation;VAE;GAN;Morpho-molecular Pathology;Cytokeratin 5","Glands;Image segmentation;Decoding;Feature extraction;Shape;Proteins;Training","biological organs;biological tissues;cancer;feature extraction;image segmentation;medical image processing;molecular biophysics;neural nets","prostate glands;histology based subtypes;prostate cancer;deep neural networks;DNNs;tissue subtypes;variational autoencoders;generative adversarial networks;histology images;data-augmentation method;molecular profiles;morphological features;semantic segmentation models;clinical biomarker","","1","","14","","11 Jul 2019","","","IEEE","IEEE Conferences"
"The Transfer Prediction Method of Bearing Remain Use Life Based on Dynamic Benchmark","Y. Zou; S. Zhao; Y. Liu; Z. Li; X. Song; G. Ding","School of Computing and Artificial Intelligence, Southwest Jiaotong University, Chengdu, China; School of Mechanical Engineering, Southwest Jiaotong University, Chengdu, China; School of Mechanical Engineering, Southwest Jiaotong University, Chengdu, China; School of Mechanical Engineering, Southwest Jiaotong University, Chengdu, China; School of Mechanical Engineering, Southwest Jiaotong University, Chengdu, China; School of Mechanical Engineering, Southwest Jiaotong University, Chengdu, China","IEEE Transactions on Instrumentation and Measurement","4 Nov 2021","2021","70","","1","11","For data-driven remaining useful life (RUL) prediction of rolling bearing (RB), deep learning methods usually do not consider the difference in distribution due to different operating conditions, which adversely affects the prediction results. Recently, transfer learning has been a research hotspot, and it can mitigate the above problem effectively. However, for different bearings under the same working condition, the data distribution changes due to the location and time of failure. To solve these problems, a transfer prediction model based on the dynamic benchmark (DB) has been proposed to predict the RUL of bearings in this study. The method is divided into three processes. First, a fully convolutional variational autoencoder is used to perform unsupervised learning; next, a domain adaptation method based on the DB is employed for reconstruction; finally, extracted hidden layer features are input to the fully connected layer of the proposed model to obtain the final prediction result. The prediction and health management (PHM) Challenging 2012 and XJTU-SY RB accelerated life test datasets were used for verification. The results showed that the proposed method could significantly improve prediction accuracy and had good stability and generalizability.","1557-9662","","10.1109/TIM.2021.3121469","National Key Research and Development Program of China(grant numbers:2020YFB1708001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9591495","Distribution difference;dynamic benchmark (DB);remaining useful life (RUL) prediction;rolling bearing (RB);transfer learning (TL)","Predictive models;Feature extraction;Degradation;Hidden Markov models;Rolling bearings;Transfer learning;Prognostics and health management","condition monitoring;life testing;mechanical engineering computing;neural nets;remaining life assessment;rolling bearings;unsupervised learning","data-driven remaining useful life prediction;deep learning methods;transfer learning;data distribution changes;transfer prediction model;dynamic benchmark;DB;fully convolutional variational autoencoder;unsupervised learning;domain adaptation method;fully connected layer;health management;XJTU-SY RB accelerated life test datasets;transfer prediction method;bearing remain use life","","1","","31","IEEE","27 Oct 2021","","","IEEE","IEEE Journals"
"Spectral Synthesis for Geostationary Satellite-to-Satellite Translation","T. J. Vandal; D. McDuff; W. Wang; K. Duffy; A. Michaelis; R. R. Nemani","Bay Area Environmental Research Institute, Moffett Field, CA, USA; Microsoft AI, Redmond, WA, USA; School of Natural Sciences, California State University at Monterey Bay, Marina, CA, USA; Civil and Environmental Engineering Department, Northeastern University, Boston, MA, USA; NASA Ames Research Center, Moffett Field, CA, USA; NASA Ames Research Center, Moffett Field, CA, USA","IEEE Transactions on Geoscience and Remote Sensing","12 Jan 2022","2022","60","","1","11","Earth-observing satellites carrying multispectral sensors are widely used to monitor the physical and biological states of the atmosphere, land, and oceans. These satellites have different vantage points above the Earth and different spectral imaging bands resulting in inconsistent imagery from one to another. This presents challenges in building downstream applications. What if we could generate synthetic bands for existing satellites from the union of all domains? We tackle the problem of generating synthetic spectral imagery for multispectral sensors as an unsupervised image-to-image translation problem modeled with a variational autoencoder (VAE) and generative adversarial network (GAN) architecture. Our approach introduces a novel shared spectral reconstruction loss to constrain the high-dimensional feature space of multispectral images. Simulated experiments performed by dropping one or more spectral bands show that cross-domain reconstruction outperforms measurements obtained from a second vantage point. Our proposed approach enables the synchronization of multispectral data and provides a basis for more homogeneous remote sensing datasets.","1558-0644","","10.1109/TGRS.2021.3088686","NASA Earth eXchange (NEX); NASA Research Opportunities in Space and Earth Science (ROSES)(grant numbers:19-ESROGSS-19-0123); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9462910","Geophysical image processing;neural networks (NNs);remote sensing;unsupervised learning","Satellites;Sensors;Image reconstruction;NASA;Monitoring;Earth;Atmospheric measurements","geophysical image processing;image classification;image reconstruction;remote sensing;satellite communication","unsupervised image-to-image translation problem;spectral reconstruction loss;high-dimensional feature space;multispectral images;spectral bands;cross-domain reconstruction;multispectral data;spectral synthesis;satellite-to-satellite translation;Earth-observing satellites;multispectral sensors;physical states;biological states;vantage points;inconsistent imagery;synthetic bands;synthetic spectral imagery;spectral imaging bands;generative adversarial network architecture;variational autoencoder","","1","","53","CCBY","23 Jun 2021","","","IEEE","IEEE Journals"
"GLASS: Geometric Latent Augmentation for Shape Spaces","S. Muralikrishnan; S. Chaudhuri; N. Aigerman; V. G. Kim; M. Fisher; N. J. Mitra",University College London; IIT Bombay; Adobe Research; Adobe Research; Adobe Research; Adobe Research,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","470","479","We investigate the problem of training generative models on very sparse collections of 3D models. Particularly, instead of using difficult-to-obtain large sets of 3D models, we demonstrate that geometrically-motivated energy functions can be used to effectively augment and boost only a sparse collection of example (training) models. Technically, we analyze the Hessian of the as-rigid-as-possible (ARAP) energy to adaptively sample from and project to the underlying (local) shape space, and use the augmented dataset to train a variational autoencoder (VAE). We iterate the process, of building latent spaces of VAE and augmenting the associated dataset, to progressively reveal a richer and more expressive generative space for creating geometrically and semantically valid samples. We evaluate our method against a set of strong baselines, provide ablation studies, and demonstrate application towards establishing shape correspondences. Glassproduces multiple interesting and meaningful shape variations even when starting from as few as 3–10 training shapes. Our code is available at https://sanjeevmk.github.io/glass_webpage/.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9880088","Vision + graphics; Deep learning architectures and techniques","Training;Geometry;Solid modeling;Adaptation models;Computer vision;Three-dimensional displays;Shape","learning (artificial intelligence);shape recognition;statistical analysis","VAE;associated dataset;richer space;more expressive generative space;semantically valid samples;shape correspondences;meaningful shape variations;3-10 training shapes;geometric latent augmentation;shape spaces;training generative models;sparse collection;geometrically-motivated energy functions;example models;adaptively sample;underlying shape space;augmented dataset;variational autoencoder;latent spaces","","1","","43","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Perception-Aware Losses Facilitate CT Denoising and Artifact Removal","S. Ghosh; A. Krug; G. Rose; S. Stober","Institute for Medical Engineering and Research Campus STIMULATE, Otto-von-Guericke University, Magdeburg, Germany; AILab, Faculty of Computer Science, Otto-von-Guericke University, Magdeburg, Germany; AILab, Faculty of Computer Science, Otto-von-Guericke University, Magdeburg, Germany; AILab, Faculty of Computer Science, Otto-von-Guericke University, Magdeburg, Germany","2021 IEEE 2nd International Conference on Human-Machine Systems (ICHMS)","27 Oct 2021","2021","","","1","6","The concerns over radiation-related health risks associated with the increasing use of computed tomography (CT) have accelerated the development of low-dose strategies. There is a higher need for low dosage in interventional applications as repeated scanning is performed. However, using the noisier and under-sampled low-dose datasets, the standard reconstruction algorithms produce low-resolution images with severe streaking artifacts. This adversely affects the CT assisted interventions. Recently, variational autoencoders (VAEs) have achieved state of-the-art results for the reconstruction of high fidelity images. The existing VAE approaches typically use mean squared error (MSE) as the loss, because it is convex and differentiable. However, pixel wise MSE does not capture the perceptual quality difference between the target and model predictions. In this work, we propose two simple but effective MSE based perception aware losses, which facilitate a better reconstruction quality. The proposed losses are motivated by perceptual fidelity measures used in image quality assessment. One of the losses involves calculation of the MSE in the spectral domain. The other involves calculation of the MSE in the pixel space and the Laplacian of Gaussian transformed domain. We use a hierarchical vector-quantized VAE equipped with the perception-aware losses for the artifact removal task. The best performing perception-aware loss improves the structural similarity index measure (SSIM) from 0.74 to 0.80. Further, we provide an analysis of the role of the pertinent components of the architecture in the denoising and artifact removal task.","","978-1-6654-0170-8","10.1109/ICHMS53169.2021.9582444","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582444","computed tomography;perception-aware;image reconstruction;deep learning;denoising;artifact removal","Computed tomography;Noise reduction;Computer architecture;Reconstruction algorithms;Predictive models;Loss measurement;Task analysis","computerised tomography;image denoising;image reconstruction;image resolution;mean square error methods;medical image processing;phantoms;tomography","existing VAE approaches;mean squared error;pixel wise MSE;perceptual quality difference;model predictions;simple but effective MSE;perception aware losses;reconstruction quality;perceptual fidelity measures;image quality assessment;hierarchical vector-quantized VAE;high fidelity images;state of-the-art results;VAEs;variational autoencoders;severe streaking artifacts;low-resolution images;standard reconstruction algorithms;low-dose datasets;repeated scanning;interventional applications;low dosage;low-dose strategies;computed tomography;radiation-related health risks;perception-aware losses facilitate CT denoising;performing perception-aware loss;artifact removal task","","1","","44","","27 Oct 2021","","","IEEE","IEEE Conferences"
"A hybrid approach to structural modeling of individualized HRTFs","R. Miccini; S. Spagnol","Aalborg University, Denmark; Delft University of Technology, Netherlands","2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","6 May 2021","2021","","","80","85","We present a hybrid approach to individualized head-related transfer function (HRTF) modeling which requires only 3 anthropometric measurements and an image of the pinna. A prediction algorithm based on variational autoencoders synthesizes a pinna-related response from the image, which is used to filter a measured head-andtorso response. The interaural time difference is then manipulated to match that of the HUTUBS dataset subject minimizing the predicted localization error. The results are evaluated using spectral distortion and an auditory localization model. While the latter is inconclusive regarding the efficacy of the structural model, the former metric shows promising results with encoding HRTFs.","","978-1-6654-4057-8","10.1109/VRW52623.2021.00022","NordForsk; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419096","Digital signal processing;Neural networks;Sound and music computing","Location awareness;Solid modeling;Three-dimensional displays;Computational modeling;Conferences;Transfer functions;Signal processing algorithms","anthropometry;deep learning (artificial intelligence);neural nets;transfer functions;user interfaces;virtual reality","interaural time difference;predicted localization error;auditory localization model;structural modeling;individualized HRTFs;individualized head-related transfer function;anthropometric measurements;prediction algorithm;pinna-related response;variational autoencoders;HUTUBS dataset;measured head-and-torso response","","1","","27","","6 May 2021","","","IEEE","IEEE Conferences"
"Effectiveness of Transfer Learning on Singing Voice Conversion in the Presence of Background Music","D. G. Rajpura; J. Shah; M. Patel; H. Malaviya; K. Phatnani; H. A. Patil","Speech Research Lab, Dhirubhai Ambani Institute of Information and Communication Technology (DA-IICT), Gandhinagar, Gujarat, India; Speech Research Lab, Dhirubhai Ambani Institute of Information and Communication Technology (DA-IICT), Gandhinagar, Gujarat, India; Speech Research Lab, Dhirubhai Ambani Institute of Information and Communication Technology (DA-IICT), Gandhinagar, Gujarat, India; Speech Research Lab, Dhirubhai Ambani Institute of Information and Communication Technology (DA-IICT), Gandhinagar, Gujarat, India; Speech Research Lab, Dhirubhai Ambani Institute of Information and Communication Technology (DA-IICT), Gandhinagar, Gujarat, India; Speech Research Lab, Dhirubhai Ambani Institute of Information and Communication Technology (DA-IICT), Gandhinagar, Gujarat, India","2020 International Conference on Signal Processing and Communications (SPCOM)","28 Aug 2020","2020","","","1","5","Singing voice conversion (SVC) is a task of converting the perception of the source speaker's identity to the target speaker without changing lyrics and rhythm. Recent approaches in traditional voice conversion involve the use of the generative models, such as Variational Autoencoders (VAE), and Generative Adversarial Networks (GANs). However, in the case of SVC, GANs are not explored much. The only system that has been proposed in the literature uses traditional GAN on the parallel data. The parallel data collection for real scenarios (with the same background music) is not feasible. Moreover, in the presence of background music, SVC is one of the most challenging tasks as it involves the source separation of vocals from the inputs, which will have some noise. Therefore, in this paper, we propose transfer learning, and fine-tuning-based Cycle consistent GAN (CycleGAN) model for non-parallel SVC, where music source separation is done using Deep Attractor Network (DANet). We designed seven different possible systems to identify the best possible combination of transfer learning and fine-tuning. Here, we use a more challenging database, MUSDB18, as our primary dataset, and we also use the NUS-48E database to pre-train CycleGAN. We perform extensive analysis via objective and subjective measures and report that with a 4.14 MOS score out of 5 for naturalness, the CycleGAN model pre-trained on NUS-48E corpus performs the best compared to the other systems described in the paper.","2474-915X","978-1-7281-8895-9","10.1109/SPCOM50965.2020.9179583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9179583","Singing Voice Conversion;Deep Attractor Network;Transfer Learning;CycleGAN","Static VAr compensators;Task analysis;Databases;Gallium nitride;Generators;Rhythm","learning (artificial intelligence);music;neural nets;source separation;speech recognition","background music;transfer learning;fine-tuning-based Cycle consistent GAN model;nonparallel SVC;music source separation;Deep Attractor Network;singing voice conversion;Variational Autoencoders;Generative Adversarial Networks;source speaker identity;Cycle GAN model pretrained;DANet;NUS-48E corpus","","1","","30","","28 Aug 2020","","","IEEE","IEEE Conferences"
"Use of Design of Experiments in Determining Neural Network Architectures for Loss of Control Detection","N. H. Campbell; J. A. Grauer; I. M. Gregory","NASA Goddard Space-Flight Center, LaRC OCIO Data Science Team, Greenbelt, MD; NASA Langley Research Center, Dynamic Systems and Control Branch, Hampton, VA; NASA Langley Research Center, Dynamic Systems and Control Branch, Hampton, VA","2021 IEEE Aerospace Conference (50100)","7 Jun 2021","2021","","","1","20","We describe empirical methods for selecting a neural network architecture to implement belief state inference on generic commercial transport aircraft. We highlight a case study on the planning, execution, and analysis of a set of experiments to determine the configurations of a conditional variational autoencoder (CVAE). Our main contribution is the application of a structured method that can be used for machine learning in many aerospace applications. This method optimizes the structure and training parameters of a neural network for belief state inference, using Design of Experiments (DOE) statistical methodologies. The motivation for this specific DOE analysis was to identify the appropriate hyperparameters for measuring the CVAE reconstruction probability and latent space, such that the measurements can be used to infer qualitative state changes for the aircraft. We demonstrate that this process yields information about a trained neural network's utility for this specific application, along with a quantifiable range of certainty. We execute 84 experiments using loss-of-control flight maneuver data from the NASA T-2 aircraft, demonstrating that this empirical process allows us to construct cheap and simple models with specific attributes amenable to belief state inference in aerospace applications.","1095-323X","978-1-7281-7436-5","10.1109/AERO50100.2021.9438231","NASA; NASA Langley Research Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9438231","","Training;Analytical models;Statistical analysis;Neural networks;Probability distribution;Sensors;Mathematical model","aircraft;design of experiments;learning (artificial intelligence);neural nets;probability","aerospace applications;training parameters;belief state inference;Design of Experiments;DOE analysis;CVAE reconstruction probability;qualitative state changes;trained neural network;loss-of-control flight maneuver data;NASA T-2 aircraft;neural network architecture;control detection;generic commercial transport aircraft;conditional variational autoencoder;structured method","","1","","69","","7 Jun 2021","","","IEEE","IEEE Conferences"
"Image Generation Based on Texture Guided VAE-AGAN for Regions of Interest Detection in Remote Sensing Images","L. Zhang; Y. Liu","School of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Artificial Intelligence, Beijing Normal University, Beijing, China","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","2310","2314","Deep learning has shown great strength in regions of interest (ROIs) detection for remote sensing images (RSIs). However, for most of RSIs, the unbalanced distribution of positive and negative samples greatly limits the performance of the deep learning-based methods. To cope with this issue, we propose a novel method based on texture guided variational autoencoder-attention wise generative adversarial network (VAE-AGAN) to augment the training data for ROI detection. First, to generate realistic texture details of RSIs, we propose a texture guidance block to embed texture prior information into encoder and decoder networks. Second, we introduce the channel and spatial-wise attention layers in the discriminator construct to adaptively recalibrate the varying importance of different channels and spatial regions of input RSIs. Finally, we apply the RSI dataset balanced by our proposal to the weakly supervised ROI detection method. Experimental results demonstrate that the proposal can not only improve the performance of ROI detection, but also outperform other competing augmentation methods.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9413823","National Natural Science Foundation of China; Beijing Normal University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9413823","Image generation;texture guidance;attention;generative adversarial networks","Learning systems;Deep learning;Image synthesis;Training data;Signal processing;Generative adversarial networks;Decoding","deep learning (artificial intelligence);image texture;remote sensing","remote sensing images;unbalanced distribution;positive samples;negative samples;deep learning;texture guidance block;spatial-wise attention layers;RSI;weakly supervised ROI detection method;image generation;texture guided VAE-AGAN;texture guided variational autoencoder;attention wise generative adversarial network","","1","","23","IEEE","13 May 2021","","","IEEE","IEEE Conferences"
"GenIcoNet: Generative Icosahedral Mesh Convolutional Network","H. Jain; O. Hellwich","Computer Vision & Remote Sensing, Technishce Universität, Berlin, Germany; Computer Vision & Remote Sensing, Technishce Universität, Berlin, Germany","2021 International Conference on 3D Vision (3DV)","6 Jan 2022","2021","","","64","73","In the past few decades, the computer vision domain has achieved outstanding success in learning 3D shapes for classification, segmentation and image-based reconstruction. However, deep networks are less explored for the generative task of obtaining new 3D shapes from the learned representation. This problem becomes more prominent for 3D shapes represented as surface meshes, mainly because the mesh structure lacks regularity, an essential property for training deep generative networks. In this work, we remedy this problem by proposing a generative icosahedral mesh convolutional network (GlenIcoNet) that learns data distribution of surface meshes. Our end-to-end trainable network learns semantic representations using 2D convolutional filters on the regularized icosahedral meshes. During inference, GenIcoNet can be used to generate new geometrically valid shapes directly as surface meshes. Our experiments for interpolation of latent space demonstrate that GenIcoNet is able to outperform networks trained on intermediate surface mesh representations. The variational autoencoder architecture of GenIcoNet learns meaningful representation which is numerically stable w.r.t. small perturbations, allows performing exploration and combination of surface meshes to generate new meaningful shapes, while maintaining the essential property of mesh manifoldness. Our code is available at https://github.com/hrdkjain/GenIcoNet","2475-7888","978-1-6654-2688-6","10.1109/3DV53792.2021.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9665830","Surface Mesh;Generative Network;Icosahedral CNN;Mesh Convolutional Network;Mesh Interpolation;Mesh Re Generation;Mesh Latent Space Exploration;Patch wise Mesh Combination;Mesh Arithmetic","Convolutional codes;Training;Interpolation;Surface reconstruction;Three-dimensional displays;Systematics;Shape","computer vision;convolutional neural nets;deep learning (artificial intelligence);image reconstruction;image representation;mesh generation;stereo image processing","generative icosahedral mesh convolutional network;surface meshes;end-to-end trainable network;regularized icosahedral meshes;GenIcoNet;geometrically valid shapes;outperform networks;intermediate surface mesh representations;mesh manifoldness;segmentation;image-based reconstruction;deep networks;generative task;learned representation;mesh structure;deep generative networks;computer vision domain;learning 3D shapes;3D shapes represented;data distribution;semantic representations;2D convolutional filters;latent space interpolation;variational autoencoder architecture;small perturbations","","1","","28","IEEE","6 Jan 2022","","","IEEE","IEEE Conferences"
"A Generative Approach Towards Improved Robotic Detection of Marine Litter","J. Hong; M. Fulton; J. Sattar","Department of Computer Science and Engineering, Minnesota Robotics Institute, University of Minnesota–Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering, Minnesota Robotics Institute, University of Minnesota–Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering, Minnesota Robotics Institute, University of Minnesota–Twin Cities, Minneapolis, MN, USA","2020 IEEE International Conference on Robotics and Automation (ICRA)","15 Sep 2020","2020","","","10525","10531","This paper presents an approach to address data scarcity problems in underwater image datasets for visual detection of marine debris. The proposed approach relies on a two-stage variational autoencoder (VAE) and a binary classifier to evaluate the generated imagery for quality and realism. From the images generated by the two-stage VAE, the binary classifier selects ""good quality"" images and augments the given dataset with them. Lastly, a multi-class classifier is used to evaluate the impact of the augmentation process by measuring the accuracy of an object detector trained on combinations of real and generated trash images. Our results show that the classifier trained with the augmented data outperforms the one trained only with the real data. This approach will not only be valid for the underwater trash classification problem presented in this paper, but it will also be useful for any data-dependent task for which collecting more images is challenging or infeasible.","2577-087X","978-1-7281-7395-5","10.1109/ICRA40945.2020.9197575","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197575","","Training;Image color analysis;Plastics;Gallium nitride;Task analysis;Shape;Decoding","image classification;learning (artificial intelligence);object detection;support vector machines","data scarcity problems;underwater image datasets;visual detection;marine debris;two-stage variational autoencoder;generated imagery;two-stage VAE;binary classifier;multiclass classifier;augmentation process;trash images;underwater trash classification problem;data-dependent task;quality images","","1","","34","","15 Sep 2020","","","IEEE","IEEE Conferences"
"ANFIC: Image Compression Using Augmented Normalizing Flows","Y. -H. Ho; C. -C. Chan; W. -H. Peng; H. -M. Hang; M. Domański","Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Electronics Engineering, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Institute of Multimedia Telecommunications, Poznań University of Technology, Poznań, Poland","IEEE Open Journal of Circuits and Systems","22 Nov 2021","2021","2","","613","626","This paper introduces an end-to-end learned image compression system, termed ANFIC, based on Augmented Normalizing Flows (ANF). ANF is a new type of flow model, which stacks multiple variational autoencoders (VAE) for greater model expressiveness. The VAE-based image compression has gone mainstream, showing promising compression performance. Our work presents the first attempt to leverage VAE-based compression in a flow-based framework. ANFIC advances further compression efficiency by stacking and extending hierarchically multiple VAE’s. The invertibility of ANF, together with our training strategies, enables ANFIC to support a wide range of quality levels without changing the encoding and decoding networks. Extensive experimental results show that in terms of PSNR-RGB, ANFIC performs comparably to or better than the state-of-the-art learned image compression. Moreover, it performs close to VVC intra coding, from low-rate compression up to perceptually lossless compression. In particular, ANFIC achieves the state-of-the-art performance, when extended with conditional convolution for variable rate compression with a single model. The source code of ANFIC can be found at https://github.com/dororojames/ANFIC.","2644-1225","","10.1109/OJCAS.2021.3123201","National Center for High-Performance Computing, Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9623351","Learning-based image compression;flow-based image compression;augmented normalizing flows;perceptually lossless image compression;variable rate image compression","Training data;Degradation;Image coding;Codes;Convolutional neural networks;Stacking;Network architecture;Machine learning","data compression;image coding;learning (artificial intelligence);neural nets","variable rate compression;Augmented Normalizing Flows;end-to-end learned image compression system;flow model;VAE-based image compression;flow-based framework;hierarchically multiple VAE;learned image compression;low-rate compression;perceptually lossless compression;ANFIC;variational autoencoders;conditional convolution","","1","","26","CCBY","22 Nov 2021","","","IEEE","IEEE Journals"
"Homogeneous Linear Inequality Constraints for Neural Network Activations","T. Frerix; M. Nießner; D. Cremers",Technical University of Munich; Technical University of Munich; Technical University of Munich,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","3229","3234","We propose a method to impose homogeneous linear inequality constraints of the form Ax ≤ 0 on neural network activations. The proposed method allows a data-driven training approach to be combined with modeling prior knowledge about the task. One way to achieve this task is by means of a projection step at test time after unconstrained training. However, this is an expensive operation. By directly incorporating the constraints into the architecture, we can significantly speed-up inference at test time; for instance, our experiments show a speed-up of up to two orders of magnitude over a projection method. Our algorithm computes a suitable parameterization of the feasible set at initialization and uses standard variants of stochastic gradient descent to find solutions to the constrained network. Thus, the modeling constraints are always satisfied during training. Crucially, our approach avoids to solve an optimization problem at each training step or to manually trade-off data and constraint fidelity with additional hyperparameters. We consider constrained generative modeling as an important application domain and experimentally demonstrate the proposed method by constraining a variational autoencoder.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00382","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150971","","Training;Neural networks;Computational modeling;Task analysis;Optimization;Machine learning;Computer architecture","gradient methods;learning (artificial intelligence);neural nets;optimisation;stochastic processes","neural network activations;data-driven training approach;projection method;constrained network;modeling constraints;linear inequality constraints;variational autoencoder;stochastic gradient descent","","1","","21","","28 Jul 2020","","","IEEE","IEEE Conferences"
"Multivariate Time-series Anomaly Detection using SeqVAE-CNN Hybrid Model","T. Choi; D. Lee; Y. Jung; H. -J. Choi","School of Computing, KAIST, Daejeon, Korea; School of Computing, KAIST, Daejeon, Korea; School of Computing, KAIST, Daejeon, Korea; School of Computing, KAIST, Daejeon, Korea","2022 International Conference on Information Networking (ICOIN)","26 Jan 2022","2022","","","250","253","Anomaly detection has been recognized as an important research area in many industries such as Information Technology, manufacturing, finance, etc. Recently, diverse research for anomaly detection has been conducted utilizing current deep learning methods including machine learning algorithms. However, multivariate time-series anomaly detection can be challenging problems because of the imbalance of anomaly data and the complexity of multivariate. In this paper, we propose a SeqVAE-CNN model based on deep learning using an unsupervised approach. Our model combines Variational Autoencoder (VAE) with Convolutional Neural Networks (CNN) as utilizing Seq2Seq structure to capture temporal correlations and spatial features in multivariate time-series. To demonstrate the performance of our approaches, we evaluate our model on 8 datasets from various domains. The experimental results demonstrate that our model has better performance of anomaly detection than other models by recording the highest AUROC and F1 scores on six of the eight datasets.","1976-7684","978-1-6654-1332-9","10.1109/ICOIN53446.2022.9687205","Korean National Police Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9687205","Anomaly detection;Multivariate time-series;Unsupervised learning;Hybrid model","Deep learning;Industries;Correlation;Machine learning algorithms;Finance;Manufacturing;Complexity theory","convolutional neural nets;deep learning (artificial intelligence);security of data;time series;unsupervised learning","multivariate time-series anomaly detection;SeqVAE-CNN hybrid model;machine learning algorithms;deep learning methods;unsupervised approach;variational autoencoder;convolutional neural networks;Seq2Seq structure;temporal correlations;spatial features;multivariate time-series","","1","","15","IEEE","26 Jan 2022","","","IEEE","IEEE Conferences"
"InfoVAEGAN: Learning Joint Interpretable Representations by Information Maximization and Maximum Likelihood","F. Ye; A. G. Bors","Department of Computer Science, University of York, York YO10 5GH, UK; Department of Computer Science, University of York, York YO10 5GH, UK","2021 IEEE International Conference on Image Processing (ICIP)","23 Aug 2021","2021","","","749","753","Learning disentangled and interpretable representations is an important step towards accomplishing comprehensive data representations on the manifold. In this paper, we propose a novel representation learning algorithm which combines the inference abilities of Variational Autoencoders (VAE) with the generalization capability of Generative Adversarial Networks (GAN). The proposed model, called InfoVAEGAN, consists of three networks: Encoder, Generator and Discriminator. InfoVAEGAN aims to jointly learn discrete and continuous interpretable representations in an unsupervised manner by using two different data-free log-likelihood functions onto the variables sampled from the generator’s distribution. We propose a two-stage algorithm for optimizing the inference network separately from the generator training. Moreover, we enforce the learning of interpretable representations through the maximization of the mutual information between the existing latent variables and those created through generative and inference processes.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506169","Hybrid VAE-GAN generative models;Disentangled representations;Mutual information","Training;Manifolds;Inference mechanisms;Tools;Generative adversarial networks;Generators;Inference algorithms","data structures;inference mechanisms;learning (artificial intelligence);maximum likelihood estimation","Generative Adversarial Networks;called InfoVAEGAN;discrete representations;continuous interpretable representations;different data-free log-likelihood functions;inference network;generator training;generative inference processes;learning joint interpretable representations;information maximization;learning disentangled;comprehensive data representations;novel representation learning;inference abilities;Variational Autoencoders","","","","26","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"Deep learning based generation of synthetic blood vessel surfaces","M. Danu; C. -I. Nita; A. Vizitiu; C. Suciu; L. M. Itu","Corporate Technology, Siemens SRL, Brasov, Romania; Corporate Technology, Siemens SRL, Brasov, Romania; Corporate Technology, Siemens SRL, Brasov, Romania; Corporate Technology, Siemens SRL, Brasov, Romania; Corporate Technology, Siemens SRL, Brasov, Romania","2019 23rd International Conference on System Theory, Control and Computing (ICSTCC)","31 Oct 2019","2019","","","662","667","In recent years, the medical imaging area showed a notably increased interest in Deep Learning (DL) based applications. Deep learning is a machine learning (ML) technique which learns features and tasks directly from data, trying to model human abstract thinking. Since deep learning can create features without a human intervention, it allows data scientists to use more complex sets of features in comparison with traditional machine learning approaches. In addition to this, the robustness to natural variations in the data is automatically learned and the deep learning architecture is flexible, so that the same neural network based approach can be applied to many different applications and data types. Our goal is to apply DL based techniques in the context of medical imaging with the purpose of developing a workflow for diagnosing cardiovascular pathologies or cerebral aneurysms. Since a major challenge of this approach is the lack of large training databases, in this paper we are focusing on performing data augmentation by generating realistic synthetic anatomical models of blood vessels. For this task we used geometries describing vessel-like structures and also real anatomies extracted from patients. We chose to experiment with two state of the art models: Variational Autoencoders (VAE) and Generative Adversarial Networks (GAN). We address the problem of employing neural network based models on three dimensional surfaces. Such surfaces typically have an unstructured representation consisting of points and polygons and are not compatible with typical neural network architectures. We propose a technique based on surface voxelization which consists on representing the unstructured surface mesh as a three-dimensional image, therefore becoming inherently compatible with a standard convolutional neural network. We performed experiments on three datasets containing both two and three dimensional surfaces representing blood vessel-like structures. We show that state of the art, deep learning based generative models, are capable of generating voxelized three dimensional surfaces of high quality that are visually indistinguishable from the training samples.","2372-1618","978-1-7281-0699-1","10.1109/ICSTCC.2019.8885576","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8885576","Generative models;deep convolutional neural networks;synthetic data generation;three-dimensional surfaces","Three-dimensional displays;Training;Solid modeling;Biomedical imaging;Generators;Deep learning;Two dimensional displays","blood vessels;cardiovascular system;convolutional neural nets;learning (artificial intelligence);medical image processing;neural net architecture;physiological models","synthetic blood vessel surfaces;medical imaging area;machine learning technique;data scientists;deep learning architecture;neural network based approach;DL based techniques;data augmentation;generative adversarial networks;three dimensional surfaces;neural network architectures;blood vessel-like structures;generative models;synthetic anatomical models;deep learning based generation;three-dimensional image;unstructured surface mesh;convolutional neural network;variational autoencoders;cerebral aneurysms;cardiovascular pathologies;medical imaging;human abstract thinking;natural variations","","","","21","","31 Oct 2019","","","IEEE","IEEE Conferences"
"Semi-Supervised Source Localization With Residual Physical Learning","M. J. Bianco; P. Gerstoft","Marine Physical Laboratory, University of California, San Diego; Marine Physical Laboratory, University of California, San Diego","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","3608","3612","Machine learning (ML) approaches to source localization have demonstrated promising results in addressing reverberation. Even with large data volumes, the number of labels available for supervised learning in such environments is usually small. This challenge has recently been addressed using semi-supervised learning (SSL) based on deep generative modeling with variational autoencoders. A problem with ML approaches is they often ignore the intuitions from conventional signal processing approaches. We present a hybrid approach to ML-based source localization, which uses both SSL and conventional, analytic signal processing approaches to obtain source location estimates. An SSL approach is developed which accounts for the residual between analytic source location estimates true locations. Thus, the approach can exploit both labelled and unlabeled data, as well as analytic source location intuition, to provide better localization than either approach in isolation.1","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746564","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746564","Source localization;semi-supervised learning;generative modeling;deep learning","Location awareness;Conferences;Supervised learning;Machine learning;Signal processing;Position measurement;Semisupervised learning","acoustic signal processing;deep learning (artificial intelligence);neural nets;supervised learning;unsupervised learning","ML-based source localization;conventional signal processing approaches;analytic signal processing approaches;SSL approach;analytic source location intuition;semisupervised source localization;residual physical learning;machine learning;reverberation;supervised learning;semisupervised learning;deep generative modeling;variational autoencoders;ML approaches","","","","33","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Computing Amplification Factors for Influence on Social Network based on Learning of Behaviors and Interacted Knowledge Graph","H. D. Nguyen; Q. M. Tran; V. T. Pham; T. Huynh","Vietnam National University, Ho Chi Minh City, Vietnam; Kyanon Digital, Ho Chi Minh City, Vietnam; Faculty of Information Technology, Sai Gon University, Ho Chi Minh city, Vietnam; Technical University of Ostrava (VŠB-TU), Ostrava, Czech Republic","2021 IEEE 23rd Int Conf on High Performance Computing & Communications; 7th Int Conf on Data Science & Systems; 19th Int Conf on Smart City; 7th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)","30 May 2022","2021","","","2194","2198","This presentation proposes a metric to estimate the influence of users and communities on Social Media Networks through the combining of Knowledge Graph and Deep Learning approaches. An unsupervised deep learning model is constructed to learn and explore the behavior of users based on Variational Graph Autoencoder (VGAE). It enhances to automatically extract from the relationships among users. The model is robust to unseen data and takes no labeling effort. The experiments show significant performance and promising results which are competitive and outperforms some well-known Graph-convolutional-based. The proposed approach is applied to measure the influence of users on the practical social network. This sudy also presents an architecture of a system to mange campaigns of digital marketing on social network.","","978-1-6654-9457-1","10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00327","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9781019","amplification factor;influencer;digital marketing;knowledge graph","Knowledge engineering;Deep learning;Measurement;Social networking (online);Smart cities;Computer architecture;Data models","graph theory;learning (artificial intelligence);social networking (online);unsupervised learning","amplification factors;interacted Knowledge Graph;Social Media Networks;unsupervised deep learning model;Variational Graph Autoencoder;labeling effort;Graph-convolutional-based;practical social network","","","","22","IEEE","30 May 2022","","","IEEE","IEEE Conferences"
"Private-Shared Disentangled Multimodal VAE for Learning of Latent Representations","M. Lee; V. Pavlovic","Rutgers University, Piscataway, NJ, USA; Rutgers University, Piscataway, NJ, USA","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","1 Sep 2021","2021","","","1692","1700","Multi-modal generative models represent an important family of deep models, whose goal is to facilitate representation learning on data with multiple views or modalities. However, current deep multi-modal models focus on the inference of shared representations, while neglecting the important private aspects of data within individual modalities. In this paper, we introduce a disentangled multi-modal variational autoencoder (DMVAE) that utilizes disentangled VAE strategy to separate the private and shared latent spaces of multiple modalities. We demonstrate the utility of DMVAE two image modalities of MNIST and Google Street View House Number (SVHN) datasets as well as image and text modalities from the Oxford-102 Flowers dataset. Our experiments indicate the essence of retaining the private representation as well as the private-shared disentanglement to effectively direct the information across multiple analysis-synthesis conduits.","2160-7516","978-1-6654-4899-4","10.1109/CVPRW53098.2021.00185","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9523016","","Computer vision;Conferences;Computational modeling;Data models;Pattern recognition;Internet;Task analysis","image coding;image representation;learning (artificial intelligence)","multimodal variational autoencoder;DMVAE;disentangled VAE strategy;private shared latent spaces;Google Street View House Number datasets;Oxford-102 Flowers dataset;private representation;private-shared disentanglement;multiple analysis-synthesis conduits;deep multimodal generative models;multimodal VAE strategy;MNIST;SVHN datasets","","","","23","IEEE","1 Sep 2021","","","IEEE","IEEE Conferences"
"Image Decomposition and Classification Through a Generative Model","H. Yao; M. Regan; Y. Yang; Y. Ren","Department of Mechanical and Aerospace Engineering, Arizona State University, Tempe, AZ, USA; Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC, USA; Department of Computer Science and Engineering, Arizona State University, Tempe, AZ, USA; Department of Mechanical and Aerospace Engineering, Arizona State University, Tempe, AZ, USA","2019 IEEE International Conference on Image Processing (ICIP)","26 Aug 2019","2019","","","400","404","We demonstrate in this paper that a generative model can be designed to perform classification tasks under challenging settings, including adversarial attacks and input distribution shifts. Specifically, we propose a conditional variational autoencoder that learns both the decomposition of inputs and the distributions of the resulting components. During test, we jointly optimize the latent variables of the generator and the relaxed component labels to find the best match between the given input and the output of the generator. The model demonstrates promising performance at recognizing overlapping components from the multiMNIST dataset, and novel component combinations from a traffic sign dataset. Experiments also show that the proposed model achieves high robustness on MNIST and NORB datasets, in particular for high-strength gradient attacks and non-gradient attacks.","2381-8549","978-1-5386-6249-6","10.1109/ICIP.2019.8802991","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802991","Generative model;classification;adversarial defense","Training;Computational modeling;Generators;Standards;Image reconstruction;Task analysis;Gallium nitride","image classification;learning (artificial intelligence);security of data","generative model;adversarial attacks;input distribution;conditional variational autoencoder;high-strength gradient attacks;image decomposition;image classification","","","","23","","26 Aug 2019","","","IEEE","IEEE Conferences"
"Facial Expression Neutralization With StoicNet","W. Carver; I. Nwogu","1 Lomb Memorial Dive, Rochester Institute of Technology, Rochester, NY; 1 Lomb Memorial Dive, Rochester Institute of Technology, Rochester, NY","2021 IEEE Winter Conference on Applications of Computer Vision Workshops (WACVW)","21 Apr 2021","2021","","","201","208","Expression neutralization is the process of synthetically altering an image of a face so as to remove any facial expression from it without changing the face's identity. Facial expression neutralization could have a variety of applications, particularly in the realms of facial recognition, in action unit analysis, or even improving the quality of identification pictures for various types of documents. Our proposed model, StoicNet, combines the robust encoding capacity of variational autoencoders, the generative power of generative adversarial networks, and the enhancing capabilities of super resolution networks with a learned encoding transformation to achieve compelling expression neutralization, while preserving the identity of the input face. Objective experiments demonstrate that StoicNet successfully generates realistic, identity-preserved faces with neutral expressions, regardless of the emotion or expression intensity of the input face.","2690-621X","978-1-6654-1967-3","10.1109/WACVW52041.2021.00026","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9407808","","Computer vision;Face recognition;Conferences;Generative adversarial networks;Encoding","emotion recognition;face recognition;image coding;image enhancement;image resolution;learning (artificial intelligence);neural nets","facial expression neutralization;StoicNet;facial recognition;generative adversarial networks;identity-preserved faces;neutral expressions;face identity;action unit analysis;variational autoencoders;super resolution network;learned encoding transformation","","","","27","","21 Apr 2021","","","IEEE","IEEE Conferences"
"Weakly-Supervised Generation and Grounding of Visual Descriptions with Conditional Generative Models","E. Mavroudi; R. Vidal","Dept. of Biomedical Engineering, Mathematical Institute for Deta Science, Johns Hopkins University; Dept. of Biomedical Engineering, Mathematical Institute for Deta Science, Johns Hopkins University","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","15523","15533","Given weak supervision from image- or video-caption pairs, we address the problem of grounding (localizing) each object word of a ground-truth or generated sentence describing a visual input. Recent weakly-supervised approaches leverage region proposals and ground words based on the region attention coefficients of captioning models. To predict each next word in the sentence they attend over regions using a summary of the previous words as a query, and then ground the word by selecting the most attended regions. However, this leads to sub-optimal grounding, since attention coefficients are computed without taking into account the word that needs to be localized. To address this shortcoming, we propose a novel Grounded Visual Description Conditional Variational Autoencoder (GVD-CVAE) and leverage its latent variables for grounding. In particular, we introduce a discrete random variable that models each word-to-region alignment, and learn its approximate posterior distribution given the full sentence. Experiments on challenging image and video datasets (Flickr30k Entities, YouCook2, ActivityNet Entities) validate the effectiveness of our conditional generative model, showing that it can substantially outperform soft-attention-based baselines in grounding.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01510","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9880355","Vision + language; Deep learning architectures and techniques; Video analysis and understanding","Visualization;Computer vision;Grounding;Video description;Computational modeling;Random variables;Pattern recognition","Bayes methods;computer vision;image classification;image motion analysis;learning (artificial intelligence);natural language processing;object detection;video signal processing","sub-optimal grounding;novel Grounded Visual Description Conditional Variational Autoencoder;word-to-region alignment;conditional generative model;soft-attention-based baselines;weakly-supervised generation;visual descriptions;given weak supervision;video-caption pairs;ground-truth;generated sentence;visual input;weakly-supervised approaches leverage region proposals;ground words;region attention coefficients;captioning models;previous words;attended regions","","","","77","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Clustering and Separating Similarities for Deep Unsupervised Hashing","W. Zhang; D. Wu; C. Yang; B. Li; W. Wang","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; National Innovation Institute of Defense Technology, Academy of Military Science, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","1655","1659","The lack of supervised information is the pivotal problem in unsupervised hashing. Most methods leverage deep features extracted from pre-trained models to generate semantic similarities as supervised information. These fixed features are, however, neither designed originally for retrieval nor updated adaptively during training. In this paper, we propose a novel deep Unsupervised Cluster and Separate Hashing (UCSH) to address these issues. Specifically, we introduce a fully end-to-end deep hashing network with a binary latent Variational AutoEncoder (VAE), which enables hash codes capable of reconstructing deep features as well as preserving semantic relations. Moreover, a ‘Cluster and Separate’ scheme is proposed to jointly cluster deep features and separate semantic similarities. Both the implicit feature clustering and the explicit similarity separating loss encourage the separation of similar and dissimilar pairs, enabling the iteratively updated similarities to better excavate semantic relations. Experiments conducted on three benchmarks show the superiority of UCSH.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9747731","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747731","deep hashing;image retrieval;unsupervised method","Training;Codes;Conferences;Semantics;Benchmark testing;Signal processing;Feature extraction","feature extraction;file organisation;learning (artificial intelligence);neural nets;pattern clustering","deep Unsupervised Hashing;supervised information;pivotal problem;methods leverage deep features;fixed features;deep Unsupervised Cluster;Separate Hashing;UCSH;deep hashing network;binary latent Variational AutoEncoder;Separate scheme;cluster deep features;separate semantic similarities;implicit feature clustering;explicit similarity separating loss;similar pairs;dissimilar pairs;iteratively updated similarities;excavate semantic relations","","","","23","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Contextual Label Transformation For Scene Graph Generation","W. Lee; S. Kim; G. Kim","Mechatronics R&D Center Samsung Electronics; Dept of CSE, Seoul National University, Seoul, Korea; Dept of CSE, Seoul National University, Seoul, Korea","2021 IEEE International Conference on Image Processing (ICIP)","23 Aug 2021","2021","","","2533","2537","For scene graph generation, it is crucial to properly understand the relationships of objects within the context of the image. We design a label transformation method using a Transformer-VAE (Variational Autoencoder) structure, which converts bounding box labels into auxiliary labels that contain each object’s context in an unsupervised manner. The auxiliary labels are then trained jointly with bounding box labels and relation labels in a multi-task way. Our approach does not require any external datasets or language prior and is applicable to any graph generation models that infer the relationship between pairs of objects. We validate our method’s effectiveness and scalability with state-of-the-art scene graph generation models on VRD and VG datasets.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506213","Scene graph generation;label transformation","Visualization;Head;Annotations;Scalability;Image processing;Conferences;Object detection","graph theory;image representation;neural nets;object detection","contextual label transformation;bounding box labels;auxiliary labels;relation labels;scene graph generation models;transformer-VAE structure;variational autoencoder;VRD dataset;VG dataset","","","","26","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"Towards Generating Image Assets Through Deep Learning for Game Development","A. Tilson; C. M. Gelowitz","Software Systems Engineering, University of Regina, Regina, Canada; Software Systems Engineering, University of Regina, Regina, Canada","2019 IEEE Canadian Conference of Electrical and Computer Engineering (CCECE)","11 Oct 2019","2019","","","1","4","This paper outlines some preliminary research toward the viability of utilizing unsupervised generative deep learning networks, such as Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), to create image assets for game development. This work explores existing GAN research and the viability of using generative networks to generate both textures and human face assets within a game engine. This research and its preliminary results examines the viability and advantages/disadvantages of utilizing generative networks directly within game engines. It also examines the potential trade-offs of a generative approach versus more traditional approaches for image assets in video game development.","2576-7046","978-1-7281-0319-8","10.1109/CCECE.2019.8861965","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861965","GANs;texture synthesis;face synthesis;game development","Games;Face;Deep learning;Three-dimensional displays;Engines;Art;Solid modeling","computer games;face recognition;image texture;neural nets;unsupervised learning","generative networks;game engine;generative approach;video game development;unsupervised generative deep learning networks;GANs;human face assets;image assets;generative adversarial networks;variational autoencoders;image texture","","","","12","","11 Oct 2019","","","IEEE","IEEE Conferences"
"Thuryalankara: Artificial Intelligence Based Audio Plugin For Sri Lankan Percussion Instruments","P. D. C. Fernando; B. A. N. Fernando; I. U. Wanaguru; M. A. P. A. Perera; T. Buddhika; N. Kodagoda; D. Ganegoda","Department of Computer Science and Software Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Department of Computer Science and Software Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Department of Computer Science and Software Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Department of Computer Science and Software Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Department of Computer Science and Software Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Department of Computer Science and Software Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka; Department of Computer Science and Software Engineering, Sri Lanka Institute of Information Technology, Malabe, Sri Lanka","2021 6th International Conference on Information Technology Research (ICITR)","4 Jan 2022","2021","","","1","6","Sri Lankan music is yet to prove its musical prowess by incorporating artificial intelligence tools, therefore, this research introduces a novel invention, an automated audio plugin for music producers, so the process of creating, mixing, mastering, and producing music is easier. To achieve this, the research introduces a Variational AutoEncoder (VAE) machine learning model to create and generate music, an artificial intelligence (AI) system that can automate the mastering process. This research also introduces an innovative component, a virtual instrumentation tool using MIDI technology for the Sri Lankan percussion instruments that allow users to play the instrument virtually using a MIDI keyboard, and alongside it, a preset beat generator that automatically maintain tempo consistency. Thuryalankara was able to receive a collective average of 80% accuracy rate exceeding the predicted accuracy rate of 65% from the software benchmarking test and the physical survey conducted with music producers. Finally, with the inclusion of powerful tools like this, the ultimate objective of this research is to take the Sri Lankan instruments to the international level where any producer from little to plenty experience is able to use this plugin to enhance their musical production.","","978-1-6654-2000-6","10.1109/ICITR54349.2021.9657391","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9657391","Audio plugin;Sri Lankan music;Machine Learning;Virtual Instrumentation;Mix and Master","Technological innovation;Instruments;Music;Keyboards;Production;Machine learning;Benchmark testing","artificial intelligence;audio signal processing;learning (artificial intelligence);music;musical instruments","artificial intelligence system;virtual instrumentation tool;Sri Lankan percussion instruments;Sri Lankan instruments;musical production;Sri Lankan music;musical prowess;artificial intelligence tools;automated audio plugin;Thuryalankara;variational autoencoder machine learning model","","","","22","IEEE","4 Jan 2022","","","IEEE","IEEE Conferences"
"Enhancing Textual Representation for Abstractive Summarization: Leveraging Masked Decoder","R. Jia; Y. Cao; F. Fang; J. Li; Y. Liu; P. Yin","School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","8","For existing models of abstractive summarization, the paradigm of autoregressive decoder inherently prefers relying on former tokens and the prediction error will propagate subsequently. To effectively eliminate the errors, we need a way to remodeling dependency during text generation. In this paper, we introduce MDSumma (as shorthand for Masked Decoder for Summarization), which masks partial tokens in decoder, aiming to alleviate the over-reliance on the antecedent. Moreover, with further facilitating the flexibility and diversity of textual representation, we employ a variational autoencoder model, sampling continuous latent variables from the probability distribution to explicitly model underlying semantics of the target summaries. Our architecture gives good balance between encoder contextual representation and decoder prediction, sidestepping the gap between training and inference. Experimental results on three benchmark datasets validate the effectiveness that our proposed method significantly outperforms the existing state-of-the-art approaches both on ROUGE and diversity scores.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9206958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206958","text summarization;diversity;VAE;model fusion","Decoding;Task analysis;Semantics;Training;Bit error rate;Data mining;Probability distribution","graph theory;learning (artificial intelligence);probability;text analysis","masked decoder;partial token masking;encoder contextual representation;continuous latent variables;variational autoencoder model;text generation;prediction error;autoregressive decoder;abstractive summarization;textual representation","","","","29","IEEE","28 Sep 2020","","","IEEE","IEEE Conferences"
"Pedestrian Trajectory Prediction via Spatial Interaction Transformer Network","T. Su; Y. Meng; Y. Xu","School of Mechanical Engineering, University of Science and Technology, Beijing, China; School of Mechanical Engineering, University of Science and Technology, Beijing, China; School of Mechanical Engineering, University of Science and Technology, Beijing, China","2021 IEEE Intelligent Vehicles Symposium Workshops (IV Workshops)","10 Jan 2022","2021","","","154","159","As a core technology of the autonomous driving system, pedestrian trajectory prediction can significantly enhance the function of active vehicle safety and reduce road traffic injuries. In traffic scenes, when encountering with oncoming people, pedestrians may make sudden turns or stop immediately, which often leads to complicated trajectories. To predict such unpredictable trajectories, we can gain insights into the interaction between pedestrians. In this paper, we present a novel generative method named Spatial Interaction Transformer (SIT), which learns the spatio-temporal correlation of pedestrian trajectories through attention mechanisms. Furthermore, we introduce the conditional variational autoencoder (CVAE) [1] framework to model the future latent motion states of pedestrians. In particular, the experiments based on large-scale traffic dataset nuScenes [2] show that SIT has an outstanding performance than state-of-the-art (SOTA) methods. Experimental evaluation on the challenging ETH [3] and UCY [4] datasets confirms the robustness of our proposed model.","","978-1-6654-7921-9","10.1109/IVWorkshops54471.2021.9669249","Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669249","","Correlation;Conferences;Roads;Vehicle safety;Transformers;Robustness;Trajectory","image motion analysis;learning (artificial intelligence);neural nets;object detection;pedestrians;road accidents;road safety;road traffic;road vehicles;traffic engineering computing","pedestrian trajectory prediction;autonomous driving system;active vehicle safety;road traffic injuries;traffic scenes;nuScenes large-scale traffic dataset;spatial interaction transformer network;generative method;SIT;spatio-temporal correlation learning;attention mechanism;conditional variational autoencoder;CVAE framework;pedestrian future latent motion state","","","","26","IEEE","10 Jan 2022","","","IEEE","IEEE Conferences"
"Normalizing Flow for Synthetic Medical Images Generation","M. Hajij; G. Zamzmi; R. Paul; L. Thukar","Faculty of Mathematics and Computer Science, Santa Clara University; Department of Computer Science and Engineering, University of South Florida; Harvard Medical School, Massachusetts General Hospital; Harvard Medical School","2022 IEEE Healthcare Innovations and Point of Care Technologies (HI-POCT)","1 Apr 2022","2022","","","46","49","Deep generative models, such as generative adversarial network (GAN) and variational autoencoder (VAE), have been utilized extensively for medical image generation. While these models made remarkable progress in medical image synthesis, they can not explicitly learn the probability density function of the input data and are highly sensitive to the hyperparameter selections. To mitigate these issues, a new type of deep generative model, called Normalizing Flows (NFs), have emerged in recent years. In this paper, we investigate NFs as an alternative for synthesizing medical images. In particular, we utilize realNVP, a popular NF model for the purpose of synthesizing medical images. To evaluate our synthesized images, we propose to utilize Wasserstien distance along with the permutation test to quantify the quality of the generated images. Within our quantifying metric, our results indicate that the two sample distributions, the first being the samples obtained from our NF model and second being the original dataset, are similar providing a promising indication of normalizing flow’s capability in medical images generation.","","978-1-6654-9615-5","10.1109/HI-POCT54491.2022.9744072","National Institutes of Health; University of South Florida; Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9744072","The performance of deep learning models relies heavily on the size and diversity of data. As it is well-known that medical imaging data is scarce and expensive to generate, image augmentation (a.k.a., image synthesis) becomes an important problem in medical images. This work presents a normalizing flow-based method for synthesizing medical images. Our results show superior performance of the proposed method as compared to the state-of-the-arts (e.g., generative models), and demonstrate its ability to generate diverse syntactic medical images, ultimately improving the performance of deep learning models and result in reliable decision-making","Deep learning;Representation learning;Technological innovation;Image synthesis;Syntactics;Generative adversarial networks;Data models","medical image processing;neural nets","synthetic medical images generation;deep generative model;variational autoencoder;NF model;normalizing flows;Wasserstien distance;sample distributions","","","","46","IEEE","1 Apr 2022","","","IEEE","IEEE Conferences"
"A weakly-supervised deep domain adaptation method for multi-modal sensor data","R. -C. Mihailescu","Department of Computer Science, Malmö University, Internet of Things and People Research Center, 20506, Malmö, Sweden","2021 IEEE Global Conference on Artificial Intelligence and Internet of Things (GCAIoT)","31 Jan 2022","2021","","","45","50","Nearly every real-world deployment of machine learning models suffers from some form of shift in data distributions in relation to the data encountered in production. This aspect is particularly pronounced when dealing with streaming data or in dynamic settings (e.g. changes in data sources, behaviour and the environment). As a result, the performance of the models degrades during deployment. In order to account for these contextual changes, domain adaptation techniques have been designed for scenarios where the aim is to learn a model from a source data distribution, which can perform well on a different, but related target data distribution.In this paper we introduce a variational autoencoder-based multi-modal approach for the task of domain adaptation, that can be trained on a large amount of labelled data from the source domain, coupled with a comparably small amount of labelled data from the target domain. We demonstrate our approach in the context of human activity recognition using various IoT sensing modalities and report superior results when benchmarking against the effective mSDA method for domain adaptation.","","978-1-6654-3841-4","10.1109/GCAIoT53516.2021.9693050","Stiftelsen för Kunskaps- och Kompetensutveckling; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9693050","Domain adaptation;Neural Networks;Internet of Things;Human Activity Recognition","Adaptation models;Soft sensors;Multimodal sensors;Neural networks;Production;Machine learning;Activity recognition","deep learning (artificial intelligence);Internet of Things","weakly-supervised deep domain adaptation method;multimodal sensor data;real-world deployment;machine learning models;data distributions;dynamic settings;data sources;contextual changes;domain adaptation techniques;source data distribution;variational autoencoder-based multimodal approach;labelled data;source domain;target domain;IoT sensing modalities;related target data distribution","","","","30","IEEE","31 Jan 2022","","","IEEE","IEEE Conferences"
"One-Shot Example Videos Localization Network for Weakly-Supervised Temporal Action Localization","Y. Liu; W. Zhang; G. Li; L. Su; Q. Huang","School of Computer Science and Technology, Harbin Institute of Technology, Weihai, China; School of Computer Science and Technology, Harbin Institute of Technology, Weihai, China; School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China; School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China; School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China","2021 IEEE 4th International Conference on Multimedia Information Processing and Retrieval (MIPR)","19 Oct 2021","2021","","","125","130","This paper tackles the problem of example-driven weakly-supervised temporal action localization. We propose the One-shot Example Videos Localization Network (OSEVLNet) for precisely localizing the action instances in untrimmed videos with only one trimmed example video. Since the frame-level ground truth is unavailable under weakly-supervised settings, our approach automatically trains a self-attention module with reconstruction and feature discrepancy restriction. Specifically, the reconstruction restriction minimizes the discrepancy between the original input features and the reconstructed features of a Variational AutoEncoder (VAE) module. The feature discrepancy restriction maximizes the distance of weighted features between highly-responsive regions and slightly-responsive regions. Our approach achieves comparable or better results on THUMOS’14 dataset than other weakly-supervised methods while it is trained with much less videos. Moreover, our approach is especially suitable for the expansion of newly emerging action categories to meet the requirements of different occasions.","","978-1-6654-1865-2","10.1109/MIPR51284.2021.00026","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9565477","Video Analysis;Weakly Supervised Learning;Action Localization;Untrimmed Video","Location awareness;Training;Conferences;Information processing;Streaming media;Image reconstruction;Videos","image colour analysis;image motion analysis;image reconstruction;video signal processing","feature discrepancy restriction;original input features;reconstructed features;weakly-supervised methods;example-driven weakly-supervised temporal action localization;action instances;untrimmed videos;weakly-supervised settings;one-shot example videos localization network;variational autoencoder","","","","19","IEEE","19 Oct 2021","","","IEEE","IEEE Conferences"
"In-Bed Human Pose Estimation from Unseen and Privacy-Preserving Image Domains","T. Cao; M. A. Armin; S. Denman; L. Petersson; D. Ahmedt-Aristizabal","Imaging and Computer Vision Group, CSIRO Data61, Canberra, Australia; Imaging and Computer Vision Group, CSIRO Data61, Canberra, Australia; SAIVT, Queensland University of Technology, Brisbane, Australia; Imaging and Computer Vision Group, CSIRO Data61, Canberra, Australia; Imaging and Computer Vision Group, CSIRO Data61, Canberra, Australia","2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)","26 Apr 2022","2022","","","1","5","Medical applications have benefited greatly from the rapid advancement in computer vision. Considering patient monitoring in particular, in-bed human posture estimation offers important health-related metrics with potential value in medical condition assessments. Despite great progress in this domain, it remains challenging due to substantial ambiguity during occlusions, and the lack of large corpora of manually labeled data for model training, particularly with domains such as thermal infrared imaging which are privacy-preserving, and thus of great interest. Motivated by the effectiveness of self-supervised methods in learning features directly from data, we propose a multi-modal conditional variational autoencoder (MC-VAE) capable of reconstructing features from missing modalities seen during training. This approach is used with HRNet to enable single modality inference for in-bed pose estimation. Through extensive evaluations, we demonstrate that body positions can be effectively recognized from the available modality, achieving on par results with baseline models that are highly dependent on having access to multiple modes at inference time. The proposed framework supports future research towards self-supervised learning that generates a robust model from a single source, and expects it to generalize over many unknown distributions in clinical environments.","1945-8452","978-1-6654-2923-8","10.1109/ISBI52829.2022.9761598","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761598","Self-supervised learning;long-wave infrared","Training;Measurement;Privacy;Patient monitoring;Medical conditions;Pose estimation;Machine learning","computer vision;image sensors;infrared imaging;learning (artificial intelligence);patient monitoring;pose estimation","bed human pose estimation;unseen;privacy-preserving image;medical applications;rapid advancement;computer vision;patient monitoring;in-bed human posture estimation;important health-related metrics;medical condition assessments;substantial ambiguity;manually labeled data;model training;thermal infrared imaging;self-supervised methods;multimodal conditional variational autoencoder;MC-VAE;single modality inference;available modality;self-supervised learning;robust model","","","","22","IEEE","26 Apr 2022","","","IEEE","IEEE Conferences"
"EmoSen: Generating Sentiment and Emotion Controlled Responses in a Multimodal Dialogue System","M. Firdaus; H. Chauhan; A. Ekbal; P. Bhattacharyya","Department of Computer Science and Engineering, IIT Patna, Bihta, Bihar, India; Department of Computer Science and Engineering, IIT Patna, Bihta, Bihar, India; Department of Computer Science and Engineering, IIT Patna, Bihta, Bihar, India; Department of Computer Science and Engineering, IIT Patna, Bihta, Bihar, India","IEEE Transactions on Affective Computing","2 Sep 2022","2022","13","3","1555","1566","An essential skill for effective communication is the ability to express specific sentiment and emotion in a conversation. Any robust dialogue system should handle the combined effect of both sentiment and emotion while generating responses. This is expected to provide a better experience and concurrently increase users’ satisfaction. Previously, research on either emotion or sentiment controlled dialogue generation has shown great promise in developing the next generation conversational agents, but the simultaneous effect of both is still unexplored. The existing dialogue systems are majorly based on unimodal sources, predominantly the text, and thereby cannot utilize the information present in the other sources, such as video, audio, image, etc. In this article, we present at first a large scale benchmark Sentiment Emotion aware Multimodal Dialogue (SEMD) dataset for the task of sentiment and emotion controlled dialogue generation. The SEMD dataset consists of 55k conversations from 10 TV shows having text, audio, and video information. To utilize multimodal information, we propose multimodal attention based conditional variational autoencoder (M-CVAE) that outperforms several baselines. Quantitative and qualitative analyses show that multimodality, along with contextual information, plays an essential role in generating coherent and diverse responses for any given emotion and sentiment.","1949-3045","","10.1109/TAFFC.2020.3015491","SERB, Govt. of India(grant numbers:IMP/2018/002072); Visvesvaraya Ph.D. scheme for Electronics and IT; Ministry of Electronics and Information Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9165162","Conversational AI;natural language generation;sentiment-aware NLG;emotion-aware NLG;multimodality","Visualization;Task analysis;Artificial intelligence;TV;Buildings;History;Generative adversarial networks","emotion recognition;interactive systems;speech-based user interfaces","multimodal attention;coherent responses;diverse responses;robust dialogue system;generation conversational agents;emotion controlled dialogue generation;multimodal information;benchmark sentiment emotion aware multimodal dialogue dataset;emotion controlled responses;SEMD dataset;EmoSen;multimodal attention based conditional variational autoencoder;M-CVAE;qualitative analysis","","","","68","IEEE","11 Aug 2020","","","IEEE","IEEE Journals"
"Voice Conversion Based Augmentation and a Hybrid CNN-LSTM Model for Improving Speaker-Independent Keyword Recognition on Limited Datasets","Y. A. Wubet; K. -Y. Lian","Department of Electrical Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Electrical Engineering, National Taipei University of Technology, Taipei, Taiwan","IEEE Access","29 Aug 2022","2022","10","","89170","89180","Keyword recognition is the basis of speech recognition, and its application is rapidly increasing in keyword spotting, robotics, and smart home surveillance. Because of these advanced applications, improving the accuracy of keyword recognition is crucial. In this paper, we proposed voice conversion (VC) - based augmentation to increase the limited training dataset and a fusion of a convolutional neural network (CNN) and long-short term memory (LSTM) model for robust speaker-independent isolated keyword recognition. Collecting and preparing a sufficient amount of voice data for speaker-independent speech recognition is a tedious and bulky task. To overcome this, we generated new raw voices from the original voices using an auxiliary classifier conditional variational autoencoder (ACVAE) method. In this study, the main intention of voice conversion is to obtain numerous and various human-like keywords’ voices that are not identical to the source and target speakers’ pronunciation. Parallel VC was used to accurately maintain the linguistic content. We examined the performance of the proposed voice conversion augmentation techniques using robust deep neural network algorithms. Original training data, excluding generated voice using other data augmentation and regularization techniques, were considered as the baseline. The results showed that incorporating voice conversion augmentation into the baseline augmentation techniques and applying the CNN-LSTM model improved the accuracy of isolated keyword recognition.","2169-3536","","10.1109/ACCESS.2022.3200479","Ministry of Science and Technology (MOST), Taiwan(grant numbers:110-2221-E-027-121); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9863772","CNN-LSTM;data augmentation;speaker-independent keyword recognition;voice conversion","Speech recognition;Convolutional neural networks;Data models;Training data;Mel frequency cepstral coefficient;Linguistics","convolutional neural nets;deep learning (artificial intelligence);recurrent neural nets;speaker recognition","ACVAE method;robust speaker-independent isolated keyword recognition;long-short term memory model;robust deep neural network algorithms;voice conversion augmentation techniques;auxiliary classifier conditional variational autoencoder method;speaker-independent speech recognition;convolutional neural network;smart home surveillance;hybrid CNN-LSTM model","","","","55","CCBY","19 Aug 2022","","","IEEE","IEEE Journals"
"Combining Virtual Sample Generation Based Data Enhancement and Multi-objective Optimization Based Selective Ensemble for Soft Sensor Modeling","S. Huang; H. Jin; B. Yang; H. Liu","Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Kunming, China; Yunnan Key Laboratory of Artificial Intelligence, Kunming University of Science and Technology, Kunming, China; Yunnan Key Laboratory of Artificial Intelligence, Kunming University of Science and Technology, Kunming, China; Yunnan Key Laboratory of Artificial Intelligence, Kunming University of Science and Technology, Kunming, China","2022 IEEE 11th Data Driven Control and Learning Systems Conference (DDCLS)","26 Aug 2022","2022","","","287","293","Soft sensor modeling technology realizes the real-time estimation of difficult-to-measure variables by constructing the mathematical model between secondary variables and primary variable. Nevertheless, sufficient and high-quality training samples are difficult to obtain owing to the high cost of data acquisition and low sampling rate. To solve this, a soft sensor modeling method, combining virtual sample generation based data enhancement and multi-objective optimization based selective ensemble (DESE), is proposed. First, a supervised variational autoencoder (SVAE) is constructed by introducing quality variable. Second, a generative model is built through the combination of SVAE and Wasserstein GAN with gradient penalty (WGAN-gp). Third, SV-WGANgp is trained on each sample subset, which is obtained by resampling, and a fixed number of virtual samples are generated. A set of base models is established for the expanded original samples subsequently. Finally, the multi-objective optimization method is utilized to prune these models, which satisfy both accuracy and diversity requirements. After integrating the selected base models, the final prediction results are obtained. Experimental results verify that, compared with the other three popular generation models, DESE significantly improves the prediction performance of soft sensor model by supplementing the original samples.","2767-9861","978-1-6654-9675-9","10.1109/DDCLS55054.2022.9858428","National Science Foundation of China(grant numbers:62163019,61763020,61863020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9858428","Soft Sensor;Data Enhancement;Generative Model;Multi-objective Optimization;Selective Ensemble","Training;Soft sensors;Diversity reception;Optimization methods;Predictive models;Prediction algorithms;Linear programming","learning (artificial intelligence);maximum likelihood estimation;neural nets;optimisation;soft sensors","soft sensor modeling technology;difficult-to-measure variables;mathematical model;secondary variables;high-quality training samples;soft sensor modeling method;SVAE;quality variable;generative model;sample subset;virtual samples;expanded original samples;multiobjective optimization method;selected base models;popular generation models;soft sensor model;virtual sample generation based data enhancement;multiobjective optimization based selective ensemble;real-time estimation;primary variable;DESE;supervised variational autoencoder;Wasserstein GAN with gradient penalty;WGAN-gp;SV-WGANgp;prediction performance improvement","","","","20","IEEE","26 Aug 2022","","","IEEE","IEEE Conferences"
"Artificial Intelligence and Dimensionality Reduction: Tools for Approaching Future Communications","A. Ramírez-Arroyo; L. García; A. Alex-Amor; J. F. Valenzuela-Valdés","Department of Signal Theory, Telematics and Communications, Universidad de Granada, Granada, Spain; Department of Signal Theory, Telematics and Communications, Universidad de Granada, Granada, Spain; Information Technologies Department, Universidad CEU San Pablo, Madrid, Spain; Department of Signal Theory, Telematics and Communications, Universidad de Granada, Granada, Spain","IEEE Open Journal of the Communications Society","22 Mar 2022","2022","3","","475","492","This article presents a novel application of the t-distributed Stochastic Neighbor Embedding (t-SNE) clustering algorithm to the telecommunication field. t-SNE is a dimensionality reduction algorithm that allows the visualization of large dataset into a 2D plot. We present the applicability of this algorithm in a communication channel dataset formed by several scenarios (anechoic, reverberation, indoor and outdoor), and by using six channel features. Applying this artificial intelligence (AI) technique, we are able to separate different environments into several clusters allowing a clear visualization of the scenarios. Throughout the article, it is proved that t-SNE has the ability to cluster into several subclasses, obtaining internal classifications within the scenarios themselves. t-SNE comparison with different dimensionality reduction techniques (PCA, Isomap) is also provided throughout the paper. Furthermore, post-processing techniques are used to modify communication scenarios, recreating a real communication scenario from measurements acquired in an anechoic chamber. The dimensionality reduction and classification by using t-SNE and Variational AutoEncoders show good performance distinguishing between the recreation and the real communication scenario. The combination of these two techniques opens up the possibility for new scenario recreations for future mobile communications. This work shows the potential of AI as a powerful tool for clustering, classification and generation of new 5G propagation scenarios.","2644-125X","","10.1109/OJCOMS.2022.3156473","Spanish Program of Research, Development, and Innovation(grant numbers:RTI2018-102002-A-I00); “Junta de Andalucía”(grant numbers:B-TIC-402-UGR18,P18.RT.4830); Ministerio de Universidades, Gobierno de España(grant numbers:FPU19/01251); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9729516","reduction;propagation;t-SNE;unsupervised learning;wireless communications","Antenna measurements;Reverberation;Artificial intelligence;Communication channels;Clustering algorithms;Dimensionality reduction;Wireless communication","anechoic chambers (electromagnetic);data visualisation;feature extraction;learning (artificial intelligence);mobile communication;pattern clustering;principal component analysis;stochastic processes;telecommunication computing","future communications;telecommunication field;dimensionality reduction algorithm;communication channel dataset;channel features;artificial intelligence technique;clear visualization;t-SNE comparison;post-processing techniques;communication scenario;classification;scenario recreations;future mobile communications;5G propagation scenarios;stochastic neighbor embedding clustering algorithm;t-SNE clustering algorithm;dimensionality reduction techniques;internal classifications;PCA;Isomap;anechoic chamber;mobile communications;Variational AutoEncoders","","","","62","CCBY","7 Mar 2022","","","IEEE","IEEE Journals"
"Generating Representative Samples for Few-Shot Classification","J. Xu; H. Le",Stony Brook University; Amazon Robotics,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","8993","9003","Few-shot learning (FSL) aims to learn new categories with a few visual samples per class. Few-shot class representations are often biased due to data scarcity. To mitigate this issue, we propose to generate visual samples based on semantic embeddings using a conditional variational autoencoder (CVAE) model. We train this CVAE model on base classes and use it to generate features for novel classes. More importantly, we guide this VAE to strictly generate representative samples by removing non-representative samples from the base training set when training the CVAE model. We show that this training scheme enhances the representativeness of the generated samples and therefore, improves the few-shot classification results. Experimental results show that our method improves three FSL baseline methods by substantial margins, achieving state-of-the-art few-shot classification performance on miniImageNet and tieredImageNet datasets for both 1-shot and 5-shot settings. Code is available at: https://github.com/cvlab-stonybrook/fsl-rsvae.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.00880","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879962","Transfer/low-shot/long-tail learning; Statistical methods","Training;Visualization;Computer vision;Codes;Semantics;Pattern recognition","feature extraction;image classification;learning (artificial intelligence);pattern classification;video signal processing","few-shot learning;visual samples;few-shot class representations;data scarcity;semantic embeddings;conditional variational autoencoder model;CVAE model;base classes;nonrepresentative samples;base training;training scheme;representativeness;few-shot classification results;FSL baseline methods;few-shot classification performance;1-shot;5-shot settings;generating representative samples","","","","86","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Reinforcement Learning in Latent Action Sequence Space","H. Kim; M. Yamada; K. Miyoshi; T. Iwata; H. Yamakawa","Laboratory for Intelligent Systems and Informatics, Graduate School of Information Science and Technology, The University of Tokyo; NTT Secure Platform Laboratories; narrative nights inc.; NTT Communication Science Laboratories; Dwango Artificial Intelligence Laboratory","2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","10 Feb 2021","2020","","","5497","5503","One problem in real-world applications of reinforcement learning is the high dimensionality of the action search spaces, which comes from the combination of actions over time. To reduce the dimensionality of action sequence search spaces, macro actions have been studied, which are sequences of primitive actions to solve tasks. However, previous studies relied on humans to define macro actions or assumed macro actions to be repetitions of the same primitive actions. We propose encoded action sequence reinforcement learning (EASRL), a reinforcement learning method that learns flexible sequences of actions in a latent space for a high-dimensional action sequence search space. With EASRL, encoder and decoder networks are trained with demonstration data by using variational autoencoders for mapping macro actions into the latent space. Then, we learn a policy network in the latent space, which is a distribution over encoded macro actions given a state. By learning in the latent space, we can reduce the dimensionality of the action sequence search space and handle various patterns of action sequences. We experimentally demonstrate that the proposed method outperforms other reinforcement learning methods on tasks that require an extensive amount of search.","2153-0866","978-1-7281-6212-6","10.1109/IROS45743.2020.9341629","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9341629","Reinforcement Learning;Transfer Learning;Learning from Demonstration","Reinforcement learning;Search problems;Decoding;Task analysis;Intelligent robots","intelligent robots;learning (artificial intelligence);neural nets","latent action sequence space;primitive actions;reinforcement learning method;flexible sequences;high-dimensional action sequence search space;encoded macro actions;encoded action sequence reinforcement learning;dimensionality reduction;EASRL;encoder network;decoder network;variational autoencoders;policy network","","","","23","","10 Feb 2021","","","IEEE","IEEE Conferences"
"A Cyclically-Trained Adversarial Network for Invariant Representation Learning","J. Chen; J. Konrad; P. Ishwar",Boston University; Boston University; Boston University,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","3393","3402","Recent studies show that deep neural networks are vulnerable to adversarial examples which can be generated via certain types of transformations. Being robust to a desired family of adversarial attacks is then equivalent to being invariant to a family of transformations. Learning invariant representations then naturally emerges as an important goal to achieve which we explore in this paper within specific application contexts. Specifically, we propose a cyclically-trained adversarial network to learn a mapping from image space to latent representation space and back such that the latent representation is invariant to a specified factor of variation (e.g., identity). The learned mapping assures that the synthesized image is not only realistic, but has the same values for unspecified factors (e.g., pose and illumination) as the original image and a desired value of the specified factor. Unlike disentangled representation learning, which requires two latent spaces, one for specified and another for unspecified factors, invariant representation learning needs only one such space. We encourage invariance to a specified factor by applying adversarial training using a variational autoencoder in the image space as opposed to the latent space. We strengthen this invariance by introducing a cyclic training process (forward and backward cycle). We also propose a new method to evaluate conditional generative networks. It compares how well different factors of variation can be predicted from the synthesized, as opposed to real, images. In quantitative terms, our approach attains state-of-the-art performance in experiments spanning three datasets with factors such as identity, pose, illumination or style. Our method produces sharp, high-quality synthetic images with little visible arte-facts compared to previous approaches.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00399","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150707","","Training;Generators;Neural networks;Task analysis;Gallium nitride;Image generation;Decoding","image representation;learning (artificial intelligence);neural nets","variational autoencoder;conditional generative networks;cyclic training process;adversarial training;disentangled representation learning;synthesized image;latent representation space;image space;adversarial attacks;deep neural networks;invariant representation learning;cyclically-trained adversarial network","","","","42","","28 Jul 2020","","","IEEE","IEEE Conferences"
"Trajectory-User Link with Attention Recurrent Networks","T. Sun; Y. Xu; F. Wang; L. Wu; T. Qian; Z. Shao","University of Chinese Academy of Sciences, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","4589","4596","The prevalent adoptions of GPS-enabled devices have witnessed an explosion of various location-based services which produces a huge amount of trajectories monitoring the individuals' movements. In this paper, we tackle Trajectory-User Link (TUL) problem, which identifies humans' movement patterns and links trajectories to the users who generated them. Existing solutions on TUL problem employ recurrent neural networks and variational autoencoder methods, which face the bottlenecks in the case of excessively long trajectories and fragmentary users' movements. However, these are common characteristics of trajectory data in reality, leading to performance degradation of the existing models. In this paper, we propose an end-to-end attention recurrent neural learning framework, called TULAR (Trajectory-User Link with Attention Recurrent Networks), which focus on selected parts of the source trajectories when linking. TULAR introduce the Trajectory Semantic Vector (TSV) via unsupervised location representation learning and recurrent neural networks, by which to reckon the weight of parts of source trajectory. Further, we employ three attention scores for the weight measurements. Experiments are conducted on two real world datasets and compared with several existing methods, and the results show that TULAR yields a new state-of-the-art performance. Source code is public available at GitHub: https://github.com/taos123/TULAR.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9412453","NSFC(grant numbers:61902376,61602447); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9412453","","Weight measurement;Training;Recurrent neural networks;Semantics;Graphics processing units;Trajectory;Pattern recognition","Global Positioning System;learning (artificial intelligence);location based services;recurrent neural nets;user interfaces","trajectory data;end-to-end attention recurrent neural learning framework;source trajectory;recurrent neural networks;GPS-enabled devices;location-based services;human movement patterns;TUL problem;trajectory-user link problem;trajectory semantic vector;attention recurrent networks;variational autoencoder methods;TULAR;TSV;unsupervised location representation learning;weight measurements","","","","28","","5 May 2021","","","IEEE","IEEE Conferences"
"Emerging Intention Mining Inspired by Semantic Reconstruction","J. Shen; J. Xiang; L. Zhao; L. Wang","Institute of Information Engineering, University of Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","2020 IEEE 3rd International Conference on Computer and Communication Engineering Technology (CCET)","6 Oct 2020","2020","","","208","213","Emerging intention mining is the process of identifying the inputs that differ in some respect from the training samples. With the development of artificial intelligence, more and more attention has been paid to data mining. Therefore, methods which can efficiently identify the emerging intentions are needed. However, due to the lack of data for emerging intention, training an end-to-end deep network is a cumbersome task. In this paper, we propose an end-to-end architecture for emerging intention mining which inspired by the success of generative adversarial networks and conditional variational autoencoder (CVAE). Our architecture tries understand the underlying concept of the inputs and then reconstruct them through semantic information. There are two deep networks by Convolutional Neural Networks (CNN). One network works as the semantic information extraction and the other works as the novelty detector. The first network supports the second by enhancing the inlier samples and distorting the outliers. The proposed framework applies to different datasets. The results illustrate that our proposed method learns the target class effectively and is superior to the baseline and state-of-the-art methods.","","978-1-7281-8811-9","10.1109/CCET50901.2020.9213133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9213133","emerging intention mining;CVAE;sematic reconstructio","Semantics;Feature extraction;Decoding;Data mining;Training;Image reconstruction;Gaussian distribution","convolutional neural nets;data mining;information retrieval;learning (artificial intelligence)","semantic information extraction;intention mining inspired;semantic reconstruction;training samples;artificial intelligence;data mining;emerging intentions;end-to-end deep network;end-to-end architecture;generative adversarial networks;conditional variational autoencoder;deep networks;Convolutional Neural Networks;network works","","","","21","","6 Oct 2020","","","IEEE","IEEE Conferences"
"A Probabilistic Model for Segmentation of Ambiguous 3D Lung Nodule","X. Long; W. Chen; Q. Wang; X. Zhang; C. Liu; Y. Li; J. Zhang","School of Big Data and Software Engineering, Chongqing University, Chongqing, China; School of Big Data and Software Engineering, Chongqing University, Chongqing, China; School of Big Data and Software Engineering, Chongqing University, Chongqing, China; School of Big Data and Software Engineering, Chongqing University, Chongqing, China; The First Affiliated Hospital of Army Medical University, Chongqing, China; Chongqing University Cancer Hospital, Chongqing, China; Chongqing University Cancer Hospital, Chongqing, China","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","1130","1134","Many medical images domains suffer from inherent ambiguities. A feasible approach to resolve the ambiguity of lung nodule in the segmentation task is to learn a distribution over segmentations based on a given 2D lung nodule image. Whereas lung nodule with 3D structure contains dense 3D spatial information, which is obviously helpful for resolving the ambiguity of lung nodule, but so far no one has studied it. To this end we propose a probabilistic generative segmentation model consisting of a V-Net and a conditional variational autoencoder. The proposed model obtains the 3D spatial information of lung nodule with V-Net to learn a density model over segmentations. It is capable of efficiently producing multiple plausible semantic lung nodule segmentation hypotheses to assist radiologists in making further diagnosis to resolve the present ambiguity. We evaluate our method on publicly available LIDC-IDRI dataset and achieves a new state-of-the-art result with 0.231±0.005 in $D_{GED}^2$. This result demonstrates the effectiveness and importance of leveraging the 3D spatial information of lung nodule for such problems. Code is available at: https://github.com/jiangjiangxiaolong/PV-Net.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9415006","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9415006","Nodule ambiguity;Probability model;3D segmentation;Medical image analysis","Solid modeling;Image segmentation;Three-dimensional displays;Semantics;Lung;Probabilistic logic;Spatial resolution","cancer;computerised tomography;image segmentation;lung;medical image processing;neural nets","probabilistic generative segmentation model;3D spatial information;multiple plausible semantic lung nodule segmentation;V-Net;conditional variational autoencoder;LIDC-IDRI dataset;2D lung nodule image;CT scans","","","","19","","13 May 2021","","","IEEE","IEEE Conferences"
"Learning Robust Latent Space of Basketball Player Trajectories for Tactics Analysis","Y. -S. Chao; W. -C. Chen; J. -W. Peng; M. -C. Hu","National Tsing Hua University, Taiwan; National Cheng Kung University, Taiwan; National Cheng Kung University, Taiwan; National Tsing Hua University, Taiwan","2022 IEEE International Conference on Multimedia and Expo (ICME)","26 Aug 2022","2022","","","1","6","Tactic analysis of trajectory data plays an important role in the field of sports science. However, the tactical labels of trajectories are usually insufficient, which limits the deep models to learn the general concept of tactics. In this work, we combine the recurrent variational autoencoder with attention module to learn a robust latent space of the basketball offensive trajectories without the need of labeled data. The learned latent space can be further applied to advanced tasks such as supervised tactics classification, unsupervised tactics clustering, and defensive trajectory generation. The experimental results show that our proposed model achieves better or competitive performance than the previous methods. Furthermore, our proposed model is the first one that focuses on zero-shot tactics clustering and the performance even outperforms the previous methods with supervised and unsupervised settings, which shows the promise of tactics analysis for trajectories in the case of limited labeled data.","1945-788X","978-1-6654-8563-0","10.1109/ICME52920.2022.9859960","Ministry of Science and Technology(grant numbers:108-2221-E-007-106-MY3,109-2221-E-007-095-MY3,110-2221-E-007-061-MY3,110-2221-E-007-060-MY3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9859960","basketball;defensive trajectories generation;offensive tactic recognition","Analytical models;Data models;Trajectory;Task analysis;Sports","data analysis;deep learning (artificial intelligence);pattern classification;pattern clustering;sport;unsupervised learning","basketball player trajectories;tactic analysis;trajectory data;recurrent variational autoencoder;basketball offensive trajectories;defensive trajectory generation;robust latent space learning;zero-shot tactic clustering;unsupervised tactic clustering;supervised tactic classification;sports science;attention module","","","","13","IEEE","26 Aug 2022","","","IEEE","IEEE Conferences"
"Generating Annotated High-Fidelity Images Containing Multiple Coherent Objects","B. Cardenas; D. Arya; D. K. Gupta","Informatics Institute, University of Amsterdam, The Netherlands; Informatics Institute, University of Amsterdam, The Netherlands; Transmute AI Research, The Netherlands","2021 IEEE International Conference on Image Processing (ICIP)","23 Aug 2021","2021","","","834","838","Recent developments related to generative models have enabled the generation of diverse and high-fidelity images. In particular, layout-to-image generation models have gained significant attention due to their capability to generate realistic and complex images containing distinct objects. These models are generally conditioned on either semantic layouts or textual descriptions. However, unlike natural images, providing auxiliary information can be extremely hard in domains such as biomedical imaging and remote sensing. In this work, we propose a multi-object generation framework1 that can synthesize images with multiple objects without explicitly requiring their contextual information during the generation process. Based on a vector-quantized variational autoencoder (VQ-VAE) backbone, our model learns to preserve spatial coherency within an image as well as semantic coherency through the use of powerful autoregressive priors. An advantage of our approach is that the generated samples are accompanied by object-level annotations. The efficacy of our approach is demonstrated through application on medical imaging datasets, where we show that augmenting the training set with the samples generated by our approach improves the performance of existing models.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506406","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506406","Generative Modelling;VQ-VAE;Pixel-SNAIL;Multi-Object Generation;Data Augmentation","Training;Image segmentation;Biological system modeling;Semantics;Layout;Spatial coherence;Remote sensing","deep learning (artificial intelligence);image representation;image segmentation;image texture;object detection;vector quantisation","high-fidelity images;generative models;layout-to-image generation models;realistic images;complex images;distinct objects;semantic layouts;natural images;biomedical imaging;multiobject generation framework;semantic coherency;object-level annotations;medical imaging datasets;multiple coherent objects;textual descriptions;remote sensing;vector-quantized variational autoencoder;VQ-VAE;spatial coherency","","","","27","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"Mobility-Aware Pre-caching Based on Unsupervised Deep Generative Model for Small Cell Networks","Z. Yao; S. Chen; J. Yang; Y. Liu; H. Xie","University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; China Academy of Electronics and Information Technology, Beijing, China; University of Science and Technology of China, Hefei, China","2019 13th International Conference on Signal Processing and Communication Systems (ICSPCS)","27 Feb 2020","2019","","","1","7","Due to the short coverage of small-cell base stations (SBS), mobile device is more likely to move away from its covered area, and thus has to continually switch between SBSs and reestablish the connections with the remote servers. Aiming for improving the delivery efficiency of ever-growing mobile data traffic, we conceive proactive caching over dense small-cell network (DSCN). Without any prior knowledge, it is challenging to Figure out users movements and determine content placement in SBSs. Motivated by the recent advances in deep learning, we first propose a model-free mobility prediction approach based on the conditional variational autoencoder (CVAE) in this paper. Our approach is able to infer the latent information about users habits, which are considered to be closely related to their movements, from historical trajectory. By testing on real-world GPS trajectories, our approach achieves a prediction accuracy of about 80%. Then based on the movement prediction, we formulate an optimization problem to maximize the local cache utility for DSCN. The experimental results show that our mobility-aware pre-caching strategy can support a seamless mobility handover with a lower delay and a higher data rate.","","978-1-7281-2194-9","10.1109/ICSPCS47537.2019.9008496","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9008496","","Hidden Markov models;Trajectory;Servers;Predictive models;Optimization;Schedules;Base stations","cache storage;cellular radio;mobile computing;mobility management (mobile radio);neural nets;optimisation;telecommunication traffic","content placement;users movements;dense small-cell network;proactive caching;mobile data traffic;delivery efficiency;remote servers;covered area;mobile device;unsupervised deep generative model;seamless mobility handover;mobility-aware pre-caching strategy;DSCN;local cache utility;movement prediction;prediction accuracy;real-world GPS trajectories;users habits;conditional variational autoencoder;model-free mobility prediction approach;deep learning","","","","16","","27 Feb 2020","","","IEEE","IEEE Conferences"
"Learning to Conceal: A Method for Preserving Privacy and Avoiding Prejudice in Images","A. Stekel; M. Hanukoglu; A. Rovshitz; N. Goldberg; A. Azaria","Computer Science Department, Data Science Center, Ariel University, Israel; Computer Science Department, Data Science Center, Ariel University, Israel; Computer Science Department, Data Science Center, Ariel University, Israel; Computer Science Department, Data Science Center, Ariel University, Israel; Computer Science Department, Data Science Center, Ariel University, Israel","2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)","24 Dec 2020","2020","","","761","766","We introduce a learning model able to conceal personal information (e.g. gender, age, ethnicity, etc.) from an image while maintaining any additional information present in the image (e.g. smile, hair-style, brightness). Our trained model is not provided the information that it is concealing, and does not try learning it either. Namely, we created a variational autoencoder (VAE) model that is trained on a dataset including labels of the information one would like to conceal (e.g. gender, ethnicity, age). These labels are directly added to the VAE's sampled latent vector. Due to the limited number of neurons in the latent vector and its appended noise, the VAE avoids learning any relation between the given images and the given labels, as those are given directly. Therefore, the encoded image lacks any of the information one wishes to conceal. The encoding may be decoded back into an image according to any provided properties (e.g. a 40-year old woman). Our method successfully conceals the private information; a convolutional neural network trained on the concealed images cannot restore the original private information. In contrast to the private information, a user study shows that the remaining properties of the original image carry-on to the concealed image. The proposed architecture can be used as a mean for privacy preserving and can serve as an input to systems, which will become unbiased and not suffer from prejudice.","2375-0197","978-1-7281-9228-4","10.1109/ICTAI50040.2020.00121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288334","Privacy, VAE, Fair representation","Privacy;Image coding;Neurons;Learning (artificial intelligence);Tools;Image restoration;Convolutional neural networks","cryptographic protocols;data privacy;image coding;learning (artificial intelligence);neural nets","VAE sampled latent vector;avoiding prejudice;privacy preserving;original private information;concealed image;encoded image;given labels;given images;dataset including labels;variational autoencoder model;trained model;additional information present;ethnicity;gender;conceal personal information;learning model","","","","14","","24 Dec 2020","","","IEEE","IEEE Conferences"
"Towards Object Shape Translation Through Unsupervised Generative Deep Models","L. Bollens; T. Tuytelaars; O. M. José","ESAT-PSI, KU Leuven, Leuven, Belgium; ESAT-PSI, KU Leuven, Leuven, Belgium; ESAT-PSI, KU Leuven, Leuven, Belgium","2019 IEEE International Conference on Image Processing (ICIP)","26 Aug 2019","2019","","","4220","4224","This paper focuses on the problem of unsupervised image-to-image translation. More specifically, we aim at finding a translation network such that objects and shapes that only appear in the source domain are translated to objects and shapes only appearing in the target domain, while style color features present in the source domain remain the same. To achieve this, we use a domain-specific variational autoencoder and represent each image in its latent space representation. In a second step, we learn a translation between latent spaces of different domains using generative adversarial networks. We evaluate this framework on multiple datasets and verify the effect of multiple perceptual losses. Experiments on the MNIST and SVHN datasets show the effectiveness of the proposed translation method.","2381-8549","978-1-5386-6249-6","10.1109/ICIP.2019.8803457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8803457","","Shape;Image color analysis;Gallium nitride;Training;Standards;Generators;Transforms","image representation;learning (artificial intelligence);neural nets","domain-specific variational autoencoder;latent space representation;generative adversarial networks;object shape translation;unsupervised generative deep models;unsupervised image-to-image translation;translation network","","","","31","","26 Aug 2019","","","IEEE","IEEE Conferences"
"An Efficient Learning Based Autonomous Exploration Algorithm For Mobile Robots","Z. Xing; J. Wang; X. Zhu","School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; Zhuhai Bigdata Research Institute, Zhuhai, China","2022 IEEE International Conference on Real-time Computing and Robotics (RCAR)","5 Sep 2022","2022","","","551","556","In this paper, a novel autonomous exploration algorithm is proposed to achieve efficient exploration task of an unknown environment in terms of the shortest path. First, a new neural network based on the variational autoencoder, LMPnet, is proposed to predict a series of local maps with projected obstacles of unknown areas. Then, a deep Q-network with long-short term memory (LSTM) structure, ETPNet, is proposed to generate piecewise local target points based on the predicted local maps where the reward function is designed to favor shorter length of the local path and larger information gain. Experimental results demonstrate that the proposed algorithm achieves good performance in reducing exploration time.","","978-1-6654-6983-8","10.1109/RCAR54675.2022.9872229","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9872229","","Deep learning;Neural networks;Collaboration;Prediction algorithms;Real-time systems;Planning;Mobile robots","collision avoidance;learning (artificial intelligence);mobile robots;neural nets;path planning","efficient exploration task;unknown environment;shortest path;neural network;variational autoencoder;projected obstacles;unknown areas;deep Q-network;long-short term memory structure;piecewise local target points;predicted local maps;local path;exploration time;mobile robots;novel autonomous exploration algorithm","","","","20","IEEE","5 Sep 2022","","","IEEE","IEEE Conferences"
"Leveraging a Probabilistic PCA Model to Understand the Multivariate Statistical Network Monitoring Framework for Network Security Anomaly Detection","F. Pérez-Bueno; L. García; G. Maciá-Fernández; R. Molina","Departamento de Ciencias de la Computación e Inteligencia Artificial, Universidad de Granada, Granada, Spain; Departamento de Teoria de la Señal, Telematica y Comunicaciones, Universidad de Granada, Granada, Spain; Departamento de Teoria de la Señal, Telematica y Comunicaciones, Universidad de Granada, Granada, Spain; Departamento de Ciencias de la Computación e Inteligencia Artificial, Universidad de Granada, Granada, Spain","IEEE/ACM Transactions on Networking","15 Jun 2022","2022","30","3","1217","1229","Network anomaly detection is a very relevant research area nowadays, especially due to its multiple applications in the field of network security. The boost of new models based on variational autoencoders and generative adversarial networks has motivated a reevaluation of traditional techniques for anomaly detection. It is, however, essential to be able to understand these new models from the perspective of the experience attained from years of evaluating network security data for anomaly detection. In this paper, we revisit anomaly detection techniques based on PCA from a probabilistic generative model point of view, and contribute a mathematical model that relates them. Specifically, we start with the probabilistic PCA model and explain its connection to the Multivariate Statistical Network Monitoring (MSNM) framework. MSNM was recently successfully proposed as a means of incorporating industrial process anomaly detection experience into the field of networking. We have evaluated the mathematical model using two different datasets. The first, a synthetic dataset created to better understand the analysis proposed, and the second, UGR’16, is a specifically designed real-traffic dataset for network security anomaly detection. We have drawn conclusions that we consider to be useful when applying generative models to network security detection.","1558-2566","","10.1109/TNET.2021.3138536","Agencia Estatal de Investigación(grant numbers:PID2019-105142RBC22/ AEI/10.13039/501100011033); Spanish Ministerio de Economía y Competitividad (MINECO)(grant numbers:TIN2017-83494-R); Fondo Europeo de Desarrollo Regional (FEDER)/Junta de Andalucia-Consejería de Transformación Económica, Industria y Universidades(grant numbers:A-TIC-215-UGR18); Ministerio de Economía, Industria y Competitividad under FPI Contract(grant numbers:BES-2017-081584); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9668967","Anomaly detection;PPCA;generative models;network security","Anomaly detection;Principal component analysis;Mathematical models;Analytical models;Adaptation models;Network security;Proposals","computer network security;data handling;neural nets;principal component analysis;telecommunication traffic","MSNM framework;variational autoencoders;multivariate statistical network monitoring framework;network security data;generative adversarial networks;network security anomaly detection;industrial process anomaly detection;probabilistic PCA model;mathematical model","","","","36","IEEE","4 Jan 2022","","","IEEE","IEEE Journals"
"Diverse Preference Augmentation with Multiple Domains for Cold-start Recommendations","Y. Zhang; C. Li; I. W. Tsang; H. Xu; L. Duan; H. Yin; W. Li; J. Shao","Intelligent Terminal Key Laboratory of Sichuan Province, Yibin, China; University of Electronic Science and Technology of China, Chengdu, China; Center for Frontier AI Research, Research Agency for Science, Technology and Research (A⋆STAR), Singapore; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; The University of Queensland, Brisbane, Australia; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China","2022 IEEE 38th International Conference on Data Engineering (ICDE)","2 Aug 2022","2022","","","2942","2955","Cold-start issues have been more and more challenging for providing accurate recommendations with the fast increase of users and items. Most existing approaches attempt to solve the intractable problems via content-aware recommendations based on auxiliary information and/or cross-domain recommendations with transfer learning. Their performances are often constrained by the extremely sparse user-item interactions, unavailable side information, or very limited domain-shared users. Recently, meta-learners with meta-augmentation by adding noises to labels have been proven to be effective to avoid overfitting and shown good performance on new tasks. Motivated by the idea of meta-augmentation, in this paper, by treating a user's preference over items as a task, we propose a so-called Diverse Preference Augmentation framework with multiple source domains based on meta-learning (referred to as MetaDPA) to i) generate diverse ratings in a new domain of interest (known as target domain) to handle overfitting on the case of sparse interactions, and to ii) learn a preference model in the target domain via a meta-learning scheme to alleviate cold-start issues. Specifically, we first conduct multi-source domain adaptation by dual conditional variational autoencoders and impose a Multi-domain InfoMax (MDI) constraint on the latent representations to learn domain-shared and domain-specific preference properties. To avoid overfitting, we add a Mutually-Exclusive (ME) constraint on the output of decoders to generate diverse ratings given content data. Finally, these generated diverse ratings and the original ratings are introduced into the meta-training procedure to learn a preference meta-learner, which produces good generalization ability on cold-start recommendation tasks. Experiments on real-world datasets show our proposed MetaDPA clearly outperforms the current state-of-the-art baselines.","2375-026X","978-1-6654-0883-7","10.1109/ICDE53745.2022.00265","National Natural Science Foundation of China(grant numbers:62002052,61801060,62176047,62172075,61832001); Australian Research Council(grant numbers:FT210100624,DP180100106,DP200101328,DP190101985); Beijing Natural Science Foundation(grant numbers:Z190023); China Postdoctoral Science Foundation(grant numbers:2019TQ0051); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9835490","Recommender system;preference augmentation;meta leaning;cold-start","Adaptation models;Conferences;Transfer learning;Data engineering;Decoding;Task analysis;Multi-layer neural network","information filtering;learning (artificial intelligence);recommender systems","transfer learning;domain-shared users;meta-augmentation;multiple source;target domain;sparse interactions;meta-learning scheme;cold-start issues;multisource domain adaptation;dual conditional variational autoencoders;domain-specific preference properties;meta-training procedure;cold-start recommendations;content-aware recommendations;cross-domain recommendations;multiple domains;mutually-exclusive;MetaDPA;multidomain InfoMax constraint","","","","64","IEEE","2 Aug 2022","","","IEEE","IEEE Conferences"
"Self-Supervised Multimodal Domino: in Search of Biomarkers for Alzheimer’s Disease","A. Fedorov; T. Sylvain; E. Geenjaar; M. Luck; L. Wu; T. P. DeRamus; A. Kirilin; D. Bleklov; V. D. Calhoun; S. M. Plis","Center for Translational Research in Neuroimaging and Data Science, Atlanta, GA, USA; Université de Montréal, Montreal, Quebec, Canada; Delft University of Technology, Delft, the Netherlands; Mila - Quebec AI Institute; Center for Translational Research in Neuroimaging and Data Science, Atlanta, GA, USA; Center for Translational Research in Neuroimaging and Data Science, Atlanta, GA, USA; Independent Researchers; Independent Researchers; Center for Translational Research in Neuroimaging and Data Science, Atlanta, GA, USA; Center for Translational Research in Neuroimaging and Data Science, Atlanta, GA, USA","2021 IEEE 9th International Conference on Healthcare Informatics (ICHI)","15 Oct 2021","2021","","","23","30","Sensory input from multiple sources is crucial for robust and coherent human perception. Different sources contribute complementary explanatory factors. Similarly, research studies often collect multimodal imaging data, each of which can provide shared and unique information. This observation motivated the design of powerful multimodal self-supervised representation-learning algorithms. In this paper, we unify recent work on multimodal self-supervised learning under a single framework. Observing that most self-supervised methods optimize similarity metrics between a set of model components, we propose a taxonomy of all reasonable ways to organize this process. We first evaluate models on toy multimodal MNIST datasets and then apply them to a multimodal neuroimaging dataset with Alzheimer’s disease patients. We find that (1) multimodal contrastive learning has significant benefits over its unimodal counterpart, (2) the specific composition of multiple contrastive objectives is critical to performance on a downstream task, (3) maximization of the similarity between representations has a regularizing effect on a neural network, which can sometimes lead to reduced downstream performance but still reveal multimodal relations. Results show that the proposed approach outperforms previous self-supervised encoder-decoder methods based on canonical correlation analysis (CCA) or the mixture-of-experts multimodal variational autoEncoder (MMVAE) on various datasets with a linear evaluation protocol. Importantly, we find a promising solution to uncover connections between modalities through a jointly shared subspace that can help advance work in our search for neuroimaging biomarkers.","2575-2634","978-1-6654-0132-6","10.1109/ICHI52183.2021.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9565782","","Neuroimaging;Publishing;Toy manufacturing industry;Taxonomy;Biomarkers;Hardware;Computational efficiency","diseases;learning (artificial intelligence);medical image processing;neural nets;neurophysiology","self-supervised learning;single framework;self-supervised methods optimize similarity metrics;model components;toy multimodal MNIST datasets;multimodal neuroimaging dataset;Alzheimer's disease patients;contrastive learning;multiple contrastive objectives;reduced downstream performance;multimodal relations;previous self-supervised encoder-decoder methods;mixture-of-experts multimodal variational autoEncoder;neuroimaging biomarkers;supervised multimodal domino;sensory input;robust human perception;coherent human perception;complementary explanatory factors;multimodal imaging data;unique information;powerful multimodal self-supervised representation-learning algorithms","","","","42","","15 Oct 2021","","","IEEE","IEEE Conferences"
"Topology Optimization of Operational Amplifier in Continuous Space via Graph Embedding","J. Lu; L. Lei; F. Yang; L. Shang; X. Zeng","State Key Lab of ASIC & System, School of Microelectronics, Fudan University, Shanghai, China; State Key Lab of ASIC & System, School of Microelectronics, Fudan University, Shanghai, China; State Key Lab of ASIC & System, School of Microelectronics, Fudan University, Shanghai, China; China and Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; State Key Lab of ASIC & System, School of Microelectronics, Fudan University, Shanghai, China","2022 Design, Automation & Test in Europe Conference & Exhibition (DATE)","19 May 2022","2022","","","142","147","Operational amplifier is a key building block in analog circuits. However, the design process of the operational amplifier is complex and time-consuming, as there are no practical automation tools available in the industry. This paper presents a new topology optimization method for operational amplifiers. The behavioral description of the operational amplifier is described using a directed acyclic graph (DAG), which is then transformed into a low-dimensional embedding in continuous space using a variational graph autoencoder. Topology search is performed in the continuous embedding space using stochastic optimization methods, such as Bayesian Optimization. The yield search results are then transformed back to operational amplifier topologies using a graph decoder. The proposed method is also equipped with a surrogate model for performance prediction. Experimental results show that the proposed approach can achieve significant speedup over the genetic searching algorithms. The produced three-stage operational amplifiers offer competitive performance compared to manual designs.","1558-1101","978-3-9819263-6-1","10.23919/DATE54114.2022.9774676","National Key R&D Program of China(grant numbers:2020YFA0711900,2020YFA0711901); National Natural Science Foundation of China (NSFC)(grant numbers:61822402,61774045,62090025,61929102,62011530132); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9774676","","Operational amplifiers;Performance evaluation;Representation learning;Directed acyclic graph;Optimization methods;Stochastic processes;Predictive models","Bayes methods;circuit optimisation;directed graphs;network topology;operational amplifiers;stochastic processes","continuous space;topology optimization method;continuous embedding space;operational amplifier topologies;three-stage operational amplifiers;graph embedding;directed acyclic graph;DAG;low-dimensional embedding;variational graph autoencoder;stochastic optimization methods;Bayesian Optimization;graph decoder","","","","22","","19 May 2022","","","IEEE","IEEE Conferences"
"Approximating Constraint Manifolds Using Generative Models for Sampling-Based Constrained Motion Planning","C. Acar; K. P. Tee","Institute for Infocomm Research (I2R), A*STAR, Singapore; Institute for Infocomm Research (I2R), A*STAR, Singapore","2021 IEEE International Conference on Robotics and Automation (ICRA)","18 Oct 2021","2021","","","8451","8457","Sampling-based motion planning under task constraints is challenging because the null-measure constraint manifold in the configuration space makes rejection sampling extremely inefficient, if not impossible. This paper presents a learning-based sampling strategy for constrained motion planning problems. We investigate the use of two well-known deep generative models, the Conditional Variational Autoencoder (CVAE) and the Conditional Generative Adversarial Net (CGAN), to generate constraint-satisfying sample configurations. Instead of precomputed graphs, we use generative models conditioned on constraint parameters for approximating the constraint manifold. This approach allows for the efficient drawing of constraint-satisfying samples online without any need for modification of available sampling-based motion planning algorithms. We evaluate the efficiency of these two generative models in terms of their sampling accuracy and coverage of sampling distribution. Simulations and experiments are also conducted for different constraint tasks on two robotic platforms.","2577-087X","978-1-7281-9077-8","10.1109/ICRA48506.2021.9561456","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9561456","","Manifolds;Automation;Conferences;Approximation algorithms;Planning;Task analysis;Robots","end effectors;learning (artificial intelligence);path planning;sampling methods","task constraints;null-measure constraint manifold;configuration space;rejection sampling;learning-based sampling strategy;constrained motion planning problems;deep generative models;Conditional Variational Autoencoder;Conditional Generative Adversarial Net;constraint-satisfying sample configurations;constraint parameters;constraint-satisfying samples;available sampling-based motion planning algorithms;sampling accuracy;sampling distribution;different constraint tasks","","","","36","","18 Oct 2021","","","IEEE","IEEE Conferences"
"Quality Prediction for Nonlinear Dynamic Processes Using Semi-Supervised Soft Sensors: An application on Ammonia Decarburization Processes","L. Y. Shan; J. Chen","Department of Chemical Engineering, Chung-Yuan Christian University Chung-Li, Taoyuan, Taiwan, Republic of China; Department of Chemical Engineering, Chung-Yuan Christian University Chung-Li, Taoyuan, Taiwan, Republic of China","2022 IEEE International Symposium on Advanced Control of Industrial Processes (AdCONIP)","21 Sep 2022","2022","","","255","260","As a measurement for the production performance, the online quality variables from soft sensors contribute greatly to obtaining immediate information from the process. The complex correlations between large numbers of process variables and disturbances inherited from the dynamic and nonlinear characteristics of chemical processes put more challenges in constructing the soft-sensor models. The soft sensors which are typically developed in steady-state conditions are not suitable for doing predictions in a dynamic operating system. This paper proposes a semi-supervised latent dynamic variational autoencoder (S2-LDVAE) to learn features between the process and quality data. Furthermore, the issue of the uneven length of the process and quality data is noteworthy. When there are fewer quality data than the process data, severe degradation to the performance of the trained model may occur. The process and quality data are encoded into the latent space in a temporal way for dynamic feature extraction. In the case of missing quality data, the artificial data generated by the trained prediction network are used to provide quality estimates during on-line prediction. The proposed method is compared with the other methods to show its contribution and performance in terms of quality prediction in a numerical case and an industrial case.","","978-1-6654-7174-9","10.1109/AdCONIP55568.2022.9894213","Ministry of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9894213","","Ammonia;Correlation;Soft sensors;Process control;Predictive models;Feature extraction;Data models","ammonia;feature extraction;neural nets;production engineering computing;quality control;semi-supervised learning (artificial intelligence);soft sensors","dynamic operating system;semisupervised latent dynamic variational autoencoder;quality data;process data;dynamic feature extraction;artificial data;trained prediction network;quality prediction;nonlinear dynamic processes;semisupervised soft sensors;ammonia decarburization processes;online quality variables;chemical processes;steady-state conditions","","","","17","IEEE","21 Sep 2022","","","IEEE","IEEE Conferences"
"Regional Forecast of Heavy Precipitation and Interpretability Based on TD-VAE","Z. Lu; X. Ding; Q. Yan; J. Guo","School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China","2021 40th Chinese Control Conference (CCC)","6 Oct 2021","2021","","","7260","7265","Heavy precipitation is a kind of regional weather condition with transitory action time, strong outburst and serious disaster. The formation of heavy precipitation weather generally requires: unstable thermodynamic and dynamic parameters and abundant precipitable water. This research solved the dilemma of forecasting severe precipitation in Tianjin. Firstly, the missing values in the original encrypted data are estimated according to the spatio-temporal interpolation method. Secondly, some convective parameters commonly used in meteorological field are calculated to increase the credibility of the classifier. Moreover, a variational autoencoder-based transfer discrimination (TD-VAE) algorithm is employed to tackle the difficulty of class imbalance: the TD-VAE generates a mass of different cases from the minority classes of the imbalanced dataset to train the classifier. Finally, the rationality of the calculated convection parameters and TD-VAE is demonstrated by an explainable machine learning method. The experimental results reveal the data augmentation strategy based on VAE can well deal with the dilemma of class imbalance in binary classification, which is superior to the traditional oversampling algorithm in several machine learning methods.","1934-1768","978-9-8815-6380-4","10.23919/CCC52363.2021.9549531","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9549531","Heavy precipitation;Spatio-temporal interpolation;TD-VAE algorithm;Explainable machine learning","Interpolation;Thermodynamics;Machine learning algorithms;Time series analysis;Weather forecasting;Predictive models;Feature extraction","convection;data handling;interpolation;learning (artificial intelligence);pattern classification;sampling methods;weather forecasting","regional forecast;TD-VAE;regional weather condition;transitory action time;strong outburst;serious disaster;heavy precipitation weather;dynamic parameters;abundant precipitable water;dilemma;severe precipitation;original encrypted data;spatio-temporal interpolation method;convective parameters;classifier;variational autoencoder-based transfer discrimination algorithm;class imbalance;calculated convection parameters;explainable machine learning method","","","","17","","6 Oct 2021","","","IEEE","IEEE Conferences"
"QHash: An efficient hashing algorithm for low-variance image deduplication","X. Li; L. Chang; X. Liu","School of Computer Science McGill University, Montreal, QC, Canada; School of Computer Science McGill University, Montreal, QC, Canada; School of Computer Science McGill University, Montreal, QC, Canada","2021 IEEE 23rd Int Conf on High Performance Computing & Communications; 7th Int Conf on Data Science & Systems; 19th Int Conf on Smart City; 7th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)","30 May 2022","2021","","","9","15","Attributed to the widespread use of general artificial intelligence (AI), large-scale datasets have become a critical component for the success of AI-powered applications. While collecting a larger dataset is desirable in general, studies have revealed that many databases include duplicated images. The accumulation of redundant images will result in excessive resource usage and inefficient cloud storage utilization. To get rid of the duplicates, hashing-based methods have been developed for the problem of image deduplication. However, as demonstrated in our experiments, current approaches fail in dataset with small visual difference, such as medical images. To this end, we propose QHash, which achieves effective image deduplication on the low-variance dataset. QHash leverages Vector Quantized Variational AutoEncoder (VQ-VAE) to learn the data distribution in an unsupervised manner. In addition, hash sequences are implemented using integer-based tensor, enabling distance calculation and deduplication being processed in parallel on either CPU or GPU. Extensive experiments show that QHash outperforms other baseline approaches by at least 50%, while is about 23% memory efficient and 18% deduplication time speedup.","","978-1-6654-9457-1","10.1109/HPCC-DSS-SmartCity-DependSys53884.2021.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9781094","Image Deduplication;Hashing;Cloud Storage","Visualization;Tensors;Smart cities;Memory management;Graphics processing units;Parallel processing;Lesions","artificial intelligence;cloud computing;cryptography;data handling;feature extraction;file organisation;image coding;learning (artificial intelligence);neural nets;storage management;vector quantisation","cloud storage utilization;hashing-based methods;visual difference;medical images;low-variance dataset;hash sequences;integer-based tensor;distance calculation;hashing algorithm;low-variance image deduplication;large-scale datasets;critical component;AI-powered applications;duplicated images;redundant images;excessive resource usage;deduplication time speedup;memory efficient;vector quantized variational autoencoder;VQ-VAE;QHash","","","","25","IEEE","30 May 2022","","","IEEE","IEEE Conferences"
"KaraSinger: Score-Free Singing Voice Synthesis with VQ-VAE Using Mel-Spectrograms","C. -F. Liao; J. -Y. Liu; Y. -H. Yang","Taiwan AI Labs, Taiwan; Taiwan AI Labs, Taiwan; Taiwan AI Labs, Taiwan","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","956","960","In this paper, we propose a novel neural network model called KaraSinger for a less-studied singing voice synthesis (SVS) task named score-free SVS, in which the prosody and melody are spontaneously decided by machine. KaraSinger comprises a vector-quantized variational autoencoder (VQ-VAE) that compresses the Mel-spectrograms of singing audio to sequences of discrete codes, and a language model (LM) that learns to predict the discrete codes given the corresponding lyrics. For the VQ-VAE part, we employ a Connectionist Temporal Classification (CTC) loss to encourage the discrete codes to carry phoneme-related information. For the LM part, we use location-sensitive attention for learning a robust alignment between the input phoneme sequence and the output discrete code. We keep the architecture of both the VQ-VAE and LM light-weight for fast training and inference speed. We validate the effectiveness of the proposed design choices using a proprietary collection of 550 English pop songs sung by multiple amateur singers. The result of a listening test shows that KaraSinger achieves high scores in intelligibility, musicality, and the overall quality.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9747441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747441","Singing voice synthesis;sequence-to-sequence;VQ-VAE;Transformer","Training;Codes;Neural networks;Training data;Predictive models;Rhythm;Recording","acoustic signal processing;audio signal processing;feature extraction;learning (artificial intelligence);music;neural nets;pattern classification;speech processing;speech recognition;speech synthesis;vector quantisation","Connectionist Temporal Classification loss;discrete codes;phoneme-related information;LM part;input phoneme sequence;output discrete code;LM light-weight;KaraSinger;high scores;Mel-spectrograms;novel neural network model;voice synthesis task named score-free SVS;prosody;melody;vector-quantized variational autoencoder;singing audio;language model;VQ-VAE part","","","","38","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Dispeech: A Synthetic Toy Dataset for Speech Disentangling","O. Zhang; N. Gengembre; O. L. Blouch; D. Lolive","CNRS, IRISA, Université de Rennes 1, Lannion, France; Orange Innovation, France; Orange Innovation, France; CNRS, IRISA, Université de Rennes 1, Lannion, France","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","8557","8561","Recently, a growing interest in unsupervised learning of disentangled representations has been observed, with successful applications to both synthetic and real data. In speech processing, such methods have been able to disentangle speakers’ attributes from verbal content. To have a better understanding of disentanglement, synthetic data is necessary, as it provides a controllable framework to train models and evaluate disentanglement. Thus, we introduce diSpeech, a corpus of speech synthesized with the Klatt synthesizer. Its first version is constrained to vowels synthesized with 5 generative factors relying on pitch and formants. Experiments show the ability of variational autoencoders to disentangle these generative factors and assess the reliability of disentanglement metrics. In addition to provide a support to benchmark speech disentanglement methods, diSpeech also enables the objective evaluation of disentanglement on real speech, which is to our knowledge unprecedented. To illustrate this methodology, we apply it to TIMIT’s isolated vowels.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9747011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747011","speech disentanglement;synthetic dataset;unsupervised learning","Measurement;Synthesizers;Conferences;Toy manufacturing industry;Signal processing;Benchmark testing;Data models","neural nets;speaker recognition;speech intelligibility;speech processing;speech synthesis;unsupervised learning","synthetic toy dataset;speech disentangling;unsupervised learning;disentangled representations;synthetic data;speech processing;Klatt synthesizer;generative factors;disentanglement metrics;benchmark speech disentanglement methods;Dispeech;speakers attributes;diSpeech;speech synthesized;variational autoencoders;TIMIT isolated vowels","","","","26","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Dynamic Curriculum Learning with Co-training for Medical Dialogue Generation","Q. Zhu; Z. Tan; J. Duan; P. Wu; D. Zhao; J. Liu","School of Software and Microelectronics, Peking University, Beijing, China; School of Software and Microelectronics, Peking University, Beijing, China; School of Software and Microelectronics, Peking University, Beijing, China; School of Software and Microelectronics, Peking University, Beijing, China; Wangxuan Institute of Computer Technology, Peking University, Beijing, China; School of Software and Microelectronics, Peking University, Beijing, China","2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","14 Jan 2022","2021","","","633","640","The purpose of medical dialogue generation is to provide automatic and accurate responses to help doctors provide diagnosis and treatment advice in an efficient w ay. However, due to the subjectivity and open-ended nature of human conversations, the complexity of training dataset varies greatly. Some methods try to solve this problem by using curriculum learning that organizes training data from easy to hard and optimizes the model with an “easy-to-difficult” scheme, but they ignore the intrinsic nature of conversation dataset that has different categories. To solve this problem, in this article, we learn a Dynamic Curriculum with Co-training (DCC) for generative dialogue systems considering both the quality and category of the data. Under our framework, we first t rain two models (query generation model and reply generation model) from dual view by leveraging end-to-end deep Gaussian Mixture Variational Autoencoders (GMVAE) architectures that combine generative and unsupervised clustering tasks together. Then we promote the clustering performance via an ensemble method by combining the clustering distribution of the two networks. Finally, we let the two models determine the training order for each other in each category according to their loss and category confidence dynamically through single-task and multitask curriculum learning. Evaluation results on the widely used medical dialogue generation dataset indicate that our proposed learning approach makes significant improvements compared to strong baselines. varies greatly.","","978-1-6654-0126-5","10.1109/BIBM52615.2021.9669462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669462","Medical dialogue generation;Curriculum learning;Co-training;GMVAE","Training;Rain;Conferences;Biological system modeling;Training data;Medical services;Data models","Gaussian processes;interactive systems;learning (artificial intelligence);pattern clustering;query processing","Dynamic Curriculum learning;medical dialogue generation;automatic responses;accurate responses;treatment advice;open-ended nature;training dataset varies;training data;easy-to-difficult scheme;conversation dataset;generative dialogue systems;query generation model;reply generation model;end-to-end deep Gaussian Mixture Variational Autoencoders architectures;training order;learning approach","","","","31","IEEE","14 Jan 2022","","","IEEE","IEEE Conferences"
"Adaptive Cycle-consistent Adversarial Network for Malaria Blood Cell Image Synthetization","Z. Liang; J. X. Huang","Dept. of Electrical Engineering & Computer Science, York University, Toronto, Canada; School of Information Technology, York University, Toronto, Canada","2021 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)","26 Apr 2022","2021","","","1","7","Malaria is a tropical infectious disease that causes massive global deaths. The convolution neural network (CNN) models can theoretically classify the malaria infected blood cells from normal cells, but they are vulnerable to network attacks even with simple uniform noise. A typical drawback of CNN is that the algorithm cannot properly capture the meaningful patterns with clinical significance. We propose a novel adaptive cycle-consistent adversarial network (Ad Cycle GAN) to synthesize malaria significant patterns based on a homogeneous image template with randomness. The Ad Cycle GAN model consists of a pretrained convolutional variational autoencoder (CVAE) and conventional cycle-consistent adversarial network (Cycle GAN). The CVAE model is trained by a large, segmented blood cell dataset with 27,578 images. The model is optimized for 120 epochs. The CVAE is pipelined to a conventional Cycle GAN model with two generator-discriminator combinations. The real malaria positive images are at first sent to the pretrained CVAE to generate template images for the adversarial optimization with the real images. Therefore, the optimization process is to use generator G to convert the CVAE generated images from the synthetic domain (X) to the real malaria positive image domain (Y), then use generator F to convert the real malaria positive images from the real positive image domain (Y) to the CVAE synthetic image domain (X). The total generator loss is composed of adversarial loss, cycle loss, and identity loss, all loss terms are computed by least squared loss. The Ad Cycle GAN architecture is optimized by 150 epochs. When using a pretrained classifier to differentiate the real and synthetic malaria positive image, 99.61% of the real images from the real image set are accurately recognized, compared to 86.6% of the synthetic images are accurately classified. The average score of Frechet Inception Distance (FID) of the generated images by the Ad Cycle GAN is 0.0053 (Std=0.0004). By human eye observation, the Ad Cycle GAN generated images have reasonable fidelity as real blood cells with meaningful pathological patterns that properly mimics real malaria infected blood cells. The proposed Ad Cycle model can generate synthetic malaria infected blood cell images to successfully optimize the deep neural network model for high classification accuracy. We conclude that the new Ad Cycle GAN model can generate high quality malaria infected blood cell images with good diversity.","2332-5615","978-1-6654-2471-4","10.1109/AIPR52630.2021.9762068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9762068","image augmentation;Ad Cycle GAN;image synthesis;deep neural network;malaria","Adaptation models;Adaptive systems;Neural networks;Cells (biology);Generative adversarial networks;Generators;Convolutional neural networks","blood;cellular biophysics;deep learning (artificial intelligence);diseases;image classification;image segmentation;medical image processing;object detection;optimisation","malaria positive image domain;CVAE synthetic image domain;Ad Cycle GAN architecture;real malaria positive image;synthetic malaria positive image;synthetic malaria infected blood cell images;deep neural network model;Ad Cycle GAN model;high quality malaria infected blood cell images;adaptive cycle-consistent adversarial network;malaria blood cell image synthetization;convolution neural network models;network attacks;malaria significant patterns;homogeneous image template;convolutional variational autoencoder;conventional cycle-consistent adversarial network;CVAE model;segmented blood cell;conventional Cycle GAN model;generator-discriminator combinations;template images;adversarial optimization;Frechet inception distance;FID;human eye observation;pathological patterns","","","","19","IEEE","26 Apr 2022","","","IEEE","IEEE Conferences"
"The Wanderings of Odysseus in 3D Scenes","Y. Zhang; S. Tang",ETH Zürich; ETH Zürich,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","20449","20459","Our goal is to populate digital environments, in which digital humans have diverse body shapes, move perpetu-ally, and have plausible body-scene contact. The core challenge is to generate realistic, controllable, and infinitely long motions for diverse 3D bodies. To this end, we propose generative motion primitives via body surface markers, or GAMMA in short. In our solution, we decompose the long-term motion into a time sequence of motion primitives. We exploit body surface markers and conditional variational autoencoder to model each motion primitive, and generate long-term motion by implementing the gen-erative model recursively. To control the motion to reach a goal, we apply a policy network to explore the genera-tive model's latent space and use a tree-based search to preserve the motion quality during testing. Experiments show that our method can produce more realistic and controllable motion than state-of-the-art data-driven methods. With conventional path-finding algorithms, the generated human bodies can realistically move long distances for a long period of time in the scene. Code is released for re-search purposes at: https://yz-cnsdqz.github.io/eigenmotion/GAMMA/","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01983","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879049","Face and gestures; Behavior analysis; Vision + graphics","Computer vision;Three-dimensional displays;Codes;Shape;Computational modeling;Biological system modeling;Aerospace electronics","iterative methods;mobile robots;motion control;path planning;trees (mathematics)","3D scenes;digital environments;digital humans;diverse body shapes;perpetu-ally;plausible body-scene contact;core challenge;realistic motions;controllable, motions;infinitely long motions;diverse 3D bodies;generative motion primitives;body surface markers;long-term motion;motion primitive;conditional variational autoencoder;gen-erative model;genera-tive model;motion quality;realistic motion;controllable motion;generated human bodies","","","","84","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"IB-DRR - Incremental Learning with Information-Back Discrete Representation Replay","J. Jiang; E. Cetin; O. Celiktutan","Department of Engineering, Centre for Robotics Research, King’s College, London, UK; Department of Engineering, Centre for Robotics Research, King’s College, London, UK; Department of Engineering, Centre for Robotics Research, King’s College, London, UK","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","1 Sep 2021","2021","","","3528","3537","Incremental learning aims to enable machine learning models to continuously acquire new knowledge given new classes, while maintaining the knowledge already learned for old classes. Saving a subset of training samples of previously seen classes in the memory and replaying them during new training phases is proven to be an efficient and effective way to fulfil this aim. It is evident that the larger number of exemplars the model inherits the better performance it can achieve. However, finding a trade-off between the model performance and the number of samples to save for each class is still an open problem for replay-based incremental learning and is increasingly desirable for real-life applications. In this paper, we approach this open problem by tapping into a two-step compression approach. The first step is a lossy compression, we propose to encode input images and save their discrete latent representations in the form of ‘codes’ that are learned using a hierarchical Vector Quantised Variational Autoencoder (VQ-VAE). In the second step, we further compress ‘codes’ losslessly by learning a hierarchical latent variable model with bits-back asymmetric numeral systems (BB-ANS). To compensate for the information lost in the first step compression, we introduce an Information Back (IB) mechanism that uti-lizes raw exemplars for a contrastive learning loss to regularise the training of a classifier. By maintaining all seen exemplars’ representations in the format of ‘codes’, Discrete Representation Replay (DRR) outperforms the state-of-art method on CIFAR-100 by a margin of 4% average accuracy with a much less memory cost required for saving samples. Incorporated with IB and saving a small set of old raw exemplars as well, the average accuracy of DRR can be further improved by 2%.","2160-7516","978-1-6654-4899-4","10.1109/CVPRW53098.2021.00392","China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9522858","","Training;Computer vision;Image coding;Conferences;Memory management;Machine learning;Pattern recognition","image classification;image coding;learning (artificial intelligence);neural nets;vector quantisation","IB-DRR;machine learning;replay-based incremental learning;two-step compression;lossy compression;discrete latent representations;contrastive learning loss;hierarchical vector quantised variational autoencoder;information-back discrete representation replay;VQ-VAE;hierarchical latent variable;bits-back asymmetric numeral systems;BB-ANS;classifier;DRR;memory cost","","","","46","","1 Sep 2021","","","IEEE","IEEE Conferences"
"Multimodal VAE Active Inference Controller","C. Meo; P. Lanillos","Department of Cognitive Robotics, Faculty of Mechanical Engineering, Delft University of Technology, Delft, The Netherlands; Department of Artificial Intelligence, Donders Institute for Brain, Cognition and Behavior, Radboud University, Nijmegen, The Netherlands","2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","16 Dec 2021","2021","","","2693","2699","Active inference, a theoretical construct inspired by brain processing, is a promising alternative to control artificial agents. However, current methods do not yet scale to high-dimensional inputs in continuous control. Here we present a novel active inference torque controller for industrial arms that maintains the adaptive characteristics of previous proprioceptive approaches but also enables large-scale multimodal integration (e.g., raw images). We extended our previous mathematical formulation by including multimodal state representation learning using a linearly coupled multimodal variational autoencoder. We evaluated our model on a simulated 7DOF Franka Emika Panda robot arm and compared its behavior with a previous active inference baseline and the Panda built-in optimized controller. Results showed improved tracking and control in goal-directed reaching due to the increased representation power, high robustness to noise and adaptability in changes on the environmental conditions and robot parameters without the need to relearn the generative models nor parameters retuning.","2153-0866","978-1-6654-1714-3","10.1109/IROS51168.2021.9636394","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9636394","Active inference;Bio-inspired perception and action;Learning and adaptive systems;Free energy principle","Representation learning;Adaptation models;Visualization;Torque;Heuristic algorithms;Predictive models;Robot sensing systems","artificial intelligence;brain;learning (artificial intelligence);multi-agent systems;neurophysiology;optimal control;torque control","linearly coupled multimodal variational autoencoder;simulated 7DOF Franka Emika Panda robot arm;previous active inference baseline;optimized controller;tracking;multimodal VAE active inference controller;brain processing;artificial agents;high-dimensional inputs;continuous control;active inference torque controller;industrial arms;adaptive characteristics;previous proprioceptive approaches;large-scale multimodal integration;previous mathematical formulation;multimodal state representation","","","","23","IEEE","16 Dec 2021","","","IEEE","IEEE Conferences"
"Adaptive attention encoder for attribute graph embedding","Z. Weng; W. Zhang; Z. Xia","Qilu University of Technology, Jinan, China; Qilu University of Technology, Jinan, China; Qilu University of Technology, Jinan, China","2021 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)","22 Dec 2021","2021","","","1353","1359","In recent years, unsupervised graph representation learning based on graph encoders has made significant progress. However, the existing methods have three shortcomings. First, the existing method based on graph convolutional network (GCN) cannot distinguish between different neighbor nodes. Second, these methods ignore the actual distribution of graph data. Finally, most existing embedding algorithms focus on restoring the feature matrix or adjacency matrix, which is not necessarily the best choice. Considering the above problems, an adaptive attention adversarial variational graph autoencoder (AAAVGE) is proposed. Its core ideas are (1) Use graph attention to distinguish the weights of different neighbor nodes. (2) Use the adversary strategy to guide the embedding vector to obey the true distribution of data. (3) Use an adaptive learning strategy to train the encoder. Link prediction experiments on four public benchmark data sets show that our proposed AAAVGE can significantly improve the performance of graph embedding compared with the mainstream graph embedding methods.","","978-1-6654-3574-1","10.1109/ISPA-BDCloud-SocialCom-SustainCom52081.2021.00185","Research and Development; National Natural Science Foundation of China; Natural Science Foundation of Shandong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9644720","Adaptive;attention;adversary","Representation learning;Training;Adaptive learning;Adaptation models;Computational modeling;Benchmark testing;Computational efficiency","graph theory;image representation;learning (artificial intelligence);network theory (graphs)","different neighbor nodes;actual distribution;graph data;existing embedding algorithms focus;feature matrix;adaptive attention adversarial variational graph autoencoder;AAAVGE;adversary strategy;embedding vector;adaptive learning strategy;public benchmark data sets;mainstream graph embedding methods;adaptive attention encoder;attribute graph;unsupervised graph representation;graph encoders;graph convolutional network","","","","27","IEEE","22 Dec 2021","","","IEEE","IEEE Conferences"
"Probability distribution guided optic disc and cup segmentation from fundus images","P. Cheng; J. Lyu; Y. Huang; X. Tang","Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China","2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","27 Aug 2020","2020","","","1976","1979","In this paper, we proposed and validated a probability distribution guided network for segmenting optic disc (OD) and optic cup (OC) from fundus images. Uncertainty is inevitable in deep learning, as induced by different sensors, insufficient samples, and inaccurate labeling. Since the input data and the corresponding ground truth label may be inaccurate, they may actually follow some potential distribution. In this study, a variational autoencoder (VAE) based network was proposed to estimate the joint distribution of the input image and the corresponding segmentation (both the ground truth segmentation and the predicted segmentation), making the segmentation network learn not only pixel-wise information but also semantic probability distribution. Moreover, we designed a building block, namely the Dilated Inception Block (DIB), for a better generalization of the model and a more effective extraction of multi-scale features. The proposed method was compared to several existing state-of-the-art methods. Superior segmentation performance has been observed over two datasets (ORIGA and REFUGE), with the mean Dice overlap coefficients being 96.57% and 95.81% for OD and 88.46% and 88.91% for OC.","2694-0604","978-1-7281-1990-8","10.1109/EMBC44109.2020.9176394","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9176394","","Image segmentation;Uncertainty;Semantics;Image reconstruction;Task analysis;Training;Biomedical optical imaging","eye;feature extraction;image segmentation;learning (artificial intelligence);medical image processing;statistical distributions","optic cup segmentation;fundus images;probability distribution guided network;deep learning;insufficient samples;inaccurate labeling;ground truth label;potential distribution;variational autoencoder based network;joint distribution;input image;ground truth segmentation;segmentation network;pixel-wise information;semantic probability distribution;probability distribution guided optic disc segmentation;dilated inception block;multiscale feature extraction;mean Dice overlap coefficients","Animals;Fundus Oculi;Gastric Fundus;Glaucoma;Optic Disk;Probability","","","14","","27 Aug 2020","","","IEEE","IEEE Conferences"
"Using Deep Gaussian Models for Images Matching Vitalii Dementiev","V. Dementiev; A. Tashlinskii","Telecommunication Department, Ulyanovsk State Technical University, Ulyanovsk, Russia; Radio Engineering Department, Ulyanovsk State Technical University, Ulyanovsk, Russia","2021 International Conference on Information Technology and Nanotechnology (ITNT)","24 Dec 2021","2021","","","1","4","In this paper, the possibilities of improving the accuracy of image matching based on the use of deep Gaussian models are considered. The possibilities of identifying the parameters of such models based on the modification of the variational autoencoder are considered. It is shown that the results of such identification can be used to improve the accuracy of matching of image pairs. The quantitative characteristics of the accuracy improvement are given.","","978-1-6654-3217-7","10.1109/ITNT52450.2021.9649244","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9649244","Deep Gaussian models;parameter identification;neural networks;pseudo-gradient algorithms;image alignment","Training;Image matching;Computational modeling;Image processing;Neural networks;Data mining;Information technology","Gaussian processes;image matching;neural nets","deep Gaussian models;images matching;image pairs;variational autoencoder","","","","11","IEEE","24 Dec 2021","","","IEEE","IEEE Conferences"
"Global Context with Discrete Diffusion in Vector Quantised Modelling for Image Generation","M. Hu; Y. Wang; T. -J. Cham; J. Yang; P. N. Suganthan",Nanyang Technological University; Sensetime Research; Nanyang Technological University; Nanyang Technological University; Nanyang Technological University,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","11492","11501","The integration of Vector Quantised Variational AutoEncoder (VQ-VAE) with autoregressive models as generation part has yielded high-quality results on image generation. However, the autoregressive models will strictly follow the progressive scanning order during the sampling phase. This leads the existing VQ series models to hardly escape the trap of lacking global information. Denoising Diffusion Probabilistic Models (DDPM) in the continuous domain have shown a capability to capture the global context, while generating high-quality images. In the discrete state space, some works have demonstrated the potential to perform text generation and low resolution image generation. We show that with the help of a content-rich discrete visual codebook from VQ-VAE, the discrete diffusion model can also generate high fidelity images with global context, which compensates for the deficiency of the classical autoregressive model along pixel space. Meanwhile, the integration of the discrete VAE with the diffusion model resolves the drawback of conventional autoregressive models being oversized, and the diffusion model which demands excessive time in the sampling process when generating images. It is found that the quality of the generated images is heavily dependent on the discrete visual codebook. Extensive experiments demonstrate that the proposed Vector Quantised Discrete Diffusion Model (VQ-DDM) is able to achieve comparable performance to top-tier methods with low complexity. It also demonstrates outstanding advantages over other vectors quantised with autoregressive models in terms of image inpainting tasks without additional training.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879884","Image and video synthesis and generation","Training;Visualization;Image resolution;Image synthesis;Pipelines;Noise reduction;Probabilistic logic","autoregressive processes;feature extraction;filtering theory;image coding;image denoising;image resolution;image restoration;learning (artificial intelligence);vector quantisation","Vector Quantised modelling;Vector Quantised Variational AutoEncoder;VQ-VAE;generation part;high-quality results;existing VQ series models;global information;Diffusion Probabilistic Models;high-quality images;discrete state space;text generation;low resolution image generation;content-rich discrete visual codebook;high fidelity images;classical autoregressive model;discrete VAE;conventional autoregressive models;generating images;Vector Quantised Discrete Diffusion Model;image inpainting tasks","","","","41","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"SetVAE: Learning Hierarchical Composition for Generative Modeling of Set-Structured Data","J. Kim; J. Yoo; J. Lee; S. Hong",KAIST; KAIST; KAIST; KAIST,"2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","2 Nov 2021","2021","","","15054","15063","Generative modeling of set-structured data, such as point clouds, requires reasoning over local and global structures at various scales. However, adopting multi-scale frameworks for ordinary sequential data to a set-structured data is nontrivial as it should be invariant to the permutation of its elements. In this paper, we propose SetVAE, a hierarchical variational autoencoder for sets. Motivated by recent progress in set encoding, we build SetVAE upon attentive modules that first partition the set and project the partition back to the original cardinality. Exploiting this module, our hierarchical VAE learns latent variables at multiple scales, capturing coarse-to-fine dependency of the set elements while achieving permutation invariance. We evaluate our model on point cloud generation task and achieve competitive performance to the prior arts with substantially smaller model capacity. We qualitatively demonstrate that our model generalizes to unseen set sizes and learns interesting subset relations without supervision. Our implementation is available at https://github.com/jw9730/setvae.","2575-7075","978-1-6654-4509-2","10.1109/CVPR46437.2021.01481","Samsung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9577267","","Computer vision;Art;Data models;Cognition;Encoding;Pattern recognition;Task analysis","learning (artificial intelligence);neural nets;set theory","generative modeling;set-structured data;local structures;global structures;adopting multiscale frameworks;SetVAE;set encoding;set elements;point cloud generation task;unseen set sizes;hierarchical variational autoencoder;VAE","","","","34","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Intrinsic Robotic Introspection: Learning Internal States From Neuron Activations","N. Pitsillos; A. Pore; B. S. Jensen; G. Aragon-Camarasa","School of Computing Science, University of Glasgow, UK; Department of Computer Science, University of Verona, Italy; School of Computing Science, University of Glasgow, UK; School of Computing Science, University of Glasgow, UK","2021 IEEE International Conference on Development and Learning (ICDL)","20 Aug 2021","2021","","","1","7","We present an introspective framework inspired by the process of how humans perform introspection. Our working assumption is that neural network activations encode information, and building internal states from these activations can improve the performance of an actor-critic model. We perform experiments where we first train a Variational Autoencoder model to reconstruct the activations of a feature extraction network and use the latent space to improve the performance of an actor-critic when deciding which low-level robotic behaviour to execute. We show that internal states reduce the number of episodes needed by about 1300 episodes while training an actor-critic, denoting faster convergence to get a high success value while completing a robotic task.","","978-1-7281-6242-3","10.1109/ICDL49984.2021.9515672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9515672","","Training;Conferences;Neurons;Learning (artificial intelligence);Feature extraction;Task analysis;Robots","feature extraction;inspection;intelligent robots;neural nets","neural network activations;actor-critic model;variational autoencoder model;feature extraction network;latent space;low-level robotic behaviour;robotic task;intrinsic robotic introspection;learning internal states;neuron activations;introspective framework;working assumption","","","","20","","20 Aug 2021","","","IEEE","IEEE Conferences"
"A Sky Image-Based Hybrid Deep Learning Model for Nonparametric Probabilistic Forecasting of Solar Irradiance","M. Xiang; W. Cui; C. Wan; C. Zhao","College of Electrical Engineering, Zhejiang University, Hangzhou, China; College of Electrical Engineering, Zhejiang University, Hangzhou, China; College of Electrical Engineering, Zhejiang University, Hangzhou, China; College of Electrical Engineering, Zhejiang University, Hangzhou, China","2021 International Conference on Power System Technology (POWERCON)","8 Feb 2022","2021","","","946","952","Accurate solar irradiance and photovoltaic power forecasting is critical to ensure the secure and economic operation of power systems with rapidly increasing photovoltaic generation. This paper proposes a sky image-based hybrid deep learning model for nonparametric probabilistic forecasting of solar irradiance. The proposed method utilizes variational autoencoder (VAE) to compress sky images autonomously. Long short-term memory (LSTM) is applied to extract temporal information embedded in images and time series. Quantile regression is adopted to estimate the conditional quantiles. Comprehensive case studies are conducted based on actual dataset, which shows the superiority of the proposed method and the potential for practical applications.","2642-6226","978-1-6654-0737-3","10.1109/POWERCON53785.2021.9697876","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9697876","Probabilistic forecasting;deep learning;sky image;quantile regression","Deep learning;Photovoltaic systems;Image coding;Time series analysis;Predictive models;Probabilistic logic;Feature extraction","data compression;deep learning (artificial intelligence);image coding;photovoltaic power systems;power engineering computing;recurrent neural nets;regression analysis;time series","sky image-based hybrid deep learning model;nonparametric probabilistic forecasting;solar irradiance;photovoltaic power forecasting;sky images;long short-term memory;variational autoencoder;VAE;LSTM;quantile regression;conditional quantiles","","","","31","IEEE","8 Feb 2022","","","IEEE","IEEE Conferences"
"Separation of the Latent Representations into ""Identity"" and ""Expression"" without Emotional Labels","Y. Kanou; T. Nagao","Graduate School of Environment and Information Sciences, Yokohama National University, Yokohama, Japan; Graduate School of Environment and Information Sciences, Yokohama National University, Yokohama, Japan","2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","14 Dec 2020","2020","","","1638","1644","Learning semantically disentangled representations is important for various computer vision tasks, such as image generation and classification. Although it is possible to learn an effective representation in supervised settings, there are problems requiring enormous effort focused in data collection and labeling, and the difficulty in labeling continuously changing events like facial expressions is significant. In this paper, we propose a method for separating the latent representation of facial images into identity factors and facial expression factors using the variational autoencoder (VAE) framework. In our method, we only use subject labels to control training, and we do not use information attached to facial expressions like emotional labels. The separation between extracted facial expression factors and identity features is very useful for controlling image generation and for classifying facial expressions. Using this latent representation, we also suggest a new approach for facial expression recognition with a simple clustering method, which is based on Euclidean distance. Our classification method dramatically reduces the cost of labeling. The experimental results show that our method successfully disentangles the representation of facial images and separates the latent representation into identity and facial expression factors. Moreover, in a facial expression recognition task, our approach shows advantages over the baseline method without supervision.","2577-1655","978-1-7281-8526-2","10.1109/SMC42975.2020.9283482","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283482","disentangled representation;facial expression","Training;Image synthesis;Face recognition;Euclidean distance;Feature extraction;Labeling;Task analysis","computer vision;emotion recognition;face recognition;feature extraction;image classification;learning (artificial intelligence);neural nets","facial images;latent representation;facial expression recognition task;emotional labels;semantically disentangled representations;computer vision tasks;image generation;facial expressions;subject labels;extracted facial expression factors;simple clustering method;classification method;Euclidean distance;variational autoencoder;VAE framework","","","","29","","14 Dec 2020","","","IEEE","IEEE Conferences"
"Novelty Detection and Analysis with a Βeta-DVAE Network","T. Graydon; F. Sahin","Department of Electrical and Microelectronic Engineering, Rochester Institute of Technology, Rochester, NY; Department of Electrical and Microelectronic Engineering, Rochester Institute of Technology, Rochester, NY","2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","17 Jan 2019","2018","","","2687","2691","In this paper we apply generative modeling to Gaussian Mixture Models (GMM) as a solution to high dimensional novel event detection and analysis on radio frequency (RF) power generators. A family of Denoising and β-Disentangling Variational Autoencoders (β-DVAE) is used to encode datasets into lower and more salient dimensions. The reduced feature sets are modeled using GMMs where model parameters are learned using the Expectation Maximization (EM) algorithm. The data is obtained from two different generator models operating under normal as well as known not-normal conditions. This approach is also tested on standard classification sets. Robust testing is reported to achieve a target class accuracy of 98.16% for the target RF generator. Additionally, the GMM parameters are decoded by the generative model to the original data space for calculating per-variable fitness in order to provide an initial novel event analysis for engineers and technicians. This per-variable fitness is very critical for determining each variable's contribution to a novelty so that engineers can perform informed trouble shooting and maintenance of the RF generators.","2577-1655","978-1-5386-6650-0","10.1109/SMC.2018.00459","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8616455","","Generators;Data models;Standards;Training;Analytical models;Radio frequency;Noise reduction","electric generators;expectation-maximisation algorithm;Gaussian processes;learning (artificial intelligence);mixture models;pattern classification;power engineering computing","EM algorithm;disentangling variational autoencoders;event detection;DVAE network;event analysis;expectation maximization algorithm;Gaussian mixture models;generative model;GMM parameters;target RF generator;radio frequency power generators","","","","21","","17 Jan 2019","","","IEEE","IEEE Conferences"
"Deep learning for the next generation (highly sensitive and reliable) ECLSS fire monitoring and detection system","Z. Xu; Y. Guo; J. H. Saleh","School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA; School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA; School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA","2021 IEEE Aerospace Conference (50100)","7 Jun 2021","2021","","","1","11","Fire detection is a critical component of the Environmental Control and Life Support System (ECLSS) on board space habitats and remains an important research area with considerable practical relevance. Significant advances have occurred over the years in ECLSS design and automation, and its operation has become more complex and requires ever more effective environmental monitoring systems in the space habitat. In this work, we develop a novel fire detection method using deep Long-Short Term Memory (LSTM) neural networks and variational autoencoder (VAE) to meet the increasingly stringent requirements of fire detection for future space habitats in terms of sensitivity and reliability. To examine the performance of our method, termed Deep Learning for Environmental Monitoring (DeLEM), and specialized for Fire Detection in this work (DeLEM-FD), we develop a series of computational experiments using a high-fidelity fire simulator. We evaluate and compare the performance results of our proposed fire detection with alternative methods, including the standard LSTM, cumulative sum control chart (CUSUM), exponentially weighted moving average (EWMA), and two currently used fixed-temperature heat detectors. The simulation-based results indicate that the DeLEM-FD robustly outperforms the other detection methods with statistically significant shorter alarm time lags, no missed detection, and no false alarms. In future work, we propose to examine the performance of our detection method on real-fire experiments conducted by the National Institute of Standards and Technology.","1095-323X","978-1-7281-7436-5","10.1109/AERO50100.2021.9438141","NASA's Space Technology Research Grants Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9438141","","Heating systems;Sensitivity;Space technology;Buildings;Neural networks;Detectors;NIST","aerospace computing;control charts;deep learning (artificial intelligence);moving average processes;recurrent neural nets;statistical process control","ECLSS fire monitoring and detection system;environmental control and life support system;VAE;variational autoencoder;LSTM neural networks;DeLEM;deep learning for environmental monitoring;high-fidelity fire simulator;deep long-short term memory;fire detection method;space habitat;environmental monitoring systems","","","","25","","7 Jun 2021","","","IEEE","IEEE Conferences"
"Hierarchical Planning Through Goal-Conditioned Offline Reinforcement Learning","J. Li; C. Tang; M. Tomizuka; W. Zhan","Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA","IEEE Robotics and Automation Letters","1 Aug 2022","2022","7","4","10216","10223","Offline Reinforcement learning (RL) has shown potent in many safe-critical tasks in robotics where exploration is risky and expensive. However, it still struggles to acquire skills in temporally extended tasks. In this paper, we study the problem of offline RL for temporally extended tasks. We propose a hierarchical planning framework, consisting of a low-level goal-conditioned RL policy and a high-level goal planner. The low-level policy is trained via offline RL. We improve the offline training to deal with out-of-distribution goals by a perturbed goal sampling process. The high-level planner selects intermediate sub-goals by taking advantages of model-based planning methods. It plans over future sub-goal sequences based on the learned value function of the low-level policy. We adopt a Conditional Variational Autoencoder to sample meaningful high-dimensional sub-goal candidates and to solve the high-level long-term strategy optimization problem. We evaluate our proposed method in long-horizon driving and robot navigation tasks. Experiments show that our method outperforms baselines with different hierarchical designs and other regular planners without hierarchy in these complex tasks.","2377-3766","","10.1109/LRA.2022.3190100","Denso International America, Inc.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9826807","Integrated planning and learning;reinforcement learning;autonomous agents","Task analysis;Time division multiplexing;Planning;Optimization;Reinforcement learning;Training;Robots","control engineering computing;learning (artificial intelligence);mobile robots;path planning;planning (artificial intelligence)","temporally extended tasks;hierarchical planning framework;low-level goal-conditioned RL policy;high-level goal planner;low-level policy;offline RL;offline training;out-of-distribution goals;perturbed goal sampling process;high-level planner;intermediate sub-goals;future sub-goal sequences;learned value function;Conditional Variational Autoencoder;sample meaningful high-dimensional sub-goal candidates;high-level long-term strategy optimization problem;long-horizon driving;robot navigation tasks;different hierarchical designs;goal-conditioned offline Reinforcement learning;safe-critical tasks","","","","35","IEEE","12 Jul 2022","","","IEEE","IEEE Journals"
"Face Attribute Transformation Based On ConStarGAN","Q. Zhang; J. Du; J. Yu","Computer Science Department, Shantou University, Shantou, China; Computer Science Department, Shantou University, Shantou, China; Computer Science Department, Shantou University, Shantou, China","2019 6th International Conference on Systems and Informatics (ICSAI)","27 Feb 2020","2019","","","1383","1390","Many models are able to transform styles by input images, such as Variational autoencoder (VAEs) and Generative adversarial networks (GANs), which have recently been applied to image style and domain transfer. In this paper, we propose a method based on unified generative adversarial networks for multi-domain image-to-image translation (StarGAN) to solve face attribute transfer problem-ConStarGAN. Given a face image, our model can extract the region of interest and transform multiple attributes in this region while keeping other features unchanged. So as to minimize the impact factor on the generated image and make it look very realistic. In our model, we present new loss function. Then, the image is segmented to avoid the influence of background, illumination and other factors, and spectral normalization is used to improve the quality of generated images. Experimental compared with the stability of relevant GAN models. Results show that we proposed model has achieved good results in face attribute translation. Finally, the effect of the improved model is illustrated through the effect analysis experiment.","","978-1-7281-5256-1","10.1109/ICSAI48974.2019.9010448","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010448","Image Generation;ConStarGAN;multi-domain image-to-image translation","Generative adversarial networks;Generators;Face;Gallium nitride;Training;Transforms;Task analysis","face recognition;feature extraction;image colour analysis;image segmentation;neural nets","Variational autoencoder;unified generative adversarial networks;multidomain image-to-image translation;face image;relevant GAN models;face attribute translation;face attribute transfer problem;ConStarGAN;multiple attribute transform;image segmentation;spectral normalization;region of interest;impact factor","","","","30","","27 Feb 2020","","","IEEE","IEEE Conferences"
"Self-Supervised VQ-VAE for One-Shot Music Style Transfer","O. Cífka; A. Ozerov; U. Şimşekli; G. Richard","Inter Digital R & D, Cesson-Sévigné, France; Inter Digital R & D, Cesson-Sévigné, France; LTCI, Télécom Paris, Institut Polytechnique de Paris, France; LTCI, Télécom Paris, Institut Polytechnique de Paris, France","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","96","100","Neural style transfer, allowing to apply the artistic style of one image to another, has become one of the most widely showcased computer vision applications shortly after its introduction. In contrast, related tasks in the music audio domain remained, until recently, largely untackled. While several style conversion methods tailored to musical signals have been proposed, most lack the ‘one-shot’ capability of classical image style transfer algorithms. On the other hand, the results of existing one-shot audio style transfer methods on musical inputs are not as compelling. In this work, we are specifically interested in the problem of one-shot timbre transfer. We present a novel method for this task, based on an extension of the vector-quantized variational autoencoder (VQ-VAE), along with a simple self-supervised learning strategy designed to obtain disentangled representations of timbre and pitch. We evaluate the method using a set of objective metrics and show that it is able to outperform selected baselines.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414235","Style transfer;music;timbre;self-supervised learning;deep learning","Measurement;Computer vision;Instruments;Conferences;Signal processing algorithms;Signal processing;Decoding","computer vision;learning (artificial intelligence);music;neural nets;vector quantisation","self-supervised VQ-VAE;one-shot music style transfer;neural style transfer;artistic style;computer vision applications;music audio domain;style conversion methods;musical signals;one-shot audio style;musical inputs;one-shot timbre transfer;self-supervised learning strategy;classical image style transfer algorithms;vector-quantized variational autoencoder;disentangled representations;objective metrics","","","","39","","13 May 2021","","","IEEE","IEEE Conferences"
"Disentangled Representation of Data Distributions in Scatterplots","J. Jo; J. Seo","Department of Computer Science and Engineering, Seoul National University; Department of Computer Science and Engineering, Seoul National University","2019 IEEE Visualization Conference (VIS)","19 Dec 2019","2019","","","136","140","We present a data-driven approach to obtain a disentangled and interpretable representation that can characterize bivariate data distributions of scatterplots. We first collect tabular datasets from the Web and build a training corpus consisting of over one million scatterplot images. Then, we train a state-of-the-art disentangling model, β-variational autoencoder, to derive a disentangled representation of the scatterplot images. The main output of this work is a list of 32 representative features that can capture the underlying structures of bivariate data distributions. Through latent traversals, we seek for high-level semantics of the features and compare them to previous human-derived concepts such as scagnostics measures. Finally, using the 32 features as an input, we build a simple neural network to predict the perceptual distances between scatterplots that were previously scored by human annotators. We found Pearson's correlation coefficient between the predicted and perceptual distances was above 0.75, which indicates the effectiveness of our representation in the quantitative characterization of scatterplots.","","978-1-7281-4941-7","10.1109/VISUAL.2019.8933670","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933670","Human-centered computing;Visualization;Visualization theory;concepts and paradigms","Training;Neural networks;Visualization;Data visualization;Correlation;Machine learning;Generative adversarial networks","data visualisation;feature extraction;image representation;learning (artificial intelligence);neural nets","bivariate data distributions;scatterplots;tabular datasets;β-variational autoencoder;disentangled representation;disentangling model;data distribution representation;scatterplot image representation;neural network;Pearson correlation coefficient;visualization technique","","","","29","","19 Dec 2019","","","IEEE","IEEE Conferences"
"UP-GNN: Ensemble Graph Neural Network for Link Prediction via Uncertainty Learning and Positional Capturing","L. Wang; Y. Wang; J. Li; B. Wang; Z. Yu","National University of Defense and Technology College of Systems Engineering, Changsha, China; National University of Defense and Technology College of Systems Engineering, Changsha, China; National University of Defense and Technology College of Systems Engineering, Changsha, China; National University of Defense and Technology College of Systems Engineering, Changsha, China; National University of Defense and Technology College of Systems Engineering, Changsha, China","2021 7th International Conference on Big Data and Information Analytics (BigDIA)","6 Dec 2021","2021","","","399","405","Link prediction is a basic task of network data mining, and has been greatly studied. Recently, graph neural networks (GNNs) has been proposed, and have achieved good prediction effects in many tasks. However, the existing graph neural network models have the following challenges in link prediction tasks: 1) They cannot capture the position of nodes in the broader context of the graph structure; 2) When learning the node's low-dimensional representation vector, the learned representation vector is difficult to approximate the real representation; 3) Although there are different solutions for different problems, there is no framework that can integrate the effects of different methods. Therefore, we propose an ensemble learning framework named UP-GNN. Specifically, this framework consists of three modules. The position-aware module captures position information by dividing the anchor-sets, the variational autoencoder module learns the Gaussian distribution of the node to capture uncertainty, and the attention mechanism module uses the attention mechanism to capture the attribute information of nodes. Each module learns the low-dimensional representation vector of each node, and then uses it for downstream tasks. Finally, according to the output of the three modules, using the voting method, get the final predicted labels. We evaluate our model and baselines on two real data sets, and the results show that our proposed model is better than the benchmark algorithms.","","978-1-6654-2466-0","10.1109/BigDIA53151.2021.9619741","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9619741","graph neural networks;link prediction;ensemble learning;uncertainty;position information","Uncertainty;Gaussian distribution;Predictive models;Big Data;Prediction algorithms;Graph neural networks;Data models","data mining;Gaussian distribution;graph theory;learning (artificial intelligence);neural nets","variational autoencoder module;attention mechanism module;low-dimensional representation vector;downstream tasks;final predicted labels;data sets;UP-GNN;ensemble graph neural network;uncertainty learning;positional capturing;basic task;network data mining;neural networks;good prediction effects;existing graph neural network models;link prediction tasks;broader context;graph structure;learned representation vector;approximate the real representation;ensemble learning framework;position-aware module captures position information","","","","27","IEEE","6 Dec 2021","","","IEEE","IEEE Conferences"
"Short-Term Visual-IMU Fusion Memory Agent For Drone's Motion Planning","Z. Xue; T. Gonsalves","Dept. of Information & Communication Sciences, Faculty of Science & Technology, Sophia University, Tokyo, Japan; Dept. of Information & Communication Sciences, Faculty of Science & Technology, Sophia University, Tokyo, Japan","2022 10th International Conference on Information and Education Technology (ICIET)","26 May 2022","2022","","","378","383","This paper provides a deep reinforcement learning motion planning algorithm that uses time series image information as input. In this paper, we use a special visual state structure. This structure is composed of two kinds of sensor data. We combine the monocular visual information compressed by the variational autoencoder (VAE) and the inertial measurement unit (IMU) data. Then we use four consecutive combinations of the sensor data as the state of the reinforcement learning model. This method greatly simplifies the neural network complexity of continuous action space deep reinforcement learning on visual control tasks. After training in a drone simulation environment, this method has been proven to enable the drone to learn to avoid obstacles of various shapes and obstacles on the side blind corner of the camera.","","978-1-6654-8048-2","10.1109/ICIET55102.2022.9778991","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9778991","deep reinforcement learning;Drone;automatic control;VAE;sensor fusion","Training;Visualization;Reinforcement learning;Robustness;Data models;Planning;Complexity theory","deep learning (artificial intelligence);image fusion;path planning;reinforcement learning;robot vision;time series","drone simulation environment;deep reinforcement learning motion planning algorithm;time series image information;special visual state structure;sensor data;monocular visual information;variational autoencoder;inertial measurement unit data;reinforcement learning model;neural network complexity;continuous action space deep reinforcement learning;visual control tasks;short-term visual-IMU fusion memory agent","","","","15","IEEE","26 May 2022","","","IEEE","IEEE Conferences"
"Unsupervised Feature Learning for Output Control of Generative Models","K. Toda; K. Atarashi; S. Oyama; M. Kurihara","Graduate School of Information Science and Technology, Hokkaido University, Sapporo, Hokkaido, Japan; Graduate School of Information Science and Technology, Hokkaido University, Sapporo, Hokkaido, Japan; Faculty of Information Science and Technology, Hokkaido University, Sapporo, Hokkaido, Japan; Faculty of Information Science and Technology, Hokkaido University, Sapporo, Hokkaido, Japan","2020 Joint 11th International Conference on Soft Computing and Intelligent Systems and 21st International Symposium on Advanced Intelligent Systems (SCIS-ISIS)","21 Jan 2021","2020","","","1","6","Deep generative models are being actively studied, particularly variational autoencoders (VAEs) because they can generate high-quality images. The M2 model supports semi-supervised learning from both labeled and unlabeled data, which enables the generated images to be easily controlled by changing the class label values. However, generative models must be learned from only unlabeled data when class labels are not available. A model is presented that incorporates a deep clustering method into the M2 model, which enables clusters to be identified among unlabeled data so that each data point can be assigned to one of the clusters. The generated images in unlabeled datasets can easily be controlled by changing the cluster assignment of each data point.","","978-1-7281-9732-6","10.1109/SCISISIS50064.2020.9322714","JSPS KAKENHI(grant numbers:JP18H03337); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9322714","unsupervised learning;deep learning;generative model;output control","Data models;Linear programming;Training;Unsupervised learning;Perturbation methods;Semisupervised learning;Entropy","deep learning (artificial intelligence);image processing;pattern clustering;unsupervised learning","unsupervised feature learning;deep generative models;variational autoencoders;high-quality images;semisupervised learning;class label values;deep clustering method;data point;unlabeled datasets;M2 model","","","","16","","21 Jan 2021","","","IEEE","IEEE Conferences"
"A Portable Ultrasound Imaging System Utilizing Deep Generative Learning-Based Compressive Sensing On Pre-Beamformed RF Signals","S. K. Gupta; K. Kumar; C. S. Seelamantula; C. Singh Thakur","Department of Electronic Systems Engineering, Indian Institute of Science, Bangalore, India; Department of Electronic Systems Engineering, Indian Institute of Science, Bangalore, India; Department of Electrical Engineering, Indian Institute of Science, Bangalore, India; Department of Electronic Systems Engineering, Indian Institute of Science, Bangalore, India","2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","7 Oct 2019","2019","","","2740","2743","Recent advances in the unsupervised and generative models of deep learning have shown promise for application in biomedical signal processing. In this work, we present a portable resource-constrained ultrasound (US) system trained using Variational Autoencoder (VAE) network which performs compressive-sensing on pre-beamformed RF signals. The encoder network compresses the RF data, which is further transmitted to the cloud. At the cloud, the decoder reconstructs back the ultrasound image, which can be used for inferencing. The compression is done with an undersampling ratio of 1/2, 1/3, 1/5 and 1/10 without significant loss of the resolution. We also compared the model by state-of-the-art compressive-sensing reconstruction algorithm and it shows significant improvement in terms of PSNR and MSE. The innovation in this approach resides in training with binary weights at the encoder, shows its feasibility for the hardware implementation at the edge. In the future, we plan to include our field-programmable gate array (FPGA) based design directly interfaced with sensors for real-time analysis of Ultrasound images during medical procedures.","1558-4615","978-1-5386-1311-5","10.1109/EMBC.2019.8857437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8857437","","Image reconstruction;Image coding;Ultrasonic imaging;Mathematical model;Computer architecture;Imaging;Compressed sensing","biomedical ultrasonics;compressed sensing;image reconstruction;image resolution;medical image processing;unsupervised learning","portable ultrasound imaging system;pre-beamformed RF signals;unsupervised models;generative models;deep learning;biomedical signal processing;variational autoencoder network;encoder network;RF data;ultrasound image reconstruction;compressive-sensing reconstruction algorithm;deep generative learning-based compressive sensing;portable resource-constrained ultrasound system;undersampling ratio;binary weights","Algorithms;Data Compression;Deep Learning;Signal Processing, Computer-Assisted;Ultrasonography","","","12","","7 Oct 2019","","","IEEE","IEEE Conferences"
"Validation Methods for Energy Time Series Scenarios From Deep Generative Models","E. Cramer; L. R. Gorjão; A. Mitsos; B. Schäfer; D. Witthaut; M. Dahmen","RWTH Aachen University, Aachen, Germany; Department of Computer Science, OsloMet—Oslo Metropolitan University, Oslo, Norway; RWTH Aachen University—Process Systems Engineering (AVT.SVT), Aachen, Germany; Faculty of Science and Technology, Norwegian University of Life Sciences, Ås, Norway; Institute for Theoretical Physics, University of Cologne, Köln, Germany; Forschungszentrum Jülich GmbH, Institute of Energy and Climate Research—Energy Systems Engineering (IEK-10), Jülich, Germany","IEEE Access","24 Jan 2022","2022","10","","8194","8207","The design and operation of modern energy systems are heavily influenced by time-dependent and uncertain parameters, e.g., renewable electricity generation, load-demand, and electricity prices. These are typically represented by a set of discrete realizations known as scenarios. A popular scenario generation approach uses deep generative models (DGM) that allow scenario generation without prior assumptions about the data distribution. However, the validation of generated scenarios is difficult, and a comprehensive discussion about appropriate validation methods is currently lacking. To start this discussion, we provide a critical assessment of the currently used validation methods in the energy scenario generation literature. In particular, we assess validation methods based on probability density, auto-correlation, and power spectral density. Furthermore, we propose using the multifractal detrended fluctuation analysis (MFDFA) as an additional validation method for non-trivial features like peaks, bursts, and plateaus. As representative examples, we train generative adversarial networks (GANs), Wasserstein GANs (WGANs), and variational autoencoders (VAEs) on two renewable power generation time series (photovoltaic and wind from Germany in 2013 to 2015) and an intra-day electricity price time series form the European Energy Exchange in 2017 to 2019. We apply the four validation methods to both the historical and the generated data and discuss the interpretation of validation results as well as common mistakes, pitfalls, and limitations of the validation methods. Our assessment shows that no single method sufficiently characterizes a scenario but ideally validation should include multiple methods and be interpreted carefully in the context of scenarios over short time periods.","2169-3536","","10.1109/ACCESS.2022.3141875","Helmholtz School for Data Science in Life, Earth and Energy (HDS-LEE) through the Helmholtz Association of German Research Centres by the Uncertainty Quantification—From Data to Reliable Knowledge (UQ)(grant numbers:ZT-I-0029); European Union’s Horizon 2020 Research and Innovation Program under the Marie Sklodowska-Curie(grant numbers:840825); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9676641","Artificial neural networks;machine learning;time series analysis;uncertainty;stochastic processes;solar power generation;wind power generation","Time series analysis;Generators;Training;Stochastic processes;Wind power generation;Generative adversarial networks;Fluctuations","neural nets;photovoltaic power systems;power engineering computing;power generation economics;pricing;probability;time series;wind power plants","deep generative models;renewable electricity generation;popular scenario generation approach;generative adversarial networks;energy time series scenarios;intra-day electricity price;energy scenario generation;uncertain parameters;DGM;data distribution;probability density;power spectral density;multifractal detrended fluctuation analysis;MFDFA;Wasserstein GAN;WGAN;VAE;variational autoencoders;Germany;photovoltaic generation;wind generation;European energy exchange","","","","60","CCBY","11 Jan 2022","","","IEEE","IEEE Journals"
"LTN: Long-Term Network for Long-Term Motion Prediction","Y. Wang","Department of Mathematics and Statistics, Colby College, Maine, ME, USA","2021 IEEE International Intelligent Transportation Systems Conference (ITSC)","25 Oct 2021","2021","","","1845","1852","Making accurate motion prediction of surrounding agents such as pedestrians and vehicles is a critical task when robots are trying to perform autonomous navigation tasks. Recent research on multi-modal trajectory prediction, including regression and classification approaches, perform very well at short-term prediction. However, when it comes to long-term prediction, most Long Short-Term Memory (LSTM) based models tend to diverge far away from the ground truth. Therefore, in this work, we present a two-stage framework for long-term trajectory prediction, which is named as Long-Term Network (LTN). Our Long-Term Network integrates both the regression and classification approaches. We first generate a set of proposed trajectories with our proposed distribution using a Conditional Variational Autoencoder (CVAE), and then classify them with binary labels, and output the trajectories with the highest score. We demonstrate our Long-Term Network's performance with experiments on two real-world pedestrian datasets: ETH/UCY, Stanford Drone Dataset (SDD), and one challenging real-world driving forecasting dataset: nuScenes. The results show that our method outperforms multiple state-of-the-art approaches in long-term trajectory prediction in terms of accuracy by around 20 percent.","","978-1-7281-9142-3","10.1109/ITSC48978.2021.9564970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9564970","","Conferences;Predictive models;Data models;Trajectory;Proposals;Task analysis;Forecasting","pattern classification;pedestrians;recurrent neural nets;regression analysis","Long-Term motion prediction;motion prediction;multimodal trajectory prediction;regression;long-term trajectory prediction;long-term network;long short-term memory based models;conditional variational autoencoder;CVAE;autonomous navigation tasks;ETH/UCY dataset;Stanford drone dataset;SDD dataset;real-world pedestrian dataset;efficiency 20.0 percent","","","","32","IEEE","25 Oct 2021","","","IEEE","IEEE Conferences"
"Learning to synthesize faces using voice clips for Cross-Modal biometric matching","P. Agarwal; S. Poddar; A. Hazarika; H. Rahaman","Electronics and Communication IIIT Guwahati, Guwahati, India; Electronics and Communication IIIT Guwahati, Guwahati, India; Electronics and Communication IIIT Guwahati, Guwahati, India; Information Technology IIEST Shibpur, Howrah, India","2019 IEEE Region 10 Symposium (TENSYMP)","30 Jan 2020","2019","","","397","402","Cross-Modal biometric matching has been a scarcely explored field but carries several important applications and aims to further secure the currently existing security systems. In this paper, a framework for cross-modal biometric matching is presented, where faces of an individual are generated using his/her voice clips and further the synthesized faces are tested using a face classification network. Generative Adversarial Network (GAN) has become a recent trend in deep learning and has been widely used for image synthesis. We explore the advancements of Convolutional Neural Network (CNN) for feature extraction and generative networks for image synthesis. In the experiment, we compare the performance of Variational Autoencoders(VAE), Conditional Generative Adversarial Networks(C-GAN) and Regularized Conditional Generative Adversarial Networks(RC-GAN) and show that RC-GAN that is C-GAN with a regularization factor added to its loss is able to generate faces corresponding to the true identity of the voice clips with the best accuracy of 84.52% while VAE generates a less noise prone image with the highest PSNR of 28.276 decibels but with an accuracy of 72.61%.","2642-6102","978-1-7281-0297-9","10.1109/TENSYMP46218.2019.8971330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8971330","Biometric matching;Deep Learning;Convolutional Neural Network;Generative Adversarial Network","","biometrics (access control);convolutional neural nets;face recognition;feature extraction;image classification;image matching;learning (artificial intelligence);speech recognition","voice clips;cross-modal biometric matching;face classification network;deep learning;image synthesis;convolutional neural network;regularized conditional generative adversarial networks;RC-GAN;VAE;variational autoencoders;CNN;feature extraction","","","","28","","30 Jan 2020","","","IEEE","IEEE Conferences"
"AnoDDPM: Anomaly Detection with Denoising Diffusion Probabilistic Models using Simplex Noise","J. Wyatt; A. Leach; S. M. Schmon; C. G. Willcocks","Department of Computer Science, Durham University, Durham, UK; Department of Computer Science, Durham University, Durham, UK; Department of Mathematical Sciences, Durham University, Durham, UK; Department of Computer Science, Durham University, Durham, UK","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","23 Aug 2022","2022","","","649","655","Generative models have been shown to provide a powerful mechanism for anomaly detection by learning to model healthy or normal reference data which can subsequently be used as a baseline for scoring anomalies. In this work we consider denoising diffusion probabilistic models (DDPMs) for unsupervised anomaly detection. DDPMs have superior mode coverage over generative adversarial networks (GANs) and higher sample quality than variational autoencoders (VAEs). However, this comes at the expense of poor scalability and increased sampling times due to the long Markov chain sequences required. We observe that within reconstruction-based anomaly detection a full-length Markov chain diffusion is not required. This leads us to develop a novel partial diffusion anomaly detection strategy that scales to high-resolution imagery, named AnoDDPM. A secondary problem is that Gaussian diffusion fails to capture larger anomalies; therefore we develop a multi-scale simplex noise diffusion process that gives control over the target anomaly size. AnoDDPM with simplex noise is shown to significantly outperform both f-AnoGAN and Gaussian diffusion for the tumorous dataset of 22 T1-weighted MRI scans (CCBS Edinburgh) qualitatively and quantitatively (improvement of +25.5% Sørensen–Dice coefficient, +17.6% IoU and +7.4% AUC).","2160-7516","978-1-6654-8739-9","10.1109/CVPRW56347.2022.00080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9857019","","Training;Image segmentation;Shape;Magnetic resonance imaging;Gaussian noise;Noise reduction;Markov processes","biodiffusion;biomedical MRI;image denoising;image reconstruction;Markov processes;medical image processing;tumours","generative adversarial networks;reconstruction-based anomaly detection;full-length Markov chain diffusion;novel partial diffusion anomaly detection strategy;Gaussian diffusion;AnoDDPM;denoising diffusion probabilistic models;generative models;normal reference data;unsupervised anomaly detection;Markov chain sequences;multiscale simplex noise diffusion;variational autoencoders;T1-weighted MRI scans","","","","29","IEEE","23 Aug 2022","","","IEEE","IEEE Conferences"
"Solving the problem of imbalanced dataset with synthetic image generation for cell classification using deep learning","D. Kupas; B. Harangi","Department of Computer Graphics and Image Processing, Faculty of Informatics, University of Debrecen, Debrecen; Department of Computer Graphics and Image Processing, Faculty of Informatics, University of Debrecen, Debrecen","2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","9 Dec 2021","2021","","","2981","2984","The low number of annotated training images and class imbalance in the field of machine learning is a common problem that is faced in many applications. With this paper, we focus on a clinical dataset where cells were extracted in a previous research. Class imbalance can be experienced within this dataset since the normal cells are in a great majority in contrast to the abnormal ones. To address both problems, we present our idea of synthetic image generation using a custom variational autoencoder, that also enables the pretraining of the subsequent classifier network. Our method is compared with a performant solution, as well as presented with different modifications. We have experienced a performance increase of 4.52% regarding the classification of the abnormal cells.Clinical Relevance — We extract images from cervical smears, using digitized Pap test. When working with these kinds of smears, a single one can contain more than 10,000 cells. Examination of these is done manually by going over each cell individually. Our main goal is to make a system that can rank these samples by importance, thus making the process easier and more effective. The research that is described in this paper gets us a step closer to achieving our goal.","2694-0604","978-1-7281-1179-7","10.1109/EMBC46164.2021.9631065","Innovation Fund; European Social Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9631065","","Training;Deep learning;Image synthesis;Benchmark testing;Biology","image classification;learning (artificial intelligence);medical image processing;pattern classification","imbalanced dataset;synthetic image generation;cell classification;deep learning;annotated training images;class imbalance;machine learning;clinical dataset;normal cells;great majority;custom variational autoencoder;abnormal cells","Deep Learning;Female;Humans;Machine Learning;Papanicolaou Test;Vaginal Smears","","","11","","9 Dec 2021","","","IEEE","IEEE Conferences"
"iVAE-GAN: Identifiable VAE-GAN Models for Latent Representation Learning","B. U. Dideriksen; K. Derosche; Z. -H. Tan","Department of Electronic Systems, Aalborg University, Aalborg, Denmark; Department of Electronic Systems, Aalborg University, Aalborg, Denmark; Department of Electronic Systems, Aalborg University, Aalborg, Denmark","IEEE Access","10 May 2022","2022","10","","48405","48418","Remarkable progress has been made within nonlinear Independent Component Analysis (ICA) and identifiable deep latent variable models. Formally, the latest nonlinear ICA theory enables us to recover the true latent variables up to a linear transformation by leveraging unsupervised deep learning. This is of significant importance for unsupervised learning in general as the true latent variables are of principal interest for meaningful representations. These theoretical results stand in stark contrast to the mostly heuristic approaches used for representation learning which do not provide analytical relations to the true latent variables. We extend the family of identifiable models by proposing an identifiable Variational Autoencoder (VAE) based Generative Adversarial Network (GAN) model we name iVAE-GAN. The latent space of most GANs, including VAE-GAN, is generally unrelated to the true latent variables. With iVAE-GAN we show the first principal approach to a theoretically meaningful latent space by means of adversarial training. We implement the novel iVAE-GAN architecture and show its identifiability, which is confirmed by experiments. The GAN objective is believed to be an important addition to identifiable models as it is one of the most powerful deep generative models. Furthermore, no requirements are imposed on the adversarial training leading to a very general model.","2169-3536","","10.1109/ACCESS.2022.3172333","Pioneer Centre for Artificial Intelligence, Denmark; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9766338","Identifiability;VAE-GAN;deep learning;latent representation learning","Data models;Generative adversarial networks;Biological system modeling;Training;Solid modeling;Representation learning;Object recognition","deep learning (artificial intelligence);independent component analysis;unsupervised learning","identifiable variational autoencoder;generative adversarial network model;identifiable VAE-GAN models;latent representation learning;identifiable deep latent variable models;latest nonlinear ICA theory;unsupervised deep learning;iVAE-GAN architecture;nonlinear independent component analysis;deep generative models","","","","16","CCBY","3 May 2022","","","IEEE","IEEE Journals"
"TraceModel: An Automatic Anomaly Detection and Root Cause Localization Framework for Microservice Systems","Y. Cai; B. Han; J. Su; X. Wang","College of Computer, National University of Defense Technology, Changsha, Hunan, CN; College of Computer, National University of Defense Technology, Changsha, Hunan, CN; College of Computer, National University of Defense Technology, Changsha, Hunan, CN; College of engineering, Ibaraki University, Hitachi city, Ibaraki, Japan","2021 17th International Conference on Mobility, Sensing and Networking (MSN)","13 Apr 2022","2021","","","512","519","Microservice system is a web application architecture that divides a single application into a suite of service nodes running as separate processes and communicating with lightweight message mechanisms. Although microservice can improve the abstraction, modularity and extensibility of web applications, it makes the anomaly detection and fault root cause localization more challenging for operational staff. To this end, in this paper, we first introduce the concept of service dependency graph (SDG) to depict the complex calling relationship between nodes and then develop an anomaly detection and root cause localization framework called TraceModel which consists of TraceVAE and ModelCoder. TraceVAE divides user requests into different request classes according to well-constructed trace and analysis them separately with variational autoencoder(VAE) to figures out abnormal requests. Based on the anomaly detection results of TraceVAE, ModelCoder localizes the root cause of unknown faults by comparing their fault features with the predefined fault models. By evaluating TraceModel on a realworld microservice system monitoring data set spanning 15 days, it is revealed that TraceModel can detect the anomaly and localize the fault root cause nodes within 110 seconds on average. Furthermore, it improves the root cause localization accuracy (to 97%) by 17.5% compared with the state-of-the-art root cause localization algorithm.","","978-1-6654-0668-0","10.1109/MSN53354.2021.00081","National Natural Science Foundation of China; Training Program for Excellent Young Innovators of Changsha; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9751531","microservice;anomaly detection;root cause localization","Location awareness;Microservice architectures;Feature extraction;Sensors;Anomaly detection;Monitoring","fault diagnosis;fault location;graph theory;neural nets;security of data;software fault tolerance;system monitoring;Web services","root cause localization framework;web application architecture;service nodes;lightweight message mechanisms;web applications;service dependency graph;complex calling relationship;TraceModel;root cause localization accuracy;automatic anomaly detection;root cause localization algorithm;microservice system monitoring data;TraceVAE;variational autoencoder;time 15.0 d;time 110.0 s","","","","29","IEEE","13 Apr 2022","","","IEEE","IEEE Conferences"
"Reward Redistribution for Reinforcement Learning of Dynamic Nonprehensile Manipulation","G. Sejnova; M. Mejdrechova; M. Otahal; N. Sokovnin; I. Farkas; M. Vavrecka","Czech Institute of Informatics, Robotics and Cybernetics Czech Technical University in Prague, Prague, Czech Republic; Czech Institute of Informatics, Robotics and Cybernetics Czech Technical University in Prague, Prague, Czech Republic; Czech Institute of Informatics, Robotics and Cybernetics Czech Technical University in Prague, Prague, Czech Republic; Czech Institute of Informatics, Robotics and Cybernetics Czech Technical University in Prague, Prague, Czech Republic; Faculty of Mathematics, Physics and Informatics, Comenius University in Bratislava, Bratislava, Slovakia; Czech Institute of Informatics, Robotics and Cybernetics Czech Technical University in Prague, Prague, Czech Republic","2021 7th International Conference on Control, Automation and Robotics (ICCAR)","25 Jun 2021","2021","","","326","331","Recent reinforcement learning (RL) systems can solve a wide variety of manipulation tasks even in real-world robotic implementations. However, in some nonprehensile manipulation tasks (e.g. poking, throwing), the classical reward system fails as the robot has to manipulate objects whose motion trajectory is partly uncontrollable. Such tasks require a specific type of reward that would reflect this temporal misalignment. We propose a novel method, based on a delayed reward redistribution, that allows a robot to fulfill goals in an only partially controllable environment. The reward system in our architecture combines information from other sensors together with inputs from an unsupervised vision module based on a variational autoencoder (VAE). This delayed reward system then controls the training of the motor module based on a Soft Actor-Critic (SAC) neural network. We compare results for a delayed and nondelayed version of our system in a simulated environment and show that the delayed reward greatly outperforms the nondelayed version.","2251-2454","978-1-6654-4986-1","10.1109/ICCAR52225.2021.9463495","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9463495","reinforcement learning;credit assignment;unsupervised learning","Training;Heuristic algorithms;Neural networks;Tactile sensors;Reinforcement learning;Sensor systems;Trajectory","dexterous manipulators;manipulator dynamics;mobile robots;motion control;neural nets;robot vision;trajectory control;unsupervised learning","RL;nonprehensile manipulation tasks;motion trajectory;temporal misalignment;delayed reward redistribution;partially controllable environment;unsupervised vision module;delayed reward system;delayed version;nondelayed version;dynamic nonprehensile manipulation;soft actor-critic neural network;variational autoencoder","","","","27","","25 Jun 2021","","","IEEE","IEEE Conferences"
"Interpretable Representation Learning on Natural Image Datasets via Reconstruction in Visual-Semantic Embedding Space","N. Nakagawa; R. Togo; T. Ogawa; M. Haseyama","Graduate School of Information Science and Technology, Hokkaido University, Japan; Education and Research Center for Mathematical and Data Science, Hokkaido University, Japan; Faculty of Information Science and Technology, Hokkaido University, Japan; Faculty of Information Science and Technology, Hokkaido University, Japan","2021 IEEE International Conference on Image Processing (ICIP)","23 Aug 2021","2021","","","2473","2477","Unsupervised learning of disentangled representations is a core task for discovering interpretable factors of variation in an image dataset. We propose a novel method that can learn disentangled representations with semantic explanations on natural image datasets. In our method, we guide the representation learning of a variational autoencoder (VAE) via reconstruction in a visual-semantic embedding (VSE) space to leverage the semantic information of image data and explain the learned latent representations in an unsupervised manner. We introduce a semantic sub-encoder and a linear semantic sub-decoder to learn word vectors corresponding to the latent variables to explain factors of variation in the language form. Each basis vector (column) of the linear semantic sub-decoder corresponds to each latent variable, and we can interpret the basis vectors as word vectors indicating the meanings of the latent representations. By introducing the sub-encoder and the sub-decoder, our model can learn latent representations that are not just disentangled but interpretable. Comparing with other state-of-the-art unsupervised disentangled representation learning methods, we observe significant improvements in the disentanglement and the transferability of latent representations.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506619","Disentanglement;representation learning;natural image;visual-semantic embedding;vision and language","Conferences;Semantics;Task analysis;Image reconstruction;Unsupervised learning","image representation;learning (artificial intelligence);unsupervised learning;vectors","image data;learned latent representations;unsupervised manner;semantic sub-encoder;word vectors;latent variables;basis vector;linear semantic sub-decoder corresponds;state-of-the-art unsupervised disentangled representation learning methods;disentanglement;interpretable representation learning;natural image datasets;visual-semantic embedding space;unsupervised learning;disentangled representations;image dataset;semantic explanations;variational autoencoder;semantic information","","","","25","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"PVAE-TTS: Adaptive Text-to-Speech via Progressive Style Adaptation","J. -H. Lee; S. -H. Lee; J. -H. Kim; S. -W. Lee","Department of Artificial Intelligence, Korea University, Seoul, Korea; Department of Brain and Cognitive Engineering, Korea University, Seoul, Korea; Department of Artificial Intelligence, Korea University, Seoul, Korea; Department of Brain and Cognitive Engineering, Korea University, Seoul, Korea","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","6312","6316","Adaptive text-to-speech (TTS) has attracted increasing interests for the purpose of training TTS systems without tons of high quality data. Nevertheless, existing adaptive TTS systems still show low adaptation quality for novel speakers, since it is hard to learn an extensive speaking style with limited data. To address this issue, we propose progressive variational autoencoder (PVAE) which generates data with adapting to style gradually. PVAE learns a progressively style-normalized representation, which is a key component of progressive style adaptation. We extend PVAE to PVAE-TTS, a multi-speaker adaptive TTS model which generates natural speech with high adaptation quality for novel speakers. To further improve the adaptation quality, we also propose dynamic style layer normalization (DSLN) which utilizes a convolution operation. The experimental results demonstrate the superiority of PVAE-TTS in terms of both subjective and objective evaluations.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9747388","Korea University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747388","text-to-speech;speech synthesis;adaptive TTS;speaker adaptation","Training;Measurement;Adaptation models;Adaptive systems;Image synthesis;Convolution;Conferences","learning (artificial intelligence);speaker recognition;speech synthesis","natural speech;high adaptation quality;novel speakers;dynamic style layer normalization;PVAE-TTS;adaptive text-to-speech;progressive style adaptation;training TTS systems;adaptive TTS systems;low adaptation quality;extensive speaking style;progressive variational autoencoder;adapting;progressively style-normalized representation;multispeaker adaptive TTS model","","","","21","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Imaging Time Series for Deep Embedded Clustering: a Cryptocurrency Regime Detection Use Case","A. Najafgholizadeh; A. Nasirkhani; H. R. Mazandarani; H. R. Soltanalizadeh; M. Sabokrou","Part AI Research Center, Tehran, Iran; Part AI Research Center, Tehran, Iran; Part AI Research Center, Tehran, Iran; Part AI Research Center, Tehran, Iran; Institute for Research in Fundamental Sciences, Tehran, Iran","2022 27th International Computer Conference, Computer Society of Iran (CSICC)","27 May 2022","2022","","","1","6","Following the recent trend of data-centric AI, we propose a clustering method to offer additional insight into precious and yet less-explored cryptocurrency price time series. While invaluable efforts have been conveyed in the domain of time series clustering, we integrate and harmonize some of the best practices in the field, namely Gramian Angular Field (GAF), Variational AutoEncoders (VAEs), and Deep Embedded Clustering (DEC). We use time series to image transformations as a preprocessing step for VAE to reduce dimensionality. After performing K-means clustering on VAE’s latent space, we provide DEC with cluster centroids from the previous step and retrain our network to do the clustering task. We evaluate the proposed method with the Bitcoin Tick-bar price dataset from 2017 onwards. Results demonstrate that our method leads to financially interpretable clusters and can improve Silhouette Score up to 10 percent compared to non-imaged time series.","","978-1-6654-8027-7","10.1109/CSICC55295.2022.9780526","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9780526","Time series Clustering;Cryptocurrency Regime Detection;Gramian Angular Field","Clustering methods;Time series analysis;Imaging;Clustering algorithms;Bitcoin;Machine learning;Markov processes","cryptocurrencies;deep learning (artificial intelligence);financial data processing;pattern clustering;share prices;stock markets;time series","Bitcoin Tick-bar price dataset;time series imaging;deep embedded clustering;cryptocurrency regime detection use case;data-centric AI;time series clustering;Gramian Angular Field;image transformations;cluster centroids;cryptocurrency price time series;VAE;DEC;variational autoencoders;k-means clustering","","","","17","IEEE","27 May 2022","","","IEEE","IEEE Conferences"
"Sampling Possible Reconstructions of Undersampled Acquisitions in MR Imaging With a Deep Learned Prior","K. C. Tezcan; N. Karani; C. F. Baumgartner; E. Konukoglu","Computer Vision Laboratory, ETH Zürich, Zürich, Switzerland; Computer Vision Laboratory, ETH Zürich, Zürich, Switzerland; Machine Learning in Medical Image Analysis Group, University of Tübingen, Tübingen, Germany; Computer Vision Laboratory, ETH Zürich, Zürich, Switzerland","IEEE Transactions on Medical Imaging","30 Jun 2022","2022","41","7","1885","1896","Undersampling the k-space during MR acquisitions saves time, however results in an ill-posed inversion problem, leading to an infinite set of images as possible solutions. Traditionally, this is tackled as a reconstruction problem by searching for a single “best” image out of this solution set according to some chosen regularization or prior. This approach, however, misses the possibility of other solutions and hence ignores the uncertainty in the inversion process. In this paper, we propose a method that instead returns multiple images which are possible under the acquisition model and the chosen prior to capture the uncertainty in the inversion process. To this end, we introduce a low dimensional latent space and model the posterior distribution of the latent vectors given the acquisition data in k-space, from which we can sample in the latent space and obtain the corresponding images. We use a variational autoencoder for the latent model and the Metropolis adjusted Langevin algorithm for the sampling. We evaluate our method on two datasets; with images from the Human Connectome Project and in-house measured multi-coil images. We compare to five alternative methods. Results indicate that the proposed method produces images that match the measured k-space data better than the alternatives, while showing realistic structural variability. Furthermore, in contrast to the compared methods, the proposed method yields higher uncertainty in the undersampled phase encoding direction, as expected.","1558-254X","","10.1109/TMI.2022.3150853","Swiss National Science Foundation(grant numbers:205321_173016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9709768","Magnetic resonance image reconstruction;uncertainty estimation;inverse problems;sampling;MCMC;deep learning;unsupervised learning","Uncertainty;Image reconstruction;Noise measurement;Measurement uncertainty;Training;Task analysis;Predictive models","Bayes methods;biomedical MRI;expectation-maximisation algorithm;image reconstruction;image sampling;inverse problems;learning (artificial intelligence);medical image processing","inversion process;multiple images;acquisition model;low dimensional latent space;posterior distribution;latent vectors;acquisition data;corresponding images;variational autoencoder;latent model;Metropolis adjusted Langevin algorithm;Human Connectome Project;multicoil images;measured k-space data;method yields higher uncertainty;undersampled phase encoding direction;sampling possible reconstructions;undersampled acquisitions;MR imaging;MR acquisitions;inversion problem;infinite set;reconstruction problem;single best image;chosen regularization","Algorithms;Connectome;Humans;Image Processing, Computer-Assisted;Magnetic Resonance Imaging","","","32","IEEE","10 Feb 2022","","","IEEE","IEEE Journals"
"Towards Addressing the Spatial Sparsity of MDT Reports to Enable Zero Touch Network Automation","J. Shodamola; H. Qureshi; U. Masood; A. Imran","Dept. of Electrical & Computer Engineering, AI4Networks Research Center University of Oklahoma, Tulsa, USA; Dept. of Electrical & Computer Engineering, AI4Networks Research Center University of Oklahoma, Tulsa, USA; Dept. of Electrical & Computer Engineering, AI4Networks Research Center University of Oklahoma, Tulsa, USA; Dept. of Electrical & Computer Engineering, AI4Networks Research Center University of Oklahoma, Tulsa, USA","2021 IEEE Global Communications Conference (GLOBECOM)","2 Feb 2022","2021","","","1","6","Minimization of Drive Test (MDT) reports are a key enabler for Machine Learning (ML)-based zero-touch automation envisioned for emerging cellular networks. However, due to numerous factors, the MDT reports are spatially sparse in nature. This sparsity undermines the performance of ML models that are built on the MDT data to estimate and optimize network KPIs. In this paper, we present and evaluate a framework to address this challenge. We leverage generative models, specifically, Gener-ative Adversarial Networks (GAN) and Variational Autoencoders (VAE) to augment the sparse multi-dimensional MDT data. Unlike image data where the quality of synthetic images produced by the generative models can be evaluated visually, establishing the authenticity of tabular synthetic data is a more complex problem. We address this problem by leveraging a tripartite approach: 1) We use several statistical measures to quantify the resemblance of synthetic data with original data. 2) We compare the performance of an ensemble learning model trained on augmented data, with that of trained on original data only 3) We benchmark the performance of the generative models with several classical ML models. This analysis is carried out for varying levels of sparsity and reveals insights about robustness of generative models against training data sparsity as well as on suitability of various methods for evaluating the quality of the generated synthetic tabular data. Results show GAN performs considerably better compared to other approaches. The presented solution thus can be used to overcome the sparsity problem in MDT reports thereby enabling ML-based automation use cases.","","978-1-7281-8104-2","10.1109/GLOBECOM46510.2021.9686011","National Science Foundation(grant numbers:1923669); Qatar National Research Fund(grant numbers:NPRP12-S0311–190302); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9686011","Minimization of Drive Test (MDT);GAN;VAE;RSRP;machine learning;key performance indicator (KPI);network automation","Training;Maximum likelihood estimation;Automation;Training data;Machine learning;Predictive models;Minimization","cellular radio;learning (artificial intelligence);minimisation;neural nets;statistical analysis;telecommunication computing","synthetic image quality;ensemble learning model;classical ML models;training data sparsity;sparsity problem;MDT reports;ML-based automation;spatial sparsity;zero touch network automation;cellular networks;sparse multidimensional MDT data;image data;generative models;generative adversarial networks;network KPI optimization;variational autoencoders;VAE;tabular synthetic data authenticity;tripartite approach;statistical measures;augmented data;minimization of drive test reports;machine learning","","","","28","IEEE","2 Feb 2022","","","IEEE","IEEE Conferences"
"Camera-Conditioned Stable Feature Generation for Isolated Camera Supervised Person Re-IDentification","C. Wu; W. Ge; A. Wu; X. Chang","School of Artificial Intelligence, Sun Yat-sen University, China; School of Computer Science and Engineering, Sun Yat-sen University, China; School of Computer Science and Engineering, Sun Yat-sen University, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, China","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","20206","20216","To learn camera-view invariant features for person Re-IDentification (Re-ID), the cross-camera image pairs of each person play an important role. However, such cross-view training samples could be unavailable under the ISo-lated Camera Supervised (ISCS) setting, e.g., a surveillance system deployed across distant scenes. To handle this challenging problem, a new pipeline is introduced by synthesizing the cross-camera samples in the feature space for model training. Specifically, the feature encoder and generator are end-to-end optimized under a novel method, Camera-Conditioned Stable Feature Generation (CCSFG). Its joint learning procedure raises concern on the stability of generative model training. Therefore, a new feature generator, σ-Regularized Conditional Variational Autoencoder (σ-Reg. CVAE), is proposed with theoretical and experimental analysis on its robustness. Extensive experiments on two ISCS person Re-ID datasets demonstrate the superiority of our CCSFG to the competitors. 11https://github.com/ftd-Wuchao/CCSFG","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01960","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9878956","Biometrics; Recognition: detection;categorization;retrieval; Representation learning","Training;Representation learning;Visualization;Surveillance;Pipelines;Cameras;Generators","cameras;image coding;image sampling;supervised learning","cross-camera image pairs;cross-view training samples;cross-camera samples;feature encoder;generative model training;camera-conditioned stable feature generation;camera-view invariant feature generation;isolated camera supervised person reidentification;CCSFG;σ-regularized conditional variational autoencoder;σ-Reg. CVAE;ISCS person reID datasets","","","","59","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Intelligent Fault Analysis Decision Flow in Semiconductor Industry 4.0 Using Natural Language Processing with Deep Clustering","K. Ezukwoke; H. Toubakh; A. Hoayek; M. Batton-Hubert; X. Boucher; P. Gounet","Mathematics and Industrial Engineering, Mines Saint-Etienne, Univ. Clermont Auvergne, CNRS UMR 6158 LIMOS, Henri FAYOL institute, Saint-Etienne, France; Mathematics and Industrial Engineering, Mines Saint-Etienne, Univ. Clermont Auvergne, CNRS UMR 6158 LIMOS, Henri FAYOL institute, Saint-Etienne, France; Mathematics and Industrial Engineering, Mines Saint-Etienne, Univ. Clermont Auvergne, CNRS UMR 6158 LIMOS, Henri FAYOL institute, Saint-Etienne, France; Mathematics and Industrial Engineering, Mines Saint-Etienne, Univ. Clermont Auvergne, CNRS UMR 6158 LIMOS, Henri FAYOL institute, Saint-Etienne, France; Organisation and Environmental Engineering, Mines Saint-Etienne, Univ. Clermont Auvergne, CNRS UMR 6158 LIMOS, Henri FAYOL institute, Saint-Etienne, France; Physical Failure Analysis, STMicroelectronics, Reliability and Failure Analysis Lab, Grenoble, France","2021 IEEE 17th International Conference on Automation Science and Engineering (CASE)","5 Oct 2021","2021","","","429","436","Microelectronics production failure analysis is a time-consuming and complicated task involving successive steps of analysis of complex process chains. The analysis is triggered to find the root cause of a failure and its findings, recorded in a reporting system using natural language. Fault analysis, physical analysis, sample preparation and package construction analysis are arguably the most used analysis activity for determining the root-cause of a failure. Intelligent automation of this analysis decision process using artificial intelligence is the objective of the FA 4.0 consortium; creating a reliable and efficient semiconductor industry. This research presents natural language processing (NLP) techniques to find a coherent representation of the expert decisions during fault analysis. The adopted methodology is a Deep learning algorithm based on $\beta$-variational autoencoder ($\beta$-VAE) for latent space disentanglement and Gaussian Mixture Model for clustering of the latent space for class identification.","2161-8089","978-1-6654-1873-7","10.1109/CASE49439.2021.9551492","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9551492","Failure analysis;Industry 4.0;Natural language processing;Artificial Intelligence;Machine learning","Deep learning;Electronics industry;Failure analysis;Clustering algorithms;Transforms;Production;Predictive models","deep learning (artificial intelligence);failure analysis;fault diagnosis;Gaussian processes;integrated circuit manufacture;mixture models;natural language processing;pattern clustering;production engineering computing;semiconductor industry","complex process chains;physical analysis;sample preparation;package construction analysis;intelligent automation;artificial intelligence;natural language processing techniques;intelligent fault analysis decision flow;deep clustering;microelectronics production failure analysis;semiconductor industry 4.0;FA 4.0 consortium;NLP techniques;deep learning algorithm;β-variational autoencoder;β-VAE;latent space disentanglement;Gaussian mixture model;class identification","","","","28","IEEE","5 Oct 2021","","","IEEE","IEEE Conferences"
"Mining Connections Between Domains through Latent Space Mapping","Y. Lu","Carnegie Mellon University, Pittsburgh, USA","2018 IEEE International Conference on Data Mining Workshops (ICDMW)","10 Feb 2019","2018","","","1086","1093","Exploring ways to connect data is crucial to building knowledge graphs to associate data from different domains together. Humans, for example, can learn to associate flour with bread because bread is made of flour so that they can recall information of flour given a piece of bread even though bread and flour have few common features. In data mining, this ability can be translated to the way to connect images, texts, audios from different classes or domains together. Most works so far assume shared feature representations between domains we want to connect together. Another limitation yet to be improved is that for each defined mapping scheme, we often have to train a new model end-to-end among all sample data, which is often expensive. In this work, we present a model that aims to simultaneously address the two limitations. We use unconditionally trained Variational Autoencoders(VAEs) to project high dimensional data into the latent space and present a novel generative model that transfer latent representation of data from one domain to another by any custom schema. The model makes no assumption on any shared representation among different domains. The VAEs that encodes entire datasets, being the largest training overhead in this model, can be reused to support any new mapping schema without any retraining.","2375-9259","978-1-5386-9288-2","10.1109/ICDMW.2018.00157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8637394","latent space, cross domain, generative models","Data models;Training;Generators;Encoding;Random variables;Transforms;Decoding","data mining;data visualisation;graph theory;learning (artificial intelligence);pattern clustering","data mining;shared feature representations;sample data;high dimensional data;latent space;generative model;transfer latent representation;shared representation;mapping schema;mining connections;knowledge graphs;unconditionally trained variational autoencoders","","","","23","","10 Feb 2019","","","IEEE","IEEE Conferences"
"Literature Review of Generative models for Image-to-Image translation problems","A. Kamil; T. Shaikh","Department of Mathematical and Computer Sciences, Heriot-Watt University, Dubai, United Arab Emirates; Department of Mathematical and Computer Sciences, Heriot-Watt University, Dubai, United Arab Emirates","2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE)","20 Feb 2020","2019","","","340","345","In recent years, data-driven (image based) methodologies like deep learning and computer vision have made computers immensely accurate in terms of identifying features inside images. Research in this area has given way to a relatively new set of deep learning models known as Generative models which generate images alongside identifying features inside them. These models, particularly conditional generative adversarial networks (CGANs), conditional variational autoencoders (CVAE) and generative stochastic networks (GSN) have become popular as they are able to translate images from one setting to another while keeping the structure of generated images aligned with the input images. In this paper, we review the work that has been done using these models to the area of web design automation which needs to be considered during the development phase. We also try to identify the benefits of implementing these models based on architectural features while keeping in view the different problem scenarios. Finally, some key challenges in solving such image-to-image translation problems has been mentioned.","","978-1-7281-3778-0","10.1109/ICCIKE47802.2019.9004254","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9004254","deep learning;CGANs;CVAE;GSN;image translation;computer vision;web design automation","Biological system modeling;Gallium nitride;Computational modeling;Generative adversarial networks;Machine learning;Generators;Data models","computer vision;learning (artificial intelligence);neural nets;stochastic processes","image-to-image translation problems;computer vision;deep learning models;conditional variational autoencoders;generative stochastic networks;input images;generative models;conditional generative adversarial networks","","","","19","","20 Feb 2020","","","IEEE","IEEE Conferences"
"MMCD VAE Model for Deep Facial Scale-Invariant-Feature-Translation","F. Barreto; S. Yadav; D. S. Patnaik; D. J. Sarvaiya","Department of Electronics and Telecommunication, Xavier Institute of Engineering, Mumbai, India; Jio Platforms Limited, Mumbai, India; School of Electronics, Kalinga Institute of Industrial Technology, Bhubaneswar, India; Department of Electronics, Sardar Vallabhbhai National Institute of Technology, Surat, India","2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS)","26 May 2021","2021","","","526","530","This paper is utilizing the joint mean and covariance discrepancy as a solution for domain adaption by using a deep Variational Auto Encoder (VAE). The proposed model is tested for the Scale Invariant Feature Transform (SIFT) of facial images. SIFT based face recognition relies heavily on the detection of facial features as the descriptor. The existence of sufficient and accurate scale invariant features can lead to better matching between model image and query image and result in robust recognition. Deep variational auto encoders have shown appreciable results in the extraction of hierarchical latent representation based domain adaptation in face recognition frameworks. Conventionally VAEs are trained to learn variance and mean of input distribution as the latent representation. Maximum mean discrepancy (MMD) uses second-order statistics in reproducing kernel Hilbert space as the representation trait. This research work proposes a novel VAE model to consider maximum mean covariance discrepancy (MMCD). While the VAE model looks for a discrepancy in the spread of variance around the mean value, MMCD measures directional discrepancy in the variance. To verify the efficacy of MMCD based VAE over conventional VAE, SIFT for face images are carried out. Quantitative evaluation of domain adaptation and use of covariance discrepancy are the two major contributions of this work. It is observed that MMCD VAE not only provides more number of SIFT feature but also better correspondent matching of feature points. Images from a created Bollywood database and the publicly available LFW database are used for comparative analysis.","","978-1-6654-1272-8","10.1109/ICICCS51141.2021.9432318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9432318","VAE;Domain adaptation;Face recognition;SIFT;Bollywood database;Mean Discrepancy;Covariance Discrepancy","Adaptation models;Image recognition;Databases;Face recognition;Surveillance;Transforms;Feature extraction","deep learning (artificial intelligence);face recognition;feature extraction;higher order statistics;Hilbert spaces;image classification;image matching;image representation;image retrieval;transforms","model image matching;query image;robust recognition;hierarchical latent representation based domain adaptation;face recognition frameworks;maximum mean discrepancy;representation trait;maximum mean covariance discrepancy;directional discrepancy;conventional VAE;face images;SIFT feature;feature point matching;MMCD VAE model;deep facial scale-invariant-feature-translation;domain adaption;Scale Invariant Feature Transform;SIFT based face recognition;facial features;deep variational autoencoders;second-order statistics;kernel Hilbert space;quantitative evaluation","","","","17","","26 May 2021","","","IEEE","IEEE Conferences"
"An Unsupervised Bayesian Neural Network for Truth Discovery in Social Networks","J. Yang; W. P. Tay","School of Artificial Intelligence, Jilin University, Changchun, Jilin, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore","IEEE Transactions on Knowledge and Data Engineering","6 Oct 2022","2022","34","11","5182","5195","The problem of estimating event truths from conflicting agent opinions in a social network is investigated. An autoencoder learns the complex relationships between event truths, agent reliabilities and agent observations. A Bayesian network model is proposed to guide the learning process by modeling the relationship of the autoencoder's outputs with different variables. At the same time, it also models the social relationships between agents in the network. The proposed approach is unsupervised and is applicable when ground truth labels of events are unavailable. A variational inference method is used to jointly estimate the hidden variables in the Bayesian network and the parameters in the autoencoder. Experiments on three real datasets demonstrate that our proposed approach is competitive with, and in most cases better than, several state-of-the-art benchmark methods.","1558-2191","","10.1109/TKDE.2021.3054853","Singapore Ministry of Education Academic Research Fund Tier 2(grant numbers:MOE2018-T2-2-019); Agency for Science, Technology and Research; Advanced Manufacturing and Engineering (AME) Industry Alignment Fund – Pre Positioning(grant numbers:A19D6a0053); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9336313","Truth discovery;unsupervised learning;autoencoder;Bayesian network;social network","Reliability;Bayes methods;Social networking (online);Neural networks;Hidden Markov models;Unsupervised learning;Probability distribution","","","","","","59","IEEE","26 Jan 2021","","","IEEE","IEEE Journals"
"Deep Learning‐Based Filters","P. Setoodeh; S. Habibi; S. Haykin",NA; NA; McMaster University,"Nonlinear Filters: Theory and Applications","","2022","","","141","183","This chapter covers the Bayesian filtering algorithms that deploy deep learning to build state‐space models from raw data. Variational inference and amortized variational inference are reviewed, which are used to estimate an approximate posterior through reformulating the inference problem as an optimization problem aimed at minimizing the Kullback–Leibler divergence between the true and the approximate posteriors. A number of deep learning‐based filtering algorithms are inspired by variational autoencoders. Such filters are trained by optimizing the evidence lower bound. The presented deep learning‐based filtering algorithms include deep Kalman filter, backpropagation Kalman filter, differentiable particle filter, deep Rao–Blackwellized particle filter, deep variational Bayes filter, and Kalman variational autoencoder. Then, deep variational information bottleneck is reviewed, which aims at providing an optimal representation in terms of a trade‐off between complexity of the representation and its predictive power. The issue of robustness is discussed by presenting the Wasserstein distributionally robust Kalman filter. Hierarchical invertible neural transport is presented, which can provide both the joint and the conditional densities. The reviewed applications of deep learning‐based filters include predicting the effect of anti‐diabetic drugs based on the electronic health records and autonomous driving using the KITTI Vision Benchmark.","","9781119078180","10.1002/9781119078166.ch9","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9740361.pdf&bkn=9740330&pdfType=chapter","","Mathematical models;Optimization;Computational modeling;State-space methods;Neural networks;Filtering algorithms;Data models","","","","","","","","23 Mar 2022","","","Wiley","Wiley Telecom eBook Chapters"
"Adversarial Examples for Generative Models","J. Kos; I. Fischer; D. Song","National University of Singapore; Google Research; University of California, Berkeley","2018 IEEE Security and Privacy Workshops (SPW)","6 Aug 2018","2018","","","36","42","We explore methods of producing adversarial examples on deep generative models such as the variational autoencoder (VAE) and the VAE-GAN. Deep learning architectures are known to be vulnerable to adversarial examples, but previous work has focused on the application of adversarial examples to classification tasks. Deep generative models have recently become popular due to their ability to model input data distributions and generate realistic examples from those distributions. We present three classes of attacks on the VAE and VAE-GAN architectures and demonstrate them against networks trained on MNIST, SVHN and CelebA. Our first attack leverages classification-based adversaries by attaching a classifier to the trained encoder of the target generative model, which can then be used to indirectly manipulate the latent representation. Our second attack directly uses the VAE loss function to generate a target reconstruction image from the adversarial example. Our third attack moves beyond relying on classification or the standard loss for the gradient and directly optimizes against differences in source and target latent representations. We also motivate why an attacker might be interested in deploying such techniques against a target generative network.","","978-1-5386-8276-0","10.1109/SPW.2018.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8424630","Adversarial examples;generative models;vae;vae gan","Image reconstruction;Receivers;Training;Image coding;Decoding;Machine learning;Data models","data models;image classification;image reconstruction;image representation;learning (artificial intelligence);neural net architecture;variational techniques","adversarial example;deep generative models;deep learning architectures;target generative model;target generative network;classification-based adversaries;input data distribution model;VAE-GAN architecture attacks;classifier;neural net architectures","","55","","27","","6 Aug 2018","","","IEEE","IEEE Conferences"
"Efficient Video Indexing for Monitoring Disease Activity and Progression in the Upper Gastrointestinal Tract","S. Ali; J. Rittscher","Institute of Biomedical Engineering, University of Oxford, Oxford; Institute of Biomedical Engineering, University of Oxford, Oxford","2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)","11 Jul 2019","2019","","","91","95","Endoscopy is a routine imaging technique used for both diagnosis and minimally invasive surgical treatment. While the endoscopy video contains a wealth of information, tools to capture this information for the purpose of clinical reporting are rather poor. In date, endoscopists do not have any access to tools that enable them to browse the video data in an efficient and user friendly manner. Fast and reliable video retrieval methods could for example, allow them to review data from previous exams and therefore improve their ability to monitor disease progression. Deep learning provides new avenues of compressing and indexing video in an extremely efficient manner. In this study, we propose to use an autoencoder for efficient video compression and fast retrieval of video images. To boost the accuracy of video image retrieval and to address data variability like multi-modality and view-point changes, we propose the integration of a Siamese network. We demonstrate that our approach is competitive in retrieving images from 3 large scale videos of 3 different patients obtained against the query samples of their previous diagnosis. Quantitative validation shows that the combined approach yield an overall improvement of 5% and 8% over classical and variational autoencoders, respectively.","1945-8452","978-1-5386-3641-1","10.1109/ISBI.2019.8759450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759450","Endoscopy;deep learning;autoencoders;Siamese network;image retrieval","Endoscopes;Image coding;Image retrieval;Streaming media;Decoding;Encoding;Training","biological organs;biomedical optical imaging;content-based retrieval;data compression;diseases;endoscopes;image classification;image representation;indexing;learning (artificial intelligence);medical image processing;patient diagnosis;surgery;video coding;video retrieval;video signal processing","upper gastrointestinal tract;routine imaging technique;minimally invasive surgical treatment;endoscopy video;clinical reporting;video data;deep learning;video image retrieval;data variability;video indexing;video compression;video retrieval methods;quantitative validation","","2","","12","","11 Jul 2019","","","IEEE","IEEE Conferences"
"GHUM & GHUML: Generative 3D Human Shape and Articulated Pose Models","H. Xu; E. G. Bazavan; A. Zanfir; W. T. Freeman; R. Sukthankar; C. Sminchisescu",Google Research; Google Research; Google Research; Google Research; Google Research; Google Research,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","6183","6192","We present a statistical, articulated 3D human shape modeling pipeline, within a fully trainable, modular, deep learning framework. Given high-resolution complete 3D body scans of humans, captured in various poses, together with additional closeups of their head and facial expressions, as well as hand articulation, and given initial, artist designed, gender neutral rigged quad-meshes, we train all model parameters including non-linear shape spaces based on variational auto-encoders, pose-space deformation correctives, skeleton joint center predictors, and blend skinning functions, in a single consistent learning loop. The models are simultaneously trained with all the 3d dynamic scan data (over 60,000 diverse human configurations in our new dataset) in order to capture correlations and ensure consistency of various components. Models support facial expression analysis, as well as body (with detailed hand) shape and pose estimation. We provide fully train-able generic human models of different resolutions- the moderate-resolution GHUM consisting of 10,168 vertices and the low-resolution GHUML(ite) of 3,194 vertices-, run comparisons between them, analyze the impact of different components and illustrate their reconstruction from image data. The models will be available for research.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00622","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157563","","Shape;Three-dimensional displays;Solid modeling;Joints;Pipelines;Head","image coding;image resolution;image scanners;learning (artificial intelligence);pose estimation;statistical analysis","articulated pose models;3D human shape modeling pipeline;fully trainable learning framework;modular learning framework;deep learning framework;hand articulation;nonlinear shape spaces;pose-space deformation correctives;skeleton joint center predictors;single consistent learning loop;facial expression analysis;trainable generic human models;3D dynamic scan data;variational autoencoders;neutral rigged quadmeshes;high-resolution complete 3D body scanning;3D human shape generation;GHUM;GHUML;blend skinning function","","51","1","44","","5 Aug 2020","","","IEEE","IEEE Conferences"
"Parallel planning: a new motion planning framework for autonomous driving","L. Chen; X. Hu; W. Tian; H. Wang; D. Cao; F. -Y. Wang","Sun Yat-Sen University, Guangzhou, Guangdong, CN; Hubei University, Wuhan, CN; Karlsruher Institut fur Technologie, Karlsruhe, Baden-WÃ¼rttemberg, DE; University of Waterloo, Waterloo, ON, CA; University of Waterloo, Waterloo, ON, CA; Institute of Automation Chinese Academy of Sciences, Beijing, Beijing, CN","IEEE/CAA Journal of Automatica Sinica","3 Jan 2019","2019","6","1","236","246","Motion planning is one of the most significant technologies for autonomous driving. To make motion planning models able to learn from the environment and to deal with emergency situations, a new motion planning framework called as “parallel planning” is proposed in this paper. In order to generate sufficient and various training samples, artificial traffic scenes are firstly constructed based on the knowledge from the reality. A deep planning model which combines a convolutional neural network (CNN) with the Long Short-Term Memory module (LSTM) is developed to make planning decisions in an end-toend mode. This model can learn from both real and artificial traffic scenes and imitate the driving style of human drivers. Moreover, a parallel deep reinforcement learning approach is also presented to improve the robustness of planning model and reduce the error rate. To handle emergency situations, a hybrid generative model including a variational auto-encoder (VAE) and a generative adversarial network (GAN) is utilized to learn from virtual emergencies generated in artificial traffic scenes. While an autonomous vehicle is moving, the hybrid generative model generates multiple video clips in parallel, which correspond to different potential emergency scenarios. Simultaneously, the deep planning model makes planning decisions for both virtual and current real scenes. The final planning decision is determined by analysis of real observations. Leveraging the parallel planning approach, the planner is able to make rational decisions without heavy calculation burden when an emergency occurs.","2329-9274","","10.1109/JAS.2018.7511186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405356","","Planning;Solid modeling;Autonomous vehicles;Training;Machine learning;Data models","convolutional neural nets;image processing;learning (artificial intelligence);planning (artificial intelligence);recurrent neural nets;road vehicles;traffic engineering computing","motion planning framework;artificial traffic scenes;deep planning model;planning decisions;driving style;parallel deep reinforcement learning approach;hybrid generative model;generative adversarial network;parallel planning approach;autonomous driving;motion planning models;long short-term memory module;convolutional neural network;CNN;LSTM;variational autoencoder;parallel planning framework","","50","","","","6 Jul 2018","","","IEEE","IEEE Journals"
"Make a Face: Towards Arbitrary High Fidelity Face Manipulation","S. Qian; K. -Y. Lin; W. Wu; Y. Liu; Q. Wang; F. Shen; C. Qian; R. He","Chinese University of Hong Kong, Hong Kong, China; Peking university; Tsinghua University. SenseTime Research; University of Electronic Science and Technology of China, Chengdu, China; Sensetime; UESTC; SenseTime; Institute of Automation. Chinese Academy of Sciences","2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","10032","10041","Recent studies have shown remarkable success in face manipulation task with the advance of GANs and VAEs paradigms, but the outputs are sometimes limited to low-resolution and lack of diversity. In this work, we propose Additive Focal Variational Auto-encoder (AF-VAE), a novel approach that can arbitrarily manipulate high-resolution face images using a simple yet effective model and only weak supervision of reconstruction and KL divergence losses. First, a novel additive Gaussian Mixture assumption is introduced with an unsupervised clustering mechanism in the structural latent space, which endows better disentanglement and boosts multi-modal representation with external memory. Second, to improve the perceptual quality of synthesized results, two simple strategies in architecture design are further tailored and discussed on the behavior of Human Visual System (HVS) for the first time, allowing for fine control over the model complexity and sample quality. Human opinion studies and new state-of-the-art Inception Score (IS) / Frechet Inception Distance (FID) demonstrate the superiority of our approach over existing algorithms, advancing both the fidelity and extremity of face manipulation task.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.01013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9008287","","Face;Task analysis;Gallium nitride;Training;Image resolution;Additives;Generative adversarial networks","face recognition;Gaussian processes;image coding;image representation;image resolution;image sampling;mixture models;unsupervised learning","arbitrary high fidelity face manipulation;face manipulation task;additive focal variational autoencoder;AF-VAE;high-resolution face images;additive Gaussian mixture assumption;unsupervised clustering mechanism;structural latent space;model complexity;KL divergence losses;GAN;human visual system;HVS;inception score;Frechet inception distance;FID","","31","","56","","27 Feb 2020","","","IEEE","IEEE Conferences"
"Fully-Hierarchical Fine-Grained Prosody Modeling For Interpretable Speech Synthesis","G. Sun; Y. Zhang; R. J. Weiss; Y. Cao; H. Zen; Y. Wu",University of Cambridge; Google; Google; Google; Google; Google,"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","6264","6268","This paper proposes a hierarchical, fine-grained and interpretable latent variable model for prosody based on the Tacotron 2 text-to-speech model. It achieves multi-resolution modeling of prosody by conditioning finer level representations on coarser level ones. Additionally, it imposes hierarchical conditioning across all latent dimensions using a conditional variational auto-encoder (VAE) with an auto-regressive structure. Evaluation of reconstruction performance illustrates that the new structure does not degrade the model while allowing better interpretability. Interpretations of prosody attributes are provided together with the comparison between word-level and phone-level prosody representations. Moreover, both qualitative and quantitative evaluations are used to demonstrate the improvement in the disentanglement of the latent dimensions.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9053520","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9053520","text-to-speech;Tacotron 2;fine-grained VAE;hierarchical","Conferences;Signal processing;Acoustics;Speech synthesis;Level control","regression analysis;speech processing;speech recognition;speech synthesis","coarser level;hierarchical conditioning;latent dimensions;conditional variational autoencoder;autoregressive structure;prosody attributes;phone-level prosody representations;fine-grained prosody modeling;interpretable speech synthesis;hierarchical model;fine-grained model;interpretable latent variable model;Tacotron 2 text-to-speech model;multiresolution modeling;finer level representation conditioning;reconstruction performance;word-level prosody representations","","24","","39","","9 Apr 2020","","","IEEE","IEEE Conferences"
"End-to-End Learnt Image Compression via Non-Local Attention Optimization and Improved Context Modeling","T. Chen; H. Liu; Z. Ma; Q. Shen; X. Cao; Y. Wang","School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; Electrical and Computer Engineering Department, New York University, New York, NY, USA","IEEE Transactions on Image Processing","25 Feb 2021","2021","30","","3179","3191","This article proposes an end-to-end learnt lossy image compression approach, which is built on top of the deep nerual network (DNN)-based variational auto-encoder (VAE) structure with Non-Local Attention optimization and Improved Context modeling (NLAIC). Our NLAIC 1) embeds non-local network operations as non-linear transforms in both main and hyper coders for deriving respective latent features and hyperpriors by exploiting both local and global correlations, 2) applies attention mechanism to generate implicit masks that are used to weigh the features for adaptive bit allocation, and 3) implements the improved conditional entropy modeling of latent features using joint 3D convolutional neural network (CNN)-based autoregressive contexts and hyperpriors. Towards the practical application, additional enhancements are also introduced to speed up the computational processing (e.g., parallel 3D CNN-based context prediction), decrease the memory consumption (e.g., sparse non-local processing) and reduce the implementation complexity (e.g., a unified model for variable rates without re-training). The proposed model outperforms existing learnt and conventional (e.g., BPG, JPEG2000, JPEG) image compression methods, on both Kodak and Tecnick datasets with the state-of-the-art compression efficiency, for both PSNR and MS-SSIM quality measurements. We have made all materials publicly accessible at https://njuvision.github.io/NIC for reproducible research.","1941-0042","","10.1109/TIP.2021.3058615","National Natural Science Foundation of China(grant numbers:62022038); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359473","Learnt image compression;non-local network;attention mechanism;conditional probability prediction;variable-rate model","Image coding;Context modeling;Three-dimensional displays;Transforms;Transform coding;Correlation;Complexity theory","autoregressive processes;convolutional neural nets;data compression;deep learning (artificial intelligence);entropy codes;image coding;image enhancement;optimisation","end-to-end learnt lossy image compression approach;nonlocal network operations;nonlinear transforms;attention mechanism;improved conditional entropy modeling;parallel 3D CNN-based context prediction;nonlocal processing;deep nerual network-based variational autoencoder structure;JPEG2000;BPG;Tecnick datasets;Kodak datasets;3D convolutional neural networ;nonlocal attention optimization and improved context modeling;NLAIC;PSNR;MS-SSIM quality measurements","","23","","56","IEEE","19 Feb 2021","","","IEEE","IEEE Journals"
"Deep Classification-driven Domain Adaptation for Cross-Modal Driver Behavior Recognition","S. Reiß; A. Roitberg; M. Haurilet; R. Stiefelhagen","Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Germany; Karlsruhe Institute of Technology, Germany; Karlsruhe Institute of Technology, Germany","2020 IEEE Intelligent Vehicles Symposium (IV)","8 Jan 2021","2020","","","1042","1047","We encounter a wide range of obstacles when integrating computer vision algorithms into applications inside the vehicle cabin, e.g. variations in illumination, sensor-type and -placement. Thus, designing domain-invariant representations is crucial for employing such models in practice. Still, the vast majority of driver activity recognition algorithms are developed under the assumption of a static domain, i.e. an identical distribution of training- and test data. In this work, we aim to bring driver monitoring to a setting, where domain shifts can occur at any time and explore generative models which learn a shared representation space of the source and target domain. First, we formulate the problem of unsupervised domain adaptation for driver activity recognition, where a model trained on labeled examples from the source domain (i.e. color images) is intended to adjust to a different target domain (i.e. infrared images) where only unlabeled data is available during training. To address this problem, we leverage current progress in image-to-image translation and adopt multiple strategies for learning a joint latent space of the source and target distribution and a mapping function to the domain of interest. As our long-term goal is a robust cross-domain classification, we enhance a Variational Auto-Encoder (VAE) for image translation with a classification-driven optimization strategy. Our model for classification-driven domain transfer leads to the best cross-domain recognition results and outperforms a conventional classification approach in color-to-infrared recognition by 13.75%.","2642-7214","978-1-7281-6673-5","10.1109/IV47402.2020.9304782","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9304782","","Vehicles;Training;Generative adversarial networks;Data models;Adaptation models;Image recognition;Generators","computer vision;computerised monitoring;driver information systems;human factors;image classification;image colour analysis;infrared imaging;neural nets;object recognition;optimisation;unsupervised learning","deep classification-driven domain adaptation;cross-modal driver behavior recognition;computer vision algorithms;sensor-type;domain-invariant representations;driver activity recognition algorithms;static domain;identical distribution;driver monitoring;domain shifts;generative models;shared representation space;unsupervised domain adaptation;source domain;infrared images;unlabeled data;image-to-image translation;joint latent space;target distribution;robust cross-domain classification;classification-driven optimization strategy;classification-driven domain transfer;cross-domain recognition results;color-to-infrared recognition;variational autoencoder","","2","","22","IEEE","8 Jan 2021","","","IEEE","IEEE Conferences"
"PatchVAE: Learning Local Latent Codes for Recognition","K. Gupta; S. Singh; A. Shrivastava","University of Maryland, College Park; Google Research; University of Maryland, College Park","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","4745","4754","Unsupervised representation learning holds the promise of exploiting large amounts of unlabeled data to learn general representations. A promising technique for unsupervised learning is the framework of Variational Auto-encoders (VAEs). However, unsupervised representations learned by VAEs are significantly outperformed by those learned by supervised learning for recognition. Our hypothesis is that to learn useful representations for recognition the model needs to be encouraged to learn about repeating and consistent patterns in data. Drawing inspiration from the mid-level representation discovery work, we propose PatchVAE, that reasons about images at patch level. Our key contribution is a bottleneck formulation that encourages mid-level style representations in the VAE framework. Our experiments demonstrate that representations learned by our method perform much better on the recognition tasks compared to those learned by vanilla VAEs.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00480","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156941","","Task analysis;Data models;Image reconstruction;Visualization;Standards;Computer architecture;Decoding","image coding;image recognition;image representation;learning (artificial intelligence);supervised learning;unsupervised learning","learning local latent codes;variational autoencoders;midlevel style representation discovery;vanilla VAE framework;supervised learning;unsupervised representation learning;PatchVAE","","2","","38","","5 Aug 2020","","","IEEE","IEEE Conferences"
"Self-critical Learning of Influencing Factors for Trajectory Prediction using Gated Graph Convolutional Network","N. Bhujel; Y. W. Yun; H. Wang; V. P. Dwivedi","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Institute for Infocomm Research, A*STAR, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore","2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","16 Dec 2021","2021","","","7904","7910","Forecasting future trajectories of multiple pedestrians in a crowded environment is a challenging problem due to the complex interactions among the pedestrians. The interactions can be asymmetric and their influences may vary over time. Moreover, each pedestrian can exhibit different behavior at any given time and context and thus they may have multiple future possible trajectories. In this work, we present a Gated Graph Convolutional Network (GatedGCN) based trajectory prediction model that explicitly deal with the asymmetric influences among the adjacent pedestrians through edge-wise gating mechanism. Through GatedGCN only, an overall average improvement of 16% and 18% was achieved on the two performance metrics over the state-of-the-art trajectory forecasting methods. Next, we tackle the problem of learning multi-modal distributions of each pedestrian trajectory using variational auto-encoders (VAEs). However, trajectories sampled from the learned distribution usually ignore the factors affecting the pedestrian motion such as collision avoidance and the target destination. While many of the existing approaches focus on learning such factors during the trajectory encoding process, we proposed a novel self-critical learning approach based on Actor-Critic framework to learn such factors during the trajectory generation process. We empirically show that our method creates fewer number of collisions than the existing methods on popular trajectory forecasting benchmarks.","2153-0866","978-1-6654-1714-3","10.1109/IROS51168.2021.9636641","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9636641","","Measurement;Logic gates;Predictive models;Benchmark testing;Encoding;Trajectory;Collision avoidance","convolutional neural nets;deep learning (artificial intelligence);graph theory;pedestrians;traffic engineering computing","gated graph convolutional network;GatedGCN;adjacent pedestrians;edge-wise gating mechanism;trajectory forecasting;pedestrian trajectory;pedestrian motion;trajectory encoding process;trajectory generation process;self-critical learning;trajectory prediction;influencing factors;variational autoencoders;VAE;actor-critic framework","","","","26","IEEE","16 Dec 2021","","","IEEE","IEEE Conferences"
"Data Augmentation for Human Motion Prediction","T. Maeda; N. Ukita","Toyota Technological Institute, Nagoya, Japan; Toyota Technological Institute, Nagoya, Japan","2021 17th International Conference on Machine Vision and Applications (MVA)","19 Aug 2021","2021","","","1","5","Human motion prediction is seldom deployed to real-world tasks due to difficulty in collecting a huge amount of motion data. We propose two motion data augmentation approaches using Variational AutoEn-coder (VAE) and Inverse Kinematics (IK). Our VAE-based generative model with adversarial training and sampling near samples generates various motions even with insufficient original motion data. Our IK-based augmentation scheme allows us to semi-automatically generate a variety of motions. Furthermore, we correct unrealistic artifacts in the augmented motions. As a result, our method outperforms previous noise-based motion augmentation methods.","","978-4-901122-20-7","10.23919/MVA51890.2021.9511368","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9511368","","Training;Machine vision;Data acquisition;Humanoid robots;Kinematics;Animation;Data models","data handling;image motion analysis;motion estimation;neural nets","human motion prediction;VAE-based generative model;adversarial training;IK-based augmentation scheme;augmented motions;noise-based motion augmentation;motion data augmentation;inverse kinematics;Variational AutoEncoder","","","","29","","19 Aug 2021","","","IEEE","IEEE Conferences"
"DPSRGAN: Dilation Patch Super-Resolution Generative Adversarial Networks","K. Mirchandani; K. Chordiya","Department of Electronics and Telecommunication Engineering, Pune Institute of Computer Technology, Pune, India; Department of Computer Engineering, Pune Institute of Computer Technology, Pune, India","2021 6th International Conference for Convergence in Technology (I2CT)","10 May 2021","2021","","","1","7","Single Image Super-Resolution (SISR) has proven itself as a highly challenging and ill-posed problem. Multiple methods have been applied to this problem in the past, with varying degrees of success. Recently, methods using deep learning such as Generative Adversarial Networks (GAN) and Variational Auto-Encoders (VAE) in particular have proven to be extremely effective. However, most of the present methods either create a blurry output, lacking fine details, or use extremely heavy models to achieve better results. We introduce a novel, lightweight GAN architecture for 4× super-resolution of images, which builds on previous methods, showing high quality of features both qualitatively and quantitatively. To achieve this, we use dilated convolutions in our generator architecture, a Markovian discriminator, a modified loss function and a training process more typical of a conditional GAN (cGAN). For testing our results qualitatively, we use Mean Opinion Score (MOS). The obtained MOS show the effectiveness of our model at generating visually superior images. Our code is available at https://www.github.com/kushalchordiya216/Super-Resolution.","","978-1-7281-8876-8","10.1109/I2CT51068.2021.9417903","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9417903","Super-Resolution;Generative Adversarial Network;SRGAN","Training;Measurement;Deep learning;Convolutional codes;Superresolution;Benchmark testing;Generative adversarial networks","deep learning (artificial intelligence);feature extraction;image resolution;image restoration;Markov processes;neural net architecture","single image super resolution;deep learning;lightweight GAN architecture;dilated convolutions;conditional GAN;dilation patch super resolution generative adversarial networks;DPSRGAN;variational autoencoders;image resolution;Markovian discriminator","","","","31","","10 May 2021","","","IEEE","IEEE Conferences"
"On Explainability and Sensor-Adaptability of a Robot Tactile Texture Representation Using a Two-Stage Recurrent Networks","R. Gao; T. Tian; Z. Lin; Y. Wu","Robotics & Autonomous Systems Department, A*STAR Insti-tute for Infocomm Research, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Robotics & Autonomous Systems Department, A*STAR Insti-tute for Infocomm Research, Singapore","2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","16 Dec 2021","2021","","","1296","1303","The ability to simultaneously distinguish objects, materials, and their associated physical properties is one fundamental function of the sense of touch. Recent advances in the development of tactile sensors and machine learning techniques allow more accurate and complex modelling of robotic tactile sensations. However, many state-of-the-art (SotA) approaches focus solely on constructing black-box models to achieve ever higher classification accuracy and fail to adapt across sensors with unique spatial-temporal data formats. In this work, we propose an Explainable and Sensor-Adaptable Recurrent Networks (ExSARN) model for tactile texture representation. The ExSARN model consists of a two-stage recurrent networks fed by a sensor-specific header network. The first stage recurrent network emulates our human touch receptors and decouples sensor-specific tactile sensations into different frequency response bands, while the second stage codes the overall temporal signature as a variational recurrent autoen-coder. We infuse the latent representation with ternary labels to qualitatively represent texture properties (e.g. roughness and stiffness), which facilitates representation learning and provide explainability to the latent space. The ExSARN model is tested on texture datasets collected with two different tactile sensors. Our results show that the proposed model not only achieves higher accuracy, but also provides adaptability across sensors with different sampling frequencies and data formats. The addition of the crudely obtained qualitative property labels offers a practical approach to enhance the interpretability of the latent space, facilitate property inference on unseen materials, and improve the overall performance of the model.","2153-0866","978-1-6654-1714-3","10.1109/IROS51168.2021.9636380","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9636380","","Representation learning;Training;Adaptation models;Neurons;Tactile sensors;Data models;Robustness","neurocontrollers;recurrent neural nets;robot programming;tactile sensors;touch (physiological)","human touch receptors;decouples sensor;variational recurrent autoencoder;latent representation;texture properties;representation learning;latent space;ExSARN model;texture datasets;tactile sensors;sampling frequencies;robot tactile texture representation;two-stage recurrent networks;machine learning techniques;robotic tactile sensations;black-box models;spatial-temporal data formats;sensor-specific header network;explainable and sensor-adaptable recurrent networks","","","","31","IEEE","16 Dec 2021","","","IEEE","IEEE Conferences"
"Social Transformer: A Pedestrian Trajectory Prediction Method based on Social Feature Processing Using Transformer","F. Wen; M. Li; R. Wang","School of Computer Science Wuhan University, Wuhan, China; School of Computer Science Wuhan University, Wuhan, China; School of Computer Science Wuhan University, Wuhan, China","2022 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2022","2022","","","1","7","In pedestrian trajectory prediction, the prediction accuracy depends largely on the consideration of the impact of social relations on the prediction object. Social pooling and graph neural networks (GNN) are two traditional social feature processing methods, they process sparse and nonuniform social features into more intensive and uniform information. In this paper, the Social Transformer Network (STNet) was proposed based on the GNN, which is a graph attention network. After a conditional variational auto-encoder (CVAE)-based preprocessing network provided a destination prediction, a transformer network was used to process the social feature data of the past trajectory and destination information. The transformer network was based on the self-attention mechanism, and it can assign different attention weights to different social features so that more attention is paid to the social relations with greater impacts on the pedestrian's trajectory. In this paper, STNet was tested on the ETH/UCY datasets. The results showed that average displacement error (ADE) was reduced by 17.2% and final displacement error (FDE) was reduced by 14.6%, indicating that the STNet improved the prediction accuracy.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9891949","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9891949","Trajectory prediction;Self-attention;Trans-former;Self-driving","Prediction methods;Transformers;Graph neural networks;Trajectory","deep learning (artificial intelligence);graph theory;pedestrians;social sciences computing","pedestrian trajectory prediction;social relations;graph neural networks;GNN;STNet;graph attention network;destination prediction;self-attention mechanism;social transformer network;conditional variational autoencoder-based preprocessing network;ETH dataset;UCY dataset;CVAE-based preprocessing network;social pooling;social feature data processing","","","","14","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"Instance-Level Semantic Alignment for Zero-Shot Cross-Modal Retrieval","K. Wang; Y. Wang; X. Xu; Z. Cao; X. Cai","Center for Future Media & School of Computer Science and Engineering, University of Electronic Science and Technology of China, China; Center for Future Media & School of Computer Science and Engineering, University of Electronic Science and Technology of China, China; Center for Future Media & School of Computer Science and Engineering, University of Electronic Science and Technology of China, China; Meituan; Meituan","2022 IEEE International Conference on Multimedia and Expo (ICME)","26 Aug 2022","2022","","","1","6","Zero-shot Cross-Modal Retrieval (ZS-CMR) is challenging due to the heterogeneous distributions across different modalities and the inconsistent semantics across seen and unseen classes. Previous methods usually perform class-level semantic alignment of data from different modalities by introducing auxiliary word embeddings of class labels, which have a fatal limitation as the learning of class-level information will lead to the ignorance of intra-modal variance. To solve this problem, we propose our Instance-Level Semantic Alignment (ILSA) method to make full use of the instance-level information. We use two disentanglement variational auto-encoders to decompose the data from two modalities into modal specific and modal invariant features. With an instance-level semantic features extractor and a distribution generator, ILSA could generate more appropriate distributions by the learned instance-level semantic features, without any auxiliary knowledge. We perform the experiment on six widely used datasets on two scenarios of ZS-CMR, the results show that our method establishes the new state-of-the-art performance on all datasets.","1945-788X","978-1-6654-8563-0","10.1109/ICME52920.2022.9860026","National Natural Science Foundation of China(grant numbers:61976049,62072080); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9860026","Zero-shot Learning;Cross-Modal Retrieval;Instance-Level Information;Semantic Alignment","Semantics;Feature extraction;Generators","feature extraction;image retrieval;information retrieval;neural nets;word processing","ZS-CMR;zero-shot cross-modal retrieval;class-level semantic alignment;class-level information;intra-modal variance;instance-level information;modal invariant features;instance-level semantic alignment method;instance-level semantic feature extractor;variational autoencoders;auxiliary word embeddings","","","","18","IEEE","26 Aug 2022","","","IEEE","IEEE Conferences"
"An Integrated Multi-Omics Approach for AMR Phenotype Prediction of Gut Microbiota","P. Gao; Z. Chen; D. Wang; M. Huang; N. Ono; M. Altaf-Ul-Amin; S. Kanaya","Graduate School of Science and Technology, Nara Insitute of Science and Technology, Takayamacho 8916-5, Ikoma, Japan; Graduate School of Science and Technology, Nara Insitute of Science and Technology, Takayamacho 8916-5, Ikoma, Japan; Graduate School of Science and Technology, Nara Insitute of Science and Technology, Takayamacho 8916-5, Ikoma, Japan; Graduate School of Science and Technology, Nara Insitute of Science and Technology, Takayamacho 8916-5, Ikoma, Japan; Data Science Center, Nara Insitute of Science and Technology, Takayamacho 8916-5, Ikoma, Japan; Graduate School of Science and Technology, Nara Insitute of Science and Technology, Takayamacho 8916-5, Ikoma, Japan; Data Science Center, Nara Insitute of Science and Technology, Takayamacho 8916-5, Ikoma, Japan","2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","14 Jan 2022","2021","","","2211","2216","The gut microbiota is crucial for human physiology and susceptibility to diseases. Knowing the AMR phenotype canfacilitate the understanding of the impact of antibiotics administration on the gut microbiota. Nowadays, whole-genome sequencing for antibiotic susceptibility testing (WGS-AST) is widely used in clinical microbiology to predict the AMR phenotype. To release the limitations of the genomic information and improve the WGS-AST prediction, we propose an integrated multi-omics approach, employing a deep generative neural network (VAE: variational auto-encoder). We evaluate the proposed approach by two machine learning techniques (i.e., K-means for clustering and Random Forest for classification). Our evaluation results show that the integrated multi-omics approach achieves relatively better performance than the conventional WGS-AST. Moreover, the integrated multi-omics approach is able to visually reveal AMR phenotype of the gutmicrobiota via antibacterial spectrum. Our work provides evidence that multi-omics information is useful to enhance the WGS-AST prediction.","","978-1-6654-0126-5","10.1109/BIBM52615.2021.9669397","Ministry of Education; National Bioscience Database Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669397","gut microbiota;antibiotic resistance;genomics;metabolomics;machine learning","Sequential analysis;Microbiology;Neural networks;Genomics;Network architecture;Physiology;Bioinformatics","bioinformatics;data analysis;deep learning (artificial intelligence);diseases;genomics;medicine;microorganisms;neural nets;patient care","integrated multiomics approach;multiomics information;WGS-AST prediction;AMR phenotype prediction;gut microbiota;human physiology;antibiotic susceptibility testing;AMR phenotype;antibiotics administration;whole-genome sequencing;clinical microbiology;deep generative neural network;variational autoencoder;machine learning techniques;random forest","","","","21","IEEE","14 Jan 2022","","","IEEE","IEEE Conferences"
"Swarm Intelligence Optimized Generative Model for Network Performance Prediction","C. Jiang; H. Wang; J. Yan; X. Li; G. Li","School of Computer Science and Technology, Shandong University, Jinan, Shandong Province, China; School of Computer Science and Technology, Shandong University, Jinan, Shandong Province, China; School of Computer Science and Technology, Shandong University, Jinan, Shandong Province, China; School of Computer Science and Technology, Shandong University, Jinan, Shandong Province, China; School of Computer Science and Technology, Shandong University, Jinan, Shandong Province, China","2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)","3 Oct 2019","2019","","","1311","1319","Network state prediction methods are widely used currently to evaluate network performance instead of monitors or detectors because of its low-cost and timeliness. However, existing prediction methods are generally based on historical time-series data and insensitive to changes of external conditions. In this paper, based on the state-of-the-art deep generative model Conditional Variational Auto-Encoder, we propose a Network Performance Prediction method using Generative Model (NPGM). This method builds the distribution of network latency features according to historical data with traffic taken as condition. Generative model can deal with hidden variables when building the model which traditional methods cannot handle. Following the ideology of phase space reconstruction, we conceal the numerous factors and map the inherent properties of network into a hidden vector. In order to speed up training process, we optimize parameters of neural networks with our Self-adaptive Stochastic Particle Swarm Optimization (SPSO) instead of Gradient Descent (GD) algorithms. This approach applies self-adaptive coefficients and mutation operation, which improves training efficiency and searching accuracy. We propose a new criterion called Weighted Matrix Mean Absolute Percentage Error (WM-MAPE) to evaluate the predicting accuracy of latency matrices. We use real commercial backbone traffic data from the Center for Applied Internet Data Analysis database. Results on validation sets show that inference error of our approach is less than 50% of time-series-based methods and SPSO has a significantly better efficiency and convergence compared with GD and PSO algorithms.","","978-1-7281-2058-4","10.1109/HPCC/SmartCity/DSS.2019.00183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8855403","latency inference;generative model;hidden vector;self-adaptive coefficients;mutation","Conferences;High performance computing;Smart cities;Data science","computer network performance evaluation;gradient methods;learning (artificial intelligence);neural nets;particle swarm optimisation;stochastic processes","neural networks;network state prediction;time-series data;swarm intelligence optimized generative model;deep generative model conditional variational autoencoder;weighted matrix mean absolute percentage error;Center for Applied Internet Data Analysis database;network performance prediction method using generative model;self-adaptive stochastic particle swarm optimization;Web applications;data network","","","","25","","3 Oct 2019","","","IEEE","IEEE Conferences"
"Intelligent Fault Diagnosis of Rotating Machines Based on Wavelet Time-Frequency Diagram and Optimized Stacked Denoising Auto-Encoder","N. Jia; Y. Cheng; Y. Liu; Y. Tian","Chongqing University of Technology, Chongqing, China; Chongqing University of Technology, Chongqing, China; Chongqing University of Technology, Chongqing, China; Chongqing University of Technology, Chongqing, China","IEEE Sensors Journal","1 Sep 2022","2022","22","17","17139","17150","When a stacked denoising auto-encoder (SDAE) manually sets several parameters, the gradient of neuron weight becomes dispersed, reducing the ability to retrieve sensitive fault feature information from a bearing vibration signal under multiple working conditions and strong noise. A bearing health monitoring and defect diagnostic model based on variational mode decomposition (VMD) combined with continuous wavelet transform (CWT) and SDAE optimized by sparrow search algorithm (SSA) is presented to tackle this problem. The wavelet time-frequency diagram is obtained by VMD and CWT, which maps the fault characteristic information to different local positions in time and scale, and then the wavelet time-frequency diagrams are input into the SDAE for in-depth training. To achieve the ideal structure of SDAE and increase the feature extraction capabilities of SDAE for weak signals, SSA is utilized for the global combination and adaptive selection of several SDAE parameters. The bearing failure diagnostic model based on VMD-CWT-SSA-SDAE outperforms BPNN, SVM, the traditional SDAE, GA-SDAE, PSO-SDAE, and SSA-DBN in diagnosis accuracy, generalization performance, and anti-noise performance when tested on various data sets.","1558-1748","","10.1109/JSEN.2022.3193943","Chongqing Research Fund(grant numbers:cstc2016jcyjA0497); Graduate Student Innovation Program of Chongqing University of Technology(grant numbers:clgycx 20202088,CYS22653); Graduate Student Innovation Program of Chongqing(grant numbers:CYS21464); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9846870","Rotating machines;fault diagnosis;the wavelet time-frequency diagram;sparrow search algorithm;stacked denoising auto-encoder","Feature extraction;Time-frequency analysis;Fault diagnosis;Continuous wavelet transforms;Wavelet transforms;Optimization;Vibrations","condition monitoring;fault diagnosis;feature extraction;information retrieval;machine bearings;neural nets;search problems;signal denoising;support vector machines;vibrational signal processing;vibrations;wavelet transforms","bearing failure diagnostic model;VMD-CWT-SSA-SDAE;GA-SDAE;PSO-SDAE;intelligent fault diagnosis;wavelet time-frequency diagram;bearing vibration signal;bearing health monitoring;continuous wavelet;stacked denoising autoencoder optimization;sensitive fault feature information retrieval;continuous wavelet transform;CWT;rotating machines;variational mode decomposition;sparrow search algorithm;feature extraction","","","","31","IEEE","1 Aug 2022","","","IEEE","IEEE Journals"
"Weighted Nonlinear Dynamic System for Deep Extraction of Nonlinear Dynamic Latent Variables and Industrial Application","B. Shen; Z. Ge","Peng Cheng Laboratory, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China","IEEE Transactions on Industrial Informatics","23 Feb 2021","2021","17","5","3090","3098","Soft sensor plays an increasingly important role in modern industrial processes for estimating key quality variables which are hard to measure. With the development of deep learning technologies, soft sensors based on the deep learning methods have drawn great attention. Aiming to predict key quality variables, a supervised weighted nonlinear dynamic system (WNDS) model aided by the maximal information coefficient (MIC) is proposed in this article. The variational autoencoder is employed into the system for extracting nonlinear dynamic features. The supervised WNDS model can simultaneously analyze the correlations between variables and the relationships between historical samples and present samples. Furthermore, the proposed method is extended to a semisupervised form, in order to handle the imbalanced numbers between routinely recorded process data and limited labeled quality data. The prediction performance is validated by an industrial case.","1941-0050","","10.1109/TII.2020.3027746","National Key Research and Development Program of China(grant numbers:2018YFC0808600); National Natural Science Foundation of China(grant numbers:61833014,61722310); Natural Science Foundation of Zhejiang Province(grant numbers:LR18F030001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9208739","Maximal information coefficient (MIC);semisupervised learning;soft sensor;supervised weighted nonlinear dynamic system (WNDS);variational auto-encoder (VAE)","Feature extraction;Nonlinear dynamical systems;Correlation;Microwave integrated circuits;Data models;Informatics;Machine learning","control engineering computing;learning (artificial intelligence);process control;process monitoring;production engineering computing;quality control;sensors","labeled quality data;industrial case;deep extraction;nonlinear dynamic latent variables;industrial application;soft sensor;modern industrial processes;key quality variables;deep learning technologies;deep learning methods;supervised weighted nonlinear dynamic system model;maximal information coefficient;nonlinear dynamic features;supervised WNDS model;routinely recorded process data","","12","","29","IEEE","29 Sep 2020","","","IEEE","IEEE Journals"
"Concept Saliency Maps to Visualize Relevant Features in Deep Generative Models","L. Brocki; N. C. Chung","Institute of Informatics, University of Warsaw, Warsaw, Poland; NIH BD2K Center of Excellence for Biomedical Computing, University of California, Los Angeles, Los Angeles, United States","2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)","17 Feb 2020","2019","","","1771","1778","Evaluating, explaining, and visualizing high-level concepts in generative models, such as variational autoencoders (VAEs), is challenging in part due to a lack of known prediction classes that are required to generate saliency maps in supervised learning. While saliency maps may help identify relevant features (e.g., pixels) in the input for classification tasks of deep neural networks, similar frameworks are understudied in unsupervised learning. Therefore, we introduce a new method of obtaining saliency maps for latent representations of known or novel high-level concepts, often called concept vectors in generative models. Concept scores, analogous to class scores in classification tasks, are defined as dot products between concept vectors and encoded input data, which can be readily used to compute the gradients. The resulting concept saliency maps are shown to highlight input features deemed important for high-level concepts. Our method is applied to the VAE's latent space of CelebA dataset in which known attributes such as ""smiles"" and ""hats"" are used to elucidate relevant facial features. Furthermore, our application to spatial transcriptomic (ST) data of a mouse ol-factory bulb demonstrates the potential of latent representations of morphological layers and molecular features in advancing our understanding of complex biological systems. By extending the popular method of saliency maps to generative models, the proposed concept saliency maps help improve interpretability of latent variable models in deep learning.","","978-1-7281-4550-1","10.1109/ICMLA.2019.00287","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8999235","saliency maps, unsupervised learning, spatial transcriptomics, variational autoenconder","Unsupervised learning;Predictive models;Computational modeling;Biological system modeling;Task analysis;Neurons;Neural networks","computer vision;face recognition;feature extraction;image classification;learning (artificial intelligence);neural nets","latent representations;high-level concepts;concept vectors;classification tasks;facial features;latent variable models;deep learning;deep generative models;deep neural networks;concept saliency maps","","2","","31","","17 Feb 2020","","","IEEE","IEEE Conferences"
"A hyperbolic embedding for scale-free networks","X. Shen; W. Huang; J. Gong; Z. Sun","School of Science, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Science, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Science, Nanjing University of Posts and Telecommunications, Nanjing, China; Post Industry Technology Research and Development Center of the State Posts Bureau (Internet of Things Technology), Post Big Data Technology and Application Engineering Research Center of Jiangsu Province, Nanjing University of Posts and Telecommunications, Nanjing University of Posts and Telecommunications, Nanjing, China","2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)","15 Mar 2022","2021","","","679","685","Graph neural network, with its powerful learning ability, has become a cutting-edge method of processing ultra-large-scale network data. In order to polished up the representation accuracy of embedding, the key is to find the intrinsic geometric metric of the complex network. Since the real data is mostly scale-free network, the embedding accuracy of traditional models is still limited by the dimensionality of the euclidean space and computational complexity. Therefore, the hyperbolic embedding, whose metric properties conform to the power-law distribution and tree-like hierarchical structure of the complex network, will effectively approximates the latent low-dimensional manifold of the data distribution. This paper proposes an auto-encoder in hyperbolic space (HVGAE), taking full use of hyperbolic graph convolutional (HGCN) and the idea of variational autoencoder. Under the optimal combination of the encoder module, competitive results have been achieved in different real scenarios.","","978-1-6654-2174-4","10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00114","National Natural Science Foundation of China(grant numbers:61972208,61802200); Natural Science Foundation of Jiangsu Province(grant numbers:BK20180745); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9730212","hyperbolic space;graph convolution;variational graph auto-encoder;scale-free networks","Measurement;Geometry;Representation learning;Manifolds;Computational modeling;Complex networks;Data models","","","","","","34","IEEE","15 Mar 2022","","","IEEE","IEEE Conferences"
"Traffic Statistical Upper Limit Prediction from Flow Features in Network Provisioning","E. Takeshita; T. Kosugi; T. Yoshida","NTT Access Network Service Systems Laboratories, Tokyo, Japan; NTT Access Network Service Systems Laboratories, Tokyo, Japan; NTT Access Network Service Systems Laboratories, Tokyo, Japan","2021 IEEE Global Communications Conference (GLOBECOM)","2 Feb 2022","2021","","","1","6","Machine learning-based network traffic prediction has been a hot research topic in recent works. The majority of recently developed prediction models have employed Long Short-Term Memory (LSTM) to predict the traffic at a few steps in the future from the most recent past traffic. However, for network provisioning to plan the capacity of a facility in a few days or months, it is necessary to derive its statistical upper limit from the traffic prediction results of a larger number of time steps. This paper investigates the network provisioning to estimate the conditional probability density function (PDF) of traffic given the future conditions instead of the traffic prediction for each step. Specifically, the network provisioning estimates the PDF of traffic given the future flow feature data and predicts the upper limit of the confidence interval of the estimated PDF as the facility capacity. This paper proposes two PDF estimation models are based on Supervised-Variational AutoEncoder (SVAE) and Student-t-SVAE (t-SVAE). Especially to deal with the biased traffic caused by the mixed flows with different features, such as elephant and mice flows, the t-SVAE uses a heavy-tailed Student-t distribution as the predictive traffic distribution. Our experimental result confirms that t-SVAE-based prediction can perform the high accuracy of the statistical upper limit prediction for provisioning networks where flows with different features are mixed.","","978-1-7281-8104-2","10.1109/GLOBECOM46510.2021.9686035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9686035","Network Provisioning;Traffic Prediction;Density Estimation;Deep Learning;Variational Auto-Encoder","Training;Conferences;Estimation;Telecommunication traffic;Probability density function;Predictive models;Mice","statistical analysis;statistical distributions","machine learning-based network traffic prediction;network provisioning;traffic prediction results;conditional probability density function;PDF estimation models;predictive traffic distribution;t-SVAE-based prediction;traffic statistical upper limit prediction;long short-term memory","","","","13","IEEE","2 Feb 2022","","","IEEE","IEEE Conferences"
"Safe Driving of Autonomous Vehicles through State Representation Learning","A. Gupta; A. S. Khwaja; A. Anpalagan; L. Guan","Dept. of Electrical Computer and Biomedical Engineering, Ryerson University, Toronto, Canada; Dept. of Electrical Computer and Biomedical Engineering, Ryerson University, Toronto, Canada; Dept. of Electrical Computer and Biomedical Engineering, Ryerson University, Toronto, Canada; Dept. of Electrical Computer and Biomedical Engineering, Ryerson University, Toronto, Canada","2021 International Wireless Communications and Mobile Computing (IWCMC)","9 Aug 2021","2021","","","260","265","In this paper, we propose an environment perception framework for autonomous driving using state representation learning (SRL). Unlike existing Q-learning based methods for efficient environment perception and object detection, our proposed method takes the learning loss into account under deterministic as well as stochastic policy gradient. Through a combination of variational autoencoder (VAE), deep deterministic policy gradient (DDPG), and soft actor-critic (SAC), we focus on uninterrupted and reasonably safe autonomous driving without steering off the track for a considerable driving distance. To ensure the effectiveness of the scheme over a sustained period of time, we employ a reward-penalty based system where a higher negative penalty is associated with an unfavourable action and a comparatively lower positive reward is awarded for favourable actions. The results obtained through simulations on DonKey simulator show the effectiveness of our proposed method by examining the variations in policy loss, value loss, reward function, and cumulative reward for `VAE+DDPG' and `VAE+SAC' over the learning process.","2376-6506","978-1-7281-8616-0","10.1109/IWCMC51323.2021.9498960","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9498960","State representation learning;variational auto encoder;deep deterministic policy gradient;soft actor-critic;autonomous driving;Markov decision process","Wireless communication;Computational modeling;Object detection;Autonomous vehicles;Mobile computing","gradient methods;learning (artificial intelligence);object detection;road safety;traffic engineering computing","environment perception;object detection;learning loss;deep deterministic policy gradient;soft actor-critic;uninterrupted driving;reasonably safe autonomous driving;reward-penalty based system;safe driving;autonomous vehicles;state representation learning;stochastic policy gradient;VAE+DDPG;VAE+SAC","","","","15","","9 Aug 2021","","","IEEE","IEEE Conferences"
"VAE-Based Adversarial Multimodal Domain Transfer for Video-Level Sentiment Analysis","Y. Wang; J. Wu; K. Furumai; S. Wada; S. Kurihara","School of Science for Open and Environmental Systems, Keio University, Tokyo, Japan; Data Intelligence Division, KDDI Research Inc., Saitama, Japan; Data Intelligence Division, KDDI Research Inc., Saitama, Japan; Data Intelligence Division, KDDI Research Inc., Saitama, Japan; School of Science for Open and Environmental Systems, Keio University, Tokyo, Japan","IEEE Access","18 May 2022","2022","10","","51315","51324","Video-level sentiment analysis is a challenging task and requires systems to obtain discriminative multimodal representations that can capture difference in sentiments across various modalities. However, due to diverse distributions of various modalities and the unified multimodal labels are not always adaptable to unimodal learning, the distance difference between unimodal representations increases, and prevents systems from learning discriminative multimodal representations. In this paper, to obtain more discriminative multimodal representations that can further improve systems’ performance, we propose a VAE-based adversarial multimodal domain transfer (VAE-AMDT) and jointly train it with a multi-attention module to reduce the distance difference between unimodal representations. We first perform variational autoencoder (VAE) to make visual, linguistic and acoustic representations follow a common distribution, and then introduce adversarial training to transfer all unimodal representations to a joint embedding space. As a result, we fuse various modalities on this joint embedding space via the multi-attention module, which consists of self-attention, cross-attention and triple-attention for highlighting important sentimental representations over time and modality. Our method improves F1-score of the state-of-the-art by 3.6% on MOSI and 2.9% on MOSEI datasets, and prove its efficacy in obtaining discriminative multimodal representations for video-level sentiment analysis.","2169-3536","","10.1109/ACCESS.2022.3174215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9772490","Multimodal representation learning;domain adaptation;variational auto-encoder (VAE);adversarial training","Sentiment analysis;Training;Task analysis;Fuses;Visualization;Linguistics;Feature extraction","learning (artificial intelligence);natural language processing;text analysis","VAE-based adversarial multimodal domain transfer;video-level sentiment analysis;discriminative multimodal representations;unified multimodal labels;distance difference;unimodal representations increases;multiattention module;visual representations;linguistic representations;acoustic representations;joint embedding space;highlighting important sentimental representations","","","","37","CCBY","11 May 2022","","","IEEE","IEEE Journals"
"Extending Music Based On Emotion And Tonality Via Generative Adversarial Network","B. -W. Tseng; Y. -L. Shen; T. -S. Chi","Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","86","90","We propose a generative model for music extension in this paper. The model is composed of two classifiers, one for music emotion and one for music tonality, and a generative adversarial network (GAN). Therefore, it can generate symbolic music not only based on low level spectral and temporal characteristics, but also on high level emotion and tonality attributes of previously observed music pieces. The generative model works in a universal latent space constructed by the variational autoencoder (VAE) for representing music pieces. We conduct subjective listening tests and derive objective measures for performance evaluation. Experimental results show that the proposed model produces much smoother and more authentic music pieces than the baseline model in terms of all subjective and objective measures.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9413365","Ministry of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9413365","Music generation;variational auto-encoder;generative adversarial network;music emotion;tonality","Performance evaluation;Current measurement;Conferences;Music;Signal processing;Generative adversarial networks;Acoustic measurements","emotion recognition;music;neural nets","generative adversarial network;music extension;music emotion;music tonality;symbolic music;low level spectral;high level emotion;tonality attributes;generative model works;smoother music pieces;baseline model;VAE;GAN;authentic music pieces","","","","19","","13 May 2021","","","IEEE","IEEE Conferences"
"Learning Neural Representations for Network Anomaly Detection","V. L. Cao; M. Nicolau; J. McDermott","School of Computer Science, University College Dublin, 4 Dublin, Ireland; Quinn School of Business, University College Dublin, 4 Dublin, Ireland; Michael Smurfit Graduate Business School, University College Dublin, 4 Dublin, Ireland","IEEE Transactions on Cybernetics","7 May 2019","2019","49","8","3074","3087","This paper proposes latent representation models for improving network anomaly detection. Well-known anomaly detection algorithms often suffer from challenges posed by network data, such as high dimension and sparsity, and a lack of anomaly data for training, model selection, and hyperparameter tuning. Our approach is to introduce new regularizers to a classical autoencoder (AE) and a variational AE, which force normal data into a very tight area centered at the origin in the nonsaturating area of the bottleneck unit activations. These trained AEs on normal data will push normal points toward the origin, whereas anomalies, which differ from normal data, will be put far away from the normal region. The models are very different from common regularized AEs, sparse AE, and contractive AE, in which the regularized AEs tend to make their latent representation less sensitive to changes of the input data. The bottleneck feature space is now used as a new data representation. A number of one-class learning algorithms are used for evaluating the proposed models. The experiments testify that our models help these classifiers to perform efficiently and consistently on high-dimensional and sparse network datasets, even with relatively few training points. More importantly, the models can minimize the effect of model selection on these classifiers since their performance is insensitive to a wide range of hyperparameter settings.","2168-2275","","10.1109/TCYB.2018.2838668","Vietnam International Education Development; University College Dublin; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8386786","Anomaly detection;autoencoders (AEs);high dimension;latent representation;one-class classification (OCC)","Anomaly detection;Data models;Distributed databases;Computational modeling;Task analysis;Neural networks;Training","data structures;learning (artificial intelligence);neural nets;security of data","hyperparameter tuning;high-dimensional network datasets;sparse network datasets;one-class learning algorithms;data representation;input data;common regularized AEs;normal region;normal points;trained AEs;bottleneck unit activations;normal data;model selection;anomaly data;sparsity;network data;latent representation models;network anomaly detection;neural representations","","51","","50","IEEE","15 Jun 2018","","","IEEE","IEEE Journals"
"Proactive Content Caching for Internet-of-Vehicles based on Peer-to-Peer Federated Learning","Z. Yu; J. Hu; G. Min; H. Xu; J. Mills","Department of Computer Science, University of Exeter, UK; Department of Computer Science, University of Exeter, UK; Department of Computer Science, University of Exeter, UK; Department of Computer Science, University of Exeter, UK; Department of Computer Science, University of Exeter, UK","2020 IEEE 26th International Conference on Parallel and Distributed Systems (ICPADS)","25 Feb 2021","2020","","","601","608","To cope with the increasing content requests from emerging vehicular applications, caching contents at edge nodes is imperative to reduce service latency and network traffic on the Internet-of-Vehicles (IoV). However, the inherent characteristics of IoV, including the high mobility of vehicles and restricted storage capability of edge nodes, cause many difficulties in the design of caching schemes. Driven by the recent advancements in machine learning, learning-based proactive caching schemes are able to accurately predict content popularity and improve cache efficiency, but they need gather and analyse users' content retrieval history and personal data, leading to privacy concerns. To address the above challenge, we propose a new proactive caching scheme based on peer-to-peer federated deep learning, where the global prediction model is trained from data scattered at vehicles to mitigate the privacy risks. In our proposed scheme, a vehicle acts as a parameter server to aggregate the updated global model from peers, instead of an edge node. A dual-weighted aggregation scheme is designed to achieve high global model accuracy. Moreover, to enhance the caching performance, a Collaborative Filtering based Variational AutoEncoder model is developed to predict the content popularity. The experimental results demonstrate that our proposed caching scheme largely outperforms typical baselines, such as Greedy and Most Recently Used caching.","2690-5965","978-1-7281-9074-7","10.1109/ICPADS51040.2020.00083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359135","Federated Learning;Deep Learning;Internet of Vehicles;Edge Caching;AutoEncoder","Training;Data privacy;Collaborative filtering;Predictive models;Collaborative work;Peer-to-peer computing;Servers","cache storage;data privacy;Internet;learning (artificial intelligence);peer-to-peer computing;traffic engineering computing","vehicular applications;peer-to-peer federated learning;proactive content caching;caching performance;high global model accuracy;dual-weighted aggregation scheme;updated global model;global prediction model;peer-to-peer federated deep learning;proactive caching scheme;personal data;users;cache efficiency;content popularity;learning-based proactive caching schemes;machine learning;restricted storage capability;high mobility;IoV;Internet-of-Vehicles;network traffic;edge node","","6","","21","","25 Feb 2021","","","IEEE","IEEE Conferences"
"Unsupervised Graph Embedding via Adaptive Graph Learning","R. Zhang; Y. Zhang; C. Lu; X. Li","Key Laboratory of Intelligent Interaction and Applications (Northwestern Polytechnical University), Ministry of Industry and Information Technology, Xi&#x0027;an, P. R. China; Key Laboratory of Intelligent Interaction and Applications (Northwestern Polytechnical University), Ministry of Industry and Information Technology, Xi&#x0027;an, P. R. China; Key Laboratory of Intelligent Interaction and Applications (Northwestern Polytechnical University), Ministry of Industry and Information Technology, Xi&#x0027;an, P. R. China; Key Laboratory of Intelligent Interaction and Applications (Northwestern Polytechnical University), Ministry of Industry and Information Technology, Xi&#x0027;an, P. R. China","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2022","PP","99","1","10","Graph autoencoders (GAEs) are powerful tools in representation learning for graph embedding. However, the performance of GAEs is very dependent on the quality of the graph structure, i.e., of the adjacency matrix. In other words, GAEs would perform poorly when the adjacency matrix is incomplete or be disturbed. In this paper, two novel unsupervised graph embedding methods, <italic>unsupervised graph embedding via adaptive graph learning</italic> (BAGE) and <italic>unsupervised graph embedding via variational adaptive graph learning</italic> (VBAGE) are proposed. The proposed methods expand the application range of GAEs on graph embedding, i.e, on the general datasets without graph structure. Meanwhile, the adaptive learning mechanism can initialize the adjacency matrix without being affected by the parameter. Besides that, the latent representations are embedded with the Laplacian graph structure to preserve the topology structure of the graph in the vector space. Moreover, the adjacency matrix can be self-learned for better embedding performance when the original graph structure is incomplete. With adaptive learning, the proposed method is much more robust to the graph structure. Experimental studies on several datasets validate our design and demonstrate that our methods outperform baselines by a wide margin in node clustering, node classification, link prediction, and graph visualization tasks.","1939-3539","","10.1109/TPAMI.2022.3202158","National Natural Science Foundation of China(grant numbers:61871470); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9868157","Graph Embedding;Adaptive Graph Learning;Graph Autoencoder","Laplace equations;Graph neural networks;Adaptation models;Adaptive learning;Task analysis;Decoding;Topology","","","","","","","IEEE","26 Aug 2022","","","IEEE","IEEE Early Access Articles"
"Unsupervised learning approach for predicting sepsis onset in ICU patients","G. Ramos; E. Gjini; L. Coelho; M. Silveira","Institute for Systems and Robotics, Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal; Center for Computational and Stochastic Mathematics, Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal; Nova Medical School, Hospital de São Francisco Xavier, Lisbon, Portugal; Institute for Systems and Robotics, Instituto Superior Técnico, Universidade de Lisboa, Lisbon, Portugal","2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","9 Dec 2021","2021","","","1916","1919","Sepsis is a life-threatening condition caused by a deregulated host response to infection. If not diagnosed at an early stage, septic patients can go into a septic shock, associated with aggravated patient outcomes. Research has been mostly focused on predicting sepsis onset using supervised models that require big labeled datasets to train. In this work we propose two fully unsupervised learning approaches to predict septic shock onset in the Intensive Care Unit (ICU). Our approach includes learning representations from patient multivariate timeseries using Recurrent Autoencoders. Then, we apply an anomaly detection framework, using clustering-based algorithms, on the representation space learned by the models. When evaluating the performance of the proposed approaches in the septic shock onset prediction task, the Variational Autoencoder (VAE) using Gaussian Mixture Models in the anomaly detection framework was competitive with a supervised LSTM network. Results led to an AUC of 0.82 and F1-score of 0.65 using the unsupervised approach in comparison with 0.80, 0.66 for the supervised model.Clinical relevance— This work proposes an unsupervised septic shock onset prediction framework which can improve current procedure for monitoring infection progression in the ICU.","2694-0604","978-1-7281-1179-7","10.1109/EMBC46164.2021.9629559","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9629559","","Electric shock;Medical services;Predictive models;Prediction algorithms;Risk management;Task analysis;Anomaly detection","diseases;Gaussian processes;learning (artificial intelligence);medical computing;medical disorders;patient treatment;pattern clustering;statistical analysis;unsupervised learning","recurrent autoencoders;anomaly detection framework;clustering-based algorithms;representation space;septic shock onset prediction task;Gaussian mixture models;supervised LSTM network;unsupervised approach;unsupervised septic shock onset prediction framework;unsupervised learning approach;ICU patients;life-threatening condition;deregulated host response;septic patients;aggravated patient outcomes;big labeled datasets;intensive care unit;patient multivariate timeseries","Critical Care;Humans;Intensive Care Units;Sepsis;Shock, Septic;Unsupervised Machine Learning","","","13","IEEE","9 Dec 2021","","","IEEE","IEEE Conferences"
"Learning-based End-to-End Video Compression Using Predictive Coding","M. C. de Oliveira; L. G. R. Martins; H. C. Jung; N. D. Guerin; R. C. da Silva; E. Peixoto; B. Macchiavello; E. M. Hung; V. Testoni; P. G. Freitas",University of Brasília; University of Brasília; University of Brasília; University of Brasília; Samsung R&D Brazil; University of Brasília; University of Brasília; University of Brasília; Samsung R&D Brazil; Samsung R&D Brazil,"2021 34th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)","20 Dec 2021","2021","","","160","167","Driven by the growing demand for video applications, deep learning techniques have become alternatives for implementing end-to-end encoders to achieve applicable compression rates. Conventional video codecs exploit both spatial and temporal correlation. However, due to some restrictions (e.g. computational complexity), they are commonly limited to linear transformations and translational motion estimation. Autoencoder models open up the way for exploiting predictive end-to-end video codecs without such limitations. This paper presents an entire learning-based video codec that exploits spatial and temporal correlations. The presented codec extends the idea of P-frame prediction presented in our previous work. The architecture adopted for I-frame coding is defined by a variational autoencoder with non-parametric entropy modeling. Besides an entropy model parameterized by a hyperprior, the inter-frame encoder architecture has two other independent networks, responsible for motion estimation and residue prediction. Experimental results indicate that some improvements still have to be incorporated into our codec to overcome the all-intra coding set up regarding the traditional algorithms High Efficiency Video Coding (HEVC) and Versatile Video Coding (VVC).","2377-5416","978-1-6654-2354-0","10.1109/SIBGRAPI54419.2021.00030","Samsung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9643143","learning based coding;video compression;deep learning;predictive coding","Correlation;Motion estimation;Computer architecture;Predictive models;Video compression;Predictive coding;Entropy","data compression;deep learning (artificial intelligence);entropy;motion estimation;video codecs;video coding","predictive coding;video applications;deep learning techniques;end-to-end encoders;spatial correlation;temporal correlation;translational motion estimation;autoencoder models;predictive end-to-end video codecs;P-frame prediction;I-frame coding;nonparametric entropy modeling;inter-frame encoder architecture;residue prediction;high efficiency video coding;versatile video coding;learning-based end-to-end video compression;learning-based video codec","","","","44","IEEE","20 Dec 2021","","","IEEE","IEEE Conferences"
"Analog Joint Source-Channel Coding for Distributed Functional Compression using Deep Neural Networks","Y. M. Saidutta; A. Abdi; F. Fekri","Dept. of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, Georgia, USA; Dept. of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, Georgia, USA; Dept. of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, Georgia, USA","2021 IEEE International Symposium on Information Theory (ISIT)","1 Sep 2021","2021","","","2429","2434","In this paper, we study Joint Source-Channel Coding (JSCC) for distributed analog functional compression over both Gaussian Multiple Access Channel (MAC) and AWGN channels. Notably, we propose a deep neural network based solution for learning encoders and decoders. We propose three methods of increasing performance. The first one frames the problem as an autoencoder; the second one incorporates the power constraint in the objective by using a Lagrange multiplier; the third method derives the objective from the information bottleneck principle. We show that all proposed methods are variational approximations to upper bounds on the indirect rate-distortion problem's minimization objective. Further, we show that the third method is the variational approximation of a tighter upper bound compared to the other two. Finally, we show empirical performance results for image classification. We compare with existing work and showcase the performance improvement yielded by the proposed methods.","","978-1-5386-8209-8","10.1109/ISIT45174.2021.9517797","National Science Foundation(grant numbers:MLWiNS-2003002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9517797","","Deep learning;AWGN channels;Training;Upper bound;Image coding;Rate-distortion;Minimization","approximation theory;AWGN channels;combined source-channel coding;Gaussian channels;image classification;image coding;neural nets;rate distortion theory","analog Joint Source-Channel Coding;distributed functional compression;deep neural networks;distributed analog functional compression;deep neural network based solution;encoders;decoders;information bottleneck principle;variational approximation;indirect rate-distortion problem;empirical performance results;Gaussian Multiple Access Channel;AWGN channels;Lagrange multiplier","","","","45","","1 Sep 2021","","","IEEE","IEEE Conferences"
"Animating Face using Disentangled Audio Representations","G. Mittal; B. Wang",Microsoft; Microsoft,"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)","14 May 2020","2020","","","3279","3287","Previous methods for audio-driven talking head generation assume the input audio to be clean with a neutral tone. As we show empirically, one can easily break these systems by simply adding certain background noise to the utterance or changing its emotional tone (to for example, sad). To make talking head generation robust to such variations, we propose an explicit audio representation learning framework that disentangles audio sequences into various factors such as phonetic content, emotional tone, background noise and others. We conduct experiments to validate that when conditioned on disentangled content representation, the generated mouth movement by our model is significantly more accurate than previous approaches (without disentangled learning) in the presence of noise and emotional variations. We further demonstrate that our framework is compatible with current state-of-the-art approaches by replacing their original component to learn audio based representation with ours. To the best of our knowledge, this is the first work which improves the performance of talking head generation through a disentangled audio representation perspective, which is important for many real-world applications.","2642-9381","978-1-7281-6553-0","10.1109/WACV45572.2020.9093527","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9093527","","Face;Solid modeling;Three-dimensional displays;Phonetics;Gallium nitride;Predictive models","audio signal processing;computer animation;learning (artificial intelligence);neural nets;speech processing","face animation;audio representations;audio-driven talking head generation;neutral tone;background noise;emotional tone;explicit audio representation;audio sequences;phonetic content;disentangled content representation;generated mouth movement;disentangled learning;emotional variations;audio based representation;disentangled audio representation perspective;explicit audio representation learning framework;variational autoencoder;generative adversarial network","","7","","32","IEEE","14 May 2020","","","IEEE","IEEE Conferences"
"Unsupervised Balanced Hash Codes Learning With Multichannel Feature Fusion","Y. Chen; D. Zhao; X. Lu; S. Xiong; H. Wang","Wuhan University of Technology Chongqing Research Institute, Chongqing, China; Wuhan University of Technology Chongqing Research Institute, Chongqing, China; Wuhan University of Technology Chongqing Research Institute, Chongqing, China; Wuhan University of Technology Chongqing Research Institute, Chongqing, China; Key Laboratory of Spectral Imaging Technology CAS, Xian Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20 Apr 2022","2022","15","","2816","2825","Unsupervised hashingalgorithms are widely used in large-scale remote sensing images (RSIs) retrieval task. However, existing RSI retrieval algorithms fail to capture the multichannel characteristic of multispectral RSIs and the balanced property of hash codes, which lead the poor performance of RSI retrieval. To tackle these issues, we develop an unsupervised hashing algorithm, namely, variational autoencoder balanced hashing (VABH), to leverage multichannel feature fusion and multiscale context information to perform RSI retrieval task. First, multichannel feature fusion module is designed to extract RSI feature information by leveraging the multichannel properties of multispectral RSI. Second, multiscale learning module is developed to learn the multiscale context information of RSIs. Finally, a novel objective function is designed to capture the discrimination and balanced property of hash codes in the hashing learning process. Comprehensive experiments on diverse benchmark have well demonstrated the reasonableness and effectiveness of the proposed VABH algorithm.","2151-1535","","10.1109/JSTARS.2022.3162251","National Natural Science Foundation of China(grant numbers:62176194,62101393); Major project of IoV(grant numbers:2020AAA001); Sanya Science and Education Innovation Park of Wuhan University of Technology(grant numbers:2021KF0031); Fundamental Research Funds for the Central Universities(grant numbers:WUT:2019III051GX,WUT:2021III054JC,WUT:215210002,WUT: 213110001,WUT:223110001); National Natural Science Foundation of China(grant numbers:cstc2021jcyj-msxmX1148); Open Project of Wuhan University of Technology Chongqing Research Institute(grant numbers:ZL2021-6); MindSpore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9743294","Deep hash codes;multichannel feature fusion;multiscale context information;unsupervised hashing learning","Feature extraction;Codes;Data mining;Convolution;Linear programming;Approximation algorithms;Semantics","feature extraction;file organisation;geophysical image processing;image classification;image fusion;image retrieval;information retrieval;learning (artificial intelligence);remote sensing","multiscale context information;RSI retrieval task;fusion module;multichannel properties;multispectral RSI;multiscale learning module;balanced property;hashing learning process;VABH algorithm;unsupervised balanced hash codes learning;multichannel feature fusion;unsupervised hashingalgorithms;large-scale remote sensing images retrieval task;existing RSI retrieval algorithms;multichannel characteristic;unsupervised hashing algorithm;variational autoencoder balanced hashing;leverage multichannel","","1","","50","CCBY","25 Mar 2022","","","IEEE","IEEE Journals"
"Image Inpainting Using Parallel Network","Y. Deng; J. Wang","Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, 28 West Xianning Road, Xi’an, Shaanxi, P. R. China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, 28 West Xianning Road, Xi’an, Shaanxi, P. R. China","2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","1088","1092","Due to the lack of contextual information and the difficulty to directly learn the distribution of a complete image, existing image inpainting methods always use a two-stages approach to make plausible prediction for missing pixels in a coarse-to-fine manner. In this paper, we propose a novel inpainting method with two parallel pipelines. The first pipeline is a standard image completion path that takes the corrupted image as input and outputs the predicted complete image. The second pipeline exists only during the training phase that inputs a complementary image of the corrupted one and still outputs the same complete image. The two pipelines operate simultaneously, and they share identical encoder and most parameters in the decoder. Furthermore, inspired by VAE, random Gaussian noise are added to the features not only to improve the robustness of the model but also to enable generating diverse and plausible results. We evaluated our model on several public datasets and demonstrated that the proposed method outperforms several state-of-the-arts approaches.","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9191275","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9191275","Image Completion;Parallel Pipelines;Complementary Images;Random Noise","Pipelines;Image reconstruction;Training;Gaussian noise;Gallium nitride;Standards;Decoding","Gaussian noise;image restoration;learning (artificial intelligence);neural nets;parallel processing","parallel network;contextual information;image inpainting methods;parallel pipelines;standard image completion path;corrupted image;complementary image;missing pixels;identical encoder sharing;random Gaussian noise;variational autoencoders","","1","","22","","30 Sep 2020","","","IEEE","IEEE Conferences"
"High-Intelligibility Speech Synthesis for Dysarthric Speakers with LPCNet-Based TTS and CycleVAE-Based VC","K. Matsubara; T. Okamoto; R. Takashima; T. Takiguchi; T. Toda; Y. Shiga; H. Kawai","National Institute of Information and Communications Technology, Japan; National Institute of Information and Communications Technology, Japan; Graduate School of System Informatics, Kobe University, Japan; Graduate School of System Informatics, Kobe University, Japan; National Institute of Information and Communications Technology, Japan; National Institute of Information and Communications Technology, Japan; National Institute of Information and Communications Technology, Japan","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","7058","7062","This paper presents a high-intelligibility speech synthesis method for persons with dysarthria caused by athetoid cerebral palsy. The muscular control of such speakers is unstable because of their athetoid symptoms, and their pronunciation is unclear, which makes it difficult for them to communicate. In this paper, we present a method for generating highly intelligible speech that preserves the individuality of dysarthric speakers by combining Transformer-TTS, CycleVAE-VC, and a LPCNet vocoder. Rather than repairing prosody from the dysarthric speech, this method transfers the dysarthric speaker’s individuality to the speech of a healthy person generated by TTS synthesis. This task is both important and challenging. From the results of our evaluation experiments, we confirmed that the proposed method can partially transfer the individuality of the target dysarthric speaker while maintaining the intelligibility of the source speech.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414136","dysarthria;speech synthesis;text-to-speech;voice conversion;neural vocoder","Vocoders;Conferences;Signal processing;Acoustics;Speech synthesis;Task analysis","medical disorders;neural nets;speaker recognition;speech intelligibility;speech synthesis;vocoders","LPCNet-based TTS;CycleVAE-based VC;high-intelligibility speech synthesis method;athetoid cerebral palsy;muscular control;athetoid symptoms;LPCNet vocoder;dysarthric speech;healthy person;TTS synthesis;dysarthric speaker;transformer-TTS;source speech intelligibility;text-to-speech synthesis;variational autoencoder","","","","30","IEEE","13 May 2021","","","IEEE","IEEE Conferences"
"Deep Learning","P. Setoodeh; S. Habibi; S. Haykin",NA; NA; McMaster University,"Nonlinear Filters: Theory and Applications","","2022","","","113","140","This chapter covers the basics of deep learning and introduces the main deep network architectures. A brief history of artificial intelligence is followed by presenting the gradient descent method and its variants such as stochastic gradient descent and natural gradient descent. Then, artificial neural networks and their building blocks are reviewed. Backpropagation and backpropagation through time are presented, which are, respectively, used to train feedforward and recurrent neural networks in a supervised manner. Regarding the training process, issues of initialization and regularization are discussed. Deep neural network architectures are presented including feedforward networks such as convolutional neural network and recurrent networks such as long short‐term memory and gated recurrent unit. After reviewing the Hebbian learning as a basic unsupervised learning method, Gibbs sampling is introduced. Next, Boltzmann machine and its variants such as restricted Boltzmann machine, deep Boltzmann machine, and deep belief network are presented. Then, autoencoder, variational autoencoder, generative adversarial network, and transformer are covered.","","9781119078180","10.1002/9781119078166.ch8","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9740370.pdf&bkn=9740330&pdfType=chapter","","Training;Approximation algorithms;Neural networks;Deep learning;Cost function;Convergence;Supervised learning","","","","","","","","23 Mar 2022","","","Wiley","Wiley Telecom eBook Chapters"
"A Real-Time Fault Detection Framework Based on Unsupervised Deep Learning for Prognostics and Health Management of Railway Assets","M. Shimizu; S. Perinpanayagam; B. Namoano","Integrated Vehicle Health Management Centre, Cranfield University, Bedfordshire, Cranfield, U.K; Integrated Vehicle Health Management Centre, Cranfield University, Bedfordshire, Cranfield, U.K; Digital Engineering and Manufacturing Centre, Cranfield University, Bedfordshire, Cranfield, U.K","IEEE Access","19 Sep 2022","2022","10","","96442","96458","Fault detection based on deep learning has been intensively investigated in the recent decade due to increasing availability of data and its ability to engineer features with deep neural network architectures. Despite much attention to its application, the major challenge is the lack of available labelled datasets to build the models since maintenance is usually conducted regularly to avoid significant defects. This paper aims to propose a successful real-time fault detection framework based on unsupervised deep learning using only healthy normal data. The approach is based on autoencoder architecture and a one-class support vector machine as a classifier. As a case study, large real-world datasets acquired from railway door systems have been employed. The five different types of deep learning models and a one-class classifier are trained and comprehensively validated based on performance metrics and sensitivity analysis. In addition, two experiments have been carried out to verify the model’s adaptability and robustness to variational time-series data. The result shows a typical autoencoder is the least sensitive to a decision boundary set by the one-class classifier. However, the two experiments show that the fault detection accuracy for a bidirectional long short-term memory-based autoencoder is considerably higher than other autoencoder-based models at 0.970 and 0.966 as F1 score, meaning only this model is adaptable and robust to variational data. The experimental result allows us to obtain the understandability of the deep learning models. Furthermore, the regions of anomalies are localised with unsupervised models, which enables diagnosing the cause of failure.","2169-3536","","10.1109/ACCESS.2022.3205352","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9882101","Fault detection;PHM;signal processing;unsupervised deep learning;machine learning;data-driven approach;AE;Bi-LSTM;railway;door systems","Fault detection;Data models;Rail transportation;Adaptation models;Mathematical models;Deep learning;Real-time systems;Unsupervised learning;Machine learning","","","","","","38","CCBY","8 Sep 2022","","","IEEE","IEEE Journals"
"Intelligent Anomaly Detection of Trajectories for IoT Empowered Maritime Transportation Systems","J. Hu; K. Kaur; H. Lin; X. Wang; M. M. Hassan; I. Razzak; M. Hammoudeh","Department of Computer Science, University of Exeter, Exeter EX4 4RN, U.K..; Electrical Engineering Department, École de technologie supérieure, Université du Québec, Montréal, QC H3C 1K3, Canada.; College of Computer and Cyber Security, Fujian Normal University, Fuzhou, Fujian 350117, China, and also with the Engineering Research Center of Cyber Security and Education Informatization, Fujian Province University, Fuzhou, Fujian 350117, China.; College of Computer and Cyber Security, Fujian Normal University, Fuzhou, Fujian 350117, China, and also with the Engineering Research Center of Cyber Security and Education Informatization, Fujian Province University, Fuzhou, Fujian 350117, China.; Department of Information Systems, College of Computer and Information Sciences, King Saud University, Riyadh 11543, Saudi Arabia.; School of Information Technology, Deakin University, Geelong, VIC 3220, Australia.; Department of Computing and Mathematics, Manchester Metropolitan University, Manchester M15 6BH, U.K..","IEEE Transactions on Intelligent Transportation Systems","","2022","PP","99","1","10","The convergence of Maritime Transportation Systems (MTS) and Internet of Things (IoT) has led to the promising IoT-empowered MTS (IoT-MTS). However, abnormal trajectories of maritime transportation ships can have highly negative impacts on the management of IoT-MTS. Therefore, anomaly detection of trajectories is important for the successful deployment of IoT-MTS. In this paper, we propose a Transfer Learning based Trajectory Anomaly Detection strategy, named TLTAD, for IoT-MTS. Specifically, a variational autoencoder is used to discover the potential connections between each dimension of the normal trajectory, while a graph variational autoencoder is used to explore the spatial similarity between normal trajectories. Based on internal connection of trajectories, a deep reinforcement learning algorithm, Twin Delayed Deep Deterministic policy gradient (TD3), is employed to train the trajectory anomaly detection model. To reduce the model training time, transfer learning is used to migrate the trained anomaly detection model between different regions of an ocean area or between similar ocean areas. Moreover, an efficient data transformation module is designed to improve the efficiency of model transfer. The experiments were conducted on a real-world automatic identification system (AIS) dataset. The results indicate that the proposed TLTAD can provide accurate anomaly detection on ships' trajectories in IoT-MTS with reduced model training times.","1558-0016","","10.1109/TITS.2022.3162491","King Saud University Riyadh Saudi Arabia through the Researchers Supporting Project(grant numbers:RSP 2022/18); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9759236","Deep reinforcement learning;maritime transportation systems;anomaly detection;transfer learning.","Trajectory;Marine vehicles;Anomaly detection;Data models;Analytical models;Transportation;Artificial intelligence","","","","","","","IEEE","18 Apr 2022","","","IEEE","IEEE Early Access Articles"
"Surface Networks","I. Kostrikov; Z. Jiang; D. Panozzo; D. Zorin; J. Bruna","Courant Institute of Mathematical Sciences, New York University; Courant Institute of Mathematical Sciences, New York University; Courant Institute of Mathematical Sciences, New York University; Courant Institute of Mathematical Sciences, New York University; Courant Institute of Mathematical Sciences, New York University","2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition","16 Dec 2018","2018","","","2540","2548","We study data-driven representations for three-dimensional triangle meshes, which are one of the prevalent objects used to represent 3D geometry. Recent works have developed models that exploit the intrinsic geometry of manifolds and graphs, namely the Graph Neural Networks (GNNs) and its spectral variants, which learn from the local metric tensor via the Laplacian operator. Despite offering excellent sample complexity and built-in invariances, intrinsic geometry alone is invariant to isometric deformations, making it unsuitable for many applications. To overcome this limitation, we propose several upgrades to GNNs to leverage extrinsic differential geometry properties of three-dimensional surfaces, increasing its modeling power. In particular, we propose to exploit the Dirac operator, whose spectrum detects principal curvature directions - this is in stark contrast with the classical Laplace operator, which directly measures mean curvature. We coin the resulting models Surface Networks (SN). We prove that these models define shape representations that are stable to deformation and to discretization, and we demonstrate the efficiency and versatility of SNs on two challenging tasks: temporal prediction of mesh deformations under non-linear dynamics and generative models using a variational autoencoder framework with encoders/decoders given by SNs.","2575-7075","978-1-5386-6420-9","10.1109/CVPR.2018.00269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8578367","","Laplace equations;Shape;Computational modeling;Face;Strain;Neural networks;Three-dimensional displays","computational geometry;differential geometry;graph theory;mesh generation;neural nets;tensors","data-driven representations;three-dimensional triangle meshes;shape representations;3D geometry;nonlinear dynamics;SN;autoencoder framework;extrinsic differential geometry properties;graph neural networks;surface networks;mesh deformations;mean curvature;principal curvature directions;Dirac operator;three-dimensional surfaces;isometric deformations;Laplacian operator;local metric tensor;spectral variants;GNNs;intrinsic geometry","","36","","42","","16 Dec 2018","","","IEEE","IEEE Conferences"
"Generative Modeling of Multimodal Multi-Human Behavior","B. Ivanovic; E. Schmerling; K. Leung; M. Pavone","Department of Computer Science, Stanford University, Stanford, CA, USA; Institute for Computational and Mathematical Engineering, Stanford University, Stanford, CA, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","6 Jan 2019","2018","","","3088","3095","This work presents a methodology for modeling and predicting human behavior in settings with N humans interacting in highly multimodal scenarios (i.e. where there are many possible highly-distinct futures). A motivating example includes robots interacting with humans in crowded environments, such as self-driving cars operating alongside human-driven vehicles or human-robot collaborative bin packing in a warehouse. Our approach to model human behavior in such uncertain environments is to model humans in the scene as nodes in a graphical model, with edges encoding relationships between them. For each human, we learn a multimodal probability distribution over future actions from a dataset of multi-human interactions. Learning such distributions is made possible by recent advances in the theory of conditional variational autoencoders and deep learning approximations of probabilistic graphical models. Specifically, we learn action distributions conditioned on interaction history, neighboring human behavior, and candidate future agent behavior in order to take into account response dynamics. We demonstrate the performance of such a modeling approach in modeling basketball player trajectories, a highly multimodal, multi-human scenario which serves as a proxy for many robotic applications.","2153-0866","978-1-5386-8094-0","10.1109/IROS.2018.8594393","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594393","","Trajectory;Predictive models;Analytical models;Deep learning;Ground penetrating radar;Data models;Robots","approximation theory;behavioural sciences computing;bin packing;human-robot interaction;learning (artificial intelligence);mobile robots;multi-agent systems;statistical distributions","deep learning approximations;probabilistic graphical models;candidate future agent behavior;crowded environments;human-driven vehicles;human-robot collaborative bin packing;multimodal probability distribution;multihuman interactions;basketball player trajectories;multimodal multihuman behavior;self-driving cars;warehouse;autoencoders;response dynamics;robotic applications;proxy","","21","","28","","6 Jan 2019","","","IEEE","IEEE Conferences"
"A Hybrid Bayesian Deep Learning Model for Remaining Useful Life Prognostics and Uncertainty Quantification","D. Huang; R. Bai; S. Zhao; P. Wen; J. He; S. Wang; S. Chen","School of Electronics and Information, Northwestern Polytechnical University, Xi’an, PR China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, PR China; Aalborg University, Aalborg, Denmark; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, PR China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, PR China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, PR China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, PR China","2021 IEEE International Conference on Prognostics and Health Management (ICPHM)","20 Jul 2021","2021","","","1","8","Remaining useful life (RUL) prognostics is critical to maintenance decision making and reliability assessment. A significant amount of neural networks research has been reported to develop prognostics models that can provide high prediction accuracy. These models use advanced neural networks to improve prediction performance and provide sole point estimation for RUL. However, accurate uncertainty quantification of the RUL is essential to understand the uncertainty of the degradation process and perform reliable risk analysis and maintenance decisions. This paper proposes a new hybrid Bayesian deep learning (HBDL)-based prognostics approach. It uses long short term memory autoencoder (LSTM-AE) to extract features that include degradation information, and then uses the Bayesian neural network (BNN) to model and predict the equipment degeneration process. It learns network weights through variational inference (VI) and provides RUL prognostics results while obtaining interval estimation. Finally, a general aircraft engine data set is used to verify the proposed model. The experimental results show that this method can achieve satisfying prediction accuracy and uncertainty quantification capability.","","978-1-6654-1970-3","10.1109/ICPHM51084.2021.9486527","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9486527","HBDL;LSTM-AE;RUL prognostics;CI;Uncertainty quantification;Aircraft engine","Degradation;Uncertainty;Atmospheric modeling;Neural networks;Estimation;Predictive models;Maintenance engineering","aerospace engines;Bayes methods;belief networks;condition monitoring;decision making;deep learning (artificial intelligence);maintenance engineering;mechanical engineering computing;reliability;remaining life assessment;risk analysis","prediction performance;sole point estimation;accurate uncertainty quantification;degradation process;reliable risk analysis;maintenance decisions;hybrid Bayesian deep learning-based prognostics approach;short term memory autoencoder;degradation information;Bayesian neural network;equipment degeneration process;network weights;RUL prognostics results;satisfying prediction accuracy;uncertainty quantification capability;hybrid Bayesian deep learning model;useful life prognostics;maintenance decision making;reliability assessment;neural networks research;develop prognostics models;high prediction accuracy;advanced neural networks","","","","17","","20 Jul 2021","","","IEEE","IEEE Conferences"
"Robust and Uncertainty-Aware VAE (RU-VAE) for One-Class Classification","R. Sharma; S. P. Awate","IITB-Monash Research Academy, Mumbai; Computer Science and Engineering Department, Indian Institute of Technology (IIT) Bombay, Mumbai","2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)","26 Apr 2022","2022","","","1","5","One-class classification (OCC) methods for abnormality detection learn either a generative model of the inlier class (e.g., using variants of kernel principal component analysis) or a decision boundary to encapsulate the inlier class (e.g., using one-class variants of the support vector machine). Recent methods use deep-neural-network models to learn (for the inlier class) either latent-space distributions or autoencoders, but not both. OCC learning typically relies solely on inlier-class data, but some recent semi-supervised versions also leverage some outlier-class training data. We propose a robust and uncertainty-aware variational framework for OCC, leveraging data-adaptive generalized-Gaussian (GG) models leading to distribution modeling in both latent space and image space. We propose a reparameterization for samples from the latent-space GG to enable backpropagation. Results on publicly available real-world datasets show the benefits of our method over others.","1945-8452","978-1-6654-2923-8","10.1109/ISBI52829.2022.9761472","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9761472","One-class classification;VAE;robustness;uncertainty;generalized Gaussian;semi-supervision","Backpropagation;Training;Support vector machines;Adaptation models;Analytical models;Shape;Training data","backpropagation;learning (artificial intelligence);neural nets;pattern classification;principal component analysis;support vector machines","kernel principal component analysis;inlier class;one-class variants;deep-neural-network models;latent-space distributions;autoencoders;OCC learning;inlier-class data;outlier-class training data;robust uncertainty-aware;leveraging data-adaptive generalized-Gaussian models;distribution modeling;latent space;image space;RU-VAE;one-class classification methods;generative model","","","","23","IEEE","26 Apr 2022","","","IEEE","IEEE Conferences"
"Deepemocluster: a Semi-Supervised Framework for Latent Cluster Representation of Speech Emotions","W. -C. Lin; K. Sridhar; C. Busso","Department of Electrical and Computer Engineering, Multimodal Signal Processing (MSP) lab, The University of Texas at Dallas, Richardson, TX, USA; Department of Electrical and Computer Engineering, Multimodal Signal Processing (MSP) lab, The University of Texas at Dallas, Richardson, TX, USA; Department of Electrical and Computer Engineering, Multimodal Signal Processing (MSP) lab, The University of Texas at Dallas, Richardson, TX, USA","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","7263","7267","Semi-supervised learning (SSL) is an appealing approach to resolve generalization problem for speech emotion recognition (SER) systems. By utilizing large amounts of unlabeled data, SSL is able to gain extra information about the prior distribution of the data. Typically, it can lead to better and robust recognition performance. Existing SSL approaches for SER include variations of encoder-decoder model structures such as autoencoder (AE) and variational autoecoders (VAEs), where it is difficult to interpret the learning mechanism behind the latent space. In this study, we introduce a new SSL framework, which we refer to as the DeepEmoCluster framework, for attribute-based SER tasks. The DeepEmoCluster framework is an end-to-end model with mel-spectrogram inputs, which combines a self-supervised pseudo labeling classification network with a supervised emotional attribute regressor. The approach encourages the model to learn latent representations by maximizing the emotional separation of K-means clusters. Our experimental results based on the MSP-Podcast corpus indicate that the DeepEmoCluster framework achieves competitive prediction performances in fully supervised scheme, outperforming baseline methods in most of the conditions. The approach can be further improved by incorporating extra unlabeled set. Moreover, our experimental results explicitly show that the latent clusters have emotional dependencies, enriching the geometric interpretation of the clusters.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414035","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414035","Semi-supervised learning (SSL);speech emotion recognition (SER);unsupervised clusters","Training;Emotion recognition;Conferences;Speech recognition;Semisupervised learning;Signal processing;Labeling","deep learning (artificial intelligence);emotion recognition;pattern classification;pattern clustering;regression analysis;speech recognition;supervised learning","emotional dependencies;latent cluster representation;semisupervised learning;generalization problem;speech emotion recognition systems;unlabeled data;robust recognition performance;encoder-decoder model structures;variational autoecoders;SSL framework;DeepEmoCluster framework;attribute-based SER tasks;end-to-end model;self-supervised pseudolabeling classification network;supervised emotional attribute regressor;emotional separation;K-means clusters;MSP-Podcast corpus","","1","","31","IEEE","13 May 2021","","","IEEE","IEEE Conferences"
"Evaluating Learned State Representations for Atari","A. Tupper; K. Neshatian","Department of Computer Science and Software Engineering, University of Canterbury, Christchurch, New Zealand; Department of Computer Science and Software Engineering, University of Canterbury, Christchurch, New Zealand","2020 35th International Conference on Image and Vision Computing New Zealand (IVCNZ)","17 Dec 2020","2020","","","1","6","Deep reinforcement learning, the combination of deep learning and reinforcement learning, has enabled the training of agents that can solve complex tasks from visual inputs. However, these methods often require prohibitive amounts of computation to obtain successful results. To improve learning efficiency, there has been a renewed focus on separating state representation and policy learning. In this paper, we investigate the quality of state representations learned by different types of autoencoders, a popular class of neural networks used for representation learning. We assess not only the quality of the representations learned by undercomplete, variational, and disentangled variational autoencoders, but also how the quality of the learned representations is affected by changes in representation size. To accomplish this, we also present a new method for evaluating learned state representations for Atari games using the Atari Annotated RAM Interface. Our findings highlight differences in the quality of state representations learned by different types of autoencoders and their robustness to reduction in representation size. Our results also demonstrate the advantage of using more sophisticated evaluation methods over assessing reconstruction quality.","2151-2205","978-1-7281-8579-8","10.1109/IVCNZ51579.2020.9290609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9290609","","Training;Visualization;Reinforcement learning;Games;Robustness;Task analysis;Image reconstruction","computer games;learning (artificial intelligence);neural nets","representation size;learned state representations;deep reinforcement learning;state representation;policy learning;representation learning;learned representations;Atari games;Atari annotated RAM Interface;reconstruction quality;neural networks","","","","15","","17 Dec 2020","","","IEEE","IEEE Conferences"
"Preserving Data Manifold Structure in Latent Space for Exploration through Network Geodesics","S. Krishnagopal; J. Bedrossian","Gatsby Computational Neuroscience Unit, University College London, London, UK; Department of Mathematics, University of Maryland, College Park, Maryland, USA","2022 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2022","2022","","","1","8","While variational autoencoders have been successful in several tasks, the use of conventional priors are limited in their ability to encode the underlying structure of input data. We introduce an Encoded Prior Sliced Wasserstein AutoEncoder wherein an additional prior-encoder network learns a geometry and topology preserving embedding of any data manifold, thus improving the structure of latent space. The autoencoder and prior-encoder networks are iteratively trained using the Sliced Wasserstein distance, which facilitates the learning of nonstandard complex priors. We then introduce a graph-based algorithm to explore the learned manifold by traversing latent space through network-geodesics that lie along the manifold and hence are more realistic compared to conventional Euclidean interpolation. Specifically, we identify network-geodesics by maximizing the density of samples along the path while minimizing total energy. We use the 3D-spiral data to show that the prior encodes the geometry underlying the data unlike conventional autoencoders, and to demonstrate the exploration of the embedded data manifold through the network algorithm. We apply our framework to artificial as well as image datasets to demonstrate the advantages of learning improved latent structure, outlier generation, and geodesic interpolation.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9891993","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9891993","data manifold;Wasserstein auto encoder;data embedding;representation learning;latent representation;network geodesics","Manifolds;Geometry;Training;Interpolation;Three-dimensional displays;Spirals;Network topology","","","","","","37","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"Joint Reduction of Ego-noise and Environmental Noise with a Partially-adaptive Dictionary","H. Fang; G. Carbajal; S. Wermter; T. Gerkmann",NA; NA; NA; NA,"Speech Communication; 14th ITG Conference","21 Dec 2021","2021","","","1","5","We consider the problem of simultaneous reduction of egonoise, i.e., the noise produced by a robot, and environmental noise. Both noise types may occur simultaneously for humanoid interactive robots. Dictionary- and template-based approaches have been proposed for ego-noise reduction. However, most of them lack adaptability to unseen noise types and thus exhibit limited performance in real-world scenarios with environmental noise. Recently, a variational autoencoder (VAE)-based speech model combined with a fully-adaptive dictionary-based noise model, i.e., non-negative matrix factorization (NMF), has been proposed for environmental noise reduction, showing decent adaptability to unseen noise data. In this paper, we propose to extend this framework with a partially-adaptive dictionary-based noise model, which partly adapts to unseen environmental noise while keeping the part pre-trained on ego-noise unchanged. With appropriate sizes, we demonstrate that the partially-adaptive approach outperforms the approaches based on the fully-adaptive and completely-fixed dictionaries, respectively.","","978-3-8007-5627-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9657516","","","","","","","","","","21 Dec 2021","","","VDE","VDE Conferences"
"A Hybrid Video Anomaly Detection Framework via Memory-Augmented Flow Reconstruction and Flow-Guided Frame Prediction","Z. Liu; Y. Nie; C. Long; Q. Zhang; G. Li","School of Computer Science and Engineering, South China University of Technology, China; School of Computer Science and Engineering, South China University of Technology, China; JD Finance America Corporation, Mountain View, CA, USA; School of Computer Science and Engineering, Sun Yat-Sen University, China; School of Computer Science and Engineering, South China University of Technology, China","2021 IEEE/CVF International Conference on Computer Vision (ICCV)","28 Feb 2022","2021","","","13568","13577","In this paper, we propose HF2-VAD, a Hybrid framework that integrates Flow reconstruction and Frame prediction seamlessly to handle Video Anomaly Detection. Firstly, we design the network of ML-MemAE-SC (Multi-Level Memory modules in an Autoencoder with Skip Connections) to memorize normal patterns for optical flow reconstruction so that abnormal events can be sensitively identified with larger flow reconstruction errors. More importantly, conditioned on the reconstructed flows, we then employ a Conditional Variational Autoencoder (CVAE), which captures the high correlation between video frame and optical flow, to predict the next frame given several previous frames. By CVAE, the quality of flow reconstruction essentially influences that of frame prediction. Therefore, poorly reconstructed optical flows of abnormal events further deteriorate the quality of the final predicted future frame, making the anomalies more detectable. Experimental results demonstrate the effectiveness of the proposed method. Code is available at https://github.com/LiUzHiAn/hf2vad.","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.01333","National Natural Science Foundation of China; Natural Science Foundation of Guangdong Province; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9710416","Action and behavior recognition;Detection and localization in 2D and 3D;Image and video manipulation detection and integrity methods;Motion and tracking","Computer vision;Image motion analysis;Correlation;Codes;Data preprocessing;Memory modules;Reconstruction algorithms","","","","7","","50","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"Using Vaes and Normalizing Flows for One-Shot Text-To-Speech Synthesis of Expressive Speech","V. Aggarwal; M. Cotescu; N. Prateek; J. Lorenzo-Trueba; R. Barra-Chicote","Amazon, Cambridge, UK; Amazon, Cambridge, UK; Amazon, Cambridge, UK; Amazon, Cambridge, UK; Amazon, Cambridge, UK","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","6179","6183","We propose a Text-to-Speech method to create an unseen expressive style using one utterance of expressive speech of around one second. Specifically, we enhance the disentanglement capabilities of a state-of-the-art sequence-to-sequence based system with a Variational AutoEncoder (VAE) and a Householder Flow. The proposed system provides a 22% KL-divergence reduction while jointly improving perceptual metrics over state-of-the-art. At synthesis time we use one example of expressive style as a reference input to the encoder for generating any text in the desired style. Perceptual MUSHRA evaluations show that we can create a voice with a 9% relative naturalness improvement over standard Neural Text-to-Speech, while also improving the perceived emotional intensity (59 compared to the 55 of neutral speech).","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9053678","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9053678","Text-to-speech;data efficiency;and semi-supervised learning","Measurement;Training data;Signal processing;Semisupervised learning;Data models;Speech processing;Standards","emotion recognition;learning (artificial intelligence);neural nets;speech synthesis;text analysis","normalizing flows;one-shot text-to-speech synthesis;expressive speech;unseen expressive style;disentanglement capabilities;VAE;householder flow;KL-divergence reduction;neural text-to-speech;neutral speech;sequence-to-sequence based system;text-to-speech method","","6","","18","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Efficient Multi-Class Out-of-Distribution Reasoning for Perception Based Networks: Work-in-Progress","S. Ramakrishna; Z. Rahiminasab; A. Easwaran; A. Dubey",Vanderbilt University; Nanyang Technological University; Nanyang Technological University; Vanderbilt University,"2020 International Conference on Embedded Software (EMSOFT)","9 Nov 2020","2020","","","40","42","Perception-based deep neural networks used in Cyber Physical Systems are known to fail when faced with inputs that are out-of-distribution (ODD). ODD detection is a complex problem as we need to first identify the shift in the test data from the training distribution and then we need to isolate the responsible generative factor(s) (weather, lighting levels, traffic density, etc.), Unlike the state of the art that uses multi-chained one-class classifiers, we propose an efficient single monitor that uses the principle of disentanglement to train the latent space of a variational autoencoder to be sensitive to distribution shifts in different generative factors. We demonstrate our approach using an end-to-end driving controller in the CARLA simulator.","","978-1-7281-9195-9","10.1109/EMSOFT51651.2020.9244027","DARPA(grant numbers:#E2019-T2-2-040); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9244027","ß-VAE;Disentanglement;Inductive Conformal Prediction;Mutual Information Gap","Training;Neural networks;Lighting;Cognition;Monitoring;Meteorology;Embedded software","computer simulation;cyber-physical systems;inference mechanisms;learning (artificial intelligence);neural nets;traffic engineering computing","efficient multiclass out-of-distribution reasoning;perception based networks;perception-based deep neural networks;cyber physical systems;ODD detection;complex problem;test data;training distribution;responsible generative factor;traffic density;multichained one-class classifiers;efficient single monitor;distribution shifts;generative factors","","1","","15","","9 Nov 2020","","","IEEE","IEEE Conferences"
"LASH: Large-scale Academic Deep Semantic Hashing","J. -N. Guo; X. -L. Mao; T. Lan; T. Rong-Xin; W. Wei; H. Huang","School of Computer, Beijing Institute of Technology, 47833 Beijing, Beijing, China, (e-mail: guojn@bit.edu.cn); School of Computer, Beijing Institute of Technology, 47833 Beijing, Beijing, China, (e-mail: maoxl@bit.edu.cn); School of Computer Science, Beijing Institute of Technology, 47833 Beijing, Beijing, China, (e-mail: lantiangmftby@gmail.com); Department of Computer Science and Technology, Jiangxi University of Finance and Economics, 12460 Nanchang, Jiangxi, China, (e-mail: rongxin_tu@163.com); School of Computer Science and Technology, Huazhong University of Science and Technology, 12443 Wuhan, Hubei, China, (e-mail: weiw@hust.edu.cn); School of Computer, Beijing Institute of Technology, 47833 Beijing, Beijing, China, (e-mail: hhy63@bit.edu.cn)","IEEE Transactions on Knowledge and Data Engineering","","2021","PP","99","1","1","With the explosively increasing of academic papers, efficient academic document retrieval is becoming an essential requirement for large-scale information retrieval systems. Inspired by the success of deep semantic hashing in normal document retrieval, deep semantic hashing is a promising approach for academic document retrieval by mapping academic documents into efficient hash codes. However, for academic document retrieval, the existing deep semantic hashing methods suffer from following two problems: (1) they cannot differentiate the importance of different field labels; (2) they cannot plenty utilize the structure information in paper citations. To address these problems, we propose a novel Large-scale Academic deep Semantic Hashing, called LASH. Specifically, LASH first treats paper citations as a citation network, and then employs a multi-input variational deep autoencoder to directly encode both structure information of the citation network and semantic information of academic documents into unified hash codes. Moreover, a weighted percentage similarity is designed to measure the importance of different field labels, which is a linear combination of Jaccard and Cosine similarity. Supervised by the similarity, the learned unified hash codes can further preserve the importance of different field labels. Extensive experiments show LASH significantly outperforms state-of-the-art baselines over proposed three real-world large-scale academic datasets.","1558-2191","","10.1109/TKDE.2021.3109433","National Natural Science Foundation of China(grant numbers:61602197,61751201,61772076); Natural Science Fund of Beijing(grant numbers:Z181100008918002); National Key RD Plan(grant numbers:2018YFB1005100); Beijing Advanced Innovation Center for Language Resources(grant numbers:TYZ19005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9529077","Information Retrieval;Document Retrieval;Semantic Hashing;Academic Paper;Citation Network","Semantics;Codes;Task analysis;Adversarial machine learning;Benchmark testing;Neural networks;Hash functions","","","","1","","","IEEE","3 Sep 2021","","","IEEE","IEEE Early Access Articles"
"Vela pulsar: single pulses analysis with machine learning techniques","C. O. Lousto; R. Missel; H. Prajapati; V. Sosa Fiscella; F. G. L. Armengol; P. K. Gyawali; L. Wang; N. D. Cahill; L. Combi; S. del Palacio; J. A. Combi; G. Gancio; F. García; E. M. Gutiérrez; F. Hauscarriaga","Center for Computational Relativity and Gravitation, Rochester Institute of Technology, 85 Lomb Memorial Drive, Rochester, NY 14623, USA; School of Mathematical Sciences, Rochester Institute of Technology, Rochester, NY 14623, USA; colsma@rit.edu; Golisano College of Computing and Information Sciences, Rochester Institute of Technology, Rochester, NY 14623, USA; Center for Imaging Science, Rochester Institute of Technology, Rochester, NY 14623, USA; Center for Computational Relativity and Gravitation, Rochester Institute of Technology, 85 Lomb Memorial Drive, Rochester, NY 14623, USA; Instituto Argentino de Radioastronomía (CCT La Plata, CONICET; CICPBA; UNLP), C.C.5, (1894) Villa Elisa, Buenos Aires, Argentina; Center for Computational Relativity and Gravitation, Rochester Institute of Technology, 85 Lomb Memorial Drive, Rochester, NY 14623, USA; Golisano College of Computing and Information Sciences, Rochester Institute of Technology, Rochester, NY 14623, USA; Golisano College of Computing and Information Sciences, Rochester Institute of Technology, Rochester, NY 14623, USA; School of Mathematical Sciences, Rochester Institute of Technology, Rochester, NY 14623, USA; Center for Computational Relativity and Gravitation, Rochester Institute of Technology, 85 Lomb Memorial Drive, Rochester, NY 14623, USA; Instituto Argentino de Radioastronomía (CCT La Plata, CONICET; CICPBA; UNLP), C.C.5, (1894) Villa Elisa, Buenos Aires, Argentina; Instituto Argentino de Radioastronomía (CCT La Plata, CONICET; CICPBA; UNLP), C.C.5, (1894) Villa Elisa, Buenos Aires, Argentina; Instituto Argentino de Radioastronomía (CCT La Plata, CONICET; CICPBA; UNLP), C.C.5, (1894) Villa Elisa, Buenos Aires, Argentina; Facultad de Ciencias Astronómicas y Geofísicas, Universidad Nacional de La Plata, Paseo del Bosque, B1900FWA La Plata, Argentina; Instituto Argentino de Radioastronomía (CCT La Plata, CONICET; CICPBA; UNLP), C.C.5, (1894) Villa Elisa, Buenos Aires, Argentina; Instituto Argentino de Radioastronomía (CCT La Plata, CONICET; CICPBA; UNLP), C.C.5, (1894) Villa Elisa, Buenos Aires, Argentina; Facultad de Ciencias Astronómicas y Geofísicas, Universidad Nacional de La Plata, Paseo del Bosque, B1900FWA La Plata, Argentina; Instituto Argentino de Radioastronomía (CCT La Plata, CONICET; CICPBA; UNLP), C.C.5, (1894) Villa Elisa, Buenos Aires, Argentina; Instituto Argentino de Radioastronomía (CCT La Plata, CONICET; CICPBA; UNLP), C.C.5, (1894) Villa Elisa, Buenos Aires, Argentina","Monthly Notices of the Royal Astronomical Society","25 Jan 2022","2021","509","4","5790","5808","We study individual pulses of Vela (PSR B0833−45/J0835−4510) from daily observations of over 3 h (around 120 000 pulses per observation), performed simultaneously with the two radio telescopes at the Argentine Institute of Radioastronomy. We select four days of observations in 2021 January to March and study their statistical properties with machine learning techniques. We first use Density-Based Spatial Clustering of Applications with Noise clustering techniques, associating pulses mainly by amplitudes, and find a correlation between higher amplitudes and earlier arrival times. We also find a weaker (polarization dependent) correlation with the mean width of the pulses. We identify clusters of the so-called mini-giant pulses, with ∼10 times the average pulse amplitude. We then perform an independent study, with Self-Organizing Maps (SOM) clustering techniques. We use Variational AutoEncoder (VAE) reconstruction of the pulses to separate them clearly from the noise and select one of the days of observation to train VAE and apply it to the rest of the observations. We use SOM to determine four clusters of pulses per day per radio telescope and conclude that our main results are robust and self-consistent. These results support models for emitting regions at different heights (separated each by roughly a hundred km) in the pulsar magnetosphere. We also model the pulses amplitude distribution with interstellar scintillation patterns at the inter-pulses time-scale finding a characterizing exponent nISS ∼ 7–10. In the appendices, we discuss independent checks of hardware systematics with the simultaneous use of the two radio telescopes in different one-polarization/two-polarizations configurations. We also provide a detailed analysis of the processes of radio-interferences cleaning and individual pulse folding.","1365-2966","","10.1093/mnras/stab3287","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9691226","methods: observational;methods: statistical;pulsars: individual: Vela","","","","","","","","","25 Jan 2022","","","OUP","OUP Journals"
"Motion Planning of Manipulator by Points-Guided Sampling Network","E. Lyu; T. Liu; J. Wang; S. Song; M. Q. . -H. Meng","School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen 518055, China.; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong, SAR, China.; School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen 518055, China.; School of Mechanical Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen 518055, China.; Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen 5180000, China, on leave from the Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong, and also with the Shenzhen Research Institute, The Chinese University of Hong Kong, Shenzhen 518172, China.","IEEE Transactions on Automation Science and Engineering","","2022","PP","99","1","11","This paper proposes a network called points-guided sampling net (PGSN) to guide the sampling process in sampling-based motion planner by utilizing the geometric information of obstacles. The geometric information is extracted from the point cloud of obstacles. By analyzing the properties of the point cloud, we propose a VAE feature extraction net that incorporates the variational autoencoder (VAE) framework with unique architectures designed for point clouds. Furthermore, we design a multi-modal sampling net to model the probability distribution of the states based on training trajectories taken from different environments. Based on PGSN, we propose a sampling-based motion planning algorithm called the point-guided rapidly-exploring random tree (PG-RRT). Three experiments are conducted to verify the proposed PGSN: Exp I shows the proposed VAE feature extraction net can successfully extract geometric features from the inputted point cloud; Exp II verifies the multi-modal sampling net successfully chooses corresponding mode with respect to extracted features; Exp III demonstrates the efficacy of our PG-RRT algorithm by showing PG-RRT outperforms other algorithms. Moreover, we provide theoretical analysis and insights towards understanding our model.","1558-3783","","10.1109/TASE.2022.3168542","Guangdong Basic and Applied Basic Research Foundation(grant numbers:2021A1515011964); Science and Technology Innovation Committee of Shenzhen(grant numbers:GXWD20201230155427003-20200824015626001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9765528","Points-guided sampling;point clouds;deep learning;sampling-based motion planning.","Feature extraction;Planning;Point cloud compression;Trajectory;Data mining;Three-dimensional displays;Training","","","","","","","IEEE","29 Apr 2022","","","IEEE","IEEE Early Access Articles"
"Gated Adversarial Network Based Environmental Enhancement Method for Driving Safety Under Adverse Weather Conditions","K. Wang; L. Pu; J. Zhang; J. Lu","College of Mechanical and Vehicle Engineering, Chongqing University, 47913 Chongqing, -, China, (e-mail: kw@cqu.edu.cn); College of Mechanical and Vehicle Engineering, Chongqing University, 47913 Chongqing, Sichuan, China, (e-mail: puliang@cqu.edu.cn); State Key Laboratory of vehicle NVH and Safety Technology, China Automotive Engineering Research Institute Co Ltd, 229036 Chongqing, china, China, (e-mail: zhangjian@cqu.edu.cn); Research and Advanced Engineering, Ford Motor Company, 1931 Dearborn, Michigan, United States, (e-mail: jianbolu@cqu.edu.cn)","IEEE Transactions on Intelligent Vehicles","","2022","PP","99","1","1","The adverse weather conditions have brought considerable difficulties in vision-based applications, which are closely related to the driving safety of autonomous vehicles. However, to date, the greater part of the existing environmental perception studies are under ordinary conditions, and the method to deal with the adverse weather conditions was ignored. Hence, this paper proposes an all-in-one gated adversarial network (AIO-GAN) to improve the performance of vision-based environment perception algorithms under adverse weather conditions, including in rain, haze, lack of light, etc. Three key technical contributions are made. At first, the deep learning based gated transformer module was proposed to classify the input mixed images to different collections by passing them through different branches. Second, the multi-branch based variational autoencoder-generative adversarial network was proposed to solve the ill-pose problem of the solution. Third, high-level weight sharing encoders was given out to guarantee the stability and the high quality of the training process. In this way, the unified clean-style images can be achieved, even if the mixed multi-modal images are transferred from the source domain of complex weather scenes. Extensive experimental results show that the proposed method has achieved better performance than state-of-the-arts and improved the accuracy of target detection.","2379-8904","","10.1109/TIV.2022.3142128","Chongqing Technology Innovation and application development project(grant numbers:cstc2020jscx-msxmX0109); Natural Science Foundation of Chongqing(grant numbers:cstc2020jcyj-msxmX0575); National Key Research and Development Program of China(grant numbers:SQ2020YFF0410766); National Natural Science Foundation of China(grant numbers:51605054); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9677938","Driving safety;Deep generative model;Image-to-Image translation;Generative adversarial network","Logic gates;Codes;Training;Safety;Image reconstruction;Visualization;Generative adversarial networks","","","","","","","IEEE","11 Jan 2022","","","IEEE","IEEE Early Access Articles"
"Extracting football players video sprites from broadcast video","A. Ionascu","Department of Computer Science, West University of Timisoara, Timisoara, Romania","2021 23rd International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)","10 Feb 2022","2021","","","242","245","The main focus of this paper is to explore an alternative method in video sprite extraction. For the case of this work, the priority is creating a dataset of football player's video sprites - directly from footage of broadcast football matches. The quality of the generated dataset is essential, considering that the obtained dataset can be used for further accurate 2D and 3D reconstructions. At its core, our approach relies on Mask R-CNN to get the player's image masks. The process is prone to multiple errors, depending on the player's pose and position. If we have a semi-supervised dataset collecting process, we can leverage the curated images, and then we use a variational autoencoder (VAE). In the reconstruction phase, many uncommon image masks will be converted to more generic ones, thus, improving the process of creating the dataset.","","978-1-6654-0650-5","10.1109/SYNASC54541.2021.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9700347","Computer vision;Mask R-CNN;VAE;Video sprites;Football;Creating datasets","Three-dimensional displays;Scientific computing;Image synthesis;Cameras;Sprites (computer);Image reconstruction;Sports","feature extraction;image reconstruction;learning (artificial intelligence);sport;video signal processing","broadcast video;video sprite extraction;football player;broadcast football matches;generated dataset;Mask R-CNN;dataset collecting process;uncommon image masks;football players video sprites","","","","8","IEEE","10 Feb 2022","","","IEEE","IEEE Conferences"
"Fast Dynamic Brain PET Imaging Using a Generative Adversarial Network","A. Sanaat; E. Mirsadeghi; B. Razeghi; N. Ginovart; H. Zaidi","Division of Nuclear Medicine & Molecular Imaging, Geneva University Hospital, Geneva, Switzerland; Electrical Engineering Department, Amirkabir University of Technology, Tehran, Iran; Department of Computer Sciences, Geneva University, Geneva, Switzerland; Department of Psychiatry and Department of Basic Neurosciences, Geneva University, Geneva, Switzerland; Geneva University Neurocenter, Geneva University, Geneva, Switzerland","2020 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC)","12 Aug 2021","2020","","","1","3","This work aims to present and evaluate a novel recurrent deep learning model for reduction of the acquisition time in dynamic brain PET imaging without forfeiting clinical information. The clinical dataset included 46 dynamic 18F-DOPA brain PET/CT images used to evaluate a model for generation of complete dynamic PET images from 27% of the total acquisition time. The dataset was split into 35, 6, and 5 for training, validation, and test, respectively. Each dynamic PET scan lasts 90 minutes acquired in list-mode format used to reconstruct 26 dynamic frames). A video prediction deep learning algorithm consisted of two generative adversarial networks and one variational autoencoder was developed and optimized to depict the tracer variation trend from the initial 13 frames (0 to 25 min) and synthesize the last 13 frames (25 to 90 min), respectively. The generated image was analyzed quantitatively by calculating standard metrics, such as the peak signal-to-noise ratio (PSNR), structural similarity index metric (SSIM), and time-activity curve (TAC). The PSNR and SSIM varied from 43.24 ± 0.4 to 38.82 ± 0.74 and from 0.98±0.03 to 0.81±0.09 for synthesized frames (14 to 26), respectively. The TAC trend showed that our model is able to predict images with similar tracer distribution compared to reference images. We demonstrated that the proposed method can generate the last 65 min time frames from the initial 25 min frames in dynamic PET imaging, thus reducing the total scanning time.","2577-0829","978-1-7281-7693-2","10.1109/NSS/MIC42677.2020.9507894","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9507894","","Measurement;Deep learning;Training;PSNR;Predictive models;Brain modeling;Market research","brain;image reconstruction;learning (artificial intelligence);medical image processing;positron emission tomography","fast dynamic brain PET imaging;generative adversarial network;deep learning model;clinical information;clinical dataset;complete dynamic PET images;total acquisition time;dynamic PET scan;list-mode format;dynamic frames;tracer variation trend;structural similarity index;time-activity curve;synthesized frames;reference images;time frames;dynamic PET imaging;total scanning time;time 90.0 min;time 65.0 min;time 25.0 min;time 0.0 min to 25.0 min;time 25.0 min to 90.0 min","","","","7","","12 Aug 2021","","","IEEE","IEEE Conferences"
"Light-curve fingerprints: an automated approach to the extraction of X-ray variability patterns with feature aggregation – an example application to GRS 1915+105","J. K. Orwat-Kapola; A. J. Bird; A. B. Hill; D. Altamirano; D. Huppenkothen","School of Physics and Astronomy, University of Southampton, Southampton, Hampshire SO17 1BJ, UK; j.k.orwat-kapola@soton.ac.uk; School of Physics and Astronomy, University of Southampton, Southampton, Hampshire SO17 1BJ, UK; School of Physics and Astronomy, University of Southampton, Southampton, Hampshire SO17 1BJ, UK; HAL24K Labs, Herikerbergweg 292, NL-1101 CT Amsterdam, the Netherlands; School of Physics and Astronomy, University of Southampton, Southampton, Hampshire SO17 1BJ, UK; SRON Netherlands Institute for Space Research, Sorbonnelaan 3, NL-3584 CA Utrecht, the Netherlands","Monthly Notices of the Royal Astronomical Society","13 Dec 2021","2021","509","1","1269","1290","Time series data mining is an important field of research in the era of ‘Big Data’. Next generation astronomical surveys will generate data at unprecedented rates, creating the need for automated methods of data analysis. We propose a method of light-curve characterization that employs a pipeline consisting of a neural network with a long-short term memory variational autoencoder architecture and a Gaussian mixture model. The pipeline performs extraction and aggregation of features from light-curve segments into feature vectors of fixed length that we refer to as light-curve ‘fingerprints’. This representation can be readily used as input of down-stream machine learning algorithms. We demonstrate the proposed method on a data set of Rossi X-ray Timing Explorer observations of the Galactic black hole X-ray binary GRS 1915+105, which was chosen because of its observed complex X-ray variability. We find that the proposed method can generate a representation that characterizes the observations and reflects the presence of distinct classes of GRS 1915+105 X-ray flux variability. We find that this representation can be used to perform efficient classification of light curves. We also present how the representation can be used to quantify the similarity of different light curves, highlighting the problem of the popular classification system of GRS 1915+105 observations, which does not account for intermediate class behaviour.","1365-2966","","10.1093/mnras/stab3043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9648134","methods: data analysis;X-rays: binaries","","","","","","","","","13 Dec 2021","","","OUP","OUP Journals"
"Defending Adversarial Attacks via Semantic Feature Manipulation","S. Wang; S. Nepal; C. Rudolph; M. Grobler; T. Chen; S. Chen; Z. An","Data61, CSIRO, 2221 Melbourne, Victoria, Australia, (e-mail: shuo.wang@csiro.au); Data61, CSIRO, Marsfield, New South Wales, Australia, 2122 (e-mail: Surya.Nepal@data61.csiro.au); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria, Australia, (e-mail: Carsten.Rudolph@monash.edu); Data61, 170512 Melbourne, Victoria, Australia, (e-mail: Marthie.Grobler@data61.csiro.au); Faculty of Information Technology, Monash University, 2541 clayton, Victoria, Australia, (e-mail: tche119@student.monash.edu); School of Computing and Information Systems, The University of Melbourne, 2281 Melbourne, Victoria, Australia, (e-mail: shangyuc@student.unimelb.edu.au); UBC, 8166 Vancouver, British Columbia, Canada, (e-mail: zkan.work@outlook.com)","IEEE Transactions on Services Computing","","2021","PP","99","1","1","Machine learning models have demonstrated vulnerability to adversarial attacks, more specifically misclassification of adversarial examples. In this paper, we propose a one-off and attack-agnostic Feature Manipulation (FM)-Defense to detect and purify adversarial examples in an interpretable and efficient manner. The intuition is that the classification result of a normal image is generally resistant to non-significant intrinsic feature changes, e.g., varying thickness of handwritten digits. In contrast, adversarial examples are sensitive to such changes since the perturbation lacks transferability. To enable manipulation of features, a Combo-variational autoencoder is applied to learn disentangled latent codes that reveal semantic features. The resistance to classification change over the morphs, derived by varying and reconstructing latent codes, is used to detect suspicious inputs. Further, Combo-VAE is enhanced to purify the adversarial examples with good quality by considering class-shared and class-unique features. We empirically demonstrate the effectiveness of detection and the quality of purified instances. Our experiments on three datasets show that FM-Defense can detect nearly $100\%$ of adversarial examples produced by different state-of-the-art adversarial attacks. It achieves more than $99\%$ overall purification accuracy on the suspicious instances that close the manifold of clean examples.","1939-1374","","10.1109/TSC.2021.3090365","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9460767","Adversarial attacks;artificial intelligence;defense;latent representation;security","Resistance;Manifolds;Image reconstruction;Feature extraction;Semantics;Faces;Decoding","","","","","","","IEEE","18 Jun 2021","","","IEEE","IEEE Early Access Articles"
"Beyond the hubble sequence – exploring galaxy morphology with unsupervised machine learning","T. -Y. Cheng; M. Huertas-Company; C. J. Conselice; A. Aragón-Salamanca; B. E. Robertson; N. Ramachandra","Centre of Extragalactic Astronomy, Durham University, Stockton Road, Durham DH1 3LE, UK; School of Physics and Astronomy, University of Nottingham, University Park, Nottingham NG7 2RD, UK; ting-yun.cheng@durham.ac.uk; Instituto de Astrofísica de Canarias (IAC), Departamento de Astrofísica, Universidad de La Laguna (ULL), E-38200 La Laguna, Spain; LERMA, Observatoire de Paris, CNRS, PSL, Université Paris Diderot, France; School of Physics and Astronomy, University of Nottingham, University Park, Nottingham NG7 2RD, UK; Jodrell Bank Centre for Astrophysics, University of Manchester, Oxford Road, Manchester M13 9PL, UK; School of Physics and Astronomy, University of Nottingham, University Park, Nottingham NG7 2RD, UK; Department of Astronomy and Astrophysics, University of California, Santa Cruz, 1156 High Street, Santa Cruz, CA 95064, USA; High Energy Physics Division, Argonne National Laboratory, Lemont, IL 60439, USA","Monthly Notices of the Royal Astronomical Society","20 Jul 2021","2021","503","3","4446","4465","We explore unsupervised machine learning for galaxy morphology analyses using a combination of feature extraction with a vector-quantized variational autoencoder (VQ-VAE) and hierarchical clustering (HC). We propose a new methodology that includes: (1) consideration of the clustering performance simultaneously when learning features from images; (2) allowing for various distance thresholds within the HC algorithm; (3) using the galaxy orientation to determine the number of clusters. This set-up provides 27 clusters created with this unsupervised learning that we show are well separated based on galaxy shape and structure (e.g. Sérsic index, concentration, asymmetry, Gini coefficient). These resulting clusters also correlate well with physical properties such as the colour–magnitude diagram, and span the range of scaling relations such as mass versus size amongst the different machine-defined clusters. When we merge these multiple clusters into two large preliminary clusters to provide a binary classification, an accuracy of $\sim 87{{\ \rm per\ cent}}$ is reached using an imbalanced data set, matching real galaxy distributions, which includes 22.7 per cent early-type galaxies and 77.3 per cent late-type galaxies. Comparing the given clusters with classic Hubble types (ellipticals, lenticulars, early spirals, late spirals, and irregulars), we show that there is an intrinsic vagueness in visual classification systems, in particular galaxies with transitional features such as lenticulars and early spirals. Based on this, the main result in this work is not how well our unsupervised method matches visual classifications and physical properties, but that the method provides an independent classification that may be more physically meaningful than any visually based ones.","1365-2966","","10.1093/mnras/stab734","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9491341","techniques: image processing;galaxies: general;methods: data analysis","","","","","","","","","20 Jul 2021","","","OUP","OUP Journals"
"Neural Network-Based Matrix Completion for Minimal Configuration of Body Surface Potential Mapping","D. Bizcaino; K. Bujnarowski; M. Matyschik; H. Mauranen; R. Zhao; P. Bonizzi; J. Karel","Department of Data Science and Knowledge Engineering, Maastricht, The Netherlands; Department of Data Science and Knowledge Engineering, Maastricht, The Netherlands; Department of Data Science and Knowledge Engineering, Maastricht, The Netherlands; Department of Data Science and Knowledge Engineering, Maastricht, The Netherlands; Department of Data Science and Knowledge Engineering, Maastricht, The Netherlands; Department of Data Science and Knowledge Engineering, Maastricht, The Netherlands; Department of Data Science and Knowledge Engineering, Maastricht, The Netherlands","2019 Computing in Cardiology (CinC)","24 Feb 2020","2019","","","Page 1","Page 4","Body surface potential mapping (BSPM) provides high spatial resolution recordings of the electric potential of the heart on the body surface. BSPM can involve up to 200 electrodes, in contrast to standard 12-lead ECG. The costs and complexity of a BSPM procedure are a limiting factor to its use in clinical practice. Both can be reduced by using fewer electrodes and reconstructing signals from the missing electrodes with an artificial neural network. The minimal configuration consists of the electrodes that are most relevant for reliable reconstruction. We propose an architecture for a variational autoencoder, trained on BSPM procedures from the Nijmegen dataset: EDGAR [1], to reconstruct a full 65-lead system from a reduced number of input electrodes. Further, we determine the effect of an increased numbers of missing electrodes on the corresponding reconstruction error, and show that it is possible to achieve a good 65-lead reconstruction from as few as 12 electrodes. We consider the implication of our research in the scope of current BSPM practice, as well as the limitations of using neural networks for this task.","2325-887X","978-1-7281-6936-1","10.23919/CinC49843.2019.9005744","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005744","","Electrodes;Electrocardiography;Image reconstruction;Computer architecture;Electric potential;Standards;Microsoft Windows","bioelectric potentials;biomedical electrodes;electrocardiography;medical signal processing;neural nets","high-spatial resolution recordings;neural networks;reconstruction error;input electrodes;artificial neural network;reconstructing signals;BSPM procedure;ECG;electric potential;body surface potential mapping;neural network-based matrix completion","","","","9","","24 Feb 2020","","","IEEE","IEEE Conferences"
"Self-Supervised Remote Sensing Image Retrieval","K. Walter; M. J. Gibson; A. Sowmya","School of Computer Science and Engineering, University of New South Wales, Sydney, Australia; School of Computer Science and Engineering, University of New South Wales, Sydney, Australia; School of Computer Science and Engineering, University of New South Wales, Sydney, Australia","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","1683","1686","Current remote sensing platforms generate a vast amount of imagery but the best current methods to index and retrieve that data require expensive and difficult to procure labels. In this paper, we aim to address this problem by presenting a performant content based image retrieval (CBIR) system that is capable of indexing and retrieval using only unlabelled data. We investigate the use of self-supervised learning, a method for end-to-end learning of visual features from large datasets. In particular, we investigate the performance of four state-of-the-art self-supervised learning methods: variational autoencoders, bidirectional GANs, colourisation networks and DeepCluster, and evaluate the quality of the representations learned on remote sensing CBIR problems. Experiments on two very high resolution datasets show that the best of these methods, DeepCluster, is able to achieve near parity with supervised transfer learning despite not using any label information.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323294","content-based image retrieval;remote sensing;unsupervised learning;self-supervised learning","Feature extraction;Remote sensing;Task analysis;Generative adversarial networks;Data models;Image retrieval;Image reconstruction","content-based retrieval;feature extraction;geophysical image processing;image retrieval;learning (artificial intelligence);remote sensing","self-supervised remote sensing image retrieval;current remote sensing platforms;performant content based image retrieval system;indexing;unlabelled data;self-supervised learning;end-to-end learning;remote sensing CBIR problems;supervised transfer learning","","","","14","","17 Feb 2021","","","IEEE","IEEE Conferences"
"Multi-Source Multi-Label Learning for User Profiling in Online Games","X. Wen; S. Zhao; H. Wang; R. Wu; M. Qu; T. Hu; G. Chen; J. Tao; C. Fan","Computer Science, Zhejiang University, 12377 Hangzhou, China; Fuxi AI lab, Netease Inc, 485092 Hangzhou, Zhejiang, China; Computer Science, Zhejiang University, 12377 Hangzhou, Zhejiang, China, 310058; Fuxi AI lab, Netease Inc, 485092 Hangzhou, Zhejiang, China; Fuxi AI lab, Netease Inc, 485092 Hangzhou, Zhejiang, China; Computer Science, Zhejiang University, 12377 Hangzhou, Zhejiang, China; College of computer science, Zhejiang University, 12377 Hangzhou, Zhejiang, China; Fuxi AI lab, Netease Inc, 485092 Hangzhou, Zhejiang, China; Fuxi AI Lab, Netease Inc, 485092 Hangzhou, Zhejiang, China","IEEE Transactions on Multimedia","","2022","PP","99","1","1","In online games, user profiling plays a vital role in a variety of personalized services. Current solutions typically treat different dimensions or labels (e.g., willing to pay or not, high, medium, or low appetite for some gameplays) of the full user profiles as independent multi-class/binary classification tasks. However, such one-by-one profiling strategy clearly overlooks the implicitly correlations among profiling tasks, which results in a degraded performance. To cope with this issue, we make the first attempt to formalize this problem as a multi-label learning task. Accordingly, we develop a unified Multi-Source Multi-Label learning framework~(MSML) that well utilizes semantically rich features and labels for boosted user profiling in online games. Specifically, we first introduce a multi-source user representation network that exploits multi-source data in online games to obtain informative user representations. Subsequently, to handle multiple labels, we propose a novel embedding-based multi-label network that consists of two variational autoencoders with disentangled latent spaces. Note that our framework can guarantee the consistency of the training and testing phases by a novel dual-tower design to overcome the limitation of existing approaches that use one coupled decoder for both features and labels. Extensive experiments on six public multi-label datasets and one real-world online game dataset from Justice demonstrate that the proposed framework outperforms the state-of-the-art baseline methods. Moreover, our proposed framework has been successfully deployed in several online games, yielding a significant boost in multi-label user profiling.","1941-0077","","10.1109/TMM.2022.3171683","Natural Science Foundation of Zhejiang Province(grant numbers:No. LY18F020005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9767715","Multi-Label Learning;User Profiling;Disentangled Latent Space;Online Games","Games;Task analysis;Testing;Correlation;Training;Social networking (online);Learning systems","","","","","","","IEEE","3 May 2022","","","IEEE","IEEE Early Access Articles"
"Generative trapdoors for public key cryptography based on automatic entropy optimization","S. Zhu; Y. Han","Key Laboratory of Network and Information Security under the People's Armed Police, Xi'an, China; College of Cryptography Engineering, Engineering University of People's Armed Police, Xi'an, China","China Communications","23 Aug 2021","2021","18","8","35","46","Trapdoor is a key component of public key cryptography design which is the essential security foundation of modern cryptography. Normally, the traditional way in designing a trapdoor is to identify a computationally hard problem, such as the NPC problems. So the trapdoor in a public key encryption mechanism turns out to be a type of limited resource. In this paper, we generalize the methodology of adversarial learning model in artificial intelligence and introduce a novel way to conveniently obtain sub-optimal and computationally hard trapdoors based on the automatic information theoretic search technique. The basic routine is constructing a generative architecture to search and discover a probabilistic reversible generator which can correctly encoding and decoding any input messages. The architecture includes a trapdoor generator built on a variational autoencoder (VAE) responsible for searching the appropriate trapdoors satisfying a maximum of entropy, a random message generator yielding random noise, and a dynamic classifier taking the results of the two generator. The evaluation of our construction shows the architecture satisfying basic indistinguishability of outputs under chosen-plaintext attack model (CPA) and high efficiency in generating cheap trapdoors.","1673-5447","","10.23919/JCC.2021.08.003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9521144","generative model;public key encryption;indistinguishability model;security model;deep learning","Security;Artificial intelligence;Ciphers;Protocols;Computational modeling;Mathematical model;Decoding","encoding;entropy;learning (artificial intelligence);public key cryptography;search problems","generative trapdoors;automatic entropy optimization;public key cryptography design;security foundation;modern cryptography;computationally hard problem;NPC problems;public key encryption mechanism;adversarial learning model;computationally hard trapdoors;automatic information theoretic search technique;generative architecture;probabilistic reversible generator;trapdoor generator;appropriate trapdoors;random message generator;cheap trapdoors","","","","","","23 Aug 2021","","","IEEE","IEEE Magazines"
"Investigation for the Need of Traditional Data-Preprocessing when Applying Artificial Neural Networks to FMCW-Radar Data","J. Valtl; J. Mendez; G. Mauro; A. Cabrera; V. Issakov","Technische Universität Braunschweig, Braunschweig, Germany; Infineon Technologies AG, Neubiberg, Germany; Infineon Technologies AG, Neubiberg, Germany; Infineon Technologies AG, Neubiberg, Germany; Technische Universität Braunschweig, Braunschweig, Germany","2022 29th International Conference on Systems, Signals and Image Processing (IWSSIP)","17 Aug 2022","2022","CFP2255E-ART","","1","4","Robust functionality of autonomous driving vehicles relies on their ability to detect obstables and various scenarios on the road. This can be only achieved by applying robust, fast and efficient AI-based signal processing to radar data. In this work we present an empirical investigation on the question, whether one can apply artificial neural networks (ANNs) directly to frequency modulated continuous wave (FMCW) radar raw data. We show that preproceessing is not necessary if one has enough raw data. In our experiment we have data of 153 648 frames collected with a 60 GHz FMCW radar. We compare systematically the options of preprocessing the data using variational autoencoder, applying traditional preprocessing or omit data-preprocessing and apply ANN directly to raw data. We show that the last option results in 28% faster signal processing and highest accuracy. This is a promising result, since it enables edge computing and direct signal processing at the sensor level.","2157-8702","978-1-6654-9578-3","10.1109/IWSSIP55020.2022.9854472","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9854472","Artificial neural networks;Data preprocessing;Radar applications.","Training;Reactive power;Network topology;Roads;Training data;Random access memory;Artificial neural networks","CW radar;FM radar;neural nets;radar computing;remotely operated vehicles","artificial neural networks;autonomous driving vehicles;AI-based signal;frequency modulated continuous wave radar raw data;FMCW radar;ANN;faster signal processing;direct signal processing;frequency 60.0 GHz","","","","10","IEEE","17 Aug 2022","","","IEEE","IEEE Conferences"
"Predicting Drug-target Interaction Via Self-supervised Learning","J. Chen; L. Zhang; K. Cheng; B. Jin; X. Lu; C. Che","Dalian University, 74547 Dalian, Liaoning, China; Dongbei University of Finance and Economics, 12688 Dalian, Liaoning, China, 116025; Dalian University of Technology, 12399 Dalian, Liaoning, China; Dalian Univeristy of Technology, Dalian, Liaoning, China; Business Intelligence Lab, Baidu Inc, 438127 Beijing, Beijing, China; Dalian University, 74547 Dalian, Liaoning, China","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2022","PP","99","1","1","Recent advances in graph representation learning provide new opportunities for computational drug-target interaction (DTI) prediction. However, it still suffers from deficiencies of dependence on manual labels and vulnerability to attacks. Inspired by the success of self-supervised learning (SSL) algorithms, which can leverage input data itself as supervision, we propose SupDTI, a SSL-enhanced drug-target interaction prediction framework based on a heterogeneous network (i.e., drug-protein, drug-drug, and protein-protein interaction network; drug-disease, drug-side-effect, and protein-disease association network; drug-structure and protein-sequence similarity network). Specifically, SupDTI is an end-to-end learning framework consisting of five components. First, localized and globalized graph convolutions are designed to capture the nodes' information from both local and global perspectives, respectively. Then, we develop a variational autoencoder to constrain the nodes' representation to have desired statistical characteristics. Finally, a unified self-supervised learning strategy is leveraged to enhance the nodes' representation, namely, a contrastive learning module is employed to enable the nodes' representation to fit the graph-level representation, followed by a generative learning module which further maximizes the node-level agreement across the global and local views by learning the probabilistic connectivity distribution of the original heterogeneous network. Experimental results show that our model can achieve better prediction performance than state-of-the-art methods.","1557-9964","","10.1109/TCBB.2022.3153963","Liaoning Provincial Department of Education(grant numbers:LZ2019002); Guidance Program of Liaoning Natural Science Foundation(grant numbers:2019-ZD-0569); National Key RD Program of China(grant numbers:2018YFC0910500); National Natural Science Foundation of China(grant numbers:61772110,62076045); Key Program of Liaoning Traditional Chinese Medicine Administration(grant numbers:LNZYXZK201910); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723567","DTI prediction;self-supervised learning;contrastive learning;generative learning;graph neural network","Proteins;Drugs;Diffusion tensor imaging;Task analysis;Diseases;Mutual information;Heterogeneous networks","","","","","","","IEEE","1 Mar 2022","","","IEEE","IEEE Early Access Articles"
"Contextually Plausible and Diverse 3D Human Motion Prediction","S. Aliakbarian; F. Saleh; L. Petersson; S. Gould; M. Salzmann","Microsoft; ACRV, ANU; Data61, CSIRO; ACRV, ANU; CVLab, EPFL","2021 IEEE/CVF International Conference on Computer Vision (ICCV)","28 Feb 2022","2021","","","11313","11322","We tackle the task of diverse 3D human motion prediction, that is, forecasting multiple plausible future 3D poses given a sequence of observed 3D poses. In this context, a popular approach consists of using a Conditional Variational Autoencoder (CVAE). However, existing approaches that do so either fail to capture the diversity in human motion, or generate diverse but semantically implausible continuations of the observed motion. In this paper, we address both of these problems by developing a new variational framework that accounts for both diversity and context of the generated future motion. To this end, and in contrast to existing approaches, we condition the sampling of the latent variable that acts as source of diversity on the representation of the past observation, thus encouraging it to carry relevant information. Our experiments demonstrate that our approach yields motions not only of higher quality while retaining diversity, but also that preserve the contextual information contained in the observed motion.","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.01114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9710194","Gestures and body pose","Computer vision;Three-dimensional displays;Tracking;Semantics;Forecasting;Task analysis","","","","4","","32","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"Lifting Posture Prediction With Generative Models for Improving Occupational Safety","L. Li; S. Prabhu; Z. Xie; H. Wang; L. Lu; X. Xu","Edward P. Fitts Department of Industrial and Systems Engineering, North Carolina State University, Raleigh, NC, USA; Edward P. Fitts Department of Industrial and Systems Engineering, North Carolina State University, Raleigh, NC, USA; Edward P. Fitts Department of Industrial and Systems Engineering, North Carolina State University, Raleigh, NC, USA; Edward P. Fitts Department of Industrial and Systems Engineering, North Carolina State University, Raleigh, NC, USA; Edward P. Fitts Department of Industrial and Systems Engineering, North Carolina State University, Raleigh, NC, USA; Edward P. Fitts Department of Industrial and Systems Engineering, North Carolina State University, Raleigh, NC, USA","IEEE Transactions on Human-Machine Systems","17 Sep 2021","2021","51","5","494","503","Lifting tasks have been identified to be highly associated with work-related low back pain. Posture prediction can be used for simulating workers’ posture of lifting tasks and thus facilitate the prevention of low back pain (LBP). This study adopts two generative models, conditional variational encoder and conditional generative adversarial network, to predict lifting postures. A regular feed-forward neural network (FNN) developed upon previous studies is also investigated for comparison purposes. Ground-truth lifting posture data collected by a motion capture system is used for training and testing the models. The models are trained with datasets of different size and loss functions, and the results are compared. The conditional variational autoencoder and the regular FNN achieved comparable top performance in lifting posture prediction in terms of accuracy and posture validity. Both generative models are able to partially capture the variability of constrained postures. Overall, the results prove that using a generative model is able to predict postures with reasonable accuracy and validity (RMSE of coordinates = 0.049 m; RMSE of joint angles = 19.58$^\circ$). The predicted postures can support biomechanical analysis and ergonomics assessment of a lifting task to reduce the risk of low back injuries.","2168-2305","","10.1109/THMS.2021.3102511","National Science Foundation(grant numbers:1822477); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9521775","Generative models;lifting tasks;neural networks;occupational injuries;posture prediction","Predictive models;Decoding;Prediction algorithms;Training;Generative adversarial networks;Neural networks","","","","1","","37","IEEE","24 Aug 2021","","","IEEE","IEEE Journals"
"Zero-Shot Learning: An Energy Based Approach","T. Zhao; G. Liu; L. wu; C. Ma; E. Chen","Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China; Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China; Hefei University of Technology; Baidu Talent Intelligence Center; Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China","2018 IEEE International Conference on Data Mining (ICDM)","30 Dec 2018","2018","","","797","806","Zero-shot learning deals with the problem when the training domain and the test domain have different class sets of image instances. To tackle the problem of some classes in the test data never appeared in the training set, a most popular approach is to map both images and classes in a common space under the embedding based framework. Nevertheless, most embedding based models suffered from the semantic loss problem. Furthermore, the expressive power is limited by representing classes and images as mere points. To tackle these problems, in this paper, we propose an Energy-Based Zero-shot Learning model (EBZL) to encode the association between class attributes and input images for zero-shot learning. EBZL is composed of two parts. The first part is a variational autoencoder that reduces the input dimension of images with representative hidden representations. By feeding the hidden representations as the input of the second part, the second part works as the energy function part based on the deep Boltzmann machine. Specifically, we adapt tradition deep Boltzmann machine to a supervised setting without changing its property as an undirected probabilistic graphic model, which helps to preserve semantic integrity and circumvents semantic loss problem. We further utilize variational inference techniques and mean-field approximation to reduce time complexity in model training process. Finally, extensive experimental results on several real-world datasets clearly show the effectiveness of our proposed method.","2374-8486","978-1-5386-9159-5","10.1109/ICDM.2018.00095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594904","zero-shot learning;deep Boltzmann machine","Training;Semantics;Feature extraction;Probabilistic logic;Task analysis;Visualization;Training data","Boltzmann machines;computational complexity;image processing;inference mechanisms;learning (artificial intelligence)","training domain;test domain;different class sets;image instances;test data;training set;popular approach;embedding based framework;embedding based models;EBZL;class attributes;input images;representative hidden representations;energy function part;tradition deep Boltzmann machine;supervised setting;undirected probabilistic graphic model;semantic integrity;model training process;zero-shot learning;energy based approach;energy-based zero-shot","","","","41","","30 Dec 2018","","","IEEE","IEEE Conferences"
"The Pose Knows: Video Forecasting by Generating Pose Futures","J. Walker; K. Marino; A. Gupta; M. Hebert","Carnegie Mellon University, Pittsburgh, PA; Carnegie Mellon University, Pittsburgh, PA; Carnegie Mellon University, Pittsburgh, PA; Carnegie Mellon University, Pittsburgh, PA","2017 IEEE International Conference on Computer Vision (ICCV)","25 Dec 2017","2017","","","3352","3361","Current approaches to video forecasting attempt to generate videos directly in pixel space using Generative Adversarial Networks (GANs) or Variational Autoencoders (VAEs). However, since these approaches try to model all the structure and scene dynamics at once, in unconstrained settings they often generate uninterpretable results. Our insight is that forecasting needs to be done first at a higher level of abstraction. Specifically, we exploit human pose detectors as a free source of supervision and break the video forecasting problem into two discrete steps. First we explicitly model the high level structure of active objects in the scene (humans) and use a VAE to model the possible future movements of humans in the pose space. We then use the future poses generated as conditional information to a GAN to predict the future frames of the video in pixel space. By using the structured space of pose as an intermediate representation, we sidestep the problems that GANs have in generating video pixels directly. We show through quantitative and qualitative evaluation that our method outperforms state-of-the-art methods for video prediction.","2380-7504","978-1-5386-1032-9","10.1109/ICCV.2017.361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8237623","","Forecasting;Decoding;Gallium nitride;Semantics;Probability distribution;Predictive models","image motion analysis;pose estimation;video signal processing","video prediction;video pixels;pose space;video forecasting problem;pose detectors;scene dynamics;VAE;GAN;pixel space;video forecasting attempt;generating pose futures","","160","","56","","25 Dec 2017","","","IEEE","IEEE Conferences"
"Multimodal Probabilistic Model-Based Planning for Human-Robot Interaction","E. Schmerling; K. Leung; W. Vollprecht; M. Pavone","Institute for Computational & Mathematical Engineering, Stanford University, Stanford, CA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA; Department of Mechanical Engineering, ETH Zurich, Zurich, Switzerland; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA","2018 IEEE International Conference on Robotics and Automation (ICRA)","13 Sep 2018","2018","","","3399","3406","This paper presents a method for constructing human-robot interaction policies in settings where multimodality, i.e., the possibility of multiple highly distinct futures, plays a critical role in decision making. We are motivated in this work by the example of traffic weaving, e.g., at highway on-ramps/off-ramps, where entering and exiting cars must swap lanes in a short distance-a challenging negotiation even for experienced drivers due to the inherent multimodal uncertainty of who will pass whom. Our approach is to learn multimodal probability distributions over future human actions from a dataset of human-human exemplars and perform real-time robot policy construction in the resulting environment model through massively parallel sampling of human responses to candidate robot action sequences. Direct learning of these distributions is made possible by recent advances in the theory of conditional variational autoencoders (CVAEs), whereby we learn action distributions simultaneously conditioned on the present interaction history, as well as candidate future robot actions in order to take into account response dynamics. We demonstrate the efficacy of this approach with a human-in-the-loop simulation of a traffic weaving scenario.","2577-087X","978-1-5386-3081-5","10.1109/ICRA.2018.8460766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8460766","","Robots;Vehicles;Predictive models;History;Cognition;Probabilistic logic;Weaving","decision making;human-robot interaction;intelligent transportation systems;learning (artificial intelligence);probability","highway on-ramp-off-ramps;human-robot interaction policies;multimodal probabilistic model-based planning;traffic weaving scenario;human-in-the-loop simulation;candidate future robot actions;interaction history;action distributions;direct learning;candidate robot action sequences;human responses;massively parallel sampling;real-time robot policy construction;human-human exemplars;future human actions;multimodal probability distributions;inherent multimodal uncertainty;experienced drivers;entering exiting cars;decision making","","59","","40","","13 Sep 2018","","","IEEE","IEEE Conferences"
"MR Image Reconstruction Using Deep Density Priors","K. C. Tezcan; C. F. Baumgartner; R. Luechinger; K. P. Pruessmann; E. Konukoglu","Computer Vision Laboratory, ETH Zürich, Zürich, Switzerland; Computer Vision Laboratory, ETH Zürich, Zürich, Switzerland; Institute for Biomedical Engineering, ETH Zürich, Zürich, Switzerland; Institute for Biomedical Engineering, ETH Zürich, Zürich, Switzerland; Computer Vision Laboratory, ETH Zürich, Zürich, Switzerland","IEEE Transactions on Medical Imaging","28 Jun 2019","2019","38","7","1633","1642","Algorithms for magnetic resonance (MR) image reconstruction from undersampled measurements exploit prior information to compensate for missing k-space data. Deep learning (DL) provides a powerful framework for extracting such information from existing image datasets, through learning, and then using it for reconstruction. Leveraging this, recent methods employed DL to learn mappings from undersampled to fully sampled images using paired datasets, including undersampled and corresponding fully sampled images, integrating prior knowledge implicitly. In this letter, we propose an alternative approach that learns the probability distribution of fully sampled MR images using unsupervised DL, specifically variational autoencoders (VAE), and use this as an explicit prior term in reconstruction, completely decoupling the encoding operation from the prior. The resulting reconstruction algorithm enjoys a powerful image prior to compensate for missing k-space data without requiring paired datasets for training nor being prone to associated sensitivities, such as deviations in undersampling patterns used in training and test time or coil settings. We evaluated the proposed method with T1 weighted images from a publicly available dataset, multi-coil complex images acquired from healthy volunteers ( ${N}=8$ ), and images with white matter lesions. The proposed algorithm, using the VAE prior, produced visually high quality reconstructions and achieved low RMSE values, outperforming most of the alternative methods on the same dataset. On multi-coil complex data, the algorithm yielded accurate magnitude and phase reconstruction results. In the experiments on images with white matter lesions, the method faithfully reconstructed the lesions.","1558-254X","","10.1109/TMI.2018.2887072","Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung(grant numbers:205321_173016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8579232","Reconstruction;MRI;prior probability;machine learning;deep learning;unsupervised learning;density estimation","Image reconstruction;Reconstruction algorithms;Training;Data models;Signal processing algorithms;Mathematical model","","","Algorithms;Connectome;Deep Learning;Humans;Image Processing, Computer-Assisted;Magnetic Resonance Imaging","36","","56","OAPA","16 Dec 2018","","","IEEE","IEEE Journals"
"An Empirical Evaluation of Deep Learning for Network Anomaly Detection","R. K. Malaiya; D. Kwon; J. Kim; S. C. Suh; H. Kim; I. Kim","Texas A&M University, Commerce, TX, USA; Texas A&M University, Commerce, TX, USA; Texas A&M University, Commerce, TX, USA; Texas A&M University, Commerce, TX, USA; ETRI, Daejeon, Korea; ETRI, Daejeon, Korea","2018 International Conference on Computing, Networking and Communications (ICNC)","21 Jun 2018","2018","","","893","898","Deep learning has been given a great deal of attention with its success story in many areas such as image analysis and speech recognition. In particular, deep learning is good at dealing with high-dimensional data exhibiting non-linearity. Our preliminary study reveals a very high degree of non-linearity from network traffic data, which explains why it is hard to improve the detection accuracy by using conventional machine learning techniques (e.g., SVM, Random Forest, Ad-aboosting). In this study, we empirically evaluate deep learning to see its feasibility for network anomaly detection. We examine a set of deep learning models constructed based on the Fully Connected Network (FCN), Variational AutoEncoder (VAE), and Long Short-Term Memory with Sequence to Sequence (LSTM Seq2Seq) structures, with two public traffic data sets that have distinctive properties with respect to the distribution of normal and attack populations. Our experimental results confirm the potential of deep learning models for network anomaly detection, and the model based on the LSTM Seq2Seq structure shows a highly promising performance, yielding 99% of binary classification accuracy on the public data sets.","","978-1-5386-3652-7","10.1109/ICCNC.2018.8390278","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8390278","","Machine learning;Anomaly detection;Data models;Training;Numerical models;Computational modeling;Performance evaluation","learning (artificial intelligence);neural nets;pattern classification","public traffic data sets;deep learning models;network anomaly detection;LSTM Seq2Seq structure;public data sets;image analysis;speech recognition;high-dimensional data exhibiting nonlinearity;network traffic data;Fully Connected Network;long short-term memory with sequence structures","","21","","26","","21 Jun 2018","","","IEEE","IEEE Conferences"
"Predicting Lymph Node Metastasis Using Histopathological Images Based on Multiple Instance Learning With Deep Graph Convolution","Y. Zhao; F. Yang; Y. Fang; H. Liu; N. Zhou; J. Zhang; J. Sun; S. Yang; B. Menze; X. Fan; J. Yao",Technical University of Munich; Tencent AI Lab; The Chinese University of Hong Kong; Sixth Affiliated Hospital of Sun Yat-sen University; Tencent AI Lab; Tencent AI Lab; Tencent AI Lab; Tencent AI Lab; Technical University of Munich; Sixth Affiliated Hospital of Sun Yat-sen University; Tencent AI Lab,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","4836","4845","Multiple instance learning (MIL) is a typical weakly-supervised learning method where the label is associated with a bag of instances instead of a single instance. Despite extensive research over past years, effectively deploying MIL remains an open and challenging problem, especially when the commonly assumed standard multiple instance (SMI) assumption is not satisfied. In this paper, we propose a multiple instance learning method based on deep graph convolutional network and feature selection (FS-GCN-MIL) for histopathological image classification. The proposed method consists of three components, including instance-level feature extraction, instance-level feature selection, and bag-level classification. We develop a self-supervised learning mechanism to train the feature extractor based on a combination model of variational autoencoder and generative adversarial network (VAE-GAN). Additionally, we propose a novel instance-level feature selection method to select the discriminative instance features. Furthermore, we employ a graph convolutional network (GCN) for learning the bag-level representation and then performing the classification. We apply the proposed method in the prediction of lymph node metastasis using histopathological images of colorectal cancer. Experimental results demonstrate that the proposed method achieves superior performance compared to the state-of-the-art methods.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00489","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156339","","Feature extraction;Generative adversarial networks;Gallium nitride;Lymph nodes;Metastasis;Task analysis","cancer;feature extraction;image classification;learning (artificial intelligence);medical image processing","lymph node metastasis;histopathological images;deep graph convolution;weakly-supervised learning method;multiple instance learning method;deep graph convolutional network;FS-GCN-MIL;histopathological image classification;instance-level feature extraction;bag-level classification;self-supervised learning mechanism;feature extractor;discriminative instance features;bag-level representation;instance-level feature selection method","","20","","50","IEEE","5 Aug 2020","","","IEEE","IEEE Conferences"
"Heterogeneous Knowledge-Based Attentive Neural Networks for Short-Term Music Recommendations","Q. Lin; Y. Niu; Y. Zhu; H. Lu; K. Z. Mushonga; Z. Niu","School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Technology, Lanzhou Jiaotong University, Lanzhou, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China","IEEE Access","31 Oct 2018","2018","6","","58990","59000","The current existing data in online music service platforms are heterogeneous, extensive, and disorganized. Finding an effective method to use these data in recommending appropriate music to users during a short-term session is a significant challenge. Another serious problem is that most of the data, in reality, obey the long-tailed distribution, which consequently leads to traditional music recommendation systems recommending a lot of popular music that users do not like on a specific occasion. To solve these problems, we propose a heterogeneous knowledge-based attentive neural network model for short-term music recommendations. First, we collect three types of data for modeling entities in user–music interaction network, i.e., graphic, textual, and visual data, and then embed them into high-dimensional spaces using the TransR, distributed memory version of paragraph vector, and variational autoencoder methods, respectively. The concatenation of these embedding results is an abstract representation of the entity. Based on this, a recurrent neural network with an attention mechanism is built, which is capable of obtaining users’ preferences in the current session and consequently making recommendations. The experimental results show that our proposed approach outperforms the current state-of-the-art short-term music recommendation systems on one real-world dataset. In addition, it can also recommend more relatively unpopular songs compared with classic models.","2169-3536","","10.1109/ACCESS.2018.2874959","National Natural Science Foundation of China(grant numbers:61370137); Ministry of Education-China Mobile Research Foundation Project(grant numbers:2016/2-7); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8486952","Heterogeneous knowledge;data embedding;entity representation;attentive neural networks;short-term music recommendation","Recommender systems;Data models;Knowledge based systems;Visualization;Recurrent neural networks","","","","17","","51","OAPA","9 Oct 2018","","","IEEE","IEEE Journals"
"HuMoR: 3D Human Motion Model for Robust Pose Estimation","D. Rempe; T. Birdal; A. Hertzmann; J. Yang; S. Sridhar; L. J. Guibas",Stanford University; Stanford University; Adobe Research; Adobe Research; Brown University; Stanford University,"2021 IEEE/CVF International Conference on Computer Vision (ICCV)","28 Feb 2022","2021","","","11468","11479","We introduce HuMoR: a 3D Human Motion Model for Robust Estimation of temporal pose and shape. Though substantial progress has been made in estimating 3D human motion and shape from dynamic observations, recovering plausible pose sequences in the presence of noise and occlusions remains a challenge. For this purpose, we propose an expressive generative model in the form of a conditional variational autoencoder, which learns a distribution of the change in pose at each step of a motion sequence. Furthermore, we introduce a flexible optimization-based approach that leverages HuMoR as a motion prior to robustly estimate plausible pose and shape from ambiguous observations. Through extensive evaluations, we demonstrate that our model generalizes to diverse motions and body shapes after training on a large motion capture dataset, and enables motion reconstruction from multiple input modalities including 3D keypoints and RGB(-D) videos. See the project page at geometry.stanford.edu/projects/humor.","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.01129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9711220","Gestures and body pose;Motion and tracking;Neural generative models;Scene analysis and understanding;Video analysis and understanding","Training;Solid modeling;Computer vision;Three-dimensional displays;Shape;Computational modeling;Pose estimation","","","","16","","91","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"We are More than Our Joints: Predicting how 3D Bodies Move","Y. Zhang; M. J. Black; S. Tang","ETH Zürich, Switzerland; Max Planck Institute for Intelligent Systems, Tübingen, Germany; ETH Zürich, Switzerland","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","2 Nov 2021","2021","","","3371","3381","A key step towards understanding human behavior is the prediction of 3D human motion. Successful solutions have many applications in human tracking, HCI, and graphics. Most previous work focuses on predicting a time series of future 3D joint locations given a sequence 3D joints from the past. This Euclidean formulation generally works better than predicting pose in terms of joint rotations. Body joint locations, however, do not fully constrain 3D human pose, leaving degrees of freedom (like rotation about a limb) undefined. Note that 3D joints can be viewed as a sparse point cloud. Thus the problem of human motion prediction can be seen as a problem of point cloud prediction. With this observation, we instead predict a sparse set of locations on the body surface that correspond to motion capture markers. Given such markers, we fit a parametric body model to recover the 3D body of the person. These sparse surface markers also carry detailed information about human movement that is not present in the joints, increasing the naturalness of the predicted motions. Using the AMASS dataset, we train MOJO (More than Our JOints), which is a novel variational autoencoder with a latent DCT space that generates motions from latent frequencies. MOJO preserves the full temporal resolution of the input motion, and sampling from the latent frequencies explicitly introduces high-frequency components into the generated motion. We note that motion prediction methods accumulate errors over time, resulting in joints or markers that diverge from true human bodies. To address this, we fit the SMPL-X body model to the predictions at each time step, projecting the solution back onto the space of valid bodies, before propagating the new markers in time. Quantitative and qualitative experiments show that our approach produces state-of-the-art results and realistic 3D body animations. The code is available for research purposes at https://yz-cnsdqz.github.io/MOJO/MOJO.html.","2575-7075","978-1-6654-4509-2","10.1109/CVPR46437.2021.00338","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9578865","","Solid modeling;Three-dimensional displays;Tracking;Shape;Time series analysis;Pipelines;Predictive models","computer animation;human computer interaction;image motion analysis;image sequences;motion estimation;pose estimation;solid modelling;video signal processing","SMPL-X body model;valid bodies;realistic 3D body animations;3D bodies;human behavior;3D human motion;human tracking;future 3D joint locations;joint rotations;body joint locations;sparse point cloud;human motion prediction;point cloud prediction;body surface;motion capture markers;parametric body model;sparse surface markers;human movement;predicted motions;latent frequencies;input motion;generated motion;motion prediction methods accumulate errors;human bodies","","13","","62","IEEE","2 Nov 2021","","","IEEE","IEEE Conferences"
"Real-time Out-of-distribution Detection in Learning-Enabled Cyber-Physical Systems","F. Cai; X. Koutsoukos","Vanderbilt University, Nashville, TN; Vanderbilt University, Nashville, TN","2020 ACM/IEEE 11th International Conference on Cyber-Physical Systems (ICCPS)","19 May 2020","2020","","","174","183","Cyber-physical systems (CPS) greatly benefit by using machine learning components that can handle the uncertainty and variability of the real-world. Typical components such as deep neural networks, however, introduce new types of hazards that may impact system safety. The system behavior depends on data that are available only during runtime and may be different than the data used for training. Out-of-distribution data may lead to a large error and compromise safety. The paper considers the problem of efficiently detecting out-of-distribution data in CPS control systems. Detection must be robust and limit the number of false alarms while being computational efficient for real-time monitoring. The proposed approach leverages inductive conformal prediction and anomaly detection for developing a method that has a well-calibrated false alarm rate. We use variational autoencoders and deep support vector data description to learn models that can be used efficiently compute the nonconformity of new inputs relative to the training set and enable realtime detection of out-of-distribution high-dimensional inputs. We demonstrate the method using an advanced emergency braking system and a self-driving end-to-end controller implemented in an open source simulator for self-driving cars. The simulation results show very small number of false positives and detection delay while the execution time is comparable to the execution time of the original machine learning components.","2642-9500","978-1-7281-5501-2","10.1109/ICCPS48487.2020.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9095995","anomaly detection;inductive conformal prediction;out-of-distribution;self-driving vehicles.","Training;Anomaly detection;Real-time systems;Safety;Robustness;Training data;Testing","braking;learning (artificial intelligence);neural nets;support vector machines","learning-enabled cyber-physical systems;deep neural networks;system safety;system behavior;CPS control systems;anomaly detection;false alarm rate;deep support vector data description;realtime detection;out-of-distribution high-dimensional inputs;advanced emergency braking system;real-time out-of-distribution detection;inductive conformal prediction;self-driving cars","","11","","26","","19 May 2020","","","IEEE","IEEE Conferences"
"Uncertainty Quantification in Deep MRI Reconstruction","V. Edupuganti; M. Mardani; S. Vasanawala; J. Pauly","Department of Electrical Engineering, Stanford University, Stanford, CA, USA; Department of Electrical Engineering, Stanford University, Stanford, CA, USA; Department of Radiology, Stanford University, Stanford, CA, USA; Department of Electrical Engineering, Stanford University, Stanford, CA, USA","IEEE Transactions on Medical Imaging","29 Dec 2020","2021","40","1","239","250","Reliable MRI is crucial for accurate interpretation in therapeutic and diagnostic tasks. However, undersampling during MRI acquisition as well as the overparameterized and non-transparent nature of deep learning (DL) leaves substantial uncertainty about the accuracy of DL reconstruction. With this in mind, this study aims to quantify the uncertainty in image recovery with DL models. To this end, we first leverage variational autoencoders (VAEs) to develop a probabilistic reconstruction scheme that maps out (low-quality) short scans with aliasing artifacts to the diagnostic-quality ones. The VAE encodes the acquisition uncertainty in a latent code and naturally offers a posterior of the image from which one can generate pixel variance maps using Monte-Carlo sampling. Accurately predicting risk requires knowledge of the bias as well, for which we leverage Stein's Unbiased Risk Estimator (SURE) as a proxy for mean-squared-error (MSE). A range of empirical experiments is performed for Knee MRI reconstruction under different training losses (adversarial and pixel-wise) and unrolled recurrent network architectures. Our key observations indicate that: 1) adversarial losses introduce more uncertainty; and 2) recurrent unrolled nets reduce the prediction uncertainty and risk.","1558-254X","","10.1109/TMI.2020.3025065","NIH(grant numbers:R01EB009690,R01EB026136); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201098","Uncertainty quantification;VAE;MRI reconstruction;SURE","Image reconstruction;Uncertainty;Magnetic resonance imaging;Biomedical imaging;Data models;Training;Probabilistic logic","biomedical MRI;image denoising;image reconstruction;learning (artificial intelligence);mean square error methods;medical image processing;Monte Carlo methods","Stein Unbiased Risk Estimator;substantial uncertainty;deep learning;MRI acquisition;deep MRI reconstruction;uncertainty quantification;prediction uncertainty;Knee MRI reconstruction;mean-squared-error;Monte-Carlo sampling;pixel variance maps;acquisition uncertainty;diagnostic-quality ones;probabilistic reconstruction scheme;DL reconstruction","Artifacts;Image Processing, Computer-Assisted;Magnetic Resonance Imaging;Monte Carlo Method;Uncertainty","10","","40","IEEE","21 Sep 2020","","","IEEE","IEEE Journals"
"Action-Conditioned 3D Human Motion Synthesis with Transformer VAE","M. Petrovich; M. J. Black; G. Varol","LIGM, École des Ponts, Univ Gustave Eiffel, CNRS, France; Max Planck Institute for Intelligent Systems, Tübingen, Germany; LIGM, École des Ponts, Univ Gustave Eiffel, CNRS, France","2021 IEEE/CVF International Conference on Computer Vision (ICCV)","28 Feb 2022","2021","","","10965","10975","We tackle the problem of action-conditioned generation of realistic and diverse human motion sequences. In contrast to methods that complete, or extend, motion sequences, this task does not require an initial pose or sequence. Here we learn an action-aware latent representation for human motions by training a generative variational autoencoder (VAE). By sampling from this latent space and querying a certain duration through a series of positional encodings, we synthesize variable-length motion sequences conditioned on a categorical action. Specifically, we design a Transformer-based architecture, ACTOR, for encoding and decoding a sequence of parametric SMPL human body models estimated from action recognition datasets. We evaluate our approach on the NTU RGB+D, HumanAct12 and UESTC datasets and show improvements over the state of the art. Furthermore, we present two use cases: improving action recognition through adding our synthesized data to training, and motion denoising. Code and models are available on our project page [53].","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.01080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9711041","Gestures and body pose;Action and behavior recognition;Neural generative models","Training;Solid modeling;Computer vision;Three-dimensional displays;Motion estimation;Noise reduction;Transformers","","","","10","","73","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"Cross-Dataset Hyperspectral Image Classification Based on Adversarial Domain Adaptation","X. Ma; X. Mou; J. Wang; X. Liu; J. Geng; H. Wang","Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian, China; Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian, China; School of Information Science and Technology, Dalian Maritime University, Dalian, China; School of Information Science and Technology, Dalian Maritime University, Dalian, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian, China","IEEE Transactions on Geoscience and Remote Sensing","21 Apr 2021","2021","59","5","4179","4190","The cross-data set knowledge is vital for hyperspectral image classification, which can reduce the dependence on the sample quantity by transferring knowledge from other data sets and improve the training efficiency by sharing knowledge between different data sets. However, due to the capturing environment change and imaging equipment difference, domain shift troubles the exploitation of the cross-data set knowledge. To address the aforementioned issue, this article proposes an unsupervised cross-data set hyperspectral image classification method based on adversarial domain adaptation. The proposed method, which employs multiple classifiers to build a discriminator and uses variational autoencoders to constitute a generator, works in an adversarial manner to drive the target samples under the support of the source domain. In particular, the classification error and the classification disagreement are considered in the objective function, which helps to align different domains while keeping the boundaries of different classes. Experimental results of the multidomain data set demonstrate that the proposed method can transfer and share cross-data set knowledge and achieve state-of-the-art performance without using the labeled information of the target data set.","1558-0644","","10.1109/TGRS.2020.3015357","National Natural Science Foundation of China(grant numbers:61801078,61671103,U1933104); China Postdoctoral Science Foundation(grant numbers:2018M630288); Liaoning Province Natural Science Foundation(grant numbers:20180520026); Dalian Science and Technology Innovation Foundation(grant numbers:2018J12GX044); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9170834","Classification;cross-data set;domain adaptation;hyperspectral image","Hyperspectral imaging;Training;Generators;Task analysis;Deep learning","image classification;learning (artificial intelligence);pattern classification;terrain mapping","cross-dataset hyperspectral image classification;adversarial domain adaptation;cross-data set knowledge;capturing environment change;imaging equipment difference;unsupervised cross-data set hyperspectral image classification method;align different domains","","10","","45","IEEE","18 Aug 2020","","","IEEE","IEEE Journals"
"Semi-Supervised Source Localization in Reverberant Environments With Deep Generative Modeling","M. J. Bianco; S. Gannot; E. Fernandez-Grande; P. Gerstoft","Marine Physical Laboratory, University of California San Diego, San Diego, CA, USA; Faculty of Engineering, Bar-Ilan University, Ramat-Gan, Israel; Department of Electrical Engineering, Technical University of Denmark, Kongens Lyngby, Denmark; Marine Physical Laboratory, University of California San Diego, San Diego, CA, USA","IEEE Access","17 Jun 2021","2021","9","","84956","84970","Localization in reverberant environments remains an open challenge. Recently, supervised learning approaches have demonstrated very promising results in addressing reverberation. However, even with large data volumes, the number of labels available for supervised learning in such environments is usually small. We propose to address this issue with a semi-supervised learning (SSL) approach, based on deep generative modeling. Our chosen deep generative model, the variational autoencoder (VAE), is trained to generate the phase of relative transfer functions (RTFs) between microphones. In parallel, a direction of arrival (DOA) classifier network based on RTF-phase is also trained. The joint generative and discriminative model, deemed VAE-SSL, is trained using labeled and unlabeled RTF-phase sequences. In learning to generate and classify the sequences, the VAE-SSL extracts the physical causes of the RTF-phase (i.e., source location) from distracting signal characteristics such as noise and speech activity. This facilitates effective end-to-end operation of the VAE-SSL, which requires minimal preprocessing of RTF-phase. VAE-SSL is compared with two signal processing-based approaches, steered response power with phase transform (SRP-PHAT) and MUltiple SIgnal Classification (MUSIC), as well as fully supervised CNNs. The approaches are compared using data from two real acoustic environments - one of which was recently obtained at Technical University of Denmark specifically for our study. We find that VAE-SSL can outperform the conventional approaches and the CNN in label-limited scenarios. Further, the trained VAE-SSL system can generate new RTF-phase samples which capture the physics of the acoustic environment. Thus, the generative modeling in VAE-SSL provides a means of interpreting the learned representations. To the best of our knowledge, this paper presents the first approach to modeling the physics of acoustic propagation using deep generative modeling.","2169-3536","","10.1109/ACCESS.2021.3087697","Office of Naval Research(grant numbers:N00014-11-1-0439); European Union’s Horizon 2020 Research and Innovation Program(grant numbers:871245); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9449880","Source localization;semi-supervised learning;generative modeling;deep learning","Acoustics;Location awareness;Direction-of-arrival estimation;Microphones;Data models;Task analysis;Position measurement","acoustic signal processing;convolutional neural nets;direction-of-arrival estimation;learning (artificial intelligence);microphone arrays;microphones;reverberation;signal classification;speech processing;transfer functions","joint generative;discriminative model;deemed VAE-SSL;labeled RTF-phase sequences;unlabeled RTF-phase sequences;signal processing-based approaches;fully supervised CNN;acoustic environment;trained VAE-SSL system;RTF-phase samples;learned representations;deep generative modeling;semisupervised source localization;reverberant environments;supervised learning approaches;addressing reverberation;semisupervised learning approach;chosen deep generative model","","8","","49","CCBY","9 Jun 2021","","","IEEE","IEEE Journals"
"FMRI Data Augmentation Via Synthesis","P. Zhuang; A. G. Schwing; O. Koyejo","Dept. of Computer Science, University of Illinois at Urbana-Champaign; Dept. of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Beckman Institute, University of Illinois at Urbana-Champaign","2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)","11 Jul 2019","2019","","","1783","1787","We present an empirical evaluation of fMRI data augmentation via synthesis. For synthesis we use generative models trained on real neuroimaging data to produce novel task-dependent functional brain images. Analyzed generative models include classic approaches such as the Gaussian mixture model (GMM), and modern implicit generative models such as the generative adversarial network (GAN) and the variational autoencoder (VAE). In particular, the proposed GAN and VAE models utilize 3-dimensional convolutions, which enables modeling of high-dimensional brain image tensors with structured spatial correlations. The synthesized datasets are then used to augment classifiers designed to predict cognitive and behavioural outcomes. Our results suggest that the proposed models are able to generate high-quality synthetic brain images which are diverse and task-dependent. Perhaps most importantly, the performance improvements of data augmentation via synthesis are shown to be complementary to the choice of the predictive model. Thus, our results suggest that data augmentation via synthesis is a promising approach to address the limited availability of fMRI data, and to improve the quality of predictive fMRI models.","1945-8452","978-1-5386-3641-1","10.1109/ISBI.2019.8759585","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759585","fMRI generation;GANs;VAEs;GMMs","Gallium nitride;Brain modeling;Three-dimensional displays;Support vector machines;Functional magnetic resonance imaging;Data models","biomedical MRI;brain;cognition;Gaussian processes;learning (artificial intelligence);medical image processing;neurophysiology","fMRI data augmentation;neuroimaging data;Gaussian mixture model;generative adversarial network;VAE models;high-dimensional brain image tensors;high-quality synthetic brain images;predictive fMRI models;implicit generative models;GAN models;3D convolutions;task-dependent functional brain images","","8","","20","","11 Jul 2019","","","IEEE","IEEE Conferences"
"Dual-Cycle Constrained Bijective Vae-Gan For Tagged-To-Cine Magnetic Resonance Image Synthesis","X. Liu; F. Xing; J. L. Prince; A. Carass; M. Stone; G. E. Fakhri; J. Woo","Dept. of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, MA, USA; Dept. of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, MA, USA; Dept. of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA; Dept. of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA; Dept. of Neural and Pain Sciences, University of Maryland School of Dentistry, Baltimore, MD, USA; Dept. of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, MA, USA; Dept. of Radiology, Massachusetts General Hospital and Harvard Medical School, Boston, MA, USA","2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)","25 May 2021","2021","","","1448","1452","Tagged magnetic resonance imaging (MRI) is a widely used imaging technique for measuring tissue deformation in moving organs. Due to tagged MRI’s intrinsic low anatomical resolution, another matching set of cine MRI with higher resolution is sometimes acquired in the same scanning session to facilitate tissue segmentation, thus adding extra time and cost. To mitigate this, in this work, we propose a novel dual-cycle constrained bijective VAE-GAN approach to carry out tagged-to-cine MR image synthesis. Our method is based on a variational autoencoder backbone with cycle reconstruction constrained adversarial training to yield accurate and realistic cine MR images given tagged MR images. Our framework has been trained, validated, and tested using 1,768, 416, and 1,560 subject-independent paired slices of tagged and cine MRI from twenty healthy subjects, respectively, demonstrating superior performance over the comparison methods. Our method can potentially be used to reduce the extra acquisition time and cost, while maintaining the same workflow for further motion analyses.","1945-8452","978-1-6654-1246-9","10.1109/ISBI48211.2021.9433852","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9433852","Tagged MRI;image synthesis;deep learning;Generative adversarial networks","Training;Image segmentation;Image resolution;Image synthesis;Magnetic resonance imaging;Motion segmentation;Magnetic resonance","biological tissues;biomechanics;biomedical MRI;cardiology;image segmentation;medical image processing","tissue segmentation;VAE-GAN approach;tagged-to-cine MR image synthesis;cycle reconstruction;cine MR images;tagged MR images;dual-cycle constrained bijective vae-gan;magnetic resonance image synthesis;tagged magnetic resonance imaging;imaging technique;tissue deformation;MRI intrinsic low-anatomical resolution","","6","","20","IEEE","25 May 2021","","","IEEE","IEEE Conferences"
"Overcoming Long-Term Catastrophic Forgetting Through Adversarial Neural Pruning and Synaptic Consolidation","J. Peng; B. Tang; H. Jiang; Z. Li; Y. Lei; T. Lin; H. Li","School of Geosciences and Info-Physics, Central South University, Changsha, China; Department of Electrical and Computer Engineering, Mississippi State University, Starkville, MS, USA; School of Geosciences and Info-Physics, Central South University, Changsha, China; School of Geosciences and Info-Physics, Central South University, Changsha, China; College of Electronics and Information Engineering, Sichuan University, Chengdu, China; College of Biosystems Engineering and Food Science, Zhejiang University, Hangzhou, China; School of Geosciences and Info-Physics, Central South University, Changsha, China","IEEE Transactions on Neural Networks and Learning Systems","31 Aug 2022","2022","33","9","4243","4256","Enabling a neural network to sequentially learn multiple tasks is of great significance for expanding the applicability of neural networks in real-world applications. However, artificial neural networks face the well-known problem of catastrophic forgetting. What is worse, the degradation of previously learned skills becomes more severe as the task sequence increases, known as the long-term catastrophic forgetting. It is due to two facts: first, as the model learns more tasks, the intersection of the low-error parameter subspace satisfying for these tasks becomes smaller or even does not exist; second, when the model learns a new task, the cumulative error keeps increasing as the model tries to protect the parameter configuration of previous tasks from interference. Inspired by the memory consolidation mechanism in mammalian brains with synaptic plasticity, we propose a confrontation mechanism in which Adversarial Neural Pruning and synaptic Consolidation (ANPyC) is used to overcome the long-term catastrophic forgetting issue. The neural pruning acts as long-term depression to prune task-irrelevant parameters, while the novel synaptic consolidation acts as long-term potentiation to strengthen task-relevant parameters. During the training, this confrontation achieves a balance in that only crucial parameters remain, and non-significant parameters are freed to learn subsequent tasks. ANPyC avoids forgetting important information and makes the model efficient to learn a large number of tasks. Specifically, the neural pruning iteratively relaxes the current task’s parameter conditions to expand the common parameter subspace of the task; the synaptic consolidation strategy, which consists of a structure-aware parameter-importance measurement and an element-wise parameter updating strategy, decreases the cumulative error when learning new tasks. Our approach encourages the synapse to be sparse and polarized, which enables long-term learning and memory. ANPyC exhibits effectiveness and generalization on both image classification and generation tasks with multiple layer perceptron, convolutional neural networks, and generative adversarial networks, and variational autoencoder. The full source code is available at https://github.com/GeoX-Lab/ANPyC.","2162-2388","","10.1109/TNNLS.2021.3056201","National Natural Science Foundation of China(grant numbers:41871364,41861048,41871302,41871276); Computing Resources at the High Performance Computing Platform of Central South University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354016","Adversarial;catastrophic forgetting;long-term learning;neural pruning;synaptic consolidation","Task analysis;Learning systems;Biological neural networks;Synapses;Measurement uncertainty;Neurons;Training","convolutional neural nets;learning (artificial intelligence);multilayer perceptrons","adversarial neural pruning;artificial neural networks;task sequence increases;low-error parameter subspace;cumulative error;parameter configuration;memory consolidation mechanism;synaptic plasticity;long-term catastrophic forgetting issue;synaptic consolidation;task-relevant parameters;common parameter subspace;synaptic consolidation strategy;structure-aware parameter-importance measurement;element-wise parameter updating strategy;long-term learning;image classification;convolutional neural networks;generative adversarial networks;neural pruning","Animals;Brain;Learning;Machine Learning;Mammals;Neural Networks, Computer;Neuronal Plasticity","6","","54","IEEE","12 Feb 2021","","","IEEE","IEEE Journals"
"Performing Co-membership Attacks Against Deep Generative Models","K. S. Liu; C. Xiao; B. Li; J. Gao","Stony Brook University; University of Michigan, Ann Arbor; UIUC; Stony Brook University","2019 IEEE International Conference on Data Mining (ICDM)","30 Jan 2020","2019","","","459","467","In this paper we propose a new membership attack method called co-membership attacks against deep generative models including Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs). Specifically, membership attack aims to check whether a given instance x was used in the training data or not. A co-membership attack checks whether the given bundle of n instances were in the training, with the prior knowledge that the bundle was either entirely used in the training or none at all. Successful membership attacks can compromise the privacy of training data when the generative model is published. Our main idea is to cast membership inference of target data x as the optimization of another neural network (called the attacker network) to search for the latent encoding to reproduce x. The final reconstruction error is used directly to conclude whether x was in the training data or not. We conduct extensive experiments on a variety of datasets and generative models showing that: our attacker network outperforms prior membership attacks; co-membership attacks can be substantially more powerful than single attacks; and VAEs are more susceptible to membership attacks compared to GANs.","2374-8486","978-1-7281-4604-1","10.1109/ICDM.2019.00056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8970995","Privacy, Deep Generative Model, Unsupervised Learning, Adversarial Machine Learning","","belief networks;inference mechanisms;learning (artificial intelligence);neural nets;pattern clustering;security of data","attacker network;prior membership attacks;single attacks;deep generative models;membership attack method;generative adversarial networks;training data;successful membership attacks;generative model;membership inference;co-membership attacks","","5","","20","","30 Jan 2020","","","IEEE","IEEE Conferences"
"A Deep Generative Model of Speech Complex Spectrograms","A. A. Nugraha; K. Sekiguchi; K. Yoshii","RIKEN Center for Advanced Intelligence Project (AIP), Japan; Graduate School of Informatics, Kyoto University, Japan; Graduate School of Informatics, Kyoto University, Japan","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","905","909","This paper proposes an approach to the joint modeling of the short-time Fourier transform magnitude and phase spectrograms with a deep generative model. We assume that the magnitude follows a Gaussian distribution and the phase follows a von Mises distribution. To improve the consistency of the phase values in the time-frequency domain, we also apply the von Mises distribution to the phase derivatives, i.e., the group delay and the instantaneous frequency. Based on these assumptions, we explore and compare several combinations of loss functions for training our models. Built upon the variational autoencoder framework, our model consists of three convolutional neural networks acting as an encoder, a magnitude decoder, and a phase decoder. In addition to the latent variables, we propose to also condition the phase estimation on the estimated magnitude. Evaluated for a time-domain speech reconstruction task, our models could generate speech with a high perceptual quality and a high intelligibility.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682797","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682797","deep generative model;magnitude;phase;group delay;instantaneous frequency","Decoding;Spectrogram;Training;Time-frequency analysis;Delays;Speech enhancement;Phase estimation","audio signal processing;Fourier transforms;Gaussian distribution;neural nets;phase estimation;speech coding;speech processing;statistical analysis;time-frequency analysis","deep generative model;speech complex spectrograms;joint modeling;Gaussian distribution;von Mises distribution;phase values;time-frequency domain;instantaneous frequency;magnitude decoder;phase decoder;phase estimation;time-domain speech reconstruction task;short-time Fourier transform magnitude spectrogram;short-time Fourier transform phase spectrogram;loss functions","","5","","39","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Learning Class-Aligned and Generalized Domain-Invariant Representations for Speech Emotion Recognition","Y. Xiao; H. Zhao; T. Li","College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China","IEEE Transactions on Emerging Topics in Computational Intelligence","21 Jul 2020","2020","4","4","480","489","Although recent research on speech emotion recognition has demonstrated that learning domain-invariant features provide an elegant solution to domain mismatch, the features learned by the existing methods lack generalization capabilities to capture latent information from datasets. We propose two novel domain adaptation methods, the generalized domain adversarial neural network (GDANN) and the class-aligned GDANN (CGDANN), to learn generalized domain-invariant representations for emotion recognition. GDANN and CGDANN, which are derived from multitask learning (MTL), consist of three tasks. The main task is to recognize the emotional category to which the input belongs. The remaining two tasks are auxiliary tasks. One is to use a variational autoencoder to model the input distribution, which encourages the model to learn the distribution of latent representations. The other is to learn the common representations of different domains, for which distinguishing via the domain classifier is difficult. The gradient of the domain classifier guides the shared representations of the source and target domains to approximate each other using a gradient reversal layer. To evaluate the effectiveness of the proposed methods, we conduct several experiments with the IEMOCAP and MSP-IMPROV datasets. The results illustrate that good performance is achieved compared with that of state-of-the-art methods. Notably, CGDANN utilizes a small quantity of labeled target domain samples to align the distribution representation and obtains the best performance among the comparison methods. We further visualize the representations learned by the proposed methods and discover that the representations of the source and target domains converge with a low variance.","2471-285X","","10.1109/TETCI.2020.2972926","National Natural Science Foundation of China(grant numbers:61772188); National Key R&D Program of China(grant numbers:2018YFC0831800); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9099376","Domain adversarial training;generalization;class alignment;speech emotion recognition","Task analysis;Emotion recognition;Training;Speech recognition;Hidden Markov models;Neural networks;Machine learning","emotion recognition;feature extraction;gradient methods;image classification;image representation;learning (artificial intelligence);neural nets;speech recognition","domain-invariant representation;speech emotion recognition;domain-invariant features;domain adaptation methods;generalized domain adversarial neural network;class-aligned GDANN;CGDANN;multitask learning;emotional category;latent representations;domain classifier;class-aligned representation;gradient reversal layer","","5","","51","IEEE","25 May 2020","","","IEEE","IEEE Journals"
"Synthesized Feature based Few-Shot Class-Incremental Learning on a Mixture of Subspaces","A. Cheraghian; S. Rahman; S. Ramasinghe; P. Fang; C. Simon; L. Petersson; M. Harandi","Data61-Csiro, Australia; North South University, Dhaka, Bangladesh; Data61-Csiro, Australia; Data61-Csiro, Australia; Data61-Csiro, Australia; Data61-Csiro, Australia; Monash University, Australia","2021 IEEE/CVF International Conference on Computer Vision (ICCV)","28 Feb 2022","2021","","","8641","8650","Few-shot class incremental learning (FSCIL) aims to incrementally add sets of novel classes to a well-trained base model in multiple training sessions with the restriction that only a few novel instances are available per class. While learning novel classes, FSCIL methods gradually forget base (old) class training and overfit to a few novel class samples. Existing approaches have addressed this problem by computing the class prototypes from the visual or semantic word vector domain. In this paper, we propose addressing this problem using a mixture of subspaces. Subspaces define the cluster structure of the visual domain and help to describe the visual and semantic domain considering the overall distribution of the data. Additionally, we propose to employ a variational autoencoder (VAE) to generate synthesized visual samples for augmenting pseudo-feature while learning novel classes incrementally. The combined effect of the mixture of subspaces and synthesized features reduces the forgetting and overfitting problem of FSCIL. Extensive experiments on three image classification datasets show that our proposed method achieves competitive results compared to state-of-the-art methods.","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.00854","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9711372","Transfer/Low-shot/Semi/Unsupervised Learning;Vision + language","Training;Visualization;Computer vision;Adaptation models;Computational modeling;Semantics;Prototypes","","","","4","","49","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"Multi-Modal Sentiment Classification With Independent and Interactive Knowledge via Semi-Supervised Learning","D. Zhang; S. Li; Q. Zhu; G. Zhou","School of Computer Science and Technology, Soochow University, Suzhou, China; School of Computer Science and Technology, Soochow University, Suzhou, China; School of Computer Science and Technology, Soochow University, Suzhou, China; School of Computer Science and Technology, Soochow University, Suzhou, China","IEEE Access","5 Feb 2020","2020","8","","22945","22954","Multi-modal sentiment analysis extends conventional text-based definition of sentiment analysis to a multi-modal setup where multiple relevant modalities are leveraged to perform sentiment analysis. In real applications, however, acquiring annotated multi-modal data is normally labor expensive and time-consuming. In this paper, we aim to reduce the annotation effort for multi-modal sentiment classification via semi-supervised learning. The key idea is to leverage the semi-supervised variational autoencoders to mine more information from unlabeled data for multi-modal sentiment analysis. Specifically, the mined information includes both the independent knowledge within single modality and the interactive knowledge among different modalities. Empirical evaluation demonstrates the great effectiveness of the proposed semi-supervised approach to multi-modal sentiment classification.","2169-3536","","10.1109/ACCESS.2020.2969205","National Natural Science Foundation of China(grant numbers:61672366); National Natural Science Foundation of China(grant numbers:61836007,61702149); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8968422","Natural language processing;sentiment analysis;multimedia computing","Semisupervised learning;Sentiment analysis;Videos;Decoding;Feature extraction;Annotations;Supervised learning","learning (artificial intelligence);pattern classification;sentiment analysis","multimodal sentiment classification;interactive knowledge;semisupervised learning;multimodal sentiment analysis;multimodal setup;multiple relevant modalities;annotated multimodal data;single modality;independent knowledge","","4","","37","CCBY","24 Jan 2020","","","IEEE","IEEE Journals"
"AdaptNet: Human Activity Recognition via Bilateral Domain Adaptation Using Semi-Supervised Deep Translation Networks","S. An; A. Medda; M. N. Sawka; C. J. Hutto; M. L. Millard-Stafford; S. Appling; K. L. S. Richardson; O. T. Inan","School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA; Aerospace Transportation and Advanced Systems Laboratory, Georgia Tech Research Institute, Atlanta, GA, USA; School of Biological Sciences, Georgia Institute of Technology, Atlanta, GA, USA; Electronic Systems Laboratory, Georgia Tech Research Institute, Atlanta, GA, USA; School of Biological Sciences, Georgia Institute of Technology, Atlanta, GA, USA; Information Communications Laboratory, Georgia Tech Research Institute, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Sensors Journal","15 Sep 2021","2021","21","18","20398","20411","This study demonstrates robust human activity recognition from a single triaxial accelerometer via bilateral domain adaptation using semi-supervised deep translation networks. Datasets were obtained from previously published studies: University of Michigan (Domain 1) and Georgia Institute of Technology (Domain 2) where triaxial accelerometry was obtained on subjects during defined conditions with the goal of recognizing standing rest, walking (level ground), walking (decline), and walking (incline) with and without stairs (activity classes). Collected accelerometer data was preprocessed then analyzed by AdaptNet, a deep translation network composed of Variational Autoencoders and Generative Adversarial Networks trained with additional cycle-consistency losses to combine information from two data domains over shared latent space. Visualization and quantitative analyses demonstrated that AdaptNet successfully reconstructs self-domain wavelet scalogram inputs and generates realistic cross-domain translations. We found AdaptNet provides up to 36 percentage points (0.75 compared to 0.39) better classification performance measured by average macro-F1 score compared to the existing domain adaptation methods when a small amount of labeled data is provided for both domains. AdaptNet yielded more robust performance than other methods when the sensor placements are different across two domains. By enabling improved ability to fuse datasets with scarce and weak labels, AdaptNet provides valid recognition of real-world locomotor activities, which can be further utilized in digital health tools such as status assessment of patients with chronic diseases.","1558-1748","","10.1109/JSEN.2021.3095176","Office of Naval Research(grant numbers:N00014-20-1-2137); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9475454","Activity recognition;deep learning;domain adaptation;semi-supervised learning","Sensors;Wearable sensors;Accelerometers;Legged locomotion;Task analysis;Protocols;Decoding","accelerometers;convolutional neural nets;deep learning (artificial intelligence);feature extraction;image classification;wavelet transforms","realistic cross-domain translations;AdaptNet;real-world locomotor activities;bilateral domain adaptation;semisupervised deep translation networks;robust human activity recognition;triaxial accelerometry;accelerometer data;deep translation network;generative adversarial networks;data domains;self-domain wavelet scalogram inputs;domain adaptation methods;visualization analysis;quantitative analysis","","3","","59","IEEE","6 Jul 2021","","","IEEE","IEEE Journals"
"MRD-Nets: Multi-Scale Residual Networks With Dilated Convolutions for Classification and Clustering Analysis of Spacecraft Electrical Signal","Y. Liu; K. Li; Y. Zhang; S. Song","Fundamental Science on Ergonomics and Environment Control Laboratory, School of Aeronautic Science and Engineering, Beihang University, Beijing, China; Fundamental Science on Ergonomics and Environment Control Laboratory, School of Aeronautic Science and Engineering, Beihang University, Beijing, China; Fundamental Science on Ergonomics and Environment Control Laboratory, School of Aeronautic Science and Engineering, Beihang University, Beijing, China; China Academy of Space Technology, Beijing, China","IEEE Access","5 Dec 2019","2019","7","","171584","171597","The fault detection of spacecraft electronic load systems is a crucial part of the spacecraft prognostics and health management system. To detect the abnormal state of spacecraft electronic load systems, complex electrical signals should be processed rapidly and accurately. For the fault detection of spacecraft electronic load systems, a robust unsupervised clustering analysis method and an accurate supervised classification method are of great importance. However, the traditional machine learning methods have poor performance when processing high-dimensional signal data because of the lack of ability to extract complex features from the signals. Therefore, neural-network-based deep learning (DL) models which can extract features from signals automatically are more suitable in this situation. In this paper, a novel convolutional neural network (CNN) module, the multi-branch residual module with dilated convolutions (MRD module), is proposed to extract multi-scale features from the electrical signal. Then, a well-designed CNN model named MRD-CNN is presented for the supervised classification task of signal. Furthermore, for the unsupervised clustering task, the clustering variational autoencoder with MRD modules (MRD-CluVAE) is proposed. The MRD-CluVAE can extract high-quality features from signal data and output the clustering results directly. To evaluate the performance of the proposed models, comparisons among the proposed models and other baseline algorithms are carried out. The experimental results show that the MRD-CNN model achieves higher classification performance and stability, while the MRD-CluVAE has a higher clustering accuracy than other algorithms. These methods can be utilized to resolve the classification and recognition problems of spacecraft electronic load signals.","2169-3536","","10.1109/ACCESS.2019.2947536","National Natural Science Foundation of China(grant numbers:61773039); Aeronautical Science Foundation of China(grant numbers:2017ZDXX1043); Aeronautical Science Foundation of China(grant numbers:2018XXX); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8876602","Fault detection;spacecraft electrical signal;MRD module;MRD-CNN;MRD-CluVAE","Feature extraction;Space vehicles;Task analysis;Fault detection;Load modeling;Clustering algorithms;Convolution","avionics;convolutional neural nets;fault diagnosis;feature extraction;learning (artificial intelligence);pattern classification;pattern clustering;space vehicles","MRD-nets;multiscale residual networks;dilated convolutions;spacecraft electrical signal;fault detection;spacecraft electronic load systems;spacecraft prognostics;health management system;complex electrical signals;robust unsupervised clustering analysis method;accurate supervised classification method;traditional machine learning methods;high-dimensional signal data;neural-network-based deep learning models;convolutional neural network module;multibranch residual module;MRD module;multiscale features;unsupervised clustering task;MRD-CluVAE;MRD-CNN model;spacecraft electronic load signals","","3","","40","CCBY","21 Oct 2019","","","IEEE","IEEE Journals"
"Deep Generative Learning-Based 1-SVM Detectors for Unsupervised COVID-19 Infection Detection Using Blood Tests","A. Dairi; F. Harrou; Y. Sun","Laboratoire des Technologies de l’Environnement (LTE), Ecole Nationale Polytechnique Oran, Oran, Algeria; Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; Computer, Electrical and Mathematical Sciences and Engineering (CEMSE) Division, King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia","IEEE Transactions on Instrumentation and Measurement","21 Feb 2022","2022","71","","1","11","A sample blood test has recently become an important tool to help identify false-positive/false-negative real-time reverse transcription polymerase chain reaction (rRT-PCR) tests. Importantly, this is mainly because it is an inexpensive and handy option to detect the potential COVID-19 patients. However, this test should be conducted by certified laboratories, expensive equipment, and trained personnel, and 3–4 h are needed to deliver results. Furthermore, it has relatively large false-negative rates around 15%–20%. Consequently, an alternative and more accessible solution, quicker and less costly, is needed. This article introduces flexible and unsupervised data-driven approaches to detect the COVID-19 infection based on blood test samples. In other words, we address the problem of COVID-19 infection detection using a blood test as an anomaly detection problem through an unsupervised deep hybrid model. Essentially, we amalgamate the features extraction capability of the variational autoencoder (VAE) and the detection sensitivity of the one-class support vector machine (1SVM) algorithm. Two sets of routine blood tests samples from the Albert Einstein Hospital, S ao Paulo, Brazil, and the San Raffaele Hospital, Milan, Italy, are used to assess the performance of the investigated deep learning models. Here, missing values have been imputed based on a random forest regressor. Compared to generative adversarial networks (GANs), deep belief network (DBN), and restricted Boltzmann machine (RBM)-based 1SVM, the traditional VAE, GAN, DBN, and RBM with softmax layer as discriminator layer, and the standalone 1SVM, the proposed VAE-based 1SVM detector offers superior discrimination performance of potential COVID-19 infections. Results also revealed that the deep learning-driven 1SVM detection approaches provide promising detection performance compared to the conventional deep learning models.","1557-9662","","10.1109/TIM.2021.3130675","King Abdullah University of Science and Technology (KAUST), Office of Sponsored Research (OSR)(grant numbers:OSR-2019-CRG7-3800); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9627171","COVID-19;deep learning;generative models;routine blood tests;unsupervised anomaly detection","COVID-19;Blood;Radio frequency;Data models;Feature extraction;Support vector machines;Detectors","biomedical measurement;blood;deep learning (artificial intelligence);diseases;epidemics;feature extraction;medical diagnostic computing;patient diagnosis;random forests;regression analysis;support vector machines","deep generative learning-based 1-SVM detectors;unsupervised COVID-19 infection detection;sample blood test;rRT-PCR;potential COVID-19 patients;false-negative rates;data-driven approaches;blood test samples;anomaly detection problem;unsupervised deep hybrid model;detection sensitivity;one-class support vector machine algorithm;routine blood tests samples;investigated deep learning models;standalone 1SVM;VAE-based 1SVM detector;potential COVID-19 infections;deep learning-driven 1SVM detection approaches;conventional deep learning models;time 3.0 hour to 4.0 hour","","3","","53","IEEE","25 Nov 2021","","","IEEE","IEEE Journals"
"Towards the Unseen: Iterative Text Recognition by Distilling from Errors","A. K. Bhunia; P. Nath Chowdhury; A. Sain; Y. -Z. Song","SketchX, CVSSP, University of Surrey, United Kingdom; iFlyTek-Surrey Joint Research Centre on Artificial Intelligence; iFlyTek-Surrey Joint Research Centre on Artificial Intelligence; iFlyTek-Surrey Joint Research Centre on Artificial Intelligence","2021 IEEE/CVF International Conference on Computer Vision (ICCV)","28 Feb 2022","2021","","","14930","14939","Visual text recognition is undoubtedly one of the most extensively researched topics in computer vision. Great progress have been made to date, with the latest models starting to focus on the more practical ""in-the-wild"" setting. However, a salient problem still hinders practical deployment – prior state-of-arts mostly struggle with recognising unseen (or rarely seen) character sequences. In this paper, we put forward a novel framework to specifically tackle this “unseen” problem. Our framework is iterative in nature, in that it utilises predicted knowledge of character sequences from a previous iteration, to augment the main network in improving the next prediction. Key to our success is a unique cross-modal variational autoencoder to act as a feedback module, which is trained with the presence of textual error distribution data. This module importantly translates a discrete predicted character space, to a continuous affine transformation parameter space used to condition the visual feature map at next iteration. Experiments on common datasets have shown competitive performance over state-of-the-arts under the conventional setting. Most importantly, under the new disjoint setup where train-test labels are mutually exclusive, ours offers the best performance thus showcasing the capability of generalising onto unseen words (Figure 1 offers a summary).","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.01468","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9710222","Scene text and document understanding","Knowledge engineering;Visualization;Computer vision;Text recognition;Computational modeling;Iterative methods;Character recognition","","","","3","","68","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"Internet of Things and Deep Learning Enabled Elderly Fall Detection Model for Smart Homecare","T. Vaiyapuri; E. L. Lydia; M. Y. Sikkandar; V. G. Díaz; I. V. Pustokhina; D. A. Pustokhin","College of Computer Engineering and Sciences, Prince Sattam Bin Abdulaziz University, Al-Kharj, Saudi Arabia; Department of Computer Science and Engineering, Vignan’s Institute of Information Technology (Autonomous), Visakhapatnam, India; Department of Medical Equipment Technology, College of Applied Medical Sciences, Majmaah University, Al Majma’ah, Saudi Arabia; Department of Computer Science, School of Computer Science Engineering, University of Oviedo, Oviedo, Spain; Department of Entrepreneurship and Logistics, Plekhanov Russian University of Economics, Moscow, Russia; Department of Logistics, State University of Management, Moscow, Russia","IEEE Access","19 Aug 2021","2021","9","","113879","113888","Recently, the techniques of Internet of Things (IoT) and mobile communications have been developed to gather human and environment information data for a variety of intelligent services and applications. Remote monitoring of elderly and disabled people living in smart homes is highly challenging due to probable accidents which might occur due to daily activities such as falls. For elderly people, fall is considered as a major reason for death of post-traumatic complication. So, early identification of elderly people falls in smart homes is needed to increase the survival rate of the person or offer required support. Recently, the advent of artificial intelligence (AI), IoT, wearables, smartphones, etc. makes it feasible to design fall detection systems for smart homecare. In this view, this paper presents an IoT enabled elderly fall detection model using optimal deep convolutional neural network (IMEFD-ODCNN) for smart homecare. The goal of the IMEFD-ODCNN model is to enable smartphones and intelligent deep learning (DL) algorithms to detect the occurrence of falls in the smart home. Primarily, the input video captured by the IoT devices is pre-processed in different ways like resizing, augmentation, and min-max based normalization. Besides, SqueezeNet model is employed as a feature extraction technique to derive appropriate feature vectors for fall detection. In addition, the hyperparameter tuning of the SqueezeNet model takes place using the salp swarm optimization (SSO) algorithm. Finally, sparrow search optimization algorithm (SSOA) with variational autoencoder (VAE), called SSOA-VAE based classifier is employed for the classification of fall and non-fall events. Finally, in case of fall event detected, the smartphone sends an alert to the caretakers and hospital management. The performance validation of the IMEFD-ODCNN model takes place on UR fall detection dataset and multiple cameras fall dataset. The experimental outcomes highlighted the promising performance of the IMEFD-ODCNN model over the recent methods with the maximum accuracy of 99.76% and 99.57% on the multiple cameras fall and UR fall detection dataset.","2169-3536","","10.1109/ACCESS.2021.3094243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9471869","Smart homecare;smartphone;fall detection;artificial intelligence;elderly people;deep learning;parameter tuning","Fall detection;Feature extraction;Wearable computers;Smart phones;Senior citizens;Classification algorithms;Cameras","feature extraction;geriatrics;handicapped aids;image classification;Internet of Things;learning (artificial intelligence);neural nets;object detection;patient monitoring;probability;smart phones","UR fall detection dataset;multiple cameras fall;IMEFD-ODCNN model;Internet of Things;elderly fall detection model;smart homecare;IoT;mobile communications;gather human environment information data;intelligent services;elderly people;disabled people;smart home;smartphones;fall detection systems;optimal deep convolutional neural network;intelligent deep learning algorithms;SqueezeNet model;nonfall events;fall event","","3","","29","CCBY","2 Jul 2021","","","IEEE","IEEE Journals"
"Deep Learning for Adverse Event Detection From Web Search","F. Ahmad; A. Abbasi; B. Kitchens; D. Adjeroh; D. Zeng","Computer Science, University of Virginia, Charlottesville, VA, USA; IT, Analytics, and Operations, University of Notre Dame, Notre Dame, IN, USA; Information Technology, University of Virginia, Charlottesville, VA, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Institute for Automation, Chinese Academy of Sciences, China","IEEE Transactions on Knowledge and Data Engineering","29 Apr 2022","2022","34","6","2681","2695","Adverse event detection is critical for many real-world applications including timely identification of product defects, disasters, and major socio-political incidents. In the health context, adverse drug events account for countless hospitalizations and deaths annually. Since users often begin their information seeking and reporting with online searches, examination of search query logs has emerged as an important detection channel. However, search context - including query intent and heterogeneity in user behaviors – is extremely important for extracting information from search queries, and yet the challenge of measuring and analyzing these aspects has precluded their use in prior studies. We propose DeepSAVE, a novel deep learning framework for detecting adverse events based on user search query logs. DeepSAVE uses an enriched variational autoencoder encompassing a novel query embedding and user modeling module that work in concert to address the context challenge associated with search-based detection of adverse events. Evaluation results on three large real-world event datasets show that DeepSAVE outperforms existing detection methods as well as comparison deep learning auto encoders. Ablation analysis reveals that each component of DeepSAVE significantly contributes to its overall performance. Collectively, the results demonstrate the viability of the proposed architecture for detecting adverse events from search query logs.","1558-2191","","10.1109/TKDE.2020.3017786","National Science Foundation(grant numbers:IIS-1553109,IIS-1816504,BDS-1636933,CCF-1629450,IIS-1552860,IIS-1816005); MOST(grant numbers:2019AAA0103405,2016QY02D0305); NNSFC Innovative Team(grant numbers:71621002); CAS(grant numbers:XDC02060600,ZDRW-XH-2017-3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9171579","Adverse event detection;search queries;deep learning;auto encoders;query embeddings;user modeling","Event detection;Drugs;Deep learning;Twitter;Data mining;Context modeling;Automotive engineering","drugs;learning (artificial intelligence);medical information systems;query processing;search engines;user modelling","search-based detection;real-world event datasets;DeepSAVE;detection methods;comparison deep learning auto encoders;adverse event detection;web search;socio-political incidents;health context;adverse drug events;countless hospitalizations;online searches;important detection channel;search context;query intent;search queries;deep learning framework;user search query logs;novel query embedding;context challenge","","3","","62","CCBY","19 Aug 2020","","","IEEE","IEEE Journals"
"Disentangled Representation Learning for Multiple Attributes Preserving Face Deidentification","M. Gong; J. Liu; H. Li; Y. Xie; Z. Tang","Key Laboratory of Intelligent Perception and Image Understanding, School of Electronic Engineering, Ministry of Education, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding, School of Electronic Engineering, Ministry of Education, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding, School of Electronic Engineering, Ministry of Education, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding, School of Electronic Engineering, Ministry of Education, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding, School of Electronic Engineering, Ministry of Education, Xidian University, Xi’an, China","IEEE Transactions on Neural Networks and Learning Systems","5 Jan 2022","2022","33","1","244","256","Face is one of the most attractive sensitive information in visual shared data. It is an urgent task to design an effective face deidentification method to achieve a balance between facial privacy protection and data utilities when sharing data. Most of the previous methods for face deidentification rely on attribute supervision to preserve a certain kind of identity-independent utility but lose the other identity-independent data utilities. In this article, we mainly propose a novel disentangled representation learning architecture for multiple attributes preserving face deidentification called replacing and restoring variational autoencoders (R2VAEs). The R2VAEs disentangle the identity-related factors and the identity-independent factors so that the identity-related information can be obfuscated, while they do not change the identity-independent attribute information. Moreover, to improve the details of the facial region and make the deidentified face blends into the image scene seamlessly, the image inpainting network is employed to fill in the original facial region by using the deidentified face as a priori. Experimental results demonstrate that the proposed method effectively deidentifies face while maximizing the preservation of the identity-independent information, which ensures the semantic integrity and visual quality of shared images.","2162-2388","","10.1109/TNNLS.2020.3027617","National Natural Science Foundation of China(grant numbers:62036006,61906146); National Key Research and Development Program of China(grant numbers:2017YFB0802200); Key Research and Development Program of Shaanxi Province(grant numbers:2018ZDXM-GY-045); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229074","Disentangled representation learning;face deidentification;image inpainting;privacy protection","Face recognition;Visualization;Faces;Task analysis;Privacy;Generative adversarial networks;Gallium nitride","data privacy;edge detection;face recognition;filtering theory;image enhancement;learning (artificial intelligence);security of data","multiple attributes preserving face deidentification;attractive sensitive information;visual shared data;effective face deidentification method;facial privacy protection;sharing data;attribute supervision;identity-independent utility;identity-independent data utilities;representation learning architecture;2 VAEs;identity-related factors;identity-independent factors;identity-related information;identity-independent attribute information;deidentified face blends;original facial region;identity-independent information;shared images","Data Anonymization;Face;Learning;Neural Networks, Computer;Semantics","3","","55","IEEE","19 Oct 2020","","","IEEE","IEEE Journals"
"A Generative Model for Generic Light Field Reconstruction","P. Chandramouli; K. V. Gandikota; A. Goerlitz; A. Kolb; M. Moeller","Department of Computer Science, University of Siegen, Siegen, Germany; Department of Computer Science, University of Siegen, Siegen, Germany; Department of Computer Science, University of Siegen, Siegen, Germany; Department of Computer Science, University of Siegen, Siegen, Germany; Department of Computer Science, University of Siegen, Siegen, Germany","IEEE Transactions on Pattern Analysis and Machine Intelligence","4 Mar 2022","2022","44","4","1712","1724","Recently deep generative models have achieved impressive progress in modeling the distribution of training data. In this work, we present for the first time a generative model for 4D light field patches using variational autoencoders to capture the data distribution of light field patches. We develop a generative model conditioned on the central view of the light field and incorporate this as a prior in an energy minimization framework to address diverse light field reconstruction tasks. While pure learning-based approaches do achieve excellent results on each instance of such a problem, their applicability is limited to the specific observation model they have been trained on. On the contrary, our trained light field generative model can be incorporated as a prior into any model-based optimization approach and therefore extend to diverse reconstruction tasks including light field view synthesis, spatial-angular super resolution and reconstruction from coded projections. Our proposed method demonstrates good reconstruction, with performance approaching end-to-end trained networks, while outperforming traditional model-based approaches on both synthetic and real scenes. Furthermore, we show that our approach enables reliable light field recovery despite distortions in the input.","1939-3539","","10.1109/TPAMI.2020.3039841","Deutsche Forschungsgemeinschaft(grant numbers:CH 2530/1-1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9266573","Light field reconstruction;deep generative model;view synthesis;coded aperture","Image reconstruction;Task analysis;Spatial resolution;Data models;Feature extraction;Apertures;Training","image reconstruction;image resolution;learning (artificial intelligence);optimisation","reliable light field recovery;generic light field reconstruction;deep generative models;training data;light field patches;data distribution;diverse light field reconstruction tasks;pure learning-based approaches;specific observation model;trained light field generative model;model-based optimization approach;diverse reconstruction tasks;light field view synthesis;spatial-angular super resolution;traditional model-based approaches","","3","","60","IEEE","23 Nov 2020","","","IEEE","IEEE Journals"
"Point Cloud Geometry Compression Via Neural Graph Sampling","L. Gao; T. Fan; J. Wan; Y. Xu; J. Sun; Z. Ma",Shanghai Jiao Tong University; Shanghai Jiao Tong University; Nanjing University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Nanjing University,"2021 IEEE International Conference on Image Processing (ICIP)","23 Aug 2021","2021","","","3373","3377","Compressing point cloud geometry (PCG) efficiently is of great interests for enabling abundant networked applications, because PCG is a promising representation to precisely illustrate arbitrary-shaped 3D objects and relevant physical scenes. To well exploit the unconstrained geometric correlation of input PCG, a three-step neural graph sampling (NGS) is developed. First, we construct the local graph of each point using its K nearest neighbors according to the Euclidean distance metric; Second, for each local graph, its graph center point expands associated feature attribute by aggregating neighbor weights via point-wise dynamic filter; We then perform attention-based sampling to select a subset of points to well represent input points. The proposed NGS is embedded into an end-to-end analysis/synthesis-based variational autoencoder (VAE), with which the encoder applies multiscale NGS to extract latent keypoints that are augmented with neighbor structures and compressed at bottleneck leveraging the hyperpriors for accurate entropy modeling, and the decoder directly uses layered convolutions to refine progressively for the reconstruction of final point cloud. Note that all computations are fulfilled using point-wise convolution, making our solution an attractive approach in practice. Experimental results demonstrate that the proposed method using NGS mechanism outperforms the state-of-the-art point-based PCG compression methods by more than $2\times \mathrm{B}\mathrm{D}$-Rate (Bjûntegaard Delta Rate) gains, and several orders of magnitude gains over the MPEG G-PCC across all testing categories on ShapeNetCorev2 dataset.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506631","National Natural Science Foundation of China; Science and Technology Commission of Shanghai Municipality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506631","Point cloud geometry (PCG);local neighborhood graph;dynamic filter;attention-based sampling;point-wise convolution","Geometry;Convolutional codes;Measurement;Three-dimensional displays;Image coding;Transform coding;Euclidean distance","computational geometry;data compression;entropy;feature extraction;graph theory;nearest neighbour methods;neural nets;robot vision;video coding","local graph;graph center point;neighbor weights;point-wise dynamic filter;input points;multiscale NGS;neighbor structures;final point cloud;point-wise convolution;NGS mechanism;point cloud geometry compression;relevant physical scenes;three-step neural graph sampling;K nearest neighbors;Euclidean distance metric;point-based PCG compression methods","","3","","21","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"Predicting Lung Cancers Using Epidemiological Data: A Generative-Discriminative Framework","J. Li; Y. Tao; T. Cai","Ningbo Institute of Life and Health Industry, University of Chinese Academy of Sciences, Ningbo, China; HwaMei Hospital, University of Chinese Academy of Sciences, Ningbo, China; Ningbo Institute of Life and Health Industry, University of Chinese Academy of Sciences, Ningbo, China","IEEE/CAA Journal of Automatica Sinica","5 Apr 2021","2021","8","5","1067","1078","Predictive models for assessing the risk of developing lung cancers can help identify high-risk individuals with the aim of recommending further screening and early intervention. To facilitate pre-hospital self-assessments, some studies have exploited predictive models trained on non-clinical data (e.g., smoking status and family history). The performance of these models is limited due to not considering clinical data (e.g., blood test and medical imaging results). Deep learning has shown the potential in processing complex data that combine both clinical and non-clinical information. However, predicting lung cancers remains difficult due to the severe lack of positive samples among follow-ups. To tackle this problem, this paper presents a generative-discriminative framework for improving the ability of deep learning models to generalize. According to the proposed framework, two nonlinear generative models, one based on the generative adversarial network and another on the variational autoencoder, are used to synthesize auxiliary positive samples for the training set. Then, several discriminative models, including a deep neural network (DNN), are used to assess the lung cancer risk based on a comprehensive list of risk factors. The framework was evaluated on over 55 000 subjects questioned between January 2014 and December 2017, with 699 subjects being clinically diagnosed with lung cancer between January 2014 and August 2019. According to the results, the best performing predictive model built using the proposed framework was based on DNN. It achieved an average sensitivity of 76.54% and an area under the curve of 69.24% in distinguishing between the cases of lung cancer and normal cases on test sets.","2329-9274","","10.1109/JAS.2021.1003910","University of Chinese Academy of Sciences(grant numbers:2020HMZD22); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9358458","Cancer prevention;discriminative model;generative model;lung cancer;machine learning","Lung cancer;Cancer;Predictive models;History;Sociology;Lung;Medical diagnostic imaging","cancer;deep learning (artificial intelligence);diseases;lung;medical image processing;medical information systems","prehospital self-assessments;complex data;medical imaging results;blood test;clinical data;family history;smoking status;nonclinical data;high-risk individuals;predictive models;epidemiological data;performing predictive model;risk factors;lung cancer risk;deep neural network;discriminative models;auxiliary positive samples;generative adversarial network;nonlinear generative models;deep learning models;generative-discriminative framework;predicting lung cancers;nonclinical information","","3","","41","","19 Feb 2021","","","IEEE","IEEE Journals"
"Context-Dependent Anomaly Detection for Low Altitude Traffic Surveillance","I. Bozcan; E. Kayacan","Department of Electrical and Computer Engineering, Artificial Intelligence in Robotics Laboratory (Air Lab), Aarhus University, Aarhus C, Denmark; Department of Electrical and Computer Engineering, Artificial Intelligence in Robotics Laboratory (Air Lab), Aarhus University, Aarhus C, Denmark","2021 IEEE International Conference on Robotics and Automation (ICRA)","18 Oct 2021","2021","","","224","230","The detection of contextual anomalies is a challenging task for surveillance since an observation can be considered anomalous or normal in a specific environmental context. An unmanned aerial vehicle (UAV) can utilize its aerial monitoring capability and employ multiple sensors to gather contextual information about the environment and perform contextual anomaly detection. In this work, we introduce a deep neural network-based method (CADNet) to find point anomalies (i.e., single instance anomalous data) and contextual anomalies (i.e., context-specific abnormality) in an environment using a UAV. The method is based on a variational autoencoder (VAE) with a context sub-network. The context sub-network extracts contextual information regarding the environment using GPS and time data, then feeds it to the VAE to predict anomalies conditioned on the context. To the best of our knowledge, our method is the first contextual anomaly detection method for UAV-assisted aerial surveillance. We evaluate our method on the AU-AIR dataset in a traffic surveillance scenario. Quantitative comparisons against several baselines demonstrate the superiority of our approach in the anomaly detection tasks. The codes and data will be available at https://bozcani.github.io/cadnet.","2577-087X","978-1-7281-9077-8","10.1109/ICRA48506.2021.9562043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9562043","","Surveillance;Traffic control;Unmanned aerial vehicles;Real-time systems;Sensors;Feeds;Task analysis","autonomous aerial vehicles;deep learning (artificial intelligence);Global Positioning System;object detection;remotely operated vehicles;security of data;surveillance;traffic information systems;video surveillance","aerial monitoring capability;employ multiple sensors;deep neural network-based method;point anomalies;single instance anomalous data;contextual anomalies;context-specific abnormality;VAE;contextual information;contextual anomaly detection method;UAV-assisted aerial surveillance;traffic surveillance scenario;anomaly detection tasks;context-dependent anomaly detection;low altitude traffic surveillance;specific environmental context;unmanned aerial vehicle","","2","","25","IEEE","18 Oct 2021","","","IEEE","IEEE Conferences"
"CodeMapping: Real-Time Dense Mapping for Sparse SLAM using Compact Scene Representations","H. Matsuki; R. Scona; J. Czarnowski; A. J. Davison","Dyson Robotics Laboratory, Imperial College London, United Kingdom; Dyson Robotics Laboratory, Imperial College London, United Kingdom; Dyson Robotics Laboratory, Imperial College London, United Kingdom; Dyson Robotics Laboratory, Imperial College London, United Kingdom","IEEE Robotics and Automation Letters","28 Jul 2021","2021","6","4","7105","7112","We propose a novel dense mapping framework for sparse visual SLAM systems which leverages a compact scene representation. State-of-the-art sparse visual SLAM systems provide accurate and reliable estimates of the camera trajectory and locations of landmarks. While these sparse maps are useful for localization, they cannot be used for other tasks such as obstacle avoidance or scene understanding. In this letter we propose a dense mapping framework to complement sparse visual SLAM systems which takes as input the camera poses, keyframes and sparse points produced by the SLAM system and predicts a dense depth image for every keyframe. We build on CodeSLAM [1] and use a variational autoencoder (VAE) which is conditioned on intensity, sparse depth and reprojection error images from sparse SLAM to predict an uncertainty-aware dense depth map. The use of a VAE then enables us to refine the dense depth images through multi-view optimization which improves the consistency of overlapping frames. Our mapper runs in a separate thread in parallel to the SLAM system in a loosely coupled manner. This flexible design allows for integration with arbitrary metric sparse SLAM systems without delaying the main SLAM process. Our dense mapper can be used not only for local mapping but also globally consistent dense 3D reconstruction through TSDF fusion. We demonstrate our system running with ORB-SLAM3 and show accurate dense depth estimation which could enable applications such as robotics and augmented reality.","2377-3766","","10.1109/LRA.2021.3097258","Dyson Technology Ltd.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9484785","SLAM;mapping;vision-based navigation","Simultaneous localization and mapping;Cameras;Optimization;Real-time systems;Bundle adjustment;Visualization;Task analysis","augmented reality;cameras;collision avoidance;image classification;image reconstruction;image representation;image segmentation;image sensors;mobile robots;object tracking;optimisation;pose estimation;robot vision;SLAM (robots);stereo image processing","sparse points;SLAM system;dense depth image;sparse depth;reprojection error images;uncertainty-aware dense depth map;arbitrary metric sparse SLAM systems;main SLAM process;dense mapper;local mapping;globally consistent dense 3D reconstruction;ORB-SLAM3;accurate dense depth estimation;real-time dense mapping;compact scene representation;novel dense mapping framework;state-of-the-art sparse visual SLAM systems;camera;sparse maps;obstacle avoidance","","2","","28","IEEE","14 Jul 2021","","","IEEE","IEEE Journals"
"Improving transfer of expressivity for end-to-end multispeaker text-to-speech synthesis","A. Kulkarni; V. Colotte; D. Jouvet","Université de Lorraine, CNRS, Inria, LORIA, Nancy, France; Université de Lorraine, CNRS, Inria, LORIA, Nancy, France; Université de Lorraine, CNRS, Inria, LORIA, Nancy, France","2021 29th European Signal Processing Conference (EUSIPCO)","8 Dec 2021","2021","","","31","35","The main goal of this work is to generate expressive speech in different speaker's voices for which no expressive speech data is available. The presented approach conditions Tacotron 2 speech synthesis with latent representations extracted from text, speaker identity, and reference expressive Mel spectrogram. We propose to use multiclass N-pair loss in the end-to-end multispeaker expressive Text-To-Speech (TTS) for improving the transfer of expressivity to the target speaker's voice. We have jointly trained the end-to-end (E2E) TTS with multiclass N-pair loss to discriminate between various emotions. This augmentation of the loss function during training paves the way to enhance the latent space representation of emotions. We have experimented with two different neural network architectures for expressivity in the encoder, namely global style token (GST) and variational autoencoder (VAE). We transferred the expressivity using the mean of latent representation extracted from the expressivity encoder for each emotion. The obtained results show that adding multiclass N-pair loss based deep metric learning in the training process improves expressivity in the desired speaker's voice.","2076-1465","978-9-0827-9706-0","10.23919/EUSIPCO54536.2021.9616249","CNRS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616249","End-to-end TTS;metric learning;expressivity;transfer learning","Training;Measurement;Neural networks;Europe;Speech synthesis;Data mining;Spectrogram","feature extraction;learning (artificial intelligence);neural nets;speaker recognition;speech processing;speech recognition;speech synthesis","different speaker;expressive speech data;presented approach conditions Tacotron 2 speech synthesis;latent representation;speaker identity;reference expressive Mel spectrogram;multiclass N-pair loss;target speaker;end-to-end TTS;latent space representation;expressivity encoder;desired speaker;improving transfer;end-to-end multispeaker text-to-speech","","2","","22","","8 Dec 2021","","","IEEE","IEEE Conferences"
"Likelihood-Based Diverse Sampling for Trajectory Forecasting","Y. J. Ma; J. P. Inala; D. Jayaraman; O. Bastani",University of Pennsylvania; MIT CSAIL; University of Pennsylvania; University of Pennsylvania,"2021 IEEE/CVF International Conference on Computer Vision (ICCV)","28 Feb 2022","2021","","","13259","13268","Forecasting complex vehicle and pedestrian multi-modal distributions requires powerful probabilistic approaches. Normalizing flows (NF) have recently emerged as an attractive tool to model such distributions. However, a key drawback is that independent samples drawn from a flow model often do not adequately capture all the modes in the underlying distribution. We propose Likelihood-Based Diverse Sampling (LDS), a method for improving the quality and the diversity of trajectory samples from a pre-trained flow model. Rather than producing individual samples, LDS produces a set of trajectories in one shot. Given a pre-trained forecasting flow model, we train LDS using gradients from the model, to optimize an objective function that rewards high likelihood for individual trajectories in the predicted set, together with high spatial separation among trajectories. LDS outperforms state-of-art post-hoc neural diverse forecasting methods for various pre-trained flow models as well as conditional variational autoencoder (CVAE) models. Crucially, it can also be used for transductive trajectory forecasting, where the diverse forecasts are trained on-the-fly on unlabeled test examples. LDS is easy to implement, and we show that it offers a simple plug-in improvement over baselines on two challenging benchmarks. Code is at: https://github.com/JasonMa2016/LDS","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.01303","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9711277","Action and behavior recognition;Motion and tracking","Computer vision;Codes;Design methodology;Predictive models;Benchmark testing;Probabilistic logic;Linear programming","","","","1","","42","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"Learning Decoupled Representations for Human Pose Forecasting","B. Parsaeifard; S. Saadatnejad; Y. Liu; T. Mordan; A. Alahi","Ecole Polytechnique Federale de Lausanne (EPFL), Switzerland; Ecole Polytechnique Federale de Lausanne (EPFL), Switzerland; Ecole Polytechnique Federale de Lausanne (EPFL), Switzerland; Ecole Polytechnique Federale de Lausanne (EPFL), Switzerland; Ecole Polytechnique Federale de Lausanne (EPFL), Switzerland","2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)","24 Nov 2021","2021","","","2294","2303","Human pose forecasting involves complex spatiotemporal interactions between body parts (e.g., arms, legs, spine). State-of-the-art approaches use Long Short-Term Memories (LSTMs) or Variational AutoEncoders (VAEs) to solve the problem. Yet, they do not effectively predict human motions when both global trajectory and local pose movements exist. We propose to learn decoupled representations for the global and local pose forecasting tasks. We also show that it is better to stop the prediction when the uncertainty in human motion increases. Our forecasting model outperforms all existing methods on the pose forecasting benchmark to date by over 20%. The code is available online †.","2473-9944","978-1-6654-0191-3","10.1109/ICCVW54120.2021.00259","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9607646","","Legged locomotion;Computer vision;Uncertainty;Conferences;Computational modeling;Predictive models;Trajectory","image motion analysis;image representation;learning (artificial intelligence);pose estimation;recurrent neural nets;spatiotemporal phenomena","decoupled representations;human pose forecasting;complex spatiotemporal interactions;body parts;human motions;global trajectory;local pose movements;global pose forecasting tasks;local pose forecasting tasks;human motion;forecasting model;forecasting benchmark","","1","","50","IEEE","24 Nov 2021","","","IEEE","IEEE Conferences"
"Perceptual Font Manifold from Generative Model","Y. Fujita; H. Xie; K. Miyata","Japan Advanced Institute of Science and Technology, Ishikawa, Japan; Japan Advanced Institute of Science and Technology, Ishikawa, Japan; Japan Advanced Institute of Science and Technology, Ishikawa, Japan","2019 Nicograph International (NicoInt)","6 Jan 2020","2019","","","41","48","Though in recent times, various fonts are available online for public usage, it is difficult and challenging to generate, explore, and edit the fonts to meet the preferences of all users. To address these issues, we propose in this paper, a font manifold interface to visualize the perceptual adjustment in the latent space of a generative model of fonts. In this paper, we adopt the variational autoencoder network for font generation. Then, we conducted a perceptual study on the generated fonts from the multi-dimensional latent space of the generative model. After we obtained the distribution data of specific preferences, we utilized a manifold learning approach to visualize the font distribution. As a case study of our proposed method, we developed a user interface for generated font exploration in the designated user preference using a heat map representation.","","978-1-7281-4021-6","10.1109/NICOInt.2019.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8949291","Character Fonts, Generative Model, Manifold Learning","","character sets;data visualisation;learning (artificial intelligence);user interfaces","designated user preference;perceptual font manifold;generative model;public usage;font manifold interface;perceptual adjustment;font generation;perceptual study;generated fonts;multidimensional latent space;font distribution;user interface;generated font exploration","","1","","14","","6 Jan 2020","","","IEEE","IEEE Conferences"
"SNoRe: Scalable Unsupervised Learning of Symbolic Node Representations","S. Mežnar; N. Lavrač; B. Škrlj","Department of Knowledge Technologies, Jožef Stefan Institute, Ljubljana, Slovenia; University of Nova Gorica, Nova Gorica, Slovenia; Jožef Stefan International Postgraduate School, Ljubljana, Slovenia","IEEE Access","7 Dec 2020","2020","8","","212568","212588","Learning from complex real-life networks is a lively research area, with recent advances in learning information-rich, low-dimensional network node representations. However, state-of-the-art methods are not necessarily interpretable and are therefore not fully applicable to sensitive settings in biomedical or user profiling tasks, where explicit bias detection is highly relevant. The proposed SNoRe (Symbolic Node Representations) algorithm is capable of learning symbolic, human-understandable representations of individual network nodes, based on the similarity of neighborhood hashes which serve as features. SNoRe's interpretable features are suitable for direct explanation of individual predictions, which we demonstrate by coupling it with the widely used instance explanation tool SHAP to obtain nomograms representing the relevance of individual features for a given classification. To our knowledge, this is one of the first such attempts in a structural node embedding setting. In the experimental evaluation on eleven real-life datasets, SNoRe proved to be competitive to strong baselines, such as variational graph autoencoders, node2vec and LINE. The vectorized implementation of SNoRe scales to large networks, making it suitable for contemporary network learning and analysis tasks.","2169-3536","","10.1109/ACCESS.2020.3039541","ARRS National Research Programme Knowledge Technologies(grant numbers:P2-0103); European Union’s Horizon 2020 Research and Innovation Programme under Grant 825153 project EMBEDDIA (Cross-Lingual Embeddings for Less-Represented Languages in European News Media); ARRS ERC Supplementary Grant SDM-Open; ARRS Grant for young researchers (last author); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9265235","Node embedding;feature construction;symbolic learning;interpretable machine learning","Task analysis;Signal processing algorithms;Prediction algorithms;Convolution;Classification algorithms;Sparse matrices;Convolutional neural networks","computational complexity;graph theory;pattern classification;unsupervised learning","scalable unsupervised learning;Symbolic Node Representations;real-life networks;lively research area;information-rich;low-dimensional network node representations;biomedical user profiling tasks;explicit bias detection;human-understandable representations;individual network nodes;individual predictions;structural node embedding setting;node2vec;SNoRe scales;contemporary network learning;instance explanation tool","","1","","49","CCBY","20 Nov 2020","","","IEEE","IEEE Journals"
"Full-Body Motion from a Single Head-Mounted Device: Generating SMPL Poses from Partial Observations","A. Dittadi; S. Dziadzio; D. Cosker; B. Lundell; T. Cashman; J. Shotton",Technical University of Denmark; Microsoft; University of Bath; Microsoft; Microsoft; Microsoft,"2021 IEEE/CVF International Conference on Computer Vision (ICCV)","28 Feb 2022","2021","","","11667","11677","The increased availability and maturity of head-mounted and wearable devices opens up opportunities for remote communication and collaboration. However, the signal streams provided by these devices (e.g., head pose, hand pose, and gaze direction) do not represent a whole person. One of the main open problems is therefore how to leverage these signals to build faithful representations of the user. In this paper, we propose a method based on variational autoencoders to generate articulated poses of a human skeleton based on noisy streams of head and hand pose. Our approach relies on a model of pose likelihood that is novel and theoretically well-grounded. We demonstrate on publicly available datasets that our method is effective even from very impoverished signals and investigate how pose prediction can be made more accurate and realistic.","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.01148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9710218","Gestures and body pose;Motion and tracking","Legged locomotion;Wearable computers;Impedance matching;Training data;Resists;Life estimation;Predictive models","","","","1","","75","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"“If You Could See Me through My Eyes”: Predicting Pedestrian Perception","J. Petzold; M. Wahby; F. Stark; U. Behrje; H. Hamann","Institute of Computer Engineering, University of Lübeck, Lübeck, Germany; Institute of Computer Engineering, University of Lübeck, Lübeck, Germany; Institute of Computer Engineering, University of Lübeck, Lübeck, Germany; Institute of Computer Engineering, University of Lübeck, Lübeck, Germany; Institute of Computer Engineering, University of Lübeck, Lübeck, Germany","2022 8th International Conference on Control, Automation and Robotics (ICCAR)","31 May 2022","2022","","","184","190","Pedestrians are particularly vulnerable road users in urban traffic. With the arrival of autonomous driving, novel technologies can be developed specifically to protect pedestrians. We propose a machine learning toolchain to train artificial neural networks as models of pedestrian behavior. In a preliminary study, we use synthetic data from simulations of a specific pedestrian crossing scenario to train a variational autoencoder and a long short-term memory network to predict a pedestrian's future visual perception. We can accurately predict a pedestrian's future perceptions within relevant time horizons. By iteratively feeding these predicted frames into these networks, they can be used as simulations of pedestrians as indicated by our results. Such trained networks can later be used to predict pedestrian behaviors even from the perspective of the autonomous car. Another future extension will be to re-train these networks with real-world video data.","2251-2454","978-1-6654-8116-8","10.1109/ICCAR55106.2022.9782646","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9782646","world models;intelligent transportation systems;machine learning;multi-agent systems;sensor prediction","Training;Visualization;Roads;Machine learning;Predictive models;Data models;Behavioral sciences","advanced driver assistance systems;automobiles;learning (artificial intelligence);pedestrians;recurrent neural nets;road traffic;traffic engineering computing;video signal processing","pedestrian perception;vulnerable road users;urban traffic;autonomous driving;artificial neural networks;pedestrian behavior;specific pedestrian crossing scenario;long short-term memory network;trained networks;real-world video data;autonomous car","","1","","51","IEEE","31 May 2022","","","IEEE","IEEE Conferences"
"Fidora: Robust WiFi-Based Indoor Localization via Unsupervised Domain Adaptation","X. Chen; H. Li; C. Zhou; X. Liu; D. Wu; G. Dudek","Samsung AI Center, Montreal, QC, Canada; Samsung AI Center, Montreal, QC, Canada; Samsung AI Center, Montreal, QC, Canada; Samsung AI Center, Montreal, QC, Canada; Samsung AI Center, Montreal, QC, Canada; Samsung AI Center, Montreal, QC, Canada","IEEE Internet of Things Journal","7 Jun 2022","2022","9","12","9872","9888","Emerging Internet of Things (IoT) applications, such as cashier-less shopping, mobile ads targeting, and geo-based augmented reality (AR), are expected to bring us much more convenience and infotainment. To realize this amazing future, we need to feed these applications with user locations of (sub)meter-level resolution anytime and anywhere. Unfortunately, many widely used location sources are either unavailable indoor (e.g., global positioning system) or coarse grained (e.g., user check-ins). In order to provide ubiquitous localization services, the widespread WiFi signals are being leveraged to establish (sub)meter-level localization systems. Fine-grained WiFi propagation characteristics, which are sensitive to human body locations, have been employed to create location fingerprints. However, these WiFi characteristics are also sensitive to: 1) the body shapes of different users and 2) the objects in the background environment. Consequently, systems based on WiFi fingerprints are vulnerable in the presence of: 1) new users with different body shapes and 2) daily changes of the environment, e.g., opening/closing doors. To tackle this issue, this article proposes a WiFi-based localization system based on domain-adaptation with cluster assumption, named Fidora. Fidora is able to: 1) localize different users with labeled data from only one or two example users and 2) localize the same user in a changed environment without labeling any new data. To achieve these, Fidora integrates two major modules. It first adopts a data augmenter that introduces data diversity using a variational autoencoder (VAE). It then trains a domain-adaptive classifier that adjusts itself to newly collected unlabeled data using a joint classification-reconstruction structure. We conducted real-world experiments to evaluate Fidora against the state of the art. It is demonstrated that when tested on an unlabeled user, Fidora increases the average  $F1$  score by 17.8% and improves the worst case accuracy by 20.2%. Moreover, when applied in a varied environment, Fidora outperforms the state of the art by 23.1%.","2327-4662","","10.1109/JIOT.2022.3163391","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745151","Location awareness;transfer learning;unsupervised learning","Wireless fidelity;Fingerprint recognition;Location awareness;Internet of Things;Feature extraction;Shape;Labeling","indoor radio;Internet of Things;mobile computing;neural nets;unsupervised learning;wireless LAN","Internet of Things applications;unsupervised domain adaptation;robust WiFi-based indoor localization;average F1 score;unlabeled user;domain-adaptive classifier;data diversity;data augmenter;domain-adaptation;WiFi-based localization system;WiFi fingerprints;background environment;WiFi characteristics;location fingerprints;human body locations;fine-grained WiFi propagation characteristics;widespread WiFi signals;ubiquitous localization services;global positioning system;location sources;user locations;infotainment;geo-based augmented reality;mobile ads","","1","","72","IEEE","30 Mar 2022","","","IEEE","IEEE Journals"
"MIST-Tacotron: End-to-End Emotional Speech Synthesis Using Mel-Spectrogram Image Style Transfer","S. Moon; S. Kim; Y. -H. Choi","School of Robotics, Kwangwoon University, Seoul, South Korea; School of Robotics, Kwangwoon University, Seoul, South Korea; School of Robotics, Kwangwoon University, Seoul, South Korea","IEEE Access","11 Mar 2022","2022","10","","25455","25463","With the development of voice synthesis technology using deep learning, voice synthesis research that expresses the characteristics and emotions of speakers is actively being conducted. Current technology does not satisfactorily express various emotions and characteristics for speakers with very low or high vocal ranges and for speakers with dialects. In this paper, we propose mel-spectrogram image transfer (MIST)-Tacotron, a Tacotron 2-based speech synthesis model that adds a reference encoder with an image style transfer module. The proposed method is a technique that adds image style transfer to the existing Tacotron 2 model and extracts the speaker’s feature from the reference mel-spectrogram using a pre-trained deep learning model. Through the extracted feature, the style such as pitch, tone, and duration of the speaker are trained to express the style and emotion of the speaker more clearly. To extract the speaker’s style independently from the speaker’s timbre and emotion, the ID value for the speaker and the ID value for the emotional state were used as inputs. Performance is evaluated by F0 voiced error (FVE), F0 gross pitch error (F0 GPE), mel-cepstral distortion (MCD), band aperiodicity distortion (BAPD), voiced/unvoiced error (VUVE), false positive rate (FPR), and false negative rate (FNR). The performance of the proposed model was observed to have lower error values than the existing models, GST (Global Style Token) Tacotron and VAE (Variational Autoencoder) Tacotron. As a result of measuring mean opinion score (MOS), the sound quality of the proposed model received the highest score in terms of emotional expression and speaker style reflection.","2169-3536","","10.1109/ACCESS.2022.3156093","National Research Foundation of Korea (NRF) funded by the Ministry of Science and ICT, Korea Government(grant numbers:2021R1F1A1064080); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9726166","Tacotron;mel-spectrogram;image style transfer;speech synthesis;multi-speaker text-to-speech (TTS);emotion expression","Speech synthesis;Feature extraction;Training data;Vocoders;Emotion recognition;Deep learning;Data mining;Text analysis","feature extraction;learning (artificial intelligence);speech processing;speech synthesis","MIST-Tacotron;end-to-end emotional speech synthesis;mel-spectrogram image Style transfer;voice synthesis technology;voice synthesis research;mel-spectrogram image transfer-Tacotron;Tacotron 2-based speech synthesis model;speaker;reference mel-spectrogram;pre-trained deep learning model;emotional state;mel-cepstral distortion;false positive rate;Global Style Token;emotional expression","","1","","46","CCBY","2 Mar 2022","","","IEEE","IEEE Journals"
"Vision-Based Autonomous Driving: A Model Learning Approach","A. Baheri; I. Kolmanovsky; A. Girard; H. E. Tseng; D. Filev","Department of Aerospace and Mechanical Engineering, West Virginia University, Morgantown, WV, USA; Department of Aerospace Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Aerospace Engineering, University of Michigan, Ann Arbor, MI, USA; Ford Research and Innovation Center, Dearborn, MI, USA; Ford Research and Innovation Center, Dearborn, MI, USA","2020 American Control Conference (ACC)","27 Jul 2020","2020","","","2520","2525","We present an integrated approach for perception and control for an autonomous vehicle and demonstrate this approach in a high-fidelity urban driving simulator. Our approach first builds a model for the environment, then trains a policy exploiting the learned model to identify the action to take at each time-step. To build a model for the environment, we leverage several deep learning algorithms. To that end, first we train a variational autoencoder to encode the input image into an abstract latent representation. We then utilize a recurrent neural network to predict the latent representation of the next frame and handle temporal information. Finally, we utilize an evolutionary-based reinforcement learning algorithm to train a controller based on these latent representations to identify the action to take. We evaluate our approach in CARLA, a high-fidelity urban driving simulator, and conduct an extensive generalization study. Our results demonstrate that our approach outperforms several previously reported approaches in terms of the percentage of successfully completed episodes for a lane keeping task.","2378-5861","978-1-5386-8266-1","10.23919/ACC45564.2020.9147510","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9147510","","Autonomous vehicles;Learning (artificial intelligence);Predictive models;Task analysis;Training;Memory modules;Acceleration","computer simulation;control engineering computing;learning (artificial intelligence);mobile robots;recurrent neural nets;road vehicles;robot vision;traffic engineering computing","integrated approach;autonomous vehicle;high-fidelity urban driving simulator;deep learning algorithms;abstract latent representation;recurrent neural network;handle temporal information;reported approaches;vision-based autonomous driving;CARLA","","1","","23","","27 Jul 2020","","","IEEE","IEEE Conferences"
"Robust Multi-User In-Hand Object Recognition in Human-Robot Collaboration Using a Wearable Force-Myography Device","E. Bamani; N. D. Kahanowich; I. Ben-David; A. Sintov","School of Mechanical Engineering, Tel-Aviv University, Tel Aviv-Yafo, Israel; School of Mechanical Engineering, Tel-Aviv University, Tel Aviv-Yafo, Israel; School of Mechanical Engineering, Tel-Aviv University, Tel Aviv-Yafo, Israel; School of Mechanical Engineering, Tel-Aviv University, Tel Aviv-Yafo, Israel","IEEE Robotics and Automation Letters","19 Oct 2021","2022","7","1","104","111","Applicable human-robot collaboration requires intuitive recognition of human intention during shared work. A grasped object such as a tool held by the human provides vital information about the upcoming task. In this letter, we explore the use of a wearable device to non-visually recognize objects within the human hand in various possible grasps. The device is based on Force-Myography (FMG) where simple and affordable force sensors measure perturbations of forearm muscles. We propose a novel Deep Neural-Network architecture termed Flip-U-Net inspired by the familiar U-Net architecture used for image segmentation. The Flip-U-Net is trained over data collected from several human participants and with multiple objects of each class. Data is collected while manipulating the objects between different grasps and arm postures. The data is also pre-processed with data augmentation and used to train a Variational Autoencoder for dimensionality reduction mapping. While prior work did not provide a transferable FMG-based model, we show that the proposed network can classify objects grasped by multiple new users without additional training efforts. Experiment with 12 test participants show classification accuracy of approximately 95% over multiple grasps and objects. Correlations between accuracy and various anthropometric measures are also presented. Furthermore, we show that the model can be fine-tuned to a particular user based on an anthropometric measure.","2377-3766","","10.1109/LRA.2021.3118087","Israel Science Foundation(grant numbers:1565/20); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9562277","Human-robot collaboration;intention recognition","Sensors;Task analysis;Object recognition;Data models;Training data;Training;Robot sensing systems","deep learning (artificial intelligence);electromyography;force sensors;human-robot interaction;image segmentation;manipulators;neural net architecture;object recognition;robot vision","wearable force-myography device;human-robot collaboration;human intention;wearable device;force sensors;forearm muscles;deep neural-network architecture;Flip-U-Net;image segmentation;data augmentation;FMG;anthropometric measure;multiuser in-hand object recognition","","1","","29","IEEE","6 Oct 2021","","","IEEE","IEEE Journals"
"When Pansharpening Meets Graph Convolution Network and Knowledge Distillation","K. Yan; M. Zhou; L. Liu; C. Xie; D. Hong","Science Island Branch, University of Science and Technology of China, Hefei, China; Science Island Branch, University of Science and Technology of China, Hefei, China; Department of Computer Science, Shanghai Jiao Tong University, Shanghai, China; Institute of Intelligent Machines, Hefei Institutes of Physical Science, Chinese Academy of Sciences, Hefei, China; Key Laboratory of Computational Optical Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","29 Apr 2022","2022","60","","1","15","In this article, we propose a novel graph convolutional network (GCN) for pansharpening, defined as GCPNet, which consists of three main modules: the spatial GCN module (SGCN), the spectral band GCN module (BGCN), and the atrous spatial pyramid module (ASPM). Specifically, due to the nature of GCN, the proposed SGCN and BGCN are capable of exploring the long-range relationship between the object and the global state in the spatial and spectral aspects, which benefits pansharpened results and has not been fully investigated before. In addition, the designed ASPM is equipped with multiscale atrous convolutions and learns richer local feature information, so as to cover the objects of different sizes in satellite images. To further enhance the representation of our proposed GCPNet, asynchronous knowledge distillation is introduced to provide compact features by heterogeneous task imitation in a teacher–student paradigm. In the paradigm, the teacher network acts as a variational autoencoder to extract compact features of the ground-truth MS images. The student network, devised for pansharpening, is trained with the assistance of the teacher network to transfer the important information of the expected ground-truth MS images. Extensive experimental results on different satellite datasets demonstrate that our proposed network outperforms the state-of-the-art methods both visually and quantitatively. The source code is released at https://github.com/Keyu-Yan/GCPNet.","1558-0644","","10.1109/TGRS.2022.3168192","National Natural Science Foundation of China(grant numbers:32171888); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9758796","Asynchronous knowledge distillation;atrous convolution;graph convolutional network (GCN);pansharpening","Pansharpening;Convolution;Satellites;Feature extraction;Task analysis;Knowledge engineering;Spatial resolution","feature extraction;geophysical image processing;graph theory;image classification;image fusion;image resolution;learning (artificial intelligence);wavelet transforms","satellite images;asynchronous knowledge distillation;compact features;heterogeneous task imitation;teacher-student paradigm;teacher network;student network;expected ground-truth MS images;different satellite datasets;pansharpening meets graph convolution network;novel graph convolutional network;spatial GCN module;SGCN;spectral band GCN module;BGCN;atrous spatial pyramid module;long-range relationship;global state;spatial aspects;spectral aspects;pansharpened results;designed ASPM;multiscale atrous convolutions;richer local feature information","","1","","67","IEEE","18 Apr 2022","","","IEEE","IEEE Journals"
"Active Exploration for Unsupervised Object Categorization Based on Multimodal Hierarchical Dirichlet Process","R. Yoshino; T. Takano; H. Tanaka; T. Taniguchi","College of Information Science and Engineering, Ritsumeikan University, Shiga, Japan; Department of Computer Science, Faculty of Informatics, Shizuoka Institute of Science and Technology, Shizuoka, Japan; College of Information Science and Engineering, Ritsumeikan University, Shiga, Japan; College of Information Science and Engineering, Ritsumeikan University, Shiga, Japan","2021 IEEE/SICE International Symposium on System Integration (SII)","24 Mar 2021","2021","","","176","183","This paper describes an effective active exploration method for multimodal object categorization using a multimodal hierarchical Dirichlet process (MHDP). MHDP is a type of multimodal latent variable models, e.g., multimodal latent Dirichlet allocation and multimodal variational autoencoder, that enables a robot to perform unsupervised multimodal object categorization on the basis of different types of sensor information. The goal of the active exploration is to reduce the number of actions executed to collect multimodal sensor information from a variety of objects to acquire knowledge on object categories. The active exploration method employing the information gain (IG) criterion for MHDP is described by extending the IG-based active perception method. Exploiting the submodular property of IG in MHDP, greedy and lazy greedy algorithms with a certain theoretical guarantee of performance are proposed. The effectiveness of the proposed method is evaluated in a robot experiment. Results show that the proposed active exploration method with the greedy algorithm works well, and it significantly reduces the step for exploration. Further, the performance of the lazy greedy algorithm is found to deteriorate at times, due to the estimation error in the IG, differently from that of active perception.","2474-2325","978-1-7281-7658-1","10.1109/IEEECONF49454.2021.9382781","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9382781","","Greedy algorithms;Monte Carlo methods;Active perception;System integration;Robot sensing systems;Approximation algorithms;Cognitive systems","greedy algorithms;intelligent robots;object recognition","multimodal hierarchical Dirichlet process;active exploration method;MHDP;unsupervised multimodal object categorization;multimodal sensor information;object categories;information gain criterion;IG-based active perception method;lazy greedy algorithms","","1","","17","","24 Mar 2021","","","IEEE","IEEE Conferences"
"Evolutionary Algorithm Driven Explainable Adversarial Artificial Intelligence","C. Veal; M. Lindsay; S. D. Kovaleski; D. T. Anderson; S. R. Price","Department of Electrical Engineering and Computer Science, University of Missouri-Columbia, Columbia, MO, USA; Department of Electrical Engineering and Computer Science, University of Missouri-Columbia, Columbia, MO, USA; Department of Electrical Engineering and Computer Science, University of Missouri-Columbia, Columbia, MO, USA; Department of Electrical Engineering and Computer Science, University of Missouri-Columbia, Columbia, MO, USA; U.S. Army Engineer Research and Development Center, Vicksburg, MS, USA","2020 IEEE Symposium Series on Computational Intelligence (SSCI)","5 Jan 2021","2020","","","913","920","It is well-known that machine learning algorithms can be susceptible to undesirable effects when exposed to conditions that are not expressed adequately in the training dataset. This leads to a growing interest throughout many communities; where do algorithms and trained models break? Recently, methods such as generative adversarial neural networks and variational autoencoders were proposed to create adversarial examples that challenge algorithms. This results in artificial intelligence having higher false detections or completely losing recognition. The problem is that existing solutions, are for the most part, black boxes. Current gaps include how do we better control and understand adversarial algorithms. Herein, we propose the concept of an adversarial modifier set as an understandable and controlled way to generate adversarial examples. This is achieved by exploiting the improved evolution-constructed algorithm to identify ideal features that a victim algorithm values in imagery. These features are combined to realize a tuple library that preserves spatial relations. Last, a set of algorithmically controlled modifiers that generate the imagery are found by examining the content of the false imagery. Preliminary results are encouraging and demonstrate that this approach has benefits in both generating explainable adversarial examples, as well as shedding some insight into victim algorithm decision making.","","978-1-7281-2547-3","10.1109/SSCI47803.2020.9308361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308361","adversarial;artificial intelligence;generative;improved evolution-constructed algorithm;machine learning","Feature extraction;Signal processing algorithms;Libraries;Visualization;Training;Transforms;Correlation","decision making;evolutionary computation;learning (artificial intelligence);neural nets;security of data","adversarial algorithms;adversarial modifier set;improved evolution-constructed algorithm;algorithmically controlled modifiers;victim algorithm decision making;evolutionary algorithm driven explainable adversarial artificial intelligence;machine learning algorithms;training dataset;trained models;generative adversarial neural networks","","1","","32","","5 Jan 2021","","","IEEE","IEEE Conferences"
"Amp-Space: A Large-Scale Dataset for Fine-Grained Timbre Transformation","J. Naradowsky","Preferred Networks, Tokyo, Japan","2021 24th International Conference on Digital Audio Effects (DAFx)","11 May 2022","2021","","","57","64","We release Amp-Space, a large-scale dataset of paired audio samples: a source audio signal, and an output signal, the result of a timbre transformation. The types of transformations we study are from blackbox musical tools (amplifiers, stompboxes, studio effects) traditionally used to shape the sound of guitar, bass, or synthesizer sounds. For each sample of transformed audio, the set of parameters used to create it are given. Samples are from both real and simulated devices, the latter allowing for orders of magnitude greater data than found in comparable datasets. We demonstrate potential use cases of this data by (a) pre-training a conditional WaveNet model on synthetic data and show that it reduces the number of samples necessary to digitally reproduce a real musical device, and (b) training a variational autoencoder to shape a continuous space of timbre transformations for creating new sounds through interpolation.","2413-6689","978-3-200-08378-3","10.23919/DAFx51585.2021.9768241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9768241","","Training;Interpolation;Codes;Shape;Synthesizers;Data models;Timbre","audio coding;digital signal processing chips;musical instruments","output signal;blackbox musical tools;studio effects;synthesizer sounds;transformed audio;simulated devices;magnitude greater data;comparable datasets;synthetic data;musical device;continuous space;Amp-Space;large-scale dataset;fine-grained timbre transformation;paired audio samples;source audio signal","","1","","29","","11 May 2022","","","IEEE","IEEE Conferences"
"Towards a Camera-Based Road Damage Assessment and Detection for Autonomous Vehicles: Applying Scaled-YOLO and CVAE-WGAN","P. Fassmeyer; F. Kortmann; P. Drews; B. Funk","Information Systems (IIS) Leuphana University, Lüneburg, Germany; Information Systems (IIS) Leuphana University, Lüneburg, Germany; Information Systems (IIS) Leuphana University, Lüneburg, Germany; Information Systems (IIS) Leuphana University, Lüneburg, Germany","2021 IEEE 94th Vehicular Technology Conference (VTC2021-Fall)","10 Dec 2021","2021","","","1","7","Initiatives such as the 2020 IEEE Global Road Damage Detection Challenge prompted extensive research in camera-based road damage detection with Deep Learning, primarily focused on improving the efficiency of road management. However, road damage detection is also relevant for automated driving to optimize passenger comfort and safety. We use the state-of-the-art object detection framework Scaled-YOLOv4 and develop two small-sized models that cope with the limited computational resources in the vehicle. With average F1 scores of 0.54 and 0.586, respectively, the models keep pace with the state-of-the-art solutions of the challenge. Since the data consists only of smartphone images, we also train expert models for autonomous driving utilizing vehicle camera data. In addition to detection, severity assessment is critical. We propose a semi-supervised learning approach based on the encodings learned by combining a class-conditional Variational Autoencoder and a Wasserstein Generative Adversarial Network to classify detected damage into different severity levels.","2577-2465","978-1-6654-1368-8","10.1109/VTC2021-Fall52928.2021.9625213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9625213","Road damage;deep learning;computer vision;autonomous driving;Scaled-YOLOv4;VAE;Wasserstein GAN","Deep learning;Vehicular and wireless technologies;Roads;Computational modeling;Object detection;Semisupervised learning;Generative adversarial networks","cameras;deep learning (artificial intelligence);image classification;learning (artificial intelligence);mobile robots;object detection;road vehicles;roads;robot vision;semi-supervised learning (artificial intelligence);smart phones;traffic engineering computing","camera-based road damage detection;Deep Learning;road management;automated driving;passenger comfort;small-sized models;expert models;autonomous driving;vehicle camera data;detected damage;camera-based Road Damage assessment;autonomous vehicles;Scaled-YOLO;CVAE-WGAN;2020 IEEE Global Road Damage Detection Challenge;Scaled-YOLOv object detection framework","","1","","41","IEEE","10 Dec 2021","","","IEEE","IEEE Conferences"
"BERT for Open-Domain Conversation Modeling","X. Zhao; Y. Zhang; W. Guo; X. Yuan","College of Computer Science, Nankai University, Tianjin, P.R.China; College of Computer Science, Nankai University, Tianjin, P.R.China; College of Computer Science, Nankai University, Tianjin, P.R.China; College of Computer Science, Nankai University, Tianjin, P.R.China","2019 IEEE 5th International Conference on Computer and Communications (ICCC)","13 Apr 2020","2019","","","1532","1536","The RNN encoder-decoder structures have critical problems in generating meaningful responses. Variational autoencoders (VAE) combined with hierarchical RNNs have emerged as a powerful framework for conversation modeling, as the latent variables can encode the high-level information (topics, tones, sentiments, etc.) in conversations. On the other hand, BERT, one of the latest deep pre-trained language representation models, has achieved the remarkable state of the art across a wide range of tasks in natural language processing. However, BERT has not yet been investigated in a conversation generation task. In this paper, we explore different BERT-empowered conversation modeling approaches by incorporating BERT, RNNs, and VAEs. Moreover, BERT can be used either with weights fixed as feature extraction module or with weights updated and optimized for a specific task. In this paper, we demonstrate that simply using fixed pre-trained BERT as part of the model without further finetuning is powerful enough for generating better responses in terms of fluency, grammar, and semantic coherency. Fine-tuning can achieve the comparable results. This paper sets new baselines for conversation generation task and we are the first to demonstrate the success of BERT in conversation modeling.","","978-1-7281-4743-7","10.1109/ICCC47050.2019.9064414","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9064414","conversation generation;BERT;VAEs","Bit error rate;Task analysis;Decoding;Iron;Computational modeling;Feature extraction;Motion pictures","decoding;feature extraction;grammars;learning (artificial intelligence);natural language processing;recurrent neural nets","conversation generation task;open-domain conversation modeling;RNN encoder-decoder structures;VAE;natural language processing;fixed pre-trained BERT;BERT-empowered conversation;deep pre-trained language representation models","","1","","9","IEEE","13 Apr 2020","","","IEEE","IEEE Conferences"
"Dual Spoof Disentanglement Generation for Face Anti-Spoofing With Depth Uncertainty Learning","H. Wu; D. Zeng; Y. Hu; H. Shi; T. Mei","Department of Communication Engineering, Shanghai University, Shanghai, China; Department of Communication Engineering, Shanghai University, Shanghai, China; JD AI Research, Beijing, China; JD AI Research, Beijing, China; JD AI Research, Beijing, China","IEEE Transactions on Circuits and Systems for Video Technology","1 Jul 2022","2022","32","7","4626","4638","Face anti-spoofing (FAS) plays a vital role in preventing face recognition systems from presentation attacks. Existing face anti-spoofing datasets lack diversity due to the insufficient identity and insignificant variance, which limits the generalization ability of FAS model. In this paper, we propose Dual Spoof Disentanglement Generation (DSDG) framework to tackle this challenge by “anti-spoofing via generation”. Depending on the interpretable factorized latent disentanglement in Variational Autoencoder (VAE), DSDG learns a joint distribution of the identity representation and the spoofing pattern representation in the latent space. Then, large-scale paired live and spoofing images can be generated from random noise to boost the diversity of the training set. However, some generated face images are partially distorted due to the inherent defect of VAE. Such noisy samples are hard to predict precise depth values, thus may obstruct the widely-used depth supervised optimization. To tackle this issue, we further introduce a lightweight Depth Uncertainty Module (DUM), which alleviates the adverse effects of noisy samples by depth uncertainty learning. DUM is developed without extra-dependency, thus can be flexibly integrated with any depth supervised network for face anti-spoofing. We evaluate the effectiveness of the proposed method on five popular benchmarks and achieve state-of-the-art results under both intra- and inter- test settings. The codes are available at https://github.com/JDAI-CV/FaceX-Zoo/tree/main/addition_module/DSDG.","1558-2205","","10.1109/TCSVT.2021.3133620","National Key Research and Development Program of China(grant numbers:2020AAA0103800); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9641836","Face anti-spoofing;dual spoof disentanglement generation;depth uncertainty learning","Faces;Training;Face recognition;Uncertainty;Feature extraction;Generators;Soft sensors","face recognition;feature extraction;learning (artificial intelligence);neural nets","depth uncertainty learning;face recognition systems;face anti-spoofing datasets;Dual Spoof Disentanglement Generation framework;interpretable factorized latent disentanglement;spoofing pattern representation;spoofing images;generated face images;lightweight Depth Uncertainty Module","","","","85","IEEE","7 Dec 2021","","","IEEE","IEEE Journals"
"Structured Cooperative Reinforcement Learning With Time-Varying Composite Action Space","W. Li; X. Wang; B. Jin; D. Luo; H. Zha","School of Computer Science and Technology and the MOE Key Laboratory for Advanced Theory and Application in Statistics and Data Science, East China Normal University, Shanghai, China; School of Computer Science and Technology and the MOE Key Laboratory for Advanced Theory and Application in Statistics and Data Science, East China Normal University, Shanghai, China; School of Computer Science and Technology and the MOE Key Laboratory for Advanced Theory and Application in Statistics and Data Science, East China Normal University, Shanghai, China; Tencent AI Lab, Tencent Inc, Shenzhen, China; School of Data Science and AIRS, Chinese University of Hong Kong, Shenzhen, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","4 Oct 2022","2022","44","11","8618","8634","In recent years, reinforcement learning has achieved excellent results in low-dimensional static action spaces such as games and simple robotics. However, the action space is usually composite, composed of multiple sub-action with different functions, and time-varying for practical tasks. The existing sub-actions might be temporarily invalid due to the external environment, while unseen sub-actions can be added to the current system. To solve the robustness and transferability problems in time-varying composite action spaces, we propose a structured cooperative reinforcement learning algorithm based on the centralized critic and decentralized actor framework, called SCORE. We model the single-agent problem with composite action space as a fully cooperative partially observable stochastic game and further employ a graph attention network to capture the dependencies between heterogeneous sub-actions. To promote tighter cooperation between the decomposed heterogeneous agents, SCORE introduces a hierarchical variational autoencoder, which maps the heterogeneous sub-action space into a common latent action space. We also incorporate an implicit credit assignment structure into the SCORE to overcome the multi-agent credit assignment problem in the fully cooperative partially observable stochastic game. Performance experiments on the proof-of-concept task and precision agriculture task show that SCORE has significant advantages in robustness and transferability for time-varying composite action space.","1939-3539","","10.1109/TPAMI.2021.3102140","National Key Research and Development Program of China(grant numbers:2020AAA0107400); NSFC(grant numbers:12071145); Shanghai Municipal Science and Technology Major Project(grant numbers:2021SHZDZX0102); STCSM(grant numbers:18DZ2270700,20511101100); Open Research Projects of Zhejiang Lab(grant numbers:2021KE0AB03); Shenzhen Institute of Artificial Intelligence and Robotics for Society; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9507301","Cooperative multi-agent reinforcement learning;composite action space;time-varying action space","Agriculture;Aerospace electronics;Task analysis;Reinforcement learning;Games;Carbon dioxide;Robustness","","","","","","67","IEEE","4 Aug 2021","","","IEEE","IEEE Journals"
"Audio-to-Image Cross-Modal Generation","M. Żelaszczyk; J. Mańdziuk","Faculty of Mathematics and Information, Science Warsaw University of Technology, Warsaw, Poland; Faculty of Mathematics and Information, Science Warsaw University of Technology, Warsaw, Poland","2022 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2022","2022","","","1","8","Cross-modal representation learning allows to integrate information from different modalities into one representation. At the same time, research on generative models tends to focus on the visual domain with less emphasis on other domains, such as audio or text, potentially missing the benefits of shared representations. Studies successfully linking more than one modality in the generative setting are rare. In this context, we verify the possibility to train variational autoencoders (VAEs) to reconstruct image archetypes from audio data. Specifically, we consider VAEs in an adversarial training framework in order to ensure more variability in the generated data and find that there is a trade-off between the consistency and diversity of the generated images - this trade-off can be governed by scaling the reconstruction loss up or down, respectively. Our results further suggest that even in the case when the generated images are relatively inconsistent (diverse), features that are critical for proper image classification are preserved.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9892863","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9892863","neural networks;cross-modal learning;generative models","Training;Representation learning;Visualization;Neural networks;Data visualization;Feature extraction;Data models","image classification;image reconstruction;learning (artificial intelligence);medical image processing","audio-to-image cross-modal generation;cross-modal representation learning;generative models;visual domain;audio text;shared representations;generative setting;VAEs;image archetypes;audio data;adversarial training framework;proper image classification","","","","37","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"Unsupervised Controllable Generation with Self-Training","G. G. Chrysos; J. Kossaifi; Z. Yu; A. Anandkumar","EPFL, Switzerland; NVIDIA, United States; NVIDIA, United States; Caltech / NVIDIA, United States","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","8","Recent generative adversarial networks (GANs) are able to generate impressive photo-realistic images. However, controllable generation with GANs remains an open research problem. Achieving controllable generation requires semantically interpretable and disentangled factors of variation. It is challenging to achieve this goal using simple fixed distributions such as Gaussian distribution. Instead, we propose an unsupervised framework to learn a distribution of latent codes that control the generator through self-training. Self-training provides an iterative feedback in the GAN training, from the discriminator to the generator, and progressively improves the proposal of the latent codes as training proceeds. The latent codes are sampled from a latent variable model that is learned in the feature space of the discriminator. We consider a normalized independent component analysis model and learn its parameters through tensor factorization of the higher-order moments. Our framework exhibits better disentanglement compared to other variants such as the variational autoencoder, and is able to discover semantically meaningful latent codes without any supervision. We empirically demonstrate on both cars and faces datasets that each group of elements in the learned code controls a mode of variation with a semantic meaning, e.g. pose or background change. We also demonstrate with quantitative metrics that our method generates better results compared to other approaches.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9534045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534045","","Training;Measurement;Codes;Tensors;Semantics;Neural networks;Independent component analysis","Gaussian distribution;independent component analysis;neural nets;realistic images;tensors;unsupervised learning","self-training;open research problem;photo-realistic images;recent generative adversarial networks;unsupervised controllable generation;learned code;semantically meaningful latent codes;normalized independent component analysis model;latent variable model;training proceeds;GAN training;unsupervised framework;Gaussian distribution;simple fixed distributions","","","","48","","20 Sep 2021","","","IEEE","IEEE Conferences"
"A Method for Identifying Origin of Digital Images Using a Convolutional Neural Network","R. Huang; F. Fang; H. H. Nguyen; J. Yamagishi; I. Echizen","Engineering Research Center of Digitized Textile & Apparel Technology, Ministry of Education, Donghua University, Shanghai, China; National Institute of Informatics, Tokyo, Japan; SOKENDAI (The Graduate University for Advanced Studies), Kanagawa, Japan; SOKENDAI (The Graduate University for Advanced Studies), Kanagawa, Japan; The University of Tokyo, Tokyo, Japan","2020 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","31 Dec 2020","2020","","","1293","1299","The rapid development of deep learning techniques has created new challenges in identifying the origin of digital images because generative adversarial networks and variational autoencoders can create plausible digital images whose contents are not present in natural scenes. In this paper, we consider the origin that can be broken down into three categories: natural photographic image (NPI), computer generated graphic (CGG), and deep network generated image (DGI). A method is presented for effectively identifying the origin of digital images that is based on a convolutional neural network (CNN) and uses a local-to-global framework to reduce training complexity. By feeding labeled data, the CNN is trained to predict the origin of local patches cropped from an image. The origin of the full-size image is then determined by majority voting. Unlike previous forensic methods, the CNN takes the raw pixels as input without the aid of “residual map”. Experimental results revealed that not only the high-frequency components but also the middle-frequency ones contribute to origin identification. The proposed method achieved up to 95.21% identification accuracy and behaved robustly against several common post-processing operations including JPEG compression, scaling, geometric transformation, and contrast stretching. The quantitative results demonstrate that the proposed method is more effective than handcrafted feature-based methods.","2640-0103","978-988-14768-8-3","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9306229","","Training;Digital images;Task analysis;Image color analysis;Transform coding;Forensics;Robustness","computer graphics;convolutional neural nets;deep learning (artificial intelligence);feature extraction;image coding;image forensics","convolutional neural network;deep learning techniques;generative adversarial networks;plausible digital images;natural photographic image;CNN;forensic methods;origin identification;handcrafted feature-based methods;computer generated graphic;deep network generated image;local-to-global framework;training complexity;JPEG compression;geometric transformation;contrast stretching","","","","27","","31 Dec 2020","","","IEEE","IEEE Conferences"
"Federated Learning-Empowered Disease Diagnosis Mechanism in the Internet of Medical Things: From the Privacy-Preservation Perspective","X. Wang; J. Hu; H. Lin; W. Liu; H. Moon; M. J. Piran","Fujian Normal University, Fuzhou, Fujian, China; University of Exeter, Exeter, UK; Fujian Normal University, Fuzhou, Fujian, China; Fujian Normal University, Fuzhou, Fujian, China; Department of Computer Software and Engineering, Sejong University, Seoul, South Korea; Department of Computer Software and Engineering, Sejong University, Seoul, South Korea","IEEE Transactions on Industrial Informatics","","2022","PP","99","1","9","The deep integration of the Internet of Things (IoT) and the medical industry has given birth to the Internet of Medical Things (IoMT). In IoMT, physicians treat a patient's disease by analyzing patient data collected through mobile devices with the assistance of an artificial intelligence (AI)-empowered systems. However, the traditional AI technology may lead to the leakage of patient privacy data due to its own design flaws. As a privacy-preserving federated learning (FL) can generate a global disease diagnosis model through multi-party collaboration. However, FL is still unable to resist inference attacks. In this paper, to address such problems, we propose a privacy-enhanced disease diagnosis mechanism using FL for IoMT. Specifically, we first reconstruct medical data through a variational autoencoder (VAE) and add differential privacy noise to it to resist inference attacks. These data are then used to train local disease diagnosis models, thereby preserving patients' privacy. Furthermore, to encourage participation in FL, we propose an incentive mechanism to provide corresponding rewards to participants. Experiments are conducted on the arrhythmia database MIT-BIH. The experimental results show that the proposed mechanism reduces the probability of reconstructing patient medical data while ensuring high-precision heart disease diagnosis.","1941-0050","","10.1109/TII.2022.3210597","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9906889","Disease Diagnosis;Internet of Medical Things;Federated Learning;Privacy Protection","Medical diagnostic imaging;Data models;Data privacy;Medical diagnosis;Hospitals;Artificial intelligence;Heart","","","","","","","IEEE","30 Sep 2022","","","IEEE","IEEE Early Access Articles"
"APEX: Characterizing Attack Behaviors from Network Anomalies","K. S. K. Liyanage; Z. Tian; D. M. Divakaran; M. C. Chan; M. Gurusamy","University of Ruhuna, Sri Lanka; National University of Singapore, Singapore; Trustwave, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore","2022 IEEE International Performance, Computing, and Communications Conference (IPCCC)","12 Oct 2022","2022","","","207","216","Networks regularly face various threats and attacks that manifest in their communication traffic. Recent works proposed unsupervised approaches, e.g., using a variational autoencoder, that are not only effective in detecting anomalies in network traffic, but also practical as they do not require ground truth or labeled data. However, the problem of characterizing anomalies into different attack behaviors is still less explored; in this work, we study this specific problem. We develop APEX, a framework that employs data mining approaches in a semisupervised way to extract the attack patterns from anomalous traffic and links them to specific attack types. APEX comprises two levels of mining: the first level extracts patterns in anomalous network flows, and the second level characterizes behaviors in the extracted patterns into different attack classes. We carry out extensive experiments on real network traces obtained from the MAWI traffic archive. The evaluations demonstrate that APEX is effective in extracting distinguishable behaviors of network attacks from anomalous traffic, and provide useful insights to security analysts investigating the anomalies.","2374-9628","978-1-6654-8018-5","10.1109/IPCCC55026.2022.9894328","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9894328","Data Mining;Network Security;Anomalies","Telecommunication traffic;Network security;Behavioral sciences;Data mining;Faces","","","","","","25","IEEE","12 Oct 2022","","","IEEE","IEEE Conferences"
"Comparative Analysis of Current Deep Learning Networks for Breast Lesion Segmentation in Ultrasound Images","M. R. Ferreira; H. R. Torres; B. Oliveira; J. Gomes-Fonseca; P. Morais; P. Novais; J. L. Vilaça","Algoritmi Center, School of Engineering, University of Minho, Guimarães, Portugal; ICVS/3B's - PT Government Associate Laboratory, Braga/Guimarães, Portugal; ICVS/3B's - PT Government Associate Laboratory, Braga/Guimarães, Portugal; 2Ai – School of Technology, IPCA, Barcelos, Portugal; 2Ai – School of Technology, IPCA, Barcelos, Portugal; Algoritmi Center, School of Engineering, University of Minho, Guimarães, Portugal; 2Ai – School of Technology, IPCA, Barcelos, Portugal","2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","8 Sep 2022","2022","","","3878","3881","Automatic lesion segmentation in breast ultrasound (BUS) images aids in the diagnosis of breast cancer, the most common type of cancer in women. Accurate lesion segmentation in ultrasound images is a challenging task due to speckle noise, artifacts, shadows, and lesion variability in size and shape. Recently, convolutional neural networks have demonstrated impressive results in medical image segmentation tasks. However, the lack of public benchmarks and a standardized evaluation method hampers the networks' performance comparison. This work presents a benchmark of seven state-of-the-art methods for the automatic breast lesion segmentation task. The methods were evaluated on a multi-center BUS dataset composed of three public datasets. Specifically, the U-Net, Dynamic U-Net, Semantic Segmentation Deep Residual Network with Variational Autoencoder (SegResNetVAE), U-Net Transformers, Residual Feedback Network, Multiscale Dual Attention-Based Network, and Global Guidance Network (GG-Net) architectures were evaluated. The training was performed with a combination of the cross-entropy and Dice loss functions and the overall performance of the networks was assessed using the Dice coefficient, Jaccard index, accuracy, recall, specificity, and precision. Despite all networks having obtained Dice scores superior to 75%, the GG-Net and SegResNetVAE architectures outperform the remaining methods, achieving 82.56% and 81.90%, respectively. Clinical Relevance— The results of this study allowed to prove the potential of deep neural networks to be used in clinical practice for breast lesion segmentation also suggesting the best model choices","2694-0604","978-1-7281-2782-8","10.1109/EMBC48229.2022.9871091","European Regional Development Fund(grant numbers:NORTE-01-0145-FEDER-000045,NORTE-01-0145-FEDER-000059); Fundação para a Ciência e a Tecnologia(grant numbers:UIDB/05549/2020,UIDP/05549/2020,LASI-LA/P/0104/2020); European Union(grant numbers:SFRH/BD/136721/2018,SFRH/BD/136670); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9871091","","Deep learning;Training;Image segmentation;Ultrasonic imaging;Breast;Benchmark testing;Speckle","biomedical ultrasonics;cancer;convolutional neural nets;deep learning (artificial intelligence);entropy;image segmentation;medical image processing","breast ultrasound images;breast cancer;lesion variability;convolutional neural networks;medical image segmentation tasks;public benchmarks;standardized evaluation method;automatic breast lesion segmentation task;multicenter BUS;U-Net transformers;global guidance network;GG-Net;deep neural networks;multiscale dual attention-based network;residual feedback network;semantic segmentation deep residual network;dynamic U-Net","Artifacts;Breast Neoplasms;Deep Learning;Female;Humans;Ultrasonography;Ultrasonography, Mammary","","","22","IEEE","8 Sep 2022","","","IEEE","IEEE Conferences"
"CHALLENGES AND OPPORTUNITIES FOR GENERATIVE METHODS IN THE CYBER DOMAIN","M. Chalé; N. D. Bastian","Department of Operational Sciences, Air Force Institute of Technology, Wright-Patterson AFB, OH, USA; 2101 New South Post Road, United States Military Academy, Army Cyber Institute, West Point, NY, USA","2021 Winter Simulation Conference (WSC)","23 Feb 2022","2021","","","1","12","Large, high quality data sets are essential for training machine learning models to perform their tasks accurately. The lack of such training data has constrained machine learning research in the cyber domain. This work explores how Markov Chain Monte Carlo (MCMC) methods can be used for realistic synthetic data generation and compares it to several existing generative machine learning techniques. The performance of MCMC is compared to generative adversarial network (GAN) and variational autoencoder (VAE) methods to estimate the joint probability distribution of network intrusion detection system data. A statistical analysis of the synthetically generated cyber data determines the goodness of fit, aiming to improve cyber threat detection. The experimental results suggest that the data generated from MCMC fits the true distribution approximately as well as the data generated from GAN and VAE; however, the MCMC requires a significantly longer training period and is unproven for higher dimensional cyber data.","1558-4305","978-1-6654-3311-2","10.1109/WSC52266.2021.9715504","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9715504","","Training;Monte Carlo methods;Network intrusion detection;Training data;Machine learning;Generative adversarial networks;Data models","learning (artificial intelligence);Markov processes;Monte Carlo methods;security of data;statistical analysis","MCMC;joint probability distribution;network intrusion detection system data;cyber threat detection;generative methods;machine learning;Markov Chain Monte Carlo methods;data generation;statistical analysis","","","","43","USGov","23 Feb 2022","","","IEEE","IEEE Conferences"
"Learning the Latent Space of Robot Dynamics for Cutting Interaction Inference","S. Rezaei-Shoshtari; D. Meger; I. Sharf","Mila Quebec AI Institute, Montreal, Canada; Mila Quebec AI Institute, Montreal, Canada; Department of Mechanical Engineering, McGill University, Montreal, Canada","2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","10 Feb 2021","2020","","","5627","5632","Utilization of latent space to capture a lower-dimensional representation of a complex dynamics model is explored in this work. The targeted application is of a robotic manipulator executing a complex environment interaction task, in particular, cutting a wooden object. We train two flavours of Variational Autoencoders-standard and Vector-Quantised-to learn the latent space which is then used to infer certain properties of the cutting operation, such as whether the robot is cutting or not, as well as, material and geometry of the object being cut. The two VAE models are evaluated with reconstruction, prediction and a combined reconstruction/prediction decoders. The results demonstrate the expressiveness of the latent space for robotic interaction inference and the competitive prediction performance against recurrent neural networks.","2153-0866","978-1-7281-6212-6","10.1109/IROS45743.2020.9341446","NCR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9341446","","Recurrent neural networks;Predictive models;Robot sensing systems;Task analysis;Robots;Manipulator dynamics;Predictive control","learning (artificial intelligence);manipulators;neural nets;recurrent neural nets;robot dynamics","latent space;robot dynamics;cutting interaction inference;lower-dimensional representation;complex dynamics model;robotic manipulator;complex environment interaction task;cutting operation;robotic interaction inference","","","","24","","10 Feb 2021","","","IEEE","IEEE Conferences"
"Bidirectional Generation of Object Images and Positions using Deep Generative Models for Service Robotics Applications","K. Hayashi; W. Zheng; L. E. Hafi; Y. Hagiwara; T. Taniguchi","Ritsumeikan University; 1-1-1 Noji-Higashi, Kusatsu, Shiga, Japan; Ritsumeikan University; 1-1-1 Noji-Higashi, Kusatsu, Shiga, Japan; Ritsumeikan University; 1-1-1 Noji-Higashi, Kusatsu, Shiga, Japan; Ritsumeikan University; 1-1-1 Noji-Higashi, Kusatsu, Shiga, Japan; Ritsumeikan University; 1-1-1 Noji-Higashi, Kusatsu, Shiga, Japan","2021 IEEE/SICE International Symposium on System Integration (SII)","24 Mar 2021","2021","","","325","329","The introduction of systems and robots for automated services is important for reducing running costs and improving operational efficiency in the retail industry. To this aim, we develop a system that enables robot agents to display products in stores. The main problem in automating product display using common supervised methods with robot agents is the huge amount of data required to recognize product categories and arrangements in a variety of different store layouts. To solve this problem, we propose a crossmodal inference system based on joint multimodal variational autoencoder (JMVAE) that learns the relationship between object image information and location information observed on site by robot agents. In our experiments, we created a simulation environment replicating a convenience store that allows a robot agent to observe an object image and its 3D coordinate information, and confirmed whether JMVAE can learn and generate a shared representation of an object image and 3D coordinates in a bidirectional manner.","2474-2325","978-1-7281-7658-1","10.1109/IEEECONF49454.2021.9382768","Ministry of Education; Japan Science and Technology Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9382768","","Training;Solid modeling;Three-dimensional displays;Uncertainty;Service robots;Robot kinematics;Working environment noise","learning (artificial intelligence);mobile robots;retail data processing;retailing;service robots","bidirectional generation;deep generative models;service robotics applications;automated services;running costs;improving operational efficiency;robot agent;automating product display;product categories;different store layouts;crossmodal inference system;object image information;location information","","","","13","IEEE","24 Mar 2021","","","IEEE","IEEE Conferences"
"Learning to Navigate Intersections with Unsupervised Driver Trait Inference","S. Liu; P. Chang; H. Chen; N. Chakraborty; K. Driggs-Campbell","Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign","2022 International Conference on Robotics and Automation (ICRA)","12 Jul 2022","2022","","","3576","3582","Navigation through uncontrolled intersections is one of the key challenges for autonomous vehicles. Identifying the subtle differences in hidden traits of other drivers can bring significant benefits when navigating in such environments. We propose an unsupervised method for inferring driver traits such as driving styles from observed vehicle trajectories. We use a variational autoencoder with recurrent neural networks to learn a latent representation of traits without any ground truth trait labels. Then, we use this trait representation to learn a policy for an autonomous vehicle to navigate through a T-intersection with deep reinforcement learning. Our pipeline enables the autonomous vehicle to adjust its actions when dealing with drivers of different traits to ensure safety and efficiency. Our method demonstrates promising performance and outperforms state-of-the-art baselines in the T-intersection scenario.","","978-1-7281-9681-7","10.1109/ICRA46639.2022.9811635","National Science Foundation(grant numbers:2143435); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9811635","","Recurrent neural networks;Automation;Navigation;Pipelines;Reinforcement learning;Trajectory;Safety","","","","","","38","IEEE","12 Jul 2022","","","IEEE","IEEE Conferences"
"Effective Pan-Sharpening by Multiscale Invertible Neural Network and Heterogeneous Task Distilling","M. Zhou; J. Huang; X. Fu; F. Zhao; D. Hong","Institute of Intelligent Machines and the Hefei Institutes of Physical Science, Chinese Academy of Sciences, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; Key Laboratory of Digital Earth Science, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","20 Sep 2022","2022","60","","1","14","As recognized, the ground-truth multispectral (MS) images possess the complementary information (e.g., high-frequency components) of low-resolution (LR) MS images, which can be considered as privileged information to alleviate the spectral distortion and insufficient spatial texture enhancement. Since existing supervised pan-sharpening methods only utilize the ground-truth MS image to supervise the network training, its potential value has not been fully explored. To accomplish this, we propose a heterogeneous knowledge-distilling pan-sharpening framework that distills pan-sharpening by imitating the ground-truth reconstruction task in both the feature space and network output. In our work, the teacher network performs as a variational autoencoder to extract effective features of the ground-truth MS. The student network, acting as pan-sharpening, is trained by the assistance of the teacher network with the process-oriented feature imitation learning. Moreover, we design a customized information-lossless multiscale invertible neural module to effectively fuse LRMS and panchromatic (PAN) images, producing expected pan-sharpened results. To reduce the artifacts generated by the knowledge distillation process, a knowledge-driven refinement subnetwork is further devised according to the pan-sharpening imaging model. Extensive experimental results on different satellite datasets validate that the proposed network outperforms the state-of-the-art methods both visually and quantitatively. The source code will be released at https://github.com/manman1995/pansharpening.","1558-0644","","10.1109/TGRS.2022.3199210","National Natural Science Foundation of China (NSFC)(grant numbers:61901433); USTC Research Funds of the Double First-Class Initiative(grant numbers:YD2100002003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9858176","Heterogeneous knowledge-distilling;invertible neural network;pan-sharpening;transformer","Task analysis;Feature extraction;Image resolution;Spatial resolution;Knowledge engineering;Neural networks;Image reconstruction","","","","","","77","IEEE","17 Aug 2022","","","IEEE","IEEE Journals"
"Spatiotemporal Prediction Based Intelligent Task Allocation for Secure Spatial Crowdsourcing in Industrial IoT","M. Peng; J. Hu; H. Lin; X. Wang; P. Liu; K. Dev; S. A. Khowaja; N. M. F. Qureshi","College of Computer and Cyber Security, Fujian Normal University, Engineering Research Center of Cyber Security and Education Informatization, Fujian Province University, Fuzhou, Fujian, China; University of Exeter, Exeter, U.K.; College of Computer and Cyber Security, Fujian Normal University, Engineering Research Center of Cyber Security and Education Informatization, Fujian Province University, Fuzhou, Fujian, China; College of Computer and Cyber Security, Fujian Normal University, Engineering Research Center of Cyber Security and Education Informatization, Fujian Province University, Fuzhou, Fujian, China; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Department of institute of intelligent systems, University of Johannesburg, South Africa; Department of Telecommunication Engineering, Faculty of Engineering &amp; Technology, University of Sindh, Pakistan; Department of Computer Education, Sungkyunkwan University, Seoul, Korea","IEEE Transactions on Network Science and Engineering","","2022","PP","99","1","12","With the emergence of spatial crowdsourcing technology, an efficient task allocation is the key to ensure the sustainable development of spatial crowdsourcing. However, previous spatial crowdsourcing task allocation technologies ignore the temporal and spatial continuity between historical task data, thus reducing the efficiency of crowdsourcing task allocation. In addition, spatial crowdsourcing also suffers from the privacy leakage problem. To solve these problems, we propose a Spatiotemporal Prediction based Spatial Crowdsourcing strategy, named SPSC, using both blockchain and artificial intelligence. Specifically, considering the temporal and spatial continuity of crowdsourced task data, SPSC combines both gated recurrent unit and variational autoencoder for crowdsourcing task prediction. In addition, different Laplacian noises are added to crowdsourced task data so as to protect the privacy of crowdsourced workers during the task prediction. Moreover, by classifying crowdsourcing tasks and grouping crowdsourcing workers, SPSC reduces the risk of crowdsourcing workers colluding to steal the privacy data of crowdsourcing tasks using the blockchain technology. The experimental results show that SPSC can improve the privacy protection of spatial crowdsourcing, specifically, the more the number of categories, the higher the degree of privacy protection, and under the premise of predicting value, excellent system performance can be achieved.","2327-4697","","10.1109/TNSE.2022.3198675","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9857623","Spatial Crowdsourcing;Task Allocation;Privacy Protection;Blockchain;Machine Learning","Task analysis;Crowdsourcing;Resource management;Privacy;Ions;Blockchains;Spatiotemporal phenomena","","","","","","","IEEE","16 Aug 2022","","","IEEE","IEEE Early Access Articles"
"Temporal Clustering with External Memory Network for Disease Progression Modeling","Z. Zhang; C. Yin; P. Zhang","Department of Computer Science and Engineering, The Ohio State University, Columbus, USA; Department of Biomedical Informatics, The Ohio State University, Columbus, USA; Department of Biomedical Informatics, The Ohio State University, Columbus, USA","2021 IEEE International Conference on Data Mining (ICDM)","24 Jan 2022","2021","","","956","965","Disease progression modeling (DPM) involves using mathematical frameworks to quantitatively measure the severity of how certain disease progresses. DPM is useful in many ways such as predicting health state, categorizing disease stages, and assessing patients’ disease trajectory, etc. Recently, with the wider availability of electronic health records (EHR) and the broad application of data-driven machine learning methods, DPM has attracted much attention yet remains two major challenges: (i) Due to the existence of irregularity, heterogeneity, and long-term dependency in EHRs, most existing DPM methods might not be able to provide comprehensive patient representations. (ii) Lots of records in EHRs might be irrelevant to the target disease. Most existing models learn to automatically focus on the relevant information instead of explicitly capture the target-relevant events, which might make the learned model suboptimal. To address these two issues, we propose Temporal Clustering with External Memory Network (TC-EMNet) for DPM that groups patients with similar trajectories to form disease clusters/stages. TC-EMNet uses a variational autoencoder (VAE) to capture internal complexity from the input data and utilizes an external memory work to capture long-term distance information, both of which are helpful for producing comprehensive patient health states. Last but not least, the k-means algorithm is adopted to cluster the extracted comprehensive patient representation to capture disease progression. Experiments on two real-world datasets show that our model demonstrates competitive clustering performance against state-of-the-art methods and is able to identify clinically meaningful clusters. The visualization of the patient representations shows that the proposed model can generate better patient health states than the baselines.","2374-8486","978-1-6654-2398-4","10.1109/ICDM51629.2021.00107","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679153","disease progression modeling;deep learning;temporal clustering","Computational modeling;Medical services;Machine learning;Network architecture;Data models;Mathematical models;Trajectory","diseases;electronic health records;health care;learning (artificial intelligence);medical diagnostic computing;pattern clustering","data-driven machine learning methods;long-term dependency;EHR;DPM methods;comprehensive patient representations;target disease;learned model suboptimal;TC-EMNet;external memory work;long-term distance information;comprehensive patient health states;extracted comprehensive patient representation;competitive clustering performance;clinically meaningful clusters;disease progression modeling;health state;disease stages;electronic health records;temporal clustering with external memory network","","","","40","IEEE","24 Jan 2022","","","IEEE","IEEE Conferences"
"Weakly-Supervised Learning for Multimodal Human Activity Recognition in Human-Robot Collaboration Scenarios","C. Pohlt; T. Schlegl; S. Wachsmuth","Regensburg Robotics Research Unit, OTH Regensburg, Regensburg, Germany; Regensburg Robotics Research Unit, OTH Regensburg, Regensburg, Germany; CITEC, Bielefeld University, Bielefeld, Germany","2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","10 Feb 2021","2020","","","8381","8386","The ability to synchronize expectations among human-robot teams and understand discrepancies between expectations and reality is essential for human-robot collaboration scenarios. To ensure this, human activities and intentions must be interpreted quickly and reliably by the robot using various modalities. In this paper we propose a multimodal recognition system designed to detect physical interactions as well as nonverbal gestures. Existing approaches feature high post-transfer recognition rates which, however, can only be achieved based on well-prepared and large datasets. Unfortunately, the acquisition and preparation of domain-specific samples especially in industrial context is time consuming and expensive. To reduce this effort we introduce a weakly-supervised classification approach. Therefore, we learn a latent representation of the human activities with a variational autoencoder network. Additional modalities and unlabeled samples are incorporated by a scalable product-of-expert sampling approach. The applicability in industrial context is evaluated by two domain-specific collaborative robot datasets. Our results demonstrate, that we can keep the number of labeled samples constant while increasing the network performance by providing additional unprocessed information.","2153-0866","978-1-7281-6212-6","10.1109/IROS45743.2020.9340788","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9340788","","Service robots;Collaboration;Activity recognition;Synchronization;Reliability;Intelligent robots","human-robot interaction;image classification;learning (artificial intelligence);pattern classification","high post-transfer recognition rates;industrial context;weakly-supervised classification approach;human activities;product-of-expert sampling approach;domain-specific collaborative robot datasets;multimodal human activity recognition;human-robot collaboration scenarios;human-robot teams;multimodal recognition system","","","","18","","10 Feb 2021","","","IEEE","IEEE Conferences"
"Promoting Quality and Diversity in Population-based Reinforcement Learning via Hierarchical Trajectory Space Exploration","J. Miao; T. Zhou; K. Shao; M. Zhou; W. Zhang; J. Hao; Y. Yu; J. Wang","Work done as an intern at Huawei Noah's Ark Lab; Work done as an intern at Huawei Noah's Ark Lab; Noah's Ark Lab, Huawei Technologies; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Noah's Ark Lab, Huawei Technologies; Shanghai Jiao Tong University; University College London","2022 International Conference on Robotics and Automation (ICRA)","12 Jul 2022","2022","","","7544","7550","Quality Diversity (QD) algorithms in population-based reinforcement learning aim to optimize agents' returns and diversity among the population simultaneously. It is conducive to solving exploration problems in reinforcement learning and potentially getting multiple good and diverse strategies. However, previous methods typically define behavioral embedding in action space or outcome space, which neglect trajectory characteristics during the execution process. In this paper, we introduce a trajectory embedding model trained by Variational Autoencoder with similarity constraint to characterize trajectory features. Based on that, we propose a hierarchical trajectory-space exploration (HTSE) framework using Determinantal Point Processes (DPP) to generate high-quality and diverse solutions in the selection and mutation process. The experimental results show that our HTSE method effectively completes several simulated tasks, outperforming other Quality-Diversity Reinforcement Learning algorithms.","","978-1-7281-9681-7","10.1109/ICRA46639.2022.9811888","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9811888","","Automation;Sociology;Reinforcement learning;Trajectory;Space exploration;Behavioral sciences;Task analysis","","","","","","32","IEEE","12 Jul 2022","","","IEEE","IEEE Conferences"
"Learning to Detect 3D Symmetry From Single-View RGB-D Images With Weak Supervision","Y. Shi; X. Xu; J. Xi; X. Hu; D. Hu; K. Xu","College of Intelligence Science and Technology, National University of Defense Technology, China; College of Intelligence Science and Technology, National University of Defense Technology, China; College of Computer Science, National University of Defense Technology, China; College of Intelligence Science and Technology, National University of Defense Technology, China; College of Intelligence Science and Technology, National University of Defense Technology, China; College of Computer Science, National University of Defense Technology, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2022","PP","99","1","15","3D symmetry detection is a fundamental problem in computer vision and graphics. Most prior works detect symmetry when the object model is fully known, few studies symmetry detection on objects with partial observation, such as single RGB-D images. Recent work addresses the problem of detecting symmetries from incomplete data with a deep neural network by leveraging the dense and accurate symmetry annotations. However, due to the tedious labeling process, full symmetry annotations are not always practically available. In this work, we present a 3D symmetry detection approach to detect symmetry from single-view RGB-D images without using symmetry supervision. The key idea is to train the network in a weakly-supervised learning manner to complete the shape based on the predicted symmetry such that the completed shape be similar to existing plausible shapes. To achieve this, we first propose a discriminative variational autoencoder to learn the shape prior in order to determine whether a 3D shape is plausible or not. Based on the learned shape prior, a symmetry detection network is present to predict symmetries that produce shapes with high shape plausibility when completed based on those symmetries. Moreover, to facilitate end-to-end network training and multiple symmetry detection, we introduce a new symmetry parametrization for the learning-based symmetry estimation of both reflectional and rotational symmetry. The proposed approach, coupled symmetry detection with shape completion, essentially learns the symmetry-aware shape prior, facilitating more accurate and robust symmetry detection. Experiments demonstrate that the proposed method is capable of detecting reflectional and rotational symmetries accurately, and shows good generality in challenging scenarios, such as objects with heavy occlusion and scanning noise. Moreover, it achieves state-of-the-art performance, improving the F1-score over the existing supervised learning method by 2%-11% on the ShapeNet and ScanNet datasets.","1939-3539","","10.1109/TPAMI.2022.3186876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9808406","Deep neural networks;RGB-D images;symmetry detection;weakly-supervised learning","Shape;Three-dimensional displays;Annotations;Training;Solid modeling;Transformers;Neural networks","","","","","","","CCBY","28 Jun 2022","","","IEEE","IEEE Early Access Articles"
"Multimodal Fusion Based Attentive Networks for Sequential Music Recommendation","K. Vaswani; Y. Agrawal; V. Alluri","Iiit Hyderabad, Hyderabad, India; Iiit Hyderabad, Hyderabad, India; Iiit Hyderabad, Hyderabad, India","2021 IEEE Seventh International Conference on Multimedia Big Data (BigMM)","17 Dec 2021","2021","","","25","32","Music has the power to evoke intense emotional experiences and regulate the mood of an individual. With the advent of online streaming services, research in music recommendation services has seen tremendous progress. Modern methods leveraging the listening histories of users for session-based song recommendations have overlooked the significance of features extracted from lyrics and acoustic content. We address the task of song prediction through multiple modalities, including tags, lyrics, and acoustic content. In this paper, we propose a novel deep learning approach by refining Attentive Neural Networks using representations derived via a Transformer model for lyrics and Variational Autoencoder for acoustic features. Our model achieves significant improvement in performance over existing state-of-the-art models using lyrical and acoustic features alone. Furthermore, we conduct a study to investigate the impact of users’ psychological health on our model’s performance.","","978-1-6654-3414-0","10.1109/BigMM52142.2021.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9643207","Music Recommendations;Multimodal;Attention Networks;User Evaluation","Sentiment analysis;Refining;Neural networks;Music;Feature extraction;Transformers;Acoustics","emotion recognition;feature extraction;learning (artificial intelligence);music;neural nets;psychology;recommender systems","multiple modalities;lyrics;acoustic content;deep learning approach;Attentive Neural Networks;Transformer model;acoustic features;existing state-of-the-art models;multimodal fusion;attentive networks;sequential music recommendation;intense emotional experiences;online streaming services;music recommendation services;session-based song recommendations;song prediction","","","","37","IEEE","17 Dec 2021","","","IEEE","IEEE Conferences"
"MetaCAR: Cross-Domain Meta-Augmentation for Content-Aware Recommendation","H. Xu; C. Li; Y. Zhang; L. Duan; I. W. Tsang; J. Shao","Sichuan Artificial Intelligence Research Institute, Yibin, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Intelligent Terminal Key Laboratory of Sichuan Province, Yibin, China; Sichuan Provincial People's Hospital, University of Electronic Science and Technology of China, Chengdu, China; Australian Artificial Intelligence Institute, University of Technology Sydney, NSW, Australia; Sichuan Artificial Intelligence Research Institute, Yibin, China","IEEE Transactions on Knowledge and Data Engineering","","2022","PP","99","1","14","Cold-start has become critical for recommendations, especially for sparse user-item interactions. Recent approaches based on meta-learning succeed in alleviating the issue, owing to the fact that these methods have strong generalization, so they can fast adapt to new tasks under cold-start settings. However, these meta-learning-based recommendation models learned with single and spase ratings are easily falling into the meta-overfitting, since the one and only rating $r_{ui}$ to a specific item $i$ cannot reflect a user's diverse interests under various circumstances(e.g., time, mood, age, etc), i.e. if $r_{ui}$ equals to 1 in the historical dataset, but $r_{ui}$ could be 0 in some circumstance. In meta-learning, tasks with these single ratings are called Non-Mutually-Exclusive(Non-ME) tasks, and tasks with diverse ratings are called Mutually-Exclusive(ME) tasks. Fortunately, a meta-augmentation technique is proposed to relief the meta-overfitting for meta-learning methods by transferring Non-ME tasks into ME tasks by adding noises to labels without changing inputs. Motivated by the meta-augmentation method, in this paper, we propose a cross-domain meta-augmentation technique for content-aware recommendation systems (MetaCAR) to construct ME tasks in the recommendation scenario. Our proposed method consists of two stages: meta-augmentation and meta-learning. In the meta-augmentation stage, we first conduct domain adaptation by a dual conditional variational autoencoder (CVAE) with a multi-view information bottleneck constraint, and then apply the learned CVAE to generate ratings for users in the target domain. In the meta-learning stage, we introduce both the true and generated ratings to construct ME tasks that enables the meta-learning recommendations to avoid meta-overfitting. Experiments evaluated in real-world datasets show the significant superiority of MetaCAR for coping with the cold-start user issue over competing baselines including cross-domain, content-aware, and meta-learning-based recommendations.","1558-2191","","10.1109/TKDE.2022.3209005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9900427","Recommendation systems;meta-augmentation;cold-start;content-aware","Task analysis;Recommender systems;Motion pictures;Adaptation models;Training;Data models;Data mining","","","","","","","IEEE","23 Sep 2022","","","IEEE","IEEE Early Access Articles"
"A Universal Data Augmentation Approach for Fault Localization","H. Xie; Y. Lei; M. Yan; Y. Yu; X. Xia; X. Mao","School of Big Data & Software Engineering, Chongqing University, Chongqing, China; School of Big Data & Software Engineering, Chongqing University, Chongqing, China; School of Big Data & Software Engineering, Chongqing University, Chongqing, China; National University of Defense Technology, Changsha, China; Software Engineering Application Technology Lab, Huawei, China; National University of Defense Technology, Changsha, China","2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)","20 Jun 2022","2022","","","48","60","Data is the fuel to models, and it is still applicable in fault localization (FL). Many existing elaborate FL techniques take the code coverage matrix and failure vector as inputs, expecting the techniques could find the correlation between program entities and failures. However, the input data is high-dimensional and extremely imbalanced since the real-world programs are large in size and the number of failing test cases is much less than that of passing test cases, which are posing severe threats to the effectiveness of FL techniques. To overcome the limitations, we propose Aeneas, a universal data augmentation approach that generAtes synthesized failing test cases from reduced feature sace for more precise fault localization. Specifically, to improve the effectiveness of data augmentation, Aeneas applies a revised principal component analysis (PCA) first to generate reduced feature space for more concise representation of the original coverage matrix, which could also gain efficiency for data synthesis. Then, Aeneas handles the imbalanced data issue through generating synthesized failing test cases from the reduced feature space through conditional variational autoencoder (CVAE). To evaluate the effectiveness of Aeneas, we conduct large-scale experiments on 458 versions of 10 programs (from ManyBugs, SIR, and Defects4J) by six state-of-the-art FL techniques. The experimental results clearly show that Aeneas is statistically more effective than baselines, e.g., our approach can improve the six original methods by 89% on average under the Top-1 accuracy.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510136","National Key Research and Development Project of China(grant numbers:2020YFB1711900); National Defense Basic Scientific Research Project(grant numbers:WDZC20 205500308); Fundamental Research Funds for the Central Universities(grant numbers:2021CDJQY-018); National Natural Science Foundation of China(grant numbers:62002034); Natural Science Foundation of Chongqing(grant numbers:cstc2021jcyj-msxmX0538); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793942","Fault Localization;Imbalanced Data;Data Augmentation","Location awareness;Correlation;Codes;Pipelines;Feature extraction;Data models;Fuels","fault diagnosis;feature extraction;learning (artificial intelligence);matrix algebra;pattern classification;principal component analysis;program testing","universal data augmentation approach;existing elaborate FL techniques;code coverage matrix;failure vector;program entities;real-world programs;Aeneas;reduced feature sace;precise fault localization;reduced feature space;original coverage matrix;data synthesis;imbalanced data issue;state-of-the-art FL techniques","","","","73","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Vector Quantized Diffusion Model for Text-to-Image Synthesis","S. Gu; D. Chen; J. Bao; F. Wen; B. Zhang; D. Chen; L. Yuan; B. Guo",University of Science and Technology of China; Microsoft Research; Microsoft Research; Microsoft Research; Microsoft Research; Microsoft Cloud+AI; Microsoft Cloud+AI; Microsoft Research,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","10686","10696","We present the vector quantized diffusion (VQ-Diffusion) model for text-to-image generation. This method is based on a vector quantized variational autoencoder (VQ-VAE) whose latent space is modeled by a conditional variant of the recently developed Denoising Diffusion Probabilistic Model (DDPM). We find that this latent-space method is well-suited for text-to-image generation tasks because it not only eliminates the unidirectional bias with existing methods but also allows us to incorporate a mask-and-replace diffusion strategy to avoid the accumulation of errors, which is a serious problem with existing methods. Our experiments show that the VQ-Diffusion produces significantly better text-to-image generation results when compared with conventional autoregressive (AR) models with similar numbers of parameters. Compared with previous GAN-based text-to-image methods, our VQ-Diffusion can handle more complex scenes and improve the synthesized image quality by a large margin. Finally, we show that the image generation computation in our method can be made highly efficient by reparameterization. With traditional AR methods, the text-to-image generation time increases linearly with the output image resolution and hence is quite time consuming even for normal size images. The VQ-Diffusion allows us to achieve a better trade-off between quality and speed. Our experiments indicate that the VQ-Diffusion model with the reparameterization is fifteen times faster than traditional AR methods while achieving a better image quality. The code and models are available at https://github.com/cientgu/VQ-Diffusion.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879180","Image and video synthesis and generation; Vision + language","Image quality;Computer vision;Image resolution;Image synthesis;Computational modeling;Noise reduction;Computer architecture","approximation theory;gallium compounds;Gaussian processes;image denoising;image representation;image resolution;image sampling;image texture;medical image processing;rendering (computer graphics);vector quantisation","vector quantized Diffusion Model;text-to-image synthesis;VQ-VAE;recently developed Denoising Diffusion Probabilistic Model;latent-space method;text-to-image generation tasks;-replace diffusion strategy;text-to-image generation results;conventional autoregressive models;previous GAN-based text-to-image methods;synthesized image quality;image generation computation;traditional AR methods;text-to-image generation time;output image resolution;normal size images;VQ-Diffusion model","","","","73","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Deep Learning Unsupervised Text-Based Detection of Anomalies in U.S. Chemical Safety and Hazard Investigation Board Reports","N. Rybak; M. Hassall","School of Chemical Engineering, The University of Queensland, Brisbane, Australia; School of Chemical Engineering, The University of Queensland, Brisbane, Australia","2021 International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME)","10 Nov 2021","2021","","","1","7","Industrial accident-related records are continually collected and stored by public and private organizations creating big data repositories. Along with others, narrative-based documents of various industrial accidents are becoming continuously more valuable for computer-assisted analysis of unwanted events owing to the advances of machine learning in recent years. Nevertheless, vital narrative data comprised in text documents, for example, detailing unwanted event descriptions and descriptions of more subtle circumstances along with novel computer-based detection methods still require scientific exploration. Therefore, this study aims to improve data processing techniques to provide unsupervised anomaly detection that can be utilized by safety experts to efficiently evaluate accident risk factors. Variational autoencoder, a deep learning-based method, is introduced to obtain the CSB accident reports anomaly factor ranking. In the next step, an analysis of key terms is performed to review the underlying causes of selected accidents. As a result, vital narrative-based information buried in a myriad of accident report documents is analyzed, providing quantitative insights on risk factors. The anomalous events can be investigated further by safety experts to fully understand and explore the unique causes for their occurrence. The anomaly detection solution presented in this paper is an adaptive method that can be extended to other use cases to enable the analysis of complex narrative data in predictive and prescriptive implementation scenarios.","","978-1-6654-1262-9","10.1109/ICECCME52200.2021.9590834","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9590834","anomaly detection;deep learning;machine learning;natural language processing","Vocabulary;Mechatronics;Organizations;Data models;Hazards;Industrial accidents;Anomaly detection","accident prevention;accidents;Big Data;data analysis;hazards;industrial accidents;information retrieval;learning (artificial intelligence);occupational safety;risk analysis;security of data;text analysis;unsupervised learning","u.s. chemical safety;hazard investigation board reports;industrial accident-related records;public organizations;private organizations;big data repositories;narrative-based documents;industrial accidents;computer-assisted analysis;unwanted events;machine learning;vital narrative data;text documents;unwanted event descriptions;subtle circumstances;computer-based detection methods;scientific exploration;unsupervised anomaly detection;safety experts;accident risk factors;deep learning-based method;CSB accident;anomaly factor;selected accidents;vital narrative-based information;accident report documents;anomalous events;anomaly detection solution;adaptive method;complex narrative data","","","","29","IEEE","10 Nov 2021","","","IEEE","IEEE Conferences"
"MotionAug: Augmentation with Physical Correction for Human Motion Prediction","T. Maeda; N. Ukita","Toyota Technological Institute, Japan; Toyota Technological Institute, Japan","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","6417","6426","This paper presents a motion data augmentation scheme incorporating motion synthesis encouraging diversity and motion correction imposing physical plausibility. This motion synthesis consists of our modified Variational AutoEncoder (VAE) and Inverse Kinematics (IK). In this VAE, our proposed sampling-near-samples method generates various valid motions even with insufficient training motion data. Our IK-based motion synthesis method allows us to generate a variety of motions semi-automatically. Since these two schemes generate unrealistic artifacts in the synthesized motions, our motion correction rectifies them. This motion correction scheme consists of imitation learning with physics simulation and subsequent motion debiasing. For this imitation learning, we propose the PD-residual force that significantly accelerates the training process. Furthermore, our motion debiasing successfully offsets the motion bias induced by imitation learning to maximize the effect of augmentation. As a result, our method outperforms previous noise-based motion augmentation methods by a large margin on both Recurrent Neural Network-based and Graph Convolutional Network-based human motion prediction models. The code is available at https://github.com/meaten/MotionAug.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.00632","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9878411","Motion and tracking","Training;Convolutional codes;Recurrent neural networks;Tracking;Force;Graphics processing units;Kinematics","computer animation;image motion analysis;learning (artificial intelligence);medical image processing;motion estimation;neural nets;recurrent neural nets;sampling methods","physical correction;motion data augmentation scheme incorporating motion synthesis;physical plausibility;VAE;sampling-near-samples method;valid motions;insufficient training motion data;IK-based motion synthesis method;motions semiautomatically;synthesized motions;motion correction scheme;imitation learning;subsequent motion debiasing;motion bias;previous noise-based motion augmentation methods;Graph Convolutional Network-based human motion prediction models","","","","51","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"CVAE-AN: Atypical Attack Flow Detection Using Incremental Adversarial Learning","U. Sabeel; S. S. Heydari; K. Elgazzar; K. El-Khatib","University of Ontario Institute of Technology, Oshawa, Canada; University of Ontario Institute of Technology, Oshawa, Canada; University of Ontario Institute of Technology, Oshawa, Canada; University of Ontario Institute of Technology, Oshawa, Canada","2021 IEEE Global Communications Conference (GLOBECOM)","2 Feb 2022","2021","","","1","6","Network Intrusion Detection Systems (NIDS) are powerful tools for identifying and deterring cybersecurity attacks nowadays. However, while these modern IDS can detect typical attacks, recent studies show their poor performances in identifying unknown or dynamically changing atypical attacks. Another issue with the training aspect of such systems is the problem of class imbalance which impedes their performance, especially for minority attack classes. This renders IDS systems vulnerable to both adversarial as well as non-AI synthesized atypical attacks when deployed in a real network. To reduce misclassification (especially for minority classes) and detect atypical attack flows, we propose a novel adversarial incremental learning approach based on a hybrid model consisting of a Conditional Variational Autoencoder (CVAE) and a Generative Adversarial Network (GAN) namely, CVAE-Adversarial Network (CVAE-AN). The binary IDS has been trained using the CICIDS2017 dataset and evaluated using multiple atypical attacks. Simulation results demonstrate that the proposed technique significantly improves the performance of the IDS against different atypical attacks and outperforms the state-of-the-art detection models as well as class balancing methods.","","978-1-7281-8104-2","10.1109/GLOBECOM46510.2021.9685699","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9685699","Artificial Intelligence (AI);Atypical Attacks;Class Imbalance;Feature Profile;Intrusion Detection System (IDS)","Training;Simulation;Conferences;Network intrusion detection;Generative adversarial networks;Hybrid power systems;Adversarial machine learning","computer network security;learning (artificial intelligence)","class imbalance;minority attack classes;IDS systems;nonAI synthesized atypical attacks;minority classes;Generative Adversarial Network;CVAE-Adversarial Network;binary IDS;class balancing methods;CVAE-AN;atypical attack flow Detection;Network Intrusion Detection Systems;cybersecurity attacks;IDS;incremental adversarial learning","","","","22","IEEE","2 Feb 2022","","","IEEE","IEEE Conferences"
"Interactive Trajectory Prediction Using a Driving Risk Map-Integrated Deep Learning Method for Surrounding Vehicles on Highways","X. Liu; Y. Wang; K. Jiang; Z. Zhou; K. Nam; C. Yin","School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Vehicle and Mobility, Tsinghua University, Beijing, China; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Mechanical Engineering, Yeungnam University, Gyeongsan, South Korea; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE Transactions on Intelligent Transportation Systems","12 Oct 2022","2022","23","10","19076","19087","Accurate trajectory prediction of surrounding vehicles is vital for automated vehicles to achieve high-level driving safety in complex situations. However, most state-of-the-art approaches for multi-vehicle trajectory prediction ignore vehicle motion uncertainty caused by different driving styles. Moreover, the interrelationship between the vehicle and the environment is seldom considered. To address the above problems, this paper proposes a driving risk map-integrated deep learning (DRM-DL) method for interactive trajectory prediction of surrounding vehicles, which comprehensively considers the motion uncertainty, trajectory intention uncertainty and interactions among vehicles, lane lines and road boundaries. Specifically, we adopt a conditional variational autoencoder (CVAE) to generate the candidate trajectories, in which the motion uncertainty is considered using a conditional Gaussian distribution. Furthermore, a driving risk map is constructed to realize a unified and interpretable representation of vehicle-vehicle and vehicle-environment interactions. The probability of each candidate trajectory is assigned using a trajectory probability model and a random selection is adopted to select a guided trajectory, which simulates the driver’s trajectory intention uncertainty. Finally, a relearning module is designed to obtain the precise trajectory prediction for surrounding vehicles. The proposed method is evaluated on the HighD dataset, and the results demonstrate a more accurate and reliable trajectory prediction for surrounding vehicles compared with state-of-the-art methods.","1558-0016","","10.1109/TITS.2022.3160630","National Natural Science Foundation of China(grant numbers:52072243); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745461","Automated vehicles;trajectory prediction;driving risk map;deep learning","Trajectory;Uncertainty;Roads;Predictive models;Deep learning;Vehicles;Safety","","","","","","35","IEEE","30 Mar 2022","","","IEEE","IEEE Journals"
"Point-BERT: Pre-training 3D Point Cloud Transformers with Masked Point Modeling","X. Yu; L. Tang; Y. Rao; T. Huang; J. Zhou; J. Lu",Tsinghua University; BAAI; Tsinghua University; Peking University; Tsinghua University; BAAI,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","19291","19300","We present Point-BERT, a new paradigm for learning Transformers to generalize the concept of BERT [8] to 3D point cloud. Inspired by BERT, we devise a Masked Point Modeling (MPM) task to pre-train point cloud Transformers. Specifically, we first divide a point cloud into several local point patches, and a point cloud Tokenizer with a discrete Variational AutoEncoder (dVAE) is designed to generate discrete point tokens containing meaningful local information. Then, we randomly mask out some patches of input point clouds and feed them into the backbone Transformers. The pre-training objective is to recover the original point tokens at the masked locations under the supervision of point tokens obtained by the Tokenizer. Extensive experiments demonstrate that the proposed BERT-style pre-training strategy significantly improves the performance of standard point cloud Transformers. Equipped with our pre-training strategy, we show that a pure Transformer architecture attains 93.8% accuracy on ModelNet40 and 83.1% accuracy on the hardest setting of ScanObjectNN, surpassing carefully designed point cloud models with much fewer hand-made designs. We also demonstrate that the representations learned by Point-BERT transfer well to new tasks and domains, where our models largely advance the state-of-the-art of few-shot point cloud classification task. The code and pre-trained models are available at https://github.com/lulutang0608/Point-BERT.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01871","National Key Research and Development Program of China(grant numbers:2017YFA0700802); National Natural Science Foundation of China(grant numbers:62152603,U1813218); Tsinghua University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9880161","Representation learning; Deep learning architectures and techniques","Point cloud compression;Solid modeling;Three-dimensional displays;Computational modeling;Bit error rate;Transformers;Pattern recognition","feature extraction;graph theory;image classification;image motion analysis;image representation;learning (artificial intelligence);neural nets","pre-training 3D;Masked Point Modeling task;pre-train point cloud Transformers;local point patches;point cloud Tokenizer;discrete point tokens;input point clouds;pre-training objective;original point;BERT-style pre-training strategy;standard point cloud Transformers;carefully designed point cloud models;Point-BERT transfer;few-shot point cloud classification task","","","","66","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Deep Clustering using Dirichlet Process Gaussian Mixture","K. -L. Lim","Institute of Microelectronics, A* Star, Singapore","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","7","Deep clustering is an emerging topic in deep learning where traditional clustering is performed in deep learning feature space. However, clustering and deep learning are often mutually exclusive. In the autoencoder based deep clustering, the challenge is how to jointly optimize both clustering and dimension reduction together, so that the weights in the hidden layers are not only guided by reconstruction loss, but also by a loss function associated with clustering. The current state-of-the-art has two fundamental flaws. First, they rely on the mathematical convenience of Kullback-Leibler divergence for the clustering loss function but the former is asymmetric. Secondly, they assume the prior knowledge on the number of clusters is always available for their dataset of interest. This paper tries to improve on these problems. In the first problem, we use a Jensen-Shannon divergence to overcome the asymmetric issue, specifically using a closed form variant. Next, we introduce an infinite cluster representation using Dirichlet process Gaussian mixture model for joint clustering and model selection in the latent space which we called deep model selection. The number of clusters in the latent space are not fixed but instead vary accordingly as they gradually approach the optimal number during training. Thus, prior knowledge is not required. We evaluate our proposed deep model selection method with traditional model selection on large class number datasets such as MIT67 and CIFAR100 and also compare with both traditional variational Bayes model and deep clustering method with convincing results.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533366","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533366","","Deep learning;Training;Dimensionality reduction;Closed-form solutions;Clustering methods;Neural networks;Gaussian mixture model","Bayes methods;feature extraction;Gaussian processes;learning (artificial intelligence);pattern clustering","deep clustering;deep learning;traditional clustering;infinite cluster representation;Dirichlet process Gaussian mixture model;joint clustering;deep model selection method;loss function clustering;Kullback-Leibler divergence;Jensen-Shannon divergence","","","","28","IEEE","20 Sep 2021","","","IEEE","IEEE Conferences"
"TracInAD: Measuring Influence for Anomaly Detection","H. Thimonier; F. Popineau; A. Rimmel; B. -L. Doan; F. Daniel","Laboratoire Interdisciplinaire des Sciences du Numérique, Université Paris-Saclay, CNRS, CentraleSupélec, Gif-sur-Yvette, France; Laboratoire Interdisciplinaire des Sciences du Numérique, Université Paris-Saclay, CNRS, CentraleSupélec, Gif-sur-Yvette, France; Laboratoire Interdisciplinaire des Sciences du Numérique, Université Paris-Saclay, CNRS, CentraleSupélec, Gif-sur-Yvette, France; Laboratoire Interdisciplinaire des Sciences du Numérique, Université Paris-Saclay, CNRS, CentraleSupélec, Gif-sur-Yvette, France; Artificial Intelligence Department of Lusis, Paris, France","2022 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2022","2022","","","1","6","As with many other tasks, neural networks prove very effective for anomaly detection purposes. However, very few deep-learning models are suited for detecting anomalies on tabular datasets. This paper proposes a novel methodology to flag anomalies based on TracIn, an influence measure initially introduced for explicability purposes. The proposed methods can serve to augment any unsupervised deep anomaly detection method. We test our approach using Variational Autoencoders and show that the average influence of a subsample of training points on a test point can serve as a proxy for abnormality. Our model proves to be competitive in comparison with state-of-the-art approaches: it achieves comparable or better performance in terms of detection accuracy on medical and cyber-security tabular benchmark data.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9892058","CNRS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9892058","","Training;Adaptation models;Neural networks;Benchmark testing;Data models;Task analysis;Anomaly detection","","","","","","22","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"Meta-Generating Deep Attentive Metric for Few-Shot Classification","F. Zhou; L. Zhang; W. Wei","School of Computer Science, Northwestern Polytechnical University, Xi’an, China; Shaanxi Provincial Key Laboratory of Speech and Image Information Processing, and the National Engineering Laboratory for Integrated Aerospace-Ground-Ocean Big Data Application Technology, School of Computer Science, Northwestern Polytechnical University, Xi’an, China; Research and Development Institute, Northwestern Polytechnical University in Shenzhen, Shenzhen, China","IEEE Transactions on Circuits and Systems for Video Technology","4 Oct 2022","2022","32","10","6863","6873","Learning to generate a task-aware base learner proves a promising direction to deal with few-shot learning (FSL) problem. Existing methods mainly focus on generating an embedding model utilized with a fixed metric (e.g., cosine distance) for nearest neighbour classification or directly generating a linear classifier. However, due to the limited discriminative capacity of such a simple metric or classifier, these methods fail to generalize to challenging cases appropriately. To mitigate this problem, we present a novel deep metric meta-generation method that turns to an orthogonal direction, i.e., learning to adaptively generate a specific metric for a new FSL task based on the task description (e.g., a few labelled samples). In this study, we structure the metric using a three-layers deep attentive network that is flexible enough to produce a discriminative metric for each task. Moreover, different from existing methods that utilize an uni-modal weight distribution conditioned on labelled samples for network generation, the proposed meta-learner establishes a multi-modal weight distribution conditioned on cross-class sample pairs using a tailored variational autoencoder, which can separately capture the specific inter-class discrepancy statistics for each class and jointly embed the statistics for all classes into metric generation. By doing this, the generated metric can be appropriately adapted to a new FSL task with pleasing generalization performance. To demonstrate this, we test the proposed method on three benchmark FSL datasets and gain competitive results with state-of-the-art competitors.","1558-2205","","10.1109/TCSVT.2022.3173687","National Natural Science Foundation of China(grant numbers:62071387,62101454); Shenzhen Science and Technology Program(grant numbers:JCYJ20190806160210899); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9771190","Few-shot learning;deep attentive metric;meta-learning","Measurement;Task analysis;Training;Gaussian distribution;Optimization;Standards;Feature extraction","","","","","","83","IEEE","9 May 2022","","","IEEE","IEEE Journals"
"Wavelet and Deep-Learning-Based Approach for Generation System Problematic Parameters Identification and Calibration","R. Fan; R. Huang; S. Wang; J. Zhao","University of Denver, CO, USA; Shanghai Jiao Tong University, Shanghai, China; Pacific Northwest National Laboratory, Richland, WA, USA; University of Connecticut, CT, USA","IEEE Transactions on Power Systems","","2022","PP","99","1","12","Accurate models of generation systems are critical for maintaining reliable and secure grid operations. In this paper, a novel and systematic approach is proposed to identify and calibrate the generator system problematic parameters using continuous wavelet transform (CWT) and advanced deep-learning technology. At the beginning, the phasor measurement unit (PMU) data are used through “event playback” to check the consistency between simulated and measured real and reactive power of the generation system. Once the results indicate a model parameter validation is required, a group of suspicious parameters will be identified as the primary problematic parameter candidates (PPCs). These primary PPCs are randomly perturbed to generate the event playback simulation data, which are used by the CWT and convolutional neural networks (CNNs) to further narrow down the primary PPCs into a smaller set of candidates. Then, the identified candidates are perturbed again to generate massive event playback simulation data for training a parameter calibration neural network. We designed a multi-output neural network structure to find the mappings between the perturbed parameters and the simulation data using both CNN and long short-term memory (LSTM) models. Finally, the well-trained and tested CNN-LSTM model is used to estimate the accurate value of the suspicious parameters with actual PMU measurements. The proposed CNN-LSTM network can accurately and reliably estimate the generation-system problematic parameters, and has better performance when compared to other machine-learning methods, such as the multilayer perceptron network and the conditional variational autoencoder method. The accuracy and effectiveness of the proposed approach have been validated through simulation and real-world data.","1558-0679","","10.1109/TPWRS.2022.3208021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9896206","problematic parameters identification and calibration;deep learning;phasor measurement unit;continuous wavelet transform;convolutional neural network;long short-term memory","Calibration;Phasor measurement units;Continuous wavelet transforms;Mathematical models;Convolutional neural networks;Brain modeling;Generators","","","","","","","IEEE","20 Sep 2022","","","IEEE","IEEE Early Access Articles"
"DEEPA: A Deep Neural Analyzer for Speech and Singing Vocoding","S. Nikonorov; B. Sisman; M. Zhang; H. Li","National University of Singapore, Singapore; Singapore University of Technology and Design, Singapore; National University of Singapore, Singapore; The Chinese University of Hong Kong, Shenzhen, China","2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)","3 Feb 2022","2021","","","618","625","Conventional vocoders are commonly used as analysis tools to provide interpretable features for downstream tasks such as speech synthesis and voice conversion. They are built under certain assumptions about the signals following signal processing principle, therefore, not easily generalizable to different audio, for example, from speech to singing. In this paper, we propose a deep neural analyzer, denoted as DeepA – a neural vocoder that extracts F0 and timbre/aperiodicity encoding from the input speech that emulate those defined in conventional vocoders. Therefore, the resulting parameters are more interpretable than other latent neural representations. At the same time, as the deep neural analyzer is learnable, it is expected to be more accurate for signal reconstruction and manipulation, and generalizable from speech to singing. The proposed neural analyzer is built based on a variational autoencoder (VAE) architecture. We show that DeepA improves F0 estimation over the conventional vocoder (WORLD). To our best knowledge, this is the first study dedicated to the development of a neural framework for extracting learnable vocoder-like parameters.","","978-1-6654-3739-4","10.1109/ASRU51503.2021.9687923","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9687923","neural vocoder;deep analysis;VAE","Vocoders;Conferences;Pipelines;Estimation;Signal reconstruction;Encoding;Speech synthesis","feature extraction;neural nets;signal reconstruction;speech intelligibility;speech processing;speech synthesis;vocoders","learnable vocoder-like parameters;DEEPA;deep neural analyzer;singing vocoding;conventional vocoder;speech synthesis;voice conversion;DeepA;neural vocoder;input speech;latent neural representations;signal reconstruction;neural framework","","","","33","IEEE","3 Feb 2022","","","IEEE","IEEE Conferences"
"Single-modal Incremental Terrain Clustering from Self-Supervised Audio-Visual Feature Learning","R. Ishikawa; R. Hachiuma; A. Kurobe; H. Saito","Department of Information and Computer Science, Keio University, Yokohama, Japan; Department of Information and Computer Science, Keio University, Yokohama, Japan; Department of Information and Computer Science, Keio University, Yokohama, Japan; Department of Information and Computer Science, Keio University, Yokohama, Japan","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","9399","9406","The key to an accurate understanding of terrain is to extract the informative features from the multi-modal data obtained from different devices. Sensors, such as RGB cameras, depth sensors, vibration sensors, and microphones, are used as the multi-modal data. Many studies have explored ways to use them, especially in the robotics field. Some papers have successfully introduced single-modal or multi-modal methods. However, in practice, robots can be faced with extreme conditions; microphones do not work well in crowded scenes, and an RGB camera cannot capture terrains well in the dark. In this paper, we present a novel framework using the multimodal variational autoencoder and the Gaussian mixture model clustering algorithm on image data and audio data for terrain type clustering. Our method enables the terrain type clustering even if one of the modalities (either image or audio) is missing at the test-time. We evaluated the clustering accuracy with a conventional multi-modal terrain type clustering method and we conducted ablation studies to show the effectiveness of our approach.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9412638","JST(grant numbers:JPMJMI19B2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9412638","","Vibrations;Training;Visualization;Robot vision systems;Predictive models;Feature extraction;Cameras","audio signal processing;Gaussian processes;learning (artificial intelligence);mixture models;pattern clustering;video signal processing","self-supervised audio-visual feature learning;informative features;multimodal data;RGB camera;depth sensors;vibration sensors;microphones;robotics field;image data;audio data;multimodal terrain type clustering method;single-modal incremental terrain clustering","","","","48","","5 May 2021","","","IEEE","IEEE Conferences"
"Hierarchical Policies for Cluttered-Scene Grasping With Latent Plans","L. Wang; X. Meng; Y. Xiang; D. Fox","Department of Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; School of Computer Science and Engineering, University of Washington, Seattle, WA, USA; Department of Computer Science, University of Texas at Dallas, Richardson, TX, USA; School of Computer Science and Engineering, University of Washington, Seattle, WA, USA","IEEE Robotics and Automation Letters","3 Feb 2022","2022","7","2","2883","2890","6D grasping in cluttered scenes is a longstanding problem in robotic manipulation. Open-loop manipulation pipelines may fail due to inaccurate state estimation, while most end-to-end grasping methods have not yet scaled to complex scenes with obstacles. In this work, we propose a new method for end-to-end learning of 6D grasping in cluttered scenes. Our hierarchical framework learns collision-free target-driven grasping based on partial point cloud observations. We learn an embedding space to encode expert grasping plans during training and a variational autoencoder to sample diverse grasping trajectories at test time. Furthermore, we train a critic network for plan selection and an option classifier for switching to an instance grasping policy through hierarchical reinforcement learning. We evaluate and analyze our method and compare against several baselines in simulation, and demonstrate that our latent planning can generalize to real-world cluttered-scene grasping tasks.1","2377-3766","","10.1109/LRA.2022.3143198","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9682579","Deep learning in grasping and manipulation;sensorimotor learning","Grasping;Trajectory;Point cloud compression;Planning;Task analysis;Switches;Grippers","dexterous manipulators;grippers;learning (artificial intelligence);robot vision;state estimation","hierarchical policies;latent plans;longstanding problem;robotic manipulation;open-loop manipulation pipelines;inaccurate state estimation;end-to-end grasping methods;complex scenes;end-to-end learning;hierarchical framework;collision-free target-driven;partial point cloud observations;expert grasping plans;sample diverse grasping trajectories;plan selection;instance grasping policy;hierarchical reinforcement learning;latent planning;real-world cluttered-scene grasping tasks;cluttered scenes grasping;6D grasping","","","","42","IEEE","14 Jan 2022","","","IEEE","IEEE Journals"
"Distinguishing Unseen from Seen for Generalized Zero-shot Learning","H. Su; J. Li; Z. Chen; L. Zhu; K. Lu",University of Electronic Science and Technology of China; Institute of Electronic and Information Engineering of UESTC in Guangdong; The University of Queensland; Shandong Normal University; University of Electronic Science and Technology of China,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","7875","7884","Generalized zero-shot learning (GZSL) aims to recognize samples whose categories may not have been seen at training. Recognizing unseen classes as seen ones or vice versa often leads to poor performance in GZSL. Therefore, distinguishing seen and unseen domains is naturally an effective yet challenging solution for GZSL. In this paper, we present a novel method which leverages both visual and semantic modalities to distinguish seen and unseen categories. Specifically, our method deploys two variational autoencoders to generate latent representations for visual and semantic modalities in a shared latent space, in which we align latent representations of both modalities by Wasserstein distance and reconstruct two modalities with the representations of each other. In order to learn a clearer boundary between seen and unseen classes, we propose a two-stage training strategy which takes advantage of seen and unseen semantic descriptions and searches a threshold to separate seen and unseen visual samples. At last, a seen expert and an unseen expert are used for final classification. Extensive experiments on five widely used benchmarks verify that the proposed method can significantly improve the results of GZSL. For instance, our method correctly recognizes more than 99% samples when separating domains and improves the final classification accuracy from 72.6% to 82.9% on AWA1.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.00773","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879149","Image and video synthesis and generation; Computer vision theory; Machine learning; Transfer/low-shot/long-tail learning","Training;Visualization;Computer vision;Semantics;Benchmark testing;Pattern recognition","image classification;image representation;learning (artificial intelligence)","GZSL;visual modalities;semantic modalities;unseen categories;shared latent space;two-stage training strategy;unseen semantic descriptions;unseen visual samples;unseen expert;generalized zero-shot learning;unseen domains;latent representations","","","","49","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Hierarchical Feature Aggregation Network for Deep Image Compression","W. Li; Z. Du; H. He; J. Tang; G. Wu","State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","1875","1879","Existing CNN-based methods for image compression extract features through serially connected high-to-low (encoder) or low-to-high (decoder) resolution stages, leading to insufficient utilization of hierarchical features. To solve this problem, we present a hierarchical feature aggregation network (HFAN) for generating more informative latent representations. In detail, we propose two strategies, namely inter-stage feature aggregation and intra-stage feature aggregation. The inter-stage feature aggregation integrates multi-scale information thereby producing more contextual features. The intra-stage aggregation fuses features within the same stage to enrich representations of one specific resolution. Besides, we incorporate a lightweight pixel-wise attention mechanism to further enhance the discriminative ability of our network. Extensive experiments demonstrate that our HFAN achieves superior performance over state-of-the-art methods without a hyperprior variational autoencoder.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746628","deep image compression;feature aggregation;attention mechanism","Image coding;Image resolution;Fuses;Conferences;Transform coding;Signal processing;Feature extraction","convolutional neural nets;data compression;feature extraction;image coding;image representation","deep image compression;CNN-based methods;low-to-high resolution stages;hierarchical feature aggregation network;inter-stage feature aggregation;intra-stage feature aggregation;contextual features;lightweight pixel-wise attention mechanism","","","","29","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Interpretable Anomaly Detection in Event Sequences via Sequence Matching and Visual Comparison","S. Guo; Z. Jin; Q. Chen; D. Gotz; H. Zha; N. Cao","College of Design and Innovation, Tongji University, 12476 Shanghai, Shanghai, China, (e-mail: g.shunan@gmail.com); College of Design and Innovation, Tongji University, 12476 Shanghai, Shanghai, China, 200092 (e-mail: chjzcjames@gmail.com); College of Design and Innovation, Tongji University, 12476 Shanghai, Shanghai, China, (e-mail: jane.qing.chen@gmail.com); School of Information and Library Science, University of North Carolina at Chapel Hill, Chapel Hill, North Carolina, United States, 27599 (e-mail: gotz@unc.edu); School of Computational Science and Engineering, Georgia Tech, Atlanta, Georgia, United States, 30332 (e-mail: zha@cc.gatech.edu); College of Design and Innovation, Tongji University, 12476 Shanghai, Shanghai, China, (e-mail: nan.cao@gmail.com)","IEEE Transactions on Visualization and Computer Graphics","","2021","PP","99","1","1","Anomaly detection is a common analytical task that aims to identify rare cases that differ from the typical cases that make up the majority of a dataset. When analyzing event sequence data, the task of anomaly detection can be complex because the sequential and temporal nature of such data results in diverse definitions and flexible forms of anomalies. This, in turn, increases the difficulty in interpreting detected anomalies. In this paper, we propose a visual analytic approach for detecting anomalous sequences in an event sequence dataset via an unsupervised anomaly detection algorithm based on Variational AutoEncoders. We further compare the anomalous sequences with their reconstructions and with the normal sequences through a sequence matching algorithm to identify event anomalies. A visual analytics system is developed to support interactive exploration and interpretations of anomalies through novel visualization designs that facilitate the comparison between anomalous sequences and normal sequences. Finally, we quantitatively evaluate the performance of our anomaly detection algorithm, demonstrate the effectiveness of our system through case studies, and report feedback collected from study participants.","1941-0506","","10.1109/TVCG.2021.3093585","National Natural Science Foundation of China(grant numbers:6200070909,62072338); Joint NSFC-DFG Research Program(grant numbers:62061136003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9468958","","Anomaly detection;Data models;Data visualization;Task analysis;Sequences;Heart;Diabetes","","","","","","","IEEE","30 Jun 2021","","","IEEE","IEEE Early Access Articles"
"Permissioned Blockchain and Deep Learning for Secure and Efficient Data Sharing in Industrial Healthcare Systems","R. Kumar; P. Kumar; R. Tripathi; G. P. Gupta; A. K. M. N. Islam; M. Shorfuzzaman","National Institute of Technology Raipur, Raipur, India; National Institute of Technology Raipur, Raipur, India; National Institute of Technology Raipur, Raipur, India; National Institute of Technology Raipur, Raipur, India; LUT School of Engineering Science, LUT University, Lappeenranta, Finland; Department of Computer Science, College of Computers and Information Technology, Taif University, Taif, Saudi Arabia","IEEE Transactions on Industrial Informatics","19 Sep 2022","2022","18","11","8065","8073","The industrial healthcaresystem has enabled the possibility of realizing advanced real-time monitoring of patients and enriched the quality of medical services through data sharing among intelligent wearable devices and sensors. However, this connectivity brings the intrinsic vulnerabilities related to security and privacy due to the need of continuous communication and monitoring over public network (insecure channel). Motivated from the aforementioned discussions, we integrate permissioned blockchain and smart contract with deep learning (DL) techniques to design a novel secure and efficient data sharing framework named PBDL. Specifically, PBDL first has a blockchain scheme to register, verify (using zero-knowledge proof), and validate the communicating entities using the smart contract-based consensus mechanism. Second, the authenticated data are used to propose a novel DL scheme that combines stacked sparse variational autoencoder (SSVAE) with self-attention-based bidirectional long short term memory (SA-BiLSTM). In this scheme, SSVAE encodes or transforms the healthcare data into new format, and SA-BiLSTM identifies and improves the attack detection process. The security analysis and experimental results using IoT-Botnet and ToN-IoT datasets confirm the superiority of the PBDL framework over existing state-of-the-art techniques.","1941-0050","","10.1109/TII.2022.3161631","Mathematical Research Impact Centric Support; Science and Engineering Research Board(grant numbers:MTR/2019/001285); Taif University Researchers Supporting Project(grant numbers:TURSP-2020/79); Taif University, Taif, Saudi Arabia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9740491","Blockchain;deep learning (DL);healthcare systems;Industrial Internet of Things (IIoT);intrusion detection system (IDS);privacy preservation","Medical services;Blockchains;Data privacy;Security;Cloud computing;Temperature sensors;Real-time systems","","","","","","33","IEEE","23 Mar 2022","","","IEEE","IEEE Journals"
"Meta-Learning, Fast Adaptation, and Latent Representation for Head Pose Estimation","M. Joshi; D. R. Pant; R. R. Karn; J. Heikkonen; R. Kanth","Institute of Engineering, Nepal; Institute of Engineering, Nepal; Khalifa University, Abu Dhabi, UAE; University of Turku, Turku, Finland; Savonia University of Applied Sciences, Kuopio, Finland","2022 31st Conference of Open Innovations Association (FRUCT)","11 May 2022","2022","","","71","78","Head pose estimation is used in a variety of human-computer interface applications, like stare tracking, driving assistance, impaired assistance, and entertainment. Advances in convolutional neural networks have a considerable improvement in the performance of head pose estimation. However, difficulties in capturing well-labelled head pose data and differences in the facial features of different persons make them difficult to use. This work proposes a meta-learning based technique for head pose estimation problem in BIWI head pose dataset. An approach to learning latent representation of head pose features using variational autoencoder is implemented. Then a fast, adaptable head pose estimator is trained using meta-learning in a few-shot settings. Model agnostic meta-learning (MAML) algorithm has been deployed for training a head pose estimator. Mean Average Error (MAEavg) of 7.33 is achieved in predicting head pose angles in one-shot settings. After meta-training, the optimized model is used to analyze fast adaptation in a test set that has been separated from the BIWI head pose dataset. We begin with the trained network’s optimum parameters and optimize the inner loop for quick adaptation. The optimized model can predict accurate head poses using as few as 10 gradient descent steps in the unseen set of tasks sampled from the test set.","","978-952-69244-7-2","10.23919/FRUCT54823.2022.9770932","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9770932","","Training;Representation learning;Human computer interaction;Adaptation models;Technological innovation;Pose estimation;Training data","face recognition;feature extraction;gradient methods;image representation;learning (artificial intelligence);neural nets;object tracking;pose estimation","fast head;adaptable head;model agnostic meta-learning algorithm;predicting head;meta-training;fast adaptation;BIWI head;accurate head;latent representation;head pose estimation;human-computer interface applications;meta-learning based technique","","","","45","","11 May 2022","","","IEEE","IEEE Conferences"
"Anomalous Gait Feature Classification From 3-D Motion Capture Data","S. Jeon; K. M. Lee; S. Koo","Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Dajeon, South Korea; Department of Orthopedic Surgery, Seoul National University Bundang Hospital (SNUH), Seongnam-si, South Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Dajeon, South Korea","IEEE Journal of Biomedical and Health Informatics","4 Feb 2022","2022","26","2","696","703","The gait kinematics of an individual is affected by various factors, including age, anthropometry, gender, and disease. Detecting anomalous gait features aids in the diagnosis and treatment of gait-related diseases. The objective of this study was to develop a machine learning method for automatically classifying five anomalous gait features, i.e., toe-out, genu varum, pes planus, hindfoot valgus, and forward head posture features, from three-dimensional data on gait kinematics. Gait data and gait feature labels of 488 subjects were acquired. The orientations of the human body segments during a gait cycle were mapped to a low-dimensional latent gait vector using a variational autoencoder. A two-layer neural network was trained to classify five gait features using logistic regression and calculate an anomalous gait feature vector (AGFV). The proposed network showed balanced accuracies of 82.8% for a toe-out, 85.9% for hindfoot valgus, 80.2% for pes planus, 73.2% for genu varum, and 92.9% for forward head posture when the AGFV was rounded to the nearest zero or 1. Multiple anomalous gait features were detectable using the proposed method, which has a practical advantage over current gait indices, including the gait deviation index with a single value. The overall results confirmed the feasibility of using the proposed method for screening subjects with anomalous gait features using three-dimensional motion capture data.","2168-2208","","10.1109/JBHI.2021.3101549","NRF(grant numbers:NRF-2020R1A2C2006057); Research and Development of Police Science and Technology(grant numbers:PA-C000001); Ministry of Science and ICT, South Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506854","Human gait;anomalous gait;feedforward neural networks","Legged locomotion;Kinematics;Diseases;Feature extraction;Three-dimensional displays;Machine learning;Motion segmentation","anthropometry;biomechanics;diseases;feature extraction;feedforward neural nets;gait analysis;image motion analysis;kinematics;learning (artificial intelligence);medical disorders;patient diagnosis;regression analysis","gait-related diseases;genu varum;pes planus;hindfoot valgus;head posture features;gait kinematics;gait data;gait feature labels;gait cycle;low-dimensional latent gait vector;anomalous gait feature vector;gait deviation index;three-dimensional motion capture data;anomalous gait feature classification;3D motion capture data;two-layer neural network;logistic regression","Biomechanical Phenomena;Foot;Gait;Humans;Machine Learning;Motion","","","54","CCBY","4 Aug 2021","","","IEEE","IEEE Journals"
"COTS: Collaborative Two-Stream Vision-Language Pre-Training Model for Cross-Modal Retrieval","H. Lu; N. Fei; Y. Huo; Y. Gao; Z. Lu; J. -R. Wen","Beijing Key Laboratory of Big Data Management and Analysis Methods; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China; Beijing Key Laboratory of Big Data Management and Analysis Methods; Beijing Key Laboratory of Big Data Management and Analysis Methods","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","15671","15680","Large-scale single-stream pre-training has shown dramatic performance in image-text retrieval. Regrettably, it faces low inference efficiency due to heavy attention layers. Recently, two-stream methods like CLIP and ALIGN with high inference efficiency have also shown promising performance, however, they only consider instance-level alignment between the two streams (thus there is still room for improvement). To overcome these limitations, we propose a novel COllaborative Two-Stream vision-language pretraining model termed COTS for image-text retrieval by enhancing cross-modal interaction. In addition to instance-level alignment via momentum contrastive learning, we leverage two extra levels of cross-modal interactions in our COTS: (1) Token-level interaction - a masked vision-language modeling (MVLM) learning objective is devised without using a cross-stream network module, where variational autoencoder is imposed on the visual encoder to generate visual tokens for each image. (2) Task-level interaction - a KL-alignment learning objective is devised between text-to-image and image-to-text retrieval tasks, where the probability distribution per task is computed with the negative queues in momentum contrastive learning. Under a fair comparison setting, our COTS achieves the highest performance among all two-stream methods and comparable performance (but with 10,800× faster in inference) w.r.t. the latest single-stream methods. Importantly, our COTS is also applicable to text-to-video retrieval, yielding new state-of-the-art on the widely-used MSR-VTT dataset.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01524","National Natural Science Foundation of China(grant numbers:61976220,61832017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879912","Vision + language; Recognition: detection;categorization;retrieval; Video analysis and understanding","Visualization;Computer vision;Collaboration;Streaming media;Probability distribution;Pattern recognition;Task analysis","computer vision;image retrieval;information retrieval;learning (artificial intelligence);probability;text analysis;video retrieval","COTS;collaborative Two-Stream vision-language pre-training model;cross-modal retrieval;image-text retrieval;low inference efficiency;two-stream methods;high inference efficiency;instance-level alignment;COllaborative Two-Stream vision-language pretraining model;cross-modal interaction;momentum contrastive learning;extra levels;Token-level interaction;masked vision-language modeling learning objective;cross-stream network module;KL-alignment learning objective;text-to-image;image-to-text retrieval tasks;single-stream methods;text-to-video retrieval","","","","53","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Laser2Vec: Similarity-based Retrieval for Robotic Perception Data","S. B. Nashed","College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA","2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","10 Feb 2021","2020","","","10657","10662","As mobile robot capabilities improve and deployment times increase, tools to analyze the growing volume of data are becoming necessary. Current state-of-the-art logging, playback, and exploration systems are insufficient for practitioners seeking to discover systemic points of failure in robotic systems. This paper presents a suite of algorithms for similarity-based queries of robotic perception data and implements a system for storing 2D LiDAR data from many deployments cheaply and evaluating top-k queries for complete or partial scans efficiently. We generate compressed representations of laser scans via a convolutional variational autoencoder and store them in a database, where a light-weight dense network for distance function approximation is run at query time. Our query evaluator leverages the local continuity of the embedding space to generate evaluation orders that, in expectation, dominate full linear scans of the database. The accuracy, robustness, scalability, and efficiency of our system is tested on real-world data gathered from dozens of deployments and synthetic data generated by corrupting real data. We find our system accurately and efficiently identifies similar scans across a number of episodes where the robot encountered the same location, or similar indoor structures or objects.","2153-0866","978-1-7281-6212-6","10.1109/IROS45743.2020.9340815","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9340815","","Scalability;Two dimensional displays;Relational databases;Tools;Robustness;Object recognition;Optimization","function approximation;mobile robots;optical radar;query processing","light-weight dense network;query time;query evaluator leverages;linear scans;real-world data;synthetic data;similar scans;similar indoor structures;laser2vec;similarity-based retrieval;robotic perception data;mobile robot capabilities;growing volume;current state-of-the-art logging;exploration systems;robotic systems;similarity-based queries;storing 2D LiDAR data;top-k queries;complete scans;partial scans;laser scans","","","","32","","10 Feb 2021","","","IEEE","IEEE Conferences"
"ClaviNet: Generate Music With Different Musical Styles","Y. -Q. Lim; C. S. Chan; F. Y. Loo","Center of Image and Signal Processing, Department of Artificial Intelligence, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia; Center of Image and Signal Processing, Department of Artificial Intelligence, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia; Department of Music, Cultural Centre, University of Malaya, Kuala Lumpur, Malaysia","IEEE MultiMedia","30 Mar 2021","2021","28","1","83","93","Classically, the style of the generated music by deep learning models is usually governed by the training dataset. In this article, we improved this by proposing the continuous style embedding ${z}_{s}$zs to the general formulation of variational autoencoder (VAE) to allow users to be able to condition on the style of the generated music. For this purpose, we explored and compared two different methods to integrate ${z}_{s}$zs into the VAE. In the literature of conditional generative modeling, disentanglement of attributes from the latent space is often associated with better generative performance. In our experiments, we find that this is not the case with our proposed model. Empirically and from a musical theory perspective, we show that our proposed model can generate better music samples than a baseline model that utilizes a discrete style label. The source code and generated samples are available at https://github.com/daQuincy/DeepMusicvStyle.","1941-0166","","10.1109/MMUL.2020.3046491","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302731","music synthesis;deep learning;style transfer","Music;Training;Computer generated music;Decoding;Task analysis;Instruments;Context modeling","convolutional neural nets;deep learning (artificial intelligence);music","music samples;musical theory perspective;conditional generative modeling;VAE;continuous style embedding;deep learning models;musical styles;music generation","","","","18","IEEE","22 Dec 2020","","","IEEE","IEEE Magazines"
"Robust outlier detection by de-biasing VAE likelihoods","K. Chauhan; B. M. U; P. Shenoy; M. Gupta; D. Sridharan","Google Research; Center for Neuroscience, and Computer Science and Automation, Indian Institute of Science; Google Research; Google Research; Center for Neuroscience, and Computer Science and Automation, Indian Institute of Science","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","9871","9880","Deep networks often make confident, yet, incorrect, predictions when tested with outlier data that is far removed from their training distributions. Likelihoods computed by deep generative models (DGMs) are a candidate metric for outlier detection with unlabeled data. Yet, previous studies have shown that DGM likelihoods are unreliable and can be easily biased by simple transformations to input data. Here, we examine outlier detection with variational autoencoders (VAEs), among the simplest of DGMs. We propose novel analytical and algorithmic approaches to ameliorate key biases with VAE likelihoods. Our bias corrections are sample-specific, computationally inexpensive, and readily computed for various decoder visible distributions. Next, we show that a well-known image pre-processing technique – contrast stretching – extends the effectiveness of bias correction to further improve outlier detection. Our approach achieves state-of-the-art accuracies with nine grayscale and natural image datasets, and demonstrates significant advantages – both with speed and performance – over four recent, competing approaches. In summary, lightweight remedies suffice to achieve robust outlier detection with VAEs.11Code is available at https://github.com/google-research/google-research/tree/master/vae_ood.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.00965","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879487","Self-& semi-& meta- Deep learning architectures and techniques; Image and video synthesis and generation; Machine learning; Statistical methods; Vision applications and systems","Training;Measurement;Computer vision;Computational modeling;Gray-scale;Data models;Pattern recognition","data handling;deep learning (artificial intelligence);image processing;maximum likelihood estimation","input data;debiasing VAE likelihoods;improve outlier detection;image preprocessing technique;decoder visible distributions;algorithmic approaches;analytical approaches;DGM likelihoods;unlabeled data;deep generative models;training distributions;outlier data;incorrect predictions;deep networks;robust outlier detection","","","","27","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Monocular Vision Obstacle Avoidance UAV: A Deep Reinforcement Learning Method","Z. Xue; T. Gonsalves","Dept. of Information & Communication Sciences, Faculty of Science & Technology, Sophia University, Tokyo, Japan; Dept. of Information & Communication Sciences, Faculty of Science & Technology, Sophia University, Tokyo, Japan","2021 2nd International Conference on Innovative and Creative Information Technology (ICITech)","9 Nov 2021","2021","","","1","6","In this paper, a method based on deep reinforcement learning (DRL) is proposed, which allows unmanned aerial vehicles (UAVs) to complete obstacle avoidance tasks only through vision in an environment full of common indoor obstacles. This technology is very important for indoor UAVs, due to the limited GPS signal and overcrowding of obstacles compared to the outdoor environment. We use Variational Autoencoder (VAE) to compress image information combined with the policy-based DRL model to implement the visual obstacle avoidance of VAVs. Simulation experiments have demonstrated that this method can make the UAV master obstacle avoidance in a continuous action space with a fixed direction. Compared with the traditional policy-based DRL visual obstacle avoidance algorithms, it can converge faster.","","978-1-7281-9747-0","10.1109/ICITech50181.2021.9590178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9590178","Drone;Deep Reinforcement Learning;VAE;Obstacle Avoidance","Training;Visualization;Adaptation models;Reinforcement learning;Unmanned aerial vehicles;Data models;Collision avoidance","autonomous aerial vehicles;collision avoidance;Global Positioning System;learning (artificial intelligence);mobile robots;remotely operated vehicles;robot vision","monocular vision obstacle avoidance UAV;deep reinforcement learning;unmanned aerial vehicles;complete obstacle avoidance tasks;common indoor obstacles;indoor UAVs;outdoor environment;policy-based DRL model;UAV master obstacle avoidance;traditional policy-based DRL visual obstacle avoidance algorithms","","","","19","","9 Nov 2021","","","IEEE","IEEE Conferences"
"Exposing DeepFakes Using Convolutional Neural Networks and Transfer Learning Approaches","S. Suratkar; F. Kazi; M. Sakhalkar; N. Abhyankar; M. Kshirsagar","COE - CNDS, Veermata Jijabai Technological Institute, Mumbai; COE - CNDS, Veermata Jijabai Technological Institute, Mumbai; COE - CNDS, Veermata Jijabai Technological Institute, Mumbai; COE - CNDS, Veermata Jijabai Technological Institute, Mumbai; COE - CNDS, Veermata Jijabai Technological Institute, Mumbai","2020 IEEE 17th India Council International Conference (INDICON)","5 Feb 2021","2020","","","1","8","Advancements in Artificial Intelligence - oriented computing power and the ever-growing reach of social media have proven to be catalysts in emergence and spread of a new vein of AI generated fake videos known as 'DeepFake' videos. Such videos are synthesized using generative machine learning models like Generative Adversarial Networks or Variational AutoEncoders and they can achieve high degrees of realism. Spread of sensitive political or obscene content in form of such videos may lead to social distress to the target entity(s). This paper presents a study pertinent to the detection of DeepFake videos using Convolutional Neural Networks (CNNs) with transfer learning. A comparative study of the performance of various models in the detection of tampered videos has been presented. These models are trained (fine-tuned) and tested on a custom dataset encompassing randomly selected labelled frames from videos in the DeepFake Detection Dataset by Google AI and FaceForensics++ dataset.","2325-9418","978-1-7281-6916-3","10.1109/INDICON49873.2020.9342252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9342252","Convolutional Neural Networks;Generative Adversarial Networks;Transfer Learning;Visual Geometry Group;DenseNet;Xception;Inception V3","Training;Social networking (online);Veins;Transfer learning;Convolutional neural networks;Videos;Information integrity","convolutional neural nets;learning (artificial intelligence);social networking (online);video signal processing","FaceForensics++ dataset;Google AI;sensitive political content;generative machine learning models;DeepFake videos;social media;artificial intelligence;transfer learning approaches;convolutional neural networks;DeepFake Detection Dataset;tampered videos","","","","39","","5 Feb 2021","","","IEEE","IEEE Conferences"
"Target-Driven Mapless Navigation for Self-Driving Car","M. Wen; F. He; Y. Yue; J. Zhang; H. Zhu; D. Wang","School of Electrical & Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical & Electronic Engineering, Nanyang Technological University, Singapore; School of Automation, Beijing Institute of Technology, Beijing, China; School of Electrical & Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical & Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical & Electronic Engineering, Nanyang Technological University, Singapore","2021 IEEE International Conference on Unmanned Systems (ICUS)","22 Dec 2021","2021","","","505","511","Self-driving cars have gained a lot of research interest in both academia and industry. However, the current solutions mainly rely on either human pre-defined rules or a precise high-resolution map, which are not feasible for the unknown environments, especially when there are some extreme situations not described in the driving rules. In this paper, a new reinforcement learning based method is proposed to address these issues. First, a pre-trained VAE (Variational AutoEncoder) is used to extract representative features from road images, then PPO (Proximal Policy Optimization) algorithm is implemented to learn target-driven navigation for the self-driving car to eliminate the dependence on the map and predefined rules. Second, to improve the learning efficiency, human driving experiences are introduced and how to effectively incorporate human driving experiences into reinforcement learning is also investigated. To evaluate the performance, this algorithm is implemented and deployed in CARLA simulation environments and extensive experiments have been conducted to select the effective strategy of reusing driving experiences. The results prove that our algorithm can successfully navigate in the urban environment without a map or any predefined rules. And by integrating human driving experiences, the learning efficiency has been dramatically improved, especially when using Ratio strategy.","","978-1-6654-3885-8","10.1109/ICUS52573.2021.9641134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9641134","","Training;Navigation;Roads;Urban areas;Reinforcement learning;Feature extraction;Autonomous automobiles","automobiles;feature extraction;learning (artificial intelligence);mobile robots;navigation;path planning;robot vision","human driving experiences;learning efficiency;mapless navigation;car;self-driving cars;human pre-defined rules;precise high-resolution map;extreme situations;driving rules;reinforcement learning based method;pre-trained VAE;PPO algorithm;Proximal Policy Optimization;target-driven navigation;predefined rules;effectively incorporate human;CARLA simulation environments;reusing driving experiences","","","","24","IEEE","22 Dec 2021","","","IEEE","IEEE Conferences"
"Adapt the Driving Policy to Local Traffic before Entering the New Area","N. Deng; Z. Cao; W. Zhou; K. Jiang; D. Yang","School of Vehicle and Mobility, Tsinghua University, Beijing, China; School of Vehicle and Mobility, Tsinghua University, Beijing, China; School of Vehicle and Mobility, Tsinghua University, Beijing, China; School of Vehicle and Mobility, Tsinghua University, Beijing, China; School of Vehicle and Mobility, Tsinghua University, Beijing, China","2021 IEEE International Intelligent Transportation Systems Conference (ITSC)","25 Oct 2021","2021","","","798","803","Autonomous vehicles (AVs) may get failures when driving in a foreign area, e.g., a new city, since the driving policy has not been designed for the local traffic characteristics. Thus, it is necessary to carefully adjust the driving policy when driving into a new area. Due to the safety and efficiency issues thorough feedback adjustment. The work proposes the active environment adaption method for AV planning using reinforcement learning. It can adjust the driving policy to local traffic with traffic data before entering the new area. By extract the local traffic driving characteristic and forming virtual environment data, the driving policy will be adapted for better initial performance in the new area. This work first uses the conditional variational autoencoder (CVAE) method to extract the local traffic characteristics from the local vehicle's driving data. The extracted model can partially represent the future trajectories of the vehicles in this area. This model will then form a virtual environment by generating vehicles data to obey the local traffic distribution. The final policy will be trained using a reinforcement learning framework, e.g., deep Q learning. Our method is demonstrated by adapting the longitudinal driving policy between different local traffic. Our adaptive policy improve the performance compared to default policy and maintains similar performance to artificial adjustments in the target local traffic.","","978-1-7281-9142-3","10.1109/ITSC48978.2021.9564711","National Natural Science Foundation of China(grant numbers:61903220,U1864203); Tsinghua University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9564711","autonomous driving;reinforcement learning;adaptive driving policy;traffic characteristic extraction","Adaptation models;Vehicle driving;Urban areas;Virtual environments;Reinforcement learning;Trajectory;Safety","learning (artificial intelligence);telecommunication traffic;traffic engineering computing;virtual reality","local traffic characteristics;active environment adaption method;traffic data;local vehicle;local traffic distribution;longitudinal driving policy;different local traffic;target local traffic","","","","18","","25 Oct 2021","","","IEEE","IEEE Conferences"
"Learning Controlled Semantic Embedding for Cross-Modal Retrieval","R. Yang; M. Meng; J. Yu; J. Wu","Department of Computer Science, Guangdong University of Technology, China; Department of Computer Science, Guangdong University of Technology, China; School of Computer Science, Hangzhou Dianzi University, Hangzhou, China; Department of Computer Science, Guangdong University of Technology, China","2021 IEEE International Conference on Multimedia and Expo (ICME)","9 Jun 2021","2021","","","1","7","Cross-modal retrieval has caught appealing attentions as it supports querying across different modalities. However, most existing methods have emphasized on directly mapping heterogeneous features into the common subspace, which inevitably results in highly entangled representations, thereby preventing them from bridging the modality gap. This paper presents a novel deep framework called Controlled Semantic Embedding (CSE), which is the first attempt to learn disentangled representations with controlled semantic structure for cross-modal retrieval. Specifically, we design two generative networks based on variational autoencoder, which incorporate semantic discriminators for effective prediction of structured semantics. Meanwhile, a self-supervised semantic network is seamlessly integrated into the generative networks to supervise the semantic embedding process, which is further coupled with a quantizer for controlling the quantizability of semantic representations. Extensive experiments show the superiority of CSE over other state-of-the-art methods in cross-modal retrieval.","1945-788X","978-1-6654-3864-3","10.1109/ICME51207.2021.9428280","National Natural Science Foundation of China; Natural Science Foundation of Guangdong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9428280","","Conferences;Semantics;Process control","feature extraction;image representation;information retrieval;learning (artificial intelligence);natural language processing;query processing;semantic networks","cross-modal retrieval;modality gap;controlled semantic structure;semantic discriminators;structured semantics;self-supervised semantic network;semantic embedding process;semantic representations","","","","26","IEEE","9 Jun 2021","","","IEEE","IEEE Conferences"
"Fed2KD: Heterogeneous Federated Learning for Pandemic Risk Assessment via Two-Way Knowledge Distillation","C. Sun; T. Jiang; S. Zonouz; D. Pompili","Department of Electrical and Computer Engineering, Rutgers University, New Brunswick, NJ, USA; Department of Electrical and Computer Engineering, Rutgers University, New Brunswick, NJ, USA; Department of Electrical and Computer Engineering, Rutgers University, New Brunswick, NJ, USA; Department of Electrical and Computer Engineering, Rutgers University, New Brunswick, NJ, USA","2022 17th Wireless On-Demand Network Systems and Services Conference (WONS)","29 Apr 2022","2022","","","1","8","The world has suffered a lot from the COVID-19 pandemic. Though vaccines have been developed, we still need to be ready for its variants and other possible pandemics in the future. To provide people with pandemic risk assessments without violating privacy, a Federated Learning (FL) framework is envisioned. However, most existing FL frameworks can only work for homogeneous models, i.e., models with the same configuration, ignoring the preferences of the users and the various properties of their devices. To this end, we propose a novel two-way knowledge distillation-based FL framework, Fed2KD. The knowledge exchange between the global and local models is achieved by distilling the information into or out from a tiny model with unified configuration. Nonetheless, the distillation cannot be conducted without a common dataset. To solve this bottleneck, we leverage the Conditional Variational Autoencoder (CVAE) to generate data that will be used as a proxy dataset for distillation. The proposed framework is firstly evaluated on benchmark datasets (MNIST and FashionMNIST) to test its performance against existing models such as Federated Averaging (FedAvg). The performance of Fed2KD improves by up to 30% on MNIST dataset, and 18% on FashionMNIST when data is non-independent and identically distributed (non-IID) as compared to FedAvg. Then, Fed2KD is evaluated on the pandemic risk assessment tasks through a mobile APP we developed, namely DP4coRUna, which provides indoor risk prediction.","","978-3-903176-46-1","10.23919/WONS54113.2022.9764443","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9764443","Federated learning;Knowledge Distillation;COVID-19 Risk Assessment","COVID-19;Wireless communication;Training;Pandemics;Benchmark testing;Collaborative work;Mobile applications","data privacy;learning (artificial intelligence);mobile computing","global models;local models;tiny model;unified configuration;common dataset;proxy dataset;benchmark datasets;Federated Averaging;Fed2KD;MNIST dataset;pandemic risk assessment tasks;indoor risk prediction;heterogeneous federated learning;COVID-19 pandemic;possible pandemics;Federated Learning framework;existing FL frameworks;homogeneous models;two-way knowledge distillation-based FL framework;knowledge exchange","","","","20","","29 Apr 2022","","","IEEE","IEEE Conferences"
"Upon Human's Unknown, Can AI Help to Address Uncertainty? A Practice on Package Substrate AOI Defect Detection","Y. -C. Hsu; J. -T. Wang; W. -S. Huang","AI & Advanced Optical Technology Development Division, Corporate R&D, Advanced Semiconductor Engineering (ASE), Inc., Zhubei City, Taiwan (R.O.C.); AI & Advanced Optical Technology Development Division, Corporate R&D, Advanced Semiconductor Engineering (ASE), Inc., Zhubei City, Taiwan (R.O.C.); AI & Advanced Optical Technology Development Division, Corporate R&D, Advanced Semiconductor Engineering (ASE), Inc., Zhubei City, Taiwan (R.O.C.)","2021 16th International Microsystems, Packaging, Assembly and Circuits Technology Conference (IMPACT)","8 Feb 2022","2021","","","42","45","To recognize defects produced in manufacturing (MFG) process becomes a daily in-line and in-time challenge in today's semiconductor industry. This paper presents an AI-assisted defect inspection method for substrates, which are widely used in packaged IC products. With the help of Automated Optical Inspection (AOI) equipment and the adoption of Machine Learning (ML) and Deep Neural Network (DNN) technologies, manual efforts in substrate defect examination have significantly been reduced, and yet it is still insufficient for the high standard required by automatic defect classification task. One big challenge is that while MFG in-process conditions change, the defect variation also occurs. The defect variances may include some uncertain scenarios, such as compound of multiple known defects, or even out-of-domain (OOD), i.e., unknown defect. A question is then raised: can we build an AI model which has capability to address uncertainty just like human reaction when facing unsure situations? In this paper, we introduce a new ML technology AL-VAE which integrates Active Learning (AL) and Variational Autoencoder (VAE) techniques to enhance our field-deployed AOI defect detection flow. The AL can address the uncertainty and filter out the ambiguity, accelerate training convergence, and minimize the training dataset to reduce labeling efforts. The VAE aims at learning deep latent-variable distribution of image, which can reproduce the similar image's feature multiple times from latent space. Aggregating the reproduced samples can significantly increase the uncertainty information, especially for the unknown defects. To demonstrate the advantage of our ML method, the public MS COCO dataset and our MFG substrate-defect dataset are evaluated. The results indicate that our method selects around 50% samples from original training dataset, and the overall accuracy is still kept at the same level. In addition, the uncertainty information aggregating samples reproduced from VAE shows that our model can recognize the difference between trained classes and untrained scenarios. Our technology enhances the field-deployed AI-assisted defect inspection flow with human-like intelligence which can significantly narrows the gap between AI computing and human understanding.","2150-5942","978-1-6654-3191-0","10.1109/IMPACT53160.2021.9696716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9696716","","Training;Optical filters;Uncertainty;Computational modeling;Optical computing;Optical fiber networks;Optical imaging","automatic optical inspection;computer vision;flaw detection;inspection;learning (artificial intelligence);neural nets;pattern classification;semiconductor industry","address uncertainty;package substrate AOI defect detection;manufacturing process;in-time challenge;defect inspection method;packaged IC products;Automated Optical Inspection equipment;Deep Neural Network technologies;manual efforts;substrate defect examination;automatic defect classification task;in-process conditions change;defect variation;defect variances;multiple known defects;unknown defect;AI model;human reaction;ML technology;VAE;field-deployed;defect detection flow;ML method;MFG substrate-defect dataset;original training dataset;uncertainty information aggregating samples;defect inspection flow;human understanding","","","","12","IEEE","8 Feb 2022","","","IEEE","IEEE Conferences"
"Development and Application of Aero-engine Experimental Data Mining Algorithm Library","Z. Yan; H. Zhang; J. Sun; Y. Yang; G. Xia","College of Civil Aviation, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Technology and Engineering Center for Space Utilization, Chinese Academy of Sciences University of Chinese Academy of Sciences, Beijing, China; College of Civil Aviation, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Civil Aviation, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Civil Aviation, Nanjing University of Aeronautics and Astronautics, Nanjing, China","2020 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD)","24 Nov 2020","2020","","","264","269","This paper presents the application of several anomaly detection algorithms in experiment data from engine test bed. Several anomaly detection algorithms are programmed in Python language and integrated into an algorithm library named PyPEFD (Python Package for Engine Fault Detection). The algorithm library includes Gaussian Mixture Model, Feature Weighted Fuzzy Compactness and Separation (WFCS), Sequential Probability Ratio Test (SPRT), Variational Autoencoder, Dynamic Time Warping, Mahalanobis Distance, Singular Value Thresholding, Random Forest and Multivariate State Estimation Technique. These algorithms can analyze the structure and characteristics of the engine test data, and mine the hidden fault information in the data, so as to detect the fault or fault trend of aero-engine test data. This paper also presents a preview of the algorithm library.","","978-1-7281-9277-2","10.1109/ICSMD50554.2020.9261719","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9261719","aero-engine test data;anomaly detection;python algorithm package;data analysis","Engines;Clustering algorithms;Fault detection;Sensors;Libraries;Anomaly detection;Gas detectors","aerospace engines;data mining;fault diagnosis;fuzzy set theory;Gaussian processes;mechanical engineering computing","aero-engine test data;aero-engine experimental data mining algorithm library;anomaly detection algorithms;engine test bed;Python language;Python package;engine fault detection;sequential probability ratio test;feature weighted fuzzy compactness and separation;Gaussian mixture model;dynamic time warping;Mahalanobis distance;singular value thresholding;random forest;multivariate state estimation technique","","","","20","","24 Nov 2020","","","IEEE","IEEE Conferences"
"Generating Out of Distribution Adversarial Attack Using Latent Space Poisoning","U. Upadhyay; P. Mukherjee","Department of Computer Science, Bharati Vidyapeeth's College of Engineering, New Delhi, India; Computer Science Department, School of Engineering, Jawaharlal Nehru University, Delhi, India","IEEE Signal Processing Letters","19 Mar 2021","2021","28","","523","527","Traditional adversarial attacks rely upon the perturbations generated by gradients from the network which are generally safeguarded by gradient guided search to provide an adversarial counterpart to the network. In this letter, we propose a novel framework to generate adversarial examples where the actual image is not corrupted rather its latent space representation is utilized to tamper the inherent structure of the image while maintaining the perceptual quality intact and to act as legitimate data samples. As opposed to gradient-based attacks, the latent space poisoning exploits the inclination of classifiers to model the independent and identical distribution of the training dataset and tricks it by producing out of distribution samples. We train a disentangled variational autoencoder (β-VAE) to model the data in latent space and then we add noise perturbations using a class-conditioned distribution function to the latent space under the constraint that it is misclassified to the target label. Our empirical results on MNIST, SVHN, and CelebA dataset validate that the generated adversarial examples can easily fool robust l0, l2, l∞ norm classifiers designed using provably robust defense mechanisms. The source code is made publicly available at https://github.com/Ujjwal-9/latent-space-poisoning.","1558-2361","","10.1109/LSP.2021.3061327","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9361176","Adversarial attacks;beta -VAEs;classification;latent space poisoning;manifold space","Training;Aerospace electronics;Perturbation methods;Gallium nitride;Smoothing methods;Mathematical model;Data models","data analysis;gradient methods;image classification;image sampling;learning (artificial intelligence);pattern classification;pattern clustering;security of data","distribution adversarial attack;generated adversarial examples;class-conditioned distribution function;noise perturbations;distribution samples;training dataset;identical distribution;independent distribution;legitimate data samples;perceptual quality intact;latent space representation;actual image;adversarial counterpart;gradient guided search;traditional adversarial attacks;latent space poisoning","","","","30","IEEE","23 Feb 2021","","","IEEE","IEEE Journals"
"SubOmiEmbed: Self-supervised Representation Learning of Multi-omics Data for Cancer Type Classification","S. Hashim; M. Ali; K. Nandakumar; M. Yaqub","Mohamed Bin Zayed University of Artificial Intelligence, UAE; Mohamed Bin Zayed University of Artificial Intelligence, UAE; Mohamed Bin Zayed University of Artificial Intelligence, UAE; Mohamed Bin Zayed University of Artificial Intelligence, UAE","2022 10th International Conference on Bioinformatics and Computational Biology (ICBCB)","23 Jun 2022","2022","","","66","72","For personalized medicines, very crucial intrinsic information is present in high dimensional omics data which is difficult to capture due to the large number of molecular features and small number of available samples. Different types of omics data show various aspects of samples. Integration and analysis of multi-omics data give us a broad view of tumours, which can improve clinical decision making. Omics data, mainly DNA methylation and gene expression profiles are usually high dimensional data with a lot of molecular features. In recent years, variational autoencoders (VAE) [1] have been extensively used in embedding image and text data into lower dimensional latent spaces. In our work, we extend the idea of using a VAE model for low dimensional latent space extraction with the self-supervised learning technique of feature subsetting. With VAEs, the key idea is to make the model learn meaningful representations from different types of omics data, which could then be used for downstream tasks such as cancer type classification. The main goals are to overcome the curse of dimensionality and integrate methylation and expression data to combine information about different aspects of same tissue samples, and hopefully extract biologically relevant features. Our extension involves training encoder and decoder to reconstruct the data from just a subset of it. By doing this, we force the model to encode most important information in the latent representation. We also added an identity to the subsets so that the model knows which subset is being fed into it during training and testing. We experimented with our approach and found that SubOmiEmbed produces comparable results to the baseline OmiEmbed [2] with a much smaller network and by using just a subset of the data. This work can be improved to integrate mutation-based genomic data as well.","","978-1-6654-0108-1","10.1109/ICBCB55259.2022.9802478","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9802478","self-supervised learning;cancer type classification;feature subsetting","Training;Representation learning;Biological system modeling;Genomics;Feature extraction;Data models;Convolutional neural networks","bioinformatics;biology computing;cancer;data analysis;data handling;decision making;DNA;feature extraction;genetics;genomics;learning (artificial intelligence);molecular biophysics;pattern classification;tumours","low dimensional latent space extraction;self-supervised learning technique;feature subsetting;VAE;cancer type classification;methylation;expression data;subset;mutation-based genomic data;representation learning;multiomics data;high dimensional omics data;molecular features;gene expression profiles;dimensional data;embedding image;text data;lower dimensional latent spaces","","","","25","IEEE","23 Jun 2022","","","IEEE","IEEE Conferences"
"Composite Travel Generative Adversarial Networks for Tabular and Sequential Population Synthesis","G. Badu-Marfo; B. Farooq; Z. Patterson","Department of Civil Engineering, Laboratory of Innovations in Transportation (LiTrans), Ryerson University, Toronto, Canada; Department of Civil Engineering, Laboratory of Innovations in Transportation (LiTrans), Ryerson University, Toronto, Canada; Department of Geography, Planning and Environment, TRIP Laboratory, Concordia University, Montreal, Canada","IEEE Transactions on Intelligent Transportation Systems","12 Oct 2022","2022","23","10","17976","17985","Agent-based microsimulation has become the standard to analyze intelligent transportation systems, using disaggregate travel demand data for entire populations, data that are not typically readily available. Population synthesis approaches are thus needed. We present Composite Travel Generative Adversarial Network (CTGAN), a novel deep generative model to estimate the underlying joint distribution of a population, that is capable of reconstructing composite synthetic agents having tabular (e.g. age and sex) as well as sequential mobility data (e.g. trip trajectory and sequence). The CTGAN model is compared with other recently proposed methods such as the Variational Autoencoders (VAE) method, which has shown success in high dimensional tabular population synthesis. We evaluate the performance of the synthesized outputs based on distribution similarity, multi-variate correlations and spatio-temporal metrics. The results show the consistent and accurate generation of synthetic populations and their tabular and spatially sequential attributes, generated over varying spatial scales and dimensions.","1558-0016","","10.1109/TITS.2022.3168232","Canada Research Program(grant numbers:CRC-2017-00038); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9765790","Population synthesis;generative adversarial networks;generative models;tabular data;sequential data;microsimulation;agent based modelling","Statistics;Sociology;Data models;Generative adversarial networks;Training;Linear programming;Generators","","","","","","31","IEEE","29 Apr 2022","","","IEEE","IEEE Journals"
"Interactive Multi-Level Prosody Control for Expressive Speech Synthesis","T. Cornille; F. Wang; J. Bekker","KU Leuven, Belgium; Acapela-Group, Mons, Belgium; KU Leuven, Belgium","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","8312","8316","Recent neural-based text-to-speech (TTS) models are able to produce highly natural speech. To synthesize expressive speech, the prosody of the speech has to be modeled, and predicted/controlled during synthesis. However, intuitive control over prosody remains elusive. Some techniques only allow control over the global style of the speech and do not allow fine-grained adjustments. Other techniques create fine-grained prosody embeddings, but these are difficult to manipulate to obtain a desired speaking style. We thus present ConEx, a novel model for expressive speech synthesis, which can produce speech in a certain speaking style, while also allowing local adjustments to the prosody of the generated speech. The model builds upon the non-autoregressive architecture of FastSpeech and includes a reference encoder to learn global prosody embeddings, and a vector quantized variational autoencoder to create fine-grained prosody embeddings. To realize prosody manipulation, a new interactive method is proposed. Experiments on two datasets show that the model enables multi-level prosody control.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746654","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746654","speech synthesis;text-to-speech;prosody;controllability;hierarchical prosody embedding","Conferences;Natural languages;Signal processing;Predictive models;Speech;Acoustics;Speech synthesis","interactive systems;speech coding;speech synthesis","text-to-speech models;highly natural speech;intuitive control;speech synthesis;generated speech;global prosody embeddings;prosody manipulation;interactive multilevel prosody control;fine grained prosody embeddings;fine grained adjustments;expressive speech synthesis;TTS models;ConEx","","","","31","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"SF-Net: A Multi-Task Model for Brain Tumor Segmentation in Multimodal MRI via Image Fusion","Y. Liu; F. Mu; Y. Shi; X. Chen","Anhui Province Key Laboratory of Measuring Theory and Precision Instrument, Hefei University of Technology, Hefei, China; Anhui Province Key Laboratory of Measuring Theory and Precision Instrument, Hefei University of Technology, Hefei, China; Anhui Province Key Laboratory of Measuring Theory and Precision Instrument, Hefei University of Technology, Hefei, China; Department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei, China","IEEE Signal Processing Letters","26 Aug 2022","2022","29","","1799","1803","Automatic segmentation of brain tumor regions from multimodal MRI scans is of great clinical significance. In this letter, we propose a “Segmentation-Fusion” multi-task model named SF-Net for brain tumor segmentation. In comparison to the widely-used multi-task model that adds a variational autoencoder (VAE) decoder to reconstruct the input data, using image fusion as an additional regularization for feature learning helps to achieve more sufficient fusion of multimodal features, which is beneficial to the multimodal image segmentation problem. To further improve the performance of the multi-task model, an uncertainty-based approach that can adaptively adjust the loss weights of different tasks during the training process is introduced for model training. Experimental results on the BraTS 2020 benchmark demonstrate that the proposed method can achieve higher segmentation accuracy than the VAE-based approach. In addition, as the by-product of the multi-task model, the image fusion results obtained are of high quality on the brain tumor regions. The source code of the proposed method is available at https://github.com/yuliu316316/SF-Net.","1558-2361","","10.1109/LSP.2022.3198594","National Natural Science Foundation of China(grant numbers:62176081,61922075); Fundamental Research Funds for the Central Universities(grant numbers:JZ2020HGPA0111); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9855845","Brain tumor segmentation;medical image fusion;multimodal MRI;multi-task learning","Image segmentation;Tumors;Task analysis;Multitasking;Brain modeling;Image fusion;Training","biomedical MRI;brain;image fusion;image segmentation;medical image processing;tumours","brain tumor regions;multimodal MRI scans;SF-Net;brain tumor segmentation;multimodal features;multimodal image segmentation problem;image fusion;automatic segmentation;segmentation-fusion multitask model;BraTS-2020 benchmark","","","","38","IEEE","15 Aug 2022","","","IEEE","IEEE Journals"
"Improving Phishing Detection with the Grey Wolf Optimizer","A. N. Jaber; L. Fritsch; H. Haugerud","Artificial Intelligence Lab, OsloMet - Oslo Metropolitan University, Oslo, Norway; Department of Computer Science, OsloMet - Oslo Metropolitan University, Oslo, Norway; Department of Computer Science, OsloMet - Oslo Metropolitan University, Oslo, Norway","2022 International Conference on Electronics, Information, and Communication (ICEIC)","11 Apr 2022","2022","","","1","6","With the recent epidemic of COVID-19-themed scam and phishing, the efficient automated detection of such attacks is crucial. Although many anti-phishing solutions, such as lists and similarity and heuristic-based approaches detect attacks, methods still can be improved. Classification accuracy is highly dependent on the feature selection method used to select appropriate features for classification. In this article, a multi-objective grey wolf optimizer is used to select proper features for classifying phishing websites through a variational autoencoder. Our results indicate the superiority of the classification rate compared with related work: A classification rate of 97.49%, is obtained, thereby suggesting the feasibility of evaluating our work.","2767-7699","978-1-6654-0934-6","10.1109/ICEIC54506.2022.9748592","Research Council of Norway(grant numbers:303585); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9748592","cybersecurity;phishing website detection;anti-phishing;machine learning","COVID-19;Epidemics;Phishing;Feature extraction;Computer crime","computer crime;feature extraction;grey systems;optimisation;pattern classification;unsolicited e-mail;Web sites","proper features;multiobjective grey wolf optimizer;feature selection method;classification accuracy;heuristic-based approaches;lists;anti-phishing solutions;efficient automated detection;recent epidemic;phishing detection;classification rate;phishing websites","","","","35","IEEE","11 Apr 2022","","","IEEE","IEEE Conferences"
"Generating Emotional Coherence and Diverse Responses in a Multimodal Dialogue System","Y. Huang; K. Li; Z. Chen; L. Wang","School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Nanjing Three-eye Spirit Information Technology Co., Ltd; Nanjing Three-eye Spirit Information Technology Co., Ltd","2021 2nd International Conference on Electronics, Communications and Information Technology (CECIT)","1 Apr 2022","2021","","","625","630","The perception of emotion and the diversity of generated response are two key factors considered by researchers in multimodal dialogue generation. However, in the field of multimodal dialogue generation, these two key factors have not been considered at the same time. In our model, we first extract the features of each modal from the multimodal context dialogue, and use the heterogeneous graph neural network to represent the large graph network composed of dialogue history, voice, video, and speaker's emotional state. Then, we use conditional variational autoencoders to generate coherent and diverse responses. A large number of experiments have shown that our model can not only automatically generate reaction emotions in two multimodal datasets, but also has coherence and controllability, which is significantly better than previous more advanced models.","","978-1-6654-3757-8","10.1109/CECIT53797.2021.00115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9742230","Dialogue system;CVAE;emotional dialogue generation;Graph heterogeneous neural network","Visualization;Coherence;Feature extraction;Controllability;Graph neural networks;Data models;Information and communication technology","emotion recognition;graph theory;interactive systems;learning (artificial intelligence);neural nets","emotional coherence;multimodal dialogue generation;multimodal context dialogue;heterogeneous graph neural network;dialogue history;reaction emotions;multimodal datasets;speakers emotional state","","","","32","IEEE","1 Apr 2022","","","IEEE","IEEE Conferences"
"Design Methodology for Deep Out-of-Distribution Detectors in Real-Time Cyber-Physical Systems","M. Yuhas; D. J. Xian Ng; A. Easwaran","Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore","2022 IEEE 28th International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA)","3 Oct 2022","2022","","","180","185","When machine learning (ML) models are supplied with data outside their training distribution, they are more likely to make inaccurate predictions; in a cyber-physical system (CPS), this could lead to catastrophic system failure. To mitigate this risk, an out-of-distribution (OOD) detector can run in parallel with an ML model and flag inputs that could lead to undesirable outcomes. Although OOD detectors have been well studied in terms of accuracy, there has been less focus on deployment to resource constrained CPSs. In this study, a design methodology is proposed to tune deep OOD detectors to meet the accuracy and response time requirements of embedded applications. The methodology uses genetic algorithms to optimize the detector’s preprocessing pipeline and selects a quantization method that balances robustness and response time. It also identifies several candidate task graphs under the Robot Operating System (ROS) for deployment of the selected design. The methodology is demonstrated on two variational autoencoder based OOD detectors from the literature on two embedded platforms. Insights into the trade-offs that occur during the design process are provided, and it is shown that this design methodology can lead to a drastic reduction in response time in relation to an unoptimized OOD detector while maintaining comparable accuracy.","2325-1301","978-1-6654-5344-8","10.1109/RTCSA55878.2022.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9904799","","Training;Quantization (signal);Design methodology;Pipelines;Detectors;Cyber-physical systems;Real-time systems","","","","","","14","IEEE","3 Oct 2022","","","IEEE","IEEE Conferences"
"VAE for Joint Source-Channel Coding of Distributed Gaussian Sources over AWGN MAC","Y. Malur Saidutta; A. Abdi; F. Fekri","School of ECE, Georgia Institute of Technology, Atlanta, U.S.A; School of ECE, Georgia Institute of Technology, Atlanta, U.S.A; School of ECE, Georgia Institute of Technology, Atlanta, U.S.A","2020 IEEE 21st International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)","3 Aug 2020","2020","","","1","5","In this paper, we introduce a framework for Joint Source-Channel Coding of distributed Gaussian sources over a multiple access AWGN channel. Although there are prior works that have studied this, they either strongly rely on intuition to design encoders and decoder or require the knowledge of the complete joint distribution of all the distributed sources. Our system overcomes this. We model our system as a Variational Autoencoder and leverage insight provided by this connection to propose a crucial regularization mechanism for learning. This allows us to beat the state of the art by improving the signal reconstruction quality by almost 1dB for certain configurations. The end-to-end learned system is also found to be robust to channel condition variations of ±5dB and shows a drop in signal reconstruction quality by at most 1dB. Finally, we propose a novel lower bound on the optimal distortion in signal reconstruction and empirically showcase the tightness of the bound in comparison with the existing bound.","1948-3252","978-1-7281-5478-7","10.1109/SPAWC48557.2020.9154331","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9154331","joint source-channel coding;distributed encoding;multiple access channels;machine learning;deep learning","Distortion;Neural networks;Wireless communication;Channel coding;AWGN channels;Decoding","AWGN channels;combined source-channel coding;interference suppression;multiuser channels;parameter estimation;signal detection;signal reconstruction","leverage insight;signal reconstruction quality;end-to-end learned system;Joint Source-Channel Coding;distributed Gaussian sources;AWGN MAC;multiple access AWGN channel;complete joint distribution;distributed sources;noise figure 1.0 dB;noise figure 5.0 dB","","","","19","","3 Aug 2020","","","IEEE","IEEE Conferences"
"Speaker Characteristics Guided Speech Synthesis","Z. Yang; Z. Wu; J. Jia","Shenzhen International Graduate School Tsinghua University, Shenzhen, China; Shenzhen International Graduate School Tsinghua University, Shenzhen, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China","2022 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2022","2022","","","1","8","Talking head techniques are widely researched. Most of the previous works focus on the association among tones, prosody, and visual cues, such as head motion, lip movement, and gestures. However, it is widely believed the timbre, matching the voice with the speaker's identity, shall be considered, since people obtain speaker-specific information from both the auditory and visual modalities. This paper aims to generate proper voice characteristics in line with the speaker characteristics we select. We first select six speaker characteristics related to the voice qualities: gender, age, race, body mass index, face shape, and personality. We then train a Conditional Variational AutoEncoder with attention (attentionCVAE) model to infer speaker embeddings from speaker characteristics and employ a multi-speaker text-to-speech system to generate utterances of nonexistent speakers we set. Subjective tests indicate the proposed method successfully reconstructs real-world speaker embedding and generates realistic embedding from speaker characteristics. The further analysis uncovers how and to what extent the speaker characteristics influence the voice qualities of speakers.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9892169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9892169","Speaker characteristics;speech synthesis;visual-auditory consistency;voice qualities","Visualization;Correlation;Shape;Lips;Neural networks;Timbre;Speech synthesis","","","","","","50","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"Defense-CycleGAN: A Defense Mechanism Against Adversarial Attacks Using CycleGAN to Reconstruct Clean Images","Z. He; M. Singhal","Electrical Engineering & Computer Science, University of California, Merced, Merced, CA; Electrical Engineering & Computer Science, University of California, Merced, Merced, CA","2022 3rd International Conference on Pattern Recognition and Machine Learning (PRML)","13 Sep 2022","2022","","","173","179","Deep Neural Networks (DNNs) approaches have been used successfully in various computer vision tasks. However, they are particularly susceptible to adversarial attacks, which can cause incorrect predictions and raise security risk to real-world deep learning applications, e.g., autonomous driving and surveillance systems. Many state-of-the-art adversarial defense models use Variational Autoencoder Decoder (VAE) to reconstruct clean images to counter adversarial attacks. However, images reconstructed from VAEs are often blurry, thus, not only their use for classification is limited, but also such defense methods blur the benign inputs and impair the accuracy when there is no adversarial attack. We propose to use Cycle Consistency GAN (CycleGAN) as the image reconstruction block, which generates higher quality images for better classification performance. Our method achieves 5%-13% higher accuracy than the best VAE-based defense models on CIFAR10 and achieves 90%-98% accuracy for Fashion-MNIST across wide range of adversarial attacks.","","978-1-6654-9950-7","10.1109/PRML56267.2022.9882238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9882238","Adversarial Defense;Adversarial Learning;CycleGAN;VAE","Deep learning;Surveillance;Perturbation methods;Neural networks;Generative adversarial networks;Pattern recognition;Decoding","computer vision;feature extraction;image classification;image reconstruction;learning (artificial intelligence);neural nets;security of data","defense-CycleGAN;defense mechanism;adversarial attack;clean images;Deep Neural Networks approaches;state-of-the-art adversarial defense models;defense methods;image reconstruction block;higher quality images;VAE-based defense models","","","","55","IEEE","13 Sep 2022","","","IEEE","IEEE Conferences"
"Towards Group Fairness via Semi-Centralized Adversarial Training in Federated Learning","Y. Yang; B. Jiang","State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China","2022 23rd IEEE International Conference on Mobile Data Management (MDM)","25 Aug 2022","2022","","","482","487","As federated learning increasingly performs better on tasks of decision-making scenarios such as medical care or commercial area, there have been concerns about discrimination against certain populations with sensitive attributes (e.g., race, gender). In this work, we propose to improve group fairness with semi-centralized adversarial training. And we adopt Variational AutoEncoder (VAE) for federated learning scenarios to generate adversarial samples. We keep VAE decoder at server side and leave encoder at client side to encode local samples into feature dimensions for transmitting, which ensures the privacy of user data. Our proposal further performs sensitive attribute alignment to improve group fairness. Our experimental evaluation shows that our approach outperforms the state-of-the-art federated learning frameworks in terms of group fairness and communication resource consumption.","2375-0324","978-1-6654-5176-5","10.1109/MDM55031.2022.00103","National Key R&D Program of China(grant numbers:2019YFB,1705902); NSFC(grant numbers:61772056); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9861177","Federated learning;Group Fairness;Adversarial Training","Training;Privacy;Decision making;Sociology;Collaborative work;Proposals;Servers","data privacy;decision making;learning (artificial intelligence)","towards group fairness;semicentralized adversarial training;decision-making scenarios;medical care;sensitive attributes;federated learning scenarios;adversarial samples;VAE decoder;sensitive attribute alignment;state-of-the-art federated learning","","","","21","IEEE","25 Aug 2022","","","IEEE","IEEE Conferences"
"Corrections to “Unsupervised Anomaly Detection of Industrial Robots Using Sliding-Window Convolutional Variational Autoencoder”","T. Chen; X. Liu; B. Xia; W. Wang; Y. Lai","Graduate School at Shenzhen, Tsinghua University, Shenzhen, China; Graduate School at Shenzhen, Tsinghua University, Shenzhen, China; Graduate School at Shenzhen, Tsinghua University, Shenzhen, China; Sunwoda Electronic Company, Shenzhen, China; Sunwoda Electronic Company, Shenzhen, China","IEEE Access","30 Jun 2020","2020","8","","117062","117062","Presents corrections to the above mentioned paper.","2169-3536","","10.1109/ACCESS.2020.3004098","Shenzhen Economic, Trade and Information Commission of Shenzhen; CMunicipality Strategic Emerging Industries and Future Industrial Development “Innovation Chain + Industrial. Chain” Project (2017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9130173","","Unsupervised learning;Anomaly detection;Service robots","","","","2","","2","CCBY","30 Jun 2020","","","IEEE","IEEE Journals"
