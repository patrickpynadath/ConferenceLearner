"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Improved denoising autoencoder for maritime image denoising and semantic segmentation of USV","Y. Qiu; Y. Yang; Z. Lin; P. Chen; Y. Luo; W. Huang","Electronic Information Engineering, Fuzhou University, Fuzhou, China; Nautical College, Jimei University, Xiamen, China; Electronic Information Engineering, Fuzhou University, Fuzhou, China; Electronic Information Engineering, Fuzhou University, Fuzhou, China; Electronic Information Engineering, Fuzhou University, Fuzhou, China; Electronic Information Engineering, Fuzhou University, Fuzhou, China","China Communications","7 Apr 2020","2020","17","3","46","57","Unmanned surface vehicle (USV) is currently a hot research topic in maritime communication network (MCN), where de-noising and semantic segmentation of maritime images taken by USV have been rarely studied. The former has recently researched on autoencoder model used for image denoising, but the existed models are too complicated to be suitable for real-time detection of USV. In this paper, we proposed a lightweight autoencoder combined with inception module for maritime image denoising in different noisy environments and explore the effect of different inception modules on the denoising performance. Furthermore, we completed the semantic segmentation task for maritime images taken by USV utilizing the pretrained U-Net model with tuning, and compared them with original U-Net model based on different backbone. Subsequently, we compared the semantic segmentation of noised and denoised maritime images respectively to explore the effect of image noise on semantic segmentation performance. Case studies are provided to prove the feasibility of our proposed denoising and segmentation method. Finally, a simple integrated communication system combining image denoising and segmentation for USV is shown.","1673-5447","","10.23919/JCC.2020.03.005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9058605","USV;denoising;autoencoder;semantic segmentation;U-Net","Image segmentation;Noise reduction;Image denoising;Semantics;Feature extraction;Training;Noise measurement","image denoising;image segmentation;marine communication;marine robots;neural nets;object detection","MCN;improved denoising autoencoder;semantic segmentation task;maritime communication network;unmanned surface vehicle;maritime image denoising;USV;image noise;U-Net model","","11","","","","7 Apr 2020","","","IEEE","IEEE Magazines"
"Denoising hybrid noises in image with stacked autoencoder","X. Ye; L. Wang; H. Xing; L. Huang","College of Automation, Harbin Engineering University, Harbin, Heilongjiang Province, China; College of Automation, Harbin Engineering University, Harbin, Heilongjiang Province, China; College of Automation, Harbin Engineering University, Harbin, Heilongjiang Province, China; College of Automation, Harbin Engineering University, Harbin, Heilongjiang Province, China","2015 IEEE International Conference on Information and Automation","1 Oct 2015","2015","","","2720","2724","A method based on sparse denoising autoencoder for denoising hybrid noises in image is proposed in this paper. The method is experimented on natural images and the performance is evaluated in terms of peak signal to noise ratio (PSNR). By specifically designing the training process of sparse denoising autoencoder, our model not only achieves good performance on single kind of noises, but also is relatively robust to mixed noises, which are more widely existed in practical situation. Autoencoder is a major branch of deep learning. It has been used in many applications as the method to exact features for its ability to represent the input data. Applying autoencoder to image denoising has been achieved good performance. Further research was deployed to find that autoencoder method is relatively robust compared with BM3D. And a sparse denoising autoencoder model is employed to train the network and it works well for the hybrid noise situation.","","978-1-4673-9104-7","10.1109/ICInfA.2015.7279746","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7279746","image denoising;stacked sparse denoising autoencoder;deep learning","Noise;Noise reduction;Training;Image denoising;Testing;Speckle;Neural networks","feature extraction;image denoising;natural scenes;performance evaluation","image denoising;hybrid noise;stacked autoencoder;natural image;performance evaluation;peak signal to noise ratio;PSNR;training process;deep learning;feature extraction;sparse denoising autoencoder model","","11","","13","","1 Oct 2015","","","IEEE","IEEE Conferences"
"Comparative analysis of the denoising effect of unstructured vs. convolutional autoencoders","S. Majeed; Y. Mansoor; S. Qabil; F. Majeed; B. Khan","Department of Computer Science, National University of Computer and Emerging Sciences, Karachi, Pakistan; Department of Computer Science, National University of Computer and Emerging Sciences, Karachi, Pakistan; Department of Computer Science, National University of Computer and Emerging Sciences, Karachi, Pakistan; Department of Computer Science, National University of Computer and Emerging Sciences, Karachi, Pakistan; Department of Computer Science, National University of Computer and Emerging Sciences, Karachi, Pakistan","2020 International Conference on Emerging Trends in Smart Technologies (ICETST)","30 Apr 2020","2020","","","1","5","Adding noise to data affects the prediction of a discriminator. Some like a deep neural network extract features directly from inputs, where the quality of the features may be affected by the amount of the noise. A deep neural model specifically meant for feature extraction is the autoencoder, while it has also been extended to perform denoising. In this paper, we investigate the denoising effect of an encoder on different nature as well as different amounts of additive noise. The experiments are evaluated on a linearized autoencoder as well as a convolutional autoencoder, which is especially meant for image data. Denoising Autoencoders (DAE) and Convolutional Denoising Autoencoders (CDAE) are evaluated by introducing with Gaussian, Salt and Pepper, and Poisson types of noise with a factor of 0.5. The results shows 0.12, 0.09, 0.47 Mean Squared Error (MSE) for DAE and 0.13, 0.10 and 0.9 MSE in case of CDAE with the same amount of noise factor added, alluding to the insight that a lack of focus on structure in the model may help it focus more on the denoising task.","","978-1-7281-7113-5","10.1109/ICETST49965.2020.9080731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9080731","Image denoising;CNN;denoising autoencoder;convolutional denoising autoencoder","","convolutional neural nets;feature extraction;Gaussian processes;image denoising;mean square error methods","convolutional autoencoder;deep neural model;feature extraction;additive noise;image data;convolutional denoising autoencoders;noise factor;mean squared error","","1","","13","","30 Apr 2020","","","IEEE","IEEE Conferences"
"Adversarial Autoencoders for Denoising Digitized Historical Documents: The Use Case of Incunabula","H. Neji; J. Nogueras-Iso; J. Lacasta; M. Ben Halima; A. M. Alimi","University of Gabes, Tunisia; I3A, Universidad de Zaragoza, Spain; I3A, Universidad de Zaragoza, Spain; REGIM-Lab., University of Sfax, Sfax, Tunisia; REGIM-Lab.: REsearch Groups in Intelligent Machines, University of Sfax, Tunisia","2019 International Conference on Document Analysis and Recognition Workshops (ICDARW)","7 Nov 2019","2019","6","","31","34","Historical document denoising is the most challenging step in the field of image processing and computer vision. In this paper, we propose a novel end-to-end adversarial autoencoder (AAE) to generate clean images and to show how adversarial autoencoders can be used in historical document denoising. We used the Adversarial Autoencoder (AAE), which uses the generative adversarial networks (GAN) so as to suit the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior. The experiments results prove that our approach functions more positively than the cutting-edge approaches on synthetic and real world images at a lower computational cost as well.","","978-1-7281-5054-3","10.1109/ICDARW.2019.50112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8893133","Adversarial Autoencoder;GAN;incunabula documents;image denoising;historical document images","Noise reduction;Generative adversarial networks;Generators;Training;Image reconstruction;Image denoising;Optical character recognition software","computer vision;document image processing;image denoising;neural nets","adversarial autoencoders;image processing;computer vision;AAE;clean images;generative adversarial networks;digitized historical document denoising;incunabula;aggregated posterior;hidden code vector","","2","","15","","7 Nov 2019","","","IEEE","IEEE Conferences"
"Medical Image Denoising Using Convolutional Denoising Autoencoders","L. Gondara","Department of Computer Science, Simon Fraser University","2016 IEEE 16th International Conference on Data Mining Workshops (ICDMW)","2 Feb 2017","2016","","","241","246","Image denoising is an important pre-processing step in medical image analysis. Different algorithms have been proposed in past three decades with varying denoising performances. More recently, having outperformed all conventional methods, deep learning based models have shown a great promise. These methods are however limited for requirement of large training sample size and high computational costs. In this paper we show that using small sample size, denoising autoencoders constructed using convolutional layers can be used for efficient denoising of medical images. Heterogeneous images can be combined to boost sample size for increased denoising performance. Simplest of networks can reconstruct images with corruption levels so high that noise and signal are not differentiable to human eye.","2375-9259","978-1-5090-5910-2","10.1109/ICDMW.2016.0041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836672","Image denoising;denoising autoencoder;convolutional autoencoder","Noise reduction;Training;Noise measurement;Noise level;Convolutional codes;Image denoising;Biomedical imaging","convolutional codes;image denoising;image reconstruction;learning (artificial intelligence);medical image processing","medical image denoising;convolutional denoising autoencoders;medical image analysis;denoising performances;deep learning-based models;heterogeneous images;image reconstruction","","232","4","33","","2 Feb 2017","","","IEEE","IEEE Conferences"
"Robust and efficient data transmission over noisy communication channels using stacked and denoising autoencoders","F. N. Khan; A. P. T. Lau","Hong Kong Polytechnic University, Kowloon, HK; Hong Kong Polytechnic University, Kowloon, HK","China Communications","30 Aug 2019","2019","16","8","72","82","We study the effects of quantization and additive white Gaussian noise (AWGN) in transmitting latent representations of images over a noisy communication channel. The latent representations are obtained using autoencoders (AEs). We analyze image reconstruction and classification performance for different channel noise powers, latent vector sizes, and number of quantization bits used for the latent variables as well as AEs' parameters. The results show that the digital transmission of latent representations using conventional AEs alone is extremely vulnerable to channel noise and quantization effects. We then propose a combination of basic AE and a denoising autoencoder (DAE) to denoise the corrupted latent vectors at the receiver. This approach demonstrates robustness against channel noise and quantization effects and enables a significant improvement in image reconstruction and classification performance particularly in adverse scenarios with high noise powers and significant quantization effects.","1673-5447","","10.23919/JCC.2019.08.007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820761","communication channels;data compression;deep learning;autoencoders;denoising autoencoders","Quantization (signal);Image reconstruction;Image coding;Receivers;Decoding;Training;Noise measurement","AWGN channels;data compression;image classification;image coding;image denoising;image reconstruction;image representation;learning (artificial intelligence);vectors","latent vector sizes;receiver;corrupted latent vector denoising;channel noise powers;AEs parameters;quantization effects;high noise powers;denoising autoencoder;digital transmission;latent variables;quantization bits;latent vector;classification performance;image reconstruction;latent representations;additive white Gaussian noise;noisy communication channel;robust data transmission","","8","","","","30 Aug 2019","","","IEEE","IEEE Magazines"
"PCB Defect Detection Using Denoising Convolutional Autoencoders","S. Khalilian; Y. Hallaj; A. Balouchestani; H. Karshenas; A. Mohammadi","Computer Engineering, University of Isfahan, Isfahan, Iran; Computer Engineering, University of Isfahan, Isfahan, Iran; Computer Engineering, University of Isfahan, Isfahan, Iran; Computer Engineering, University of Isfahan, Isfahan, Iran; Industrial Automation Unit, Pardisan Rayaneh System Company, Isfahan, Iran","2020 International Conference on Machine Vision and Image Processing (MVIP)","14 Sep 2020","2020","","","1","5","Printed Circuit boards (PCBs) are one of the most important stages in making electronic products. A small defect in PCBs can cause significant flaws in the final product. Hence, detecting all defects in PCBs and locating them is essential. In this paper, we propose an approach based on denoising convolutional autoencoders for detecting defective PCBs and to locate the defects. Denoising autoencoders take a corrupted image and try to recover the intact image. We trained our model with defective PCBs and forced it to repair the defective parts. Our model not only detects all kinds of defects and locates them, but it can also repair them as well. By subtracting the repaired output from the input, the defective parts are located. The experimental results indicate that our model detects the defective PCBs with high accuracy (97.5%) compare to state of the art works.","2166-6784","978-1-7281-6832-6","10.1109/MVIP49855.2020.9187485","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187485","PCB;defect detection;autoencoder;denoising convolutional autoencoders","Noise reduction;Machine learning;Feature extraction;Maintenance engineering;Noise measurement;Inspection","automatic optical inspection;convolutional neural nets;electronic engineering computing;image denoising;object detection;printed circuits","electronic products;denoising autoencoders;Printed Circuit boards;denoising convolutional autoencoders;PCB defect detection","","6","","","","14 Sep 2020","","","IEEE","IEEE Conferences"
"Facial Image Denoising Using Convolutional Autoencoder Network","N. M. Tun; A. I. Gavrilov; N. L. Tun","Bauman Moscow State Technical University, Moscow, Russia; Bauman Moscow State Technical University, Moscow, Russia; Bauman Moscow State Technical University, Moscow, Russia","2020 International Conference on Industrial Engineering, Applications and Manufacturing (ICIEAM)","9 Jun 2020","2020","","","1","5","Noise effects can interfere the face recognition process in outdoor conditions. Therefore, image denoising topic is the classical issue in the field of image processing and computer vision subjects. In this paper, we show that the solution of denoising process using the autoencoder networks based on the ORL face database. The proposed method can support face recognition systems designed for use in an outdoor environment as the preprocessing stage and it can provide the effective results after training process.","","978-1-7281-4590-7","10.1109/ICIEAM48468.2020.9112080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9112080","Autoencoder;image denoising;face recognition;convolutional neural networks","Training;Image recognition;Databases;Face recognition;Noise reduction;Neural networks;Industrial engineering","computer vision;face recognition;image denoising;neural nets","ORL face database;face recognition systems;outdoor environment;effective results;training process;facial image denoising;convolutional autoencoder network;noise effects;face recognition process;image denoising topic;image processing;computer vision subjects;autoencoder networks","","6","","16","","9 Jun 2020","","","IEEE","IEEE Conferences"
"Denoising Hyperspectral Field Spectra of Vegetation with a Prosail-Fed Denoising Autoencoder","Z. Wu; Q. Qin","Institute of Remote Sensing and Geographical Information Systems, School of Earth and Space Sciences, Peking University, Beijing, China; Institute of Remote Sensing and Geographical Information Systems, School of Earth and Space Sciences, Peking University, Beijing, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","5857","5860","Hyperspectral field spectra are an essential foundation for the construction and evaluation of many vegetation indices and vegetation models. However, they are often contaminated by water vapor absorption and instrument noise. In this paper, a new denoising method based on a denoising autoencoder (DAE) is proposed, which was trained with simulated spectra generated by the radiative transfer model, PROSAIL. The performance of this new method was evaluated on both simulated and real-world spectra and was compared to that of several most used spectral denoising methods. Although limited by the soil spectra used for dataset generation, DAE looks remarkably promising in the denoising of vegetation field spectra, and works especially well in the removal of water vapor effects.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554538","National Natural Science Foundation of China(grant numbers:42071314); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554538","spectral denoising;hyperspectral;denoising auto encoder;PROSAIL;vegetation spectra","Reflectivity;Smoothing methods;Instruments;Noise reduction;Vegetation mapping;Training data;Vegetation","geophysical signal processing;neural nets;radiative transfer;remote sensing;signal denoising;soil;vegetation;vegetation mapping","prosail-fed denoising autoencoder;vegetation indices;vegetation models;water vapor absorption;instrument noise;DAE;radiative transfer model;real-world spectra;spectral denoising methods;soil spectra;vegetation field spectra;water vapor effects;hyperspectral field spectra","","","","7","","12 Oct 2021","","","IEEE","IEEE Conferences"
"Hyperspectral Stimulated Raman Scattering microscopy image denoising via a Deep Convolutional Autoencoder","P. Abdolghader; A. F. Pegoraro; A. Ridsdale; A. Stolow; I. Tamblyn","Department of Physics, University of Ottawa, Ottawa, ON, Canada; Department of Physics, University of Ottawa, Ottawa, ON, Canada; Security and Disruptive Technologies, National Research Council Canada, Ottawa, ON, Canada; Department of Physics, University of Ottawa, Ottawa, ON, Canada; Department of Physics, University of Ottawa, Ottawa, ON, Canada","2020 Photonics North (PN)","17 Aug 2020","2020","","","1","1","We demonstrate the use of a Convolutional Denoising Autoencoder Neural Network to denoise Hyperspectral Stimulated Raman Scattering microscopy images.","","978-1-7281-8108-0","10.1109/PN50013.2020.9166931","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9166931","Stimulated Raman Microscopy-Deep Convolutional Autoencoder-Hyperspectral Image Denoising","Power lasers;Hyperspectral imaging;Noise reduction;Laser noise;Image reconstruction;Convolution;Pump lasers","biomedical optical imaging;coherent antiStokes Raman scattering;image denoising;neural nets;optical microscopy;Raman spectra;stimulated Raman scattering","microscopy image;deep convolutional autoencoder;Convolutional Denoising Autoencoder Neural Network;Hyperspectral Stimulated Raman Scattering microscopy images","","","","5","","17 Aug 2020","","","IEEE","IEEE Conferences"
"A Multi-Level-Denoising Autoencoder Approach for Wind Turbine Fault Detection","X. Wu; G. Jiang; X. Wang; P. Xie; X. Li","School of Electrical Engineering, Yanshan University, Qinhuangdao, China; School of Electrical Engineering, Yanshan University, Qinhuangdao, China; School of Electrical Engineering, Yanshan University, Qinhuangdao, China; School of Electrical Engineering, Yanshan University, Qinhuangdao, China; National Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal University, Beijing, China","IEEE Access","15 May 2019","2019","7","","59376","59387","The effective fault detection of wind turbines (WTs) can greatly help to improve their availability and reduce their operation and maintenance costs. In this context, data-driven fault detection approaches have attracted a lot of interests due to the availability of a large amount of monitoring sensor data containing rich information related to health conditions of WTs. However, sensor data collected from WTs are naturally multivariate and highly nonlinear correlated with redundant information and significantly contaminated measurement noise, which makes the WT fault detection more challenging. To this end, this paper develops a multivariate data-driven fault detection (MDFD) framework based on a recently emerged neural network algorithm named denoising autoencoder (DAE). Instead of using a single fixed noise level in the traditional DAE, a novel multi-level-denoising autoencoder (MLD-AE) method is proposed to enhance the representation learning ability by designing different multi-level noise adding schemes. The proposed MLD-AE could better discover useful patterns at multiple corrupted scales and capture nonlinear dependencies from noisy multivariate sensor data, therefore robustly reconstruct the original signal with the preserved largest information. The proposed framework and method are evaluated on both simulated data from a generic 5 MW WT benchmark and SCADA data from a real wind farm. The results demonstrate that our proposed MLD-AE-based fault detection approach significantly outperforms traditional DAE, AE, and linear PCA approaches, which has great potentials for practical applications in the wind industry.","2169-3536","","10.1109/ACCESS.2019.2914731","National Natural Science Foundation of China(grant numbers:61803329,51575472); Natural Science Foundation of Hebei Province(grant numbers:F2018203413,F2016203421); China Postdoctoral Science Foundation(grant numbers:2018M640247); Key Research and Development Program of Qinhuangdao(grant numbers:201805A005); Yanshan University(grant numbers:BL18040); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8705222","Wind turbines (WTs);fault detection;multivariate data-driven;denoising autoencoder (DAE);multi-level-denoising autoencoder (MLD-AE)","Fault detection;Monitoring;Noise level;Wind turbines;Noise measurement;Temperature sensors;Data models","fault diagnosis;image denoising;learning (artificial intelligence);neural nets;principal component analysis;SCADA systems;wind power plants;wind turbines","multilevel-denoising autoencoder approach;wind turbine fault detection;effective fault detection;maintenance costs;data-driven fault detection approaches;redundant information;measurement noise;WT fault detection;multivariate data-driven fault detection framework;single fixed noise level;traditional DAE;multiple corrupted scales;capture nonlinear dependencies;noisy multivariate sensor data;simulated data;wind farm;MLD-AE-based fault detection approach;linear PCA approaches;wind industry;multilevel-denoising autoencoder method;multilevel-denoising autoencoder method;multilevel noise;neural network algorithm;power 5.0 MW","","28","","35","OAPA","3 May 2019","","","IEEE","IEEE Journals"
"Image noise reduction by denoising autoencoder","L. Yasenko; Y. Klyatchenko; O. Tarasenko-Klyatchenko","Department of System Programming and Specialized Computer Systems, National Technical University of Ukraine ""Igor Sikorsky Kyiv Polytechnic Institute"", Kyiv, Ukraine; Department of System Programming and Specialized Computer Systems, National Technical University of Ukraine ""Igor Sikorsky Kyiv Polytechnic Institute"", Kyiv, Ukraine; Department of System Programming and Specialized Computer Systems, National Technical University of Ukraine ""Igor Sikorsky Kyiv Polytechnic Institute"", Kyiv, Ukraine","2020 IEEE 11th International Conference on Dependable Systems, Services and Technologies (DESSERT)","25 Jun 2020","2020","","","351","355","Neural networks are used in many tasks today. One of them is the images processing. Autoencoder is very popular neural networks for such problems. Denoising autoencoder is an important autoencoder because some tasks we need a preprocessed image to get less noisy result. This research describes ways to analyze noisy images produced by a physically-based render engine and how to reduce that noise. The results showed that the algorithms are logarithmic.","","978-1-7281-9957-3","10.1109/DESSERT50317.2020.9125027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9125027","render;noise;autoencoder;denoise;neural network","Training;Image processing;Conferences;Noise reduction;Neural networks;Rendering (computer graphics);Noise measurement","image denoising;neural nets;rendering (computer graphics)","image noise reduction;denoising autoencoder;neural networks;image processing;preprocessed image;noisy images;physically-based render engine","","3","","9","","25 Jun 2020","","","IEEE","IEEE Conferences"
"A performance evaluation of defect detection by using Denoising AutoEncoder Generative Adversarial Networks","K. Komoto; S. Nakatsuka; H. Aizawa; K. Kato; H. Kobayashi; K. Banno","Faculty of Engineering, Gifu University, Gifu, Japan; Faculty of Engineering, Gifu University, Gifu, Japan; Faculty of Engineering, Gifu University, Gifu, Japan; Faculty of Engineering, Gifu University, Gifu, Japan; N-TECH, 134 Toyo Aza Kawahara Yorocho Yorogun, Gifu, 503-1334, Japan; N-TECH, Gifu, Japan","2018 International Workshop on Advanced Image Technology (IWAIT)","31 May 2018","2018","","","1","4","In this paper, we discuss a method to detect defects in industrial products by using Denoising AutoEncoder Generative Adversarial Networks. In previous methods, a defective area is detected by restoring a defective product image which added an artificial defect to a non-defective product image by Denoising AutoEncoder (DAE). Therefore, a defective area is detected by subtracted image of them. We discuss whether further accuracy improvement is possible by introducing a framework of adversarial learning to DAE in order to restore a defective image to a non-defective image clearer.","","978-1-5386-2615-3","10.1109/IWAIT.2018.8369766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8369766","Deep Learning;Denoising AutoEncoder;Adversarial Learning","Image restoration;Generators;Training;Gallium nitride;Plastic products;Noise reduction;Textiles","belief networks;image denoising;learning (artificial intelligence);pattern classification;production engineering computing","performance evaluation;defect detection;industrial products;defective area;defective product image;artificial defect;nondefective product image;adversarial learning;denoising autoencoder generative adversarial networks","","4","1","5","","31 May 2018","","","IEEE","IEEE Conferences"
"Anomaly MFL Signal Recovery based on Denoising Sparse Autoencoder","L. Jiang; J. Liu; X. Shen; J. Liu; X. Liu; B. Zhang; H. Xu","School of Information Science and Engineering, Northeastern University, Shenyang; School of Information Science and Engineering, Northeastern University, Shenyang; School of Information Science and Engineering, Northeastern University, Shenyang; School of Information Science and Engineering, Northeastern University, Shenyang; School of Information Science and Engineering, Northeastern University, Shenyang; Yanqianshan Branch, Ansteel Group Mining Co., Ltd., Anshan; School of Information Science and Engineering, Northeastern University, Shenyang","2021 33rd Chinese Control and Decision Conference (CCDC)","30 Nov 2021","2021","","","1956","1960","Abnormal signals in Magnetic Flux Leakage (MFL) signals seriously affect accurate assessment of pipeline health. To overcome this problem, this paper proposes a novel anomaly MFL signal recovery method based on denoise sparse autoencoder (DSAE). First, similar to the denoise autoencoder, the input of DSAE is the signals with anomalies, and the target signals are the complete signals. Second, relative entropy is added in the loss function as a penalty factor to improve the sparsity of the network. Finally, the proposed method is verified by comparison experiments. The results indicate that the method proposed in this paper is effective.","1948-9447","978-1-6654-4089-9","10.1109/CCDC52312.2021.9602163","National Key R&D Program of China(grant numbers:2017YFF0108800); National Natural Science Foundation of China(grant numbers:61473069,61627809); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9602163","Magnetic Flux Leakage (MFL);Anomaly signal recovery;Denoising sparse autoencoder (DSAE)","Magnetic flux leakage;Deconvolution;Convolution;Noise reduction;Pipelines;Feature extraction;Entropy","electrical engineering computing;entropy;feature extraction;magnetic flux;magnetic leakage;neural nets;signal denoising;signal reconstruction","denoising sparse autoencoder;abnormal signals;magnetic flux leakage signals;pipeline health assessment;novel anomaly MFL signal recovery method;DSAE;target signals;relative entropy;loss function;penalty factor","","","","10","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"A Denoising Autoencoder for Speaker Recognition. Results on the MCE 2018 Challenge","R. Font",Biometric Vox S.L.,"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","16 Apr 2019","2019","","","6016","6020","We propose a Denoising Autoencoder (DAE) for speaker recognition, trained to map each individual ivector to the mean of all ivectors belonging to that particular speaker. The aim of this DAE is to compensate for inter-session variability and increase the discriminative power of the ivectors prior to PLDA scoring. We test the proposed approach on the MCE 2018 1st Multi-target speaker detection and identification Challenge Evaluation. This evaluation presents a call-center fraud detection scenario: given a speech segment, detect if it belongs to any of the speakers in a blacklist. We show that our DAE system consistently outperforms the usual LDA + PLDA pipeline, achieving a Top-S EER of 4.33% and Top-1 EER of 6.11% on the evaluation set, which represents a 45.6% error reduction with respect to the baseline system provided by organizers.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683525","MCE 2018 challenge;speaker recognition;blacklist detection;denoising autoencoder;speaker embeddings","Blacklisting;Training;Noise reduction;Speaker recognition;Task analysis;Computer architecture;Neural networks","fraud;signal denoising;speaker recognition;vectors","speaker recognition;ivectors;inter-session variability;discriminative power;PLDA scoring;call-center fraud detection scenario;DAE system;evaluation set;denoising autoencoder;multitarget speaker detection;LDA + PLDA pipeline;Top-S EER;Top-1 EER","","3","","18","","16 Apr 2019","","","IEEE","IEEE Conferences"
"Using Stacked Denoising Autoencoder for the Student Dropout Prediction","J. Y. Kuo; C. W. Pan; B. Lei","Computer Science and Information Engineering, National Taipei University of Technology, Taiwan; Computer Science and Information Engineering, National Taipei University of Technology, Taiwan; National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, Shenzhen, China","2017 IEEE International Symposium on Multimedia (ISM)","1 Jan 2018","2017","","","483","488","This paper extended Stacked Denoising Autoencoder to build a deep neural network which initialized the weight of neural network through the encoder's weight and used Dropout to reduce the error rate in fine-tuning stage. The neural network used the information of students in recent years as input data to train neural network, and predicted the possibility of dropout on the students during the semester. The prediction result can be used to counseling and warning students which be dropout likely and then reduced the unnecessary resource of school.","","978-1-5386-2937-6","10.1109/ISM.2017.96","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8241662","Neural Network;Deep Learning;Unsupervised Feature Learning;Stacked Denoising Autoencoder","Multimedia communication;Machine learning;Noise reduction;Neural networks;Learning systems","belief networks;computer aided instruction;image denoising;learning (artificial intelligence);neural nets","Stacked Denoising Autoencoder;student Dropout prediction;deep neural network;encoder;fine-tuning stage;prediction result;counseling;warning students","","3","","9","","1 Jan 2018","","","IEEE","IEEE Conferences"
"Rolling Bearing Fault Diagnosis Method Based on Stacked Denoising Autoencoder and Convolutional Neural Network","Y. Wang; M. Han; W. Liu","School of Reliability and Systems Engineering, Beihang University, Beijing, P.R. China; School of Reliability and Systems Engineering, Beihang University, Beijing, P.R. China; School of Reliability and Systems Engineering, Beihang University, Beijing, P.R. China","2019 International Conference on Quality, Reliability, Risk, Maintenance, and Safety Engineering (QR2MSE)","5 Mar 2020","2019","","","833","838","The signal of rotating machine faults often exhibits strong nonlinearity and noise interference. Therefore. A fault diagnosis method towards non-stationary signal is proposed in this paper. A fault diagnosis model of combining stacked denoising autoencoder (SDAE) and convolutional neural network (CNN) is proposed to solve the problem of difficult classification under strong noise environment. First, the SDAE model is utilized to reduce noise interference from the original data set. Then the processed data set is input into the CNN model for fault classification. The validity of the fault diagnosis model has been verified by the case western reserve university (CWRU) bearing data. The effectiveness of the method has been verified by comparison with other models.","","978-1-7281-1427-9","10.1109/QR2MSE46217.2019.9021126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9021126","rolling bearing fault diagnosis;stacked denoising autoencoder;convolutional neural network","Convolution;Fault diagnosis;Data models;Signal to noise ratio;Noise reduction;Training;Analytical models","convolutional neural nets;fault diagnosis;mechanical engineering computing;rolling bearings;signal classification;signal denoising","rolling bearing fault diagnosis method;stacked denoising autoencoder;convolutional neural network;machine faults;noise interference;fault diagnosis model;SDAE model;CNN model;fault classification;case western reserve university bearing data","","3","","9","","5 Mar 2020","","","IEEE","IEEE Conferences"
"A Degradation Indicator Construction Method for Aeroengine Lifetime Estimation based on Denoising Autoencoder","N. Yifan; S. Jingfeng","School of Management, Xi’an Polytechnic University, Xi’an, China; School of Management, Xi’an Polytechnic University, Xi’an, China","2019 IEEE 3rd Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)","6 Jun 2019","2019","","","160","164","Degradation indicator construction is essential for the lifetime estimation process, since it provides useful indicator for lifetime estimation effectively. However, the degradation indicator is hard to constructed because of the complex relationships between various parameters. This paper proposes a degradation indicator construction method for aeroengine based on denoising autoencoder (DAE) algorithm. To make the degradation data can indicate the equipment operation state easily, the spearman correlation was adopted for the process of equipment operating state characterizing. Thus, the data smoothing method was used to smooth the degradation data, in order to make the prediction results of the equipment lifetime more accurate. Moreover, the degradation construction method was verified to predict the aeroengine lifetime by adopting the aeroengine degradation data provide by NASA datasets. The expected results of this construction method for degradation indicator based on parameter fusion has a lower mean-square error.","","978-1-5386-6243-4","10.1109/ITNEC.2019.8729233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8729233","Denoising Autoencoder;Lifetime Estimation;Aeroengine;Degradation Indicator","Degradation;Fans;Training;Monitoring;Clustering algorithms;Estimation;Smoothing methods","aerospace computing;aerospace engines;signal denoising;smoothing methods","aeroengine lifetime estimation;degradation indicator construction method;data smoothing method;aeroengine degradation data;denoising autoencoder;spearman correlation;NASA datasets;parameter fusion","","","","13","","6 Jun 2019","","","IEEE","IEEE Conferences"
"Hyperspectral Target Detection with Hierarchical Denoising Autoencoder and Subspace Projection","Y. Shi; K. Wang; J. Li; Y. Li","State Key Laboratory of Integrated Services Networks, Xidian University, Xi'an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi'an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi'an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi'an, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","4404","4407","Target detection technique in hyperspectral imagery has been widely applied in various applications. However, its performance is severely limited by the useless interference contained in hyperspectral images (HSIs), mainly caused by the atmosphere, illumination, issues within the sensor itself, and some other factors. In this paper, we propose a hyperspectral target detector based on linear mixture model (LMM), which consists of three components. First, a hierarchical denoising autoencoder (HDAE) is specifically designed for redundant interference removal; then we apply an adaptive cluster approach to extract several representative background samples from the clean HSI; lastly, a target detector with subspace projection is developed for background suppression and target enhancement based on the clean HSI, representative background and prior-known target signatures. Experimental results on two real-world HSIs show the superiority of our proposed method, namely, the HDASP detector, comparing with other state-of-the-art target detection methods.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553151","National Key Research and Development Program of China(grant numbers:2018AAA0102702,2018AAA0102702); 111 project(grant numbers:B08038); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553151","Hierarchical denoising autoencoder;adaptively clustered background extraction;subspace projection;hyperspectral target detection","Atmospheric modeling;Noise reduction;Lighting;Geoscience and remote sensing;Object detection;Detectors;Interference","geophysical image processing;hyperspectral imaging;image denoising;object detection","hyperspectral target detection;hierarchical denoising autoencoder;subspace projection;target detection technique;hyperspectral imagery;useless interference;hyperspectral images;hyperspectral target detector;linear mixture model;redundant interference removal;adaptive cluster approach;representative background samples;clean HSI;background suppression;target enhancement;prior-known target signatures;real-world HSIs;HDASP detector;state-of-the-art target detection methods","","","","9","","12 Oct 2021","","","IEEE","IEEE Conferences"
"Comparing AutoEncoder Variants for Real-Time Denoising of Hyperspectral X-Ray","N. Bonettini; C. A. Gonano; P. Bestagini; M. Marcon; B. Garavelli; S. Tubaro","Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy; Xnext S.p.A., Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy; Xnext S.p.A., Milan, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy","IEEE Sensors Journal","14 Sep 2022","2022","22","18","17997","18007","Hyperspectral X-ray analysis is used in many industrial pipelines, from quality control to detection of low-density contaminants in food. Unfortunately, the signal acquired by X-ray sensors is often affected by a great amount of noise. This hinders the performance of most of the applications building on top of these acquisitions (e.g., detection of food contaminants). Therefore, a good denoising pipeline is necessary. This article proposes a comparison between three different AutoEncoder variants: the Variational AutoEncoder, the Augmented AutoEncoder, and a plain vanilla AutoEncoder. All the networks are trained in an unsupervised fashion to denoise a given noisy spectrum. Focusing on the specific application of recognizing possible food contaminants, we force the latent space of the networks to have just two parameters, as suggested by the physical law of Lambert–Beer. We validate our experiments on a synthetic dataset composed of roughly 15 million spectra. Results suggest that the Augmented AutoEncoder is the best network configuration for this task, showing excellent performance without suffering from the nondeterministic behavior of the Variational AutoEncoder.","1558-1748","","10.1109/JSEN.2022.3195038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9850976","AutoEncoder;denoising;hyperspectral X-ray","Noise reduction;Sensors;X-ray imaging;Hyperspectral imaging;Noise measurement;Photonics;Plastics","contamination;data reduction;feature extraction;image classification;image denoising;learning (artificial intelligence);neural nets;pipelines;quality control;signal denoising","Augmented AutoEncoder;network configuration;Variational AutoEncoder;real-time denoising;hyperspectral X-ray analysis;industrial pipelines;quality control;low-density contaminants;X-ray sensors;applications building;good denoising pipeline;different AutoEncoder variants;plain vanilla AutoEncoder;unsupervised fashion;given noisy spectrum;possible food contaminants","","","","40","IEEE","4 Aug 2022","","","IEEE","IEEE Journals"
"Noise Reduction in ECG Signals Using Fully Convolutional Denoising Autoencoders","H. -T. Chiang; Y. -Y. Hsieh; S. -W. Fu; K. -H. Hung; Y. Tsao; S. -Y. Chien","Graduate Institute of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Graduate Institute of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Graduate Institute of Electrical Engineering, National Taiwan University, Taipei, Taiwan","IEEE Access","20 May 2019","2019","7","","60806","60813","The electrocardiogram (ECG) is an efficient and noninvasive indicator for arrhythmia detection and prevention. In real-world scenarios, ECG signals are prone to be contaminated with various noises, which may lead to wrong interpretation. Therefore, significant attention has been paid on denoising of ECG for accurate diagnosis and analysis. A denoising autoencoder (DAE) can be applied to reconstruct the clean data from its noisy version. In this paper, a DAE using the fully convolutional network (FCN) is proposed for ECG signal denoising. Meanwhile, the proposed FCN-based DAE can perform compression with regard to the DAE architecture. The proposed approach is applied to ECG signals from the MIT-BIH Arrhythmia database and the added noise signals are obtained from the MIT-BIH Noise Stress Test database. The denoising performance is evaluated using the root-mean-square error (RMSE), percentage-root-mean-square difference (PRD), and improvement in signal-to-noise ratio (SNRimp). The results of the experiments conducted on noisy ECG signals of different levels of input SNR show that the FCN acquires better performance as compared to the deep fully connected neural network- and convolutional neural network-based denoising models. Moreover, the proposed FCN-based DAE reduces the size of the input ECG signals, where the compressed data is 32 times smaller than the original. The results of the study demonstrate the superiority of FCN in denoising, with lower RMSE and PRD, as well as higher SNRimp. According to the results, we believe that the proposed FCN-based DAE has a good application prospect in clinical practice.","2169-3536","","10.1109/ACCESS.2019.2912036","Ministry of Science and Technology, Taiwan(grant numbers:MOST 107-2633-E-002-001,MOST 107-2221-E-001-012-MY2,MOST 106-2221-E-001-017-MY2); National Taiwan University(grant numbers:NTU-107L104039); Intel Corporation; Delta; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693790","Electrocardiography;signal denoising;artificial neural networks;denoising autoencoders;fully convolutional network","Electrocardiography;Noise reduction;Convolution;Decoding;Noise measurement;Databases;Signal to noise ratio","convolutional neural nets;electrocardiography;mean square error methods;medical signal processing;signal denoising","MIT-BIH Arrhythmia database;denoising performance;percentage-root-mean-square difference;signal-to-noise ratio;noisy ECG signals;deep fully connected neural network;noise reduction;MIT-BIH noise stress test database;DAE architecture;ECG signal denoising;fully convolutional network;denoising autoencoder;arrhythmia detection;convolutional denoising autoencoders;input ECG signals;FCN-based DAE;convolutional neural network-based denoising","","69","","36","OAPA","18 Apr 2019","","","IEEE","IEEE Journals"
"A Robust Acoustic Feature Extraction Approach Based on Stacked Denoising Autoencoder","J. H. Liu; W. Q. Zheng; Y. X. Zou","ADSPLAB/ELIP, Peking University, Shenzhen, China; ADSPLAB/ELIP, Peking University, Shenzhen, China; ADSPLAB/ELIP, Peking University, Shenzhen, China","2015 IEEE International Conference on Multimedia Big Data","13 Jul 2015","2015","","","124","127","Acoustic feature extraction (AFE) is considered as one of the most challenging techniques for speech applications since the adverse environment noises always cause significant variation on the extracted acoustic features. In this paper, we propose a systematical AFE approach which based on stacked denoising auto encoder (SDAE) aiming at extracting acoustic features automatically. Denoising auto encoder (DAE), which is trained to reconstruct a clean ""repaired"" input from a corrupted version of it, works as the basic building block to form SDAE. Besides, the training set with clean and noisy speech ensures the SDAE has much powerful ability to extract the robust features under different noise conditions. Considering the speaker classification task using features extracted by the proposed approach for evaluation, intensive experiments have been conducted on TIMIT and NIST SRE 2004 to show SDAE with 3 hidden layers (3L-SDAE) gives better performance than shallow layers. The results also show that the features extracted by 3L-SDAE performs better than MFCC features when SNR is lower than 6dB and act more robustly when SNR decreases. What's more, for different types of noises at SNR of 0dB, the accuracy of speaker classification using 3L-SDAE features is higher than about 84% while MFCC features is lower than 77%.","","978-1-4799-8688-0","10.1109/BigMM.2015.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7153865","robust acoustic feature extraction;stacked denoising autoencoder;noisy environment;speaker classification","Feature extraction;Mel frequency cepstral coefficient;Signal to noise ratio;Speech;Spectrogram","feature extraction;signal denoising;speaker recognition;speech coding","speaker classification task;stacked denoising autoencoder;robust acoustic feature extraction","","5","","14","","13 Jul 2015","","","IEEE","IEEE Conferences"
"Modular dynamic deep denoising autoencoder for speech enhancement","R. Safari; S. M. Ahadi; S. Seyedin","Electrical Engineering Department, Amirkabir University of Technology, Tehran, Iran; Electrical Engineering Department, Amirkabir University of Technology, Tehran, Iran; Electrical Engineering Department, Amirkabir University of Technology, Tehran, Iran","2017 7th International Conference on Computer and Knowledge Engineering (ICCKE)","7 Dec 2017","2017","","","254","259","Deep Denoising Autoencoder (DDAE) is an effective method for noise reduction and speech enhancement. However, a single DDAE with a fixed number of frames for neural network input cannot extract contextual information sufficiently. It has also less generalization in unknown SNRs (signal-to-noise-ratio) and the enhanced output has some residual noise. In this paper, we use a modular model in which three DDAEs with different window lengths are stacked. Experimental results showes that our proposed architecture, namely modular dynamic deep denoising autoencoder (MD-DDAE) provides superior performance in comparison with the traditional DDAE models in different noisy conditions.","","978-1-5386-0804-3","10.1109/ICCKE.2017.8167886","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8167886","Speech enhancement;Deep Denoising Autoencoder (DDAE);Modular Dynamic Deep Denoising Autoencoder (MD-DDAE);Unseen Signal to Noise Ratio;Improved Context Pattern","Speech;Noise measurement;Speech enhancement;Noise reduction;Neural networks;Training;Signal to noise ratio","differential algebraic equations;learning (artificial intelligence);neural nets;signal denoising;speech coding;speech enhancement;speech recognition","modular dynamic deep denoising autoencoder;speech enhancement;noise reduction;neural network input;signal-to-noise-ratio;MD-DDAE;DDAE;neural network;deep denoising autoencoder","","4","","22","","7 Dec 2017","","","IEEE","IEEE Conferences"
"Blind Denoising Autoencoder","A. Majumdar","Indraprastha Institute of Information Technology, New Delhi, India","IEEE Transactions on Neural Networks and Learning Systems","21 Dec 2018","2019","30","1","312","317","The term “blind denoising” refers to the fact that the basis used for denoising is learned from the noisy sample itself during denoising. Dictionary learning- and transform learning-based formulations for blind denoising are well known. But there has been no autoencoder-based solution for the said blind denoising approach. So far, autoencoder-based denoising formulations have learned the model on a separate training data and have used the learned model to denoise test samples. Such a methodology fails when the test image (to denoise) is not of the same kind as the models learned with. This will be the first work, where we learn the autoencoder from the noisy sample while denoising. Experimental results show that our proposed method performs better than dictionary learning (K-singular value decomposition), transform learning, sparse stacked denoising autoencoder, and the gold standard BM3D algorithm.","2162-2388","","10.1109/TNNLS.2018.2838679","DST-CNRS-2016-02; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8383709","Autoencoder;denoising","Noise reduction;Transforms;Training;Noise measurement;Machine learning;Training data;Dictionaries","encoding;image denoising;learning (artificial intelligence);singular value decomposition","K-singular value decomposition;dictionary learning-based formulations;transform learning-based formulations;autoencoder-based denoising formulations;blind denoising approach;autoencoder-based solution;blind denoising autoencoder;noisy sample;denoise test samples","","24","","34","IEEE","12 Jun 2018","","","IEEE","IEEE Journals"
"A Modular Deep Denoising Autoencoder for speech enhancement","R. Y. L. Al-Taai; X. Wu","Key Laboratory of Modern Teaching Technology, Ministry of Education Shaanxi Normal University SNNU, Xi’an, China; Key Laboratory of Modern Teaching Technology, Ministry of Education Shaanxi Normal University SNNU, Xi’an, China","2022 3rd International Conference for Emerging Technology (INCET)","15 Jul 2022","2022","","","1","6","Recent researches have proven that deep denoising autoencoder is an effective method for noise reduction and speech enhancement, and can provide better performance than several existing methods. However, training deep denoising autoencoder has proven to be difficult computationally. The goal of this study is to develop a modular approach for training deep denoising autoencoders as a set of classifiers based on collaborative learning. Each classifier is a multilayer deep denoising autoencoder network and specialized for a particular enhancement task and handles a subset of the complete training dataset. The approach performance was assessed using a perceptual evaluation of speech quality and the segmental signal-to-noise ratio. We have trained two individual DDAEs with three and five hidden layers respectively for comparison purposes. We have also compared our proposed model with the traditional spectral subtraction and, log MMSE methods. The results showed that DDAE with three and five hidden layers was sufficient (deeper is better), while the proposed approach provided higher intelligibility results and was more suitable for high-quality cases.","","978-1-6654-9499-1","10.1109/INCET54531.2022.9825440","Research and Development; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825440","Deep denoising autoencoder;speech enhancement;modular neural network;stacked network","Training;Noise reduction;Neural networks;Speech enhancement;Collaborative work;Nonhomogeneous media;Reverberation","image denoising;learning (artificial intelligence);least mean squares methods;neural nets;pattern classification;signal denoising;speech coding;speech enhancement","modular deep denoising autoencoder;speech enhancement;multilayer deep denoising autoencoder network","","","","26","IEEE","15 Jul 2022","","","IEEE","IEEE Conferences"
"Denoised Autoencoder using DCNN Transfer Learning Approach","R. Singh; A. K. Dubey; R. Kapoor","Amity Institute of Information Technology, Amity University Uttar Pradesh, Noida, India; Amity School of Engineering and Technology, Amity University Uttar Pradesh, Noida, India; Department of Electronics and Communication Engineering, Delhi Technological University, New Delhi, India","2022 International Mobile and Embedded Technology Conference (MECON)","14 Apr 2022","2022","","","446","449","Many image denoising models have been designed for enhancing visibility of noisy images. In computer vision denoising of images is an important problem. A lot of emphasis is given to Machine Learning and Deep Learning approach in this regard. This work proposes the study of Deep Convolutional Neural network-based model VGG16 with the custom dataset of bad weather outdoor images via Transfer Learning. The sequential model 1 and model 2 is evaluated to have smooth image. The model architecture using Deep CNN is designed, and training of model is obtained using transfer learning. A model using autoencoder is designed. To decrease training time and perform better rectified Linear Unit (RELU) is used. Number of epochs identified to have increased performance in CNN. Further various optimizers are compared to have better accuracy. The estimation of performance such as RMSE and PSNR values are evaluated. The model is applied to single as well as 25 own outdoor images.","","978-1-6654-2020-4","10.1109/MECON53876.2022.9751863","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9751863","Neural Network;Rectified Linear Unit;Autoencoder;VGG16;Transfer Learning","Training;Deep learning;Computational modeling;Transfer learning;Noise reduction;Computer architecture;Convolutional neural networks","computer vision;convolutional neural nets;deep learning (artificial intelligence);image coding;image denoising","denoised autoencoder;DCNN transfer learning approach;image denoising models;visibility enhancement;noisy images;machine learning;deep convolutional neural network-based model;bad weather outdoor images;sequential model 1;smooth image;model architecture;deep CNN;training time;outdoor images;deep learning approach;VGG16;sequential model 2;RMSE value;PSNR value;rectified linear unit;RELU","","1","","22","IEEE","14 Apr 2022","","","IEEE","IEEE Conferences"
"Reconstruction of time series with missing value using 2D representation-based denoising autoencoder","T. Huamin; D. Qiuqun; X. Shanzhu","National Key Laboratory of Science and Technology on Automatic Target Recognition, National University of Defense Technology, Changsha, China; National Key Laboratory of Science and Technology on Automatic Target Recognition, National University of Defense Technology, Changsha, China; National Key Laboratory of Science and Technology on Automatic Target Recognition, National University of Defense Technology, Changsha, China","Journal of Systems Engineering and Electronics","6 Jan 2021","2020","31","6","1087","1096","Time series analysis is a key technology for medical diagnosis, weather forecasting and financial prediction systems. However, missing data frequently occur during data recording, posing a great challenge to data mining tasks. In this study, we propose a novel time series data representation-based denoising autoencoder (DAE) for the reconstruction of missing values. Two data representation methods, namely, recurrence plot (RP) and Gramian angular field (GAF), are used to transform the raw time series to a 2D matrix for establishing the temporal correlations between different time intervals and extracting the structural patterns from the time series. Then an improved DAE is proposed to reconstruct the missing values from the 2D representation of time series. A comprehensive comparison is conducted amongst the different representations on standard datasets. Results show that the 2D representations have a lower reconstruction error than the raw time series, and the RP representation provides the best outcome. This work provides useful insights into the better reconstruction of missing values in time series analysis to considerably improve the reliability of time-varying system.","1004-4132","","10.23919/JSEE.2020.000081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9316391","time series;missing value;2D representation;denoising autoencoder (DAE);reconstruction","Time series analysis;Two dimensional displays;Decoding;Noise reduction;Transforms;Image reconstruction;Training","data mining;data structures;image denoising;time series","lower reconstruction error;raw time series;RP representation;time series analysis;time-varying system;missing value;2D representation-based;autoencoder;weather forecasting;financial prediction systems;data recording;data mining tasks;time series data representation-based;data representation methods","","2","","","","6 Jan 2021","","","BIAI","BIAI Journals"
"A Denoising Autoencoder based wireless channel transfer function estimator for OFDM communication system","T. Wada; T. Toma; M. Dawodi; J. Baktash","Dept. of Information Engineering, University of the Ryukyus, Senbaru 1, Nishihara, Okinawa, Japan; Dept. of Information Engineering, University of the Ryukyus, Senbaru 1, Nishihara, Okinawa, Japan; Graduate School of Engineering and Science University of the Ryukyus, Senbaru 1, Nishihara, Okinawa, Japan; Graduate School of Engineering and Science University of the Ryukyus, Senbaru 1, Nishihara, Okinawa, Japan","2019 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)","21 Mar 2019","2019","","","530","533","This paper proposes a channel estimation method for Orthogonal Frequency Division Multiple Access (OFDM) communication system by utilizing a Neural Network (NN) based a Machine Learning (ML). Especially, Autoencoder is utilized to estimate Channel Transfer Function (CTF) and to reduce a noise on the estimate. Japanese Digital TV broadcast system is assumed as target system. Then 8k FFT/IFFT is used and number of sub-carriers are 5617 such as mode3 in Integrated Services Digital Broadcasting-Terrestrial (ISDB-T) spec. 5617 complex CTF points must be estimated by limited number of scattered pilot sub-carriers. Assumed channel condition is 2 wave multipath channel with Additive White Gaussian Noise (AWGN). The multipath parameters are randomly generated. To train the autoencoder, 5000 CTFs are generated and pre-training was performed. System performance was evaluated by measuring Bit Error Rate (BER). The system with conventional frequency-domain interpolator and the system with autoencoder based were compared. According to BER simulation results, the autoencoder based system has shown lower BER than the conventional. At BER=10-5, autoencoder system shows roughly 2dB gain than conventional system.","","978-1-5386-7822-0","10.1109/ICAIIC.2019.8669044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8669044","Neural Network;Machine Learning;Deep Learninig;Autoencoder;OFDM;Channel Estimation;Denoise","Bit error rate;Channel estimation;OFDM;Machine learning;Communication systems;Artificial neural networks","AWGN;channel estimation;digital television;encoding;error statistics;fast Fourier transforms;frequency division multiple access;interpolation;multipath channels;OFDM modulation;transfer functions;wireless channels","Orthogonal Frequency Division Multiple Access communication system;Neural Network;Japanese Digital TV broadcast system;target system;Integrated Services Digital Broadcasting-Terrestrial spec;scattered pilot sub-carriers;2 wave multipath channel;Additive White Gaussian Noise;autoencoder based system;OFDM communication system;channel estimation method;bit error rate;complex CTF points;frequency-domain interpolator;denoising autoencoder based wireless Channel Transfer Function estimator;FFT/IFFT;gain 2.0 dB","","1","","11","","21 Mar 2019","","","IEEE","IEEE Conferences"
"uDAS: An Untied Denoising Autoencoder With Sparsity for Spectral Unmixing","Y. Qu; H. Qi","Advanced Imaging and Collaborative Information Processing Group, University of Tennessee, Knoxville, TN, USA; Advanced Imaging and Collaborative Information Processing Group, University of Tennessee, Knoxville, TN, USA","IEEE Transactions on Geoscience and Remote Sensing","25 Feb 2019","2019","57","3","1698","1712","Linear spectral unmixing is the practice of decomposing the mixed pixel into a linear combination of the constituent endmembers and the estimated abundances. This paper focuses on unsupervised spectral unmixing where the endmembers are unknown a priori. Conventional approaches use either geometrical- or statistical-based approaches. In this paper, we address the challenges of spectral unmixing with unsupervised deep learning models, in specific, the autoencoder models, where the decoder serves as the endmembers and the hidden layer output serves as the abundances. In several recent attempts, part-based autoencoders have been designed to solve the unsupervised spectral unmixing problem. However, the performance has not been satisfactory. In this paper, we first discuss some important findings we make on issues with part-based autoencoders. By proof of counterexample, we show that all existing part-based autoencoder networks with nonnegative and tied encoder and decoder are inherently defective by making these inappropriate assumptions on the network structure. As a result, they are not suitable for solving the spectral unmixing problem. We propose a so-called untied denoising autoencoder with sparsity, in which the encoder and decoder of the network are independent, and only the decoder of the network is enforced to be nonnegative. Furthermore, we make two critical additions to the network design. First, since denoising is an essential step for spectral unmixing, we propose to incorporate the denoising capacity into the network optimization in the format of a denoising constraint rather than cascading another denoising preprocessor in order to avoid the introduction of additional reconstruction error. Second, to be more robust to the inaccurate estimation of a number of endmembers, we adopt an $l_{21}$ -norm on the encoder of the network to reduce the redundant endmembers while decreasing the reconstruction error simultaneously. The experimental results demonstrate that the proposed approach outperforms several state-of-the-art methods, especially for highly noisy data.","1558-0644","","10.1109/TGRS.2018.2868690","Intelligence Advanced Research Projects Activity(grant numbers:D17PC00280); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8476591","Deep learning;denoising autoencoder;hyperspectral image (HSI);spectral unmixing","Decoding;Noise reduction;Machine learning;Estimation;Collaboration;Minimization;Matrix decomposition","hyperspectral imaging;image coding;image denoising;remote sensing;unsupervised learning","untied denoising autoencoder;linear spectral unmixing;mixed pixel;linear combination;unsupervised deep learning models;autoencoder models;hidden layer output;unsupervised spectral unmixing problem;nonnegative tied encoder;network structure;network design;denoising capacity;network optimization;denoising preprocessor;autoencoder network","","81","","76","IEEE","28 Sep 2018","","","IEEE","IEEE Journals"
"Automatic Enhancement of Two-Dimensional Gel electrophoresis images using Denoising Autoencoder","A. S. Ahmed; W. H. El-Behaidy; A. A. A. Youssif","Faculty of Computers and Artificial Intelligence, Helwan University, Cairo, Egypt; Faculty of Computers and Artificial Intelligence, Helwan University, Cairo, Egypt; Faculty of Computers and Artificial Intelligence, Helwan University, Cairo, Egypt","2019 14th International Conference on Computer Engineering and Systems (ICCES)","16 Apr 2020","2019","","","357","361","Image denoising is an important preprocessing step in two-dimensional gel electrophoresis (2-DGE) that strongly affect spot detection or pixel-based methods. Denoising autoen-coders (DAE) is a new approach in deep learning used in image denoising that has a challenging performance. In this study, DAE technique is applied on 2-DGE images motivated by its ability to learn a robust representation to partially corrupted input. DAE is applied on over than 300 real gels got from LEeB 2-D PAGE database. To validate the efficiency of this technique three indicators are used; Signal-to-noise ratio (SNR), False discovery rate (FDR) and spot efficiency. The average results before denoising are 0.6332 for SNR and 71.05 for spot efficiency. Whereas, the average results after DAE are 61.3317 for SNR, 99.9944 for FDR and 88.4 for spot efficiency. Moreover, DAE outperforms the denoising wavelet by 1.75 %.","","978-1-7281-5260-8","10.1109/ICCES48960.2019.9068175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068175","Noise Reduction;2-D Gel Electrophoresis;Auto encoder;Denoising Autoencoder","Noise reduction;Signal to noise ratio;Proteins;Image segmentation;Neurons;Image denoising;Noise measurement","biological techniques;biology computing;data compression;electrophoresis;gels;image coding;image denoising;molecular biophysics","denoising wavelet;average results;spot efficiency;SNR;technique three indicators;LEeB 2-D PAGE database;partially corrupted input;2-DGE images;DAE technique;deep learning;denoising autoen-coders;spot detection;image denoising;denoising autoencoder;two-dimensional gel electrophoresis images;automatic enhancement","","1","","26","","16 Apr 2020","","","IEEE","IEEE Conferences"
"Feature Fusion for Denoising and Sparse Autoencoders: Application to Neuroimaging Data","A. Moussavi-Khalkhali; M. Jamshidi; S. Wijemanne","Department of Electrical and Computer Engineering, University of Texas at San Antonio, Texas, USA; Department of Electrical and Computer Engineering, University of Texas at San Antonio, Texas, USA; Department of Neurology, Movement Disorders, University of Texas Health Science Center at San Antonio, Texas, USA","2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)","2 Feb 2017","2016","","","605","610","Although there is no cure to date, Alzheimer's disease detection in early stages has a significant impact on the patient's life in terms of cost, the progress, and helping to plan in advance for an appropriate healthcare in the life ahead as well as providing clinical etiologies for further research. This paper discusses implementing a feature fusion method utilizing sparse and denoising autoencoders to reveal the stage of Alzheimer's disease. Four cohorts consisted of individuals with Alzheimer's disease, late mild cognitive impairment, early mild cognitive impairment, and normal control groups are classified using multinomial logistic regression fueled by the fusion of high-level and low-level features. The high-level features are extracted from the stacked autoencoders. The results show that feature fusion enhance the performance of typical autoencoders. However, the performance of feature fusion using denoising autoencoders is superior to that of the sparse training of autoencoders in terms of overall accuracy, precision, and recall.","","978-1-5090-6167-9","10.1109/ICMLA.2016.0106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7838210","deep learning;Alzheimer's disease stage detection;feature fusion;sacked sparse autoencoders;stacked denoising autoencoders","Magnetic resonance imaging;Training;Feature extraction;Alzheimer's disease;Noise reduction;Classification algorithms","diseases;feature extraction;image coding;image denoising;image fusion;medical image processing;neurophysiology;regression analysis","sparse autoencoder training;stacked autoencoders;high-level features;low-level features;multinomial logistic regression;normal control groups;mild cognitive impairment;denoising autoencoders;feature fusion method;clinical etiologies;Alzheimer disease detection;neuroimaging data","","4","","19","","2 Feb 2017","","","IEEE","IEEE Conferences"
"Hyperspectral image unmixing using autoencoder cascade","R. Guo; W. Wang; H. Qi","Department of Electrical Engineering and Computer Science, Knoxville, TN, USA; Department of Electrical Engineering and Computer Science, Knoxville, TN, USA; Department of Electrical Engineering and Computer Science, Knoxville, TN, USA","2015 7th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)","23 Oct 2017","2015","","","1","4","Hyperspectral image unmixing is the process of estimating pure source signals (endmemebers) and their proportions (abundances) from highly mixed spectroscopic images. Due to model inaccuracies and observation noise, unmixing has been a very challenging problem. In this paper, we exploit the potential of using autoencoder to tackle the unmixing challenges. Two important facts are considered in the algorithm: first, the observation noise in the hyperspectral image generally exists and largely affects the unmixing results; second, the mixing process contains sparsity priori which should be considered to assist the endmember extraction. The proposed autoencoder cascade concatenates a marginalized denoising autoencoder and a non-negative sparse autoencoder to solve the unmixing problem which implicitly denoises the observation data and employs the self-adaptive sparsity constraint. The algorithm is tested on a set of synthetic mixtures and a real hyperspectral image. The experimental results demonstrate the proposed algorithm outperforms several advanced unmixing approaches in highly noisy environment.","2158-6276","978-1-4673-9015-6","10.1109/WHISPERS.2015.8075378","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8075378","Hyperspectral image unmixing;Autoencoder cascade;Marginalized denoising auto-encoder;Nonnegative sparse auto-encoder","Hyperspectral imaging;Noise reduction;Noise measurement;Sparse matrices;Encoding;Neurons","hyperspectral imaging;image coding;image denoising","hyperspectral image unmixing;autoencoder cascade;pure source signals;highly mixed spectroscopic images;observation noise;mixing process;marginalized denoising autoencoder;nonnegative sparse autoencoder;self-adaptive sparsity constraint","","45","","17","","23 Oct 2017","","","IEEE","IEEE Conferences"
"Unsupervised Feature Learning With Distributed Stacked Denoising Sparse Autoencoder for Abnormal Behavior Detection Using Apache Spark","N. Marir; H. Wang; G. Feng","College of Computer Science and Technology, Harbin Engineering University, Harbin, China; College of Computer Science and Technology, Harbin Engineering University, Harbin, China; College of Computer Science and Technology, Harbin Engineering University, Harbin, China","2019 IEEE 2nd International Conference on Knowledge Innovation and Invention (ICKII)","23 Mar 2020","2019","","","473","476","The modern age of internet connectivity and advanced communication technologies has created an ever larger area for cyber attackers to develop, which has resulted in the need for fast and accurate detection of those sophisticated attacks. Abnormal behavior detection is a data analysis task that identifies interesting and emerging patterns from data. Many research in the area of abnormal behavior detection has used machine learning and deep learning techniques to classify anomaly traffic from normal traffic. However, due the massive volumes of data that need to be analyzed and the fast development of attacks, most of the existing machine learning and deep learning solutions for network intrusion detection have low accuracy and less scalability over long period of time, thus an efficient distributed deep detection method is required. In this paper, we propose a novel semi -supervised distributed approach based on stacked denoising sparse autoencoder and SVM for large-scale intrusion detection systems. Our aim is to explore the suitability of big data analytics and deep learning techniques in the context of abnormal behavior detection system. First, a distributed stacked denoising sparse autoencoder is applied to perform an unsupervised non-linear dimensionality reduction. Then, the reduced features are embed to the distributed SVM for classification. The approach is carried out using the iterative reduce paradigm based on Spark. Experimental results on four cyber security datasets including KDD Cup'99, NSL-KDD, UNSW-NB15 and CICIDS2017 show that the proposed method yields promising performance and reduces the detection time.","","978-1-7281-0110-1","10.1109/ICKII46306.2019.9042645","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9042645","Intrusion detection;Big data analytics;Deep learning and distributed stacked denoising sparse autoencoder","","computer network security;feature extraction;neural nets;support vector machines;telecommunication traffic;unsupervised learning","unsupervised feature learning;distributed stacked denoising sparse autoencoder;cyber attackers;data analysis task;deep learning techniques;machine learning;network intrusion detection;efficient distributed deep detection method;large-scale intrusion detection systems;abnormal behavior detection system;detection time;distributed SVM;unsupervised nonlinear dimensionality reduction","","3","","11","","23 Mar 2020","","","IEEE","IEEE Conferences"
"Exploiting the Non-Uniform Frequency-Resolution Spectrograms to Improve the Deep Denoising Auto-Encoder for Speech Enhancement","J. -W. Hung; S. -T. Tsai; Y. -T. Chen","National Chi Nan University, Nantou, Taiwan; National Chi Nan University, Nantou, Taiwan; National Chi Nan University, Nantou, Taiwan","2021 7th International Conference on Applied System Innovation (ICASI)","26 Oct 2021","2021","","","26","29","This study focuses on improving the deep denoising autoencoder (DDAE) for speech enhancement by reducing the size of its input feature. DDAE is a well-known deep learning structure that learns the mapping from the noisy signal to the clean noise-free counterpart. One of the most commonly used representative for the input signal used to train the DDAE is the spectrogram, which is the ordered series of the short-time Fourier transform (STFT) of each frame for the input signal. In this study, we examine a variant of the spectrogram as the input to a DDAE, which possesses a non-uniform acoustic frequency resolution and thus downscales the original spectrogram. Stating in more details, we decompose the original full-resolution spectrogram into four sub-bands, and then down-sample the sub-band spectral points in turn. The higher frequencies the sub-band has, the greater decimation factor it gets. The overall spectral drop rate is around 50%. The preliminary experiments conducted on the utterances corrupted by various noise types (babble, babycry, car, engine and white) reveal that halving the input spectral points with the non-uniform sampling can benefit the learned DDAE to provide higher speech quality and intelligibility of the test signals. Therefore, this new method can improve the denoising performance of the DDAE as well as reduce its computation complexity.","2768-4156","978-1-6654-4143-8","10.1109/ICASI52993.2021.9568478","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9568478","deep denoising autoencoder;speech enhancement;non-uniform frequency resolution","Deep learning;Technological innovation;Fourier transforms;Noise reduction;Speech enhancement;Sampling methods;Noise measurement","feature extraction;Fourier transforms;image denoising;learning (artificial intelligence);neural nets;noise;signal denoising;speech coding;speech enhancement;speech recognition","full-resolution spectrogram;sub-band spectral points;input spectral points;nonuniform sampling;learned DDAE;higher speech quality;intelligibility;test signals;denoising performance;nonuniform frequency-resolution spectrograms;deep denoising auto-encoder;speech enhancement;deep denoising autoencoder;input feature;deep learning structure;noisy signal;clean noise-free counterpart;input signal;nonuniform acoustic frequency resolution;original spectrogram","","","","8","","26 Oct 2021","","","IEEE","IEEE Conferences"
"Weak Label Supervision for Monaural Source Separation Using Non-negative Denoising Variational Autoencoders","E. Karamatlı; A. T. Cemgil; S. Kırbız","Bogazici Universitesi, Istanbul, TR; Bogazici Universitesi, Istanbul, TR; MEF Üniversitesi, İstanbul, , Türkiye","2019 27th Signal Processing and Communications Applications Conference (SIU)","22 Aug 2019","2019","","","1","4","Deep learning models are very effective in source separation when there are large amounts of labeled data available. However it is not always possible to have carefully labeled datasets. In this paper, we propose a weak supervision method that only uses class information rather than source signals for learning to separate short utterance mixtures. We associate a variational autoencoder (VAE) with each class within a nonnegative model. We demonstrate that deep convolutional VAEs provide a prior model to identify complex signals in a sound mixture without having access to any source signal. We show that the separation results are on par with source signal supervision.","2165-0608","978-1-7281-1904-5","10.1109/SIU.2019.8806536","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8806536","weak supervision;source separation;variational autoencoders","NOMA;Dogs;Source separation;Noise reduction;Data models;Convolution;Art","learning (artificial intelligence);signal denoising;source separation","variational autoencoder;nonnegative model;deep convolutional VAEs;complex signals;sound mixture;source signal supervision;weak label supervision;monaural source separation;nonnegative denoising variational autoencoders;deep learning models;carefully labeled datasets;weak supervision method;short utterance mixtures;class information","","4","1","","","22 Aug 2019","","","IEEE","IEEE Conferences"
"Indoor Motion State Recognition using Denoising Autoencoders on Smartphone","H. Dai; C. B. Tao; Y. Lu; H. B. Lu","School of electronic & information engineering, Suzhou University of Science and Technology, Suzhou, China; School of electronic & information engineering, Suzhou University of Science and Technology, Suzhou, China; School of electronic & information engineering, Suzhou University of Science and Technology, Suzhou, China; Department of Computer Information Technology, Indiana University Purdue University Indianapaolis, Indianapaolis, USA","2018 International Computers, Signals and Systems Conference (ICOMSSC)","27 Dec 2019","2018","","","743","745","The interest of indoor movement state recognition has been recently extensively evaluated by several research teams. This paper fully explores the signals from all the sensors in a smartphone and develops a novel deep neural network-based model. In the off-line training phase, this paper firstly proposes a matrix to pre-processing the raw data from a smartphone to overcome its redundancy and complexity. In a second place, this paper managed to go through a stacked denoising autoencoder neural network, resulting in an output layer with seven different indoor movement states. The trained network is then implemented on a smartphone and evaluated with online tests. Extensive experimental results demonstrate that the proposed method achieves 20% higher identification accuracy than other existing methods with respect to various indoor motion status (e.g., walking up and down stairs, taking elevator up and down).","","978-1-5386-6751-4","10.1109/ICOMSSC45026.2018.8941962","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941962","Indoor Motion;Autoencoders;Smartphone","Sensors;Feature extraction;Training;Mathematical model;Neural networks;Legged locomotion;Noise reduction","neural nets;signal denoising;smart phones","deep neural network;off-line training phase;smartphone;stacked denoising autoencoder neural network;indoor motion state recognition;indoor movement state recognition","","","","5","IEEE","27 Dec 2019","","","IEEE","IEEE Conferences"
"Feature-Aware and Content-wise Denoising of 3D Static and Dynamic Meshes using Deep Autoencoders","G. Arvanitis; A. Lalos; K. Moustakas","Electrical and Computer Engineering, University of Patras, Greece; Industrial Systems Institute, “ATHENA” Research Center; Electrical and Computer Engineering, University of Patras, Greece","2019 IEEE International Conference on Multimedia and Expo (ICME)","5 Aug 2019","2019","","","97","102","Throughout the years, several works have been proposed for performing feature-preserving mesh denoising. Despite their reconstruction benefits, there are still challenges that need to be addressed. Meanwhile, several researchers, system engineers, and software developers have shown increasing interest in the application of deep learning approaches for performing several low-level information processing tasks, such as denoising, compression, etc., in image and video applications. In this paper, we present a method for reconstructing accurately static and dynamic noisy meshes by applying autoencoders on guided normals. To increase the effectiveness of the proposed method, we use different models for different set of faces that are classified as features and non-features. Extensive evaluation studies carried out using a variety of static and dynamic meshes, verify that the proposed approach achieves plausible reconstruction output despite the constraints posed by complex noise and geometry patterns.","1945-788X","978-1-5386-9552-4","10.1109/ICME.2019.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8784985","3D mesh denoising, denoising autoencoders, feature-aware and content-wise denoising","Noise reduction;Three-dimensional displays;Noise measurement;Training;Sparse matrices;Image reconstruction;Feature extraction","computational geometry;feature extraction;image denoising;image reconstruction;mesh generation;neural nets;unsupervised learning","content-wise denoising;deep autoencoders;deep learning approaches;low-level information processing tasks;video applications;nonfeatures;plausible reconstruction output;feature-preserving mesh denoising;feature-aware denoising;3D static mesh;3D dynamic mesh;image applications;static noisy mesh reconstruction;dynamic noisy mesh reconstruction;guided normals;complex noise;geometry patterns","","1","","21","","5 Aug 2019","","","IEEE","IEEE Conferences"
"Bengali handwritten numeric character recognition using denoising autoencoders","A. Pal","Dept of CST, Goa University, GOA, India","2015 IEEE International Conference on Engineering and Technology (ICETECH)","24 Sep 2015","2015","","","1","6","This work describes the recognition of Bengali Handwritten Numeral Recognition using Deep Denoising Autoencoder using Multilayer Perceptron (MLP) trained through backpropagation algorithm (DDA). To bring the weights of the DDA to some good solution a layer wise pre-training is done with Denoising Autoencoders. Denoising Autoencoders using MLP trained through backpropagation algorithm are made by introducing masking noise at input to the Autoencoder to capture meaningful information while hidden layers are remain untouched at pre-training. Those pre-trained Denoising Autoencoders are then stacked to build a DDA. DDA is then converted to a Deep Classifier (DC) by using a final output layer. After a final fine-tune best DC is selected to discriminate classes. Performance of the DC using DDA is compared with the Deep Autoencoder using MLP trained through backpropagation (DA) and Support Vector Machines (SVM). From the experiment it is evident that recognition performance of DDA that is 98.9% is higher than DA and SVM those are 97.3% and 97%. Using their performance at validation set results are further combined to build a Hybrid Recognizer that gives a performance of 99.1%.","","978-1-4799-1854-6","10.1109/ICETECH.2015.7275002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275002","Denoising Autoencoder;MLP;Deep Network;Handwriting Numeral Recognition","Noise reduction;Support vector machines;Feature extraction;Backpropagation algorithms;Training;Handwriting recognition;Character recognition","backpropagation;handwritten character recognition;image denoising;multilayer perceptrons;natural language processing","Bengali handwritten numeric character recognition;deep denoising autoencoder;multilayer perceptron;MLP;DDA;backpropagation algorithm;layer wise pre-training;denoising autoencoders;deep classifier;support vector machines","","5","","21","","24 Sep 2015","","","IEEE","IEEE Conferences"
"Research on Gas Recognition Based on Stacked Denoising Autoencoders","W. Yu; C. Gan; W. Lu","School of Computer Science & Information Engineering, Shanghai Institute of Technology, Shanghai, China; School of Computer Science & Information Engineering, Shanghai Institute of Technology, Shanghai, China; School of Computer Science & Information Engineering, Shanghai Institute of Technology, Shanghai, China","2015 8th International Symposium on Computational Intelligence and Design (ISCID)","12 May 2016","2015","1","","301","304","The gas data coming from an array of chemical gas sensors is a kind of multivariate time-series. This data set is extremely difficult and complex to interpret for human experts. It needs designing hand-made features when applying traditional shallow machine learning algorithms in gas recognition. A new gas recognition method based on Deep Learning were proposed in this paper. It is one of unsupervised feature learning methods that can extract self-adapting features from the gas data, overcoming the complex process in designing features by hands and making the features more general. In this work, two methods based on UCI Machine learning database respectively were compared in the experiments. One of them is a two-hidden-layer structure of deep neural network-Stacked denoising Autoencoders and another is a kind of shallow machine learning algorithms. The results show that extracting features automaticly using Deep Learning is a simpler and more universal way in gas recognition. The method proposed in this paper not only improves the gas classification accuracy, but also reduces complexity of the process in shallow machine learning alogithms, so it is valuable to be applied in practice.","","978-1-4673-9587-8","10.1109/ISCID.2015.226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7468955","gas recognition;time-series signal;high-dimensional;Deep Learning;Stacked denoising Autoencoders","Feature extraction;Machine learning;Support vector machines;Noise reduction;Gas detectors;Data mining","computerised instrumentation;feature extraction;gas sensors;neural nets;sensor arrays;time series;unsupervised learning","gas classification;deep neural network;two-hidden-layer structure;UCI machine learning database;self-adapting feature extraction;unsupervised feature learning method;deep learning;gas recognition method;shallow machine learning algorithm;multivariate time-series;chemical gas sensor;stacked denoising autoencoder","","","","9","","12 May 2016","","","IEEE","IEEE Conferences"
"A Pruned-CELP Speech Codec Using Denoising Autoencoder with Spectral Compensation for Quality and Intelligibility Enhancement","Y. -T. Lo; S. -S. Wang; Y. Tsao; S. -Y. Peng","Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei City, Taiwan R.O.C.; Research Center for Information Technology Innovation, Academia Sinica, Taipei City, Taiwan R.O.C.; Research Center for Information Technology Innovation, Academia Sinica, Taipei City, Taiwan R.O.C.; Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei City, Taiwan R.O.C.","2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS)","25 Jul 2019","2019","","","150","151","A codec based on the excited linear prediction (CELP) speech compression method adopting a denoising autoencoder with spectral compensation (DAE-SC) for quality and intelligibility enhancement is proposed in this paper. The sizes of CELP parameters in the encoder are carefully pruned to achieve a higher compression rate. To recover the speech quality and intelligibility degradation due to the pruned CELP parameters, a DAE-SC network with three hidden layers is employed in the decoder. Compared with the conventional CELP codec at a 9.6k bps transmission rate, the proposed speech codec achieves extra 21.9% bit rate reduction with comparable speech quality and intelligibility that are evaluated by four commonly used speech performance metrics.","","978-1-5386-7884-8","10.1109/AICAS.2019.8771507","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8771507","speech codec;speech compression;code excited linear prediction;denoising autoencoder","Speech coding;Decoding;Bit rate;Noise reduction;Speech codecs;Indexes","compensation;data compression;decoding;speech codecs;speech coding;speech intelligibility","intelligibility enhancement;DAE-SC network;speech quality;speech performance metrics;pruned-CELP speech codec parameters;codec based on the excited linear prediction speech compression method;CELP speech compression method;denoising autoencoder with spectral compensation;bit rate 9.6 kbit/s","","","","5","","25 Jul 2019","","","IEEE","IEEE Conferences"
"Attention-Based Convolutional Denoising Autoencoder for Two-Lead ECG Denoising and Arrhythmia Classification","P. Singh; A. Sharma","Electrical Engineering Department, Indian Institute of Technology Roorkee, Roorkee, India; Electrical Engineering Department, Indian Institute of Technology Roorkee, Roorkee, India","IEEE Transactions on Instrumentation and Measurement","24 Aug 2022","2022","71","","1","10","This article presents a fast and accurate electrocardiogram (ECG) denoising and classification method for low-quality ECG signals. To achieve this, a novel attention-based convolutional denoising autoencoder (ACDAE) model is proposed that utilizes a skip-layer and attention module for reliable reconstruction of ECG signals from extreme noise conditions. Skip-layer connections are used to reduce information loss while reconstructing the original signal, and a lightweight, efficient channel attention (ECA) module is used to update relevant features retrieved via cross-channel interaction efficiently. The model is trained and tested using four widely available databases. For evaluation, the signals are mixed with simulated additive white Gaussian noise (AWGN) ranging from −20 to 20 dB and the Massachusetts Institute of Technology-Beth Israel Hospital (MIT-BIH) noise stress test database (NSTDB) noise ranging from −6 to 24 dB. The model outperformed the most cited published works, achieving an average signal-to-noise ratio (SNR) improvement of 19.07 ± 1.67 and a percentage-root-mean-square difference (PRD) of 11.0 % at 0-dB SNR. The model classification performance on 60 000 beats is 98.76% ± 0.44% precision, 98.48% ± 0.58% recall, and 98.88% ± 0.42% accuracy, respectively, using a stratified fivefold cross-validation strategy.","1557-9662","","10.1109/TIM.2022.3197757","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9853604","Arrhythmias;atrial fibrillation (AF);convolutional neural network (CNN);denoising autoencoder (DAE);electrocardiogram (ECG)","Electrocardiography;Noise reduction;Databases;Feature extraction;Signal to noise ratio;Recording;Convolution","AWGN;AWGN channels;electrocardiography;medical signal processing;signal classification;signal denoising","two-lead ECG denoising;arrhythmia classification;classification method;ECG signals;attention-based convolutional denoising autoencoder model;skip-layer connections;cross-channel interaction;simulated additive white Gaussian noise;Technology-Beth Israel Hospital noise stress test database noise;signal-to-noise ratio;model classification performance","","","","38","IEEE","10 Aug 2022","","","IEEE","IEEE Journals"
"Denoised Bottleneck Features From Deep Autoencoders for Telephone Conversation Analysis","K. Janod; M. Morchid; R. Dufour; G. Linarès; R. De Mori","Universite d’Avignon Centre d’Enseignement et de Recherche en Informatique, Avignon, France; Laboratoire Informatique d’Avignon, University of Avignon, Avignon, France; Laboratoire Informatique d’Avignon, University of Avignon, Avignon, France; Laboratoire Informatique d’Avignon, University of Avignon, Avignon, France; Computer Science, McGill University, Montreal, Canada","IEEE/ACM Transactions on Audio, Speech, and Language Processing","12 Jul 2017","2017","25","9","1809","1820","Automatic transcription of spoken documents is affected by automatic transcription errors that are especially frequent when speech is acquired in severe noisy conditions. Automatic speech recognition errors induce errors in the linguistic features used for a variety of natural language processing tasks. Recently, denoisng autoencoders (DAE) and stacked autoencoders (SAE) have been proposed with interesting results for acoustic feature denoising tasks. This paper deals with the recovery of corrupted linguistic features in spoken documents. Solutions based on DAEs and SAEs are considered and evaluated in a spoken conversation analysis task. In order to improve conversation theme classification accuracy, the possibility of combining abstractions obtained from manual and automatic transcription features is considered. As a result, two original representations of highly imperfect spoken documents are introduced. They are based on bottleneck features of a supervised autoencoder that takes advantage of both noisy and clean transcriptions to improve the robustness of error prone representations. Experimental results on a spoken conversation theme identification task show substantial accuracy improvements obtained with the proposed recovery of corrupted features.","2329-9304","","10.1109/TASLP.2017.2718843","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7954983","Automatic speech recognition (ASR);denoisng autoencoders (DAEs);multilayer neural networks;speech analytics;stacked autoencoders (SAEs)","Feature extraction;Speech;Semantics;Manuals;Noise reduction;Noise measurement;Speech processing","signal denoising;speech codecs;speech recognition","denoised bottleneck;deep autoencoders;telephone conversation analysis;automatic transcription errors;denoisng autoencoders;stacked autoencoders;acoustic feature denoising;conversation theme classification;supervised autoencoder","","11","","54","IEEE","22 Jun 2017","","","IEEE","IEEE Journals"
"Optical Fiber Fault Detection and Localization in a Noisy OTDR Trace Based on Denoising Convolutional Autoencoder and Bidirectional Long Short-Term Memory","K. Abdelli; H. Grießer; C. Tropschug; S. Pachnicke","Chair of Communications, Kiel University (CAU), Kiel, Germany; ADVA Optical Networking SE, Munich/Martinsried, Germany; ADVA Optical Networking SE, Munich/Martinsried, Germany; Chair of Communications, Kiel University (CAU), Kiel, Germany","Journal of Lightwave Technology","4 Apr 2022","2022","40","8","2254","2264","Optical time-domain reflectometry (OTDR) has been widely used for characterizing fiber optical links and for detecting and locating fiber faults. OTDR traces are prone to be distorted by different kinds of noise, causing blurring of the backscattered signals, and thereby leading to a misleading interpretation and a more cumbersome event detection task. To address this problem, a novel method combining a denoising convolutional autoencoder (DCAE) and a bidirectional long short-term memory (BiLSTM) is proposed, whereby the former is used for noise removal of OTDR signals and the latter for fault detection, localization, and diagnosis with the denoised signal as input. The proposed approach is applied to noisy OTDR signals of different levels of input SNR ranging from −5 dB to 15 dB. The experimental results demonstrate that: (i) the DCAE is efficient in denoising the OTDR traces and it outperforms other deep learning techniques and the conventional denoising methods; and (ii) the BiLSTM achieves a high detection and diagnostic accuracy of 96.7% with an improvement of 13.74% compared to the performance of the same model trained with noisy OTDR signals.","1558-2213","","10.1109/JLT.2021.3138268","CELTIC-NEXT; AI-NET-PROTECT(grant numbers:C2019/3-4); German Federal Ministry of Education and Research(grant numbers:FKZ16KIS1279K); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9663018","Bidirectional long short-term memory;convolutional autoencoder;denoising;fiber optics;intelligent fault detection and diagnosis;OTDR (optical time domain reflectometry)","Computer architecture;Noise reduction;Optical fibers;Microprocessors;Decoding;Logic gates;Convolution","fault diagnosis;fibre optic sensors;image denoising;learning (artificial intelligence);neural nets;optical fibre networks;optical fibre testing;optical time-domain reflectometry;signal denoising","optical fiber fault detection;noisy OTDR trace;denoising convolutional autoencoder;bidirectional long short-term memory;optical time-domain reflectometry;fiber optical links;detecting locating fiber faults;OTDR traces;backscattered signals;cumbersome event detection task;DCAE;noise removal;denoised signal;noisy OTDR signals;conventional denoising methods;high detection;noise figure -5.0 dB to 15.0 dB","","1","","16","IEEE","24 Dec 2021","","","IEEE","IEEE Journals"
"A Fast Convolutional Denoising Autoencoder Based Extreme Learning Machine","J. Sawaengchob; P. Horata; P. Musikawan; Y. Kongsorot","Department of computer Science, Khon Kaen University, Khon Kaen, Thailand; Department of computer Science, Khon Kaen University, Khon Kaen, Thailand; Department of computer Science, Khon Kaen University, Khon Kaen, Thailand; Department of computer Science, Khon Kaen University, Khon Kaen, Thailand","2017 21st International Computer Science and Engineering Conference (ICSEC)","23 Aug 2018","2017","","","1","5","The convolutional autoencoder (CAE) was proposed on convolutional neural network (CNN) and denoising autoencoder (DAE). CAE can address the corrupted input samples and high dimensional problem. However, CAE has a shortcoming involving a large training timescale because the parameters of network are commonly tuned by gradient descent (GD) learning method. In order to alleviate this problem, this paper proposed a fast convolutional denoising autoencoder based extreme learning machine (ELM), called fast convolutional denoising autoencoder (FCDA). In FCDA, the random convolutional hidden nodes are used to reduce the dimension of input data. After that, the proposed denoising ELM autoencoder is used to reconstruct the cleaned data. The experimental results indicate that the proposed method not only speeds up the traditional CAE, but it also outperforms the CAE algorithm in terms of reconstruction error. Moreover, we applied the proposed method FCDA as the pre-processing method for ML-ELM classifier. The results illustrate the combination of the proposed FCDA, and ML-ELM achieves the classification performance better than the comparative methods.","","978-1-5386-0787-9","10.1109/ICSEC.2017.8443962","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8443962","Denoising Autoencoder;Convolutional Autoencoder;Extreme Learning Machine","Handheld computers;Machine learning;Cybernetics;Noise reduction;Market research;Artificial neural networks;Learning systems","data handling;feedforward neural nets;gradient methods;learning (artificial intelligence);pattern classification","random convolutional hidden nodes;denoising ELM autoencoder;CAE algorithm;FCDA;extreme learning machine;convolutional neural network;gradient descent learning method;fast convolutional denoising autoencoder;GD learning method;data cleaning;data reconstruction;ML-ELM classifier","","1","","13","","23 Aug 2018","","","IEEE","IEEE Conferences"
"Bidirectional Denoising Autoencoders-Based Robust Representation Learning for Underwater Acoustic Target Signal Denoising","Y. Dong; X. Shen; H. Wang","Department of Physics and Electronic Engineering, Yuncheng University, Shanxi, Yuncheng, China; Ministry of Industry and Information Technology, Key Laboratory of Ocean Acoustics and Sensing (Northwestern Polytechnical University), Shaanxi, Xi’an, China; School of Electronic Information and Artificial Intelligence, Shaanxi University of Science and Technology, Shaanxi, Xi’an, China","IEEE Transactions on Instrumentation and Measurement","14 Oct 2022","2022","71","","1","8","The marine environmental noise formed by wind noise, rain noise, biological noise, sea surface waves, seismic disturbances, and so on is a kind of interference background field in underwater acoustic channels, which brings adverse effects to underwater acoustic target recognition. To improve the recognition accuracy of underwater targets under background noise interference, a bidirectional denoising autoencoder (BDAE) is proposed in this article for underwater acoustic target signal denoising robust representation learning. The proposed BDAE is an extension of the regular denoising autoencoder, which uses the original underwater acoustic target signals and their corresponding denoised signals to learn robust representations. We then measure the usefulness of the learned representations using a support vector machine (SVM) classifier. Our proposed approach is verified on the ShipsEar database. Experimental results indicate that the proposed BDAE can effectively learn the robust representations of underwater acoustic target signal denoising and is superior to the traditional methods.","1557-9662","","10.1109/TIM.2022.3210979","National Natural Science Foundation of China(grant numbers:62031021); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9906298","Bidirectional denoising autoencoder (BDAE);pseudo-clean label;representation learning;underwater acoustic target signal denoising","Noise reduction;Underwater acoustics;Signal denoising;Correlation;Training;Target recognition;Noise measurement","","","","","","37","IEEE","30 Sep 2022","","","IEEE","IEEE Journals"
"Orthogonal Features Based EEG Signals Denoising Using Fractional and Compressed One-Dimensional CNN Autoencoder","S. Nagar; A. Kumar","DA-IICT, Gandhinagar, Gujarat, India; Department of Information and Communication Technology, DA-IICT, Gandhinagar, Gujarat, India","IEEE Transactions on Neural Systems and Rehabilitation Engineering","2 Sep 2022","2022","30","","2474","2485","This paper presents a fractional one-dimensional convolutional neural network (CNN) autoencoder for denoising the Electroencephalogram (EEG) signals which often get contaminated with noise during the recording process, mostly due to muscle artifacts (MA), introduced by the movement of muscles. The existing EEG denoising methods make use of decomposition, thresholding and filtering techniques. In the proposed approach, EEG signals are first transformed to orthogonal domain using Tchebichef moments before feeding to the proposed architecture. A new hyper-parameter ( $\alpha $ ) is introduced which refers to the fractional order with respect to which gradients are calculated during back-propagation. It is observed that by tuning  $\alpha $ , the quality of the restored signal improves significantly. Motivated by the high usage of portable low energy devices which make use of compressed deep learning architectures, the trainable parameters of the proposed architecture are compressed using randomized singular value decomposition (RSVD) algorithm. The experiments are performed on the standard EEG datasets, namely, Mendeley and Bonn. The study shows that the proposed fractional and compressed architecture performs better than existing state-of-the-art signal denoising methods.","1558-0210","","10.1109/TNSRE.2022.3201197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9865981","EEG signal denoising;convolutional neural networks;autoencoder;Tchebichef moments;compression","Electroencephalography;Convolution;Matrix decomposition;Noise reduction;Signal denoising;Muscles;Kernel","electroencephalography;learning (artificial intelligence);medical signal processing;neural nets;signal denoising;singular value decomposition","EEG signals;one-dimensional convolutional neural network autoencoder;CNN;Electroencephalogram signals;recording process;muscle artifacts;existing EEG denoising methods;orthogonal domain;Tchebichef moments;hyper-parameter;fractional order;restored signal;portable low energy devices;compressed deep learning architectures;trainable parameters;randomized singular value decomposition algorithm;fractional architecture;compressed architecture;state-of-the-art signal denoising methods;orthogonal features","Algorithms;Artifacts;Electroencephalography;Humans;Movement;Neural Networks, Computer","","","31","CCBY","24 Aug 2022","","","IEEE","IEEE Journals"
"An Autoencoder based Technique for DNA Microarray Image Denoising","A. Mohandas; S. M. Joseph; P. S. Sathidevi","ECE department, NIT, Calicut, India; ECE department, NIT, Calicut, India; ECE department, NIT, Calicut, India","2020 International Conference on Communication and Signal Processing (ICCSP)","1 Sep 2020","2020","","","1366","1371","DNA Microarray is one of the proven tools for genomics. It can be used to detect all the gene expression variations between two different types of cells in a single experiment. The microarray image is a rectangular grid with many subgrids, and each subgrid has organized gene samples called spots, the number of which varies with the manufacturer. The spot intensity information is the most important parameter for gene expression analysis, disease diagnosis, and drug discovery. But, obtaining the spot intensity of DNA microarray images (MAI) is highly challenging as the image is of low contrast and noisy. The various steps involved in obtaining the intensity of the spot are Image enhancement, Gridding, Spot segmentation and Extraction of intensity. Out of these steps, image enhancement is of utmost importance as it can affect the accuracy of the extraction of spot intensity. In this paper, we propose an autoencoder based image denoising for enhancing the DNA MAI. It is a stochastic extension to classic autoencoder. The method is tested on SIB and Derisi datasets. The experimental results indicate that there is a considerable reduction in noise when compared with other recent related methods.","","978-1-7281-4988-2","10.1109/ICCSP48568.2020.9182265","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9182265","Autoencoder;DNA microarray image;Denoising","Noise reduction;DNA;Gene expression;Image segmentation;Noise measurement;Image denoising;Image enhancement","diseases;DNA;genetics;genomics;image denoising;image enhancement;image segmentation;medical image processing;molecular biophysics;patient diagnosis","spot intensity information;gene expression analysis;disease diagnosis;drug discovery;image enhancement;spot segmentation;autoencoder based image;DNA microarray image denoising;autoencoder","","","","15","","1 Sep 2020","","","IEEE","IEEE Conferences"
"Drone Noise Reduction using Deep Convolutional Autoencoder for UAV Acoustic Sensor Networks","C. Chun; K. M. Jeon; T. Kim; W. Choi","Future Infrastructure Research Center, Korea Institute of Civil Engineering and Building Technology, Goyang, South Korea; AI Convergence Technology Research Center, IntFlow Co., Ltd., Gwangju, South Korea; School of Software Hallym University, Chuncheon, South Korea; Dept. of Computer Engineering, Chonsun University, Gwangju, South Korea","2019 IEEE 16th International Conference on Mobile Ad Hoc and Sensor Systems Workshops (MASSW)","9 Apr 2020","2019","","","168","169","Drones are widely utilized in various industries. Unfortunately, when a drone acquires sound through a microphone, which is installed itself, drone flying and wind noises appear in recorded signals. Therefore, it is necessary to reduce such drone flying and wind noises for enhancing the quality of the recorded sound signals for UAV acoustic sensor networks. In this paper, we proposes the noise reduction method using a deep convolutional denoising autoencoder for eliminating drone flying and wind noises. The deep convolutional denoising autoencoder is widely utilized to extract the target sound source in monaural audio source separation. To do this task, a training dataset is constructed by mixing drone flying and wind noises in clean speech signal. Also, we train the neural network model, which is in form of fully convolutional neural networks. From the sound signals recorded in the real outdoor environment, it is shown that the trained model can reduce the drone flying and wind noises, and only separate the target speech.","","978-1-7281-4121-3","10.1109/MASSW.2019.00043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9059492","Drone noise reduction; Convolutional neural network; Denoising autoencoder","Drones;Noise reduction;Convolution;Convolutional codes;Convolutional neural networks;Training;Time-frequency analysis","acoustic signal processing;audio signal processing;autonomous aerial vehicles;control engineering computing;convolutional neural nets;microphones;signal denoising;source separation;speech processing;target tracking","UAV acoustic sensor networks;drone flying;wind noises;recorded sound signals;deep convolutional denoising autoencoder;fully convolutional neural networks;drone noise reduction;deep convolutional autoencoder;noise reduction","","5","","6","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Speech feature denoising and dereverberation via deep autoencoders for noisy reverberant speech recognition","X. Feng; Y. Zhang; J. Glass","MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA","2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","14 Jul 2014","2014","","","1759","1763","Denoising autoencoders (DAs) have shown success in generating robust features for images, but there has been limited work in applying DAs for speech. In this paper we present a deep denoising autoencoder (DDA) framework that can produce robust speech features for noisy reverberant speech recognition. The DDA is first pre-trained as restricted Boltzmann machines (RBMs) in an unsupervised fashion. Then it is unrolled to autoencoders, and fine-tuned by corresponding clean speech features to learn a nonlinear mapping from noisy to clean features. Acoustic models are re-trained using the reconstructed features from the DDA, and speech recognition is performed. The proposed approach is evaluated on the CHiME-WSJ0 corpus, and shows a 16-25% absolute improvement on the recognition accuracy under various SNRs.","2379-190X","978-1-4799-2893-4","10.1109/ICASSP.2014.6853900","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6853900","robust speech recognition;feature denoising;denoising autoencoder;deep neural network","Speech;Noise reduction;Speech recognition;Noise measurement;Decoding;Hidden Markov models;Robustness","Boltzmann machines;learning (artificial intelligence);reverberation;signal denoising;speech coding;speech recognition","speech feature denoising;speech feature dereverberation;deep denoising autoencoders;noisy reverberant speech recognition;restricted Boltzmann machines;unsupervised learning;acoustic models;CHiME-WSJ0 corpus;recognition accuracy","","116","3","21","","14 Jul 2014","","","IEEE","IEEE Conferences"
"Improved Sacked Denoising Autoencoders-Based Defect Detection in Bar Surface","Q. Lv; Y. He; Y. Song","School of Software, Engineering Xi'an Jiaotong University, Xi'an, China; Central Research Institute, Baoshan Iron & Steel Co.,LTD, Shanghai, China; School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China","2018 Chinese Automation Congress (CAC)","24 Jan 2019","2018","","","675","680","Traditional pattern recognition methods are widely used to detect defects in the industry, however most of existing methods are not universal for all kinds of defects on bars. This paper proposes a method which combines Rectified Linear Units (ReLU) and Batch Normalization(BN) in Sacked Denoising Autoencoders(SDA) for surface defect detection of bars. Gradient diffusion often occurs in traditional SDA, which leading to inefficient learning. In order to solve gradient diffusion, we replace the Sigmod activation function with ReLU function. The activation value calculated by ReLU is often oversparing which leading to loss of features. For solving the oversparing of ReLU, we add BN layer into SDA to normalize each batch. Finally we obtain network weights through unsupervised pre-training and supervised fine-tuning. We train two models which one for prediction and the other for reconstruction. Experiment results show that the proposed method can achieve an average accuracy rate of 99.1% on our data set. Compared with the traditional pattern recognition method, traditional SDA and Fisher criterion-based stacked denoising autoencoders(FCSDA), our method shows higher accuracy and TPR. Moreover, due to the addition of BN, the time complexity of our method is significantly lower than the SDA and FCSDA.","","978-1-7281-1312-8","10.1109/CAC.2018.8623185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8623185","Deep learning;bars;batch normalization;stacked denoising autoencoders;rectified linear units","Image reconstruction;Training;Noise reduction;Bars;Pattern recognition;Steel","feature extraction;gradient methods;image coding;image denoising;image recognition;learning (artificial intelligence);neural nets;production engineering computing;steel industry;steel manufacture","sacked denoising autoencoders;FCSDA;Fisher criterion-based stacked denoising autoencoders;BN;SDA;batch normalization;rectified linear units;pattern recognition;ReLU;bar surface;autoencoders-based defect detection;unsupervised pre-training;activation value;Sigmod activation function;gradient diffusion;surface defect detection","","","","20","","24 Jan 2019","","","IEEE","IEEE Conferences"
"Clutter Mitigation in Range Enhanced Radar Images Using Sparsity Based Denoising Autoencoders","S. Vishwakarma; N. Pandey; S. S. Ram","Indraprastha Institute of Information Technology Delhi, New Delhi, India; Indraprastha Institute of Information Technology Delhi, New Delhi, India; Indraprastha Institute of Information Technology Delhi, New Delhi, India","2019 International Radar Conference (RADAR)","27 Apr 2020","2019","","","1","6","Complex propagation channels in indoor environments introduce considerable clutter and distortions to frontal radar images. Autoencoders, when provided with corrupted and corresponding clean images during training, can learn how to mitigate clutter in these images during testing. The main advantage is that an analytical framework of the channel is not required. On the other hand, the algorithm relies on the availability of a large database of correctly labelled training data - the target scenarios in cluttered environments must be exactly replicated in free space. We propose to augment the conventional denoising autoencoder with sparsity based multiple layer representations to handle the labelling mismatch errors. We hypothesize that the deeper representations with sparsity constraints will enable extraction of more fundamental features of the images. Our radar data consists of measurements made with a wideband RF imaging sensor called the Walabot. Our algorithm improves upon the conventional autoencoder in terms of performance with respect to signal to clutter and signal to noise ratios, labelling mismatch errors and computational time during testing.","2640-7736","978-1-7281-2660-9","10.1109/RADAR41533.2019.171257","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9079020","Radar;Range Enhanced Frontal Imaging;Sparsity;Denoising Autoencoders","","Bayes methods;Doppler radar;feature extraction;image denoising;image representation;image resolution;image sensors;learning (artificial intelligence);radar clutter;radar computing;radar imaging","sparsity based multiple layer representations;sparsity constraints;radar data;wideband RF imaging sensor;conventional autoencoder;clutter mitigation;range enhanced radar images;denoising autoencoders;complex propagation channels;indoor environments;frontal radar images;corrupted images;clean images;analytical framework;target scenarios;cluttered environments;free space;conventional denoising autoencoder","","1","","23","","27 Apr 2020","","","IEEE","IEEE Conferences"
"A Bandpass Filter With Multi Deep Denoising Autoencoder for Hearing Applications","R. Yaseen Lazim; X. Wu","Key Laboratory of Modern Teaching Technology, Ministry of Education, Shaanxi Normal University SNNU, Xi'an, China; Key Laboratory of Modern Teaching Technology, Ministry of Education, Shaanxi Normal University SNNU, Xi'an, China","2020 15th IEEE International Conference on Signal Processing (ICSP)","18 Jan 2021","2020","1","","26","31","Speech enhancement techniques in hearing applications aimed to improve the quality of speech in a noisy environment. Deep denoising autoencoder suppresses noise from noise corrupted speech efficiently. Unfortunately, previous applications provide only limited benefits for the enhancement of speech in noisy environments. This paper presents a new approach for the hearing application, which indicates two stages of the bandpass filter and a model composed of three levels of deep denoising autoencoders. In the first stage, the bandpass filter designed to allow signals based on the human cochlea, which then followed by a model of three levels of multilayers deep denoising autoencoder, each which specialized for specific enhancement task of a complete set of tasks. The approach performance measured using the perceptual evaluation of speech quality, hearing aid sound quality index, and segmental signal-to-noise ratio. The simulation results prove that the proposed method yielded higher intelligibility and quality in comparison with single-multilayers neural networks.","2164-5221","978-1-7281-4480-1","10.1109/ICSP48669.2020.9320899","Research and Development; National Natural Science Foundation of China; China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9320899","Bandpass Filter;Deep Denoising Autoencoder;Hearing Aids;Speech Enhancement;Noise Reduction","Auditory system;Band-pass filters;Speech enhancement;Noise reduction;Noise measurement;Ear;Signal to noise ratio","band-pass filters;deep learning (artificial intelligence);handicapped aids;hearing;signal denoising;speech enhancement","bandpass filter;multideep denoising autoencoder;hearing application;speech enhancement;multilayers deep denoising autoencoder;speech quality;signal-to-noise ratio;hearing aid sound quality index","","","","29","","18 Jan 2021","","","IEEE","IEEE Conferences"
"Denoising of Radar Pulse Streams With Autoencoders","X. Li; Z. -M. Liu; Z. Huang","Department of Electronic Science, National University of Defense Technology, Changsha, China; Department of Electronic Science, National University of Defense Technology, Changsha, China; Department of Electronic Science, National University of Defense Technology, Changsha, China","IEEE Communications Letters","9 Apr 2020","2020","24","4","797","801","There are many cases in which the noise corrupts the signals in a significant manner. To better analyze these signals, the noise must be removed from the signals for further data analysis, and the process of noise removal is referred to as denoising. In this letter, we propose a novel approach to the pulse denoising problem by extracting features from time of arrival (TOA) sequences using the autoencoders. The noise-contaminated TOA sequence is first coded into a binary vector and then fed into an autoencoder for training. Then, the trained autoencoder is capable of generating the original TOA sequence without lost and spurious pulses. Moreover, the proposed method does not require a noise-free TOA sequence as a priori as with conventional autoencoders. Simulation results show that the new technique can deal with TOA sequences with complex pulse repetition interval (PRI) modes that have not been tackled before. In addition, the proposed method has a better performance in noisy environments than conventional methods and general deep neural network structures.","1558-2558","","10.1109/LCOMM.2020.2967365","Natural Science Foundation of Hunan Province(grant numbers:2019JJ10004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8966468","Denoising;pulse streams;TOA sequences;autoencoders;binary coding","Noise reduction;Training;Decoding;Radar;Signal denoising;Task analysis;Switches","feature extraction;neural nets;radar signal processing;signal denoising;time-of-arrival estimation","conventional autoencoders;TOA sequences;complex pulse repetition interval modes;radar pulse streams;data analysis;noise removal;pulse denoising problem;noise-contaminated TOA sequence;binary vector;noise-free TOA sequence;time of arrival sequences","","1","","22","IEEE","22 Jan 2020","","","IEEE","IEEE Journals"
"Mitigation of through-wall interference in radar images using denoising autoencoders","S. Vishwakarma; V. Ummalaneni; M. S. Iqbal; A. Majumdar; S. S. Ram","Indraprastha Institute of Information Technology Delhi, New Delhi, India; Indraprastha Institute of Information Technology Delhi, New Delhi, India; Indraprastha Institute of Information Technology Delhi, New Delhi, India; Indraprastha Institute of Information Technology Delhi, New Delhi, India; Indraprastha Institute of Information Technology Delhi, New Delhi, India","2018 IEEE Radar Conference (RadarConf18)","11 Jun 2018","2018","","","1543","1548","The detection and identification of humans and concealed objects by through wall radars is affected by wall propagation effects such as attenuation and multipath. Several works, in the past, have provided solutions for mitigating wall effects based on either prior information of the wall parameters or signal processing solutions for separating wall interference from the direct signal from the target to the radar. In this paper, we propose a machine learning based method-denoising autoencoders-to mitigate wall interference effects and for reconstructing an image resembling the ground truth in free space conditions. This method relies on training the algorithm to denoise corrupted through-wall radar images into clean line-of-sight images. We have demonstrated the effectiveness of the proposed solution using simulated narrowband Doppler-Azimuth images in free space and through-wall conditions. We simulated the propagation through diverse wall conditions using stochastic finite difference time domain techniques. Next, we tested the algo­rithm on measured frontal (Azimuth-Elevation) images obtained from Walabot — a wideband, low power, radar with a planar antenna array. Both the measurement and simulation results showed a low error between the denoised reconstructed images and the clean line-of-sight images.","2375-5318","978-1-5386-4167-5","10.1109/RADAR.2018.8378796","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8378796","Through-wall radar;Doppler-DOA Imaging;sFDTD;Denoising Autoencoders","Radar imaging;Noise reduction;Spaceborne radar;Interference;Doppler radar;Time-domain analysis","finite difference time-domain analysis;image denoising;image reconstruction;radar imaging;signal denoising","concealed objects;wall radars;wall propagation effects;attenuation;multipath;signal processing solutions;direct signal;method-denoising autoencoders;wall interference effects;free space conditions;through-wall radar images;line-of-sight images;narrowband Doppler-Azimuth images;through-wall conditions;diverse wall conditions;stochastic finite difference time domain techniques;measured frontal images;denoised reconstructed images;through-wall interference mitigation","","9","","17","IEEE","11 Jun 2018","","","IEEE","IEEE Conferences"
"Ameliorated Deep Learning based on Improved Denoising Autoencoder and GACNN","D. Wang; X. Zhou; Z. Xu; T. Cheng; X. Wang; H. Miao","Shenyang University of Technology, School of information science and engineering, Shenyang; Guangdong Key Laboratory of Modern Control Technology, Guangdong Institute of Intelligent Manufacturing, Guangzhou; Guangdong Key Laboratory of Modern Control Technology, Guangdong Institute of Intelligent Manufacturing, Guangzhou; Guangdong Key Laboratory of Modern Control Technology, Guangdong Institute of Intelligent Manufacturing, Guangzhou; Shenyang University of Technology, School of information science and engineering, Shenyang; Shenyang University of Technology, School of information science and engineering, Shenyang","2018 37th Chinese Control Conference (CCC)","7 Oct 2018","2018","","","9504","9509","Improving the performance of deep learning and making it more in line with real life have always been the research direction of artificial intelligence. In this paper, a denoising autoencoder genetic algorithm convolution neural network (DGCNN) model based on deep learning is proposed. Two parts of the research work are combined to improve its performance. Firstly, the traditional autoencoder is replaced by the denoising autoencoder and improved the way of adding noise. Secondly, genetic algorithm is utilized to combine CNN at the stage of image classification. This allows DGCNN to cope with complex and volatile situations while enhancing image processing capabilities. Simulation results show that the method can enhance the ability of image processing than traditional methods. The performance of the proposed model is better than traditional method when the images of different loss levels are processed by this method. The results are verifying the feasibility and effectiveness of the model and algorithm. DGCNN shows better capacity in improving the performance of image processing and dealing with complex situations effectively.","1934-1768","978-988-15639-5-8","10.23919/ChiCC.2018.8482659","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8482659","deep learning;denoising autoencoder;genetic algorithm;convolution neural network","Noise reduction;Machine learning;Genetic algorithms;Convolution;Biological neural networks;Training;Image classification","convolution;feedforward neural nets;genetic algorithms;image classification;image denoising;learning (artificial intelligence)","deep learning;artificial intelligence;denoising autoencoder genetic algorithm convolution neural network model;image classification;denoising autoencoder;image processing;ameliorated deep learning;DGCNN model;GACNN","","","","14","","7 Oct 2018","","","IEEE","IEEE Conferences"
"Fast mesh denoising with data driven normal filtering using deep autoencoders","S. Nousias; G. Arvanitis; A. S. Lalos; K. Moustakas","Department of Electrical & Computer Engineering, University of Patras, Greece; Department of Electrical & Computer Engineering, University of Patras, Greece; Industrial Systems Institute, Athena Research Center; Department of Electrical & Computer Engineering, University of Patras, Greece","2019 IEEE 17th International Conference on Industrial Informatics (INDIN)","30 Jan 2020","2019","1","","260","263","Through the years, several works have demonstrated high-quality 3D mesh denoising. Despite the high reconstruction quality, there are still challenges that need to be addressed ranging from variations in configuration parameters to high computational complexity. These drawbacks are crucial especially if the reconstructed models have to be used for quality check, inspection or repair in manufacturing environments where we have to deal with large objects resulting in very dense 3D meshes. Recently, deep learning techniques have shown that are able to automatically learn and find more accurate and reliable results, without the need for setting manually parameters. In this work, motivated by the aforementioned requirements, we propose a fast and reliable denoising method that can be effectively applied for reconstructing very dense noisy 3D models. The proposed method applies conditional variational autoencoders on face normals. Extensive evaluation studies carried out using a variety of 3D models verify that the proposed approach achieves plausible reconstruction outputs, very relative or even better of those proposed by the literature, in considerably faster execution times.","2378-363X","978-1-7281-2927-3","10.1109/INDIN41052.2019.8972221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8972221","3D mesh denoising;data driven normal filtering;variational autoencoders.","","image denoising;image filtering;image reconstruction;learning (artificial intelligence);neural nets","deep autoencoders;high-quality 3D mesh denoising;high reconstruction quality;configuration parameters;high computational complexity;reconstructed models;quality check;manufacturing environments;deep learning techniques;reliable denoising method;conditional variational autoencoders;face normals;plausible reconstruction;very dense noisy 3D models;very dense 3D meshes;data driven normal filtering;fast mesh denoising","","2","","32","","30 Jan 2020","","","IEEE","IEEE Conferences"
"Abnormality Monitoring in the Blast Furnace Ironmaking Process Based on Stacked Dynamic Target-Driven Denoising Autoencoders","K. Jiang; Z. Jiang; Y. Xie; D. Pan; W. Gui","School of Automation, Central South University, Changsha, China; Peng Cheng Laboratory, Shenzhen, China; School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China","IEEE Transactions on Industrial Informatics","7 Dec 2021","2022","18","3","1854","1863","Accurate monitoring of abnormalities is of great significance to the stable operation of the blast furnace ironmaking process. This article proposes a data-driven model to accurately monitor the abnormal conditions of blast furnaces. Generally, data-driven models primarily rely on feature extraction from high-dimensional raw data. Recently, deep learning networks have been developed and considered a promising technology in extracting high-level abstract features. However, most of these networks cannot capture deep target-related features for abnormality monitoring. Thus, this article proposes a novel stacked dynamic target-driven denoising autoencoder for layer-by-layer hierarchical feature representation, and the dynamic relationship between samples and targets is described by dynamic factors. Then, we design a corresponding target-driven reconstruction loss function to pretrain the deep network successively. Experimental results in an ironmaking plant demonstrate the effectiveness and feasibility of the proposed method.","1941-0050","","10.1109/TII.2021.3084911","National Natural Science Foundation of China(grant numbers:61773406); National Science Foundation for Distinguished Young Scholars of China(grant numbers:61725306); National Major Scientific Research Equipment of China(grant numbers:61927803); Central South University Post-Graduate Independent Exploration and Innovation Project(grant numbers:2021zzts0183); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9444193","Blast furnace (BF);denoising autoencoder (DAE);dynamic target-driven denoising autoencoder (D-DAE);process monitoring","Monitoring;Feature extraction;Noise reduction;Iron;Deep learning;Blast furnaces;Data models","blast furnaces;convolutional neural nets;deep learning (artificial intelligence);feature extraction;image denoising;image representation;industrial plants;production engineering computing;steel manufacture","abnormality monitoring;blast furnace ironmaking process;stacked dynamic target-driven denoising autoencoders;data-driven model;blast furnaces;feature extraction;high-dimensional raw data;deep learning networks;high-level abstract features;deep target-related features;layer-by-layer hierarchical feature representation;ironmaking plant;target-driven reconstruction loss function","","4","","24","IEEE","28 May 2021","","","IEEE","IEEE Journals"
"Ground Target Recognition Using Carrier-Free UWB Radar Sensor With a Semi-Supervised Stacked Convolutional Denoising Autoencoder","Y. Zhu; S. Zhang; X. Li; H. Zhao; L. Zhu; S. Chen","School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Sensors Journal","15 Sep 2021","2021","21","18","20685","20693","This paper proposes a scheme for ground-target recognition based on the carrier-free ultra-wideband (UWB) radar sensor for the first time. Carrier-free UWB system emits an extremely short pulse, which can provide potential advantages over other UWB systems, such as high range resolution, short blind range, enhanced anti-multipath jamming ability. These characteristics above guarantee that UWB echoes contain more comprehensive and detailed information with respect to the target of interest. Feature extraction is fundamental and crucial for target recognition. In this paper a deep network named semi-supervised stacked convolutional denoising autoencoder (SCDAE) is developed to extract discriminative features. As an extension of stacked denoising autoencoders (SDAE), SCDAE replaces fully-connected layers with one-dimensional convolutional layers as middle structures. In order to capture essential signatures exactly and improve classification accuracy, we build up a semi-supervised learning mechanism via binding a label regularization term with SCDAE. Moreover, given that echoes observed at different angles belonging to the same target are different, a new multi-level label coding method is proposed and embedded in SCDAE. Experimental results demonstrate that the proposed algorithm can effectively learn essential representation and improve classification accuracy in the presence of low signal-to-noise ratios (SNRs), making it very suitable for use in a classification scheme.","1558-1748","","10.1109/JSEN.2021.3099823","National Natural Science Foundation of China (NSFC)(grant numbers:61971226,61801220); Natural Science Foundation of Jiangsu Province(grant numbers:BK20200075); Fundamental Research Funds for the Central Universities(grant numbers:30917011315); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9495777","Complex target recognition;carrier-free UWB radar;stacked denoising autoencoders;1D-convolutional neural networks;multi-level label;semi-supervised SCDAE","Feature extraction;Ultra wideband radar;Target recognition;Encoding;Deep learning;Unsupervised learning;Decoding","convolution;feature extraction;image classification;image denoising;image representation;jamming;learning (artificial intelligence);neural nets;radar interference;ultra wideband communication;ultra wideband radar","extremely short pulse;UWB systems;high range resolution;short blind range;enhanced anti-multipath jamming ability;UWB echoes;semisupervised stacked convolutional denoising autoencoder;SCDAE;stacked denoising autoencoders;one-dimensional convolutional layers;semisupervised learning mechanism;ground target recognition;carrier-free UWB radar sensor;ground-target recognition;carrier-free ultra-wideband radar sensor;carrier-free UWB system","","3","","34","IEEE","26 Jul 2021","","","IEEE","IEEE Journals"
"Targeted Voice Enhancement by Bandpass Filter and Composite Deep Denoising Autoencoder","R. Y. Lazim AL-Taai; W. Xiaojun; Z. Y","School of Computer Science, Shaanxi Normal University, Key Laboratory of Modern Teaching Technology, Ministry of Education, Shaanxi Normal University SNNU, Xi’an, China; School of Computer Science, Shaanxi Normal University, Key Laboratory of Modern Teaching Technology, Ministry of Education, Shaanxi Normal University SNNU, Xi’an, China; School of Computer Science, Shaanxi Normal University, Key Laboratory of Modern Teaching Technology, Ministry of Education, Shaanxi Normal University SNNU, Xi’an, China","2020 14th International Conference on Signal Processing and Communication Systems (ICSPCS)","4 Jan 2021","2020","","","1","6","In many hearing-aids systems, background noise degrades the speech quality and intelligibility. In this paper, we propose a hybrid system for hearing-aids application, which works to separates the target voice from the noisy signal and then enhance the speech based on the user's hearing loss. We achieve this by using two stages: (1) A bandpass filter to filter out the unwanted noise which is followed by (2) composite of two-level of multi-layers deep denoising autoencoder, each which specialized for specific enhancement task of a complete set of tasks. We evaluated the improvement of the speech quality using two typical hearing loss audiograms. For evaluation, hearing-aid speech perception index (HASPI), hearing-aid sound quality index (HASQI), and perceptual evaluation of speech quality (PESQ) used in two types audiograms of high-frequency hearing loss (HFHL). The results for the experiments show that the proposed method achieved significant results compared with the individual deep denoising autoencoder.","","978-1-7281-9972-6","10.1109/ICSPCS50536.2020.9310026","Research and Development; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9310026","Hearing Aids;Deep Denoising Autoencoder (DDAE);Bandpass Filter (BPF);Speech Enhancement (SE);Noise Reduction (NR)","Noise measurement;Band-pass filters;Training;Speech enhancement;Signal to noise ratio;Auditory system;Task analysis","auditory evoked potentials;band-pass filters;hearing;hearing aids;medical signal processing;signal denoising;speech;speech coding","speech quality;high-frequency hearing loss;targeted voice enhancement;bandpass filter;composite deep denoising autoencoder;background noise;hybrid system;specific enhancement task;hearing-aid speech perception index;hearing-aid sound quality index;HASQI;HASPI;hearing loss audiograms;HFHL;perceptual evaluation of speech quality;PESQ;multilayers deep denoising autoencoder;speech intelligibility","","","","35","","4 Jan 2021","","","IEEE","IEEE Conferences"
"Reducing Speckle Noise from Ultrasound Images Using an Autoencoder Network","O. Karaoğlu; H. Ş. Bilge; İ. Uluer","Elektrik-Elektronik Mühendisliği, Karabuk Üniversitesi, Karabük, Türkiye; Elektrik-Elektronik Mühendisliği, Karabuk Üniversitesi, Karabük, Türkiye; Elektrik-Elektronik Mühendisliği, Karabuk Üniversitesi, Karabük, Türkiye","2020 28th Signal Processing and Communications Applications Conference (SIU)","7 Jan 2021","2020","","","1","4","Image enhancement aims to obtain a clear image from a noisy image and it also uses for ultrasound images. In the experimental study, unlike classical image enhancement methods, deep learning method was used. Different levels of speckle noise added to the ultrasound images of the brachial plexus, which is known as the large nerve community under the armpit, were tried to be removed with the help of the convolutional denoising autoencoder network, which is one of the deep learning methods. The results obtained from the experimental study were compared with classical methods results and the proposed method was found to be more successful than classical methods.","2165-0608","978-1-7281-7206-4","10.1109/SIU49456.2020.9302250","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9302250","image enhancement;deep learning;ultrasound imaging;denoising autoencoder","Noise reduction;Ultrasonic imaging;Deep learning;Conferences;Image enhancement;Convolution;Speckle","biomedical ultrasonics;convolutional neural nets;image denoising;image enhancement;learning (artificial intelligence);medical image processing;speckle","speckle noise;ultrasound images;noisy image;image enhancement;deep learning;convolutional denoising autoencoder network;armpit;brachial plexus","","","","","","7 Jan 2021","","","IEEE","IEEE Conferences"
"An energy-efficient data collection scheme using denoising autoencoder in wireless sensor networks","G. Li; S. Peng; C. Wang; J. Niu; Y. Yuan","Northeastern University, Shenyang, Liaoning, CN; Guangdong University of Foreign Studies, Guangzhou, Guangdong, CN; Northeastern University, Shenyang, Liaoning, CN; Beihang University, Beijing, CN; Northeastern University, Shenyang, Liaoning, CN","Tsinghua Science and Technology","8 Nov 2018","2019","24","1","86","96","As one of the key operations in Wireless Sensor Networks (WSNs), the energy-efficient data collection schemes have been actively explored in the literature. However, the transform basis for sparsifing the sensed data is usually chosen empirically, and the transformed results are not always the sparsest. In this paper, we propose a Data Collection scheme based on Denoising Autoencoder (DCDA) to solve the above problem. In the data training phase, a Denoising AutoEncoder (DAE) is trained to compute the data measurement matrix and the data reconstruction matrix using the historical sensed data. Then, in the data collection phase, the sensed data of whole network are collected along a data collection tree. The data measurement matrix is utilized to compress the sensed data in each sensor node, and the data reconstruction matrix is utilized to reconstruct the original data in the sink. Finally, the data communication performance and data reconstruction performance of the proposed scheme are evaluated and compared with those of existing schemes using real-world sensed data. The experimental results show that compared to its counterparts, the proposed scheme results in a higher data compression rate, lower energy consumption, more accurate data reconstruction, and faster data reconstruction speed.","1007-0214","","10.26599/TST.2018.9010002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8526509","wireless sensor networks;data collection;neural networks;autoencoder;data reconstruction","Data collection;Wireless sensor networks;Noise reduction;Training;Neurons;Transforms;Sparse matrices","data communication;data compression;energy conservation;energy consumption;telecommunication power management;tree data structures;wireless sensor networks","wireless sensor networks;data training phase;data measurement matrix;data reconstruction matrix;historical sensed data;data collection phase;data collection tree;data communication performance;data reconstruction performance;real-world sensed data;accurate data reconstruction;data compression rate;data reconstruction speed;WSN;energy-efficient data collection scheme based on denoising autoencoder;energy-efficient DCDA;sensed data compression;energy consumption","","11","","","","8 Nov 2018","","","TUP","TUP Journals"
"Cross-Technology Interference Mitigation Using Fully Convolutional Denoising Autoencoders","C. -L. Lin; K. C. -J. Lin; C. -C. Lee; Y. Tsao","Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan; Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan","GLOBECOM 2020 - 2020 IEEE Global Communications Conference","25 Jan 2021","2020","","","1","6","Cross-Technology Interference (CTI) is one of the major issues that hinder WiFi networks from achieving full spectrum utilization. Interference from nearby ZigBee devices, LTE-U UEs or even microwave ovens could emit RF signals over the frequency partially overlapping with the WiFi band. To combat such CTI, existing solutions have proposed several signal processing algorithms for error recovery or interference cancellation. However, most of those approaches need knowledge about the physical layer structure of CTI, which cannot be applied to denoise the unstructured interference from unknown electronics, e.g., microwave ovens. To overcome this deficiency, we present a CTI suppression framework based on Denoising AutoEncoder (DAE). The DAE is developed to learn the patterns of interference with unknown structures and passively suppress CTI with the zero cost. To avoid the expansive human cost of data collection, we propose a systematic way to synthesize corrupted WiFi signals for model training. Our experiments verify that the model trained with synthesized data can effectively reconstruct real corrupted WiFi signals and improve the decoding success probability.","2576-6813","978-1-7281-8298-8","10.1109/GLOBECOM42002.2020.9322340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9322340","cross-technology interference;interference suppression;denoising;autoencoder","Wireless fidelity;Interference;Microwave imaging;Gallium nitride;Training;Generators;Noise reduction","decoding;interference suppression;learning (artificial intelligence);Long Term Evolution;probability;radiofrequency interference;signal denoising;wireless LAN;Zigbee","cross-Technology Interference mitigation;convolutional Denoising autoencoders;hinder WiFi networks;spectrum utilization;nearby ZigBee devices;LTE-U UEs;microwave ovens;WiFi band;signal processing algorithms;error recovery;physical layer structure;unstructured interference;CTI suppression framework;Denoising AutoEncoder;DAE;unknown structures;corrupted WiFi signals","","1","","14","","25 Jan 2021","","","IEEE","IEEE Conferences"
"Convolutional Autoencoder for Image Denoising: A Compositional Subspace Representation Perspective","M. Y. W. Teow","Department of Computing and Information Systems, School of Engineering and Technology, Sunway University, Bandar Sunway, Malaysia","2021 IEEE International Conference on Artificial Intelligence in Engineering and Technology (IICAIET)","28 Oct 2021","2021","","","1","6","This study explores a convolutional autoencoder for image denoising with a proposed compositional subspace method. This modeling approach presents a structural and rigorous mathematical abstraction to understand a convolutional autoencoder's functional computation layers. The theoretical basis is that the best way to model a complex learning function is by using a composition of simple functions to form a multilayer successive cascaded function for complex representation. The proposed method has experimented with the Fashion-MNIST dataset. Experimental results are discussed and were consistent with the theoretical expectation.","","978-1-6654-2899-6","10.1109/IICAIET51634.2021.9573657","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9573657","Convolutional Autoencoders;Deep Learning;Computer Vision;Image Denoising;Compositional Subspace Representations","Computational modeling;Conferences;Learning (artificial intelligence);Nonhomogeneous media;Mathematical models;Image reconstruction;Image denoising","convolutional neural nets;image denoising;image representation;learning (artificial intelligence)","image denoising;structural abstraction;mathematical abstraction;complex learning function;multilayer successive cascaded function;compositional subspace representation perspective;convolutional autoencoder functional computation layers","","","","17","IEEE","28 Oct 2021","","","IEEE","IEEE Conferences"
"Denoising Range-Doppler-Data using ML-based Autoencoders for Automotive Applications","F. Rutz; E. Biebl","Professur für Höchstfrequenztechnik, Technische Universität München, München, Deutschland; Professur für Höchstfrequenztechnik, Technische Universität München, München, Deutschland","2021 Kleinheubach Conference","9 Nov 2021","2021","","","1","3","Frequency modulated continuous wave radar systems are a common component of many driver assistance systems. Modern radar systems are heavily used for fast and reliable surrounding area sensing in both safety and automated driving applications. Recently a lot of of neural networks have been introduced for real time detection and classification of vulnerable road users without the need for traditional radar signal processing. One of these systems is based on the real-time object detection system YOLO (You Only Look Once) applied to the pre-processed radar range-Doppler-angle power spectrum. Therefore, the radar cube data is interpreted as a digital image for the computer-vision based YOLO algorithm. This paper deals with the possibility to increase performance of this algorithm, especially in noisy environments, by adding a denoising autoencoder (DAE) structure to the neural network. The DAE input is the noisy radar sensor data represented as an image. Adapted from computer vision applications, the DAE is trained to reconstruct an uncorrupted representation of the input data and hence reduces the noise effects from the measurement data. Furthermore, the domain adaptation capability of the neural network is researched, using simulated measurement data to improve training.","","978-3-948571-04-7","10.23919/IEEECONF54431.2021.9598357","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9598357","","Training;Neural networks;Noise reduction;Signal processing algorithms;Radar imaging;Real-time systems;Sensors","computer vision;CW radar;driver information systems;FM radar;image denoising;learning (artificial intelligence);neural nets;object detection;radar computing;radar imaging;road vehicle radar","range-Doppler-data;ML-based autoencoders;automotive applications;continuous wave radar systems;driver assistance systems;modern radar systems;fast surrounding area sensing;reliable surrounding area sensing;safety;automated driving applications;neural network;time detection;classification;vulnerable road users;traditional radar signal processing;real-time object detection system YOLO;pre-processed radar range-Doppler-angle power spectrum;radar cube data;digital image;computer-vision;YOLO algorithm;denoising autoencoder structure;DAE input;noisy radar sensor data;computer vision applications;simulated measurement data","","","","15","","9 Nov 2021","","","IEEE","IEEE Conferences"
"Removing Noise from Extracellular Neural Recordings Using Fully Convolutional Denoising Autoencoders","C. Kechris; A. Delitzas; V. Matsoukas; P. C. Petrantonakis","Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece; Centre for Research and Technology – Hellas (CERTH), Information Technologies Institute, Thessaloniki, Greece","2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","9 Dec 2021","2021","","","890","893","Extracellular recordings are severely contaminated by a considerable amount of noise sources, rendering the denoising process an extremely challenging task that should be tackled for efficient spike sorting. To this end, we propose an end-to-end deep learning approach to the problem, utilizing a Fully Convolutional Denoising Autoencoder, which learns to produce a clean neuronal activity signal from a noisy multichannel input. The experimental results on simulated data show that our proposed method can improve significantly the quality of noise-corrupted neural signals, outperforming widely-used wavelet denoising techniques.","2694-0604","978-1-7281-1179-7","10.1109/EMBC46164.2021.9630585","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9630585","","Convolution;Noise reduction;Brain modeling;Discrete wavelet transforms;Noise measurement;Extracellular;Task analysis","bioelectric potentials;convolution;image denoising;learning (artificial intelligence);medical signal detection;medical signal processing;neural nets;neurophysiology;signal denoising;wavelet transforms","extracellular neural recordings;Convolutional Denoising autoencoders;extracellular recordings;noise sources;denoising process;extremely challenging task;efficient spike sorting;end-to-end deep learning approach;Fully Convolutional Denoising Autoencoder;clean neuronal activity signal;noisy multichannel input;noise-corrupted neural signals;wavelet denoising techniques","Cell Movement;Neural Networks, Computer;Noise;Protein Transport;Signal-To-Noise Ratio","","","17","","9 Dec 2021","","","IEEE","IEEE Conferences"
"Gradient Artifact Correction for Simultaneous EEG- fMRI using Denoising Autoencoders","B. A. Duffy; A. W. Toga; H. Kim",USC Stevens Institute for Neuroimaging and Informatics; USC Stevens Institute for Neuroimaging and Informatics; USC Stevens Institute for Neuroimaging and Informatics,"2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)","22 May 2020","2020","","","1","4","EEG recorded during MRI acquisition suffers from severe artifacts due to the imaging gradients. Here, we explore the possibility of using denoising autoencoders for correcting for these artifacts. After hyperparameter optimization, the performance of the algorithm was compared against PCA on two different synthesized datasets. The first dataset was created by adding a template artifact to clean EEG data and randomly shifting it in time to simulate aliasing. While the second dataset was formed by filtering out the EEG frequencies and adding a known ground-truth clean EEG signal. The performance of each method was assessed by the RMSE relative to the clean EEG signal. In addition, the correlation coefficient compared to the artifact signal was used to measure the residual artifact level. On the second synthesized dataset, denoising autoencoders outperformed PCA by 4.3% in terms of RMSE, meaning they were able to better preserve the original signal while at the same time the correlation with the underlying artifact was reduced by 40%. These preliminary results merit further investigation on a larger dataset.","1945-8452","978-1-5386-9330-8","10.1109/ISBI45749.2020.9098447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9098447","deep learning;CNN;RNN;neural network","Electroencephalography;Principal component analysis;Noise reduction;Training;Functional magnetic resonance imaging;Brain modeling","biomedical MRI;electroencephalography;image denoising;medical image processing;principal component analysis","residual artifact level;synthesized dataset;denoising autoencoders;PCA;underlying artifact;gradient artifact correction;simultaneous EEG- fMRI;MRI acquisition;severe artifacts;imaging gradients;hyperparameter optimization;different synthesized datasets;template artifact;known ground-truth clean EEG signal;artifact signal","","","","11","","22 May 2020","","","IEEE","IEEE Conferences"
"Enhanced Stacked Denoising Autoencoder-Based Feature Learning for Recognition of Wafer Map Defects","J. Yu","School of Mechanical Engineering, Tongji University, Shanghai, China","IEEE Transactions on Semiconductor Manufacturing","1 Nov 2019","2019","32","4","613","624","In semiconductor manufacturing systems, defects on wafer maps tend to cluster and then these spatial patterns provide important process information for helping operators in finding out root-causes of abnormal processes. Promptly recognizing wafer map defects is an effective way to increase manufacturing process stability and then to improve yields. Deep learning has been widely applied and obtained many successes in image and visual analysis. This paper proposes an effective deep learning method, enhanced stacked denoising autoencoder (ESDAE) with manifold regularization for wafer map pattern recognition (WMPR) in manufacturing processes. This study will concentrate on developing a deep learning model to learn effective discriminative features from wafer maps through a deep network architecture for WMPR improvement. An indication based on ESDAE is developed for detecting map defects online. An ESDAE-based classifier is finally developed to implement recognition of wafer map defects. The most motivation for developing deep learning and manifold regularization techniques is to achieve higher accuracy and applicability than that of some regular recognizers. The effectiveness of the proposed method has been demonstrated by experimental results from a real-world wafer map dataset (WM-811K).","1558-2345","","10.1109/TSM.2019.2940334","National Natural Science Foundation of China(grant numbers:71777173); Fundamental Research Funds for Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8830417","Wafer map;defect recognition;deep learning;stacked denoising autoencoder;manifold regularization","Deep learning;Manifolds;Noise reduction;Feature extraction;Manufacturing processes;Learning systems","computer vision;feature extraction;flaw detection;image classification;image denoising;learning (artificial intelligence);manufacturing processes;neural nets;object detection;object recognition;production engineering computing;semiconductor industry;semiconductor technology","enhanced stacked denoising autoencoder-based feature learning;semiconductor manufacturing systems;process information;abnormal processes;manufacturing process stability;effective deep learning method;wafer map pattern recognition;deep learning model;map defect detection;wafer map defect recognition;spatial patterns;image analysis;visual analysis;enhanced stacked denoising autoencoder;manifold regularization;effective discriminative feature learning;deep network architecture;ESDAE-based classifier","","22","","57","IEEE","10 Sep 2019","","","IEEE","IEEE Journals"
"Radio Frequency Fingerprint Identification Based on Denoising Autoencoders","J. Yu; A. Hu; F. Zhou; Y. Xing; Y. Yu; G. Li; L. Peng","School of Information Science and Engineering, Southeast University, Nanjing, China; School of Cyber Science and Engineering, Southeast University, Nanjing, China; CERI-LIA, Université d’Avignon, Avignon, France; School of Information Science and Engineering, Southeast University, Nanjing, China; Institut Supérieur d’Electronique de Paris, Paris, France; School of Cyber Science and Engineering, Southeast University, Nanjing, China; School of Cyber Science and Engineering, Southeast University, Nanjing, China","2019 International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)","5 Dec 2019","2019","","","1","6","Radio Frequency Fingerprinting (RFF) is one of the promising passive authentication approaches for improving the security of the Internet of Things (IoT). However, with the proliferation of low-power IoT devices, it becomes imperative to improve the identification accuracy at low SNR scenarios. To address this problem, this paper proposes a general Denoising AutoEncoder (DAE)-based model for deep learning RFF techniques. Besides, a partially stacking method is designed to appropriately combine the semi-steady and steady-state RFFs of ZigBee devices. The proposed Partially Stacking-based Convolutional DAE (PSC-DAE) aims at reconstructing a high-SNR signal as well as device identification. Experimental results demonstrate that compared to Convolutional Neural Network (CNN), PSCDAE can improve the identification accuracy by 14% to 23.5% at low SNRs (from -10 dB to 5 dB) under Additive White Gaussian Noise (AWGN) corrupted channels. Even at SNR = 10 dB, the identification accuracy is as high as 97.5%.","2160-4894","978-1-7281-3316-4","10.1109/WiMOB.2019.8923325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8923325","RF fingerprinting;denoising autoencoder;partially stacking;ZigBee","Radio frequency;ZigBee;Stacking;Steady-state;Signal to noise ratio;Feature extraction;Image reconstruction","AWGN channels;computer network security;convolutional neural nets;feature extraction;Internet of Things;learning (artificial intelligence);signal denoising;Zigbee","identification accuracy;low SNR scenarios;general Denoising AutoEncoder-based model;deep learning RFF techniques;partially stacking method;steady-state RFFs;ZigBee devices;Partially Stacking-based Convolutional DAE;PSC-DAE;high-SNR signal;device identification;Convolutional Neural Network;PSCDAE;low SNRs;radio Frequency fingerprint identification;Denoising autoencoders;Radio Frequency Fingerprinting;promising passive authentication approaches;low-power IoT devices;noise figure 10.0 dB;noise figure -10.0 dB to 5.0 dB","","19","1","17","","5 Dec 2019","","","IEEE","IEEE Conferences"
"Toward Robust Fault Identification of Complex Industrial Processes Using Stacked Sparse-Denoising Autoencoder With Softmax Classifier","J. Liu; L. Xu; Y. Xie; T. Ma; J. Wang; Z. Tang; W. Gui; H. Yin; H. Jahanshahi","Hunan Provincial Key Laboratory of Intelligent Computing and Language Information Processing, Hunan Normal University, Changsha 410081, Hunan, China (e-mail: ljp202518@163.com); Hunan Provincial Key Laboratory of Intelligent Computing and Language Information Processing, Hunan Normal University, Changsha 410081, Hunan, China.; School of Automation, Central South University, Changsha 410083, Hunan, China.; Hunan Provincial Key Laboratory of Intelligent Computing and Language Information Processing, Hunan Normal University, Changsha 410081, Hunan, China.; School of Automation, Central South University, Changsha 410083, Hunan, China.; School of Automation, Central South University, Changsha 410083, Hunan, China.; School of Automation, Central South University, Changsha 410083, Hunan, China.; Hunan Provincial Key Laboratory of Intelligent Computing and Language Information Processing, Hunan Normal University, Changsha 410081, Hunan, China.; Department of Mechanical Engineering, University of Manitoba, Winnipeg, MB R3T 5V6, Canada.","IEEE Transactions on Cybernetics","","2021","PP","99","1","15","This article proposes a robust end-to-end deep learning-induced fault recognition scheme by stacking multiple sparse-denoising autoencoders with a Softmax classifier, called stacked spare-denoising autoencoder (SSDAE)-Softmax, for the fault identification of complex industrial processes (CIPs). Specifically, sparse denoising autoencoder (SDAE) is established by integrating a sparse AE (SAE) with a denoising AE (DAE) for the low-dimensional but intrinsic feature representation of the CIP monitoring data (CIPMD) with possible noise contamination. SSDAE-Softmax is established by stacking multiple SDAEs with a layerwise pretraining procedure, and a Softmax classifier with a global fine-tuning strategy. Furthermore, SSDAE-Softmax hyperparameters are optimized by a relatively new global optimization algorithm, referred to as the state transition algorithm (STA). Benefiting from the deep learning-based feature representation scheme with the STA-based hyperparameter optimization, the underlying intrinsic characteristics of CIPMD can be learned automatically and adaptively for accurate fault identification. A numeric simulation system, the benchmark Tennessee Eastman process (TEP), and a real industrial process, that is, the continuous casting process (CCP) from a top steel plant of China, are used to validate the performance of the proposed method. Experimental results show that the proposed SSDAE-Softmax model can effectively identify various process faults, and has stronger robustness and adaptability against the noise interference in CIPMD for the process monitoring of CIPs.","2168-2275","","10.1109/TCYB.2021.3109618","National Natural Science Foundation of China NSFC(grant numbers:61971188,61771492,U1701261); National Science Fund for Distinguished Young Scholars(grant numbers:61725306); Scientific Research Project of Education Department of Hunan Province(grant numbers:19B364); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9546667","Complex industrial process (CIP);continuous casting process (CCP);fault recognition;softmax classifier;stacked spare-denoising autoencoder (SSDAE);ventilation exhaust fan (VEF)","Feature extraction;Process monitoring;Fault diagnosis;Principal component analysis;Optimization;Numerical models;Deep learning","","","","1","","","IEEE","22 Sep 2021","","","IEEE","IEEE Early Access Articles"
"Multi-Task Autoencoder for Noise-Robust Speech Recognition","H. Zhang; C. Liu; N. Inoue; K. Shinoda","Tokyo Institute of Technology, Japan; Tokyo Institute of Technology, Japan; Tokyo Institute of Technology, Japan; Tokyo Institute of Technology, Japan","2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 Sep 2018","2018","","","5599","5603","For speech recognition in noisy environments, we propose a multi-task autoencoder which estimates not only clean speech features but also noise features from noisy speech. We introduce the deSpeeching autoencoder, which excludes speech signals from noisy speech, and combine it with the conventional denoising autoencoder to form a unified multi-task au-toencoder (MTAE). We evaluate it using the Aurora 2 dataset and CHIME 3 dataset. It reduced WER by 15.7% from the conventional denoising autoencoder in the Aurora 2 test set A.","2379-190X","978-1-5386-4658-8","10.1109/ICASSP.2018.8461446","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8461446","Denoising autoencoder;deSpeeching au-toencoder;robust speech recognition","Training;Noise measurement;Task analysis;Noise reduction;Speech recognition;Magnetosphere;Ion radiation effects","speech coding;speech recognition;vocoders","denoising autoencoder;CHIME 3 dataset;speech signals;deSpeeching autoencoder;noisy speech;noise features;clean speech features;noise-robust speech recognition;multitask autoencoder","","4","","22","","13 Sep 2018","","","IEEE","IEEE Conferences"
"Convolutional Denoising Auto-Encoder Based AWGN Removal From ECG Signal","L. El Bouny; M. Khalil; A. Adib","Department of Computer Science, Faculty of Sciences and Technology, Mohammedia, Morocco; Department of Computer Science, Faculty of Sciences and Technology, Mohammedia, Morocco; Department of Computer Science, Faculty of Sciences and Technology, Mohammedia, Morocco","2021 International Conference on INnovations in Intelligent SysTems and Applications (INISTA)","30 Sep 2021","2021","","","1","6","Electrocardiogram (ECG) signal is a non-invasive technique that is currently used to diagnose various types of cardiovascular diseases. However, ECG recording is vulnerable to different types of noises and artifacts that make it very difficult to obtain an accurate diagnosis. In this context, we propose a novel ECG denoising algorithm based on the deep Convolutional Denoising Auto-Encoder (CDAE) which requires minimal preprocessing steps, and conserves the important ECG features. In this study, the proposed CDAE algorithm is specifically implemented to remove the Additive White Gaussian noise (AWGN) from the recorded ECG signal. The CDAE was trained, validated and tested on a set of real ECG signals acquired from the well-known MIT-BIH-Arrythmia (MITDB) database with artificially generated AWGN. The experimental results demonstrate that the proposed method shows better Signal to Noise Ratio (SNR) and lower Root Mean Square Error (RMSE) compared to some of the state-of-the-art methods. The promising results indicate also that the proposed CDAE technique is an effective solution for denoising the ECG signal, by providing ECG waves accentuation for other ECG processing applications like diseases diagnosis.","","978-1-6654-3603-8","10.1109/INISTA52262.2021.9548524","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9548524","ECG signal;Denoising;Deep Learning;Convolutional Neural Networks;Convolutional Denoising Auto-Encoder","Technological innovation;Convolution;Noise reduction;Electrocardiography;Convolutional neural networks;Signal denoising;Noise measurement","AWGN;bioelectric potentials;convolution;diseases;electrocardiography;encoding;feature extraction;mean square error methods;medical signal detection;medical signal processing;signal denoising","MITDB database;MIT-BIH-Arrythmia database;convolutional denoising autoencoder based AWGN removal;artificially generated AWGN;ECG signal recording;additive white Gaussian noise;CDAE algorithm;deep convolutional denoising autoencoder;ECG denoising algorithm;electrocardiogram signal;ECG processing applications;ECG waves","","","","19","","30 Sep 2021","","","IEEE","IEEE Conferences"
"Dual Denoising Autoencoder Feature Learning for Cancer Diagnosis","Y. Gao; W. W. Y. Ng; T. Wang; S. Kwong","Guangdong Provincial Key Lab of Computational Intelligence and Cyberspace Information, School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Guangdong Provincial Key Lab of Computational Intelligence and Cyberspace Information, School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Guangdong Provincial Key Lab of Computational Intelligence and Cyberspace Information, School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Department of Computer Science, City University of Hong Kong, Hong Kong, China","2019 IEEE 18th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC)","22 Jul 2020","2019","","","366","371","Microarray data analysis has emerged as a strong tool for cancer diagnosis. Nevertheless, researches on it are significantly challenging as the microarray datasets are imbalanced and high-dimensional with relatively small sample size. In this paper, we utilized Dual Denoising Autoencoder Features (DDAF), which integrates two Denoising Auto-Encoders (DAE) with different activation function to map the features for both minority and majority classes into a better classification representation. The experimental results on four typical microarray datasets show that the DDAF outperforms the Dual Autoencoder Features (DAF) and the Cost-sensitive Oversampling Stacked Denoising Auto-Encoder (CO-SDAE), rendering the robust ability for dimensionality reduction and imbalanced classification.","","978-1-7281-1419-4","10.1109/ICCICC46617.2019.9146039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9146039","imbalanced classification;denoising autoencoder;feature learning","Noise reduction;Handheld computers;Cancer;Decoding;Measurement;Data analysis;Tools","cancer;data analysis;feature extraction;genetics;learning (artificial intelligence);medical diagnostic computing;neural nets;patient diagnosis;pattern classification","Dual Denoising Autoencoder feature learning;cancer diagnosis;microarray data analysis;Dual Denoising Autoencoder Features;DDAF;activation function;minority;majority classes;typical microarray datasets;Cost-sensitive Oversampling Stacked Denoising Auto-Encoder","","","","16","","22 Jul 2020","","","IEEE","IEEE Conferences"
"Mitigation of Through-Wall Distortions of Frontal Radar Images Using Denoising Autoencoders","S. Vishwakarma; S. S. Ram","University College London (UCL), London, U.K.; Indraprastha Institute of Information Technology Delhi, New Delhi, India","IEEE Transactions on Geoscience and Remote Sensing","27 Aug 2020","2020","58","9","6650","6663","Radar images of humans and other concealed objects are considerably distorted by attenuation, refraction, and multipath clutter in indoor through-wall environments. Although several methods have been proposed for removing target-independent static and dynamic clutter, there still remain considerable challenges in mitigating target-dependent clutter especially when the knowledge of the exact propagation characteristics or analytical framework is unavailable. In this article, we focus on mitigating wall effects using a machine learning-based solution-denoising autoencoders-that does not require prior information of the wall parameters or room geometry. Instead, the method relies on the availability of a large volume of training radar images gathered in through-wall conditions and the corresponding clean images captured in line-of-sight conditions. During the training phase, the autoencoder learns how to denoise the corrupted through-wall images in order to resemble the free space images. We have validated the performance of the proposed solution for both static and dynamic human subjects. The frontal radar images of static targets are obtained by processing wideband planar array measurement data with 2-D array and range processing. The frontal radar images of dynamic targets are simulated using narrowband planar array data processed with 2-D array and Doppler processing. In both simulation and measurement processes, we incorporate considerable diversity in the target and propagation conditions. Our experimental results, from both simulation and measurement data, show that the denoised images are considerably more similar to the free-space images when compared to the original through-wall images.","1558-0644","","10.1109/TGRS.2020.2978440","Ministry of Electronics and Information Technology, Government of India, through the Visvesvaraya PhD Scheme; Air Force Office of Scientific Research (AFOSR), Asian Office of Aerospace Research and Development (AOARD)(grant numbers:5IOA036,FA23861610004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9040872","Denoising autoencoders;Doppler/range-enhanced frontal imaging;stochastic finite difference time-domain (sFDTD);through-wall radar","Radar imaging;Clutter;Noise reduction;Training;Doppler radar;Aerodynamics","Doppler radar;image coding;image denoising;learning (artificial intelligence);radar clutter;radar computing;radar imaging","free space imaging;dynamic human subjects;wideband planar array measurement data;propagation conditions;through-wall distortion mitigation;multipath clutter;indoor through-wall environments;machine learning-based solution;training radar imaging;autoencoder denoising;wall parameter effects;dynamic target-dependent clutter;free-space image denoising;frontal radar imaging;through-wall imaging conditions;Doppler processing;2D array","","9","","41","IEEE","18 Mar 2020","","","IEEE","IEEE Journals"
"Denoising High Resolution Multispectral Images Using Deep Learning Approach","U. Ojha; A. Garg","Department of Computer Science and Engineering, Motilal Nehru National Institute of Technology Allahabad, Allahabad, India; Indian Space Research Organisation, Space Applications Centre, Ahmedabad, India","2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)","2 Feb 2017","2016","","","871","875","In this paper we address the image denoising problem specifically for high resolution multispectral images. We explore the possibility to device a method that approximates the denoising function using the ideology of learning from data. The overall objective is to build a model that replicates the denoised results of Non-local means algorithm using far less computational resources for each of the four spectral bands (blue, green, red and near infrared). We have used deep neural networks and in particular stacked autoencoders to learn the function that maps a noisy image to its denoised version. We show that after training the model on a large set noisy and denoised images, excellent results that are comparable to the results of Non-local means algorithm can be obtained in much less computational time. The scope of the model can further be extended to denoise any other natural image by training it on the appropriate data set.","","978-1-5090-6167-9","10.1109/ICMLA.2016.0156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7838260","Deep learning;Image denoising;Multispectral images;Stacked Autoencoders","Training;Noise reduction;Neurons;Noise measurement;Cost function;Image denoising;Image resolution","geophysical image processing;image denoising;image resolution;learning (artificial intelligence);neural nets","denoising high resolution multispectral images;deep learning approach;image denoising problem;denoising function;non-local means algorithm;data handling;computational resources;deep neural networks;stacked autoencoders","","1","","17","IEEE","2 Feb 2017","","","IEEE","IEEE Conferences"
"Noise Learning-Based Denoising Autoencoder","W. -H. Lee; M. Ozger; U. Challita; K. W. Sung","Department of Control and Instrumentation Engineering, Korea University, Sejong-si, Republic of Korea; School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; Ericsson Research, Stockholm, Sweden; School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden","IEEE Communications Letters","9 Sep 2021","2021","25","9","2983","2987","This letter introduces a new denoiser that modifies the structure of denoising autoencoder (DAE), namely noise learning based DAE (nlDAE). The proposed nlDAE learns the noise of the input data. Then, the denoising is performed by subtracting the regenerated noise from the noisy input. Hence, nlDAE is more effective than DAE when the noise is simpler to regenerate than the original data. To validate the performance of nlDAE, we provide three case studies: signal restoration, symbol demodulation, and precise localization. Numerical results suggest that nlDAE requires smaller latent space dimension and smaller training dataset compared to DAE.","1558-2558","","10.1109/LCOMM.2021.3091800","Korea University Grant; BK21 FOUR (Fostering Outstanding Universities for Research) funded by the Ministry of Education (MOE, Korea) and National Research Foundation of Korea (NRF); European Union Horizon 2020 Research and Innovation Programme under the EU/KR PriMO-5G project(grant numbers:815191); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9462839","Machine learning;noise learning based denoising autoencoder;signal restoration;symbol demodulation;precise localization","Noise reduction;Training;Noise measurement;Random variables;Encoding;Decoding;Internet of Things","image denoising;learning (artificial intelligence);signal denoising","nlDAE;noisy input;signal restoration;symbol demodulation;precise localization;noise learning based denoising autoencoder","","4","","9","CCBY","23 Jun 2021","","","IEEE","IEEE Journals"
"Underwater Color Restoration Using U-Net Denoising Autoencoder","Y. Hashisho; M. Albadawi; T. Krause; U. F. von Lukas","Department of Maritime Graphics, Fraunhofer Institute for Computer Graphics Research (IGD), Rostock, Germany; Department of Maritime Graphics, Fraunhofer Institute for Computer Graphics Research (IGD), Rostock, Germany; Department of Maritime Graphics, Fraunhofer Institute for Computer Graphics Research (IGD), Rostock, Germany; Department of Maritime Graphics, Fraunhofer Institute for Computer Graphics Research (IGD), Rostock, Germany","2019 11th International Symposium on Image and Signal Processing and Analysis (ISPA)","17 Oct 2019","2019","","","117","122","Visual inspection of underwater structures by vehicles, e.g. remotely operated vehicles (ROVs), plays an important role in scientific, military, and commercial sectors. However, the automatic extraction of information using software tools is hindered by the characteristics of water which degrade the quality of captured videos. As a contribution for restoring the color of underwater images, Underwater Denoising Autoencoder (UDAE) model is developed using a denoising autoencoder with U-Net architecture. The proposed network takes into consideration the accuracy and the computation cost to enable realtime implementation on underwater visual tasks using end-to-end autoencoder network. Underwater vehicles perception is improved by reconstructing captured frames; hence obtaining better performance in underwater tasks. Related learning methods use generative adversarial networks (GANs) to generate color corrected underwater images, and to our knowledge this paper is the first to deal with a single autoencoder capable of producing same or better results. Moreover, image pairs are constructed for training the proposed network, where it is hard to obtain such dataset from underwater scenery. At the end, the proposed model is compared to a state-of-the-art method.","1849-2266","978-1-7281-3140-5","10.1109/ISPA.2019.8868679","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868679","autoencoders;underwater image;image restoration;Generative Adverarial Networks;real-time","Image color analysis;Image restoration;Training;Image reconstruction;Degradation;Noise reduction;Videos","autonomous underwater vehicles;image colour analysis;image restoration;image sensors;inspection;learning (artificial intelligence)","color restoration;U-net Denoising Autoencoder;visual inspection;underwater structures;ROVs;scientific sectors;military sectors;commercial sectors;software tools;captured videos;Autoencoder model;U-Net architecture;computation cost;underwater visual tasks;end-to-end autoencoder network;captured frames;underwater tasks;related learning methods;generative adversarial networks;color corrected underwater images;single autoencoder;image pairs;underwater scenery;underwater vehicles perception;Underwater Denoising Autoencoder;UDAE model","","15","","20","","17 Oct 2019","","","IEEE","IEEE Conferences"
"Fault Diagnosis for Hydraulic Servo System: A Stacked Denoising Autoencoder Method based on Self-Learning of Robustness Features","Z. Wang; J. Fan; H. Huang; T. Han","Research and Development Department, China Academy of Launch Vehicle Technology, Beijing, China; Research and Development Department, China Academy of Launch Vehicle Technology, Beijing, China; Research and Development Department, China Academy of Launch Vehicle Technology, Beijing, China; Research and Development Department, China Academy of Launch Vehicle Technology, Beijing, China","2020 Chinese Automation Congress (CAC)","29 Jan 2021","2020","","","4479","4483","The fault diagnosis of hydraulic servo system attracts more attention in complex system prognostics and health management. As the precondition of most fault diagnosis methods, feature extraction could efficiently draw information from the initial data and supply more evidence to the following results. However, traditional time-frequency analysis largely depend on artificial selection and optimization, which are generally limited by the quality of input data and working environment. Thus this paper proposes a stacked deep learning based model to represent robust feature information in terms of the advantage of cognitive computing and pattern classification theory, which is shown to be suitable for certain applications with inevitable ambient noise and working condition fluctuations. To effectively realize feature reconstruction, a stacked denoising autoencoder (SDA) in which multiple encoders are established and trained is used. The employed deep neural network is trained layer by layer to extract high-level features, where the sparsity representation is applied to map the original inputs to better high-level features. Considering better robustness of the learnt features to avoid external interferences, the original input neural parameters of each autoencoder are denoised by randomly assigning some units to be zero. The modified denoising autoencoders are then stacked to initialize the deep hierarchical architecture instead of the original. High-level feature representations of the monitoring data samples are obtained based on unsupervised self-learning, and are set as the inputs of a top fault pattern classifier for final training, followed by a fine-tuning process. Validation data are collected to facilitate the comparison and evaluation of the fault diagnosis results of the SDA models, of which the denoising proportion is different for each. Experiments show an obvious advantage of the SDA model based on the self-learning of the robustness features for fault pattern classification.","2688-0938","978-1-7281-7687-1","10.1109/CAC51589.2020.9326938","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9326938","stacked denoising autoencoder;deep learning;hydraulic servo system;fault diagnosis","Noise reduction;Fault diagnosis;Feature extraction;Training;Robustness;Deep learning;Servomotors","deep learning (artificial intelligence);fault diagnosis;feature extraction;hydraulic systems;mechanical engineering computing;pattern classification;servomechanisms;time-frequency analysis;unsupervised learning","high-level features;modified denoising autoencoders;deep hierarchical architecture;high-level feature representations;unsupervised self-learning;fault pattern classifier;fault diagnosis;SDA model;fault pattern classification;hydraulic servo system;stacked denoising autoencoder method;complex system prognostics;health management;time-frequency analysis;optimization;stacked deep learning;robust feature information;cognitive computing;pattern classification theory;feature reconstruction;deep neural network","","1","","13","IEEE","29 Jan 2021","","","IEEE","IEEE Conferences"
"Short-Term Wind-Speed Forecasting Based on Multiscale Mathematical Morphological Decomposition, K-Means Clustering, and Stacked Denoising Autoencoders","W. Dong; H. Sun; Z. Li; J. Zhang; H. Yang","School of Electrical Engineering, Hebei University of Science and Technology, Shijiazhuang, China; School of Electrical Engineering, Hebei University of Science and Technology, Shijiazhuang, China; School of Electrical Engineering, Hebei University of Science and Technology, Shijiazhuang, China; School of Electrical Engineering, North China University of Science and Technology, Tangshan, China; Academic Affairs Office, Shijiazhuang Tiedao University, Shijiazhuang, China","IEEE Access","17 Aug 2020","2020","8","","146901","146914","Wind energy plays an increasingly important role in economic development. In this study, we propose a hybrid short-term wind-speed forecasting model comprising multiscale mathematical morphological decomposition (MMMD), K-means clustering algorithm, and stacked denoising autoencoder (SDAE) networks. First, in contrast to traditional signal-decomposing tools, the original wind-speed sequence is decomposed into a series of subsequences with different frequencies and fluctuant levels using the adaptive multiscale mathematical morphological algorithm directly in the time domain. The signal does not need to be transferred from the time domain to the frequency domain; hence, the accuracy can be considerably improved. Moreover, this is the first study that uses a time domain signal-decomposing tool in a hybrid wind forecasting model. Next, the data are split into different clusters of similar frequencies and fluctuant level subsequences using the K-means algorithm. The characteristics of each cluster are then captured using the SDAE as the core forecasting unit. Finally, the predictions of all subsequences are aggregated to obtain the final wind speed. The data from two real wind turbines are used to evaluate the performance of the proposed model, and the forecasting results are compared with five different benchmark models, namely, backpropagation neural network (BPNN), stacked denoising autoencoder (SDAE), mathematical morphology-backpropagation, mathematical morphology-SDAE, and K-means-SDAE for multiple scales, and two novel hybrid wind forecasting models namely, wavelet transform (WT)-K-means-SDAE and variation mode decomposition (VMD)-K-means-long short-term memory networks (LSTMs). The results of the comparison demonstrate that the proposed model provides a short-term wind-speed forecasting method whose prediction accuracy decreases with time; however, the proposed model achieves a better performance in comparison with other exiting models. At same time, the proposed model significantly increases the prediction accuracy of wind-speed forecasting and can be a reference for future research in this area.","2169-3536","","10.1109/ACCESS.2020.3015336","National Natural Science Foundation of China(grant numbers:51877070,51577048); Natural Science Foundation of Hebei Province(grant numbers:E2018208155,E2018210044); Talent Engineering Training Support Project of Hebei Province(grant numbers:A201905008); National Engineering Laboratory of Energy-Saving Motor and Control Technique, Anhui University(grant numbers:KFKT201901); Key Project of Scientific and Technological Research in Universities of Hebei Province(grant numbers:ZD2018228); Hebei Education Department Fund(grant numbers:QN2020433); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9163090","K-means clustering;multiscale mathematical morphological decomposition;short-term wind-speed forecasting;stacked denoising autoencoders","Predictive models;Forecasting;Mathematical model;Data models;Wind power generation;Morphology;Clustering algorithms","backpropagation;image denoising;load forecasting;mathematical morphology;neural nets;pattern clustering;power engineering computing;wavelet transforms;wind power;wind power plants;wind turbines","multiscale mathematical morphological decomposition;stacked denoising autoencoders;wind energy;short-term wind-speed forecasting model;clustering algorithm;autoencoder networks;traditional signal-decomposing tools;wind-speed sequence;adaptive multiscale mathematical morphological algorithm;frequency domain;time domain signal-decomposing tool;hybrid wind forecasting model;fluctuant level subsequences;core forecasting unit;final wind speed;wind turbines;different benchmark models;mathematical morphology-backpropagation;mathematical morphology-SDAE;K-means-SDAE;variation mode decomposition-K-means-long short-term memory networks;short-term wind-speed forecasting method;prediction accuracy","","6","","31","CCBY","10 Aug 2020","","","IEEE","IEEE Journals"
"A modulation classification method in cognitive radios system using stacked denoising sparse autoencoder","X. Zhu; T. Fujii","Advanced Wireless and Communication Research Center, The University of Electro-Communications, Tokyo, Japan; Advanced Wireless and Communication Research Center, The University of Electro-Communications, Tokyo, Japan","2017 IEEE Radio and Wireless Symposium (RWS)","27 Mar 2017","2017","","","218","220","This paper proposes a modulation classification method based on Stacked Denoising Sparse Autoencoder (SDAE). This method can extract modulation features automatically, and classify input signals based on the features it extracts. The scenarios of rapid classification and high accuracy classification are considered. In the rapid classification scenario, a long symbols sequence is not attainable for this scenario. Moreover, expert features are not necessary for this scenario, simplifying the modulation classification procedure and rendering rapid classification more achievable. In addition, in the high accuracy classification scenario, the higher cumulants are used as expert features due to its advantage over other tries at noise resistance. Moreover, we use complex symbols rather than pulse shaped complex signals as network input, which simplifies the network topology and saves the calculation overhead. The results of the average classification accuracy and the execution time are presented, indicating significant performance advantages over the other methods.","2164-2974","978-1-5090-3446-8","10.1109/RWS.2017.7885992","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7885992","modulation classification;cognitive radio;machine learning","Modulation;Feature extraction;Cognitive radio;Noise reduction;Manganese;Training;Resistance","cognitive radio;modulation;signal denoising","modulation classification method;cognitive radio system;stacked denoising sparse autoencoder;SDAE;feature extraction;complex symbols;network topology","","9","","7","","27 Mar 2017","","","IEEE","IEEE Conferences"
"Noise reduction in low-dose CT with stacked sparse denoising autoencoders","Z. Ma; Y. Zhang; W. Zhang; Y. Wang; F. Lin; K. He; X. Li; Y. Pu; J. Zhou","College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China","2016 IEEE Nuclear Science Symposium, Medical Imaging Conference and Room-Temperature Semiconductor Detector Workshop (NSS/MIC/RTSD)","19 Oct 2017","2016","","","1","2","Many approaches have been proposed to improve the quality of low-dose CT images from noisy projections. These approaches can be categorized into three groups: Sinogram filtering approaches, iterative reconstruction approaches and post-reconstruction restoration approaches. Sinogram filtering approaches directly smooth the raw data before filtered back-projection (FBP) is applied. Iterative reconstruction approaches optimize a prior-regularized objective function by iterative ways. Despite the successes achieved by these two kinds of approaches, researchers on these approaches are often limited in practice due to the difficulty of gaining well-formatted projection data from the commercial CT scanner. The post-reconstruction restoration approaches, which don't rely on the projection data, can be directly applied on low-dose CT and easily integrated into the current CT systems [1]. In this summary, we will focus on the third group. Inspired by the superior performance achieved by non-linear deep neural networks in the field of image processing, a stacked sparse denoising autoencoders (SSDA) based noise reduction method for low-dose CT imaging is presented in this summary. The experiments demonstrate the feasibility and effectiveness of our method.","","978-1-5090-1642-6","10.1109/NSSMIC.2016.8069500","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8069500","","Noise reduction;Computed tomography","computerised tomography;image denoising;image filtering;image reconstruction;iterative methods;medical image processing;neural nets","post-reconstruction restoration approaches;filtered back-projection;iterative reconstruction approaches;commercial CT scanner;low-dose CT imaging;CT systems;stacked sparse denoising autoencoders;noise reduction method;low-dose CT image quality;sinogram filtering approaches;nonlinear deep neural networks;image processing","","","","3","","19 Oct 2017","","","IEEE","IEEE Conferences"
"Spatio-temporal-Aware Sparse Denoising Autoencoder Neural Network for Air Quality Prediction","Y. Li; X. Shen; D. Han; J. Sun; Y. Shen","School of Computer and Information Engineering, Henan University Kaifeng, Henan, 475004, China; School of Computer and Information Engineering, Henan University Kaifeng, Henan, 475004, China; School of Computer and Information Engineering, Henan University Kaifeng, Henan, 475004, China; School of Computer and Information Engineering, Henan University Kaifeng, Henan, 475004, China; School of Computer and Information Engineering, Henan University Kaifeng, Henan, 475004, China","2018 5th IEEE International Conference on Cloud Computing and Intelligence Systems (CCIS)","14 Apr 2019","2018","","","96","100","Nowadays, air quality prediction is an important task. The main way to solve this problem is to use neural network, which are robust enough to handle time sensitive data. In this paper, we propose a novel spatio-temporal-aware sparse denoising autoencoding neural network architecture for this task. Our model makes full use of the spatio-temporal characteristics of the data, thus the accuracy of the prediction is improved. Experiments on historical dataset released by China National Environmental Monitoring Station and China Meteorological Administration show that our model achieves better performances than other models.","","978-1-5386-6005-8","10.1109/CCIS.2018.8691167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691167","Air quality prediction;Sparse Denoising auto-encoding;Spatio-temporal Dataset;Neural networks","","air pollution;air quality;environmental monitoring (geophysics);geophysical image processing;image coding;image denoising;image representation;neural net architecture;neural nets","air quality prediction;time sensitive data;spatio-temporal characteristics;spatio-temporal-aware sparse denoising autoencoding neural network architecture;historical dataset;China National Environmental Monitoring Station;China Meteorological Administration","","3","","13","","14 Apr 2019","","","IEEE","IEEE Conferences"
"Denoising for Intracranial Hemorrhage Images Using Autoencoder Based on CNN","W. Lin; M. Gao; C. Ruan; J. Zhong","Department of Mechanical Engineering, Ocean College University of Fuzhou, Fuzhou, Fujian Province, China; Department of Logistics Management, Ocean College University of Fuzhou, Fuzhou, Fujian Province, China; Department of Mechanical Engineering, Ocean College University of Fuzhou, Fuzhou, Fujian Province, China; Department of Mechanical Engineering, Ocean College University of Fuzhou, Fuzhou, Fujian Province, China","2021 IEEE International Conference on Computer Science, Electronic Information Engineering and Intelligent Control Technology (CEI)","29 Oct 2021","2021","","","520","523","Intracranial Hemorrhage, known as ICH, is a serious malady and is a major cause of stroke, disability, and death. Due to the malignant impact it would cause, it is essential to diagnose ICH in an efficient way. Meanwhile, the prevalence of artificial intelligence has caught people's attention and we considered that the diagnosis of ICH could be improved with the help of machine learning methods since these methods have succeeded in realms like speech recognition, visual object recognition, object detection etc. There have already been some computer aided diagnosis systems, based on machine learning methods, for helping the diagnosis of ICH, but most of them were used to classify the images and people seem to have ignored the importance of the quality of images. In this study, we applied a denoising method based on CNNs to improve the quality of ICH images based on CT. LeNet-5 and AlexNet were used due to their mighty ability to extract features. Autoencoder was used to reduce the dimensionality of the datasets to reduce the complexity of the data. Before denoising, we did some preprocessing in order to make our training faster by setting all images into a specific format. To test our model, three kinds of noise were added to the images, which were Salt&Pepper, Poisson and Gaussian. Lastly, we used Euclidean distance, which is the D-value of the pixel value between the original images and the processed ones, to measure the results of denoising images and determine their similarity to the original images. And the smaller the value, the better the effect. The results turned out that our denoising model is effective for all three kinds of noise, and the result of Salt&Pepper noise is the best.","","978-1-6654-3881-0","10.1109/CEI52496.2021.9574478","Natural Science Foundation of Fujian Province, China(grant numbers:2019J01211); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9574478","CNN;Autoencoder;intracranial hemorrhage;denoising","Training;Visualization;Computed tomography;Noise reduction;Process control;Machine learning;Speech recognition","feature extraction;image classification;image denoising;image segmentation;learning (artificial intelligence);medical image processing;neural nets;object detection;object recognition;object tracking;speech recognition","diagnosis systems;machine learning methods;denoising method;ICH images;autoencoder;original images;denoising model;intracranial Hemorrhage images;serious malady;malignant impact;artificial intelligence;people;speech recognition;visual object recognition;object detection etc","","","","26","","29 Oct 2021","","","IEEE","IEEE Conferences"
"Conditional Generative Denoising Autoencoder","S. Karatsiolis; C. N. Schizas","Department of Computer Science, University of Cyprus, Nicosia, Cyprus; Department of Computer Science, University of Cyprus, Nicosia, Cyprus","IEEE Transactions on Neural Networks and Learning Systems","5 Oct 2020","2020","31","10","4117","4129","We present a generative denoising autoencoder model that has an embedded data classifier in its architecture in order to take advantage of class-based discriminating features and produce better data samples. The proposed model is a conditional generative model and is sampled with a Markov chain Monte Carlo (MCMC) process according to a label that denotes the desired (or undesired) class or classes. In this sense, any chosen predefined class or characteristic may have a positive or negative effect on the image generation process, meaning that it can be instructed to be present or absent from the generated sample. We argue that allowing discriminative information in the form of feature detectors to be present in the latent representation of the autoencoder can be generally beneficial. This technique is an alternative approach to variational autoencoders (VAEs) that enforce a prior on the latent distribution. We further claim that supervised learning may be generally able to serve unsupervised learning through an interaction between the two paradigms. However, the extreme majority of research done on the interaction of the two learning regimes has the goal of using unsupervised learning to improve supervised learning. In this article, we explore the two learning paradigms' interaction in the opposite direction.","2162-2388","","10.1109/TNNLS.2019.2952203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924906","Artificial neural networks;image denoising;image sampling;multilayer perceptron;unsupervised learning","Noise reduction;Supervised learning;Training;Unsupervised learning;Decoding;Data models;Markov processes","feature extraction;image denoising;Markov processes;Monte Carlo methods;unsupervised learning","conditional generative denoising autoencoder;generative denoising autoencoder model;data samples;conditional generative model;Markov chain Monte Carlo process;image generation;discriminative information;feature detectors;latent representation;variational autoencoders;latent distribution;supervised learning;unsupervised learning;learning paradigms interaction;opposite direction;learning regimes;MCMC;class-based discriminating features;data classifier embedding;VAEs","","3","","41","IEEE","5 Dec 2019","","","IEEE","IEEE Journals"
"Omnidirectional Ring Structured Light Noise Filtering Based On DCGAN Network And Autoencoder","W. Li; T. Jia; Q. Chen; Y. Wu; J. Wang; J. Huang","College of Information Science and Engineering, Northeastern University, ShenYang, China; College of Information Science and Engineering, Northeastern University, ShenYang, China; College of Information Science and Engineering, Northeastern University, ShenYang, China; College of Information Science and Engineering, Northeastern University, ShenYang, China; College of Information Science and Engineering, Northeastern University, ShenYang, China; College of Information Science and Engineering, Northeastern University, ShenYang, China","2020 International Conference on Culture-oriented Science & Technology (ICCST)","24 Nov 2020","2020","","","452","456","The omnidirectional ring structured light depth perception system can project a 360-degree structured light.However, due to the influence of ambient light, refraction and other noise factors, it is easy to cause false detection of structured light. Therefore, denoising plays an important role in the omnidirectional ring structured light depth perception system.Firstly, this paper uses the DCGAN network to generate more data sets due to the lack of data sets. Secondly, based on the above data sets, this paper uses the autoencoder network to denoise the ring structured light. Experiments show that by using a combination of DCGAN and autoencoder network for denoising, the structured light’s noise is lesstherefore more robust to the surrounding environment compared to other methods.","","978-1-7281-8138-7","10.1109/ICCST50977.2020.00093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262722","DCGAN network;autoencoder;denoising;omnidirectional ring structured light;depth perception","Noise reduction;Structural rings;Convolution;Training;Data models;Training data;Generators","image denoising;image filtering;neural nets;object detection","noise factors;DCGAN network;data sets;autoencoder network;omnidirectional ring structured light noise filtering;360-degree structured light;refraction;omnidirectional ring structured light depth perception system","","","","15","IEEE","24 Nov 2020","","","IEEE","IEEE Conferences"
"Single channel audio source separation using convolutional denoising autoencoders","E. M. Grais; M. D. Plumbley","Speech and Signal Processing, University of Surrey, Guildford, UK; Speech and Signal Processing, University of Surrey, Guildford, UK","2017 IEEE Global Conference on Signal and Information Processing (GlobalSIP)","8 Mar 2018","2017","","","1265","1269","Deep learning techniques have been used recently to tackle the audio source separation problem. In this work, we propose to use deep fully convolutional denoising autoencoders (CDAEs) for monaural audio source separation. We use as many CDAEs as the number of sources to be separated from the mixed signal. Each CDAE is trained to separate one source and treats the other sources as background noise. The main idea is to allow each CDAE to learn suitable spectral-temporal filters and features to its corresponding source. Our experimental results show that CDAEs perform source separation slightly better than the deep feedforward neural networks (FNNs) even with fewer parameters than FNNs.","","978-1-5090-5990-4","10.1109/GlobalSIP.2017.8309164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8309164","Fully convolutional denoising autoencoders;single channel audio source separation;stacked convolutional autoencoders;deep convolutional neural networks;deep learning","Convolution;Spectrogram;Two dimensional displays;Source separation;Feature extraction;Noise reduction;Convolutional codes","audio coding;convolution;feature extraction;feedforward neural nets;filtering theory;learning (artificial intelligence);signal denoising;source separation;spatiotemporal phenomena","deep feedforward neural networks;single channel audio source separation;deep learning techniques;fully convolutional denoising autoencoders;CDAE;monaural audio source separation;FNN;spectral-temporal filters","","48","","36","","8 Mar 2018","","","IEEE","IEEE Conferences"
"Recognition of online handwritten Bangla characters using hierarchical system with Denoising Autoencoders","A. Pal; J. D. Pawar","Department of C. S. T, Goa University, Goa, India; Department of C. S. T, Goa University, Goa, India","2015 International Conference on Computation of Power, Energy, Information and Communication (ICCPEIC)","14 Sep 2015","2015","","","0047","0051","This work describes the recognition of online handwritten Bengali characters using Deep Denoising Autoencoder with Multilayer Perceptron (MLP) trained through backpropagation algorithm [1]. Initial pre-training has been done to the Denoising Autoencoder with MLP trained through backpropagation algorithm, to bring the weights of the Deep network to some good solution and then pre-trained Denoising Autoencoders are stacked to form a Deep Denoising Autoencoder (DDA). A final classification layer makes DDA to a Deep Classifier (DC) followed by a final fine-tune that gives the best classifier for the job of classification of Bengali characters. The overall system is hierarchical in nature and the system has been trained in two phase where the first phase has trained a broad classifier and in the second phase class specific recognizer has been trained. At the testing phase in this hierarchical approach, first a broad classifier has been used to recognize broad classes like Vowel, Consonant, Special Symbol and Numeral for a novel test sample. Once the broad class gets recognized then a class specific recognizer has been used to recognize the exact character the test sample belongs. Recognition performance of the hierarchical system is 93.12%.","","978-1-4673-6525-3","10.1109/ICCPEIC.2015.7259440","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7259440","MLP;Denoising Autoencoder;Deep Network;Bengali Character;Classification","Handwriting recognition;Character recognition;Hidden Markov models;Backpropagation algorithms;Computational modeling;Numerical models","backpropagation;handwriting recognition;handwritten character recognition;image classification;image denoising;multilayer perceptrons;natural language processing","online handwritten BangIa character recognition;hierarchical system;deep denoising autoencoder;DDA;multilayer perceptron;MLP;backpropagation algorithm;classification layer;deep classifier;DC","","3","","25","","14 Sep 2015","","","IEEE","IEEE Conferences"
"Network intrusion detection based on Contractive Sparse Stacked Denoising Autoencoder","J. Lu; H. Meng; W. Li; Y. Liu; Y. Guo; Y. Yang","State Grid Henan Information &Telecommunication Company, Zhengzhou, China; State Grid Henan Information &Telecommunication Company, Zhengzhou, China; State Grid Henan Information &Telecommunication Company, Zhengzhou, China; State Grid Henan Information &Telecommunication Company, Zhengzhou, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China","2021 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)","1 Oct 2021","2021","","","1","6","The rapid growth of network scale leads to the increasingly prominent network security problems. Intrusion detection is an important method to resist complex and growing network attacks. For traditional shallow intrusion detection methods can not effectively identify and classify network intrusion data, this paper proposes a Contractive Sparse Stack Denoising Autoencoder(CSSDAE), which cascades multiple traditional Autoencoders, and introduces noise, sparse constraint and contractive penalty term on this basis, so as to improve the robustness of the model, enhance decoding ability of the deep network and promote intrusion detection performance. In addition, this paper improves the softmax classifier to make the feature vectors as compact as possible within the class and separate as much as possible between classes, and solves the problem of uneven number of sample classes by weighting. The experimental results show that compared with traditional AE, the CSSDAE's accuracy of network intrusion detection is effectively improved.","2155-5052","978-1-6654-4908-3","10.1109/BMSB53066.2021.9547087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9547087","autoencoder;characteristic dimension reduction;sparse denoising;softmax;intrusion detection","Noise reduction;Network intrusion detection;Resists;Network security;Broadcasting;Robustness;Data models","computer network security;feature extraction;pattern classification;signal denoising","intrusion detection performance;deep network;contractive penalty term;sparse constraint;multiple traditional Autoencoders;network intrusion data;traditional shallow intrusion detection methods;network attacks;network security problems;network scale;contractive sparse stacked denoising autoencoder;network intrusion detection","","1","","9","IEEE","1 Oct 2021","","","IEEE","IEEE Conferences"
"Stacked Multilevel-Denoising Autoencoders: A New Representation Learning Approach for Wind Turbine Gearbox Fault Diagnosis","G. Jiang; H. He; P. Xie; Y. Tang","School of Electrical Engineering, Yanshan University, Qihuangdao, China; Department of Electrical, Computer and Biomedical Engineering, The University of Rhode Island, Kingston, RI, USA; School of Electrical Engineering, Yanshan University, Qihuangdao, China; Institute for Sensing and Embedded Network Systems Engineering, Florida Atlantic University, Boca Raton, FL, USA","IEEE Transactions on Instrumentation and Measurement","9 Aug 2017","2017","66","9","2391","2402","Currently, vibration analysis has been widely considered as an effective way to fulfill the fault diagnosis task of gearboxes in wind turbines (WTs). However, vibration signals are usually with abundant noise and characterized as nonlinearity and nonstationarity. Therefore, it is quite challenging to extract robust and useful fault features from complex vibration signals to achieve an accurate and reliable diagnosis. This paper proposes a novel feature representation learning approach, named stacked multilevel-denoising autoencoders (SMLDAEs), with the aim to learn robust and discriminative fault feature representations through a deep network architecture for diagnosis accuracy improvement. In our proposed approach, we design an MLD training scheme, which uses multiple noise levels to train AEs. It enables to learn more general and detailed fault feature patterns simultaneously at different scales from the complex frequency spectra of the raw vibration data, and therefore helps enhance the feature learning and fault diagnosis capability. Furthermore, SMLDAE-based fault diagnosis is performed with an unsupervised representation learning procedure followed by a supervised fine-tuning process with label information for classification. Our approach is evaluated by using the field vibration data collected from a self-designed WT gearbox test rig. The results show that our proposed approach learned more robust and discriminative fault feature representations and achieved the best diagnosis accuracy compared with the traditional approaches.","1557-9662","","10.1109/TIM.2017.2698738","National Natural Science Foundation of China(grant numbers:61673336); Natural Science Foundation of Hebei Province(grant numbers:F2016203421); Scientific Research Project of the Higher Education Institutions of Hebei Province(grant numbers:ZD20131080); National Science Foundation(grant numbers:ECCS 1053717,CCF 1439011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7932980","Fault diagnosis;multilevel-denoising (MLD) training;stacked denoising autoencoders (SDAEs);vibration representation learning;wind turbine (WT) gearbox","Feature extraction;Fault diagnosis;Vibrations;Training;Robustness;Noise reduction;Wind turbines","condition monitoring;encoding;fault diagnosis;feature extraction;gears;learning (artificial intelligence);neural nets;power engineering computing;signal classification;signal denoising;vibrational signal processing;wind turbines","wind turbine gearbox fault diagnosis;vibration signals;signal classification;supervised fine tuning process;deep network architecture;discriminative fault feature representations learning;stacked multilevel denoising autoencoder;novel feature representation learning method","","164","","41","IEEE","23 May 2017","","","IEEE","IEEE Journals"
"Fast Mesh Denoising With Data Driven Normal Filtering Using Deep Variational Autoencoders","S. Nousias; G. Arvanitis; A. S. Lalos; K. Moustakas","Department of Electrical and Computer Engineering, University of Patras, Rion Patras, Greece; Department of Electrical and Computer Engineering, University of Patras, Rion Patras, Greece; Industrial Systems Institute, Athena Research Center, Marousi, Greece; Department of Electrical and Computer Engineering, University of Patras, Rion Patras, Greece","IEEE Transactions on Industrial Informatics","19 Nov 2020","2021","17","2","980","990","Recent advances in 3-D scanning technology have enabled the deployment of 3-D models in various industrial applications such as digital twins, remote inspection, and reverse engineering. Despite their evolving performance, 3-D scanners still introduce noise and artifacts in the acquired dense models. In this article, we propose a fast and robust denoising method for the dense 3-D scanned industrial models. The proposed approach employs conditional variational autoencoders to effectively filter face normals. Training and inference are performed in a sliding patch setup reducing the size of the required training data and execution times. We conducted extensive evaluation studies using 3-D scanned and CAD models. The results verify plausible denoising outcomes, demonstrating similar or higher reconstruction accuracy, compared to other state-of-the-art approaches. Specifically, for 3-D models with more than 1e4 faces, the presented pipeline is twice as fast as methods with equivalent reconstruction error.","1941-0050","","10.1109/TII.2020.3000491","European Union Horizon 2020 Research and innovation program; WARMEST; Marie Sklodowska(grant numbers:777981); European Union Horizon 2020 Research and Innovation Program Ageing@Work(grant numbers:826299); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9110709","3-D mesh denoising;data driven normal filtering;variational autoencoders","Three-dimensional displays;Noise reduction;Face;Solid modeling;Training;Tensors;Decoding","automatic optical inspection;CAD;image denoising;image filtering;image reconstruction;learning (artificial intelligence);neural nets;production engineering computing;reverse engineering","reverse engineering;higher reconstruction accuracy;similar reconstruction accuracy;CAD models;conditional variational autoencoders;remote inspection;digital twins;industrial applications;3-D scanning technology;deep variational autoencoders;data driven normal filtering;fast mesh denoising","","6","","35","CCBY","8 Jun 2020","","","IEEE","IEEE Journals"
"Denoising Autoencoder Aided Spectrum Reconstruction for Colloidal Quantum Dot Spectrometers","J. Zhang; X. Zhu; J. Bao","Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Mathematics, University of Iowa, Iowa City, IA, USA; Department of Electronic Engineering, Tsinghua University, Beijing, China","IEEE Sensors Journal","4 Feb 2021","2021","21","5","6450","6458","Recently, the colloidal quantum dot spectrometer has received much attention due to its advantages in cost, size, and operation. Yet, just like many other filter-based miniature spectrometers, spectrum reconstruction for the colloidal quantum dot spectrometer is typically prone to the measurement noise due to the correlation of the filters. In this paper, we propose an effective spectrum reconstruction method for the colloidal quantum dot spectrometer, which can recover high-quality spectra in noisy environments. Specifically, we employ a denoising autoencoder, a machine-learning approach, to reduce noise in the filters' raw measurements before performing the reconstruction. After that, we reconstruct the spectra with the denoised data by a sparse recovery algorithm. We investigate the feasibility of the proposed reconstruction approach on a synthetic dataset and an experimental dataset collected by the colloidal quantum dot spectrometer. The results demonstrate that the proposed approach could deliver accurate reconstruction results even when data are corrupted with the measurement noise.","1558-1748","","10.1109/JSEN.2020.3039973","Beijing National Research Center for Information Science and Technology(grant numbers:BNR2019ZS01005); Beijing Innovation Center for Future Chips, Tsinghua University; Simons Foundation(grant numbers:504054); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9269398","Miniature spectrometer;denoising autoencoder;spectrum reconstruction","Sensors;Noise reduction;Image reconstruction;Reconstruction algorithms;Quantum dots;Noise measurement;Sensitivity","colloids;computerised instrumentation;learning (artificial intelligence);signal denoising;signal reconstruction;spectrometers","autoencoder aided spectrum reconstruction;colloidal quantum dot spectrometer;filter-based miniature spectrometers;noisy environments;denoising autoencoder;machine-learning approach;sparse recovery algorithm;synthetic dataset;experimental dataset;measurement noise","","1","","39","IEEE","24 Nov 2020","","","IEEE","IEEE Journals"
"An Approach to Image Denoising Using Autoencoders and Spatial Filters for Gaussian Noise","A. P. Patil; A. Pramod; A. Harish; K. Singh; K. Purushotham","Department of Computer Science and Engineering, Ramaiah Institute of technology, Bangalore, India; Department of Computer Science and Engineering, Ramaiah Institute of technology, Bangalore, India; Department of Computer Science and Engineering, Ramaiah Institute of technology, Bangalore, India; Department of Computer Science and Engineering, Ramaiah Institute of technology, Bangalore, India; Department of Computer Science and Engineering, Ramaiah Institute of technology, Bangalore, India","2021 11th International Conference on Cloud Computing, Data Science & Engineering (Confluence)","15 Mar 2021","2021","","","454","458","At a prime age in data science where information extracted from a large variety of data sources drives a lot of research, the need for having clean data is important. Accumulation and extraction of pure and specific data from such sources is an important stage in this area. It is important to consider noise from the data sources in order to pre-process the data. The work focuses specifically on handling Gaussian noise in acquired images that are used in specific domains like image classification. The work proposes a denoising pipeline involving spatial filters and autoencoder networks to remove Gaussian noise in image data to achieve high performance in computer vision tasks. Image data that is abundantly available can be put to good use by the proposed denoising pipeline which enhances machine interpretation of such data. The work provides an empirical analysis on the results obtained and discusses important trends observed.","","978-1-6654-1451-7","10.1109/Confluence51648.2021.9377166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9377166","Autoencoder;Gaussian Noise;Image Denoising;Spatial Filters","Gaussian noise;Pipelines;Noise reduction;Computer architecture;Market research;Spatial filters;Data mining","computer vision;filtering theory;Gaussian noise;image classification;image denoising;neural nets;spatial filters","data science;data sources drives;clean data;pure data;Gaussian noise;image classification;denoising pipeline;spatial filters;autoencoder networks;image data;prime age;autoencoders","","","","15","","15 Mar 2021","","","IEEE","IEEE Conferences"
"Investigation of Network Architecture for Single-Channel End-to-End Denoising","T. Hasumi; T. Kobayashi; T. Ogawa","Department of Communications and Computer Engineering, Waseda University, Tokyo, Japan; Department of Communications and Computer Engineering, Waseda University, Tokyo, Japan; Department of Communications and Computer Engineering, Waseda University, Tokyo, Japan","2020 28th European Signal Processing Conference (EUSIPCO)","18 Dec 2020","2021","","","441","445","This paper examines the effectiveness of a fully convolutional time-domain audio separation network (Conv-TasNet) on single-channel denoising. Conv-TasNet, which has a structure to explicitly estimate a mask for encoded features, has shown to be effective in single-channel sound source separation in noise-free environments, but it has not been applied to denoising. Therefore, the present study investigates a method of learning Conv-TasNet for denoising and clarifies the optimal structure for single-channel end-to-end modeling. Experimental comparisons conducted using the CHiME-3 dataset demonstrate that Conv-TasNet performs well in denoising and yields improvements in single-channel end-to-end denoising over existing denoising autoencoder-based modeling.","2076-1465","978-9-0827-9705-3","10.23919/Eusipco47968.2020.9287753","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287753","fully convolutional time-domain audio separation network;time-domain convolutional denoising autoencoders;end-to-end modeling;single-channel denoising;speech recognition","Convolution;Noise reduction;Speech recognition;Data models;Decoding;Time-domain analysis;Periodic structures","convolution;neural nets;signal denoising;source separation;speech enhancement","Conv-TasNet;single-channel end-to-end denoising;network architecture;fully convolutional time-domain audio separation network;single-channel denoising;single-channel sound source separation;single-channel end-to-end modeling;denoising autoencoder-based modeling;CHiME-3 dataset","","","","26","","18 Dec 2020","","","IEEE","IEEE Conferences"
"Spectral unmixing through part-based non-negative constraint denoising autoencoder","Y. Qu; R. Guo; H. Qi","EECS Department, The University of Tennessee, Knoxville, TN; EECS Department, The University of Tennessee, Knoxville, TN; EECS Department, The University of Tennessee, Knoxville, TN","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","209","212","Spectral unmixing is to decompose the hyperspectral data into endmembers and abundances. It has been known to be a challenging and ill-posed task due to the corruption of noise as well as complex environmental conditions. In this paper, we propose a part-based denoising autoencoder with unique structure that solves the unmixing challenges. The effective l21 norm and denoising constraints are applied on the network to better handle noise, while at the same time reducing the reconstruction error and redundant endmembers simultaneously. A back propagation optimization method powered with the Armijo rule is proposed to project the weights to the non-negativity space that guarantees the sum-to-one constraint. The experimental results demonstrate the proposed approach is able to outperform several state-of-the-art methods for highly noisy data.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8126931","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8126931","Hyperspectral image;spectral unmixing;part-based denoising autoencoder","Noise reduction;Signal to noise ratio;Noise measurement;Bayes methods;Decoding;Force;Hyperspectral imaging","backpropagation;hyperspectral imaging;image denoising;optimisation","denoising constraints;reconstruction error;redundant endmembers;back propagation optimization method;nonnegativity space;highly noisy data;noise handling;part-based non-negative constraint denoising autoencoder;l21 norm;Armijo rule;sum-to-one constraint;complex environmental conditions;abundances;hyperspectral data;spectral unmixing","","10","","17","","4 Dec 2017","","","IEEE","IEEE Conferences"
"Denoising Sparse Autoencoder-Based Ictal EEG Classification","Y. Qiu; W. Zhou; N. Yu; P. Du","School of Microelectronics, Shandong University, Jinan, China; School of Microelectronics, Shandong University, Jinan, China; School of Microelectronics, Shandong University, Jinan, China; School of Microelectronics, Shandong University, Jinan, China","IEEE Transactions on Neural Systems and Rehabilitation Engineering","6 Sep 2018","2018","26","9","1717","1726","Automatic seizure detection technology can automatically mark the EEG by using the epileptic detection algorithm, which is helpful to the diagnosis and treatment of epileptic diseases. This paper presents an EEG classification framework based on the denoising sparse autoencoder. The denoising sparse autoencoder (DSAE) is an improved unsupervised deep neural network over sparse autoencoder and denoising autoencoder, which can learn the closest representation of the data. The sparsity constraint applied in the hidden layer of the network makes the expression of data as sparse as possible so as to obtain a more efficient representation of EEG signals. In addition, corrupting operation used in input data help to enhance the robustness of the system and make it suitable for the analysis of non-stationary epileptic EEG signals. In this paper, we first imported the pre-processed training data to the DSAE network and trained the network. A logistic regression classifier was connected to the top of the DSAE. Then, put the test data into the system for classification. Finally, the output results of the overall network were post-processed to obtain the final epilepsy detection results. In the two-class (nonseizure and seizure EEGs) problem, the system has achieved effective results with the average sensitivity of 100%, specificity of 100%, and recognition of 100%, showing that the proposed framework can be efficient for the classification of epileptic EEGs.","1558-0210","","10.1109/TNSRE.2018.2864306","Natural Science Foundation of Shandong Province(grant numbers:ZR2013FZ002); Development Program of Science and Technology of Shandong(grant numbers:2014GSF118171); Shandong University(grant numbers:2014QY008); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8429921","Automatic seizure detection;epileptic EEG;denoising sparse autoencoder;logistic regression classifier","Electroencephalography;Epilepsy;Noise reduction;Neurons;Feature extraction;Databases;Standardization","diseases;electroencephalography;medical signal detection;medical signal processing;neural nets;regression analysis;signal classification;signal denoising;unsupervised learning","epileptic EEGs;automatic seizure detection technology;epileptic detection algorithm;epileptic diseases;denoising sparse autoencoder;nonstationary epileptic EEG signals;pre-processed training data;DSAE network;unsupervised deep neural network;epilepsy detection results;ictal EEG classification;diagnosis;sparsity constraint;hidden layer;logistic regression classifier","Algorithms;Data Interpretation, Statistical;Electroencephalography;Epilepsy;Humans;Logistic Models;Neural Networks, Computer;Seizures;Sensitivity and Specificity;Signal-To-Noise Ratio","25","","64","IEEE","8 Aug 2018","","","IEEE","IEEE Journals"
"Multi-Modal Stacked Denoising Autoencoder for Handling Missing Data in Healthcare Big Data","J. -C. Kim; K. Chung","Department of Computer Science, Kyonggi University, Suwon-si, South Korea; Division of Computer Science and Engineering, Kyonggi University, Suwon-si, South Korea","IEEE Access","11 Jun 2020","2020","8","","104933","104943","Supply and demand increase in response to healthcare trends. Moreover, personal health records (PHRs) are being managed by individuals. Such records are collected using different avenues and vary considerably in terms of their type and scope depending on the particular circumstances. As a result, some data may be missing, which has a negative effect on the data analysis, and such data should, therefore, be replaced with appropriate values. In this study, a method for estimating missing data using a multi-modal autoencoder applied to the field of healthcare big data is proposed. The proposed method uses a stacked denoising autoencoder to estimate the missing data that occur during the data collection and processing stages. Autoencoders are neural networks that output value of x^ similar to an input value of x. In the present study, data from the Korean National Health Nutrition Examination Survey (KNHNES), conducted by the Korea Centers for Disease Control and Prevention (KCDC), are used. As representative healthcare data from South Korea, they contain a large number of parameters identical to those used in the PHRs. Based on this, models can be generated to estimate missing data occurring in PHRs. Furthermore, PHRs involve a multi-modality that allows the data to be collected from multiple sources for a single object. Therefore, the stacked denoising autoencoder applied is configured under a multi-modal setting. Through pre-processing, a set of data without missing value in KNHNES is designed. In the data set based learning, a label is set as original data, and an autoencoder input is set as noised input that additionally has as many random zero numbers as noise factor. In this way, the autoencoder learns in the way of making the zero-based noise value similar to the original label value. When the amount of missing data in a dataset reaches approximately 25%, the accuracy of the proposed method using a multi-modal stacked denoising autoencoder is 0.9217, which is higher than that achieved by other ordinary methods. For a single-modal denoising autoencoder, the accuracy is 0.932, with a slight difference of approximately 0.01, which falls within the allowable limits in data analysis. In terms of computational performance, a single-modal autoencoder has 10,384 parameters, which is 5,594 more than those used in a multi-modal stacked autoencoder. These parameters affect the speed of the model. Both models exhibit a significant difference in the number of parameters but demonstrate a relatively small difference in accuracy, suggesting that the proposed multi-modal stacked denoising autoencoder is advantageous over a single-modal model when used on a personal device. Moreover, a multi-modal model can save additional time when processing large amounts of data in locations such as hospitals and institutions.","2169-3536","","10.1109/ACCESS.2020.2997255","Korea Agency for Infrastructure Technology Advancement (KAIA); Ministry of Land, Infrastructure, and Transport(grant numbers:20CTAP-C157011-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9099281","Autoencoder;data pre-processing;data estimation;data imputation;health big data;multi-modal;missing data;machine learning","Medical services;Big Data;Noise reduction;Machine learning;Data models;Computational modeling;Estimation","Big Data;data analysis;diseases;health care;learning (artificial intelligence);medical computing;medical information systems","multimodal stacked denoising autoencoder;missing data;healthcare big data;PHRs;data analysis;data collection;processing stages;representative healthcare data;multimodal setting;single-modal denoising autoencoder;multimodal model;Korea Centers for Disease Control and Prevention;PHR;KNHNES;random zero numbers","","18","","45","CCBY","25 May 2020","","","IEEE","IEEE Journals"
"Link-Information Augmented Twin Autoencoders for Network Denoising","Z. Liu; L. Pan; G. Chen","Big Data Research Center and Web Sciences Center, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China.; Big Data Research Center and Web Sciences Center, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China.; Department of Electrical Engineering, City University of Hong Kong, Hong Kong, SAR, China.","IEEE Transactions on Cybernetics","","2022","PP","99","1","11","Removing noisy links from an observed network is a task commonly required for preprocessing real-world network data. However, containing both noisy and clean links, the observed network cannot be treated as a trustworthy information source for supervised learning. Therefore, it is necessary but also technically challenging to detect noisy links in the context of data contamination. To address this issue, in the present article, a two-phased computational model is proposed, called link-information augmented twin autoencoders, which is able to deal with: 1) link information augmentation; 2) link-level contrastive denoising; 3) link information correction. Extensive experiments on six real-world networks verify that the proposed model outperforms other comparable methods in removing noisy links from the observed network so as to recover the real network from the corrupted one very accurately. Extended analyses also provide interpretable evidence to support the superiority of the proposed model for the task of network denoising.","2168-2275","","10.1109/TCYB.2022.3160470","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745753","Link-information augmentation;link-information correction;network denoising;twin autoencoder (AE)","Noise measurement;Noise reduction;Task analysis;Image edge detection;Computational modeling;Brain modeling;Anomaly detection","","","","","","","IEEE","31 Mar 2022","","","IEEE","IEEE Early Access Articles"
"Deep Learning Hyperspectral Image Classification using Multiple Class-Based Denoising Autoencoders, Mixed Pixel Training Augmentation, and Morphological Operations","J. E. Ball; P. Wei","Department of Electrical and Computer Engineering, Mississippi State University; Department of Electrical and Computer Engineering, Mississippi State University","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","6903","6906","Herein, we present a system for hyperspectral image segmentation that utilizes multiple class-based denoising autoen-coders which are efficiently trained. Moreover, we present a novel hyperspectral data augmentation method for labelled HSI data using linear mixtures of pixels from each class, which helps the system with edge pixels which are almost always mixed pixels. Finally, we utilize a deep neural network and morphological hole-filling to provide robust image classification. Results run on the Salinas dataset verify the high performance of the proposed algorithm.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8519368","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8519368","Deep learning;remote sensing;denoising auto encoder","Training data;Training;Hyperspectral imaging;Noise reduction;Feature extraction","geophysical image processing;hyperspectral imaging;image classification;image segmentation;learning (artificial intelligence);neural nets;probability;remote sensing","multiple class-based denoising autoencoders;mixed pixel training augmentation;morphological operations;hyperspectral image segmentation;hyperspectral data augmentation method;edge pixels;deep neural network;morphological hole-filling;robust image classification;HSI data;deep learning hyperspectral image classification;linear mixtures;Salinas dataset;remote sensing","","2","","9","","4 Nov 2018","","","IEEE","IEEE Conferences"
"Improving generation performance of speech emotion recognition by denoising autoencoders","L. Chao; J. Tao; M. Yang; Y. Li","National Laboratory of Pattern Recognition (NLPR), Chinese Academy of Sciences, Beijing; Institute of Automation Chinese Academy of Sciences, Beijing, Beijing, CN; National Laboratory of Pattern Recognition (NLPR), Chinese Academy of Sciences, Beijing; National Laboratory of Pattern Recognition (NLPR), Chinese Academy of Sciences, Beijing","The 9th International Symposium on Chinese Spoken Language Processing","27 Oct 2014","2014","","","341","344","A speech emotion recognition algorithm should generalize well when the target person's speech samples and prior knowledge about their emotional content are not included in the training data. In order to achieve this objective, we utilize denoising autoencoders based approach to solve this task. In this study, a relatively small dataset, which contains close to 1500 persons' emotion sentences, is introduced. By unsupervised pre-training with this dataset, denoising autoencoders learn features which contain more emotion-specific information than speaker-specific information in data successfully. Experiment results in CASIA dataset show that this denoising autoencoders based approach can improve the generation performance of speech emotion recognition significantly.","","978-1-4799-4219-0","10.1109/ISCSLP.2014.6936627","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6936627","speech emotion recognition;denoising autoencoders","Databases;Speech;Noise reduction;Emotion recognition;Speech recognition;Training;Feature extraction","emotion recognition;encoding;learning (artificial intelligence);signal denoising;speech recognition","generation performance improvement;speech emotion recognition algorithm;target person speech samples;emotional content;training data;denoising autoencoder-based approach;emotion sentences;unsupervised pretraining;feature learning;emotion-specific information;CASIA dataset","","9","","15","","27 Oct 2014","","","IEEE","IEEE Conferences"
"A Novel Variational Autoencoder based Radar Signal Reconstruction Algorithm Using Polluted Data","Z. Jing; B. Wu; P. Li; R. Yang; J. Li; Z. Wang","Key Laboratory of Electronic Information Countermeasure and Simulation Technology Ministry of Education, School of Electronic Engineering, Xidian University, Xi'an, Shaanxi Province, China; Key Laboratory of Electronic Information Countermeasure and Simulation Technology Ministry of Education, School of Electronic Engineering, Xidian University, Xi'an, Shaanxi Province, China; Key Laboratory of Electronic Information Countermeasure and Simulation Technology Ministry of Education, School of Electronic Engineering, Xidian University, Xi'an, Shaanxi Province, China; Key Laboratory of Electronic Information Countermeasure and Simulation Technology Ministry of Education, School of Electronic Engineering, Xidian University, Xi'an, Shaanxi Province, China; Key Laboratory of Electronic Information Countermeasure and Simulation Technology Ministry of Education, School of Electronic Engineering, Xidian University, Xi'an, Shaanxi Province, China; Key Laboratory of Electronic Information Countermeasure and Simulation Technology Ministry of Education, School of Electronic Engineering, Xidian University, Xi'an, Shaanxi Province, China","IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium","17 Feb 2021","2020","","","2715","2718","In the transmission process, radar signal could be polluted easily, and the radar individual recognition process will be undermined by the polluted data. Some existing algorithms so far use the image denoising method to deal with this issue while ignoring the essential characteristics of the signal, and thus the noise reduction effect is poor. To address this issue, a novel variational autoencoder based radar signal reconstruction algorithm is proposed in this paper to reconstruct high quality data from the polluted ones by compressing the one-dimensional polluted signal and learning the essential characteristics. The experiments prove that the algorithm indeed improves the quality of the reconstructed data compared with the polluted signal.","2153-7003","978-1-7281-6374-1","10.1109/IGARSS39084.2020.9323729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9323729","Radar individual recognization;Deep Neural Network;Variational autoencoder;Noise reduction","Signal to noise ratio;Radar;Training;Image reconstruction;Signal reconstruction;Radar countermeasures;Radar imaging","image denoising;image reconstruction;radar signal processing;signal denoising;signal reconstruction","reconstructed data;polluted data;transmission process;radar individual recognition process;image denoising method;essential characteristics;noise reduction effect;novel variational autoencoder based radar signal reconstruction algorithm;polluted ones;one-dimensional polluted signal","","2","","6","","17 Feb 2021","","","IEEE","IEEE Conferences"
"Denoising The Wireless Channel Corrupted Images Using Machine Learning","M. Sufian; A. Khan; T. Saeed; Z. Khan","Department of Computer Engineering, National University of Science & Technology (NUST), Islamabad, Pakistan; Department of Computer Engineering, National University of Science & Technology (NUST), Islamabad, Pakistan; Department of Computer Engineering, National University of Science & Technology (NUST), Islamabad, Pakistan; Department of Computer Engineering, National University of Science & Technology (NUST), Islamabad, Pakistan","2019 20th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)","19 Dec 2019","2019","","","1","6","Digital communication depends on channel coding for the integrity and correct reception of the data. The traditional communication techniques ignore the context and content associated with the received data while mitigating the channel effects. Image transmission in digital communication have many major constraints. Image quality degrades over wireless channel due to limited characteristic of transmitted data. To mitigate the effects of the noisy channel on the images different image denoising techniques are used such as DCT, Convolutional Denoising Autoencoders, DWT, BM3D, FFT, NLM and Deep Learning. Main objective of this paper is to study the application of machine learning in digital communication to correct errors and remove the effects of channel degradation. This will help us improve the energy consumption, resource utilization, and the Bit Error Rate. It will enable us to communicate with low bandwidth and using minimum resources. Machine learning for denoising the image has attracted substantial attentions because of its high denoising performance. We have constructed a Convolutional Neural Network that will denoise the image which is corrupted by the noisy channel. The existing traditional models only denoise the image for a specific noise type (Gaussian noise) and certain noise level σ = 25, but our trained network denoise the image for unknown noise level. By using the methods of batch normalization and residual learning the denoising performance is increased. Experiments prove that our trained model displays high efficiency in image denoising. The proposed network is trained in MATLAB and Python with the help of GPU computing which accelerates neural network's performance. The application areas of this paper mainly are in the domains related to digital communications. This include wireless communications, optical communications and line communications. However, as the wireless communications (especially underwater wireless) is extremely error prone, so this domain will be highly benefited. The applications can include military communications, Underwater Communication and Noisy Industrial Communication.","","978-1-7281-1651-8","10.1109/SNPD.2019.8935803","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8935803","Digital Communication;Machine Learning;Batch Normalization;Image Transmission;Residual Learning;Image Denoising;Deep Learning;Convolutional Neural Network","Image denoising;Noise measurement;Convolutional neural networks;Noise reduction;Wireless communication;Digital communication;Image coding","channel coding;convolutional neural nets;digital communication;discrete cosine transforms;error statistics;Gaussian noise;image coding;image denoising;learning (artificial intelligence);optical communication;wireless channels","wireless communications;wireless channel;machine learning;digital communication;channel coding;correct reception;received data;channel effects;image quality degrades;transmitted data;noisy channel;convolutional denoising autoencoders;channel degradation;high denoising performance;convolutional neural network;trained network denoise;trained model displays high efficiency;optical communications;line communications;image denoising techniques","","1","","21","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Dual Adversarial Autoencoder for Dermoscopic image Generative Modeling","H. -Y. Yang; L. H. Staib",CuraCloud Corp; Yale University,"2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)","11 Jul 2019","2019","","","1247","1250","Skin cancer is a severe public health issue in the United States and worldwide. While Computer Aided Diagnosis (CAD) of dermoscopic images shows potential in accelerating diagnosis and improving accuracy, numerous issues remain that may be addressed by generative modeling. Major challenges in automated skin lesion classification include manual efforts required to label new training data and a relatively limited amount of data compared to more generalized computer vision tasks. We propose a novel generative model based on a dual discrimination training algorithm for autoencoders. At each training iteration, the encoder and decoder undergo two stages of adversarial training by two individual discriminator networks. The algorithm is end-to-end trainable with standard back-propagation. In contrast with traditional autoencoders, our method incorporates extra constraints via adversarial training, which results in visually realistic synthetic data. We demonstrate the versatility of the proposed method and applications on numerous tasks including latent space visualization, data augmentation, and image denoising.","1945-8452","978-1-5386-3641-1","10.1109/ISBI.2019.8759293","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759293","Adversarial Autoencoder;Unsupervised learning;Dermoscopy;Skin lesion","Training;Skin;Lesions;Image reconstruction;Decoding;Convolution;Computational modeling","biomedical optical imaging;CAD;cancer;computer vision;image classification;image coding;image denoising;iterative methods;medical image processing;skin","dermoscopic images;automated skin lesion classification;generalized computer vision tasks;generative model;dual discrimination training algorithm;training iteration;individual discriminator networks;traditional autoencoders;visually realistic synthetic data;data augmentation;image denoising;dual adversarial autoencoder;dermoscopic image generative modeling;skin cancer;computer aided diagnosis;end-to-end trainable algorithm;latent space visualization","","","","10","","11 Jul 2019","","","IEEE","IEEE Conferences"
"Deinterleaving of Pulse Streams With Denoising Autoencoders","X. Li; Z. Liu; Z. Huang","National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China","IEEE Transactions on Aerospace and Electronic Systems","3 Dec 2020","2020","56","6","4767","4778","Analyzing radar signals is an important task in operating electronic support measure systems. The received signals in the real electromagnetic environment often originate from multiple emitters and must be separated for further processing. Pulses from important target emitters with known parameters should be picked out first. To solve the problem, time-of-arrival (TOA) deinterleaving may be performed to extract signals from a certain emitter by learning the pulse repetition interval (PRI) modulation that makes up the signal. However, conventional deinterleaving methods only work with simple PRI modulations; their performance degrades in noisy environments. A novel approach based on denoising autoencoders for TOA deinterleaving was developed in this article. The inner patterns of pulse-of-interest sequences were learned by the proposed denoising autoencoders to generate output sequences from well-trained autoencoders. Simulation results show that the proposed method outperforms conventional methods, especially in environments with high lost and spurious pulse ratios.","1557-9603","","10.1109/TAES.2020.3004208","Natural Science Foundation of Hunan Province(grant numbers:2019JJ10004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9123957","Deinterleaving;denoising autoencoders;pulse repetition interval (PRI);pulse streams;time of arrival(TOA)","Noise reduction;Modulation;Radar;Task analysis;Electromagnetics;Pulse measurements;Histograms","learning (artificial intelligence);modulation;radar computing;radar signal processing;radar theory;signal denoising;time-of-arrival estimation","pulse streams;denoising autoencoders;radar signals;electronic support measure systems;received signals;electromagnetic environment;time-of-arrival deinterleaving;pulse repetition interval modulation;PRI modulations;noisy environments;TOA deinterleaving;pulse-of-interest sequences;spurious pulse ratios","","10","","30","IEEE","24 Jun 2020","","","IEEE","IEEE Journals"
"Cleaning Method for Status Monitoring Data of Power Equipment Based on Stacked Denoising Autoencoders","J. Dai; H. Song; G. Sheng; X. Jiang","Department of Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE Access","13 Nov 2017","2017","5","","22863","22870","Currently, the cleaning process for power equipment monitoring data is cumbersome and often leads to loss of information. To address these problems, a data cleaning method based on stacked denoising autoencoder (SDAE) networks is proposed in this paper. SDAE networks have a strong ability to denoise and restore corrupted data and have a strong feature extraction capability. The status monitoring data of equipment under normal conditions are trained by SDAE to obtain the cleaning parameters and the reconstruction errors. An upper threshold of the reconstruction errors obtained from training samples is determined through Kernel density estimation. A tolerance window width is added to achieve rapid anomaly detection. The abnormal data are classified as outliers, missing data, or fault status data according to the relationship between the reconstruction error and the threshold and between the duration of abnormal data and the tolerance window. To verify the effectiveness of the proposed method, the SDAE model is used to process the data for the dissolved gas concentration in transformer oil and the temperature of the transmission line. The results show that the proposed method can effectively identify and repair outliers and missing information. The model can perform rapid anomaly detection when the equipment is running abnormally.","2169-3536","","10.1109/ACCESS.2017.2740968","The National Natural Science Foundation of China(grant numbers:51477100); National High Technology Research and Development Program (863 Program)(grant numbers:2015AA050204); State Grid Science and Technology Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8016320","Power equipment;status data;data cleaning;stacked denoising autoencoders;anomaly detection","Cleaning;Monitoring;Training;Data models;Noise reduction;Data mining;Maintenance engineering","computerised monitoring;data handling;fault diagnosis;feature extraction;learning (artificial intelligence);power apparatus;power engineering computing;power transmission lines;transformer oil","SDAE networks;corrupted data;status monitoring data;cleaning parameters;reconstruction error;rapid anomaly detection;abnormal data;fault status data;SDAE model;stacked denoising autoencoders;cleaning process;power equipment monitoring data;data cleaning method;stacked denoising autoencoder networks;feature extraction capability;tolerance window;transformer oil;dissolved gas concentration;transmission line;missing information","","29","","27","OAPA","24 Aug 2017","","","IEEE","IEEE Journals"
"Denoising Convolutional Variational Autoencoders-Based Feature Learning for Automatic Detection of Plant Diseases","V. Zilvan; A. Ramdan; E. Suryawati; R. B. S. Kusumo; D. Krisnandi; H. F. Pardede","Research Center for Informatics, Indonesian Institute of Sciences (LIPI), Bandung, Indonesia; Research Center for Informatics, Indonesian Institute of Sciences (LIPI), Bandung, Indonesia; Research Center for Informatics, Indonesian Institute of Sciences (LIPI), Bandung, Indonesia; Research Center for Informatics, Indonesian Institute of Sciences (LIPI), Bandung, Indonesia; Research Center for Informatics, Indonesian Institute of Sciences (LIPI), Bandung, Indonesia; Research Center for Informatics, Indonesian Institute of Sciences (LIPI), Bandung, Indonesia","2019 3rd International Conference on Informatics and Computational Sciences (ICICoS)","6 Feb 2020","2019","","","1","6","Early detection is critical for maintaining quantity and quality of farming commodity. Currently, detection of plant diseases still requires human expertise and/or need microscopic identification such as spectroscopic technique and molecular biological. So, it would be very costly and time consuming, and hence unattainable for small-holder farmers. The rapid development of intelligent agriculture using machine learning has led the widespread use of computer or smart-phones to solve this problem. So, early detection of plant disease can be performed with minimal support from human experts and microscopic identification is no longer needed. However, conventional machine-learning techniques are limited in their ability to process raw data directly. So it require some efforts and domain expertise to design feature extractor to support it. Moreover, impulse noise such as salt-pepper noise may present on the images and it arises another challenge to provide a robust system. In this paper, we present denoising convolutional variational autoencoders as automatic unsupervised feature extractor and automatic denoiser to learn and to extract good features directly from the raw data. Here, we use the output of denoising convolutional variational auto encoders as inputs to fully connected networks classifiers for automatic detection of plant diseases. Our experiments show the average accuracies of our method is better than denoising variational autoencoders which is built using fully deep connected networks architectures. We also found that our proposed method is more robust against noisy test data.","","978-1-7281-4610-2","10.1109/ICICoS48119.2019.8982494","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8982494","Denoising convolutional variational autoencoders;feature learning;plant diseases detection;deep learning;autoen-coders","","agriculture;convolution;convolutional neural nets;feature extraction;image denoising;pattern classification;plant diseases;product quality;smart phones;unsupervised learning","plant disease detection;microscopic identification;spectroscopic technique;machine-learning techniques;automatic unsupervised feature extractor;automatic denoiser;denoising convolutional variational autoencoders-based feature learning","","7","","19","","6 Feb 2020","","","IEEE","IEEE Conferences"
"Medical Image Denoising with Recurrent Residual U-Net (R2U-Net) base Auto-Encoder","S. Nasrin; M. Z. Alom; R. Burada; T. M. Taha; V. K. Asari","Department of Electrical and Computer Engineering, University of Dayton, Dayton, OH, USA; Department of Electrical and Computer Engineering, University of Dayton, Dayton, OH, USA; Department of Electrical and Computer Engineering, University of Dayton, Dayton, OH, USA; Department of Electrical and Computer Engineering, University of Dayton, Dayton, OH, USA; Department of Electrical and Computer Engineering, University of Dayton, Dayton, OH, USA","2019 IEEE National Aerospace and Electronics Conference (NAECON)","9 Apr 2020","2019","","","345","350","Deep learning (DL) approaches have been applied in different sectors of medical imaging applications, i.e. classification, segmentation and detection tasks and shown superior performance. The DL based generative methods are used for image denoising, enhancement and restoration task. In case of image analysis, image denoising is one of the most crucial preprocessing steps. Recently, there are various DL approaches are applied in image denoising problems and achieved state-of-the-art performance. In this work, we apply recurrent residual U-Net (R2U-Net) based autoencoder model for medical image denoising which is applied for digital pathology, dermoscopy, Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) images denoising tasks. The performance of R2U-Net based autoencoder model is also evaluated for Transfer domain (TD) between MRI and CT scan images. The experiments have conducted on different publicly available medical image datasets and shows promising denoising results which can be applied in different medical imaging applications.","2379-2027","978-1-7281-1416-3","10.1109/NAECON46414.2019.9057834","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9057834","DL;R2U-Net;Autoencoder;Medical Imaging;and Image denoising","Biomedical imaging;Magnetic resonance imaging;Computed tomography;Image denoising;Pathology;Noise reduction;Mathematical model","biomedical MRI;computerised tomography;encoding;image denoising;image enhancement;image restoration;image segmentation;learning (artificial intelligence);medical image processing;neural nets","deep learning;image segmentation;image restoration task;image analysis;recurrent residual U-Net;medical image denoising;magnetic resonance imaging;computed tomography images;R2U-Net based autoencoder model;CT scan images;medical imaging;image enhancement;digital pathology;dermoscopy;transfer domain","","4","","26","","9 Apr 2020","","","IEEE","IEEE Conferences"
"3-D BLE Indoor Localization Based on Denoising Autoencoder","C. Xiao; D. Yang; Z. Chen; G. Tan","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Chinese Academy of Sciences, SIAT, Shenzhen, China","IEEE Access","24 Jul 2017","2017","5","","12751","12760","Bluetooth low energy (BLE)-based indoor localization has attracted increasing interests for its low-cost, low-power consumption, and ubiquitous availability in mobile devices. In this paper, a novel denoising autoencoder-based BLE indoor localization (DABIL) method is proposed to provide high-performance 3-D positioning in large indoor places. A deep learning model, called denoising autoencoder, is adopted to extract robust fingerprint patterns from received signal strength indicator measurements, and a fingerprint database is constructed with reference locations in 3-D space, rather than traditional 2-D plane. Field experiments show that 3-D space fingerprinting can effectively increase positioning accuracy, and DABIL performs the best in terms of both horizontal accuracy and vertical accuracy, comparing with a traditional fingerprinting method and a deep learning-based method. Moreover, it can achieve stable performance with incomplete beacon measurements due to unpredictable BLE beacon lost.","2169-3536","","10.1109/ACCESS.2017.2720164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7959171","Bluetooth low energy;indoor localization;fingerprinting;denoising autoencoder","Noise reduction;Three-dimensional displays;Databases;Wireless fidelity;Robustness;Wireless communication;Receivers","Bluetooth;indoor radio;RSSI;signal denoising;telecommunication power management","3D BLE indoor localization;denoising autoencoder;Bluetooth low energy;low-power consumption;mobile devices;deep learning model;fingerprint patterns;received signal strength indicator;fingerprint database","","71","","30","OAPA","27 Jun 2017","","","IEEE","IEEE Journals"
"Stacked denoising autoencoder and dropout together to prevent overfitting in deep neural network","J. Liang; R. Liu","School of Information and Communication Engineering, Beijing University of Post and Telecommunication, Beijing, China; School of Information and Communication Engineering, Beijing University of Post and Telecommunication, Beijing, China","2015 8th International Congress on Image and Signal Processing (CISP)","18 Feb 2016","2015","","","697","701","Deep neural network has very strong nonlinear mapping capability, and with the increasing of the numbers of its layers and units of a given layer, it would has more powerful representation ability. However, it may cause very serious overfitting problem and slow down the training and testing procedure. Dropout is a simple and efficient way to prevent overfitting. We combine stacked denoising autoencoder and dropout together, then it has achieved better performance than singular dropout method, and has reduced time complexity during fine-tune phase. We pre-train the data with stacked denoising autoencoder, and to prevent units from co-adapting too much dropout is applied in the period of training. At test time, it approximates the effect of averaging the predictions of many networks by using a network architecture that shares the weights. We show the performance of this method on a common benchmark dataset MNIST.","","978-1-4673-9098-9","10.1109/CISP.2015.7407967","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7407967","deep neural network;stacked denoising autoencoder;dropout;regulation;method combination","Decision support systems;Noise reduction;Signal processing;Neural networks","encoding;neural nets;signal denoising","stacked denoising autoencoder;deep neural network;nonlinear mapping;overfitting problem;singular dropout method;time complexity;fine-tune phase;network architecture;MNIST benchmark dataset","","31","","20","","18 Feb 2016","","","IEEE","IEEE Conferences"
"Offline Urdu Nastaleeq optical character recognition based on stacked denoising autoencoder","I. Ahmad; X. Wang; R. Li; S. Rasheed","Beijing University of Posts and Telecommunications, Beijing, Beijing, CN; Beijing University of Posts and Telecommunications, Beijing, Beijing, CN; Beijing University of Posts and Telecommunications, Beijing, Beijing, CN; Pakistan Telecommunication Company Ltd, Islamabad, PK","China Communications","2 Feb 2017","2017","14","1","146","157","Offline Urdu Nastaleeq text recognition has long been a serious problem due to its very cursive nature. In order to get rid of the character segmentation problems, many researchers are shifting focus towards segmentation free ligature based recognition approaches. Majority of the prevalent ligature based recognition systems heavily rely on hand-engineered feature extraction techniques. However, such techniques are more error prone and may often lead to a loss of useful information that might hardly be captured later by any manual features. Most of the prevalent Urdu Nastaleeq test recognition was trained and tested on small sets. This paper proposes the use of stacked denoising autoencoder for automatic feature extraction directly from raw pixel values of ligature images. Such deep learning networks have not been applied for the recognition of Urdu text thus far. Different stacked denoising autoencoders have been trained on 178573 ligatures with 3732 classes from un-degraded (noise free) UPTI (Urdu Printed Text Image) data set. Subsequently, trained networks are validated and tested on degraded versions of UPTI data set. The experimental results demonstrate accuracies in range of 93% to 96% which are better than the existing Urdu OCR systems for such large dataset of ligatures.","1673-5447","","10.1109/CC.2017.7839765","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7839765","offline printed ligature recognition;urdu nastaleeq;denoising autoencoder;deep learning;classification","Optical character recognition software;Noise reduction;Feature extraction;Training;Character recognition;Writing;Hidden Markov models","feature extraction;feedforward neural nets;image coding;image denoising;image segmentation;optical character recognition;text detection","offline Urdu Nastaleeq optical character recognition;Urdu OCR systems;stacked denoising autoencoder;text recognition;character segmentation;segmentation free ligature based recognition;automatic feature extraction;ligature images;deep learning networks;Urdu printed text image;UPTI data set","","23","","","","2 Feb 2017","","","IEEE","IEEE Magazines"
"Multivariate Time Series Missing Data Imputation Using Recurrent Denoising Autoencoder","J. Zhang; P. Yin","Department of Computer Science and Technology, Shenzhen International Graduated School, Tsinghua University, Shenzhen, China; Joint Engineering Research Center for Health Big Data Intelligent Analysis Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China","2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","6 Feb 2020","2019","","","760","764","This paper presents a novel method for imputing missing data of multivariate time series by adapting the Long Short Term-Memory(LSTM) and Denoising Autoencoder(DAE). Missing data are ubiquitous in many domains; proper imputation methods can improve performance on many tasks. Our method focus on multivariate time series, applying bidirectional LSTM to learn temporal information and DAE to learn correlation between variables, and we combine these two models by using LSTM as the encoder component of DAE. Several real-world datasets, including electroencephalogram(EEG), electromyogram(EMG) and electronic health records(EHRs), are extracted to test the performance of our method. Through simulation studies, we compare the proposed recurrent denoising autoencoder with several baseline imputation methods and demonstrate its effectiveness in both missing data estimation and label prediction after imputation.","","978-1-7281-1867-3","10.1109/BIBM47256.2019.8982996","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8982996","missing data;multivariate;time series;denoising autoencoder","","data analysis;data handling;electroencephalography;electromyography;learning (artificial intelligence);medical information systems;medical signal processing;recurrent neural nets;signal denoising;time series","multivariate time series;proper imputation methods;method focus;bidirectional LSTM;recurrent denoising autoencoder;baseline imputation methods;missing data estimation;label prediction;time series missing data imputation;EEG;electroencephalogram;electromyogram;EMG;electronic health records;EHRs","","8","","23","","6 Feb 2020","","","IEEE","IEEE Conferences"
"Partial Discharge Patterns Recognition of GIS with Denoising-stacked Autoencoder Networks","Y. Zhao; J. Yan; Y. Wang; T. Liu; J. Jiang","State Key Laboratory of Electrical Insulation and Power Equipment, Xi’an Jiaotong University, Xi’an, China; State Key Laboratory of Electrical Insulation and Power Equipment, Xi’an Jiaotong University, Xi’an, China; State Key Laboratory of Electrical Insulation and Power Equipment, Xi’an Jiaotong University, Xi’an, China; State Key Laboratory of Electrical Insulation and Power Equipment, Xi’an Jiaotong University, Xi’an, China; State Grid Corporation of China State Grid Corporation of Fujian, Sanming, Sanming, China","2020 5th Asia Conference on Power and Electrical Engineering (ACPEE)","8 Jul 2020","2020","","","1815","1818","Partial discharge (PD) is the main characterization of gas insulated switchgear (GIS) insulation defects, which will further aggravate equipment aging. Therefore, monitoring the PD of GIS equipment is of great significance to detect insulation defects and avoid GIS equipment failure to ensure safe and reliable operation of the grid. However, the traditional partial discharge pattern recognition mostly relies on artificial feature engineering, and the appropriateness of feature selection directly affects the recognition result. This paper proposes a pattern recognition classifier that directly and automatically selects and classifies fault features by denoising-stacked autoencoder. Automatic feature extraction effectively reduces the dependence of traditional pattern recognition classification algorithms based on expert systems and excessive human intervention. The results show that it not only inherits the advantages of the generalization ability of the denoising autoencoder model, but also has the advantages of easy stacking, faster convergence and higher accuracy.","","978-1-7281-5281-3","10.1109/ACPEE48638.2020.9136370","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9136370","partial discharge;gas insulated switchgear;denoising-stacked autoencoder;pattern recognition","Partial discharges;Training;Support vector machines;Stacking;Feature extraction;Pattern recognition;Classification algorithms","fault diagnosis;feature extraction;gas insulated switchgear;image denoising;learning (artificial intelligence);neural nets;partial discharges;pattern classification;power engineering computing","easy stacking;denoising-stacked autoencoder networks;PD;main characterization;gas insulated switchgear insulation defects;equipment aging;GIS equipment failure;safe operation;artificial feature engineering;feature selection;recognition result;pattern recognition classifier;fault feature classification;automatic feature extraction","","1","","16","","8 Jul 2020","","","IEEE","IEEE Conferences"
"Fast Machine Fault Diagnosis Using Marginalized Denoising Autoencoders Based on Acoustic Signal","D. Xiao; Z. Tao; C. Qin; H. Yu; Y. Huang; C. Liu","State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China","2020 Prognostics and Health Management Conference (PHM-Besançon)","12 Jun 2020","2020","","","229","234","Recently, an increasing popularity of data-driven deep learning research in the field of machine fault diagnosis has been observed. Stacked Denoising Autoencoder (SDA), as a classic type of deep learning method, has been successfully used to learn effective representations for machine fault diagnosis. However, those previous studies always encounter with the inherent limitations of SDA: high computational cost, time-consuming training, and lack of scalability to high-dimensional data. Unfortunately, those limitations can restrict the applicability of those studies in real-world applications, which require timely model upgrade and fast real-time diagnosis. Besides, most previous studies concentrate on the vibration signal, and thus lack the attention towards other kinds of sensor data like acoustical signal. Therefore, to address the two problems above, inspired by the marginalized Stacked Denoising Autoencoder (mSDA), we adopt a variant of SDA for fast fault diagnosis on sound signal. In this way, the required stochastic gradient descent based on back propagation in traditional deep learning methods is replaced by a forward closed-form solution. Opposite to the time-consuming works which demand training thousands of parameters during optimization, this deep architecture only needs to determine a few hyper parameters in advance. To verify the effectiveness and efficiency of the proposal on sound signal, extensive empirical evaluation on a publicly available sound signal dataset of gear fault is carried on. Thorough comparisons with some state-of-the-art faulty diagnosis approaches, confirm the superiority of the proposal in high diagnostic accuracy and lower computational cost.","2166-5656","978-1-7281-5675-0","10.1109/PHM-Besancon49106.2020.00045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9115517","Machine fault diagnosis, Denoising Autoencoder, Acoustical Signal.","Fault diagnosis;Training;Deep learning;Backpropagation;Closed-form solutions;Gears;Noise reduction","acoustic signal processing;backpropagation;fault diagnosis;gears;gradient methods;machinery;neural nets;signal denoising;stochastic processes;vibrational signal processing","acoustic signal;data-driven deep learning research;high computational cost;high-dimensional data;real-time diagnosis;vibration signal;backpropagation;forward closed-form solution;fast machine fault diagnosis;gear fault;sound signal dataset;deep architecture;traditional deep learning methods;stochastic gradient descent;fast fault diagnosis;mSDA;marginalized stacked denoising autoencoder;sensor data","","","","20","","12 Jun 2020","","","IEEE","IEEE Conferences"
"Deep Convolutional Autoencoders for Deblurring and Denoising Low-Resolution Images","M. Fernando Mendez Jimenez; O. DeGuchy; R. F. Marcia","Department of Applied Mathematics, University of California, Merced, Merced, USA; Department of Applied Mathematics, University of California, Merced, Merced, USA; Department of Applied Mathematics, University of California, Merced, Merced, USA","2020 International Symposium on Information Theory and Its Applications (ISITA)","2 Mar 2021","2020","","","549","553","In this paper, we implement machine learning methods to recover higher-dimensional signals from lower-dimensional, noisy, and blurry measurements. In particular, rather than utilizing optimization-based reconstruction methods, we use fully-connected multilayer perceptron (MLP) architectures and convolutional neural networks (CNN). In addition, we consider two different loss functions based on mean squared error and a Huber potential to train our models. Numerical experiments on the Street View House Numbers dataset show that while fully-connected MLPs are faster to train, reconstructions using CNNs are much more accurate.","2689-5854","978-4-88552-330-4","","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9366155","","Training;Convolution;Reconstruction algorithms;Loss measurement;Noise measurement;Image reconstruction;Photonics","convolutional neural nets;filtering theory;image denoising;image reconstruction;image restoration;learning (artificial intelligence);multilayer perceptrons","deep convolutional autoencoders;deblurring;denoising low-resolution images;higher-dimensional signals;lower-dimensional blurry measurements;optimization-based reconstruction methods;multilayer perceptron architectures;MLP;convolutional neural networks;loss functions;mean squared error;Huber potential;numerical experiments;Street View House Numbers dataset;fully-connected MLPs","","","","25","","2 Mar 2021","","","IEEE","IEEE Conferences"
"Research on Text Classification of Denoising Autoencoder Based on Additional Momentum and Adaptive Learning Rate","Z. Yang; X. Pang","School of Information, Qilu University Of Technology, Jinan, China; School of Information, Qilu University Of Technology, Jinan, China","2018 11th International Symposium on Computational Intelligence and Design (ISCID)","25 Apr 2019","2018","01","","329","334","Aiming at the problem of slow convergence speed and long training time of traditional Denoising Autoencoder (DAE) deep learning model in the process of feature expression, a deep learning model of DAE additional with momentum term and adaptive learning rate is proposed in this paper, which is used for text feature learning. And at the last layer of the model, softmax is used for classification. Finally, the text categorization experiments are carried out by using KNN classifier, denoising autoencoder model and improved model of denoising autoencoder respectively. The experimental results show that the reconstruction error curve of the improved DAE model is obviously lower than the traditional DAE model after 30 iterations, which greatly improves the convergence speed of the model. The value of the reconstruction error is also reduced. Moreover, the comprehensive correct rate of the improved DAE model is 95%, which is higher than that of KNN algorithm (88%) and traditional DAE model (92%). Experiments show that the method is feasible and practical.","2473-3547","978-1-5386-8527-3","10.1109/ISCID.2018.00081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8695629","text classification;deep learning;denoising autoencoder;adagrad algorithm;momentum term","Computational intelligence;Handheld computers","backpropagation;learning (artificial intelligence);nearest neighbour methods;neural nets;pattern classification;text analysis","text classification;additional momentum;adaptive learning rate;feature expression;DAE additional;text feature learning;text categorization experiments;autoencoder model;DAE model;denoising Autoencoder deep learning model;KNN classifier","","","","20","","25 Apr 2019","","","IEEE","IEEE Conferences"
"Denoising Adversarial Autoencoders","A. Creswell; A. A. Bharath","Biologically Inspired Computer Vision Group, Imperial College London, London, U.K.; Biologically Inspired Computer Vision Group, Imperial College London, London, U.K.","IEEE Transactions on Neural Networks and Learning Systems","18 Mar 2019","2019","30","4","968","984","Unsupervised learning is of growing interest because it unlocks the potential held in vast amounts of unlabeled data to learn useful representations for inference. Autoencoders, a form of generative model, may be trained by learning to reconstruct unlabeled input data from a latent representation space. More robust representations may be produced by an autoencoder if it learns to recover clean input samples from corrupted ones. Representations may be further improved by introducing regularization during training to shape the distribution of the encoded data in the latent space. We suggest denoising adversarial autoencoders (AAEs), which combine denoising and regularization, shaping the distribution of latent space using adversarial training. We introduce a novel analysis that shows how denoising may be incorporated into the training and sampling of AAEs. Experiments are performed to assess the contributions that denoising makes to the learning of representations for classification and sample synthesis. Our results suggest that autoencoders trained using a denoising criterion achieve higher classification performance and can synthesize samples that are more consistent with the input data than those trained without a corruption process.","2162-2388","","10.1109/TNNLS.2018.2852738","Engineering and Physical Sciences Research Council(grant numbers:EP/L504786/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438540","Image analysis;pattern recognition;semisupervised learning;unsupervised learning","Noise reduction;Training;Data models;Decoding;Encoding;Task analysis;Probabilistic logic","image denoising;image representation;unsupervised learning","generative model;unlabeled input data;latent representation space;robust representations;autoencoder;encoded data;latent space;denoising adversarial autoencoders;adversarial training;classification;denoising criterion;unsupervised learning;AAE","","36","","32","CCBY","16 Aug 2018","","","IEEE","IEEE Journals"
"Noise reduction in low-dose ct using a 3D multiscale sparse denoising autoencoder","K. Mentl; B. Mailhé; F. C. Ghesu; F. Schebesch; T. Haderlein; A. Maier; M. S. Nadar","Pattern Recognition Lab, Friedrich-Alexander-Universität, Erlangen, Germany; Medical Imaging Technologies, Siemens Healthineers, USA; Pattern Recognition Lab, Friedrich-Alexander-Universität, Erlangen, Germany; Pattern Recognition Lab, Friedrich-Alexander-Universität, Erlangen, Germany; Pattern Recognition Lab, Friedrich-Alexander-Universität, Erlangen, Germany; Pattern Recognition Lab, Friedrich-Alexander-Universität, Erlangen, Germany; Pattern Recognition Lab, Friedrich-Alexander-Universität, Erlangen, Germany","2017 IEEE 27th International Workshop on Machine Learning for Signal Processing (MLSP)","7 Dec 2017","2017","","","1","6","This article presents a novel neural network-based approach for enhancement of 3D medical image data. The proposed networks learn a sparse representation basis by mapping the corrupted input data to corresponding optimal targets. To reinforce the adjustment of the network to the given data, the threshold values are also adaptively learned. In order to capture important image features on various scales and be able to process large computed tomography (CT) volumes in a reasonable time, a multiscale approach is applied. Recursively downsampled versions of the input are used and denoising operator of constant size are learnt at each scale. The networks are trained end-to-end from a database of real highdose acquisitions with synthetic additional noise to simulate the corresponding low-dose scans. Both 2D and 3D networks are evaluated on CT volumes and compared to the block-matching and 3D filtering (BM3D) algorithm. The presented methods achieve an increase of 4% to 11% in the SSIM and of 2.4 to 2.8 dB in the PSNR with respect to the ground truth, outperform BM3D in quantitative comparisions and present no visible texture artifacts. By exploiting volumetric information, 3D networks achieve superior results over 2D networks.","","978-1-5090-6341-3","10.1109/MLSP.2017.8168176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8168176","CT;3D neural networks;denoising autoencoder","Three-dimensional displays;Noise reduction;Computed tomography;Two dimensional displays;Image reconstruction;Noise level;Noise measurement","computerised tomography;image denoising;image reconstruction;image representation;image texture;learning (artificial intelligence);medical image processing;neural nets;stereo image processing","CT volumes;noise reduction;3D multiscale sparse denoising autoencoder;novel neural network;3D medical image data;computed tomography volumes;multiscale approach;recursively downsampled versions;synthetic additional noise;low-dose scans;BM3D algorithm;low-dose CT;image features;sparse representation learning;corrupted input data mapping;denoising operator;block-matching and 3D filtering algorithm;SSIM;PSNR;volumetric information;3D networks","","4","2","23","","7 Dec 2017","","","IEEE","IEEE Conferences"
"UAV-Enabled Spatial Data Sampling in Large-Scale IoT Systems Using Denoising Autoencoder Neural Network","T. Yu; X. Wang; A. Shami","Department of Electrical and Computer Engineering, Western University, London, ON, Canada; Department of Electrical and Computer Engineering, Western University, London, ON, Canada; Department of Electrical and Computer Engineering, Western University, London, ON, Canada","IEEE Internet of Things Journal","8 May 2019","2019","6","2","1856","1865","Internet of Things (IoT) technology has been pervasively applied to environmental monitoring, due to the advantages of low cost and flexible deployment of IoT enabled systems. In many large-scale IoT systems, accurate and efficient data sampling and reconstruction is among the most critical requirements, since this can relieve the data rate of trunk link for data uploading while ensure data accuracy. To address the related challenges, we have proposed an unmanned aerial vehicle (UAV) enabled spatial data sampling scheme in this paper using denoising autoencoder (DAE) neural network. More specifically, a UAV-enabled edge-cloud collaborative IoT system architecture is first developed for data processing in large-scale IoT monitoring systems, where UAV is utilized as mobile edge computing device. Based on this system architecture, the UAV-enabled spatial data sampling scheme is further proposed, where the wireless sensor nodes of large-scale IoT systems are clustered by a newly developed bounded-size K-means clustering algorithm. A neural network model, i.e., DAE, is applied to each cluster for data sampling and reconstruction, by exploitation of both linear and nonlinear spatial correlation among data samples. Simulations have been conducted and the results indicate that the proposed scheme has improved data reconstruction accuracy under the sampling ratio without introducing extra complexity, as compared to the compressive sensing-based method.","2327-4662","","10.1109/JIOT.2018.2876695","Natural Sciences and Engineering Research Council of Canada(grant numbers:RGPIN-2018-06254); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8496746","Data sampling;denoising autoencoder (DAE);large-scale Internet of Things (IoT) system;neural network;spatial correlation;unmanned aerial vehicle (UAV)","Cloud computing;Neural networks;Spatial databases;Principal component analysis;Unmanned aerial vehicles;Internet of Things;Wireless sensor networks","autonomous aerial vehicles;cloud computing;control engineering computing;Internet of Things;mobile computing;neural nets;pattern clustering;remotely operated vehicles;wireless sensor networks","data rate;denoising autoencoder neural network;UAV-enabled edge-cloud collaborative IoT system architecture;data processing;UAV-enabled spatial data sampling scheme;neural network model;data reconstruction accuracy;Internet of Things technology;unmanned aerial vehicle;spatial data sampling scheme;denoising autoencoder;large-scale IoT monitoring systems;mobile edge computing device;bounded-size K-means clustering algorithm;nonlinear spatial correlation;linear spatial correlation","","30","","20","IEEE","18 Oct 2018","","","IEEE","IEEE Journals"
"Attentive Stacked Denoising Autoencoder With Bi-LSTM for Personalized Context-Aware Citation Recommendation","T. Dai; L. Zhu; Y. Wang; K. M. Carley","School of Software Engineering, Xi’an Jiaotong University, Xi’an, China; School of Software Engineering, Xi’an Jiaotong University, Xi’an, China; School of Software Engineering, Xi’an Jiaotong University, Xi’an, China; Center for Computational Analysis of Social and Organizational Systems, Institute of Software Research, School of Computer Science, Carnegie Mellon University, Pittsburgh, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","22 Jan 2020","2020","28","","553","568","The rapid growth of scientific publications brings the problem of finding appropriate citations for authors. Context-aware citation recommendation is an essential technology to overcome this obstacle when given a fragment of manuscript. In this article, we propose a novel neural network model for context-aware citation recommendation by combining stacked denoising autoencoders (SDAE) and Bi-LSTM. To obtain effective embedding for cited paper, we extend SDAE into attentive SDAE (ASDAE) by utilizing the attentive information from citation context, which essentially enhance the learning ability of original SDAE. For citation context, we devise an attentive Bi-LSTM to obtain effective embedding. Specifically, the attentive Bi-LSTM is able to extract suitable citation context and recommend citations simultaneously when given a long text, which is a issue that few papers addressed before. We also integrate personalized author information to improve the performance of recommendation. Our model is essentially a seemly integration of different types of neural network with latent variables. We derive the generative process of our model, and develop a learning algorithm based on maximum a posteriori (MAP) estimation. Experimental results on the RefSeer, ANN and DBLP datasets show that our model outperforms baseline methods.","2329-9304","","10.1109/TASLP.2019.2949925","National Natural Science Foundation of China(grant numbers:61373046); Ministry of Science and Technology of China(grant numbers:2018AAA0101100); Natural Science Basic Research Plan in Shaanxi Province of China(grant numbers:S2015YFJM2129); China Scholarship Council(grant numbers:201806280399); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8884121","Stacked denoising autoencoders;Bi-LSTM;attention mechanism;citation recommendation;citation context extraction","Context modeling;Speech processing;Task analysis;Noise reduction;Deep learning;Recurrent neural networks","citation analysis;maximum likelihood estimation;neural nets;recommender systems","neural network model;denoising autoencoders;effective embedding;attentive SDAE;attentive information;attentive Bi-LSTM;citation context;personalized author information;stacked denoising autoencoder;personalized context-aware citation recommendation;appropriate citations;maximum a posteriori estimation","","11","","52","IEEE","28 Oct 2019","","","IEEE","IEEE Journals"
"Probabilistic Stacked Denoising Autoencoder for Power System Transient Stability Prediction With Wind Farms","T. Su; Y. Liu; J. Zhao; J. Liu","School of Electrical Engineering and Information, Sichuan University, Chengdu, China; School of Electrical Engineering and Information, Sichuan University, Chengdu, China; Electrical and Computer Engineering, Mississippi State University, Mississippi State, USA; School of Electrical Engineering and Information, Sichuan University, Chengdu, China","IEEE Transactions on Power Systems","18 Jun 2021","2021","36","4","3786","3789","To address the uncertainties of renewable energy and loads in transient stability assessment with credible contingencies, this letter proposes a stacked denoising autoencoder (SDAE)-based probabilistic prediction method. The correlations among wind farms have been effectively considered through the variable transformation via the Cholesky decomposition. SDAE allows learning the mapping relationship between operational features and the transient stability margin. The possible operation scenarios are sampled under different confidence levels to generate appropriate inputs for SDAE to assess the probabilistic transient stability distribution. Results on the modified IEEE 39-bus system show that our proposed method can achieve a similar level of accuracy as the benchmark and improved Monte Carlo simulations-based methods while having much higher computational efficiency.","1558-0679","","10.1109/TPWRS.2020.3043620","National Natural Science Foundation of China(grant numbers:51977133); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288771","Transient stability;probabilistic prediction;wind uncertainty;stacked denoising autoencoder (SDAE)","Transient analysis;Power system stability;Stability criteria;Probabilistic logic;Wind power generation","learning (artificial intelligence);Monte Carlo methods;power system security;power system transient stability;probability;wind power plants","probabilistic stacked denoising autoencoder;power system transient stability prediction;wind farms;renewable energy;transient stability assessment;credible contingencies;stacked denoising autoencoder-based probabilistic prediction method;SDAE;operational features;transient stability margin;possible operation scenarios;different confidence levels;probabilistic transient stability distribution;modified IEEE 39-bus system show;Monte Carlo simulations-based methods","","5","","15","IEEE","9 Dec 2020","","","IEEE","IEEE Journals"
"The hidden layer design for staked denoising autoencoder","Qianqian Hao; Hua Zhang; Jinkou Ding","Beijing School of Science, Beijing University of Posts and Telecommunications, Beijing; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications; Beijing School of Science, Beijing University of Posts and Telecommunications, Beijing","2015 12th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)","20 Jun 2016","2015","","","150","153","Deep learning can achieve the complex function approximation and the characteristics of the input data by studying a deep nonlinear network. At present, one of the most important problems in the study of deep learning is how to construct a reasonable structure. This paper studies the deep learning model of stacked denoising autoencoder (SDA) and the remaining task is to construct its reasonable model. We introduce three effective methods to construct the structure of the SDA. Numerical experiments imply that the structure obtained by the golden section principle performs the best.","","978-1-4673-8266-3","10.1109/ICCWAMTIP.2015.7493964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7493964","Deep Learning;SDA;golden section;Hidden Layer;nonlinear network","Machine learning;Mathematical model;Training;Data models;Noise reduction;Numerical models;Neural networks","learning (artificial intelligence);neural nets","hidden layer design;staked denoising autoencoder;complex function approximation;input data characteristics;deep nonlinear network;deep learning model;stacked denoising autoencoder;SDA structure;golden section principle;multilayer neural network","","","","12","","20 Jun 2016","","","IEEE","IEEE Conferences"
"Lightweight Denoising Autoencoder Design for Noise Removal in Electrocardiography","M. -H. Sheu; Y. -S. Jhang; Y. -C. Chang; S. -T. Wang; C. -Y. Chang; S. -C. Lai","Department of Electronics Engineering, National Yunlin University of Science & Technology, Douliu, Taiwan; Department of Electronics Engineering, National Yunlin University of Science & Technology, Douliu, Taiwan; Department of Electronics Engineering, National Yunlin University of Science & Technology, Douliu, Taiwan; Doctor’s Program of Smart Industry Technology Research and Design, National Formosa University, Huwei, Taiwan; Department of Computer Science and Information Engineering, National Yunlin University of Science & Technology, Yunlin, Taiwan; Smart Machinery and Intelligent Manufacturing Research Center, National Formosa University, Huwei, Taiwan","IEEE Access","23 Sep 2022","2022","10","","98104","98116","This study proposes two denoising autoencoder models with discrete cosine transform and discrete wavelet transform, to remove electrode motion artifacts in noisy electrocardiography. Initially, the discrete cosine transform and discrete wavelet transform efficiently removed the high-frequency noise. The six encoder layers then retain important electrocardiography features, whereas the six decoder layers reconstruct the clean electrocardiography. To improve the denoising performance, two network layers, the residual block and pixel adjustment, are added to the encoder and decoder layers to solve the vanishing gradient and improve subtle feature extraction. The proposed methods were applied to 66,000 real-recorded noisy electrocardiography fragments. The experimental result indicates that discrete wavelet transform based denoising autoencoder and discrete cosine transform based denoising autoencoder can improve the signal-to-noise ratio by 25.29 and 25.13 dB on average when the input signal-to-noise ratio is −6 dB.","2169-3536","","10.1109/ACCESS.2022.3206620","Ministry of Science and Technology, Taiwan(grant numbers:MOST 110-2622-E-224 -006,110-2221-E-150 -045,109-2221-E-150 -043); Smart Machinery and Intelligent Manufacturing Research Center through the Higher Education Sprout Project, National Formosa University, Yunlin, Taiwan; Ministry of Education (MOE) Female Researching Talent Cultivation Project for Science, Technology, Engineering, and Mathematics (STEM) Field; Intelligent Recognition Industry Service Center from the Featured Areas Research Center Program within the Framework of the Higher Education Sprout Project of the Ministry of Education (MOE) in Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9889721","Artificial neural networks;biomedical computing;biomedical signal processing;discrete cosine transforms;deep learning;discrete wavelet transforms;electrocardiography;noise cancellation;neural networks;signal reconstruction","Electrocardiography;Discrete wavelet transforms;Noise measurement;Adaptive filters;Noise reduction;Decoding;Transforms;Artificial neural networks;Biomedical signal processing;Deep learning","discrete cosine transforms;discrete wavelet transforms;electrocardiography;feature extraction;medical signal processing;signal denoising","pixel adjustment;decoder layers;subtle feature extraction;noisy electrocardiography fragments;input signal-to-noise ratio;autoencoder design;noise removal;denoising autoencoder models;electrode motion artifacts;high-frequency noise;encoder layers;clean electrocardiography;denoising performance;network layers;residual block;electrocardiography features","","","","42","CCBYNCND","14 Sep 2022","","","IEEE","IEEE Journals"
"Research on Underwater Acoustic Channel Denoising Algorithm based on Auto-Encoder","Z. Liu; Y. Duan","Department of Information Technology, Taizhou Polytechnic College, Taizhou, China; Department of Information Technology, Taizhou Polytechnic College, Taizhou, China","2019 IEEE 3rd Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)","6 Feb 2020","2019","","","625","628","Aiming at the complexity of underwater communication environment, a denoising algorithm based on autoencoder (AE-DNA) is proposed. In this algorithm, the autoencoder is used as the decoder, and the network model is established by learning the training data. At the same time, in order to improve the processing ability of the network, the idea of multiple inputs and multiple outputs is introduced to convert the input dataes and the output dataes. In addition, in order to improve the generalization ability of the network, when transmitting high-order signals, signal transformation is used to reduce the complexity of the signal. The simulation results of underwater acoustic channel show that compared with the denoising algorithm based on RBF neural network (RBF-DNA), the proposed algorithm has faster convergence speed, smaller mean square error and better decoding ability.","","978-1-7281-0513-0","10.1109/IMCEC46724.2019.8984139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8984139","autoencoder;multiple inputs and multiple outputs;signal transformation;underwater communication","","decoding;geophysical signal processing;learning (artificial intelligence);mean square error methods;neural nets;signal denoising;telecommunication computing;underwater acoustic communication;wireless channels","signal transformation;decoding ability;underwater acoustic channel denoising algorithm;underwater communication environment;autoencoder;network model;training data;processing ability;generalization ability;high-order signal transmission;AE-DNA;signal complexity reduction;mean square error","","","","8","","6 Feb 2020","","","IEEE","IEEE Conferences"
"Generalization of iterative sampling in autoencoders","M. Solinas; C. Galiez; R. Cohendet; S. Rousset; M. Reyboz; M. Mermillod","Univ. Grenoble Alpes, CEA, LIST, Grenoble, France; Univ. Grenoble Alpes, CNRS, Grenoble INP, Institute of Engineering, LJK, Grenoble, France; Univ. Grenoble Alpes, CEA, LIST, Grenoble, France; Univ. Grenoble Alpes, Univ. Savoie Mont Blanc, CNRS, LPNC, Grenoble, France; Univ. Grenoble Alpes, CEA, LIST, Grenoble, France; Univ. Grenoble Alpes, Univ. Savoie Mont Blanc, CNRS, LPNC, Grenoble, France","2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA)","23 Feb 2021","2020","","","877","882","Generative autoencoders are designed to model a target distribution with the aim of generating samples and it has also been shown that specific non-generative autoencoders (i.e. contractive and denoising autoencoders) can be turned into generative models using reinjections (i.e. iterative sampling). In this work, we provide mathematical evidence that any autoencoder reproducing the input data with a loss of information can sample from the training distribution using reinjections. More precisely, we prove that the property of modeling a given distribution and sampling from it not only applies to contractive and denoising autoencoders but also to all lossy autoencoders. In accordance with previous results, we emphasize that the reinjection sampling procedure in autoencoders improves the quality of the sampling. We experimentally illustrate the above property by generating synthetic data with non-generative autoencoders trained on standard datasets. We show that the learning curve of a classifier trained with synthetic data is similar to that of a classifier trained with original data.","","978-1-7281-8470-8","10.1109/ICMLA51294.2020.00143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9356324","Iterative sampling;autoencoders;denoising au-toencoders;reinjection;sampling","Training;Noise reduction;Neural networks;Machine learning;Loss measurement;Mathematical model;Standards","iterative methods;learning (artificial intelligence);neural nets;pattern classification;sampling methods","iterative sampling;generative autoencoders;target distribution;nongenerative autoencoders;contractive autoencoder;lossy autoencoders;reinjection sampling procedure;synthetic data generation;denoising autoencoder;learning curve","","1","","26","","23 Feb 2021","","","IEEE","IEEE Conferences"
"A Performance Prediction Model Based on Combined Autoencoder","Y. Wu; Z. Zhang","Computer Software and Theory Major, Inner Mongolia Baotou Teachers' College; Books and Materials Major, Inner Mongolia Baotou Teachers' College Library","2020 IEEE 11th International Conference on Software Engineering and Service Science (ICSESS)","4 Nov 2020","2020","","","364","368","Since most performance prediction models fail to make effective use of the essential characteristics of student performance data, this paper builds a combined autoencoder student performance prediction model, named HS-BP, which combines marginalized denoising autoencoder and stack sparse autoencoder to perform unsupervised feature learning on the student's historical performance data and behavior data, and connects the BP neural network on the top layer to achieve student performance prediction. Experimental results show that the proposed HS-BP model has higher prediction accuracy than other shallow models without feature learning.","2327-0594","978-1-7281-6579-0","10.1109/ICSESS49938.2020.9237748","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237748","Achievement prediction;Edge denoising autoencoder;Stack sparse autoencoder;BP neural network","Deep learning;Adaptation models;Noise reduction;Neural networks;Predictive models;Feature extraction;Data models","backpropagation;educational administrative data processing;feature extraction;neural nets;unsupervised learning","student performance data;stack sparse autoencoder;HS-BP model;shallow models;autoencoder student performance prediction model;BP neural network","","1","","13","","4 Nov 2020","","","IEEE","IEEE Conferences"
"Radar Signal Intra-Pulse Modulation Recognition Based on Convolutional Denoising Autoencoder and Deep Convolutional Neural Network","Z. Qu; W. Wang; C. Hou; C. Hou","College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China","IEEE Access","21 Aug 2019","2019","7","","112339","112347","Radar signal intra-pulse modulation recognition is an important technology in electronic warfare. A radar signal intra-pulse modulation recognition method based on convolutional denoising autoencoder (CDAE) and deep convolutional neural network (DCNN) is proposed in this paper. First, we use Cohen's time-frequency distribution to convert radar signals into time-frequency images (TFIs). Then image preprocessing is applied to TFIs, including bilinear interpolation and amplitude normalization. Next, we design a CDAE to denoise and repair TFIs. Finally, we design a deep convolutional neural network based on Inception architecture to identify the processed TFIs. Simulation results demonstrate that CDAE effectively reduces the interference of noise on TFIs classification, and improves the classification performance at a low signal-to-noise ratio (SNR). The DCNN architecture we designed makes good use of computing resources and has a good classification effect. The approach has good noise immunity and generalization. It can classify twelve kinds of modulation signals and an overall probability of successful recognition is more than 95% when the SNR is -9 dB.","2169-3536","","10.1109/ACCESS.2019.2935247","National Natural Science Foundation of China(grant numbers:61801143); Natural Science Foundation of Heilongjiang Province(grant numbers:LH2019F005); Fundamental Research Funds for the Central Universities(grant numbers:3072019CF0801,3072019CFM0802); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798607","Radar signal recognition;Cohen class time frequency distribution;convolutional denoising autoencoder;deep convolutional neural network","Modulation;Feature extraction;Noise reduction;Time-frequency analysis;Signal to noise ratio;Radar imaging","convolutional neural nets;electronic warfare;image denoising;image recognition;interference (signal);interpolation;pulse modulation;radar imaging;time-frequency analysis","convolutional denoising autoencoder;deep convolutional neural network;radar signal intra-pulse modulation recognition method;CDAE;Cohen's time-frequency distribution;radar signals;time-frequency images","","15","","20","CCBY","14 Aug 2019","","","IEEE","IEEE Journals"
"A Convolutional Autoencoder Method for Simultaneous Seismic Data Reconstruction and Denoising","J. Jiang; H. Ren; M. Zhang","Key Laboratory of Geoscience Big Data and Deep Resource of Zhejiang Province, School of Earth Sciences, Zhejiang University, Hangzhou, China; Key Laboratory of Geoscience Big Data and Deep Resource of Zhejiang Province, School of Earth Sciences, Zhejiang University, Hangzhou, China; Shengli Oilfield Geophysical Research Institute of SINOPEC, Dongying, China","IEEE Geoscience and Remote Sensing Letters","30 Dec 2021","2022","19","","1","5","Petroleum geophysical exploration is based on seismic data and has been widely affected by deep learning technology in recent years. As a consequence of the high efficiency and nonlinear fitting ability of deep learning models, we propose an improved convolutional autoencoder (CAE) method to achieve simultaneous reconstruction and denoising of seismic data. The architecture of the improved CAE is based on group convolution and inception structures, which have powerful feature extraction capabilities for seismic data. The CAE method regards the reconstruction and denoising of seismic data as a feature extraction process of the target seismic signals; this enables the method to simultaneously reconstruct the seismic signal accurately and suppress the random noise mixed in the seismic data. During the training of the CAE, the mean absolute error (MAE) loss function and Adam optimization algorithm were used. Because this is a data-driven method and does not require the threshold to be input manually, it can process a large amount of seismic data quickly and intelligently. Synthetic and field data examples demonstrate the effectiveness of the CAE method.","1558-0571","","10.1109/LGRS.2021.3073560","Natural Science Foundation of China(grant numbers:42074135,41674123); Zhejiang Province Basic Public Welfare Research Program(grant numbers:LY19D040002); Shengli Oilfield Geophysical Research Institute of SINOPEC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9416991","Convolutional autoencoder (CAE);deep learning;denoising;seismic data reconstruction","Convolution;Noise reduction;Interpolation;Image reconstruction;Deep learning;Signal to noise ratio;Feature extraction","deep learning (artificial intelligence);feature extraction;optimisation;seismology;signal denoising;signal reconstruction","seismic signal;data-driven method;CAE method;simultaneous seismic data reconstruction;convolutional autoencoder method;seismic data denoising;Adam optimization algorithm;deep learning technology","","2","","27","IEEE","27 Apr 2021","","","IEEE","IEEE Journals"
"Extending Denoising AutoEncoders for Feature Recognition","N. Jeppu; K. Chandrasekaran","Computer Engineering Department, National Institute of Technology, Karnataka, Surathkal, Mangalore; Computer Engineering Department, National Institute of Technology, Karnataka, Surathkal, Mangalore","2018 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","2 Dec 2018","2018","","","856","861","Image rendering techniques involve the addition of noise on the rendered samples. The characteristics of Monte Carlo rendered noisy images makes it difficult to denoise using conventional methods. The noise induced in this case is spatially sparse. Using traditional methods of denoising and feature recognition is time consuming for such images as they use the entire image space as their search space. This results in unnecessary calculations that can be avoided and therefore reduce the processing time significantly. A recurrent convolutional neural network that operates on varying spatial resolutions, also known as the auto encoder decoder structure perform very well on these rendered images. The partitioning into encoder and decoder phases lets the network operate on continuously decreasing and increasing spatial domains respectively. This can be coupled with classification techniques to incorporate feature recognition of noisy images. In this paper the pretrained autoencoder layers are supported with additional softmax and sigmoid layers to enable feature recognition capabilities.","","978-1-5386-5314-2","10.1109/ICACCI.2018.8554518","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8554518","autoencoders;convolutional neural networks;denoising","Rendering (computer graphics);Noise reduction;Decoding;Monte Carlo methods;Spatial resolution;Machine learning;Neurons","convolution;decoding;encoding;feature extraction;feedforward neural nets;image denoising;learning (artificial intelligence);Monte Carlo methods;pattern classification;recurrent neural nets;rendering (computer graphics)","denoising autoencoders;softmax layers;monte carlo rendered noisy images;encoder phases;sigmoid layers;feature recognition capabilities;classification techniques;decoder phases;spatial resolutions;recurrent convolutional neural network;image rendering techniques","","","","20","","2 Dec 2018","","","IEEE","IEEE Conferences"
"Object-Based Land-Cover Supervised Classification for Very-High-Resolution UAV Images Using Stacked Denoising Autoencoders","X. Zhang; G. Chen; W. Wang; Q. Wang; F. Dai","State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; College of Science, Wuhan University of Science and Technology, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","2 Aug 2017","2017","10","7","3373","3385","Over the last decade, object-based image classification (OBIC) has become a mainstream method in remote sensing land-use/land-cover applications. Many supervised classification methods have been proposed in the OBIC framework. However, most did not use deep learning methods. In this paper, a new deep-learning-based OBIC framework is introduced. First, we segment the original image into objects by graph-based minimal-spanning-tree segmentation algorithm. Second, we extract the spectral, spatial, and texture features for each object. Then we put all features into stacked autoencoders (SAE) or stacked denoising autoencoders (SDAE) network, and trained the parameters of the network using training samples. Finally, all objects were classified by the network. Based on our SAE/SDAE OBIC framework, we achieved 97% overall accuracy when classifying an UAV image into five categories. In addition, our experiment shows that our framework increases overall accuracy by approximately 6% when compared to the linear support vector machine (linear SVM) and radial basis function kernel support vector machine (RBF SVM) algorithms when sufficient training samples are lacking.","2151-1535","","10.1109/JSTARS.2017.2672736","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7879207","Deep learning (DL);object-based image classification (OBIC);stacked autoencoders (SAE);stacked denoising autoencoders (SDAE)","Feature extraction;Image segmentation;Remote sensing;Training;Support vector machines;Indexes;Neural networks","geophysical image processing;image classification;image resolution","object-based land-cover supervised classification;very-high-resolution UAV images;stacked denoising autoencoders;mainstream method;remote sensing;OBIC framework;supervised classification methods;graph-based minimal-spanning-tree segmentation algorithm;texture features;training samples;SAE/SDAE OBIC framework;linear support vector machine;radial basis function kernel support vector machine algorithms","","42","","37","IEEE","15 Mar 2017","","","IEEE","IEEE Journals"
"Quadratic Autoencoder (Q-AE) for Low-Dose CT Denoising","F. Fan; H. Shan; M. K. Kalra; R. Singh; G. Qian; M. Getzin; Y. Teng; J. Hahn; G. Wang","Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, USA; Department of Radiology, Massachusetts General Hospital, Boston, USA; Department of Radiology, Massachusetts General Hospital, Boston, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, USA; Sino-Dutch Biomedical and Information Engineering School, Northeastern University, Shenyang, China; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, USA","IEEE Transactions on Medical Imaging","2 Jun 2020","2020","39","6","2035","2050","Inspired by complexity and diversity of biological neurons, our group proposed quadratic neurons by replacing the inner product in current artificial neurons with a quadratic operation on input data, thereby enhancing the capability of an individual neuron. Along this direction, we are motivated to evaluate the power of quadratic neurons in popular network architectures, simulating human-like learning in the form of “quadratic-neuron-based deep learning”. Our prior theoretical studies have shown important merits of quadratic neurons and networks in representation, efficiency, and interpretability. In this paper, we use quadratic neurons to construct an encoder-decoder structure, referred as the quadratic autoencoder, and apply it to low-dose CT denoising. The experimental results on the Mayo low-dose CT dataset demonstrate the utility and robustness of quadratic autoencoder in terms of image denoising and model efficiency. To our best knowledge, this is the first time that the deep learning approach is implemented with a new type of neurons and demonstrates a significant potential in the medical imaging field.","1558-254X","","10.1109/TMI.2019.2963248","IBM AIHN Horizon Scholarship, NIH/NCI, and NIH/NIBIB(grant numbers:R01CA233888,R01CA237267,R01EB026646); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946589","Deep learning;quadratic neurons;autoencoder;low-dose CT","Neurons;Computed tomography;Noise reduction;Deep learning;Image reconstruction;Complexity theory;Feature extraction","computerised tomography;encoding;image denoising;learning (artificial intelligence);medical image processing","quadratic neurons;quadratic autoencoder;low-dose CT denoising;Mayo low-dose CT dataset;biological neurons;current artificial neurons;quadratic operation;individual neuron;quadratic-neuron-based deep learning;network architectures;human-like learning;image denoising;model efficiency;medical imaging field","Humans;Neurons;Tomography, X-Ray Computed","20","","52","IEEE","31 Dec 2019","","","IEEE","IEEE Journals"
"Improvement of Denoising in Images Using Generic Image Denoising Network (GID Net)","K. Dutta; R. Lenka; M. S. Sarowar","Executive Analyst,Analytics and Cognitive, Deloitte Touche Tohmatsu India LLP, Durgapur, India; School Of Electronics Engineering, KIIT University, Bhubaneswar, India; School Of Electronics Engineering, KIIT University, Bhubaneswar, India","2021 IEEE 2nd International Conference on Applied Electromagnetics, Signal Processing, & Communication (AESPC)","15 Feb 2022","2021","","","1","6","Images are generated in various forms in different sectors. These images are difficult to handle with and thus, cannot be effectively used in various fields. In this paper, two important techniques in the fields of Image Reconstruction and Restoration are carried out. Image Denoising is the process in which an image is reconstructed from the noisy image. In this process, To restore the original image, the undesired noise is removed. In other words, original (unidentified ) signal, i.e., the image is estimated from the available noisy data. There are many traditional methods of Image Processing which have been used for the process of image denoising [1]. But, these methods are not so robust to handle any type of noise signal which results in a deformed reconstructed denoised image. Therefore, in this paper, a method of image denoising using Image Reconstruction technique is proposed. For this purpose, Deep Learning techniques and architectures have been proposed in order to get the reconstructed denoised image in our paper.","","978-1-6654-4299-2","10.1109/AESPC52704.2021.9708513","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9708513","Convolutional Neural Network;Autoencoder;Image Denoising;Reconstruction Error;Hybrid Model;Encoder;Decoder;Up-Sampling","Deep learning;Noise reduction;Neurons;Image restoration;Noise measurement;Task analysis;Image reconstruction","deep learning (artificial intelligence);image denoising;image restoration;neural net architecture","generic image denoising network;noisy image;image processing;deformed reconstructed denoised image;image reconstruction;GID Net;image restoration;deep learning architectures","","","","19","IEEE","15 Feb 2022","","","IEEE","IEEE Conferences"
"Communication transmitter individual feature extraction method based on stacked denoising autoencoders under small sample prerequisite","J. Huang; Y. Lei; X. Liao","Hefei 230037, Anhui of china Electronic engineering Institute, China; Hefei 230037, Anhui of china Electronic engineering Institute, China; Hefei 230037, Anhui of china Electronic engineering Institute, China","2017 7th IEEE International Conference on Electronics Information and Emergency Communication (ICEIEC)","23 Oct 2017","2017","","","132","135","For the goal of improving the effectiveness and robustness of identifying communicatioin radio individual under small sample prerequisite, we proposed a communication radio individual identification method based on stacked denoising auto-encoder, which can learn fingerprint feature from input unlabeled communication radio signal samples and then extract low-dimension feature of raio signals facing to high-dimension sample space. Finally, the accurate individual identification phase will be accomplished in classifier. Experiments showed the effectiveness and reliability of method proposed on three different communication radio data set.","2377-844X","978-1-5090-3025-5","10.1109/ICEIEC.2017.8076528","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8076528","Small sample;individual identification;stacked auto-encoder;denoising auto-encoder","Feature extraction;Noise reduction;Training;Radio transmitters;Gaussian noise;Cost function","encoding;feature extraction;learning (artificial intelligence);signal classification;signal denoising;signal sampling","communication transmitter individual feature extraction method;stacked denoising autoencoders;sample prerequisite;communication radio individual identification method;fingerprint feature;low-dimension feature;high-dimension sample space;stacked denoising autoencoder;input unlabeled communication radio signal sample;individual identification phase;radio data communication","","3","","15","","23 Oct 2017","","","IEEE","IEEE Conferences"
"Motor Imagery EEG Recognition Based on Scheduled Empirical Mode Decomposition and Adaptive Denoising Autoencoders","T. Xie; W. Ma; X. Li; W. Li; B. Hao; X. Tang","Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing University of Posts and Telecommunications, Chongqing, China","2020 Chinese Automation Congress (CAC)","29 Jan 2021","2020","","","1528","1532","Artificial definition is mainly used as the pre-training in existing research on motor imagery (MI), which costs time on adjusting parameters. Deep-learning method like convolutional neural networks (CNNs) used in motor imagery classification would cause the problem of local convergence because of its random initialization strategy. To address these limitations, we proposed a method by reconstructing MI signal by using empirical mode decomposition (EMD) and apply the reconstructed signal in a denoising auto encoder (DAE) trained by an adaptive learning rate strategy. In this model, DAE obtains its noise level adaptively according to the annealing principle and chooses an adaptive learning rate to solve the local minimums in non-convex network. Both offline and online experiments are carried out to evaluate its performance. The corresponding results show that the proposed method can achieve higher recognition accuracy and better convergence speed, compared with other mainstream methods.","2688-0938","978-1-7281-7687-1","10.1109/CAC51589.2020.9327855","Natural Science Foundation of Chongqing; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9327855","motor imagery;empirical mode decomposition;denoising auto encoder;adaptive learning rate","Electroencephalography;Training;Noise reduction;Feature extraction;Noise level;Image reconstruction;Adaptive learning","brain-computer interfaces;convolutional neural nets;electroencephalography;feature extraction;Hilbert transforms;learning (artificial intelligence);medical signal processing;signal classification;signal denoising","empirical mode decomposition;adaptive denoising autoencoders;deep-learning method;convolutional neural networks;motor imagery classification;local convergence;random initialization strategy;reconstructing MI signal;reconstructed signal;denoising autoencoder;adaptive learning rate strategy;nonconvex network;motor imagery EEG recognition","","","","12","","29 Jan 2021","","","IEEE","IEEE Conferences"
"Optimal Model Analysis for Denoising Monte Calro Rendering Noise","M. -C. Kim; K. -Y. Lee","Dept. of Computer Engineering, Seokyeong University, Seoul, Korea; Dept. of Computer Engineering, Seokyeong University, Seoul, Korea","2018 International SoC Design Conference (ISOCC)","24 Feb 2019","2018","","","263","264","Recently monte carlo rendering has been used a lot for rendering realistic images. However, in order to obtain the film-quality result, We need a large amount of sample per pixel (spp), so many methods to postprocess a rendered image at a low spp. A denoising method with auxiliary buffers (normal, depth, albedo etc.) is often used. There are many filters-based methods that remove noises, the performance is good, but it is not easy to find the optimal filter parameter because it is too slow. In order to solve this problem, we propose a deep learning method which can find optimal filter parameters. In this paper, we find an optimal model for removing noise. We experiment with VGGNet, DnCNN, ResNet, DenseNet, and Recurrent autoencoder as a model to compare, and consequently Recurrent autoencoder can be seen to be the best model with this loss value 0.0649.","2163-9612","978-1-5386-7960-9","10.1109/ISOCC.2018.8649801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8649801","Monte Carlo Rendering;Denoising;Convolutional Neural Network","Noise reduction;Rendering (computer graphics);Monte Carlo methods;Computational modeling;Filtering;Feature extraction;Deep learning","image coding;image denoising;image filtering;learning (artificial intelligence);Monte Carlo methods;optimisation;realistic images;rendering (computer graphics)","auxiliary buffers;optimal filter parameter;deep learning method;optimal model analysis;rendered image;denoising Monte Carlo rendering noise;recurrent autoencoder;VGGNet;DnCNN;ResNet;DenseNet","","","","9","","24 Feb 2019","","","IEEE","IEEE Conferences"
"A New Training Principle for Stacked Denoising Autoencoders","Q. You; Y. -J. Zhang","Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China","2013 Seventh International Conference on Image and Graphics","24 Oct 2013","2013","","","384","389","In this work, a new training principle is introduced for unsupervised learning that makes the learned representations more efficient and useful. Using partially corrupted inputs instead, the denoising Auto encoder can obtain more robust and representative pattern of inputs than the traditional learning methods. Besides, this denoising Auto encoder can be stacked to form a deep network. The whole framework of training stacked denoising Auto encoders, which involved several supervised training methods in the framework, is given for image classification. Comparative experiments have shown that the model can resist noise of training examples powerfully and achieve better accuracy of image classification on MNIST database.","","978-0-7695-5050-3","10.1109/ICIG.2013.83","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6643701","unsupervised learning;stacked denoising Autoencoders;image classification","Noise reduction;Training;Image reconstruction;Image classification;Tuning;Databases;Classification algorithms","image classification;image denoising;neural nets;unsupervised learning","training principle;stacked denoising autoencoders;unsupervised learning;supervised training methods;image classification;MNIST database","","2","","12","","24 Oct 2013","","","IEEE","IEEE Conferences"
"Denoising Convolutional Autoencoder Based B-mode Ultrasound Tongue Image Feature Extraction","B. Li; K. Xu; D. Feng; H. Mi; H. Wang; J. Zhu","Automation Dept., Beijing University of Posts and Telecommunications, Beijing, China; National Key Lab of Parallel and Distributed Processing, Changsha, China; National Key Lab of Parallel and Distributed Processing, Changsha, China; National Key Lab of Parallel and Distributed Processing, Changsha, China; National Key Lab of Parallel and Distributed Processing, Changsha, China; Department of Linguistics, University of Michigan, Ann Arbor, USA","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","7130","7134","B-mode ultrasound tongue imaging is widely used in the speech production field. However, efficient interpretation is in a great need for the tongue image sequences. Inspired by the recent success of unsupervised deep learning approach, we explore unsupervised convolutional network architecture for the feature extraction in the ultrasound tongue image, which can be helpful for the clinical linguist and phonetics. By quantitative comparison between different unsupervised feature extraction approaches, the denoising convolutional autoencoder (DCAE)-based method outperforms the other feature extraction methods on the reconstruction task and the 2010 silent speech interface challenge. A Word Error Rate of 6.17% is obtained with DCAE, compared to the state-of-the-art value of 6.45% using Discrete cosine transform as the feature extractor. Our codes are available at https://github.com/DeePBluE666/Source-code1.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682806","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682806","B-mode ultrasound tongue imaging;unsupervised learning;feature extraction;convolutional autoencoder;denoising convolutional autoencoder","Ultrasonic imaging;Feature extraction;Noise reduction;Tongue;Convolutional codes;Image reconstruction;Discrete cosine transforms","biomedical ultrasonics;convolution;discrete cosine transforms;feature extraction;image representation;image sequences;learning (artificial intelligence);medical image processing;speech processing;unsupervised learning","convolutional autoencoder based b-mode ultrasound tongue image feature;b-mode ultrasound tongue imaging;speech production field;tongue image sequences;unsupervised deep learning approach;unsupervised convolutional network architecture;feature extraction methods;2010 silent speech interface challenge;feature extractor;convolutional autoencoder-based method;word error rate;discrete cosine transform","","8","1","20","IEEE","17 Apr 2019","","","IEEE","IEEE Conferences"
"Predicting Unmeasured Region of the Efficiency Map of a Speed Reducer Using a Denoising Auto-Encoder","C. Shin; J. Yun; S. Jeong; Y. Jin","Korea Institute of Industrial Technology (KITECH), Kyungpook National University, Republic of Korea; Kyungpook National University, Daegu, Daegu, KR; Korea Institute of Industrial Technology (KITECH), Republic of Korea; Korea Institute of Industrial Technology (KITECH), Republic of Korea","2018 3rd International Conference on Computational Intelligence and Applications (ICCIA)","13 May 2019","2018","","","124","127","This paper presents a Remaining Useful Life (RUL) prediction method for a speed reducer based on denoising au- to-encoder (DAE). Constructing the efficiency map of the re- ducer is an important process for predicting the life span. However, due to the situational constraints that occur, un- measured intervals hinder the completion of the efficiency map. to solve this problem, we propose a method that can pre- dict and reconstruct an unmeasured interval effectively and reliably by using DAE. In addition, we examine the applicabil- ity of the proposed algorithm through experiments that assume various situations.","","978-1-5386-9571-5","10.1109/ICCIA.2018.00030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8711508","Denoising autoencoder;Remaining Useful Life;predicting unmeasured value","Torque;Noise reduction;Prediction algorithms;Angular velocity;Decoding;Visualization;Feature extraction","condition monitoring;gears;image denoising;mechanical engineering computing;remaining life assessment","remaining useful life prediction method;DAE;denoising auto-encoder;speed reducer;efficiency map","","","","8","","13 May 2019","","","IEEE","IEEE Conferences"
"Reduced Biquaternion Stacked Denoising Convolutional AutoEncoder for RGB-D Image Classification","X. Huang; S. Gai","School of Information and Engineering, Nanchang Hangkong University, Nanchang, China; School of Information and Engineering, Nanchang Hangkong University, Nanchang, China","IEEE Signal Processing Letters","22 Jun 2021","2021","28","","1205","1209","RGB-D image classification based on convolutional neural networks have been extensively explored recently. However, they suffer from problems of effective representation of RGB-D image, intra-class variances and inter-class similarities. To address these problems, this letter proposes a novel RGB-D image classification framework based on reduced biquaternion stacked denoising convolutional autoencoder (RQ-SDCAE). The proposed framework can encode and extract the depth feature effectively by using the reduced biquaternion. The stacked training method is utilized to train the proposed reduced biquaternion convolutional autoencoder. Extensive evaluations for RGB-D image classification demonstrate that RQ-SDCAE outperforms the state-of-the-art methods.","1558-2361","","10.1109/LSP.2021.3088049","National Natural Science Foundation of China(grant numbers:62061032); Outstanding Youth Foundation of Jiangsu Province of China(grant numbers:20192ACB21032); Jiangxi Science Foundation(grant numbers:20202BABL202038); Nanchang Hangkong University(grant numbers:YC2019022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9449952","Reduced biquaternion;RGB-D;image classification;autoencoder;hypercomplex network","Training;Convolution;Feature extraction;Tensors;Noise reduction;Matrix converters;Image color analysis","convolution;feature extraction;image classification;image colour analysis;image denoising;image representation;learning (artificial intelligence);neural nets","reduced biquaternion convolutional autoencoder;biquaternion stacked denoising convolutional AutoEncoder;convolutional neural networks;intra-class variances;novel RGB-D image classification framework","","","","22","IEEE","9 Jun 2021","","","IEEE","IEEE Journals"
"Denoising Gravitational Waves with Enhanced Deep Recurrent Denoising Auto-encoders","H. Shen; D. George; E. A. Huerta; Z. Zhao","Dept. of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Dept. of Astronomy, University of Illinois at Urbana-Champaign; NCSA, University of Illinois at Urbana-Champaign; NCSA, University of Illinois at Urbana-Champaign","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","3237","3241","Denoising of time domain data is a crucial task for many applications such as communication, translation, virtual assistants etc. For this task, a combination of a recurrent neural net (RNNs) with a Denoising Auto-Encoder (DAEs) has shown promising results. However, this combined model is challenged when operating with low signal-to-noise ratio (SNR) data embedded in non-Gaussian and non-stationary noise. To address this issue, we design a novel model, referred to as `Enhanced Deep Recurrent Denoising Auto-Encoder' (EDR-DAE), that incorporates a signal amplifier layer, and applies curriculum learning by first denoising high SNR signals, before gradually decreasing the SNR until the signals become noise dominated. We showcase the performance of EDR-DAE using time-series data that describes gravitational waves embedded in very noisy backgrounds. In addition, we show that EDRDAE can accurately denoise signals whose topology is significantly more complex than those used for training, demonstrating that our model generalizes to new classes of gravitational waves that are beyond the scope of established denoising algorithms.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683061","RNN;denoising algorithm;time series;gravitational waves","Noise reduction;Training;Signal to noise ratio;Data models;Noise measurement;Time series analysis","Gaussian noise;gravitational waves;learning (artificial intelligence);recurrent neural nets;signal denoising;time series","time domain data;nonstationary noise;EDR-DAE;signal amplifier layer;time-series data;gravitational wave denoising;signal-to-noise ratio;SNR signals;enhanced deep recurrent denoising autoencoders","","15","","23","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Wind Turbine Fault Detection Using a Denoising Autoencoder With Temporal Information","G. Jiang; P. Xie; H. He; J. Yan","School of Electrical Engineering, Yanshan University, Qinhuangdao, China; Department of Electrical, Computer, and Biomedical Engineering, University of Rhode Island, Kingston, RI, USA; Concordia Institute for Information Systems Engineering, Concordia University, Montréal, QC, Canada; Concordia Institute for Information Systems Engineering, Concordia University, Montréal, QC, Canada","IEEE/ASME Transactions on Mechatronics","16 Feb 2018","2018","23","1","89","100","Data-driven approaches have gained increasing interests in the fault detection of wind turbines (WTs) due to the difficulty in system modeling and the availability of sensor data. However, the nonlinearity of WTs, uncertainty of disturbances and measurement noise, and temporal dependence in time-series data still pose grand challenges to effective fault detection. To this end, this paper proposes a new fault detector based on a recently developed unsupervised learning method, denoising autoencoder (DAE), which offers the learning of robust nonlinear representations from data against noise and input fluctuation. A DAE is used to build a robust multivariate reconstruction model on raw time-series data from multiple sensors, and then, the reconstruction error of the DAE trained with normal data is analyzed for fault detection. In addition, we apply the sliding-window technique to consider temporal information inherent in time-series data by including the current and past information within a small time window. A key advantage of the proposed approach is the ability to capture the nonlinear correlations among multiple sensor variables and the temporal dependence of each sensor variable simultaneously, which significantly enhanced the fault detection performance. Simulated data from a generic WT benchmark and field supervisory control and data acquisition data from a real wind farm are used to evaluate the proposed approach. The results of two case studies demonstrate the effectiveness and advantages of our proposed approach.","1941-014X","","10.1109/TMECH.2017.2759301","National Natural Science Foundation of China(grant numbers:61673336,51529701); Natural Science Foundation of Hebei Province(grant numbers:F2016203421); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8059861","Complex mechatronics;denoising autoencoder (DAE);fault detection;multivariate data driven;temporal information;wind turbines (WTs)","Fault detection;Correlation;Robustness;Temperature measurement;Monitoring;Mechatronics;Noise reduction","data acquisition;fault diagnosis;neural nets;power engineering computing;signal denoising;time series;unsupervised learning;wind power plants;wind turbines","wind turbine fault detection;denoising autoencoder;temporal information;data-driven approaches;wind turbines;WTs;system modeling;temporal dependence;fault detector;DAE;robust nonlinear representations;robust multivariate reconstruction model;raw time-series data;nonlinear correlations;multiple sensor variables;fault detection performance;wind farm;noise measurement;fault detection;unsupervised learning method;time-series data","","105","","51","IEEE","5 Oct 2017","","","IEEE","IEEE Journals"
"Deep Architecture for High-Speed Railway Insulator Surface Defect Detection: Denoising Autoencoder With Multitask Learning","G. Kang; S. Gao; L. Yu; D. Zhang","School of Electrical and Automation Engineering, East China Jiaotong University, Nanchang, China; School of Electrical Engineering, Southwest Jiaotong University, Chengdu, China; School of Electrical Engineering, Southwest Jiaotong University, Chengdu, China; School of Electrical Engineering, Southwest Jiaotong University, Chengdu, China","IEEE Transactions on Instrumentation and Measurement","12 Jul 2019","2019","68","8","2679","2690","The insulator is an important catenary component that maintains the insulation between the catenary and earth. Due to the long-term impact of railway vehicles and the environment, defects in the insulator are inevitable. Recently, automatic catenary inspection using computer vision and pattern recognition has been introduced to improve the safety of railway operation. However, achieving full automation of insulator defect detection is still very challenging due to the visual complexity of defects and the small number of defective insulators. To overcome these problems, this paper proposes a novel insulator surface defect detection system using a deep convolutional neural network (CNN). The proposed system consists of two stages. First, a Faster R-CNN network is adopted to localize the key catenary components, and the image areas that contain the insulators are obtained. Then, the classification score and anomaly score are determined from a deep multitask neural network that is composed of a deep material classifier and a deep denoising autoencoder. The defect state is determined by analyzing the classification score and anomaly score. Experiments of the catenary insulator defect detection along the Hefei-Fuzhou high-speed railway line indicate that the system can achieve high detection accuracy.","1557-9662","","10.1109/TIM.2018.2868490","National Natural Science Foundation of China(grant numbers:U1434203); National Key Research and Development Plan of China(grant numbers:2017YFB1201202); China Railway Corporation Science and Technology Research and Development Project(grant numbers:2015J008-A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516370","Catenary;deep denoising autoencoder (DDAE);defect detection;high-speed railway;insulator;multitask learning (MTL)","Insulators;Rail transportation;Inspection;Feature extraction;Monte Carlo methods;Noise reduction;Image segmentation","computer vision;convolutional neural nets;image classification;image denoising;inspection;insulators;learning (artificial intelligence);railway engineering;railway safety;railways","deep convolutional neural network;key catenary components;classification score;anomaly score;deep multitask neural network;deep material classifier;deep denoising autoencoder;defect state;catenary insulator defect detection;Hefei-Fuzhou high-speed railway line;high detection accuracy;high-speed railway insulator surface defect detection;railway vehicles;automatic catenary inspection;computer vision;pattern recognition;railway operation;defective insulators;insulator surface defect detection system;faster R-CNN network;deep architecture;multitask learning","","103","","34","IEEE","31 Oct 2018","","","IEEE","IEEE Journals"
"A Deep Denoising Autoencoder Approach to Improving the Intelligibility of Vocoded Speech in Cochlear Implant Simulation","Y. -H. Lai; F. Chen; S. -S. Wang; X. Lu; Y. Tsao; C. -H. Lee","Department of Electrical Engineering, Yuan Ze University; Department of Electrical and Electronic Engineering, Southern University of Science and Technology; Research Center for Information Technology Innovation, Academia Sinica; National Institute of Information and Communications Technology; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; School of Electrical and Computer Engineering, Georgia Institute of Technology","IEEE Transactions on Biomedical Engineering","15 Jun 2017","2017","64","7","1568","1578","Objective: In a cochlear implant (CI) speech processor, noise reduction (NR) is a critical component for enabling CI users to attain improved speech perception under noisy conditions. Identifying an effective NR approach has long been a key topic in CI research. Method: Recently, a deep denoising autoencoder (DDAE) based NR approach was proposed and shown to be effective in restoring clean speech from noisy observations. It was also shown that DDAE could provide better performance than several existing NR methods in standardized objective evaluations. Following this success with normal speech, this paper further investigated the performance of DDAE-based NR to improve the intelligibility of envelope-based vocoded speech, which simulates speech signal processing in existing CI devices. Results: We compared the performance of speech intelligibility between DDAE-based NR and conventional single-microphone NR approaches using the noise vocoder simulation. The results of both objective evaluations and listening test showed that, under the conditions of nonstationary noise distortion, DDAE-based NR yielded higher intelligibility scores than conventional NR approaches. Conclusion and significance: This study confirmed that DDAE-based NR could potentially be integrated into a CI processor to provide more benefits to CI users under noisy conditions.","1558-2531","","10.1109/TBME.2016.2613960","National Natural Science Foundation of China(grant numbers:61571213); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577811","Cochlear implant;deep denoising autoencoder (DDAE);noise reduction (NR);Voice Operated reCOrDER (vocoder) simulation","Speech;Noise measurement;Noise reduction;Performance evaluation;Signal to noise ratio;Speech enhancement","cochlear implants;medical signal processing;microphones;signal denoising;speech processing","deep denoising autoencoder approach;cochlear implant simulation;cochlear implant speech processor;noise reduction;speech perception;noisy conditions;envelope-based vocoded speech;speech signal processing;single-microphone NR approach;noise vocoder simulation;listening test;nonstationary noise distortion","Algorithms;Cochlear Implants;Humans;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;Signal-To-Noise Ratio;Sound Spectrography;Speech Intelligibility;Speech Production Measurement","58","","71","IEEE","27 Sep 2016","","","IEEE","IEEE Journals"
"Modeling gender information for emotion recognition using Denoising autoencoder","R. Xia; J. Deng; B. Schuller; Y. Liu","Machine Intelligence & Signal Processing Group, Technische Universität München, Germany; Machine Intelligence & Signal Processing Group, Technische Universität München, Germany; Machine Intelligence & Signal Processing Group, Technische Universität München, Germany; Computer Science Department, The University of Texas, Dallas, USA","2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","14 Jul 2014","2014","","","990","994","The Denoising autoencoder (DAE) has been successfully applied to acoustic emotion recognition lately. In this paper, we adopt the framework of the modified DAE introduced in that projects the input signal to two different hidden representations, for neutral and emotional speech respectively, and uses the emotional representation for the classification task. We propose to model gender information for more robust emotional representation in this work. For neutral representation, male and female dependent DAEs are built using non-emotional speech with the aim of capturing distinct information between the two genders. The emotional hidden representation is shared for the two genders in order to model more emotion specific characteristics, and is used as features in a back-end classifier for emotion recognition. We propose different optimization objectives in training the DAEs. Our experimental results show improvement on unweighted accuracy compared with previous work using the modified DAE method and the classifiers using the standard static features. Further performance gain can be achieved by structural level system combination.","2379-190X","978-1-4799-2893-4","10.1109/ICASSP.2014.6853745","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6853745","Emotion recognition;Denoising autoencoder;Gender","Emotion recognition;Speech;Training;Speech recognition;Feature extraction;Noise reduction","emotion recognition;image classification;image coding;image denoising;image representation;speech coding;speech recognition","gender information modeling;denoising autoencoder;DAE;acoustic emotion recognition;signal representation;neutral speech representation;emotional speech representation;emotional classification;emotional hidden representation;back-end classifier;optimization;structural level system combination","","26","","24","","14 Jul 2014","","","IEEE","IEEE Conferences"
"A New Approach for Supervised Power Disaggregation by Using a Denoising Autoencoder and Recurrent LSTM Network","T. S. Wang; T. Y. Ji; M. S. Li","School of Electric Power Engineering, South China University of Technology, Guangzhou, Guangdong, China; School of Electric Power Engineering, South China University of Technology, Guangzhou, Guangdong, China; School of Electric Power Engineering, South China University of Technology, Guangzhou, Guangdong, China","2019 IEEE 12th International Symposium on Diagnostics for Electrical Machines, Power Electronics and Drives (SDEMPED)","14 Oct 2019","2019","","","507","512","Non-intrusive load monitoring (NILM) is a task of estimating the contribution of individual appliance to the overall power consumption by using a set of electrical signals measured by a smart meter. In this paper, we propose a comprehensive and extensible framework based on DNNs. We employ denoising autoencoder (dAE) to reconstruct the power signal of individual appliance from aggregated power consumption, and we use long short term memory (LSTM) network to make sure which appliance the power signal belongs to. We select 5 appliances to validate our method, and the results have shown the advantages of the proposed framework in some aspects compared to hidden Markov models (HMMs) and premier dAE.","","978-1-7281-1832-1","10.1109/DEMPED.2019.8864870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8864870","Non-intrusive load monitoring (NILM);load disaggregation;deep neural network (DNN);long short-term memory network (LSTM);denoising autoencoder (dAE)","Noise reduction;Hidden Markov models;Neural networks;Training data;Feature extraction;Logic gates;Washing machines","domestic appliances;power engineering computing;power system measurement;recurrent neural nets;signal denoising;smart meters","recurrent LSTM network;nonintrusive load monitoring;electrical signals;smart meter;power signal;aggregated power consumption;short term memory network;supervised power disaggregation;denoising autoencoder;DNNs;long short term memory network","","7","","10","","14 Oct 2019","","","IEEE","IEEE Conferences"
"A Novel Stacked Denoising Autoencoder-Based Reconstruction Framework for Cerenkov Luminescence Tomography","X. Cao; X. Wei; F. Yan; L. Wang; L. Su; Y. Hou; G. Geng; X. He","School of Information Science and Technology, Northwest University, Xi’an, China; School of Information Science and Technology, Northwest University, Xi’an, China; School of Information Science and Technology, Northwest University, Xi’an, China; School of Information Science and Technology, Northwest University, Xi’an, China; School of Information Science and Technology, Northwest University, Xi’an, China; School of Information Science and Technology, Northwest University, Xi’an, China; School of Information Science and Technology, Northwest University, Xi’an, China; School of Information Science and Technology, Northwest University, Xi’an, China","IEEE Access","9 Jul 2019","2019","7","","85178","85189","Cerenkov luminescence tomography (CLT) is a promising imaging modality in the field of optical molecular imaging (OMI), which successfully bridges the OMI and tradition nuclear medical imaging and provides the location and quantitative analysis of the distribution of radionuclide probes inside the biological objects. As the CLT is an inherent highly ill-posed inverse problem, it is still a challenge to obtain an accurate reconstruction result. Here, we proposed a novel reconstruction framework based on stacking denoising autoencoders (SDAE), which serve as one famous structure of the artificial neural network (ANN). In our framework, the initial permission region is the whole domain and then a traditional reconstruction algorithm is used to reconstruct each node's energy. Then these nodes are clustered into two regions: permission region and non-permission region, and the permission region is used to start a new reconstruction loop where a new result can be obtained. The procedures above are repeated before the result meets the stop conditions. The numerical simulation experiments, physical phantom experiments and in vivo experiments are all carried out to validate the feasibility and potential of our framework. Results demonstrate that the proposed framework can indeed achieve a good performance in CLT reconstruction.","2169-3536","","10.1109/ACCESS.2019.2924042","National Natural Science Foundation of China(grant numbers:61701403,11571012,61806164,61601363); China Postdoctoral Science Foundation(grant numbers:2018M643719,2018M643717,2019M653717); Young Talent Support Program of the Shaanxi Association for Science and Technology(grant numbers:20190107); Postdoctoral Innovative Talents Support Program(grant numbers:BX20180254); Scientific Research Program; Shaanxi Provincial Education Department(grant numbers:16JF026,17JF027,18JK0767,18JK0778); Natural Science Research Plan Program in Shaanxi Province of China(grant numbers:2017JQ6017,2017JQ6006); Xi’an Science and Technology Project; Xi'an Science and Technology Bureau(grant numbers:201805060ZD11CG44); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8742561","Cerenkov luminescence tomography;optical molecular imaging;reconstruction algorithm;stacking denoising autoencoders","Image reconstruction;Tomography;Biological tissues;Artificial neural networks;Luminescence;Noise reduction","biomedical optical imaging;image denoising;image reconstruction;inverse problems;medical image processing;neural nets;optical tomography;phantoms","biological objects;inverse problem;artificial neural network;reconstruction loop;CLT reconstruction;optical molecular imaging;radionuclide probes;physical phantom experiments;numerical simulation;ANN;stacked denoising autoencoder-based reconstruction framework;nuclear medical imaging;Cerenkov luminescence tomography","","5","","63","CCBY","20 Jun 2019","","","IEEE","IEEE Journals"
"Target Detection With Unconstrained Linear Mixture Model and Hierarchical Denoising Autoencoder in Hyperspectral Imagery","Y. Li; Y. Shi; K. Wang; B. Xi; J. Li; P. Gamba","State Key Laboratory of Integrated Service Network, Xidian University, Xi&#x2019;an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi&#x2019;an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi&#x2019;an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi&#x2019;an, China; State Key Laboratory of Integrated Service Network, Xidian University, Xi&#x2019;an, China; Department of Electrical, Computer and Biomedical Engineering, University of Pavia, Pavia, Italy","IEEE Transactions on Image Processing","25 Jan 2022","2022","31","","1418","1432","Hyperspectral imagery with very high spectral resolution provides a new insight for subtle nuances identification of similar substances. However, hyperspectral target detection faces significant challenges of intraclass dissimilarity and interclass similarity due to the unavoidable interference caused by atmosphere, illumination, and sensor noise. In order to effectively alleviate these spectral inconsistencies, this paper proposes a novel target detection method without strict assumptions on data distribution based on an unconstrained linear mixture model and deep learning. Our proposed detector firstly reduces interference via a specifically designed deep-learning-based hierarchical denoising autoencoder, and then carries out accurate detection with a two-step subspace projection, aiming at background suppression and target enhancement. Additionally, to generate representative background and reliable target samples required in the detection procedure, an efficient spatial-spectral unified endmember extraction method has been developed. Performance comparison with several state-of-the-art detection methods and further analysis on four real-world hyperspectral images demonstrate the effectiveness and efficiency of our proposed target detector.","1941-0042","","10.1109/TIP.2022.3141843","National Key Research and Development Program of China(grant numbers:2018AAA0102702); National Natural Science Foundation of China(grant numbers:61901343,61571345,61671383,91538101,61501346,61502367); China Postdoctoral Science Foundation(grant numbers:2017M623124); China Postdoctoral Science Special Foundation(grant numbers:2018T111019); China Scholarship Council Program(grant numbers:202006960028); Open Research Fund of the Chinese Academy of Sciences (CAS) Key Laboratory of Spectral Imaging Technology(grant numbers:LSIT201924W); Fundamental Research Funds for the Central Universities(grant numbers:JB190107); Yangtse Rive Scholar Bonus Schemes(grant numbers:CJT160102); Ten Thousand Talent Program; 111 Project(grant numbers:B08038); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684246","Unconstrained linear mixture model;hierarchical denoising autoencoder;spatial-spectral unification;hyperspectral target detection","Detectors;Object detection;Hyperspectral imaging;Noise reduction;Mixture models;Interference;Deep learning","deep learning (artificial intelligence);feature extraction;geophysical image processing;hyperspectral imaging;image denoising;image resolution;mixture models;object detection;remote sensing","hyperspectral imagery;high spectral resolution;subtle nuances identification;hyperspectral target detection;intraclass dissimilarity;interclass similarity;sensor noise;spectral inconsistencies;unconstrained linear mixture model;deep learning;hierarchical denoising autoencoder;background suppression;spatial-spectral unified endmember extraction method;real-world hyperspectral images;target detector","","3","","45","IEEE","17 Jan 2022","","","IEEE","IEEE Journals"
"Unsupervised adaptation of a denoising autoencoder by Bayesian Feature Enhancement for reverberant asr under mismatch conditions","J. Heymann; R. Haeb-Umbach; P. Golik; R. Schlüter","Department of Communications Engineering Paderborn, University of Paderborn, Germany; Department of Communications Engineering Paderborn, University of Paderborn, Germany; Human Language Technology and Pattern Recognition Computer Science Department Aachen, RWTH Aachen University, Germany; Human Language Technology and Pattern Recognition Computer Science Department Aachen, RWTH Aachen University, Germany","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","6 Aug 2015","2015","","","5053","5057","The parametric Bayesian Feature Enhancement (BFE) and a datadriven Denoising Autoencoder (DA) both bring performance gains in severe single-channel speech recognition conditions. The first can be adjusted to different conditions by an appropriate parameter setting, while the latter needs to be trained on conditions similar to the ones expected at decoding time, making it vulnerable to a mismatch between training and test conditions. We use a DNN backend and study reverberant ASR under three types of mismatch conditions: different room reverberation times, different speaker to microphone distances and the difference between artificially reverberated data and the recordings in a reverberant environment. We show that for these mismatch conditions BFE can provide the targets for a DA. This unsupervised adaptation provides a performance gain over the direct use of BFE and even enables to compensate for the mismatch of real and simulated reverberant data.","2379-190X","978-1-4673-6997-8","10.1109/ICASSP.2015.7178933","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178933","robust speech recognition;deep neuronal networks;feature enhancement;denoising autoencoder","Speech;Speech recognition;Training;Reverberation;Adaptation models;Noise reduction","codecs;signal denoising;speech recognition","unsupervised adaptation;denoising autoencoder;Bayesian feature enhancement;reverberant ASR;single-channel speech recognition;speaker to microphone distances","","2","","25","","6 Aug 2015","","","IEEE","IEEE Conferences"
"Single-channel dereverberation for distant-talking speech recognition by combining denoising autoencoder and temporal structure normalization","Y. Ueda; L. Wang; A. Kai; X. Xiao; E. S. Chng; H. Li","Graduate School of Engineering, Shizuoka University, Hamamatsu, Japan; Nagaoka University of Technology, Nagaoka, Japan; Graduate School of Engineering, Shizuoka University, Hamamatsu, Japan; School of Computer Engineering, Nanyang Technological University, Singapore; School of Computer Engineering, Nanyang Technological University, Singapore; Human Language Technology, Institute for Infocomm Research, A*STAR, Singapore","The 9th International Symposium on Chinese Spoken Language Processing","27 Oct 2014","2014","","","379","383","In this paper, we propose a robust distant-talking speech recognition by combining cepstral domain denoising autoencoder (DAE) and temporal structure normalization (TSN) filter. For the proposed method, after applying a DAE in the cepstral domain of speech to suppress reverberation, we apply a post-processing technology based on temporal structure normalization (TSN) filter to reduce the noise and reverberation effects by normalizing the modulation spectra to reference spectra of clean speech. The proposed method was evaluated using speech in simulated and real reverberant environments. By combining a cepstral-domain DAE and TSN, the average Word Error Rate (WER) was reduced from 25.2% of the baseline system to 21.2% in simulated environments and from 47.5% to 41.3% in real environments, respectively.","","978-1-4799-4219-0","10.1109/ISCSLP.2014.6936613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6936613","speech recognition;dereverberation;denoising autoencoder;environment adaptation;distant-talking speech","Speech;Noise reduction;Robustness;Educational institutions;Abstracts;Spectral analysis;Indexes","cepstral analysis;filtering theory;reverberation;signal denoising;speech coding;speech recognition","single-channel dereverberation;distant-talking speech recognition;temporal structure normalization;cepstral domain denoising autoencoder;TSN filter;reverberation suppression;post-processing technology;noise reduction;reverberation effects reduction;modulation spectra normalization;clean speech reference spectra;cepstral-domain DAE;cepstral-domain TSN;word error rate;WER","","2","","31","","27 Oct 2014","","","IEEE","IEEE Conferences"
"Underwater Acoustic Detection and Localization with a Convolutional Denoising Autoencoder","A. Testolin; R. Diamant","Department of Information Engineering and the Department of General Psychology, University of Padova, Italy; Department of Marine Technologies, University of Haifa, Israel","2019 IEEE 8th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)","5 Mar 2020","2019","","","281","285","Detecting and tracking moving targets is a challenging task, which becomes even harder in underwater scenarios due to the extremely low levels of signal-to-noise ratio associated with common acoustic measures. In the context of continuous marine monitoring, a further challenge is provided by the need to deploy computationally efficient methods that guarantee minimum use of power resources in off-shore monitoring platforms. Here we present a novel approach to accurately detect and track moving targets from the reflections of an active acoustic emitter. Our system is based on a computationally- and energy-efficient deep convolutional denoising autoencoder. System performance is evaluated both on simulated and emulated data, and benchmarked against a probabilistic tracking method based on the Viterbi algorithm.","","978-1-7281-5549-4","10.1109/CAMSAP45676.2019.9022594","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022594","Marine monitoring;Underwater acoustics;Signal detection;Underwater tracking;Denoising autoencoders;Convolutional Neural Networks;Viterbi algorithm","Target tracking;Convolution;Clutter;Machine learning;Noise reduction;Transceivers","acoustic signal detection;acoustic signal processing;convolutional neural nets;geophysical signal processing;oceanographic techniques;signal denoising;target tracking","moving target detection;underwater scenarios;signal-to-noise ratio;common acoustic measures;continuous marine monitoring;power resources;off-shore monitoring platforms;active acoustic emitter;energy-efficient deep convolutional denoising autoencoder;system performance;probabilistic tracking method;underwater acoustic detection;underwater acoustic localization;moving target tracking","","2","","22","","5 Mar 2020","","","IEEE","IEEE Conferences"
"A Feature Extraction Method Based on Stacked Denoising Autoencoder for Massive High Dimensional Data","B. Xu; X. Ding; R. Hou; C. Zhu","College of Information Science and Engineering, Ocean University of China, Qingdao, China; College of Information Science and Engineering, Ocean University of China, Qingdao, China; College of Information Science and Engineering, Ocean University of China, Qingdao, China; Project management department, China Unicom Jinan Software Research Institute, Jinan, China","2018 14th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)","11 Apr 2019","2018","","","206","210","Massive high dimensional data has a large sample size and high dimensionality. However, all the features of the massive high dimensional data are used for identification or classification, which will increase the calculation time and reduce the accuracy of identification or classification. Therefore, extracting features with strong expressive ability is very important for processing massive high-dimensional data. In order to solve this problem, this paper presents a feature extraction method which based on Stacked Denoising Autoencoder (SDAE). SDAE trains each layer of neural network by unsupervised layer-by-layer greedy training. Then supervised training Softmax classifier. And finally uses Back Propagation (BP) algorithm to optimize the entire model. In this paper, the ISOLET data set is taken as experimental data. The experimental results demonstrated that our proposed method can extract feature subsets with strong expressive ability. And using this feature subset for classification, the classification accuracy is significantly improved.","","978-1-5386-8097-1","10.1109/FSKD.2018.8687138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8687138","massive high dimensional data;classification;feature extraction;Stacked Denoising Autoencoder","","backpropagation;data handling;feature extraction;image classification;image denoising;learning (artificial intelligence);neural nets;pattern classification","feature extraction method;Stacked Denoising Autoencoder;feature subset;high dimensionality;massive high-dimensional data;neural network;unsupervised layer-by-layer greedy training;Back Propagation algorithm;BP algorithm;ISOLET data set","","1","","11","","11 Apr 2019","","","IEEE","IEEE Conferences"
"Efficient Noisy Data Transmission Using Denoising Autoencoder in Internet of Things","Y. Xin; H. Chen; L. Xie","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; The Engineering Research Center of Oceanic Sensing Technology and Equipment, Ministry of Education, Zhoushan, China; Zhejiang Provincial Key Laboratory of Information Processing, Communication and Networking, Hangzhou, China","2021 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)","25 Oct 2021","2021","","","1","6","Internet of Things (IoT) is an extension and expansion of the physical world based on Internet and various emerging technologies. In this paper, we investigate the problem of efficient noisy data transmission in a resource-constrained IoT -based application, we focus on the data transmission between the resource-limited sensor and the well-resource control center. We propose an efficient noisy data transmission scheme based on denoising Autoencoder (DAE). In order to train the DAE architecture, a modified random noise introducing (RNI) method is presented. The proposed data transmission scheme is named as DTDA-RNI. Performance evaluation results show that the proposed DTDA-RNI scheme outperforms in terms of a higher reconstruction accuracy, a lower compression rate, and a faster reconstruction speed.","","978-1-6654-2918-4","10.1109/ICSPCC52875.2021.9565090","Fund of National Natural Science Foundation of China(grant numbers:61531017); Science and Technology Department of Zhejiang Province(grant numbers:2018R52046,LGG18F010005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9565090","noisy data transmission;denoising autoencoder (DAE);compress;Internet of things (IoT)","Training;Performance evaluation;Noise reduction;Signal processing algorithms;Signal processing;Feature extraction;Data models","data compression;image denoising;image reconstruction;Internet of Things;performance evaluation;random noise;wireless sensor networks","denoising Autoencoder;resource-constrained IoT;resource-limited sensor;well-resource control center;efficient noisy data transmission scheme","","","","14","","25 Oct 2021","","","IEEE","IEEE Conferences"
"Wi-Fi DSAR: Wi-Fi based Indoor Localization using Denoising Supervised Autoencoder","Y. -H. Wang; T. -W. Yang; C. -F. Chou; I. -C. Chang","Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan, ROC; Graduate Institute of Networking and Multimedia, National Taiwan University, Taipei, Taiwan, ROC; Department of Computer Science and Information Engineering and Information Technology Office, National Taiwan University Hospital, National Taiwan University, Taipei, Taiwan, ROC; Department. of Computer Science and Information Engineering, National Changhua University of Education, Changhua, Taiwan, ROC","2021 30th Wireless and Optical Communications Conference (WOCC)","15 Nov 2021","2021","","","188","192","In recent years, the demand for Wi-Fi has grown exponentially, which has led to the rapid development of indoor positioning services based on Wi-Fi fingerprints. Due to the Received Signal Strength Indicator (RSSI) variation over time, the device heterogeneity, and dynamic changes in the environment, the accuracy and robustness of traditional Wi-Fi fingerprint-based methods usually degrade. To alleviate these issues, we propose an approach based on the denoising supervised autoencoder for regression tasks that we named Wi-Fi DSAR. The idea of Wi-Fi DSAR design is to (a) has strong resistance to the noise in the received Wi-Fi signal, and (b) prevent overfitting the fingerprint database to achieve robustness. We do a performance study by comparing other fingerprint-based works with our Wi-Fi DSAR. All works are evaluated in three open datasets, i.e., DSI, IPIN2016, and IPIN2020, with different area sizes and access point densities. Experimental results demonstrate that compared with existing fingerprint-based methods, our Wi-Fi DSAR is able to reduce the average positioning error by 20% to 50%. This is because our Wi-Fi DSAR has both noise immunity and generalization performance.","2379-1276","978-1-6654-2772-2","10.1109/WOCC53213.2021.9602896","Ministry of Science and Technology; National Taiwan University Hospital; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9602896","indoor localization;Wi-Fi fingerprint positioning;machine learning;RSSI;denoising autoencoder","Location awareness;Wireless communication;Resistance;Noise reduction;Fingerprint recognition;Robustness;Optical fiber communication","indoor navigation;indoor radio;neural nets;radiofrequency interference;regression analysis;RSSI;signal denoising;supervised learning;wireless LAN","received Wi-Fi signal;denoising supervised autoencoder;Wi-Fi DSAR design;Wi-Fi fingerprint-based methods;Wi-Fi based indoor localization;received signal strength indicator;RSSI;noise immunity","","","","9","IEEE","15 Nov 2021","","","IEEE","IEEE Conferences"
"GNSS-R Delay/Doppler Map Compression Method Using a Denoising Convolutional Autoencoder","H. Du; R. Min; W. Guo","GNSS Research Center, Wuhan University, Wuhan, China; School of Geodesy and Geomatics, Wuhan University, Wuhan, China; GNSS Research Center, Wuhan University, Wuhan, China","2021 IEEE Specialist Meeting on Reflectometry using GNSS and other Signals of Opportunity (GNSS+R)","24 Nov 2021","2021","","","53","56","To reduce the channel transmission and data storage in the spaceborne Global Navigation Satellite System Reflectometry (GNSS-R), a Delay/Doppler Map (DDM) compression method for CYGNSS products is proposed in this paper. It applies a self-supervised denoising convolutional autoencoder (DCAE) to dig out effective features in the DDM, which are used to reconstruct the DDM. This network is an encoder-decoder symmetric structure, which can reduce about 90% of the data volume. CYGNSS L0, L1a, and L1b DDMs are all used to validate the compressing performance in this paper. Results show that the averaged root mean square errors (RMSEs) between reconstructed and original L0, L1a, and L1b DDMs are 2816 counts, 2.8*10−18 W and 5.7×1010 m2 respectively. The averaged peak signal-to-noise ratios (PSNRs) are respectively 19.48 dB, 13.67 dB, and 6.79 dB. The encoder-decoder structure of DCAE can effectively compress and restore DDMs. We also verify the effectiveness of features from the encoder by a simple fully connected network (FCN) for wind speed retrieval. The RMSE of wind speed retrievals is 1.76 m/s, which proves that compressed features carry roughness information.","","978-1-6654-1782-2","10.1109/GNSSR53802.2021.9617706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9617706","DDM compression;feature extraction;denoising convolutional autoencoder (DCAE);CYGNSS;wind speed retrieval","Global navigation satellite system;PSNR;Convolution;Wind speed;Noise reduction;Memory;Reflectometry","atmospheric techniques;convolution;convolutional neural nets;data compression;encoding;feature extraction;geophysical image processing;image coding;image denoising;image representation;mean square error methods;reflectometry;remote sensing;satellite navigation;supervised learning;wind","channel transmission;data storage;spaceborne Global Navigation Satellite System Reflectometry;DDM;CYGNSS products;self-supervised denoising convolutional autoencoder;DCAE;encoder-decoder symmetric structure;CYGNSS L0;averaged root mean square errors;encoder-decoder structure;GNSS-R delay-Doppler map compression method;PSNR;fully connected network;FCN;wind speed retrieval","","","","9","IEEE","24 Nov 2021","","","IEEE","IEEE Conferences"
"Terrain Recognition Based on the Carrier-Free UWB Radar Using Stacked Denoising Autoencoder","X. Li; S. Chen; Y. Zhu; S. Zhang","School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China","2022 7th International Conference on Signal and Image Processing (ICSIP)","19 Sep 2022","2022","","","162","166","The carrier-free ultra-wideband (UWB) sensor characterizes high distance resolution and high interference immunity. It is not easily affected by weather and lighting conditions, and its received echoes contain detailed structural information of the target. In this paper, we propose a terrain recognition framework based on the carrier-free UWB sensor. For the purpose of extracting noise-robustness features, a deep network named stacked denoising autoencoder (SDAE) is developed. Given that the convolutional neural network (CNN) is insensitive to translation to some extent, we combine several CNNs as middle structures of the proposed model. Experimental results demonstrate that the proposed algorithm can effectively learn essential representation and improve classification accuracy in the presence of low signal-to-noise ratios (SNRs), making it very suitable for use in a classification scheme.","","978-1-6654-9563-9","10.1109/ICSIP55141.2022.9886559","Natural Science Foundation of Jiangsu Province; National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9886559","terrain recognition;carrier-free UWB radar;stacked denoising autoencoder","Image recognition;Noise reduction;Lighting;Interference;Feature extraction;Classification algorithms;Convolutional neural networks","feature extraction;image classification;image denoising;learning (artificial intelligence);neural nets;radar interference;ultra wideband radar","carrier-free UWB radar;stacked denoising autoencoder;carrier-free ultra-wideband sensor;high distance resolution;high interference immunity;weather;lighting conditions;received echoes;detailed structural information;terrain recognition framework;carrier-free UWB sensor;noise-robustness features;deep network;convolutional neural network;middle structures","","","","14","IEEE","19 Sep 2022","","","IEEE","IEEE Conferences"
"Integrating Denoising Autoencoder and Vector Taylor Series with Auditory Masking for Speech Recognition in Noisy Conditions","A. Biswajit Das; A. Panda","INRIA Bordeaux Sud-Ouest (GeoStat team), Talence, France; TCS Innovation Labs-Mumbai, Thane, Maharashtra, India","2018 26th European Signal Processing Conference (EUSIPCO)","2 Dec 2018","2018","","","2305","2309","We propose a new front-end feature compensation technique to improve the performance of Automatic Speech Recognition (ASR) systems in noisy environments. First, a Time Delay Neural Network (TDNN) based Denoising Autoencoder (DAE) is considered to compensate the noisy features. The DAE provides good gain in performance when it has been trained using the noise present in the test utterances (“seen” conditions). However, if the noise present in the test utterance is different to what was used in the training of the DAE (“un-seen” conditions), then the performance degrades to a great extent. To improve the ASR performance in such unseen conditions, a model compensation technique, namely the Vector Taylor Series with Auditory Masking (VTS-AM) is used. We propose a new Signal-to-Noise Ratio (SNR) based measure, which can reliably choose the type of compensation to be used for best performance gain. We show that the proposed technique improves the ASR performance significantly on noise corrupted TIMIT and Librispeech databases.","2076-1465","978-9-0827-9701-5","10.23919/EUSIPCO.2018.8553339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8553339","Noise robust speech recognition;Auditory masking;Vector Taylor series;Time delay neural network;Denoising autoencoder","Signal to noise ratio;Speech recognition;Noise measurement;Training;Databases;Psychoacoustic models;Taylor series","neural nets;signal denoising;speech recognition","automatic speech recognition systems;time delay neural network;denoising autoencoder;vector Taylor series;auditory masking;signal-to-noise ratio-based measurement;front-end feature compensation technique;noisy conditions;performance gain;model compensation technique;unseen conditions;ASR performance;test utterance;noisy features;DAE;noisy environments","","","","20","","2 Dec 2018","","","IEEE","IEEE Conferences"
"Multistage committees of deep feedforward convolutional sparse denoise autoencoder for object recognition","Shicao Luo; Yongsheng Ding; Kuangrong Hao","College of Information Science and Technology, Donghua University, Shanghai, China; College of Information Science and Technology, Donghua University, Shanghai, China; College of Information Science and Technology, Donghua University, Shanghai, China","2015 Chinese Automation Congress (CAC)","18 Jan 2016","2015","","","565","570","Deep learning and unsupervised feature learning systems are known to achieve good performance in benchmarks by using extremely large architectures with many features at each layer. However, we found that the number of features' contribution to performance is very small when it is more than the threshold. Meanwhile, the size of pooling layer has an important influence on performance. In this paper, we present an unsupervised method to improve the classification result by going deep and combining multistage classifiers in a committee with a small amount of features at each layer. The network is trained layer-wise via denoise autoencoder (dA) with L-BFGS to optimize convolutional kernels and no backpropagation is used. In addition, we regularize the dA encouraging representations to fit sparse for each coding layer. We apply it on the STL-10 dataset which has very few training examples and a large amount of unlabeled data. Experimental results show that our method presents higher performance than the existing ones on the condition via individual network.","","978-1-4673-7189-6","10.1109/CAC.2015.7382564","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7382564","multistage classifiers;sparse denoise autoencoder;object recognition;deep learning","Feature extraction;Noise reduction;Training;Kernel;Encoding;Robustness;Convolution","feedforward neural nets;image classification;image coding;image denoising;object recognition;unsupervised learning","multistage committees;deep feedforward convolutional sparse denoise autoencoder;object recognition;deep learning;unsupervised feature learning systems;pooling layer;multistage classifiers;dA;L-BFGS;convolutional kernel optimization;coding layer;STL-10 dataset","","","1","30","","18 Jan 2016","","","IEEE","IEEE Conferences"
"Stacked denoising autoencoder for infrared thermography image enhancement","Z. Wei; H. Fernandes; J. R. Tarpani; A. Osman; X. Maldague","School of Engineering, University of Applied Sciences in Saarbrücken, Saarbrücken, Germany; Faculty of Computing, Federal University of Uberlandia, Uberlandia, Brazil; Sao Carlos School of Engineering, Sao Paulo University, Sao Carlos, Brazil; Algorithms / Signal and Data Processing Fraunhofer IZFP Institute for Nondestructive Testing School of Engineering, University of Applied Sciences in Saarbrücken, Saarbrücken, Germany; Department of Electrical Engineering and Computer Engineering, University Laval, Quebec City, QC, Canada","2021 IEEE 19th International Conference on Industrial Informatics (INDIN)","11 Oct 2021","2021","","","1","7","Pulsed thermography is one of the most popular thermography inspection methods. During an experiment of pulsed thermography, a specimen is quickly heated, and infrared images are captured to provide information about the specimen’s surface and subsurface conditions. Adequate transformations are usually performed to enhance the contrast of the thermal images and to highlight the abnormal regions before these thermal images are visually inspected. Given that deep neural networks have been a success in computer vision in the past few years, a data contrast enhancement approach with stacked denoising autoencoder (DAE) is proposed in this paper to enhance the abnormal regions in the thermal frames gathered by pulsed thermography. Compared to the direct principal component thermography, the proposed method can enhance the abnormalities evidently without weakening important details.","","978-1-7281-4395-8","10.1109/INDIN45523.2021.9557407","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9557407","stacked denoising autoencoder;pulsed thermography;PCT;deep learning;non-destructive evaluation","Deep learning;Computer vision;Infrared heating;Conferences;Noise reduction;Inspection;Informatics","computer vision;computerised instrumentation;deep learning (artificial intelligence);image coding;image denoising;image enhancement;infrared imaging","stacked denoising autoencoder;infrared thermography image enhancement;thermal imaging;data contrast enhancement approach;direct principal component thermography;DAE;pulsed thermography inspection methods;deep neural networks","","","","29","IEEE","11 Oct 2021","","","IEEE","IEEE Conferences"
"Variational Denoising Autoencoders and Least-Squares Policy Iteration for Statistical Dialogue Managers","V. Diakoloukas; F. Lygerakis; M. G. Lagoudakis; M. Kotti","School of Electrical and Computer Engineering, Technical University of Crete, Chania, Greece; School of Electrical and Computer Engineering, Technical University of Crete, Chania, Greece; School of Electrical and Computer Engineering, Technical University of Crete, Chania, Greece; Artificial Intelligence, Deloitte, London, U.K.","IEEE Signal Processing Letters","18 Jun 2020","2020","27","","960","964","The use of Reinforcement Learning (RL) approaches for dialogue policy optimization has been the new trend for dialogue management systems. Several methods have been proposed, which are trained on dialogue data to provide optimal system response. However, most of these approaches exhibit performance degradation in the presence of noise, poor scalability to other domains, as well as performance instabilities. To overcome these problems, we propose a novel approach based on the incremental, sample-efficient Least-Squares Policy Iteration (LSPI) algorithm, which is trained on compact, fixed-size dialogue state encodings, obtained from deep Variational Denoising Autoencoders (VDAE). The proposed scheme exhibits stable and noise-robust performance, which significantly outperforms the current state-of-the-art, even in mismatched noise environments.","1558-2361","","10.1109/LSP.2020.2998361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9103219","Variational autoencoders;denoising;dialogue systems;sample-efficient statistical dialogue managers;least-squares policy iteration","Noise reduction;Signal processing algorithms;Encoding;Training;Optimization;Approximation algorithms;Degradation","interactive systems;iterative methods;learning (artificial intelligence);least squares approximations;neural nets;signal denoising;speech processing;statistical analysis","Spoken Dialogue Systems;deep VDAE;sample-efficiency least-squares policy iteration;incremental least-squares policy iteration;noise-robust performance;deep Variational Denoising Autoencoders;fixed-size dialogue state encodings;compact size dialogue state encodings;dialogue management systems;dialogue policy optimization;RL;Reinforcement Learning;statistical dialogue managers","","","","25","IEEE","28 May 2020","","","IEEE","IEEE Journals"
"Test time augmentation by regular shifting for deep denoising autoencoder networks","J. A. Rodríguez-Rodríguez; M. A. Molina-Cabello; R. Benítez-Rochel; E. López-Rubio","Instituto de Investigación Biomédica de Málaga (IBIMA), Málaga, Spain; Instituto de Investigación Biomédica de Málaga (IBIMA), Málaga, Spain; Instituto de Investigación Biomédica de Málaga (IBIMA), Málaga, Spain; Instituto de Investigación Biomédica de Málaga (IBIMA), Málaga, Spain","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","7","Image restoration, which is the process of denoising noisy images in order to recover their latent clean images, has been frequently addressed. The importance of this field resides in the impact of noisy images on the performance of computer vision systems. In this work, a deep autoencoder neural network architecture is proposed to denoise images affected by Gaussian noise. The performance of the system is enhanced by using a test time augmentation scheme. Experiments have been carried out by considering different levels of Gaussian noise. Results demonstrate the suitability of the proposed methodology in order to enhance the quality of the image restoration process in images affected by Gaussian noise.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9534044","Ministry of Economy and Competitiveness of Spain(grant numbers:PPIT.UMA.B1.2017); European Regional Development Fund (ERDF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534044","convolutional neural networks;image classification;Gaussian noise;autoencoder;test time augmentation","Statistical analysis;Gaussian noise;Noise reduction;Neural networks;Image restoration;Storage tanks;Noise measurement","computer vision;image denoising;image restoration;neural net architecture","noisy images;computer vision systems;deep autoencoder neural network architecture;Gaussian noise;image restoration;test time augmentation;regular shifting;deep denoising autoencoder networks;latent clean images","","","","16","","20 Sep 2021","","","IEEE","IEEE Conferences"
"Representation learning by Denoising Autoencoders for Clustering-based Classification","M. Owhadi-Kareshk; M. -R. Akbarzadeh-T","Department of Computer Engineering, Center of Excellence on Soft Computing and Intelligent Information Processing (SCIIP), Ferdowsi University of Mashhad (FUM), Mashhad, Iran; Department of Computer Engineering, Center of Excellence on Soft Computing and Intelligent Information Processing (SCIIP), Ferdowsi University of Mashhad, Mashhad, Razavi Khorasan, IR","2015 5th International Conference on Computer and Knowledge Engineering (ICCKE)","28 Dec 2015","2015","","","228","233","Representation learning is a fast growing approach in machine learning that aims to improve the quality of the input data, instead of insisting on designing complex subsequent learning algorithms. In this paper, we propose to use Denoising AutoEncoders (DAEs), as one of the most effective representation learning methods, in Clustering-based Classification (CC). CC is a multi-class classification solution for large-scale and complicated data sets. In this approach, data are divided into small and simple clusters, which are described by One-Class Classifiers (OCCs). In the proposed Representation Learning for Clustering-based Classification (RLCC), the new representation of each cluster is generated locally to increase the performance of OCCs in term of accuracy. This method still preserves the scalability property as one of the significant advantages of CC methods. RLCC is evaluated with six different data sets from UCI. The results of the experiments show that RLCC has higher generalization power compared to the standard version of CC.","","978-1-4673-9280-8","10.1109/ICCKE.2015.7365832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7365832","Autoencoders;Clustering-based Classification;Denoising Autoencoders;Representation Learning;Representation Learning for Clustering-based Classification","Glass;Heart;Iris;Sonar;Supervised learning;Particle separators;Testing","data structures;learning (artificial intelligence);pattern classification;pattern clustering","denoising autoencoder;machine learning;DAE;multiclass classification solution;one-class classifier;OCC;representation learning-for-clustering-based classification;RLCC;CC method;UCI","","4","","41","","28 Dec 2015","","","IEEE","IEEE Conferences"
"Online marginalized linear stacked denoising autoencoders for learning from big data stream","A. Budiman; M. I. Fanany; C. Basaruddin","Faculty of Computer Science, University of Indonesia, Depok, West Java, Indonesia; Faculty of Computer Science, University of Indonesia, Depok, West Java, Indonesia; Faculty of Computer Science, University of Indonesia, Depok, West Java, Indonesia","2015 International Conference on Advanced Computer Science and Information Systems (ICACSIS)","25 Feb 2016","2015","","","227","235","Big non-stationary data, which comes in gradual fashion or stream, is one important issue in the application of big data to train deep learning machines. In this paper, we focused on a unique variant of traditional autoencoder, which is called Marginalized Linear Stacked Denoising Autoencoder (MLSDA). MLSDA uses a simple linear model. It is faster and uses less number of parameters than the traditional SDA. It also takes advantages of convex optimization. It has better improvement in the bag of words feature representation. However, the traditional SDA with stochastic gradient descent has been more widely accepted in many applications. The stochastic gradient descent is naturally an online learning. It makes the traditional SDA more scalable for streaming big data. This paper proposes a simple modification of MLSDA. Our modification uses matrix multiplication concept for online learning. The experiment result showed the similar accuracy level compared with a batch version of MLSDA and using lower computation resources. The online MLSDA will improve the scalability of MLSDA for handling streaming big data that representing bag of words features for natural language processing, information retrieval, and computer vision.","","978-1-5090-0363-1","10.1109/ICACSIS.2015.7415181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7415181","Autoencoder;big data;deep learning;denoising;online;sequential","Natural language processing;Graphics processing units;Support vector machines","Big Data;gradient methods;learning (artificial intelligence);matrix multiplication;optimisation","online marginalized linear stacked denoising autoencoders;big data stream;big nonstationary data;deep learning machines;traditional autoencoder;MLSDA;simple linear model;traditional SDA;convex optimization;bag of words feature representation;stochastic gradient descent;matrix multiplication concept;online learning;information retrieval;natural language processing;computer vision","","1","","21","","25 Feb 2016","","","IEEE","IEEE Conferences"
"Facial Expression Recognition Based on Convolutional Denoising Autoencoder and XGBoost","J. Yang; D. Zhang; Z. Pan; D. Liu; J. Chen","College of Big Data and Information Engineering, Guizhou University, Guiyang, China; College of Big Data and Information Engineering, Guizhou University, Guiyang, China; College of Big Data and Information Engineering, Guizhou University, Guiyang, China; College of Big Data and Information Engineering, Guizhou University, Guiyang, China; College of Big Data and Information Engineering, Guizhou University, Guiyang, China","2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)","5 Aug 2019","2019","","","149","154","In order to solve the insufficiency of feature extraction in traditional facial expression recognition process and further improve the classification accuracy, a deep learning method combining the convolutional denoising autoencoder and XGBoost model is proposed in this paper. In the early stage of feature extraction, convolutional autoencoder is used to fully learn the high-dimensional complex feature data and reduce the nonlinear dimension. On this basis, noise is introduced into the original image to enhance the robustness and generalization ability of the model. In the later classification process, XGBoost classifier is used to classify the extracted features. Experiments are performed on JAFFE and CK+ facial expression recognition datasets, the results show that this method has better recognition accuracy than other comparison methods.","","978-1-5386-8178-7","10.1109/ITAIC.2019.8785596","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8785596","facial expression recognition;feature extraction;convolutional denoising autoencoder;XGBoost classifier","Feature extraction;Convolution;Noise reduction;Kernel;Face recognition;Deconvolution;Image reconstruction","convolutional neural nets;emotion recognition;face recognition;feature extraction;learning (artificial intelligence)","convolutional denoising autoencoder;feature extraction;deep learning method;XGBoost model;convolutional autoencoder;high-dimensional complex feature data;XGBoost classifier;JAFFE facial expression recognition dataset;CK+ facial expression recognition dataset","","","","18","","5 Aug 2019","","","IEEE","IEEE Conferences"
"A Novel Bionic Corruption Process with High Level Features Based on the SDAE","T. Duan; M. Li","College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China","2021 14th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","7 Dec 2021","2021","","","1","4","The ability of the stacked denoising autoencoder to learn the underlying distribution makes it an ideal choice for feature extraction. The human visual system (HVS) can efficiently recognize images with higher efficiency, especially in various scales, rotations, and corrupted partially. However, computer vision must need many training examples to achieve the same performance. Based on statistic descriptions, the classical corruption process is inconsistent with HVS and has deficiencies of poor computational efficiency. Firstly, this work preprocesses the image into a different number of normalized line segment groups. Then, we proposed a new corruption process that simulates human cognitive behavior based on the stack denoising autoencoder (SDAE). Meanwhile, the input of the SDAE uses both the line segment group and the geometric features of the line segment group. Given the same amount of normalized line segments, the proposed method achieves comparable results on the MNIST dataset.","","978-1-6654-0004-6","10.1109/CISP-BMEI53629.2021.9624357","National Natural Science Foundation of China(grant numbers:62076248,62036013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9624357","Line segments;Stacked denoising autoencoder (SDAE);HVS;Bionic;Image classification","Training;Image segmentation;Image recognition;Noise reduction;Visual systems;Signal processing;Feature extraction","computer vision;feature extraction;image denoising;image segmentation;learning (artificial intelligence);neural nets","human cognitive behavior;stack denoising autoencoder;SDAE;line segment group;geometric features;normalized line segments;stacked denoising autoencoder;feature extraction;human visual system;HVS;computer vision;normalized line segment groups;bionic corruption process;MNIST dataset","","","","18","IEEE","7 Dec 2021","","","IEEE","IEEE Conferences"
"Cascaded Denoising Convolutional Auto-Encoders for Automatic Recovery of Missing Time Series Data","Y. Chen; Y. Wang; Q. Yang","College of Electrical Engineering, Zhejiang University, Hangzhou, China; College of Electrical Engineering, Zhejiang University, Hangzhou, China; Jiangsu Key Construction Laboratory of IoT Application Technology, Wuxi, China","2020 19th International Symposium on Distributed Computing and Applications for Business Engineering and Science (DCABES)","9 Dec 2020","2020","","","283","286","This paper proposes a kind of supervised cascaded denoising convolutional auto-encoders (CDCAE), aiming to accurately recover the missing load data in electric power system. The one-dimensional load data are reshaped as two-dimensional image for data enhancement, which enables the convolutional neural network (CNN) to understand the semantics of load data. Numerical results in comparison with similar day filling (SDF) clearly validate the effectiveness of the proposed CDCAE in accuracy.","2473-3636","978-1-7281-9724-1","10.1109/DCABES50732.2020.00080","National Natural Science Foundation of China(grant numbers:51777183); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9277756","cascaded denoising convolutional auto-encoders;recovery of missing data;deep learning","Signal to noise ratio;Power systems;Noise reduction;Testing;Interpolation;Decoding;Data models","convolutional neural nets;data handling;image denoising;image restoration;power engineering computing;supervised learning;time series","CDCAE;electric power system;two dimensional image;data enhancement;convolutional neural network;supervised cascaded denoising convolutional autoencoders;missing load data recovery;time series data recovery;image inpainting;image denoising","","","","12","IEEE","9 Dec 2020","","","IEEE","IEEE Conferences"
"Effective joint training of denoising feature space transforms and Neural Network based acoustic models","T. Fukuda; O. Ichikawa; G. Kurata; R. Tachibana; S. Thomas; B. Ramabhadran","IBM Watson Multimodal, Tokyo, JAPAN; IBM Watson Multimodal, Tokyo, JAPAN; IBM Watson Multimodal, Tokyo, JAPAN; IBM Watson Multimodal, Tokyo, JAPAN; IBM Watson Multimodal, NY, US; IBM Watson Multimodal, NY, US","2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","19 Jun 2017","2017","","","5190","5194","Neural Network (NN) based acoustic frontends, such as denoising autoencoders, are actively being investigated to improve the robustness of NN based acoustic models to various noise conditions. In recent work the joint training of such frontends with backend NNs has been shown to significantly improve speech recognition performance. In this paper, we propose an effective algorithm to jointly train such a denoising feature space transform and a NN based acoustic model with various kinds of data. Our proposed method first pretrains a Convolutional Neural Network (CNN) based denoising frontend and then jointly trains this frontend with a NN backend acoustic model. In the unsupervised pretraining stage, the frontend is designed to estimate clean log Mel-filterbank features from noisy log-power spectral input features. A subsequent multi-stage training of the proposed frontend, with the dropout technique applied only at the joint layer between the frontend and backend NNs, leads to significant improvements in the overall performance. On the Aurora-4 task, our proposed system achieves an average WER of 9.98%. This is a 9.0% relative improvement over one of the best reported speaker independent baseline system's performance. A final semi-supervised adaptation of the frontend NN, similar to feature space adaptation, reduces the average WER to 7.39%, a further relative WER improvement of 25%.","2379-190X","978-1-5090-4117-6","10.1109/ICASSP.2017.7953146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7953146","Speech recognition;neural network;CNN;joint training;denoising autoencoder","Training;Artificial neural networks;Noise reduction;Transforms;Feature extraction","channel bank filters;feedforward neural nets;learning (artificial intelligence);signal denoising;speech recognition;transforms","effective joint training;denoising feature space transforms;neural network based acoustic models;NN;denoising autoencoders;speech recognition performance;denoising feature space transform;convolutional neural network based denoising frontend;CNN;unsupervised pretraining stage;clean log Mel-filterbank features;Aurora-4 task;WER;speaker independent baseline system performance;semisupervised adaptation;average WER","","","","38","","19 Jun 2017","","","IEEE","IEEE Conferences"
"Autoencoder Combined with CBAM Improves Denoising of MR Images","T. Lu; T. Li; D. Wu; X. Li","College of Information Engineering, China Jiliang University, Hangzhou, China; College of Information Engineering, China Jiliang University, Hangzhou, China; College of Information Engineering, China Jiliang University, Hangzhou, China; College of Information Engineering, China Jiliang University, Hangzhou, China","2021 11th International Conference on Information Technology in Medicine and Education (ITME)","15 Apr 2022","2021","","","209","213","Magnetic resonance imaging (MRI) is a useful technique for clinical diagnostics. However, MRI requires relatively long data acquisition, and the image quality can be deteriorated by physiological and thermal noises. Denoising is an important post-processing step for MRI, particularly when quantitative measurements are involved. Traditional denoising algorithms are mostly based on various spatial filtering. In recent years, CNN based algorithms have been explored for denoising of MRI magnitude images. In this study, we take one step forward by combining RDN with CBAM to construct a more robust framework for denoising of MR images. We trained the model with simulated MRI data with known “ground truth”. To illustrate the effectiveness of the model, we compared the performance of the model with other two state-of-the-art baseline frameworks.","2474-3828","978-1-6654-0679-6","10.1109/ITME53901.2021.00050","China Scholarship Council, Zhejiang Natural Science Foundation of China(grant numbers:LY18E070005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9750433","MRI;denoising;residual dense block;CBAM;attention mechanism","Image quality;Filtering;Magnetic resonance imaging;Noise reduction;Education;Rician channels;Thermal noise","biomedical MRI;data acquisition;image denoising;medical image processing","CNN based algorithms;MRI magnitude images;MR images;simulated MRI data;autoencoder combined;CBAM improves denoising;magnetic resonance imaging;clinical diagnostics;relatively long data acquisition;image quality;physiological noises;thermal noises;important post-processing step;quantitative measurements;traditional denoising algorithms;spatial filtering","","","","13","IEEE","15 Apr 2022","","","IEEE","IEEE Conferences"
"Deep Learning Based Retinal OCT Image Denoising using Generative Adversarial Network","M. J. Hasan; M. S. Alom; U. Fatema; M. F. Wahid","Dept. of Electrical and Electronic Engineering, Hajee Mohammad Danesh Science and Technology University, Dinajpur, Bangladesh; Dept. of Electrical and Electronic Engineering, Hajee Mohammad Danesh Science and Technology University, Dinajpur, Bangladesh; Dept. of Electrical and Electronic Engineering, Hajee Mohammad Danesh Science and Technology University, Dinajpur, Bangladesh; Dept. of Electrical and Electronic Engineering, Hajee Mohammad Danesh Science and Technology University, Dinajpur, Bangladesh","2021 International Conference on Automation, Control and Mechatronics for Industry 4.0 (ACMI)","8 Sep 2021","2021","","","1","6","Optical Coherence Tomography (OCT) is the mostly used imaging modality for detecting retinal diseases. But, the presence of multiplicative granular type speckle noise in the OCT image makes it difficult to accurately identify the retinal disorders. This paper presents, a computer vision and deep learning based OCT image denoising technique using Generative Adversarial Network (GAN) that contains a generator and a discriminator. The generator generates denoised image form noisy input image and the discriminator acts as a classifier whether the image is real or denoised image. Furthermore, an improved loss function has been added to train the GAN network. Through this adversarial training process, weight of the generator gets updated and produces denoised image with much similar as ground-truth image. A UNet shaped Res-Autoencoder and a CNN model is used as generator and discriminator respectively. To evaluate the proposed system, the peak signal-to-noise ratio (PSNR) and mean-square error (MSE) were used as evaluation matrices. In addition to that, the denoising performance of the proposed model was compared with some traditional image denoising techniques such as Wavelet-transform, Bilateral, Non-local Means (NLM) and BM3D. The evaluation matrices validate the supremacy of the acclaimed model on the OCT image.","","978-1-6654-3843-8","10.1109/ACMI53878.2021.9528116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9528116","Speckle noise;OCT image denoising;generative adversarial network;U-Net Autoencoder;densely connected convolutional neural network;PSNR;MSE;BM3D","Deep learning;Training;PSNR;Noise reduction;Speckle;Generative adversarial networks;Retina","biomedical optical imaging;diseases;eye;image denoising;learning (artificial intelligence);mean square error methods;medical image processing;optical tomography;speckle;wavelet transforms","Generative Adversarial Network;image form noisy input image;denoised image;GAN network;adversarial training process;ground-truth image;denoising performance;traditional image denoising techniques;retinal OCT image denoising;Optical Coherence Tomography;imaging modality;retinal diseases;multiplicative granular type speckle noise;retinal disorders;deep learning;OCT image denoising technique","","","","26","","8 Sep 2021","","","IEEE","IEEE Conferences"
"Automatic Arrival Time Detection for Earthquakes Based on Stacked Denoising Autoencoder","O. M. Saad; K. Inoue; A. Shalaby; L. Samy; M. S. Sayed","National Research Institute of Astronomy and Geophysics, Helwan, Egypt; Department of I&E Visionaries, Kyushu University, Fukuoka, Japan; Department of Computer Science, Benha University, Benha, Egypt; National Research Institute of Astronomy and Geophysics, Helwan, Egypt; Department of Electronics and Communications Engineering, Zagazig University, Zagazig, Egypt","IEEE Geoscience and Remote Sensing Letters","2 Nov 2018","2018","15","11","1687","1691","The accurate detection of P-wave arrival time is imperative for determining the hypocenter location of an earthquake. However, precise detection of onset time becomes more difficult when the signal-to-noise ratio (SNR) of the seismic data is low, such as during microearthquakes. In this letter, a stacked denoising autoencoder (SDAE) is proposed to smooth the background noise. The SDAE acts as a denoising filter for the seismic data. In the proposed algorithm, the SDAE is utilized to reduce background noise such that the onset time becomes more clear and sharp. Afterward, a hard decision with one threshold is used to detect the onset time of the event. The proposed algorithm is evaluated on both synthetic and field seismic data. As a result, the proposed algorithm outperforms the short-time average/long-time average and the Akaike information criterion algorithms. The proposed algorithm accurately picks the onset time of 94.1% for 407 field seismic waveforms with a standard deviation error of 0.10 s. In addition, the results indicate that the proposed algorithm can pick arrival times accurately for weak SNR seismic data with SNR higher than -14 dB.","1558-0571","","10.1109/LGRS.2018.2861218","Egypt-Japan University of Science and Technology; Egyptian Ministry of Higher Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8437146","Deep learning;P-wave arrival time of earthquakes;stacked denoising autoencoder (SDAE)","Noise measurement;Feature extraction;Machine learning;Decoding;Earthquakes;Noise reduction;Signal to noise ratio","earthquakes;geophysical techniques;seismic waves;seismology","automatic arrival time detection;earthquake;stacked denoising autoencoder;accurate detection;P-wave arrival time;precise detection;onset time;signal-to-noise ratio;SDAE;background noise;denoising filter;synthetic field seismic data;short-time average/long-time average;Akaike information criterion algorithms;weak SNR seismic data;seismic waveforms;hypocenter location;time 0.1 s;noise figure -14.0 dB","","18","","17","IEEE","15 Aug 2018","","","IEEE","IEEE Journals"
"Attractor Manipulation in Denoising Autoencoders for Robust Phone Recognition","S. Reza; S. A. Seyyedsalehi; S. Z. Seyyedsalehi","Biomedical Engineering Faculty, Amirkabir University of Technology, Tehran, Iran; Biomedical Engineering Faculty, Amirkabir University of Technology, Tehran, Iran; Department of Biomedical Engineering, Faculty of Health, Tehran Medical sciences, Islamic Azad university, Tehran, Iran","2021 29th Iranian Conference on Electrical Engineering (ICEE)","4 Oct 2021","2021","","","454","459","Autoencoder Neural Networks can filter unwanted variabilities; however, their performance will degrade if their attractors and their basins of attraction are not correctly adjusted. This paper proposes a heuristic method to increase attractors shaped in desired points and expand their basins of attraction. These well-formed attractors can compensate variabilities and hence increase the chance of robust recognition. This method's effectiveness is shown on synthetic data and is compared with another attractor manipulation method called the cyclic method. This method's performance on the phone recognition task has shown 22.1 percent relative increase in the number of attractors and 4.2 percent relative improvement in the phone error rate on the Farsdat database.","2642-9527","978-1-6654-3365-5","10.1109/ICEE52715.2021.9543707","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9543707","deep neural networks;denoising autoencoders;attractors;acoustic landmarks;robust recognition;phone recognition","Electrical engineering;Shape;Error analysis;Databases;Noise reduction;Neural networks;Acoustics","feature extraction;image denoising;neural nets","desired points;well-formed attractors;robust recognition;synthetic data;attractor manipulation method;cyclic method;phone recognition task;phone error rate;autoencoders;robust phone recognition;Autoencoder Neural Networks;unwanted variabilities;heuristic method;efficiency 22.1 percent;efficiency 4.2 percent","","","","22","IEEE","4 Oct 2021","","","IEEE","IEEE Conferences"
"Deep fraud. A fraud intention recognition framework in public transport context using a deep-learning approach","J. L. L. Herrera; H. V. R. Figueroa; E. J. R. Ramírez","Universidad Veracruzana, Xalapa, Veracruz, MX; Universidad Veracruzana, Xalapa, Veracruz, MX; Universidad Veracruzana, Xalapa, Veracruz, MX","2018 International Conference on Electronics, Communications and Computers (CONIELECOMP)","29 Mar 2018","2018","","","118","125","In this paper, we present a framework for fraud intention recognition of public transport bus operators based on a deep learning approach using a stack of denoising and sparse autoencoders. Bus operator's fraud is a common problem in passenger transport organizations with cash payment method and tickets as proof of passenger on board. Fraud detection could be considered as an anomaly detection problem, and several techniques in this area have been applied to it. Our approach is an architecture based on a sort of Stacked Autoencoders with a Softmax Classification Layer and a normalization pre-phase using word2vec and a Denoising Autoencoder. This framework permits to recognize the fraud intention in the operators delivers account time, based on date, route, count of passengers on board, among other features. In this framework, the fraud intention is modeled as a binary classification problem, there is fraud intention, or there isn't. We compare our approach with another nondeep state of the art classification approaches like Logistic Regression, SVM, Decision Trees, KNN and Adaboost ensemble method, obtaining a superior performance on intention recognition, with an accuracy of 87.3 percent and an F1 score of 0.752.","2474-9044","978-1-5386-2363-3","10.1109/CONIELECOMP.2018.8327186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8327186","fraud detection;public transport;deep learning;stacked autoencoders;sparse autoencoder;denoising autoencoder","Machine learning;Training;Neurons;Biological neural networks;Noise reduction;Organizations","decision trees;fraud;learning (artificial intelligence);pattern classification;public transport;regression analysis;security of data;support vector machines;traffic engineering computing","Denoising Autoencoder;binary classification problem;deep fraud;public transport context;deep-learning approach;public transport bus operators;deep learning approach;denoising autoencoders;sparse autoencoders;bus operator;passenger transport organizations;fraud detection;anomaly detection problem;Stacked Autoencoders;fraud intention recognition;word2vec;word2vec","","3","","25","","29 Mar 2018","","","IEEE","IEEE Conferences"
"Hyperspectral X-ray Denoising: Model-Based and Data-Driven Solutions","N. Bonettini; M. Paracchini; P. Bestagini; M. Marcon; S. Tubaro","Dipartimento di Elettronica, Politecnico di Milano, Piazza Leonardo da Vinci 32, Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Piazza Leonardo da Vinci 32, Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Piazza Leonardo da Vinci 32, Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Piazza Leonardo da Vinci 32, Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Piazza Leonardo da Vinci 32, Milano, Italy","2019 27th European Signal Processing Conference (EUSIPCO)","18 Nov 2019","2019","","","1","5","In this paper we deal with the problem of hyperspectral X-Ray image denoising. In particular, we compare a classical model-based Wiener filter solution with a datadriven methodology based on a Convolutional Autoencoder. A challenging aspect is related to the specific kind of 2D signal we are processing: it presents mixed dimensions information since on the vertical axis there is the pixels position while, on the abscissa, there are the different wavelengths associated to the acquired X-Ray spectrum. The goal is to approximate the denoising function using a learning-from-data approach and to verify its capability to emulate the Wiener filter using a much less demanding approach in terms of signal and noise statistical knowledge. We show that, after training, the CNN is able to properly restore the 2D signal with results very close to the Wiener filter, honouring the proper signal shape.","2076-1465","978-9-0827-9703-9","10.23919/EUSIPCO.2019.8903151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903151","Hyperspectral Imaging;Image Denoising;Convolutional Autoencoder;Machine Vision","Convolution;Two dimensional displays;Noise reduction;Hyperspectral imaging;X-ray imaging;Image denoising;Shape","image denoising;learning (artificial intelligence);statistical analysis;Wiener filters","data-driven solutions;convolutional autoencoder;pixels position;learning-from-data approach;noise statistical knowledge;hyperspectral X-ray image denoising;model-based Wiener filter solution","","3","","15","","18 Nov 2019","","","IEEE","IEEE Conferences"
"Denoising of Over-the-Horizon Propagation Loss Based on 1D Convolutional Autoencoder","J. Wu; Z. Wei; D. Jia; J. Zhang; B. Yin; H. Ji","National key laboratory of electromagnetic environment, Chinese Research Institute of Radiowave Propagation, Qingdao, China; School of Information Science and Engineering, Ocean University of China, Qingdao, China; School of Information Science and Engineering, Ocean University of China, Qingdao, China; National key laboratory of electromagnetic environment, Chinese Research Institute of Radiowave Propagation, Qingdao, China; School of Information Science and Engineering, Ocean University of China, Qingdao, China; National key laboratory of electromagnetic environment, Chinese Research Institute of Radiowave Propagation, Qingdao, China","2022 IEEE 10th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)","3 Aug 2022","2022","10","","965","968","Over-the-horizon radar systems have attracted widespread attention because they target at resolving the challenges of marine communication over long distance and weakened signals. However, these systems are limited by signal noise. To address this issue, we construct a denoising model based on a one-dimensional convolutional autoencoder (1DCAE) to improve the quality of the input data. Experiments show that the root mean square and mean absolute errors of the proposed 1DCAE are dramatically reduced, compared with those of the model without using the 1DCAE filter. Our proposed 1DCAE deep learning framework outperforms the other state-of-the-art techniques in terms of over-the-horizon propagation loss signal noise.","2693-2865","978-1-6654-2207-9","10.1109/ITAIC54216.2022.9836669","National Natural Science Foundation of China(grant numbers:61801446); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9836669","Over-the-horizon;radar systems;one-dimensional convolutional autoencoder;marine communication","Convolution;Noise reduction;Poles and towers;Radar;Propagation losses;Information filters;Noise measurement","convolutional neural nets;filtering theory;learning (artificial intelligence);marine communication;signal denoising","mean absolute errors;1DCAE filter;1DCAE deep learning framework;over-the-horizon propagation loss signal noise;1d convolutional autoencoder;over-the-horizon radar systems;marine communication;weakened signals;denoising model;one-dimensional convolutional autoencoder","","","","15","IEEE","3 Aug 2022","","","IEEE","IEEE Conferences"
"A Joint Framework of Denoising Autoencoder and Generative Vocoder for Monaural Speech Enhancement","Z. Du; X. Zhang; J. Han","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Department of Computer Science, Inner Mongolia University, Hohhot, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China","IEEE/ACM Transactions on Audio, Speech, and Language Processing","1 Jun 2020","2020","28","","1493","1505","Conventional monaural speech enhancement methods usually enhance the magnitude spectrum of noisy speech and leave the phase unchanged. Recent studies suggest that phase is also important for both speech intelligibility and perceptual quality. Although deep learning exhibits great potential on enhancing the magnitude and phase spectra in complex spectrogram domain and waveform domain, complex spectrogram and waveform are always more difficult to predict than the magnitude spectrum due to lack of clear structure in them. In this study, a Mel-domain denoising autoencoder and a deep generative vocoder are stacked to form a joint framework for monaural speech enhancement, in which the clean speech waveform is reconstructed without using the phase. Specifically, a convolutional recurrent network (CRN) is employed as the denoising autoencoder to enhance the Mel power spectrum of noisy speech. Then, the enhanced Mel power spectrum is fed to a deep generative vocoder to synthesize the speech waveform. Furthermore, the denoising autoencoder and generative vocoder are jointly fine-tuned. Experimental results show that the proposed method significantly improves speech intelligibility and perceptual quality. More importantly, our method achieves much better generalization ability for untrained noises than previous methods.","2329-9304","","10.1109/TASLP.2020.2991537","National Natural Science Foundation of China(grant numbers:U1736210); National Basic Research Program of China (973 Program)(grant numbers:2017YFB1002102); National Natural Science Foundation of China(grant numbers:61876214); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9082858","Monaural speech enhancement;joint framework;denoising autoencoder;generative vocoder","Speech enhancement;Vocoders;Noise measurement;Noise reduction;Spectrogram;Couplings","convolutional neural nets;recurrent neural nets;speech coding;speech enhancement;speech intelligibility;vocoders","CRN;convolutional recurrent network;speech waveform domain;complex spectrogram domain;deep learning;magnitude spectrum;perceptual quality;speech intelligibility;enhanced Mel power spectrum;monaural speech enhancement;deep generative vocoder;Mel-domain denoising autoencoder","","2","","42","IEEE","30 Apr 2020","","","IEEE","IEEE Journals"
"Reconstructing the Medical Image by Autoencoder with Stochastic Processing in Neural Network","V. S. Kumar; V. Jayalakshmi","Department of Computer Science, Vels Institute of Science Technology and Advanced Studies, Chennai, India; Department of Computer Applications, Vels Institute of Science Technology and Advanced Studies, Chennai, India","2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA)","1 Oct 2021","2021","","","1521","1526","The working on image to perform different operation is known as image processing. Digital Image is a collection of a defined number of pixels. Each feature has a particular pixel value at a specific position. Image restoration can be considered as an image enrichment where the final image is printed with more important features that create more appealing for the spectator but it is not essential to create genuine data from the point of a scientific vision. Autoencoder is one of the techniques in artificial neural network to analyze and predict a huge volume of data with different many features. This technique has three stages namely the first one is encoding, second one is compression and third one is decoding. Denoising autoencoder is an enhanced technique for image processing to reconstruct the damaged image to original image. Denoising autoencoder techniques are applying on the medical image to get the high quality image in digital image processing. In this paper, stochastic gradient descent algorithm is applied to predict the damaged pixel and replaced by new pixel values. The result is better than previous result in medical images.","","978-1-6654-3877-3","10.1109/ICIRCA51532.2021.9545041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9545041","Medical Image;Restoration;Artificial Neural Network;Deep Neural Network;Autoencoder;Denoising","Image coding;Digital images;Noise reduction;Artificial neural networks;Prediction algorithms;Image restoration;Decoding","gradient methods;image denoising;image processing;image restoration;medical image processing;neural nets;stochastic processes","high quality image;autoencoder techniques;damaged image;denoising autoencoder;different many features;artificial neural network;image enrichment;Image restoration;particular pixel value;stochastic processing;medical image;pixel values;digital image processing","","","","21","IEEE","1 Oct 2021","","","IEEE","IEEE Conferences"
"The Denoise and Reconstruction Method for Radar HRRP Using Enhanced Sparse Auto-Encoder","C. Guo; C. Xu; S. Sun; X. Zhang","Institute of Information Fusion, Naval Aviation University, Yantai, China; Institute of Information Fusion, Naval Aviation University, Yantai, China; Institute of Information Fusion, Naval Aviation University, Yantai, China; Institute of Information Fusion, Naval Aviation University, Yantai, China","2019 IEEE International Conference on Signal, Information and Data Processing (ICSIDP)","21 Aug 2020","2019","","","1","4","The HRRP is a summation vector of sub-echoes of the target scattering points acquired by the wide-band radar. Generally, the HRRP obtained under the non-cooperative complex electromagnetic environment is contaminated by strong noise, which result in a significant reduction in recognition accuracy. Effective pre-processing of the HRRP can solve the above problem. A denoise and reconstruction method for HRRP is proposed based on Enhanced Sparse Auto-Encoder. Auto-Encoder is a representative non-linear model. To better sparse reconstruct the HRRP, an enhanced sparsity term is proposed in the objective function and the sparse coefficient is computed according to the intrinsic dimension of HRRP. Simulation results show that the proposed method can both reconstruct the signal and suppress noise effectively, which significantly outperforms comparison methods, especially at low SNR conditions.","","978-1-7281-2345-5","10.1109/ICSIDP47821.2019.9173369","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9173369","HRRP;Signal Reconstruction;Signal denoise;Enhanced Sparse Auto-Encoder","","neural nets;radar cross-sections;radar resolution;signal denoising;signal reconstruction","radar HRRP;wide-band radar;noncooperative complex electromagnetic environment;enhanced sparse autoencoder;subecho summation vector;target scattering points;HRRP denoise method;HRRP reconstruction method;sparse reconstruction;sparsity term;sparse coefficient;signal reconstruction;noise suppression","","","","9","","21 Aug 2020","","","IEEE","IEEE Conferences"
"Fault Diagnosis of High-Voltage Circuit Breakers Using Hilbert-Huang Transform and Denoising-Stacked Autoencoder","W. Yang; G. Zhang; D. Song; M. Cai; H. Zhao; J. Yan","State Grid Anhui Electric Power Company Limited, Research Institute, Hefei, P.R.China; State Grid Anhui Electric Power Company Limited, Research Institute, Hefei, P.R.China; State Grid Anhui Electric Power Company Limited, Research Institute, Hefei, P.R.China; State Grid Anhui Electric Power Company Limited, Research Institute, Hefei, P.R.China; State Grid Anhui Electric Power Company Limited, Research Institute, Hefei, P.R.China; State Key Lab of Electrical Insulation and Power Equipment, Xi’an Jiaotong University, Xi’an, P.R.China","2019 4th International Conference on Power and Renewable Energy (ICPRE)","16 Mar 2020","2019","","","228","232","As the main protection and control equipment of the power system, the high-voltage circuit breaker are required to be disconnected instantaneously within a few milliseconds. Once it fails, it will seriously threaten the safety of the power grid. In this paper, a new high-voltage circuit breaker fault diagnosis algorithm based on denoising-stacked autoencoder is proposed. Firstly, the acceleration sensor is used to collect the vibration signal of the high voltage circuit breaker. The high voltage circuit breaker fault signal data are collected during equipment failure in the laboratory simulation experiment and site field operation. This non-stationary random vibration signal is then denoised and processed using the Hilbert-Huang transform. Since the on-site vibration signal is derived from data from different voltage levels and equipment manufacturers, it is necessary to clean the data firstly. Finally, the denoising-stacked autoencoder is used to perform automatic feature extraction and pattern recognition classification on the preprocessed data. Automatic feature extraction reduces the dependence of traditional artificial feature engineering on expert knowledge as much as possible, and makes full use of fault features, thus improving the accuracy of diagnosis and the generalization ability of the model.","","978-1-7281-4574-7","10.1109/ICPRE48497.2019.9034783","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9034783","denoising-stacked autoencoder;high-voltage circuit breaker;fault diagnosis;Hilbert-Huang transform","Circuit breakers;Circuit faults;Vibrations;Feature extraction;Transforms;High-voltage techniques;Fault diagnosis","circuit breakers;fault diagnosis;feature extraction;Hilbert transforms;pattern recognition;power engineering computing;power grids;power system faults;vibrations","high-voltage circuit breaker fault diagnosis algorithm;denoising-stacked autoencoder;high voltage circuit breaker fault signal data;nonstationary random vibration signal;Hilbert-Huang transform;acceleration sensor;automatic feature extraction;pattern recognition classification","","","","18","","16 Mar 2020","","","IEEE","IEEE Conferences"
"Post-DAE: Anatomically Plausible Segmentation via Post-Processing With Denoising Autoencoders","A. J. Larrazabal; C. Martínez; B. Glocker; E. Ferrante","Institute for Signals, Systems, and Computational Intelligence, sinc(i), CONICET, Universidad Nacional del Litoral (UNL), Santa Fe, Argentina; Institute for Signals, Systems, and Computational Intelligence, sinc(i), CONICET, Universidad Nacional del Litoral (UNL), Santa Fe, Argentina; Biomedical Image AnalysisGroup, Imperial College London, London, U.K.; Institute for Signals, Systems, and Computational Intelligence, sinc(i), CONICET, Universidad Nacional del Litoral (UNL), Santa Fe, Argentina","IEEE Transactions on Medical Imaging","30 Nov 2020","2020","39","12","3813","3820","We introduce Post-DAE, a post-processing method based on denoising autoencoders (DAE) to improve the anatomical plausibility of arbitrary biomedical image segmentation algorithms. Some of the most popular segmentation methods (e.g. based on convolutional neural networks or random forest classifiers) incorporate additional post-processing steps to ensure that the resulting masks fulfill expected connectivity constraints. These methods operate under the hypothesis that contiguous pixels with similar aspect should belong to the same class. Even if valid in general, this assumption does not consider more complex priors like topological restrictions or convexity, which cannot be easily incorporated into these methods. Post-DAE leverages the latest developments in manifold learning via denoising autoencoders. First, we learn a compact and non-linear embedding that represents the space of anatomically plausible segmentations. Then, given a segmentation mask obtained with an arbitrary method, we reconstruct its anatomically plausible version by projecting it onto the learnt manifold. The proposed method is trained using unpaired segmentation mask, what makes it independent of intensity information and image modality. We performed experiments in binary and multi-label segmentation of chest X-ray and cardiac magnetic resonance images. We show how erroneous and noisy segmentation masks can be improved using Post-DAE. With almost no additional computation cost, our method brings erroneous segmentations back to a feasible space.","1558-254X","","10.1109/TMI.2020.3005297","Universidad Nacional del Litoral (UNL)(grant numbers:CAID-PIC-50420150100098LI,CAID-PIC-50220140100084LI); Agencia Nacional de Promoción de la Investigación, el Desarrollo Tecnológico y la Innovación (ANPyCT)(grant numbers:PICT 2016-0651,PICT 2018-03907); AXA Research Fund through a grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9126830","Anatomical segmentation;autoencoders;convolutional neural networks;learning representations;post-processing","Image segmentation;Shape;Noise reduction;Biomedical imaging;Topology;Manifolds;X-ray imaging","biomedical MRI;convolutional neural nets;diagnostic radiography;image denoising;image segmentation;learning (artificial intelligence);medical image processing","binary segmentation;cardiac magnetic resonance images;chest X-ray images;manifold learning;contiguous pixel;convolutional neural networks;random forest classifier;noisy segmentation masks;multilabel segmentation;unpaired segmentation mask;arbitrary biomedical image segmentation algorithms;anatomical plausibility;denoising autoencoders;anatomically plausible segmentation;Post-DAE","Algorithms;Brain;Image Processing, Computer-Assisted;Magnetic Resonance Imaging;Neural Networks, Computer","14","","35","IEEE","26 Jun 2020","","","IEEE","IEEE Journals"
"An Unsupervised Feature Extraction Method based on Multi-granularity Convolution Denoising Autoencoder","L. Cao; Q. Liu; Y. Yang","School of Software, Yunnan University, Kunming, China; School of Software, Yunnan University, Kunming, China; School of Software, Yunnan University, Kunming, China","2019 IEEE/ACIS 18th International Conference on Computer and Information Science (ICIS)","27 Dec 2019","2019","","","118","123","In recent years, many cutting-edge research results have emerged in the field of computer vision, especially in the field of image classification. But, researchers are still trying to explore more sophisticated models to further improve the accuracy of image classification. However, many models have failed to achieve satisfactory results due to the complexity of the image and the problems of image noise. Therefore, in order to solve these problems, this paper proposes an unsupervised feature extraction method called multi-granularity convolution denoising autoencoder (MGCDAE). Based on convolutional neural network, the method proposed the concept of multi-granularity convolution kernel to solve the problem of complex image feature extraction. In addition, we introduce denoising autoencoder (DAE) for image noise, which enables our approach to extract more robust features from noise images. The high-level features extracted by the above method are sent to the softmax classifier for classification to evaluate the validity of the feature extraction. Our method has been evaluated on three benchmark data sets, which results show that our approach can extract more discriminative high-level features compared with other existing algorithms.","","978-1-7281-0801-8","10.1109/ICIS46139.2019.8940316","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8940316","unsupervised learning;feature extraction;autoencoder;convolutional neural network;softmax classifier","Feature extraction;Convolution;Classification algorithms;Kernel;Training;Decoding;Data mining","computer vision;convolutional neural nets;feature extraction;image classification;image coding;image denoising","unsupervised feature extraction method;multigranularity convolution denoising autoencoder;image classification;image noise;convolutional neural network;multigranularity convolution kernel;complex image feature extraction;computer vision;softmax classifier","","","","35","","27 Dec 2019","","","IEEE","IEEE Conferences"
"Denoised Senone I-Vectors for Robust Speaker Verification","Z. Tan; M. -W. Mak; B. K. -W. Mak; Y. Zhu","Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong; Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong; Department of Computer Science, The Hong Kong University of Science and Technology, Hong Kong; Department of Computer Science, The Hong Kong University of Science and Technology, Hong Kong","IEEE/ACM Transactions on Audio, Speech, and Language Processing","9 Feb 2018","2018","26","4","820","830","Recently, it has been shown that senone i-vectors, whose posteriors are produced by senone deep neural networks (DNNs), outperform the conventional Gaussian mixture model (GMM) i-vectors in both speaker and language recognition tasks. The success of senone i-vectors relies on the capability of the DNN to incorporate phonetic information into the i-vector extraction process. In this paper, we argue that to apply senone i-vectors in noisy environments, it is important to robustify the phonetically discriminative acoustic features and senone posteriors estimated by the DNN. To this end, we propose a deep architecture formed by stacking a deep belief network on top of a denoising autoencoder (DAE). After backpropagation fine-tuning, the network, referred to as denoising autoencoder-deep neural network (DAE-DNN), facilitates the extraction of robust phonetically-discriminitive bottleneck (BN) features and senone posteriors for i-vector extraction. We refer to the resulting i-vectors as denoised BN-based senone i-vectors. Results on NIST 2012 SRE show that senone i-vectors outperform the conventional GMM i-vectors. More interestingly, the BN features are not only phonetically discriminative, results suggest that they also contain sufficient speaker information to produce BN-based senone i-vectors that outperform the conventional senone i-vectors. This work also shows that DAE training is more beneficial to BN feature extraction than senone posterior estimation.","2329-9304","","10.1109/TASLP.2018.2796843","The RGC of Hong Kong SAR(grant numbers:PolyU 152518/16E,PolyU 152068/15E); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8269399","Speaker verification;i-vectors;phonetically discriminative features;senone posteriors;deep learning;denoising autoencoders;noise robustness","Feature extraction;Speech;Noise reduction;Training;Robustness;Noise measurement;Speaker recognition","acoustic signal processing;backpropagation;belief networks;feature extraction;neural nets;signal denoising;speaker recognition","denoised senone i-vectors;senone deep neural networks;i-vector extraction process;phonetically discriminative acoustic features;senone posterior estimation;noisy environments;deep architecture;deep belief network;denoising autoencoder;backpropagation fine-tuning;Speaker Verification","","8","","49","IEEE","25 Jan 2018","","","IEEE","IEEE Journals"
"Two-stage noise aware training using asymmetric deep denoising autoencoder","K. H. Lee; S. J. Kang; W. H. Kang; N. S. Kim","Department of Electrical and Computer Engineering and INMC, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and INMC, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and INMC, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and INMC, Seoul National University, Seoul, Korea","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","19 May 2016","2016","","","5765","5769","Ever since the deep neural network (DNN)-based acoustic model appeared, the recognition performance of automatic speech recognition has been greatly improved. Due to this achievement, various researches on DNN-based technique for noise robustness are also in progress. Among these approaches, the noise-aware training (NAT) technique which aims to improve the inherent robustness of DNN using noise estimates has shown remarkable performance. However, despite the great performance, we cannot be certain whether NAT is an optimal method for sufficiently utilizing the inherent robustness of DNN. In this paper, we propose a novel technique which helps the DNN to address the complex connection between the input and target vectors of NAT smoothly. The proposed method outperformed the conventional NAT in Aurora-5 task.","2379-190X","978-1-4799-9988-0","10.1109/ICASSP.2016.7472782","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472782","Deep neural networks (DNNs);robust speech recognition;noise aware training (NAT);denoising autoencoder","Hidden Markov models;Training;Speech;Noise measurement;Feature extraction;Robustness;Speech recognition","acoustic signal processing;neural nets;signal denoising;speech recognition","Aurora-5 task;automatic speech recognition;acoustic model;DNN;deep neural network;asymmetric deep denoising autoencoder;NAT technique;noise aware training technique","","11","","21","","19 May 2016","","","IEEE","IEEE Conferences"
"A novel denoising autoencoder assisted segmentation algorithm for cotton field","Yanan Li; Z. Cao; Y. Xiao; Hao Lu; Yanjun Zhu","School of Automation, Huazhong University of Science and Technology, Wuhan, PR China; School of Automation, Huazhong University of Science and Technology, Wuhan, PR China; School of Automation, Huazhong University of Science and Technology, Wuhan, PR China; School of Automation, Huazhong University of Science and Technology, Wuhan, PR China; School of Automation, Huazhong University of Science and Technology, Wuhan, PR China","2015 Chinese Automation Congress (CAC)","18 Jan 2016","2015","","","588","593","Crop segmentation from the images captured in the outdoor field is a complex task in agriculture automation, let alone detecting some specific crops with one method. Cotton, as one of the four major economic crops, is of great significance to the development of the national economy. In this paper, a novel strategy based on the deep learning is utilized to establish the crop classifier in the RGB vector color space in order to realize the specific crop image segmentation. To the best of our knowledge, little research has been done to crop segmentation in the wild cotton field with digital cameras. To verify the performance of the proposed method, two specific crops (cotton plants and raw cotton) grown in the cotton field are demonstrated in this paper. Experiment results show that our method outperforms other state-of-art algorithms on cotton plants (raw cotton) segmentation in yielding the highest performance with the lowest mean square deviation. Moreover, the impact of different color spaces to the proposed method is compared. The proposed crop segmentation method can not only be used to green crop segmentation in the field, but segment specific crop like cotton.","","978-1-4673-7189-6","10.1109/CAC.2015.7382568","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7382568","specific crop segmentation;denoising autoencoder;cotton","Cotton;Image segmentation;Image color analysis;Noise reduction;Training;Green products","agricultural engineering;crops;image capture;image denoising;image segmentation;inspection;mean square error methods","cotton field;image capture;crop classifier;RGB vector color space;crop image segmentation;lowest mean square deviation;denoising autoencoder","","1","","18","","18 Jan 2016","","","IEEE","IEEE Conferences"
"Music removal by convolutional denoising autoencoder in speech recognition","M. Zhao; D. Wang; Z. Zhang; X. Zhang","Center for Speech and Language Technology (CSLT), Tsinghua National Lab for Information Science and Technology; Center for Speech and Language Technology (CSLT), Tsinghua National Lab for Information Science and Technology; Center for Speech and Language Technology (CSLT), Tsinghua National Lab for Information Science and Technology; Center for Speech and Language Technology (CSLT), Tsinghua National Lab for Information Science and Technology","2015 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)","25 Feb 2016","2015","","","338","341","Music embedding often causes significant performance degradation in automatic speech recognition (ASR). This paper proposes a music-removal method based on denoising autoencoder (DAE) that learns and removes music from music-embedded speech signals. Particularly, we focus on convolutional denoising autoencoder (CDAE) that can learn local musical patterns by convolutional feature extraction. Our study shows that the CDAE model can learn patterns of music in different genres and the CDAE-based music removal offers significant performance improvement for ASR. Additionally, we demonstrate that this music-removal approach is largely language independent, which means that a model trained with data in one language can be applied to remove music from speech in another language, and models trained with multilingual data may lead to better performance.","","978-9-8814-7680-7","10.1109/APSIPA.2015.7415289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7415289","speech recognition;music removal;noisy training;denoising autoencoder","Multiple signal classification;Speech;Training;Convolution;Speech recognition;Data models;Harmonic analysis","encoding;music;speech recognition","convolutional denoising autoencoder;music embedding;performance degradation;automatic speech recognition;ASR;music-removal method;CDAE;local musical patterns;convolutional feature extraction;multilingual data","","14","","20","","25 Feb 2016","","","IEEE","IEEE Conferences"
"Reconstruction of Power System Measurements Based on Enhanced Denoising Autoencoder","Y. Lin; J. Wang; M. Cui","Department of Electrical Engineering, Southern Methodist University, Dallas, TX, USA; Department of Electrical Engineering, Southern Methodist University, Dallas, TX, USA; Department of Electrical Engineering, Southern Methodist University, Dallas, TX, USA","2019 IEEE Power & Energy Society General Meeting (PESGM)","30 Jan 2020","2019","","","1","5","This paper presents a new solution for reconstructing missing data in power system measurements. An Enhanced Denoising Autoencoder (EDAE) is proposed to reconstruct the missing data through the input vector space reconstruction based on the neighbor values correlation and Long Short-Term Memory (LSTM) networks. The proposed LSTM-EDAE is able to remove the noise, extract principle features of the dataset, and reconstruct the missing information for new inputs. The paper shows that the utilization of neighbor correlation can perform better in missing data reconstruction. Trained with LSTM networks, the EDAE is more effective in coping with big data in power systems and obtains a better performance than the neural network in conventional Denoising Autoencoder. A random data sequence and the simulated Phasor Measurement Unit (PMU) data of power system are utilized to verify the effectiveness of the proposed LSTM-EDAE.","1944-9933","978-1-7281-1981-6","10.1109/PESGM40551.2019.8973925","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8973925","Power system measurements;data reconstruction;Enhanced Denoising Autoencoder;Long Short-Term Memory network","","Big Data;feature extraction;learning (artificial intelligence);phasor measurement;power engineering computing;recurrent neural nets;vectors","enhanced denoising autoencoder;neighbor values correlation;long short-term memory networks;LSTM-EDAE;big data;neural network;phasor measurement unit data;vector space reconstruction;power system measurement reconstruction;missing data reconstruction;dataset feature extraction;noise suppression methods","","10","","20","","30 Jan 2020","","","IEEE","IEEE Conferences"
"Stacked Denoising Extreme Learning Machine Autoencoder Based on Graph Embedding for Feature Representation","H. Ge; W. Sun; M. Zhao; Y. Yao","College of Computer Science and Technology, Dalian University of Technology, Dalian, China; College of Computer Science and Technology, Dalian University of Technology, Dalian, China; School of Computer Science, McGill University, Montreal, QC, Canada; College of Computer Science and Technology, Dalian University of Technology, Dalian, China","IEEE Access","8 Feb 2019","2019","7","","13433","13444","Extreme learning machine is characterized by less training parameters, fast training speed, and strong generalization ability. It has been applied to obtain feature representations from the complex data in the tasks of data clustering or classification. In this paper, a graph embedding-based denoising extreme learning machine autoencoder (GDELM-AE) is proposed for capturing the structure of the inputs. Specifically, in GDELM-AE, a graph embedding framework that contains an intrinsic graph and a penalty graph constructed by local Fisher discrimination analysis is integrated into the autoencoder. So, it can exploit both local structure and global structure information in extreme learning machine (ELM) spaces. Further, we propose a stacked graph embedded denoising (SGD)-ELM by stacking several GDELM-AEs. The experimental results on several benchmarks validate that GDELM-AE can obtain efficient and robust feature representation of original data; moreover, the stacked GDELM-AE can obtain high-level and noise-robust representations. The comparative results with the state-of-the-art algorithms indicate that the proposed algorithm can obtain better accuracy as well as faster training speed.","2169-3536","","10.1109/ACCESS.2019.2894014","National Natural Science Foundation of China(grant numbers:61572104,61402076,61103146); Jilin University(grant numbers:93K172017K03); Fundamental Research Funds for Central Universities(grant numbers:DUT17JC04); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8620205","Extreme learning machine;stacked autoencoder;denoising;graph embedding","Noise reduction;Training;Feature extraction;Feedforward neural networks;Manifolds;Neurons;Task analysis","feature extraction;generalisation (artificial intelligence);graph theory;learning (artificial intelligence);pattern classification;pattern clustering","local structure;global structure information;stacked graph;efficient feature representation;robust feature representation;original data;stacked GDELM-AE;noise-robust representations;stacked denoising extreme learning machine autoencoder;training parameters;complex data;data clustering;graph embedding framework;intrinsic graph;penalty graph;local Fisher discrimination analysis;training speed;generalization ability","","8","","34","OAPA","20 Jan 2019","","","IEEE","IEEE Journals"
"Dynamic Feature Acquisition Using Denoising Autoencoders","M. Kachuee; S. Darabi; B. Moatamed; M. Sarrafzadeh","Department of Computer Science, University of California at Los Angeles, Los Angeles, CA, USA; Department of Computer Science, University of California at Los Angeles, Los Angeles, CA, USA; Department of Computer Science, University of California at Los Angeles, Los Angeles, CA, USA; Department of Computer Science, University of California at Los Angeles, Los Angeles, CA, USA","IEEE Transactions on Neural Networks and Learning Systems","17 Jul 2019","2019","30","8","2252","2262","In real-world scenarios, different features have different acquisition costs at test time which necessitates cost-aware methods to optimize the cost and performance tradeoff. This paper introduces a novel and scalable approach for cost-aware feature acquisition at test time. The method incrementally asks for features based on the available context that are known feature values. The proposed method is based on sensitivity analysis in neural networks and density estimation using denoising autoencoders with binary representation layers. In the proposed architecture, a denoising autoencoder is used to handle unknown features (i.e., features that are yet to be acquired), and the sensitivity of predictions with respect to each unknown feature is used as a context-dependent measure of informativeness. We evaluated the proposed method on eight different real-world data sets as well as one synthesized data set and compared its performance with several other approaches in the literature. According to the results, the suggested method is capable of efficiently acquiring features at test time in a cost- and context-aware fashion.","2162-2388","","10.1109/TNNLS.2018.2880403","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8561258","Context aware;cost aware;denoising autoencoder;feature acquisition;test time","Feature extraction;Noise reduction;Sensitivity analysis;Mathematical model;Training;Predictive models","estimation theory;feature selection;neural nets;sensitivity analysis;ubiquitous computing","cost-aware feature acquisition;sensitivity analysis;neural networks;density estimation;binary representation layers;dynamic feature acquisition;cost-aware methods;denoising autoencoders","","7","","36","IEEE","5 Dec 2018","","","IEEE","IEEE Journals"
"Feature ensemble learning using stacked denoising autoencoders for induction motor fault diagnosis","J. Wang; C. Sun; Z. Zhao; X. Chen","State Key Laboratory for Manufacturing Systems, Xi'an Jiaotong University, Xi'an, Shaanxi, P.R. China; State Key Laboratory for Manufacturing Systems, Xi'an Jiaotong University, Xi'an, Shaanxi, P.R. China; State Key Laboratory for Manufacturing Systems, Xi'an Jiaotong University, Xi'an, Shaanxi, P.R. China; State Key Laboratory for Manufacturing Systems, Xi'an Jiaotong University, Xi'an, Shaanxi, P.R. China","2017 Prognostics and System Health Management Conference (PHM-Harbin)","23 Oct 2017","2017","","","1","6","Fault diagnosis is significant to induction motor which has been widely used as industrial power driving sources. By fault diagnosis, proper maintenance can be arranged to avoid accidents, ensure safety and reduce maintenance costs. However, variable operating conditions and background noise always reduce effectiveness of traditional fault diagnosis methods. Currently the most advanced machine learning technology, that is deep learning, not only has strong ability for hierarchical representations, but also can adaptively extract feature information from considerable measured data without necessary of much prior knowledge. Nevertheless, only the last layer is utilized for feature extraction in current deep learning models, due to its better performance of feature abstraction and compactness than that of the lower layers. Different feature layers hold different identification ability. In order to consider all features in different layers and achieve effective fault diagnosis, an alternative method of feature ensemble learning based on stacked denoising autoencoders (SDAE) is proposed in this paper. Our proposed method can be constructed in three steps: first, obtaining the samples of raw data under different health conditions. A deep neural network with multiple hidden layers is then established layer-by-layer by considering each pair of layers as a denoising autoencoder (DAE), with the strategies of greedy layer-wise pre-training and fine-tuning. Finally, softmax regression is created by the last hidden layer and integrate feature to classify different fault types. Feature ensemble is considered by mutually independent rules with different weights according to corresponding accuracy. Effectiveness of the proposed method is demonstrated though identifying health conditions of an induction motor.","2166-5656","978-1-5386-0370-3","10.1109/PHM.2017.8079196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8079196","fault diagnosis;stacked denoising autoencoder;feature ensemble learning","Fault diagnosis;Feature extraction;Induction motors;Machine learning;Noise reduction;Training;Classification algorithms","cost reduction;fault diagnosis;feature extraction;induction motors;learning (artificial intelligence);maintenance engineering;mechanical engineering computing;neural nets;pattern classification;regression analysis","feature ensemble;stacked denoising autoencoders;induction motor fault diagnosis;maintenance cost reduction;feature information extraction;identification ability;health conditions;fault type classification;feature layers;SDAE;softmax regression;greedy layer-wise pretraining;hidden layer;layer-by-layer;multiple hidden layers;deep neural network;lower layers;feature abstraction;current deep learning models;advanced machine learning technology;variable operating conditions;industrial power driving sources","","5","","15","","23 Oct 2017","","","IEEE","IEEE Conferences"
"Network Intrusion Detection Method Based on Stacked Denoising Sparse Autoencoder and Extreme Learning Machine","G. Zhang; X. Wang; R. Li; J. Lai; Q. Xiang; J. He","Air Force Engineering, University Air Defense and Antimissile Academy, Xian, China; Air Force Engineering, University Air Defense and Antimissile Academy, Xian, China; Air Force Engineering, University Air Defense and Antimissile Academy, Xian, China; Air Force Engineering, University Air Defense and Antimissile Academy, Xian, China; Air Force Engineering, University Air Defense and Antimissile Academy, Xian, China; Air Force Engineering, University Air Defense and Antimissile Academy, Xian, China","2020 2nd International Conference on Information Technology and Computer Application (ITCA)","7 May 2021","2020","","","194","199","Aiming at the problem of low detection accuracy and high false positive rate caused by noise doping in network data, and at the same time improving detection speed, a network intrusion detection based on stacked denoising sparse autoencoder and extreme learning machine (sDSAE-ELM) is proposed. First, the stacked denoising sparse autoencoder is used to automatically extract the robustness characteristics of the network data, and then the extreme learning machine is used for classification. Experiments on the NSL-KDD dataset show that the network intrusion detection method based on sDSAE-ELM has strong noise robustness when processing high-dimensional noisy data, while shortening the training time. And high detection accuracy and low false positive rate have been achieved.","","978-1-6654-0378-8","10.1109/ITCA52113.2020.00048","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9421975","cyberspace security;intrusion detection;denoising sparse autoencoder;extreme learning machine;robustness;training time;feature extraction","Training;Extreme learning machines;Network intrusion detection;Cyberspace;Doping;Robustness;Noise robustness","feedforward neural nets;pattern classification;security of data","high-dimensional noisy data;network intrusion detection;stacked denoising sparse autoencoder;extreme learning machine;low detection accuracy;high false positive rate;network data;sDSAE-ELM;noise doping;classification","","","","15","IEEE","7 May 2021","","","IEEE","IEEE Conferences"
"Stacked Denoising Autoencoders Based Poisson Regression For Count Data Modeling","X. Zhang; Y. Liu; Z. Song; Z. Zhu; C. Wei","State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, P. R. China; State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, P. R. China; State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, P. R. China; State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, P. R. China; School of Information Science and Technology, Hangzhou Normal University, Hangzhou, P. R. China","2022 IEEE 11th Data Driven Control and Learning Systems Conference (DDCLS)","26 Aug 2022","2022","","","606","611","Data-driven virtual-sensors or soft-sensors are important tools for predicting quality variables or KPIs in many industrial processes. However, the existing virtual-sensors models are generally based on the assumption that the response variable or model error structure satisfies normality and homoscedasticity. But, in many practical applications, the response variable of interest is a nonnegative integer or count that we want to model or analyze based on a set of explanatory variables. The count data usually violate these assumptions and exhibit heteroscedasticity and skewed distribution. To model and analyze count data, this paper proposes a stacked denoising autoencoders-based Poisson regression (SDAE-PR) model. In SDAE-PR, the stacked denoising autoencoders are adopted to extract the high-level feature representation of the data, and Poisson regression is then performed on this representation. Unlike the conventional Poisson regression model which use hand-crafted features to build the model, SDAE-PR can extract high-level feature representations, which not only helps to improve the prediction accuracy of the Poisson regression model, but also is more robust to noise; In addition, SDAE-PR inherits the merits of Poisson regression that can ensure the non-negativity for the prediction of the response variable, which is a key for the count data modeling and analysis. The experimental results demonstrated that the proposed SDAE-PR model is more accurate than the other state-of-the-art methods in terms of prediction accuracy.","2767-9861","978-1-6654-9675-9","10.1109/DDCLS55054.2022.9858406","Natural Science Foundation of Zhejiang Province(grant numbers:LQ21F030018); National Natural Science Foundation(grant numbers:62003301); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9858406","Virtual-sensors;Deep learning;Denoising autoencoder;Count data regression;Poisson regression","Learning systems;Analytical models;Noise reduction;Predictive models;Feature extraction;Numerical simulation;Control systems","least squares approximations;neural nets;production engineering computing;regression analysis;soft sensors;stochastic processes","count data modeling;data-driven virtual-sensors;soft-sensors;quality variables;model error structure;nonnegative integer;stacked denoising autoencoders-based Poisson regression model;high-level feature representation;conventional Poisson regression model;prediction accuracy;SDAE-PR model;virtual-sensors models","","","","21","IEEE","26 Aug 2022","","","IEEE","IEEE Conferences"
"Video Popularity Prediction: An Autoencoder Approach With Clustering","Y. -T. Lin; C. -C. Yen; J. -S. Wang","Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, University of California at Davis, Davis, USA; Department of Computer Science, National Tsing Hua University, Hsinchu, Taiwan","IEEE Access","21 Jul 2020","2020","8","","129285","129299","Autoencoders implemented by artificial neural networks (ANNs) are utilized to learn the latent space representation of data in an unsupervised manner, and they have been widely used in recommender systems. For instance, several collaborative denoising autoencoder (CDAE) models have shown that their performance gains outperform that of the collaborative filtering based (CF-based) models. In this work, a near-optimal Top-K forecasting solution is proposed for our advanced autoencoder recommender systems. We propose a method which utilizes CDAE model in predicting the Top-K popular videos in an upcoming time period. In order to improve the prediction accuracy, we also propose an autoencoder based recommendation algorithm with the help of K-means clustering that upgrades the performance of the original autoencoder model. The experimental results show that our method increases significantly the Average Precision (AP) and Recall values by nearly 30%. We then further utilize our proposed autoencoder model with clustering in predicting Top-K popular videos. The applications of predicting Top-K popular videos can be used in the video delivery for the Mobile Edge Computing (MEC) environment to avoid bottleneck in the constricted capacity of backhaul link. Namely, the performance gain will be upgraded if our proposed method precisely predicts and caches the Top-K popular videos in advance with the help of a better forecasting model.","2169-3536","","10.1109/ACCESS.2020.3009253","Ministry of Science and Technology, Taiwan(grant numbers:MOST 104-2221-E-007-017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9139947","Top-K ranking and predicting;autoencoder;caching;K-means","Recommender systems;Predictive models;Collaboration;Streaming media;Machine learning;Prediction algorithms","collaborative filtering;image denoising;learning (artificial intelligence);mobile computing;neural nets;pattern clustering;recommender systems;video signal processing","CDAE model;prediction accuracy;autoencoder based recommendation algorithm;original autoencoder model;video delivery;performance gain;forecasting model;video popularity prediction;artificial neural networks;collaborative denoising autoencoder models;collaborative filtering;advanced autoencoder recommender systems;near-optimal top-k forecasting solution;top-k popular videos","","3","","22","CCBY","14 Jul 2020","","","IEEE","IEEE Journals"
"Noise reduction in images using autoencoders","A. Pawar","Department of Electronics & Telecommunication, Pune Institute of Computer Technology, Pune, India","2020 3rd International Conference on Intelligent Sustainable Systems (ICISS)","18 Jan 2021","2020","","","987","990","Pure signals can ideally exist only on paper. However, with the availability of a considerable number of state-of-the-art techniques that claim to denoise a given signal only up to an extent, it is at the same time necessary that such techniques must be compatible with a large number of devices. This paper discusses an approach to reduce the noise present in images through Image Processing and Deep Learning algorithms by implementing autoencoders. Using an autoencoder for removing noise is one such approach where the main focus is to retain the originality as autoencoders follow the backpropagation process, rather than the traditional techniques, where the output signal is ultimately the unoriginal version of the input signal. The technique discussed in the paper is interconvertible, i.e., could be used for any signal, is reliable, efficient, and compatible with a larger pool of devices.","","978-1-7281-7089-3","10.1109/ICISS49785.2020.9315908","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9315908","Deep Learning;Artificial Neural Network;Autoencoders;Latent Space Representation","Decoding;Image coding;Noise reduction;Training;Image reconstruction;Conferences;Testing","backpropagation;deep learning (artificial intelligence);image denoising","image processing;deep learning;autoencoder;backpropagation process;noise reduction","","","","15","","18 Jan 2021","","","IEEE","IEEE Conferences"
"Hierarchy Denoising Recursive Autoencoders for 3D Scene Layout Prediction","Y. Shi; A. X. Chang; Z. Wu; M. Savva; K. Xu",National University of Defense Technology; Eloquent Labs; Princeton University; Simon Fraser University; National University of Defense Technology,"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","1771","1780","Indoor scenes exhibit rich hierarchical structure in 3D object layouts. Many tasks in 3D scene understanding can benefit from reasoning jointly about the hierarchical context of a scene, and the identities of objects. We present a variational denoising recursive autoencoder (VDRAE) that generates and iteratively refines a hierarchical representation of 3D object layouts, interleaving bottom-up encoding for context aggregation and top-down decoding for propagation. We train our VDRAE on large-scale 3D scene datasets to predict both instance-level segmentations and a 3D object detections from an over-segmentation of an input point cloud. We show that our VDRAE improves object detection performance on real-world 3D point cloud datasets compared to baselines from prior work.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.00187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8954246","Scene Analysis and Understanding;Recognition: Detection;Categorization;Retrieval;Segmentation;Grouping and Shape","Point cloud compression;Three-dimensional displays;Layout;Noise reduction;Refining;Object detection;Encoding","image denoising;image segmentation;object detection;traffic engineering computing","hierarchy denoising recursive autoencoders;indoor scenes;hierarchical structure;3D object layouts;hierarchical context;variational denoising recursive autoencoder;VDRAE;hierarchical representation;3D object detections;object detection performance;real-world 3D point cloud datasets;large-scale 3D scene datasets;instance-level segmentation","","14","","65","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Denoising Autoencoder-Based Missing Value Imputation for Smart Meters","S. Ryu; M. Kim; H. Kim","Department of Electronic Engineering, Sogang University, Seoul, South Korea; Department of Electronic Engineering, Sogang University, Seoul, South Korea; Department of Electronic Engineering, Sogang University, Seoul, South Korea","IEEE Access","4 Mar 2020","2020","8","","40656","40666","Electric load data are essential for data-driven approaches (including deep learning) in smart grid, and advanced smart meter technologies provide fine-grained data with reliable communications. Despite the recent development of smart metering devices, however, missing data still arise due to unexpected device power off, communication failure, measuring error, or other unknown reasons. In this paper, we investigate a deep learning framework for missing imputation of smart meter data by leveraging a denoising autoencoder (DAE). Then, we compare the performance of the proposed DAE with traditional methods as well as other recently developed generative models, e.g., variational autoencoder and Wasserstein autoencoder. The proposed DAE based imputation shows significantly better results compared to other methods in terms of root mean square error (RMSE) by up to 28.9% for point-wise error, and by up to 56% for daily-accumulated error.","2169-3536","","10.1109/ACCESS.2020.2976500","Ministry of Land, Infrastructure and Transport(grant numbers:19NSPS-B152996-02); National Research Foundation of Korea(grant numbers:NRF-2017R1A1A1A05001377); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9016055","Deep learning;smart grid;missing imputation;smart meters;denoising autoencoder;generative model;daily load profile (DLP)","Machine learning;Smart meters;Noise reduction;Smart grids;Load modeling","data analysis;learning (artificial intelligence);neural nets;power engineering computing;smart meters;smart power grids","electric load data;smart grid;smart meter technologies;deep learning;smart meter data;DAE based imputation;denoising autoencoder-based missing value imputation","","21","","30","CCBY","27 Feb 2020","","","IEEE","IEEE Journals"
"Speech Enhancement Using Convolutional Denoising Autoencoder","S. A. Shahriyar; M. A. H. Akhand; N. Siddique; T. Shimamura","Dept. of CSE, Khulna University of Engineering & Technology, Khulna, Bangladesh; Dept. of CSE, Khulna University of Engineering & Technology, Khulna, Bangladesh; Engineering and Intelligent Systems, Ulster University, United Kingdom; Graduate School of Science and Engineering, Saitama University, Japan","2019 International Conference on Electrical, Computer and Communication Engineering (ECCE)","4 Apr 2019","2019","","","1","5","Speech signals are complex in nature with respect to other forms of communication media such as text or image. Different forms of noises (e.g., additive noise, channel noise, babble noise) interfere with the speech signals and drastically hamper the quality of the speech in the noisy speech signals. Enhancement of speech signals is a daunting task considering multiple forms of noises while denoising speech signals. Certain analog noise eliminator models have been studied over the years for this purpose. Researchers have also delved into some deep learning techniques to enhance speech signals. In this study, a speech enhancement system is investigated using Convolutional Denoising Autoencoder (CDAE). It takes advantages from the 2D structured inputs of the features extracted from speech signals and also considers the local temporal relationship among the features. In the proposed system, CDAE is trained considering features from noisy speech signal as input and clean speech features as desired output. The proposed CDAE based method has been tested on a benchmark dataset, called Speech Command Dataset, and attained 80% similarity between denoised speech and actual clean speech. The proposed system achieved perceptual evaluation of speech quality (PESQ) value of 2.43 which outperformed other related existing methods.","","978-1-5386-9111-3","10.1109/ECACE.2019.8679106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8679106","Speech Enhancement;Speech Cleaning;MFCC;Convolutional Denoising Autoencode;Clean Audio","Speech enhancement;Noise measurement;Feature extraction;Mel frequency cepstral coefficient;Noise reduction;Convolution;Two dimensional displays","learning (artificial intelligence);signal denoising;speech enhancement","speech signals;speech enhancement system;Convolutional Denoising Autoencoder;noisy speech signal;clean speech features;actual clean speech;Speech Command Dataset;benchmark dataset;perceptual evaluation of speech quality value;analog noise eliminator models","","4","","19","","4 Apr 2019","","","IEEE","IEEE Conferences"
"Sparsely connected autoencoder","K. Gupta; A. Majumdar","IIIT Delhi, New Delhi, India; IIIT Delhi, New Delhi, India","2016 International Joint Conference on Neural Networks (IJCNN)","3 Nov 2016","2016","","","1940","1947","This work proposes to learn autoencoders with sparse connections. Prior studies on autoencoders enforced sparsity on the neuronal activity; these are different from our proposed approach - we learn sparse connections. Sparsity in connections helps in learning (and keeping) the important relations while trimming the irrelevant ones. We have tested the performance of our proposed method on two tasks - classification and denoising. For classification we have compared against stacked autneencoders, contractive autoencoders, deep belief network, sparse deep neural network and optimal brain damage neural network; the denoising performance was compared against denoising autoencoder and sparse (activity) autoencoder. In both the tasks our proposed method yields superior results.","2161-4407","978-1-5090-0620-5","10.1109/IJCNN.2016.7727437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727437","autoencoder;classification;sparsity;denoising","Biological neural networks;Neurons;Noise reduction;Minimization;Decoding;Training","image classification;image coding;image denoising","sparsely connected autoencoder;classification;denoising performance","","4","","34","","3 Nov 2016","","","IEEE","IEEE Conferences"
"Robust and Fast Temperature Extraction for Brillouin Optical Time-Domain Analyzer by Using Denoising Autoencoder-Based Deep Neural Networks","B. Wang; N. Guo; L. Wang; C. Yu; C. Lu","Department of Electronics and Information Engineering, The Hong Kong Polytechnic University, Hong Kong; Department of Electronics and Information Engineering, The Hong Kong Polytechnic University, Hong Kong; National Engineering Laboratory for Next Generation Internet Access System, School of Optics and Electronic Information, Huazhong University of Science and Technology, Wuhan, China; Department of Electronics and Information Engineering, The Hong Kong Polytechnic University, Hong Kong; Department of Electronics and Information Engineering, The Hong Kong Polytechnic University, Hong Kong","IEEE Sensors Journal","5 Mar 2020","2020","20","7","3614","3620","A method of robust and fast temperature extraction for Brillouin optical time-domain analyzer (BOTDA) sensing systems using the denoising autoencoder (DAE) based deep neural networks (DNN) is demonstrated. After appropriate training, the DAE suppresses the noise on the measured Brillouin gain spectrum (BGS), and improves the signal-to-noise ratio (SNR) by 9.96dB in our experiment. To extract temperature, the DAE as a basic block is stacked to form the DNN model. Since the DNN model is based on DAE, both denoising and fast temperature extraction can be simultaneously finished using only one DNN model. Thus, it is more robust and faster than the conventional Lorentzian curve fitting (LCF) method, especially when the input data has low SNR level. In the case of 4.6dB SNR, the standard deviation (SD) of the measured temperature at the end of 40km fiber under test (FUT) is reduced from 2.4°C to 1.2°C by using DAE based DNN when compared with that using the LCF method, and the corresponding root-mean-square error (RMSE) is reduced from 2.4°C to 1.3°C. Moreover, since the temperature information can be extracted directly from the experimental BGS data without the need of time-consuming curve fitting and subsequent conversion from Brillouin frequency shift (BFS) to temperature, the speed of temperature extraction using the DAE based DNN is faster by 500 times than that using LCF. Combining the advantages of both denoising and fast processing speed, the DAE based DNN would be a practical way of temperature extraction for the BOTDA systems.","1558-1748","","10.1109/JSEN.2019.2960876","Research Grants Council of Hong Kong (RGC) Project(grant numbers:CUHK GRF 14204019,PolyU GRF 15265816,15216817,15211317); Heilongjiang University of Science and Technology(grant numbers:3011182020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936935","Brillouin optical time-domain analyzer;denoising autoencoder;deep neural networks;temperature extraction","Temperature measurement;Training;Noise reduction;Feature extraction;Data mining;Temperature distribution;Scattering","Brillouin spectra;fibre optic sensors;neural nets;optical engineering computing;optical noise;temperature measurement;time-domain analysis","temperature information;Brillouin frequency shift;DAE based DNN;fast temperature extraction;denoising autoencoder-based deep neural networks;robust temperature extraction;Brillouin optical time-domain analyzer sensing systems;noise suppression;measured Brillouin gain spectrum;signal-to-noise ratio;DNN model;SNR level;standard deviation;fiber under test;root-mean-square error;size 40.0 km","","9","","20","IEEE","19 Dec 2019","","","IEEE","IEEE Journals"
"Elastic SDAE: An Adaptive Noise Selection for Stacked Denoising Auto encoder","B. V. Gokulnath; U. Devi G.","School of Information Technology, Vellore Institute of Technology, Vellore, Tamil Nadu, India; School of Information Technology, Vellore Institute of Technology, Vellore, Tamil Nadu, India","2020 International Conference on Emerging Trends in Information Technology and Engineering (ic-ETITE)","27 Apr 2020","2020","","","1","5","This paper proposes an Elastic Stacked Denoising Autoencoder model, an upgraded model of a stacked autoencoder algorithm. It works on the basis of reconstruction through learning from the input towards generating the same as the output. But, the selection of noise levels in the autoencoder is determined as fixed-parameter throughout the learning. The proposed model addresses this limitation based on the principle of annealing (ElasticSDAE), a novel method of adaptively obtaining the noise level. This is achieved by first computing the average noise level for each epoch using a linear average noise level function based on the principle of annealing; and second calculating the noise level for each input neuron based on the average noise level, and the contribution of the input neuron to the activation of hidden neurons (which depend on the input neuron's value and the weights). Thus, the network includes a combination of features at multiple scales. The experimental results show that our proposed ElasticSDAE performed better than SDAE and other unsupervised feature learning methods.","","978-1-7281-4142-8","10.1109/ic-ETITE47903.2020.275","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9077788","Elastic Stacked Denoising Autoencoder;Feature Extraction;Plant Village;Noise Reduction","","feature extraction;image denoising;learning (artificial intelligence);neural nets","stacked autoencoder algorithm;linear average noise level function;input neuron;adaptive noise selection;elastic SDAE;elastic stacked denoising autoencoder model;annealing","","","","8","","27 Apr 2020","","","IEEE","IEEE Conferences"
"Learning autoencoders with low-rank weights","K. Gupta; A. Majumdar",TCS; IIIT-Delhi,"2017 IEEE International Conference on Image Processing (ICIP)","22 Feb 2018","2017","","","3899","3903","In this work we propose to regularize the encoding and decoding weights of an autoencoder using low-rank penalty in the form of nuclear norm. Such a formulation models redundancy in the network. We show that our proposed method yields better classification accuracy (on an average) and denoising results than other stochastic and deterministic regularization techniques used in deep autoencoders. Our method is also considerably faster compared to these techniques. The experiments have been carried out on benchmark deep learning datasets.","2381-8549","978-1-5090-2175-8","10.1109/ICIP.2017.8297013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8297013","autoencoder;deep learning;classification;denoising;nuclear norm","Training;Decoding;Noise reduction;Biological neural networks;Neurons;Redundancy;Artificial neural networks","image classification;image coding;image denoising;learning (artificial intelligence)","low-rank weights;decoding weights;low-rank penalty;nuclear norm;classification accuracy;deep autoencoders;redundancy;autoencoders learning;encoding weights;deep learning datasets;denoising results","","1","","28","","22 Feb 2018","","","IEEE","IEEE Conferences"
"A Study on Feature Extraction of Handwriting Data Using Kernel Method-Based Autoencoder","V. Q. Dang; Y. Pei","School of Computer Science and Engineering, University of Aizu, Aizu-Wakamatsu, Fukushima, Japan; Computer Science Division, University of Aizu, Aizu-Wakamatsu, Fukushima, Japan","2018 9th International Conference on Awareness Science and Technology (iCAST)","1 Nov 2018","2018","","","1","6","We use kernel method-based autoencoder in feature extraction application and evaluate its performance with a public handwriting database. Neural network-based autoencoder is an unsupervised algorithm and model that tries to learn an approximation function so as to extract features from data. Kernel method-based autoencoder has the same function compared with neural network-based autoencoder, but uses kernel methods to implement linear and non-linear data transformation. We use a handwriting dataset to evaluate kernel-based autoencoder, and examine the result by mean square error estimator, structural similarity index and peak signal-to-noise ratio for measuring image quality. We also investigate parameters of kernel functions to observe changes in the performance of the autoencoder. We found that effectiveness of kernel method-based autoencoder depends on the selection of kernel function and its parameter.","2325-5994","978-1-5386-5826-0","10.1109/ICAwST.2018.8517169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517169","kernel method;kernel-based autoencoder;autoencoder;kernel-based principal component analysis;kernel-based linear regression","Kernel;Linear regression;Feature extraction;Databases;Training;Covariance matrices;Data models","feature extraction;Gaussian processes;handwriting recognition;image denoising;learning (artificial intelligence);mean square error methods;neural nets","kernel method-based autoencoder;neural network-based autoencoder;kernel methods;kernel-based autoencoder;kernel function;handwriting dataset;mean square error estimator;structural similarity index;peak signal-to-noise ratio;image quality","","2","","10","","1 Nov 2018","","","IEEE","IEEE Conferences"
"Denoising-Contractive Autoencoder for Robust Device-Free Occupancy Detection","P. C. Ng; J. She","Department of Electronics and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong; Department of Electronics and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong","IEEE Internet of Things Journal","11 Dec 2019","2019","6","6","9572","9582","Device-free occupancy detection is very important for certain Internet of Things applications that do not require the user to carry a receiver. This paper achieves the device-free occupancy detection with RF fingerprinting, which labels each zone with a 2M-dimensional fingerprint vector. Specifically, the fingerprint vector consists of received signal strength (RSS) values measured from M Bluetooth low energy (BLE) beacons and also their corresponding temporal RSS variations. However, the unreliable RSS values caused two common issues with the fingerprint vector: 1) noise and 2) sparsity. To this end, we propose denoising-contractive autoencoder (DCAE) to jointly deal with these two issues, by learning a robust fingerprint prior to device-free occupancy detection. We validate the performance of our proposed DCAE with large-scale real-world datasets. The experimental results indicate the substantial performance gain of our proposed DCAE in comparison with state-of-the-art autoencoders. In particular, the classifier trained using the fingerprints learned by our proposed DCAE is able to maintain at least 90% accuracy when the noise factor or sparsity ratio increases to 0.6 and 0.5, respectively.","2327-4662","","10.1109/JIOT.2019.2929822","HKUST-NIE Social Media Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8766808","Autoencoder;Bluetooth low energy (BLE) beacon;occupancy detection","Receivers;Radio frequency;Smart phones;Internet of Things;Performance evaluation;Noise measurement;Bluetooth","Bluetooth;indoor radio;learning (artificial intelligence);object tracking;radio networks;RSSI;signal denoising;wireless LAN","DCAE;robust fingerprint;denoising-contractive autoencoder;robust device-free occupancy detection;RF fingerprinting;2M-dimensional fingerprint vector","","7","","35","IEEE","19 Jul 2019","","","IEEE","IEEE Journals"
"Performance Analysis of Stego Images Detection Using Shallow Denoising Autoencoders","D. Progonov","Institute of Physics and Technology, Igor Sikorsky Kyiv Polytechnic Institute, Kyiv, Ukraine","2021 IEEE 8th International Conference on Problems of Infocommunications, Science and Technology (PIC S&T)","16 May 2022","2021","","","179","182","Early detection of sensitive information leakage in communication systems is topical task today. This requires usage of advanced statistical processing methods for detection negligible changes of cover files, such as digital images, caused by message hiding. One of promising approaches for solving the task is learning an appropriate representation of cover and formed stego images that is sensitive to data embedding. This approach is widely used in modern stegdetectors based on utilization of convolutional neural networks. Achieving of high detection accuracy by stegdetector requires usage deep convolutional networks, whose computation-intensive re-train procedure limits fast adaptation to unknown embedding methods. For overcoming this limitation, we propose to use special types of neural networks, namely autoencoders that provides fast adaptation to changes of inputted data by preserving high restoration accuracy. The work is devoted to performance analysis of usage shallow denoising autoencoders for detection of stego images formed by advanced embedding methods. It is revealed that considered networks allows improving detection accuracy up to 1.5%-2% for the most difficult case of small cover image payload (less than 10%).","","978-1-6654-0682-6","10.1109/PICST54195.2021.9772180","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9772180","steganalysis;digital image;adaptive embedding methods;autoencoders","Image coding;Filtering;Digital images;Noise reduction;Neural networks;Performance analysis;Image restoration","convolutional neural nets;embedded systems;image coding;image denoising;image representation;image restoration;learning (artificial intelligence);object detection;steganography","high detection accuracy;stegdetector;computation-intensive re-train procedure;fast adaptation;unknown embedding methods;high restoration accuracy;performance analysis;advanced embedding methods;cover image payload;stego image detection;shallow denoising autoencoders;communication systems;advanced statistical processing methods;cover files;digital images;message hiding;data embedding;modern stegdetectors;convolutional neural networks;deep convolutional networks;sensitive information leakage detection","","","","19","IEEE","16 May 2022","","","IEEE","IEEE Conferences"
"Improving The Robustness Of Right Whale Detection In Noisy Conditions Using Denoising Autoencoders And Augmented Training","W. Vickers; B. Milner; R. Lee","School of Computing Sciences, University of East Anglia, Norwich, UK; School of Computing Sciences, University of East Anglia, Norwich, UK; Gardline Environmental, Gardline Geosurvey Limited, Great Yarmouth, UK","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","91","95","The aim of this paper is to examine denoising autoencoders (DAEs) for improving the detection of right whales recorded in harsh marine environments. Passive acoustic recordings are taken from autonomous surface vehicles (ASVs) and are subject to noise from sources such as shipping and offshore construction. To mitigate the noise we apply DAEs and consider how best to train the classifier by augmenting clean training data with examples contaminated by noise. Evaluations find that the DAE improves detection accuracy and is particularly effective when the classifier is trained on data that has itself been denoised rather than using a clean model. Further, testing on unseen noises is also effective particularly for noises that exhibit similar character to noises seen in training.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414682","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414682","cetacean detection;autonomous surface vehicles;CNN;autoencoder;right whale","Training;Surface cleaning;Surface contamination;Noise reduction;Whales;Training data;Data models","acoustic signal processing;image classification;image denoising;marine engineering;marine vehicles;mobile robots;neural nets;robot vision","right whale detection;noisy conditions;denoising autoencoders;augmented training;DAE;harsh marine environments;passive acoustic recordings;autonomous surface vehicles;ASV;classifier;clean training data augmentation","","1","","21","","13 May 2021","","","IEEE","IEEE Conferences"
"Research on fault diagnosis method of rotating machinery based on deep learning","Z. Chen; Z. Li","Key laboratory of Nondestructive Testing, Ministry of Education Nanchang Hangkong University, Nanchang, China; Key laboratory of Nondestructive Testing, Ministry of Education Nanchang Hangkong University, Nanchang, China","2017 Prognostics and System Health Management Conference (PHM-Harbin)","23 Oct 2017","2017","","","1","4","Based on the deficiency in the traditional fault diagnosis method, i.e shallow learning is usually used to characterize complex mapping relationship between vibration signals and the rotor system, a deep neural network (DNN)based on denoising auto-encoder is proposed. At the same time, the proposed method has been successfully applied to the fault diagnosis of rotating machinery. In the proposed method, the frequency domain information of the vibration signal is used as input signal, and the deep neural network is obtained by the unsupervised training of the denoising autoencoder, the dropout method is employed to adjust the network parameters, reducing the problem of the over-fitting. Finally, the fault features obtained by learning of denoising auto-encoder is used for fault diagnosis. The experimental result show that the proposed method is very effective, and can effectively extract the implicit characteristics of the fault signal.","2166-5656","978-1-5386-0370-3","10.1109/PHM.2017.8079279","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8079279","denoising autoencoders;deep learning;fault diagnosis;Rotating mchinery","Machine learning;Fault diagnosis;Machinery;Noise reduction;Standards","fault diagnosis;learning (artificial intelligence);machinery;neural nets;signal denoising;vibrational signal processing;vibrations","rotating machinery;deep learning;complex mapping relationship;vibration signal;rotor system;deep neural network;frequency domain information;input signal;denoising autoencoder;dropout method;network parameters;fault features;fault signal","","6","","10","","23 Oct 2017","","","IEEE","IEEE Conferences"
"Deep Convolutional Autoencoder for Estimation of Nonstationary Noise in Images","S. G. Bahncmiri; M. Ponomarenko; K. Egiazarian","Tampere University, Finland; Tampere University, Finland; Tampere University, Finland","2019 8th European Workshop on Visual Information Processing (EUVIP)","2 Jan 2020","2019","","","238","243","A precise estimation of noise parameters is very important in many image processing applications, such as denoising, deblurring, compression, etc. This problem is well studied for the case of stationary noise in images, and much less studied for the case of nonstationary noise. In this paper, we develop an efficient method of nonstationary noise variance estimation in image regions, based on specially designed deep convolutional autoencoder (DCAE) with a small dimensionality reduction. Training of the proposed DCAE is carried out for a large set of image blocks, including fragments of noise free textures, faces and texts. In the numerical analysis, we compare the proposed method and method of blind estimation of nonstationary noise, based on block matching (BM). Additionally, we analyze efficiency of the proposed DCAE in comparison with the conventional autoencoder (AE). We show that usage of the proposed DCAE provides an error of noise variance estimation about 2 times smaller, that the error when the standard AE is used, and 4 times smaller than the variance estimation error of the BM method.","2471-8963","978-1-7281-4496-2","10.1109/EUVIP47703.2019.8946273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946273","noise parameters estimation;autoencoder;deep convolutional networks;image denoising;image compression;image visual quality assessment","Estimation;Noise measurement;Training;Visualization;Image denoising;Image coding","computer vision;convolutional neural nets;image denoising;image matching;image restoration;image texture;learning (artificial intelligence);motion estimation","variance estimation error;precise estimation;noise parameters;image processing;stationary noise;nonstationary noise variance estimation;image regions;DCAE;image blocks;blind estimation;designed deep convolutional autoencoder;noise free textures;numerical analysis","","5","","22","","2 Jan 2020","","","IEEE","IEEE Conferences"
"Denoising AutoEncoder in Neural Networks with Modified Elliott Activation Function and Sparsity-Favoring Cost Function","H. Burhani; W. Feng; G. Hu","Departments of Computing & Information Systems and Mathematics, Trent University, Peterborough, Ontario, Canada; Departments of Computing & Information Systems and Mathematics, Trent University, Peterborough, Ontario, Canada; Department of Computer Science, Central Michigan University Mount Pleasant, Michigan, USA","2015 3rd International Conference on Applied Computing and Information Technology/2nd International Conference on Computational Science and Intelligence","30 Nov 2015","2015","","","343","348","Neural networks (NN) are architectures and algorithms for machine learning. They are quite powerful for tasks like classification, clustering, and pattern recognition. Large neural networks can be considered a universal function that can approximate any function, and hence are effective at learning from the training data, not only the useful information but also the noise in the training data. However, as the number of neurons and the number of hidden layers grow, the number of connections in the network increases exponentially, and the over fitting problem becomes more severe biased towards noise. Various methods have been proposed to address this problem such as AutoEncoder, Dropout, DropConnect, and Factored Mean training. In this paper, we propose a denoising autoencoder approach using a modified Elliott activation function and a cost function that favors sparsity in the input data. Preliminary experiments using the modified algorithm on several real data sets showed that the proposed approach performed well.","","978-1-4673-9642-4","10.1109/ACIT-CSI.2015.67","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7336086","Deep neural networks;denoising autoencoder;activation function;cost function","Neurons;Biological neural networks;Training;Noise reduction;Cost function;Machine learning algorithms","neural nets;transfer functions","neural networks;sparsity-favoring cost function;denoising autoencoder;modified Elliott activation function;input data sparsity","","4","1","18","","30 Nov 2015","","","IEEE","IEEE Conferences"
"Dual Denoising Autoencoder Features for Imbalance Classification Problems","T. Wang; G. Zeng; W. W. Y. Ng; J. Li","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","2017 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)","1 Feb 2018","2017","","","312","317","In pattern classification problems, it is difficult to force all classes to have the same number of training samples. Undersampling-based methods loss information while oversampling-based methods easily overfit. Therefore, the Dual Autoencoders Features (DAF) relieves the imbalanced pattern classification problem via learning a set of better features to project samples in different classes onto a more distinguishable space. However, the feature set learned by the DAF may not be robust to partial corruption of input patterns. Therefore, this work proposes a Dual Denoising Autoencoders Features (DDAF) to learn a more robust set of features to contaminated or destroyed training datasets. Experimental results show that the DDAF outperforms existing resampling-based methods and the DAF for imbalanced pattern classification problems.","","978-1-5386-3066-2","10.1109/iThings-GreenCom-CPSCom-SmartData.2017.52","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8276770","imbalanced classification;feature learning;stacked denoising autoencoder","Encoding;Training;Noise reduction;Decoding;Robustness;Image reconstruction;Pattern classification","feature extraction;learning (artificial intelligence);pattern classification;sampling methods","pattern classification problems;imbalanced pattern classification problem;feature set learning;DDAF;dual denoising autoencoder features","","3","","21","","1 Feb 2018","","","IEEE","IEEE Conferences"
"Denoising Deep Autoencoder Gaussian Mixture Model and Its Application for Robust Nonlinear Industrial Process Monitoring","Y. -C. Zhou; M. -Q. Li; L. -B. Ji","College of Mathematics and Physics, Beijing University of Chemical Technology, Beijing, China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; School of Advanced Technology, Xi’an Jiaotong-Liverpool University, Suzhou, China","2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI)","28 Feb 2022","2021","","","67","73","Process monitoring on high-dimensional nonlinear data is of great significance in the industrial process. This paper presents a denoising deep autoencoder Gaussian mixture model (DDAGMM) for anomaly detection in the industrial process. We add Gaussian white noise as preprocessing to the input data, which is further fed into a deep autoencoder to generate a low-dimensional representation and reconstruction error. Finally, we propose a monitoring strategy based on sample energy criterion to judge whether the new sample is anomaly or not. The DDAGMM can reduce the influence of outliers in the original data, has strong robustness, and can handle multi-modal data well. Compared with PCA, LDA and DAGMM based monitoring methods, the proposed counterpart shows superior performance.","","978-1-6654-0692-5","10.1109/CISAI54367.2021.00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9719279","Denoising Deep Autoencoder Gaussian Mixture Model (DDAGMM);fault detection;kernel density estimation (KDE);robust process monitoring","Process monitoring;Information science;Gaussian noise;Noise reduction;Estimation;White noise;Feature extraction","data reduction;deep learning (artificial intelligence);feature extraction;Gaussian noise;mixture models;process monitoring;production engineering computing;white noise","denoising deep autoencoder Gaussian mixture model;high-dimensional nonlinear data;Gaussian white noise;robust nonlinear industrial process monitoring;data preprocessing;DDAGMM;data outlier reduction;multi-modal data handling;anomaly detection","","","","20","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"An Overview of Selected Autoencoders and Their Potential Application in Smart Cities","R. Hendricks; L. C. Altherr","Faculty of Electrical Engineering and Information Technology, Aachen University of Applied Sciences, Aachen, Germany; Faculty of Electrical Engineering and Information Technology, Aachen University of Applied Sciences, Aachen, Germany","2021 International Conference on Computational Science and Computational Intelligence (CSCI)","22 Jun 2022","2021","","","1895","1897","The following work gives an overview of a special type of neural networks, autoencoders, that can be of great interest to researchers and practitioners in the field of smart city, due to their numerous application possibilities in this context. Given the fact that these networks can be trained in an unsupervised fashion, autoencoders are immediately applicable to practically collected data sets that often lack labels, not requiring the tedious process of data labeling. In addition to the classical autoencoder, we present two other types, and highlight their differences in architecture and in areas of application. In doing so, the benefits of the respective autoencoders and their possible application, especially in the context of smart cities, are presented.","","978-1-6654-5841-2","10.1109/CSCI54926.2021.00354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9799159","Smart City;Neural Network;Autoencoder;Anomaly Detection;Denoising","Smart cities;Scientific computing;Neural networks;Computer architecture;Labeling;Computational intelligence","data handling;neural nets;smart cities","neural networks;smart city;classical autoencoder;data labeling","","","","16","IEEE","22 Jun 2022","","","IEEE","IEEE Conferences"
"Classification of massive noisy image using auto-encoders and convolutional neural network","S. S. Roy; M. Ahmed; M. A. H. Akhand","Institute of Information and Communication Technology Khulna University of Engineering & Technology, Bangladesh; Dept. of Computer Science and Engineering, Khulna University of Engineering & Technology, Bangladesh; Khulna University of Engineering and Technology, Khulna, BD","2017 8th International Conference on Information Technology (ICIT)","23 Oct 2017","2017","","","971","979","Image processing tasks has found a new dimension with the improvement of learning feature representation from images using deep networks. Most of the research works are conducted over pre-possessed image data in the lab. But, these methods fail in the real world scenario as most of the time the image required to classify is subject to noise and other disfigurement. For the last three decades, many researches has been conducted and numerus algorithms have been proposed with varying performances to classify noisy images. But in recent times, various autoencoders have outperformed all traditional methods for reconstructing native image from it's noisy form and opened a new door for the research of noisy image classification. In this paper, we studied various auto encoders for reconstructing native images from noisy input images. We have applied convolutional neural network as classifier. Before classification task we have rectified noisy images using denoising autoencoder, convolutional denoising autoencoder and finally a hybrid of them as proposed in this paper. The proposed methods are evaluated by experimenting over benchmark dataset adulterated with noises of different proportionate. This method has outperformed some other prominent methods achieving satisfying classification accuracy even when the image is too much noisy (50% noise is added with the image data).","","978-1-5090-6332-1","10.1109/ICITECH.2017.8079976","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8079976","Image denoising;convolution;Denoising Autoencoder;Convolutional Autoencoder;Convolutional Neural Network","Image reconstruction;Noise measurement;Noise reduction;Image classification;Kernel;Neural networks","feature extraction;image classification;image denoising;image representation;learning (artificial intelligence);neural nets;pattern classification","auto-encoders;convolutional neural network;image processing tasks;deep networks;pre-possessed image data;noisy image classification;auto encoders;noisy input images;convolutional denoising autoencoder;massive noisy image classification;native image reconstruction","","4","","19","","23 Oct 2017","","","IEEE","IEEE Conferences"
"Improving image recognition by hierarchical model and denoising","Fuqiang Chen; Yan Wu","College of Electronics and Information Engineering, Tongji University, Shanghai, China; College of Electronics and Information Engineering, Tongji University, Shanghai, China","2015 11th International Conference on Natural Computation (ICNC)","11 Jan 2016","2015","","","977","981","In this study, a novel method for image recognition based on deep learning algorithm and image denoising is proposed. It is based on Bernoulli process factor analysis denoising method and tiled convolutional neural network. The images are first denoised using Bernoulli process factor analysis, and then the denoised images are transmitted to tiled convolutional neural network for robust feature extraction. Lastly, support vector machine is used for classification. The experiments implemented on the benchmark dataset CIFAR-10 shows the effectiveness of our proposed method, which performs better than our previously proposed method, CDAE-SVM (contractive denoising autoencoder + SVM).","2157-9563","978-1-4673-7679-2","10.1109/ICNC.2015.7378124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7378124","Image denoising;Tiled convolutional neural network;Bernoulli process factor analysis;Topologic independent component analysis","Feature extraction;Neural networks;Support vector machines;Image recognition;Image denoising;Robustness;Noise reduction","feature extraction;image classification;image denoising;learning (artificial intelligence);neural nets;support vector machines","image recognition;hierarchical model;deep learning algorithm;image denoising;Bernoulli process factor analysis denoising method;tiled convolutional neural network;robust feature extraction;support vector machine;classification;CIFAR-10 dataset","","","","27","","11 Jan 2016","","","IEEE","IEEE Conferences"
"Autoencoder-based Unsupervised Domain Adaptation for Speech Emotion Recognition","J. Deng; Z. Zhang; F. Eyben; B. Schuller","Machine Intelligence & Signal Processing Group, MMK, Technische Universität München, Germany; Machine Intelligence & Signal Processing Group, MMK, Technische Universität München, Germany; Machine Intelligence & Signal Processing Group, MMK, Technische Universität München, Germany; Machine Intelligence & Signal Processing Group, MMK, Technische Universität München, Germany","IEEE Signal Processing Letters","21 May 2014","2014","21","9","1068","1072","With the availability of speech data obtained from different devices and varied acquisition conditions, we are often faced with scenarios, where the intrinsic discrepancy between the training and the test data has an adverse impact on affective speech analysis. To address this issue, this letter introduces an Adaptive Denoising Autoencoder based on an unsupervised domain adaptation method, where prior knowledge learned from a target set is used to regularize the training on a source set. Our goal is to achieve a matched feature space representation for the target and source sets while ensuring target domain knowledge transfer. The method has been successfully evaluated on the 2009 INTERSPEECH Emotion Challenge's FAU Aibo Emotion Corpus as target corpus and two other publicly available speech emotion corpora as sources. The experimental results show that our method significantly improves over the baseline performance and outperforms related feature domain adaptation methods.","1558-2361","","10.1109/LSP.2014.2324759","China Scholarship Council(grant numbers:338164); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6817520","Adaptive denoising autoencoders;domain adaptation;speech emotion recognition","Speech;Training;Speech recognition;Emotion recognition;Noise reduction;Vectors","emotion recognition;signal denoising;speech recognition;unsupervised learning","autoencoder-based unsupervised domain adaptation;speech emotion recognition;speech data availability;acquisition conditions;affective speech analysis;adaptive denoising autoencoder;feature space representation;target domain knowledge transfer;INTERSPEECH Emotion Challenge;FAU Aibo emotion corpus;speech emotion corpora","","177","","20","IEEE","16 May 2014","","","IEEE","IEEE Journals"
"Unsupervised Outlier Detection via Transformation Invariant Autoencoder","Z. Cheng; E. Zhu; S. Wang; P. Zhang; W. Li","School of Computer, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China; School of Computer, National University of Defense Technology, Changsha, China","IEEE Access","23 Mar 2021","2021","9","","43991","44002","Autoencoder based methods are the majority of deep unsupervised outlier detection methods. However, these methods perform not well on complex image datasets and suffer from the noise introduced by outliers, especially when the outlier ratio is high. In this paper, we propose a framework named Transformation Invariant AutoEncoder (TIAE), which can achieve stable and high performance on unsupervised outlier detection. First, instead of using a conventional autoencoder, we propose a transformation invariant autoencoder to do better representation learning for complex image datasets. Next, to mitigate the negative effect of noise introduced by outliers and stabilize the network training, we select the most confident inliers likely examples in each epoch as the training set by incorporating adaptive self-paced learning in our TIAE framework. Extensive evaluations show that TIAE significantly advances unsupervised outlier detection performance by up to 10% AUROC against other autoencoder based methods on five image datasets.","2169-3536","","10.1109/ACCESS.2021.3065838","National Key Research and Development Program of China(grant numbers:2018YFB0204301); National Natural Science Foundation of China(grant numbers:62006236); Hunan Provincial Natural Science Foundation(grant numbers:2020JJ5673); National University of Defense Technology (NUDT) Research Project(grant numbers:ZK20-10); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9376856","Deep Learning;unsupervised outlier detection;autoencoder;transformation invariant autoencoder","Anomaly detection;Training;Image reconstruction;Image restoration;Deep learning;Data models;Task analysis","adaptive signal processing;deep learning (artificial intelligence);image denoising;image representation;neural nets;object detection;transforms;unsupervised learning","transformation invariant autoencoder;autoencoder based methods;complex image datasets;conventional autoencoder;deep unsupervised outlier detection;TIAE;representation learning;negative noise effect;adaptive self-paced learning","","4","","59","CCBYNCND","12 Mar 2021","","","IEEE","IEEE Journals"
"A Closer Look at Autoencoders for Unsupervised Anomaly Detection","O. K. Oyedotun; D. Aouada","Interdisciplinary Centre for Security, Reliability and Trust (Snt), University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (Snt), University of Luxembourg, Luxembourg","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","3793","3797","Unsupervised anomaly detection is a challenging problem, where the aim is to detect irregular data instances. Interestingly, generative models can learn data distribution, and thus have been proposed for anomaly detection. In this direction, the variational autoencoder (VAE) is popular, as it enforces an explicit probabilistic interpretation of the latent space. We note that there are other generative autoencoders (AEs) such as the denoising AE (DAE) and contractive AE (CAE), which also model data generation process without enforcing an explicit probabilistic latent space interpretation. While it is intuitively straightforward to see the benefit of a latent space with explicit probabilistic interpretation for generative tasks, it is unclear how this can be crucial for anomaly detection problems. Consequently, our exposition in this paper is to investigate the extent to which different latent space attributes of AEs impact their performances for anomaly detection tasks. We take the conventional and deterministic AE that we refer to as plain AE (PAE) as the baseline for performance comparison. Our results obtained using five different datasets reveal that an explicit probabilistic latent space is not necessary for good performance. The best results on most of the datasets are obtained using CAE, which enjoys stable latent representations.","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746898","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746898","Anomaly detection;autoencoder;variational autoencoder;latent representations","Conferences;Noise reduction;Signal processing;Probabilistic logic;Data models;Acoustics;Task analysis","data handling;learning (artificial intelligence);neural nets","unsupervised anomaly detection;irregular data instances;generative models;data distribution;variational autoencoder;explicit probabilistic interpretation;generative autoencoders;model data generation process;explicit probabilistic latent space interpretation;generative tasks;anomaly detection problems;different latent space attributes;anomaly detection tasks;stable latent representations;VAE;AEs;DAE;CAE;PAE;denoising autoencoder;contractive autoencoder","","","","28","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Autoencoder Matrix Completion Based Indoor Localization","I. Ahriz; M. Terre; W. Njima","LAETITIA/CEDRIC laboratory, Le CNAM, Paris, France; LAETITIA/CEDRIC laboratory, Le CNAM, Paris, France; LAETITIA/CEDRIC laboratory, Le CNAM, Paris, France","2020 54th Asilomar Conference on Signals, Systems, and Computers","3 Jun 2021","2020","","","1323","1326","The widespread of mobile devices facilitated the of many new applications that provide services based on user's location. Several techniques have been presented to enable such a service even in indoor environments where Global Positioning System (GPS) has low localization accuracy. These methods use some environment measurements. The most popular are using Received Signal Strength (RSS) for user location estimation. Due to the propagation conditions in indoor environment, the RSS methods suffer from missing data problem where the RSS can be below the sensitivity of some receivers. To overcome this problem, we propose in this paper an RSS matrix completion strategy based on an autoencoder algorithm as a preprocessing step. This latter exhibits a good performance in data denoising problems and can be applied for matrix completion purpose. A neural network is then used on the recovered RSS matrix to estimate a user's position. The performance of the proposed scheme is evaluated in a simulated environment and compared with traditional method of matrix completion based on the gradient descend algorithm and its variant. The results show the outperformances of our system of between 1 and 3 meters gain on localization error.","2576-2303","978-0-7381-3126-9","10.1109/IEEECONF51394.2020.9443459","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9443459","Autoencoder;localization;matrix completion","Location awareness;Meters;Sensitivity;Neural networks;Noise reduction;Receivers;Mobile handsets","encoding;gradient methods;indoor communication;indoor navigation;indoor radio;mobile radio;neural nets;radionavigation;radiowave propagation;RSSI;telecommunication computing","autoencoder matrix completion;indoor localization;mobile devices;indoor environment;Global Positioning System;localization accuracy;environment measurements;user location estimation;RSS methods;RSS matrix completion strategy;autoencoder algorithm;localization error;received signal strength;data denoising problems;neural network;gradient descend algorithm","","","","15","","3 Jun 2021","","","IEEE","IEEE Conferences"
"Use of a Tracer-Specific Deep Artificial Neural Net to Denoise Dynamic PET Images","I. S. Klyuzhin; J. -C. Cheng; C. Bevington; V. Sossi","Department of Medicine, The University of British Columbia, Vancouver, Canada; Pacific Parkinson’s Research Centre, The University of British Columbia, Vancouver, Canada; Department of Physics and Astronomy, The University of British Columbia, Vancouver, Canada; Department of Physics and Astronomy, The University of British Columbia, Vancouver, Canada","IEEE Transactions on Medical Imaging","3 Feb 2020","2020","39","2","366","376","Application of kinetic modeling (KM) on a voxel level in dynamic PET images frequently suffers from high levels of noise, drastically reducing the precision of parametric image analysis. In this paper, we investigate the use of machine learning and artificial neural networks to denoise dynamic PET images. We train a deep denoising autoencoder (DAE) using noisy and noise-free spatiotemporal image patches, extracted from the simulated images of [11C]raclopride, a dopamine D2 receptor agonist. The DAE-processed dynamic and corresponding parametric images (simulated and acquired) are compared with those obtained with conventional denoising techniques, including temporal and spatial Gaussian smoothing, iterative spatiotemporal smoothing/deconvolution, and the highly constrained backprojection processing (HYPR). The simulated (acquired) parametric image non-uniformity was 7.75% (19.49%) with temporal and 5.90% (14.50%) with spatial smoothing, 5.82% (16.21%) with smoothing/deconvolution, 5.49% (13.38%) with HYPR, and 3.52% (11.41%) with DAE. The DAE also produced the best results in terms of the coefficient of variation of voxel values and structural similarity index. Denoising-induced bias in the regional mean binding potential was 7.8% with temporal and 26.31% with spatial smoothing, 28.61% with smoothing/deconvolution, 27.63% with HYPR, and 14.8% with DAE. When the test data did not match the training data, erroneous outcomes were obtained. Our results demonstrate that a deep DAE can provide a substantial reduction in the voxel-level noise compared with the conventional spatiotemporal denoising methods while introducing a similar or lower amount of bias. The better DAE performance comes at the cost of lower generality and requiring appropriate training data.","1558-254X","","10.1109/TMI.2019.2927199","Natural Sciences and Engineering Research Council of Canada(grant numbers:240670-13); Canadian Institutes of Health Research(grant numbers:125989); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756077","Dynamic PET;denoising;neural network;machine learning;deep learning;kinetic modeling","Noise reduction;Training;Kinetic theory;Spatiotemporal phenomena;Positron emission tomography;Noise measurement;Image reconstruction","deconvolution;image denoising;iterative methods;learning (artificial intelligence);medical image processing;neural nets;positron emission tomography;smoothing methods;spatiotemporal phenomena","regional mean binding potential;structural similarity index;iterative spatiotemporal deconvolution;iterative spatiotemporal smoothing;[11C]raclopride;noise-free spatiotemporal image patches;machine learning;DAE performance;conventional spatiotemporal denoising methods;voxel-level noise;denoising-induced bias;parametric image nonuniformity;HYPR;highly constrained backprojection processing;spatial Gaussian smoothing;temporal Gaussian smoothing;conventional denoising techniques;dopamine D2 receptor agonist;simulated images;denoising autoencoder;artificial neural networks;parametric image analysis;dynamic PET images;tracer-specific deep artificial neural net","Brain;Humans;Image Processing, Computer-Assisted;Machine Learning;Neural Networks, Computer;Phantoms, Imaging;Positron-Emission Tomography;Raclopride","11","","24","IEEE","5 Jul 2019","","","IEEE","IEEE Journals"
"Denoising and Inpainting On-Display Fingerprints Using a Novel Dilated Auto-encoder Network","S. -X. Zhuang; C. -Y. Zheng; P. -Y. Hsiao","Department of Electrical Engineering, National University of Kaohsiung, Kaohsiung, Taiwan, R.O.C.; Department of Electrical Engineering, National University of Kaohsiung, Kaohsiung, Taiwan, R.O.C.; Department of Electrical Engineering, National University of Kaohsiung, Kaohsiung, Taiwan, R.O.C.","2022 IEEE International Conference on Consumer Electronics - Taiwan","1 Sep 2022","2022","","","117","118","For on-display fingerprint (ODF) sensors, inpainting and noise removal is an important step to achieve the subsequent fingerprint recognition algorithm. This paper presents four advanced CNNs to enhance and clarify the quality of ODF images. Moreover, the pragmatic ODF databases and thinned ground truths, GTs, are used for testing and similarity verification. Experiments show that our novel dilated autoencoder CNN makes the best of the ODF image quality performance and the training efficiency.","2575-8284","978-1-6654-7050-6","10.1109/ICCE-Taiwan55306.2022.9869021","Ministry of Science and Technology, Taiwan ROC(grant numbers:108-2221-E-390-019-MY3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869021","deep learning;autoencoder;U-net;CNN;ODF sensor;fingerprint denoising and inpainting;smartphone","Training;Image quality;Deep learning;Databases;Noise reduction;Fingerprint recognition;Generative adversarial networks","cellular neural nets;computer displays;fingerprint identification;image coding;image denoising;visual databases","subsequent fingerprint recognition algorithm;advanced CNN;ODF images;pragmatic ODF databases;thinned ground truths;ODF image quality performance;noise removal;novel dilated auto encoder network;on display fingerprints;similarity verification","","","","8","IEEE","1 Sep 2022","","","IEEE","IEEE Conferences"
"Static hand gesture recognition using stacked Denoising Sparse Autoencoders","V. Kumar; G. C. Nandi; R. Kala","Robotics and Artificial Intelligence Laboratory, Indian Institute of Information Technology, Allahabad, India; Robotics and Artificial Intelligence Laboratory, Indian Institute of Information Technology, Allahabad, India; Robotics and Artificial Intelligence Laboratory, Indian Institute of Information Technology, Allahabad, India","2014 Seventh International Conference on Contemporary Computing (IC3)","15 Sep 2014","2014","","","99","104","With the advent of personal computers, humans have always wanted to communicate with them in either their natural language or by using gestures. This gave birth to the field of Human Computer Interaction and its subfield Automatic Sign Language Recognition. This paper proposes the method of automatic feature extraction of the images of hand. These extracted features are then used to train the Softmax classifier to classify them into 20 classes. Five stacked Denoising Sparse Autoencoders (DSAE) trained in unsupervised fashion are used to extract features from image. The proposed architecture is trained and tested on a standard dataset [1] which was extended by adding random jitters such as rotation and Gaussian noise. The performance of the proposed architecture is 83% which is better than shallow Neural Network trained on manual hand-engineered features called Principal Components which is used as a benchmark.","","978-1-4799-5173-4","10.1109/IC3.2014.6897155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6897155","Static hand gesture recognition;Deep learning;Autoencoders","Feature extraction;Noise reduction;Cost function;Training;Gesture recognition;Neurons;Vectors","feature extraction;human computer interaction;image classification;image denoising;neural nets;principal component analysis;sign language recognition","static hand gesture recognition;stacked denoising sparse autoencoders;human computer interaction;automatic sign language recognition;automatic feature extraction;softmax classifier training;DSAE;random jitters;shallow neural network;manual hand-engineered features;principal components","","10","","17","IEEE","15 Sep 2014","","","IEEE","IEEE Conferences"
"Radar HRRP recognition based on sparse denoising autoencoder and multi-layer perceptron deep model","H. Yan; Z. Zhang; G. Xiong; W. Yu","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, CN","2016 Fourth International Conference on Ubiquitous Positioning, Indoor Navigation and Location Based Services (UPINLBS)","9 Jan 2017","2016","","","283","288","A good feature representation of the high resolution range profile(HRRP) is important in radar automatic target recognition. In this paper, denoising autoencoder is used to automatically extract features and the output can be seen as the non-linear overcomplete representation of HRRP. Multi-layer perceptron is used as the final classifier. White Gaussian noise is added to test the robustness of our method and the results of the experiment show the efficiency of the proposed deep model.","","978-1-5090-2879-5","10.1109/UPINLBS.2016.7809986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7809986","HRRP;radar target recognition;autoencoder;deep model","Neurons;Robustness;Radar;Noise reduction;Feature extraction;Target recognition;Sensitivity","encoding;feature extraction;Gaussian noise;multilayer perceptrons;radar target recognition;signal classification;signal denoising;signal representation;white noise","high resolution range profile;radar HRRP recognition;sparse denoising autoencoder;multilayer perceptron deep model;feature representation;radar automatic target recognition;feature extraction;nonlinear overcomplete representation;white Gaussian noise","","7","","15","","9 Jan 2017","","","IEEE","IEEE Conferences"
"The Application of Deep Convolutional Denoising Autoencoder for Optical Character Recognition Preprocessing","C. Wiraatmaja; K. Gunadi; I. N. Sandjaja","Department of Informatics, Petra Christian University, Surabaya, Indonesia; Department of Informatics, Petra Christian University, Surabaya, Indonesia; Department of Informatics, Petra Christian University, Surabaya, Indonesia","2017 International Conference on Soft Computing, Intelligent System and Information Technology (ICSIIT)","18 Jan 2018","2017","","","72","77","The process of converting physical documents into digital texts generally requires a scanner tool to obtain high-quality document images. These high quality images will be read by OCR software to get digital text results. The weakness of this method is that OCR software requires a high quality document with low blur noise and no parallax in the image to have high accuracy. We developed an application to increase the document image quality with the help of Deep Convolutional Denoising Autoencoder, afterwards read by the OCR application. The final product of this program is a digital text converted from a document image which has been taken from a smartphone. There is an increase in accuracy using this application by 26.68% in a blurred image compare to standard Tesseract OCR and outperformed Simple OCR in average accuracy testing.","","978-1-4673-9899-2","10.1109/ICSIIT.2017.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8262546","deep learning;OCR;Tesseract OCR;Theano;Keras;convolutional network;autoencoder","Optical character recognition software;Training;Noise reduction;Libraries;Machine learning;Computer architecture","document image processing;image denoising;optical character recognition;text analysis","physical documents;scanner tool;high-quality document images;OCR software;digital text results;low blur noise;Deep Convolutional Denoising Autoencoder;OCR application;blurred image compare;standard Tesseract OCR;Simple OCR;optical character recognition preprocessing","","3","","16","","18 Jan 2018","","","IEEE","IEEE Conferences"
"Fully convolutional denoising autoencoder for 3D scene reconstruction from a single depth image","A. Palla; D. Moloney; L. Fanucci","Computer Vision and Machine Learing Group, Movidius/Intel, Dublin, Ireland; Computer Vision and Machine Learing Group, Movidius/Intel, Dublin, Ireland; Department of Information Engineering, University of Pisa, Italy","2017 4th International Conference on Systems and Informatics (ICSAI)","8 Jan 2018","2017","","","566","575","In this work, we propose a 3D scene reconstruction algorithm based on a fully convolutional 3D denoising autoencoder neural network. The network is capable of reconstructing a full scene from a single depth image by creating a 3D representation of it and automatically filling holes and inserting hidden elements. We exploit the fact that our neural network is capable of generalizing object shapes by inferring similarities in geometry. Our fully convolutional architecture enables the network to be unconstrained by a fixed 3D shape, and so it is capable of successfully reconstructing arbitrary scene sizes. Our algorithm was evaluated on a real word dataset of tabletop scenes acquired using a Kinect and processed using KinectFusion software in order to obtain ground truth for network training and evaluation. Extensive measurements show that our deep neural network architecture outperforms the previous state of the art both in terms of precision and recall for the scene reconstruction task. The network has been broadly profiled in terms of memory footprint, number of floating point operations, inference time and power consumption in CPU, GPU and embedded devices. Its small memory footprint and its low computation requirements enable low power, memory constrained, real time always-on embedded applications such as autonomous vehicles, warehouse robots, interactive gaming controllers and drones.","","978-1-5386-1107-4","10.1109/ICSAI.2017.8248355","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8248355","AI;CNN;Voxel;Point Cloud;Scene Reconstruction;Deep Learning;Autoencoder;Neural Network","Three-dimensional displays;Image reconstruction;Geometry;Shape;Solid modeling;Noise reduction;Training","computational geometry;image denoising;image reconstruction;image sensors;neural nets;object detection;solid modelling","fixed 3D shape;tabletop scenes;network training;deep neural network architecture;scene reconstruction task;single depth image;fully convolutional 3D denoising autoencoder neural network;object shapes;fully convolutional architecture;3D scene reconstruction;3D representation;holes automatic filling;hidden elements insertion;KinectFusion software;arbitrary scene sizes reconstruction;network evaluation;memory footprint;floating point operations;inference time;power consumption;CPU;embedded devices;GPU;autonomous vehicles;warehouse robots;interactive gaming controllers;drones","","2","","56","","8 Jan 2018","","","IEEE","IEEE Conferences"
"The research of underwater target recognition method based on deep learning","Y. Chen; X. Xu","National Key Laboratory of Science and Technology on Sonar, Hangzhou Applied Acoustics Research Institute, Hangzhou, China; National Key Laboratory of Science and Technology on Sonar, Hangzhou Applied Acoustics Research Institute, Hangzhou, China","2017 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)","1 Jan 2018","2017","","","1","5","The deep learning is a popular research direction in machine learning field now. In this paper, the deep learning algorithms are used to recognize the underwater target radiated noises. The deep belief network (DBN) model and the stacked denoising autoencoder (SDAE) model are built respectively. Then the underwater acoustic simulated data of different types of targets as well as different states of one target and experimental data of different states of one target were recognized by these models, and the support vector machine (SVM), general regression neural network (GRNN) and probabilistic neural network (PNN) are selected as the comparison algorithms. The spectrum features extracted from the target radiated noises are used as the input data of the recognition models. The results show that the recognition accuracy of DBN and that of SDAE are all higher than that of the other three methods for all situations, which shows that the deep learning algorithms can effectively improve the underwater target recognition effect.","","978-1-5386-3142-3","10.1109/ICSPCC.2017.8242464","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8242464","Deep belief network;Stacked denoising autoencoder;Underwater target recognition;Spectrum feature","Target recognition;Feature extraction;Data models;Machine learning;Underwater acoustics;Support vector machines;Training","belief networks;encoding;feature extraction;image coding;image denoising;learning (artificial intelligence);neural nets;regression analysis;support vector machines","underwater target recognition method;machine learning field;deep learning algorithms;deep belief network model;stacked denoising autoencoder model;SDAE;underwater acoustic simulated data;support vector machine;general regression neural network;probabilistic neural network;target radiated noises;recognition models;underwater target recognition effect;GRNN","","7","","15","","1 Jan 2018","","","IEEE","IEEE Conferences"
"Fault Diagnosis of Electro-mechanical Actuator Based on Deep Learning Network","N. Yang; J. Shen; Y. Jia; J. Zhang","Shandong Institute of Space Electronic Technology, Yantai, China; Shandong Institute of Space Electronic Technology, Yantai, China; Shandong Institute of Space Electronic Technology, Yantai, China; Shandong Institute of Space Electronic Technology, Yantai, China","2020 39th Chinese Control Conference (CCC)","9 Sep 2020","2020","","","4002","4006","An efficient and accurate fault diagnosis method based on deep learning network is proposed to solve the problems in the traditional fault diagnosis methods of electro-mechanical actuator (EMA). In this method, several denoising autoencoders are stacked to generate a neural network with multiple hidden layers, in which fault features are automatically extracted from original signals, getting rid of the dependence on signal processing technologies and diagnostic experiences. The greedy algorithm is adopted to carry out the pre-training of network to avoid problems of local extremum and gradient diffusion. Then, the back propagation (BP) algorithm is used to fine tune the whole network, in which the weights and biases of each layer are corrected to minimize the classification errors. The experiment results show that the fault diagnosis accuracy of the method in this paper can reach 100% with appropriate parameters, which can realize the accurate fault diagnosis of EMA.","1934-1768","978-9-8815-6390-3","10.23919/CCC50068.2020.9189666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9189666","Electro-mechanical actuator;Fault diagnosis;Deep learning;Denoising autoencoders","Fault diagnosis;Training;Machine learning;Feature extraction;Electron tubes;Brushless DC motors;Monitoring","backpropagation;control engineering computing;electromechanical actuators;fault diagnosis;feature extraction;greedy algorithms;neural nets;signal classification;signal denoising","electro-mechanical actuator;deep learning network;fault diagnosis;EMA;denoising autoencoders;neural network;multiple hidden layers;fault feature extraction;signal processing technologies;backpropagation;greedy algorithm","","1","","14","","9 Sep 2020","","","IEEE","IEEE Conferences"
"Enhanced Denoising Autoencoder-aided Bad Data Filtering for Synchrophasor-based State Estimation","G. Tian; Y. Gu; Z. Yu; Q. Zhang; D. Shi; Q. Zhou; Z. Wang","Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL, USA; GEIRI North America, San Jose, CA, USA; GEIRI North America, San Jose, CA, USA; Grid Dispatch Center, State Grid Jiangsu Electric Power Company Ltd., Nanjing, China; GEIRI North America, San Jose, CA, USA; Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL, USA; GEIRI North America, San Jose, CA, USA","CSEE Journal of Power and Energy Systems","28 Mar 2022","2022","8","2","640","651","Due to its high accuracy and ease of calculation, synchrophasor-based linear state estimation (LSE) has attracted a lot of attention in the last decade and has formed the cornerstone of many wide area monitor system (WAMS) applications. However, an increasing number of data quality concerns have been reported, among which bad data can significantly undermine the performance of LSE and many other WAMS applications it supports. Bad data filtering can be difficult in practice due to a variety of issues such as limited processing time, non-uniform and changing patterns, and etc. To pre-process phasor measurement unit (PMU) measurements for LSE, we propose an improved denoising autoencoder (DA)-aided bad data filtering strategy in this paper. Bad data is first identified by the classifier module of the proposed DA and then recovered by the autoencoder module. Two characteristics distinguish the proposed methodology: 1) The approach is lightweight and can be implemented at individual PMU level to achieve maximum parallelism and high efficiency, making it suited for real-time processing; 2) the system not only identifies bad data but also recovers it, especially for critical measurements. We use numerical experiments employing both simulated and real-world phasor data to validate and illustrate the effectiveness of the proposed method.","2096-0042","","10.17775/CSEEJPES.2020.06270","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9535418","Autoencoder;bad data processing;linear state estimation;PMU","Voltage measurement;Phasor measurement units;State estimation;Current measurement;Real-time systems;Phase measurement;Data models","data handling;pattern classification;phasor measurement;power engineering computing;power system state estimation","data quality concerns;LSE;WAMS applications;phasor measurement unit measurements;autoencoder module;enhanced denoising autoencoder-aided bad data filtering;wide area monitor system applications;synchrophasor-based linear state estimation;PMU;classifier module","","","","49","","10 Sep 2021","","","CSEE","CSEE Journals"
"Application of Denoising Autoencoder in Intelligent Fault Diagnosis for Bearings under Varying Working Conditions","H. Wen; W. Guo","School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, PR China; School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, PR China","2021 Global Reliability and Prognostics and Health Management (PHM-Nanjing)","24 Nov 2021","2021","","","1","6","Bearing fault diagnosis is an important issue and useful tool to keep the equipment safe and reliable. With sustainable progress of deep learning and the use of large-scale industrial data, intelligent fault diagnosis based on the deep learning has become one of main research directions in this field. To improve the practicability of results, the denoising autoencoder (DAE) is applied to the bearings with complex working conditions. Two experiments are conducted to compare the performances of the DAE and the stack autoencoder (SAE). In the experiments, the data from one rotation speed are used for training, and the data from different conditions, including the changes of the rotation speed, load torque, and radial force, are used for test. The results indicate that only the rotation speed may influence the classification accuracy, and its changes may lead to the misclassification of bearing health states. For the changes of the other two conditions, the DAE and SAE have high diagnosis accuracies, and the former shows better results.","","978-1-6654-0131-9","10.1109/PHM-Nanjing52125.2021.9613061","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9613061","deep learning;autoencoder;intelligent fault diagnosis;classification;bearing","Employee welfare;Fault diagnosis;Deep learning;Training;Torque;Noise reduction;Force","condition monitoring;deep learning (artificial intelligence);fault diagnosis;machine bearings;mechanical engineering computing;torque","rotation speed;DAE;denoising autoencoder;intelligent fault diagnosis;bearing health states;deep learning;large-scale industrial data;stack autoencoder;SAE;load torque;radial force","","","","23","IEEE","24 Nov 2021","","","IEEE","IEEE Conferences"
"An imbalanced data classification algorithm of improved autoencoder neural network","C. Zhang; W. Gao; J. Song; J. Jiang","College of Mathematics Inner Mongolia, University for the Nationalities, Tongliao, China; College of Computer Science and Information Technology, Northeast Normal University, Changchun, China; College of Mathematics Inner Mongolia, University for the Nationalities Tongliao, China; College of Computer Science and Technology, Inner Mongolia University for the Nationalities Tongliao, China","2016 Eighth International Conference on Advanced Computational Intelligence (ICACI)","9 Apr 2016","2016","","","95","99","Imbalanced data classification problem has always been a hotspot in the field of machine learning research. Pointing to the overfitting and noise problems of oversampling algorithm when synthesizing new minority class samples, the current study proposed a stacked denoising autoencoder neural network (SDAE) algorithm based on cost-sensitive oversampling, combining the cost-sensitive learning with denoising autoencoder neural network. The proposed algorithm can not only oversample minority class sample through misclassification cost, but it can denoise and classify the sampled dataset. Experiment shows that, compared with the traditional stacked autoencoder neural network (SAE) and oversampling autoencoder neural network without denoising process (OS-SAE), the proposed algorithm improves the classification accuracy of minority class of imbalanced datasets.","","978-1-4673-7782-9","10.1109/ICACI.2016.7449810","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449810","imbalanced data;oversampling;cost sensitive;stacked denoising autoencoder neural network;classification","Noise reduction;Biological neural networks;Classification algorithms;Training;Machine learning algorithms;Cancer","learning (artificial intelligence);neural nets;pattern classification","imbalanced data classification algorithm;machine learning;overfitting problem;noise problem;oversampling algorithm;stacked denoising autoencoder neural network;SDAE algorithm;cost-sensitive oversampling;cost-sensitive learning;misclassification cost;sampled dataset denoising;sampled dataset classification","","17","","19","","9 Apr 2016","","","IEEE","IEEE Conferences"
"Wi-Fi Signal Noise Reduction and Multipath Elimination Based on Autoencoder","L. Pi; C. Zhang; T. Xie; H. Yu; H. Wang; M. Yin","The Institute of Microelectronics, Tsinghua University, Beijing, China; Research Institute of Tsinghua University in Shenzhen, Shen Zhen, China; The Institute of Microelectronics, Tsinghua University, Beijing, China; The Institute of Automation, Chinese Academy of Sciences, Beijing, China; The Institute of Microelectronics, Tsinghua University, Beijing, China; The Institute of Microelectronics, Tsinghua University, Beijing, China","2019 IEEE International Conference on Electron Devices and Solid-State Circuits (EDSSC)","8 Jul 2019","2019","","","1","3","It is known that the signal is noisy and susceptible to multipath interference in indoor positioning, resulting in a significant error in the processing of the signal. The RSS- assisted cross-correlation (RACC) method can reduce noise and eliminate multipath interference to a certain extent, but too environmentally sensitive. Therefore, in this paper, an effective way of using the deep neural network is proposed to address this problem. Accordingly, the performance of the AutoEncoder in signal noise reduction and multipath interference elimination are discussed. To achieve better results, four AutoEncoder models are put forward, fully connection (FC), convolution plus fully connected (C-FC), convolution plus pooling (C-P), inception (ICP), and the performance of these four models are compared when processing signals with different signal to noise ratio (SNR) and multipath interference. The mean square error (MSE) and the time difference of arrival (TDoA) are the standards for evaluating the effect of signal noise reduction and multipath interference removal. Besides simulated data, we also conducted model performance comparisons in terms of ground truth signal. Experimental results show that fully connected layer is essential to automatic signal coding and the model performs better with the appropriate addition of convolution layer when faced with noise and multipath environments. Notably, compared with RACC method, the TDoA of two resultant signals obtained from the model is more accurate, verified by IEEE 802. 11b WLAN.","","978-1-7281-0286-3","10.1109/EDSSC.2019.8753922","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8753922","AutoEncoder;neural network;signal processing","","convolution;interference suppression;mean square error methods;multipath channels;neural nets;signal denoising;time-of-arrival estimation;wireless LAN","resultant signals;Wi-Fi Signal Noise Reduction;multipath elimination;cross-correlation method;multipath interference elimination;AutoEncoder models;convolution;multipath interference removal;model performance comparisons;ground truth signal;fully connected layer;automatic signal coding;multipath environments;signal to noise ratio","","","","3","","8 Jul 2019","","","IEEE","IEEE Conferences"
"Feature Decoupled Autoencoder: Semi-Supervised Learning for Image Dehazing","J. Wang; F. Wang; D. Yin","School of Information Science and Technology, University of Science and Technology of China; School of Information Science and Technology, University of Science and Technology of China; School of Information Science and Technology, University of Science and Technology of China","2022 IEEE International Conference on Multimedia and Expo (ICME)","26 Aug 2022","2022","","","01","06","Single image dehazing plays an important role in image processing. Now, most image dehazing methods only use synthetic datasets to train models which produce some poor results on the real hazy images. To solve this problem, we propose a new network named feature decoupled autoencoder which can be trained by semi-supervised learning due to the real hazy images lacking labels. Our autoencoder includes a feature decoupled encoder and a feature fusion decoder. The clear image feature and the hazy feature are decomposed by the encoder and merged by the decoder. When the hazy feature is set to 0, the decoder will produce a dehazing image relying on the clear image feature. By training on the synthetic datasets and real datasets together, our model has good dehazing ability on the real-world hazy images. On the HazeRD and SOTS, our model's performance is comparable to the state-of-the-art algorithms.","1945-788X","978-1-6654-8563-0","10.1109/ICME52920.2022.9859652","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9859652","Single Image Dehazing;Feature Decoupled Autoencoder;Semi-supervised Learning","Training;Image synthesis;Semisupervised learning;Distortion;Decoding","image denoising;image fusion;semi-supervised learning (artificial intelligence)","feature decoupled autoencoder;single image dehazing;image processing;synthetic datasets;semisupervised learning;feature fusion decoder;clear image feature;hazy feature","","","","17","IEEE","26 Aug 2022","","","IEEE","IEEE Conferences"
"Robust Monitoring and Fault Isolation of Nonlinear Industrial Processes Using Denoising Autoencoder and Elastic Net","W. Yu; C. Zhao","State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, China","IEEE Transactions on Control Systems Technology","14 Apr 2020","2020","28","3","1083","1091","Robust process monitoring and reliable fault isolation in industrial processes usually encounter different challenges, including process nonlinearity and noise interference. In this brief, a novel method denoising autoencoder and elastic net (DAE-EN) is proposed to solve the aforementioned issues by effectively integrating DAE and EN. The DAE is first trained to robustly capture the nonlinear structure of the industrial data. Then, the encoder network is updated into a sparse model using EN, so that the key variables associated with each neuron can be selected. After that two statistics are developed based on the extracted systematic structure and the retained residual information. In addition, another statistic is also constructed by combining the aforementioned two statistics to provide an overall measurement for the process sample. In this way, a robust monitoring model can be constructed to monitor the abnormal status in industrial processes. After the fault is detected, the faulty neurons are identified by the sparse exponential discriminant analysis, so that the associated faulty variables along each faulty neuron can thus be isolated. Two real industrial processes are used to validate the performance of the proposed method. Experimental results show that the proposed method can effectively detect the abnormal samples in industrial processes and accurately isolate the faulty variables from the normal ones.","1558-0865","","10.1109/TCST.2019.2897946","National Natural Science Foundation of China(grant numbers:U1709211); Zhejiang Key Research and Development Project(grant numbers:2019C03100,2019C01048); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8654023","Denoising autoencoder (DAE);elastic net (EN);fault isolation;kernel density estimation (KDE);process monitoring","Monitoring;Kernel;Principal component analysis;Data mining;Neurons;Feature extraction;Noise reduction","fault diagnosis;neural nets;process monitoring;production engineering computing;statistical analysis","sparse exponential discriminant analysis;fault detection;abnormal status monitoring;statistics;sparse model;encoder network;DAE-EN method;faulty neuron;robust monitoring model;industrial data;nonlinear structure;noise interference;process nonlinearity;reliable fault isolation;robust process monitoring;elastic net;denoising autoencoder;nonlinear industrial processes","","56","","42","IEEE","27 Feb 2019","","","IEEE","IEEE Journals"
"Exploring multi-channel features for denoising-autoencoder-based speech enhancement","S. Araki; T. Hayashi; M. Delcroix; M. Fujimoto; K. Takeda; T. Nakatani","NTT Communication Science Laboratories, Soraku-gun, Kyoto, Japan; Department of Media Science, Nagoya University 1 Furo-cho Chikusa-ku, Nagoya-shi, Aichi, Japan; NTT Communication Science Laboratories, Soraku-gun, Kyoto, Japan; NTT Communication Science Laboratories, Soraku-gun, Kyoto, Japan; Department of Media Science, Nagoya University 1 Furo-cho Chikusa-ku, Nagoya-shi, Aichi, Japan; NTT Communication Science Laboratories, Soraku-gun, Kyoto, Japan","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","6 Aug 2015","2015","","","116","120","This paper investigates a multi-channel denoising autoencoder (DAE)-based speech enhancement approach. In recent years, deep neural network (DNN)-based monaural speech enhancement and robust automatic speech recognition (ASR) approaches have attracted much attention due to their high performance. Although multi-channel speech enhancement usually outperforms single channel approaches, there has been little research on the use of multi-channel processing in the context of DAE. In this paper, we explore the use of several multi-channel features as DAE input to confirm whether multi-channel information can improve performance. Experimental results show that certain multi-channel features outperform both a monaural DAE and a conventional time-frequency-mask-based speech enhancement method.","2379-190X","978-1-4673-6997-8","10.1109/ICASSP.2015.7177943","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7177943","Deep learning;denoising autoencoder;multi-channel noise suppression;PASCAL ‘CHiME’ challenge","Noise reduction;Training;Testing;Filter banks;Artificial neural networks","interference suppression;speech coding;speech enhancement","multi-channel denoising autoencoder-based speech enhancement approach;multi-channel DAE-based speech enhancement approach;deep neural network-based monaural speech enhancement;DNN-based monaural speech enhancement;robust automatic speech recognition approaches;ASR;multi-channel speech enhancement;multi-channel processing;multi-channel information","","55","","25","","6 Aug 2015","","","IEEE","IEEE Conferences"
"A Pythagorean-Type Fuzzy Deep Denoising Autoencoder for Industrial Accident Early Warning","Y. -J. Zheng; S. -Y. Chen; Y. Xue; J. -Y. Xue","College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; School of Computer Science and Engineering, Tianjin University of Science and Technology, Tianjin, China; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China; Jiangxi Provincial Laboratory of High-Performance Computing, Jiangxi Normal University, Nanchang, China","IEEE Transactions on Fuzzy Systems","29 Nov 2017","2017","25","6","1561","1575","Early warning is crucial for preventing industrial accidents and mitigating damage, but current methods are often time-consuming, error-prone, and incompetent to deal with uncertainty. This paper presents a fuzzy deep neural network for early warning of industrial accidents, which equips the classical deep denoising autoencoder (DDAE) model with Pythagorean-type fuzzy parameters in order to enhance the model's representation ability and robustness. To efficiently train the fuzzy deep model, we propose a hybrid algorithm combining Hessian-free optimization and biogeography-based optimization metaheuristic to balance global search and local search. Experiments on datasets from several industrial zones in China show that the proposed Pythagorean-type fuzzy DDAE (PFDDAE) can achieve much higher accuracy of accident risk classification than the classical DDAE and the fuzzy DDAE using regular fuzzy parameters, and the proposed hybrid learning algorithm exhibits significant performance advantage over some other learning algorithms in training PFDDAE. In particular, a test on the 2014 Kunshan aluminum dust explosion accident shows that the deep learning model would be very likely to prevent the accident if it was adopted in advance.","1941-0034","","10.1109/TFUZZ.2017.2738605","National Natural Science Foundation of China(grant numbers:61325019,61472167,61473263,U1509207); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007290","Accident early warning;biogeography-based optimization (BBO);deep denoising autoencoder (DDAE);deep learning;evolutionary learning;pythagorean fuzzy set (PFS)","Noise reduction;Fuzzy sets;Industrial accidents;Uncertainty;Machine learning;Explosions","accident prevention;dust;emergency management;fuzzy set theory;industrial accidents;learning (artificial intelligence);neural nets;optimisation","accident risk classification;classical DDAE;regular fuzzy parameters;2014 Kunshan aluminum dust explosion accident;deep learning model;industrial accident;early warning;classical deep denoising autoencoder model;Pythagorean-type fuzzy parameters;fuzzy deep model;Hessian-free optimization;global search;local search;industrial zones;Pythagorean-type fuzzy DDAE;Pythagorean-type fuzzy deep neural network","","39","","75","IEEE","10 Aug 2017","","","IEEE","IEEE Journals"
"Whispered Speech Recognition Using Deep Denoising Autoencoder and Inverse Filtering","Đ. T. Grozdić; S. T. Jovičić","School of Electrical Engineering, University of Belgrade, Belgrade, Serbia; School of Electrical Engineering, University of Belgrade, Belgrade, Serbia","IEEE/ACM Transactions on Audio, Speech, and Language Processing","23 Nov 2017","2017","25","12","2313","2322","Due to the profound differences between acoustic characteristics of neutral and whispered speech, the performance of traditional automatic speech recognition (ASR) systems trained on neutral speech degrades significantly when whisper is applied. In order to deeply analyze this mismatched train/test situation and to develop an efficient way for whisper recognition, this study first analyzes acoustic characteristics of whispered speech, addresses the problems of whispered speech recognition in mismatched conditions, and then proposes a new robust cepstral features and preprocessing approach based on deep denoising autoencoder (DDAE) that enhance whisper recognition. The experimental results confirm that Teager-energy-based cepstral features, especially TECCs, are more robust and better whisper descriptors than traditional Mel-frequency cepstral coefficients (MFCC). Further detailed analysis of cepstral distances, distributions of cepstral coefficients, confusion matrices, and experiments with inverse filtering, prove that voicing in speech stimuli is the main cause of word misclassification in mismatched train/test scenarios. The new framework based on DDAE and TECC feature, significantly improves whisper recognition accuracy and outperforms traditional MFCC and GMM-HMM (Gaussian mixture density-Hidden Markov model) baseline, resulting in an absolute 31% improvement of whisper recognition accuracy. The achieved word recognition rate in neutral/whisper scenario is 92.81%.","2329-9304","","10.1109/TASLP.2017.2738559","Serbian Ministry of Education; Science and Technological Development(grant numbers:TR 32032,OI 178027); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114355","Automatic speech recognition;deep denoising autoencoder;inverse filtering;Teager-energy operator;whispered speech recognition","Biology;Speech recognition;Inverse filtering;Automatic speech recognition;Noise levels;Encoding;Mel frequency cepstral coefficient;Character recognition","cepstral analysis;filtering theory;Gaussian processes;hidden Markov models;speech recognition","whispered speech recognition;deep denoising autoencoder;inverse filtering;robust cepstral features;traditional Mel-frequency cepstral coefficients;speech stimuli;neutral/whisper scenario;automatic speech recognition systems;neutral speech;word recognition","","26","","38","IEEE","23 Nov 2017","","","IEEE","IEEE Journals"
"A Cross-Domain Stacked Denoising Autoencoders for Rotating Machinery Fault Diagnosis Under Different Working Conditions","S. Pang; X. Yang","College of Information and Electrical Engineering, Ludong University, Yantai, China; Aeronautical Foundation College, Naval Aeronautical University, Yantai, China","IEEE Access","24 Jun 2019","2019","7","","77277","77292","In fault diagnosis of rotating machinery, the shift in domain distributions caused by working condition fluctuations poses a major obstacle for accurate diagnosis. Due to the lack of domain adaptation ability, the diagnosis performance of existing deep learning-based methods degrades significantly when confronting other unseen working conditions. To address this problem, we develop a cross-domain stacked denoising autoencoders (CD-SDAE) with a new adaptation training strategy. Taking advantages from both domain adaptation and manifold learning, the adaptation training strategy consists of two successive paradigms: 1) unsupervised adaptation pre-training to correct marginal distribution mismatch and 2) semi-supervised manifold regularized fine-tuning to minimize conditional distribution distance between domains. In this way, the marginal distributions between the source and target domains are first matched. Then, on this basis, the conditional distributions can be matched more effectively thus makes the model become more adaptable to the target domain. The CD-SDAE is evaluated on gearbox and engine rolling bearing fault datasets. The experimental results show that CD-SDAE is superior to not only conventional deep learning method but also state-of-the-art deep domain adaptation method in terms of diagnostic accuracy.","2169-3536","","10.1109/ACCESS.2019.2919535","ZR2016FQ19; National Natural Science Foundation of China(grant numbers:61873117); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8723430","Fault diagnosis;rotating machinery;stacked denoising autoencoders (SDAE);domain adaption;manifold learning","Employee welfare;Adaptation models;Feature extraction;Manifolds;Fault diagnosis;Training","condition monitoring;fault diagnosis;mechanical engineering computing;rolling bearings;supervised learning;unsupervised learning;vibrational signal processing","cross-domain stacked denoising autoencoders;rotating machinery fault diagnosis;domain distributions;condition fluctuations;domain adaptation ability;diagnosis performance;deep learning-based methods;CD-SDAE;adaptation training strategy;manifold learning;marginal distribution mismatch;conditional distribution distance;target domains;target domain;working conditions;source domains;deep domain adaptation method","","24","","54","OAPA","28 May 2019","","","IEEE","IEEE Journals"
"Stacked Denoising Autoencoder With Density-Grid Based Clustering Method for Detecting Outlier of Wind Turbine Components","Z. Sun; H. Sun","School of Artificial Intelligence, Hebei University of Technology, Tianjin, China; School of Artificial Intelligence, Hebei University of Technology, Tianjin, China","IEEE Access","5 Feb 2019","2019","7","","13078","13091","Different types of outliers have existed in the monitoring data of wind turbines, which are not conducive to the follow-up data mining. However, the complex inner characteristics of the monitoring data pose major challenges to detect the outliers. To address this problem, an unsupervised outlier detection approach combining stacked denoising autoencoder (SDAE) and density-grid-based clustering method is proposed. First, the characteristics of the outliers in supervisory control and data acquisition data caused by different reasons are analyzed. Then, the SDAE is utilized to extract features by training the original data. Furthermore, the density-grid-based clustering method is applied to achieve the clustering results. Window width is added to classify the outliers as isolated outliers, missing data, and fault data according to the duration of abnormal data. The monitoring data of four wind turbines are sampled as the training data to demonstrate the effectiveness of the proposed method. The results show that the proposed model can effectively identify the isolated outliers, missing data, and fault information in the high dimensional data set by unsupervised learning.","2169-3536","","10.1109/ACCESS.2019.2893206","Hebei Province Science and Technology Plan Project: Construction and Application of Wind Power “Smart Capsule” Cloud Management Platform Based on Big Data Technology(grant numbers:17214304D); Natural Science Foundation of Hebei Province(grant numbers:F2018202206); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8620681","Density-grid based clustering;outlier detection;stacked denoising autoencoder;unsupervised learning","Wind turbines;Distributed databases;Anomaly detection;Noise reduction;Clustering methods;Monitoring;Feature extraction","data mining;fault diagnosis;feature extraction;pattern clustering;power engineering computing;SCADA systems;unsupervised learning;wind power plants;wind turbines","wind turbines;data mining;complex inner characteristics;unsupervised outlier detection approach;isolated outliers;fault data;abnormal data;training data;high dimensional data;stacked denoising autoencoder;wind turbine components;density-grid-based clustering method;monitoring data;SDAE;outlier characteristics;supervisory control and data acquisition;feature extraction;high dimensional data set;unsupervised learning","","20","","21","OAPA","21 Jan 2019","","","IEEE","IEEE Journals"
"DDSA: A Defense Against Adversarial Attacks Using Deep Denoising Sparse Autoencoder","Y. Bakhti; S. A. Fezza; W. Hamidouche; O. Déforges","INSA Rennes, CNRS, IETR - UMR CNRS 6164, Université de Rennes, Rennes, France; National Institute of Telecommunications and ICT, Oran, Algeria; IRT b<>com, Cesson-Sévigné, France; INSA Rennes, CNRS, IETR - UMR CNRS 6164, Université de Rennes, Rennes, France","IEEE Access","11 Nov 2019","2019","7","","160397","160407","Given their outstanding performance, the Deep Neural Networks (DNNs) models have been deployed in many real-world applications. However, recent studies have demonstrated that they are vulnerable to small carefully crafted perturbations, i.e., adversarial examples, which considerably decrease their performance and can lead to devastating consequences, especially for safety-critical applications, such as autonomous vehicles, healthcare and face recognition. Therefore, it is of paramount importance to offer defense solutions that increase the robustness of DNNs against adversarial attacks. In this paper, we propose a novel defense solution based on a Deep Denoising Sparse Autoencoder (DDSA). The proposed method is performed as a pre-processing step, where the adversarial noise of the input samples is removed before feeding the classifier. The pre-processing defense block can be associated with any classifier, without any change to their architecture or training procedure. In addition, the proposed method is a universal defense, since it does not require any knowledge about the attack, making it usable against any type of attack. The experimental results on MNIST and CIFAR-10 datasets have shown that the proposed DDSA defense provides a high robustness against a set of prominent attacks under white-, gray- and black-box settings, and outperforms state-of-the-art defense methods.","2169-3536","","10.1109/ACCESS.2019.2951526","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890816","Deep neural network;security;adversarial attacks;defense;sparse autoencoder;denoising","Perturbation methods;Noise reduction;Training;Neural networks;Robustness;Training data","learning (artificial intelligence);neural nets;pattern classification;security of data","MNIST datasets;CIFAR-10 datasets;white-box setting;gray-box setting;black-box settings;deep denoising sparse autoencoder;deep neural networks models;defense methods;DDSA defense;universal defense;pre-processing defense block;adversarial noise;adversarial attacks;defense solution;safety-critical applications;real-world applications","","18","","34","CCBY","4 Nov 2019","","","IEEE","IEEE Journals"
"Stacked Denoising Autoencoders for Mortality Risk Prediction Using Imbalanced Clinical Data","Z. Alhassan; D. Budgen; R. Alshammari; T. Daghstani; A. S. McGough; N. Al Moubayed","Department of Computer Science, Durham University, Durham, United Kingdom; Department of Computer Science, Durham University, Durham, United Kingdom; KSAU for Health Sciences, Public Health and Health Informatics, Riyadh, Saudi Arabia; KSAU for Health Sciences, College of Public Health and Health Informatics, Riyadh, Saudi Arabia; Newcastle University, Newcastle upon Tyne, Tyne and Wear, GB; Department of Computer Science, Durham University, Durham, United Kingdom","2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)","17 Jan 2019","2018","","","541","546","Clinical data, such as evaluations, treatments, vital sign and lab test results, are usually observed and recorded in hospital systems. Making use of such data to help physicians to evaluate the mortality risk of in-hospital patients provides an invaluable source of information that can ultimately help with improving healthcare services. In particular, quick and accurate predictions of mortality can be valuable for physicians who are making decisions about interventions. In this work we introduce the use of a predictive Deep Learning model to help evaluate the mortality risk for in-hospital patients. Stacked Denoising Autoencoder (SDA) has been trained using a unique time-stamped dataset (King Abdullah International Research Center – KAIMRC) which is naturally imbalanced. The results are compared to those from common deep learning approaches, using different methods for data balancing. The proposed model demonstrated here aims to overcome the problem of imbalanced data, and outperforms common deep learning approaches with an accuracy of 77.13% for the Recall macro","","978-1-5386-6805-4","10.1109/ICMLA.2018.00087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8614112","Mortality risk, Deep Learning, Stacked Denoising Autoencoder, King Abdullah International Research Center, Data Imbalance, Recall Macro","Predictive models;Data models;Deep learning;Neural networks;Hospitals","data analysis;decision making;health care;hospitals;learning (artificial intelligence);medical computing;neural nets;patient monitoring;risk management","decision making;KAIMRC;deep learning model;King Abdullah International Research Center;stacked denoising autoencoders;clinical data;healthcare services;hospital systems;mortality risk prediction;data balancing;in-hospital patients","","9","","28","","17 Jan 2019","","","IEEE","IEEE Conferences"
"Hybrid Speech Enhancement with Wiener filters and Deep LSTM Denoising Autoencoders","M. Coto-Jimenez; J. Goddard-Close; L. Di Persia; H. Leonardo Rufiner","Pattern Recognition and Intelligent Systems Lab (PRIS-Lab), Universidad de Costa Rica, San Jose, Costa Rica; Departamento de Ingenieria Electrica, Universidad Autonoma Metropolitana, Mexico City, Mexico; Sistemas e Inteligencia Computacional, sinc(i), Instituto de Investigacion en Senales, Santa Fe, Argentina; FICH-UNL-CONICET & Facultad de Ingenieria, UNER, Oro Verde, Sistemas e Inteligencia Computacional, sinc(i) & Laboratorio de Cibernetica, Entre Rios, Argentina","2018 IEEE International Work Conference on Bioinspired Intelligence (IWOBI)","13 Sep 2018","2018","","","1","8","Over the past several decades, numerous speech enhancement techniques have been proposed to improve the performance of modern communication devices in noisy environments. Among them, there is a large range of classical algorithms (e.g. spectral subtraction, Wiener filtering and Bayesian-based enhancement), and more recently several deep neural network-based. In this paper, we propose a hybrid approach to speech enhancement which combines two stages: In the first stage, the well-known Wiener filter performs the task of enhancing noisy speech. In the second stage, a refinement is performed using a new multi-stream approach, which involves a collection of denoising autoencoders and auto-associative memories based on Long Short-term Memory (LSTM) networks. We carry out a comparative performance analysis using two objective measures, using artificial noise added at different signal-to-noise levels. Results show that this hybrid system improves the signal's enhancement significantly in comparison to the Wiener filtering and the LSTM networks separately.","","978-1-5386-7506-9","10.1109/IWOBI.2018.8464132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8464132","Deep learning;Denoising autoencoders;LSTM;Signal processing","Speech enhancement;Noise measurement;Training;Noise reduction;Speech recognition;Databases;Mel frequency cepstral coefficient","Bayes methods;content-addressable storage;neural nets;speech enhancement;Wiener filters","long short-term memory networks;spectral subtraction;signals enhancement;auto-associative memories;LSTM networks;deep neural network-based;Bayesian-based enhancement;noisy environments;modern communication devices;deep LSTM denoising autoencoders;Wiener filter;hybrid speech enhancement","","7","","40","","13 Sep 2018","","","IEEE","IEEE Conferences"
"Examining the Mapping Functions of Denoising Autoencoders in Singing Voice Separation","S. I. Mimilakis; K. Drossos; E. Cano; G. Schuller","Semantic Music Technologies Group, Fraunhofer IDMT, Ilmenau, Germany; Audio Research Group, Tampere University, Tampere, Finland; Semantic Music Technologies Group, Fraunhofer IDMT, Ilmenau, Germany; Technical University of Ilmenau, Germany","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20 Dec 2019","2020","28","","266","278","The goal of this article is to investigate what singing voice separation approaches based on neural networks learn from the data. We examine the mapping functions of neural networks based on the denoising autoencoder (DAE) model that are conditioned on the mixture magnitude spectra. To approximate the mapping functions, we propose an algorithm inspired by the knowledge distillation, denoted the neural couplings algorithm (NCA). The NCA yields a matrix that expresses the mapping of the mixture to the target source magnitude information. Using the NCA, we examine the mapping functions of three fundamental DAE-based models in music source separation; one with single-layer encoder and decoder, one with multi-layer encoder and single-layer decoder, and one using skip-filtering connections (SF) with a single-layer encoding and decoding. We first train these models with realistic data to estimate the singing voice magnitude spectra from the corresponding mixture. We then use the optimized models and test spectral data as input to the NCA. Our experimental findings show that approaches based on the DAE model learn scalar filtering operators, exhibiting a predominant diagonal structure in their corresponding mapping functions, limiting the exploitation of inter-frequency structure of music data. In contrast, skip-filtering connections are shown to assist the DAE model in learning filtering operators that exploit richer inter-frequency structures.","2329-9304","","10.1109/TASLP.2019.2952013","European Union's H2020 Framework Programme(grant numbers:H2020-MSCA-ITN-2014,642685); German Research Foundation(grant numbers:AB 675/2-1,MU 2686/11-1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8892665","Music source separation;singing voice;denoising autoencoder;DAE;skip connections;neural couplings algorithm;NCA","Source separation;Computational modeling;Noise reduction;Neural networks;Approximation algorithms;Multiple signal classification;Decoding","acoustic signal processing;audio signal processing;blind source separation;filtering theory;learning (artificial intelligence);music;neural nets;optimisation","single-layer decoder;skip-filtering connections;singing voice magnitude spectra;NCA;mapping functions;singing voice separation approaches;neural networks;denoising autoencoder model;mixture magnitude spectra;neural couplings algorithm;target source magnitude information;music source separation;single-layer encoder;multilayer encoder;knowledge distillation;DAE-based models","","7","","47","IEEE","6 Nov 2019","","","IEEE","IEEE Journals"
"Leveraging Stacked Denoising Autoencoder in Prediction of Pathogen-Host Protein-Protein Interactions","H. Chen; J. Shen; L. Wang; J. Song","School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; Department of Biochemistry and Molecular Biology, Monash University, Melbourne, Victoria, Australia","2017 IEEE International Congress on Big Data (BigData Congress)","11 Sep 2017","2017","","","368","375","In big data research related to bioinformatics, one of the most critical areas is proteomics. In this paper, we focus on the protein-protein interactions, especially on pathogen-host protein-protein interactions (PHPPIs), which reveals the critical molecular process in biology. Conventionally, biologists apply in-lab methods, including small-scale biochemical, biophysical, genetic experiments and large-scale experiment methods (e.g. yeast-two-hybrid analysis), to identify the interactions. These in-lab methods are time consuming and labor intensive. Since the interactions between proteins from different species play very critical roles for both the infectious diseases and drug design, the motivation behind this study is to provide a basic framework for biologists, which is based on big data analytics and deep learning models. Our work contributes in leveraging unsupervised learning model, in which we focus on stacked denoising autoencoders, to achieve a more efficient prediction performance on PHPPI. In this paper, we further detail the framework based on unsupervised learning model for PHPPI researches, while curating a large imbalanced PHPPI dataset. Our model demonstrates a better result with the unsupervised learning model on PHPPI dataset.","","978-1-5386-1996-4","10.1109/BigDataCongress.2017.54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8029347","big data;PHPPI;denoising autoencoder;prediction;machine learning","Proteins;Biological system modeling;Data models;Predictive models;Unsupervised learning;Amino acids","Big Data;bioinformatics;proteins","pathogen-host protein-protein interactions;Big Data research;bioinformatics;critical molecular process;biology;in-lab methods;infectious diseases;drug design;Big Data analytics;deep learning models;unsupervised learning model;stacked denoising autoencoders;PHPPI researches;imbalanced PHPPI dataset","","7","","34","","11 Sep 2017","","","IEEE","IEEE Conferences"
"A Novel Acoustic Emission Sources Localization and Identification Method in Metallic Plates Based on Stacked Denoising Autoencoders","L. Yang; F. Xu","School of Mechanical Engineering, Southeast University, Nanjing, China; School of Mechanical Engineering, Southeast University, Nanjing, China","IEEE Access","10 Aug 2020","2020","8","","141123","141142","Nowadays, deep learning could be an alternative approach to crack characterization. However, to the best of the authors' knowledge, little research exists on a deep learning-based characterization of fatigue-related AE sources occurring in plate-like structures. Consequently, this paper introduces a stacked denoising autoencoders (SDAE)-based framework to localize acoustic emission (AE) sources in common and complex metallic panels. The experimental specimen are respectively a Q235B steel plate and a 316L stainless steel containing a laser cladding layer. Specifically, SDAE is pre-trained and utilized to localize AE sources that are simulated by using the classical pencil lead break (PLB) approach. Meanwhile, the number of layers and hidden nodes of SDAE used for coordinate-based location is optimized according to a Bayesian Information Criteria (BIC) approach. To validate the proposed network and simplify the analysis, experiments are carried out on the surface of plate-like structures, which only one sensor is applied. After identifying AE sources that occur near laser cladding layers, the proposed approach classifies them into four source-to-laser cladding layer distance categories. Particularly, a ten-fold cross-validation method is utilized to improve the accuracy of localization in this paper. Moreover, the effectiveness analysis to the number of sensors and comparison with conventional machine learning methods, including support vector machine (SVM) and artificial neural network (ANN), are also evaluated. In order to validate the performance of the proposed approach in terms of coordinate-based source localization. Ultimately, the results demonstrate that 100% accuracy for zonal localization, and the root mean squared (RMS) localization errors of two metallic panels are 38 mm (1.5”) and 48 mm (1.9”), respectively. Additionally, in comparison with conventional machine learning approaches (i.e. SVM and ANN) which the RMS errors were 78 mm (2.5”) and 67 mm (2.1”), respectively, the coordinates-based localization accuracy is significantly improved using the proposed approach. The results demonstrate the proposed approach is effective in AE-based structural health monitoring of plate-like structures with single-sensor.","2169-3536","","10.1109/ACCESS.2020.3012521","National Natural Science Foundation of China(grant numbers:51975117); Postgraduate Research and Practice Innovation Program of Jiangsu Province, China(grant numbers:KYCX20_0078); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9151142","Acoustic emission (AE);sources localization and identification;stacked denoising autoencoders (SDAE);metallic steel plates;structural health monitoring","Machine learning;Steel;Feature extraction;Signal processing algorithms;Lasers;Neural networks;Support vector machines","acoustic emission;acoustic emission testing;Bayes methods;condition monitoring;cracks;learning (artificial intelligence);neural nets;plates (structures);stainless steel;steel;structural engineering computing;support vector machines","Bayesian information criteria approach;coordinate-based localization accuracy;stacked denoising autoencoder-based framework;pencil lead break approach;316L stainless steel;Q235B steel plate;complex metallic panels;common panels;acoustic emission sources;SDAE;fatigue-related AE sources;deep learning-based characterization;metallic plates;AE-based structural health monitoring;machine learning approaches;zonal localization;coordinate-based source localization;artificial neural network;support vector machine;cross-validation method;source-to-laser cladding layer distance categories;plate-like structures;coordinate-based location;size 48.0 mm;size 38.0 mm;size 67.0 mm;size 78.0 mm","","5","","52","CCBY","28 Jul 2020","","","IEEE","IEEE Journals"
"Mood detection from daily conversational speech using denoising autoencoder and LSTM","K. -Y. Huang; C. -H. Wu; M. -H. Su; H. -C. Fu","Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan","2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","19 Jun 2017","2017","","","5125","5129","In current studies, an extended subjective self-report method is generally used for measuring emotions. Even though it is commonly accepted that speech emotion perceived by the listener is close to the intended emotion conveyed by the speaker, research has indicated that there still remains a mismatch between them. In addition, the individuals with different personalities generally have different emotion expressions. Based on the investigation, in this study, a support vector machine (SVM)-based emotion model is first developed to detect perceived emotion from daily conversational speech. Then, a denoising autoencoder (DAE) is used to construct an emotion conversion model to characterize the relationship between the perceived emotion and the expressed emotion of the subject for a specific personality. Finally, a long short-term memory (LSTM)-based mood model is constructed to model the temporal fluctuation of speech emotions for mood detection. Experimental results show that the proposed method achieved a detection accuracy of 64.5%, improving by 5.0% compared to the HMM-based method.","2379-190X","978-1-5090-4117-6","10.1109/ICASSP.2017.7953133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7953133","Long-term emotion tracking;mood detection;denoising autoencoder;long short-term memory","Mood;Hidden Markov models;Databases;Speech;Predictive models;Support vector machines;Emotion recognition","emotion recognition;recurrent neural nets;speech processing;support vector machines","mood detection;daily conversational speech;denoising autoencoder;LSTM;long short-term memory;speech emotion;emotion expression;SVM-based emotion model;support vector machine;DAE;emotion conversion model;temporal fluctuation","","5","","19","","19 Jun 2017","","","IEEE","IEEE Conferences"
"Self-Supervised Denoising Autoencoder with Linear Regression Decoder for Speech Enhancement","R. E. Zezario; T. Hussain; X. Lu; H. -M. Wang; Y. Tsao","Research Center for Information Technology Innovation, Academia Sinica, Taiwan; Taiwan International Graduate Program in Social Network and Human-Centered Computing, Institute of Information Science, Academia Sinica, Taiwan; National Institute of Information and Communications Technology, Japan; Institute of Information Science, Academia Sinica, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taiwan","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","6669","6673","Nonlinear spectral mapping-based models based on supervised learning have successfully applied for speech enhancement. However, as supervised learning approaches, a large amount of labelled data (noisy-clean speech pairs) should be provided to train those models. In addition, their performances for unseen noisy conditions are not guaranteed, which is a common weak point of supervised learning approaches. In this study, we proposed an unsupervised learning approach for speech enhancement, i.e., denoising autoencoder with linear regression decoder (DAELD) model for speech enhancement. The DAELD is trained with noisy speech as both input and target output in a self-supervised learning manner. In addition, with properly setting a shrinkage threshold for internal hidden representations, noise could be removed during the reconstruction from the hidden representations via the linear regression decoder. Speech enhancement experiments were carried out to test the proposed model. Results confirmed that the proposed DAELD could achieve comparable and sometimes even better enhancement performance as compared to the conventional supervised speech enhancement approaches, in both seen and unseen noise environments. Moreover, we observe that higher performances tend to achieve by DAELD when the training data cover more diverse noise types and signal-tonoise-ratio (SNR) levels.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9053925","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9053925","speech enhancement;deep denoising autoencoder;unsupervised learning","Linear regression;Supervised learning;Noise reduction;Speech enhancement;Decoding;Noise measurement;Task analysis","decoding;neural nets;regression analysis;signal classification;speech enhancement;unsupervised learning","nonlinear spectral mapping-based models;supervised learning approaches;noisy-clean speech pairs;unsupervised learning approach;linear regression decoder model;self-supervised learning manner;conventional supervised speech enhancement approach;signal-to-noise ratio;denoising autoencoder with linear regression decoder;DAELD model","","5","","45","","9 Apr 2020","","","IEEE","IEEE Conferences"
"CLPM: A Cooperative Link Prediction Model for Industrial Internet of Things Using Partitioned Stacked Denoising Autoencoder","L. Rui; Y. Zhu; Z. Gao; X. Qiu","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Transactions on Industrial Informatics","23 Feb 2021","2021","17","5","3620","3629","With the development of Industry 4.0, an increasing number of industrial Internet of Things (IIoT) mobile devices (MD), which constantly transmit data at any time, are working on the production line. However, due to node movement, signal attenuation, or physical obstacles, data must rely on the transmission of relay nodes to finally reach the destination node. Based on this scenario, in this article, we propose a cooperative link prediction model (CLPM) using a stacked denoising autoencoder (SDAE) to predict links of the IIoT-based MDs at the next moment through historical link information. The layer structure of the SDAE model is partitioned so that the local MD and edge servers can cooperatively process the link prediction tasks. Experimental results show that our proposed CLPM outperforms others in terms of prediction performance and execution delay.","1941-0050","","10.1109/TII.2020.2999318","National Key R&D Program of China(grant numbers:2018YFE0205502); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9105066","Industrial Internet of Things (IIoT);link prediction;stacked denoising autoencoder (SDAE)","Delays;Ions;Predictive models;Deep learning;Servers;Task analysis","Internet of Things;learning (artificial intelligence);neural nets;production engineering computing","CLPM;link prediction model;partitioned stacked denoising autoencoder;production line;signal attenuation;relay nodes;destination node;IIoT-based MDs;historical link information;SDAE model;link prediction tasks;prediction performance;execution delay;mobile devices;Industry 4.0","","4","","37","IEEE","1 Jun 2020","","","IEEE","IEEE Journals"
"Direction-of-Arrival Estimation in the Low-SNR Regime via a Denoising Autoencoder","G. K. Papageorgiou; M. Sellathurai","School of Engineering and Physical Sciences, Heriot-Watt University, Edinburgh, UK; School of Engineering and Physical Sciences, Heriot-Watt University, Edinburgh, UK","2020 IEEE 21st International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)","3 Aug 2020","2020","","","1","5","The performance of covariance-based DoA estimation methods is limited in practice, particularly in the low signal-to-noise ratio (SNR) regime, due to the finite number of observations. In this work, we approach the direction-of-arrival (DoA) estimation in the presence of extreme noise from the Machine Learning (ML) perspective using Deep Learning (DL). First, we derive a relation between the covariance matrix and its sample estimate formulating the problem as a manifold learning task. Next, we train a denoising autoencoder (DAE) that predicts a Hermitian matrix, which is subsequently used for the DoA estimation. Experimental results demonstrate significant performance gains in terms of the root-mean-squared error (RMSE) in the low-SNR regime by using popular covariance-based DoA estimators. Nevertheless, the proposed method runs independent of the DoA estimator, opening up new possibilities for the testing of other methods as well. We believe that the proposed approach has several applications, ranging from wireless array sensors to microphones and transducers used in ultrasound imaging, where the operating environments are characterized by extreme noise.","1948-3252","978-1-7281-5478-7","10.1109/SPAWC48557.2020.9154221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9154221","Direction-of-arrival DoA estimation;deep learning;denoising autoencoder DAE;DoA estimation at low-SNR;array processing with uniform linear arrays ULAs","Direction-of-arrival estimation;Estimation;Covariance matrices;Manifolds;Wireless communication;Noise reduction","covariance analysis;covariance matrices;direction-of-arrival estimation;learning (artificial intelligence);mean square error methods","Hermitian matrix;root-mean-squared error;low-SNR regime;popular covariance-based DoA estimators;DoA estimator;extreme noise;direction-of-arrival estimation;denoising autoencoder;covariance-based DoA estimation methods;low signal-to-noise ratio;Deep Learning;covariance matrix;sample estimate;manifold learning task","","4","","20","","3 Aug 2020","","","IEEE","IEEE Conferences"
"Research of 3D face recognition algorithm based on deep learning stacked denoising autoencoder theory","J. Zhang; Z. Hou; Z. Wu; Y. Chen; W. Li","College of Information, Changzhou University, Changzhou, China; College of Information, Changzhou University, Changzhou, China; College of Information, Changzhou University, Changzhou, China; College of Information, Changzhou University, Changzhou, China; College of Information, Changzhou University, Changzhou, China","2016 8th IEEE International Conference on Communication Software and Networks (ICCSN)","10 Oct 2016","2016","","","663","667","This electronic Due to the fact that the 3D face depth data have more information, the 3D face recognition is attracting more and more attention in the machine learning area. Firstly, this paper selects 30 feature points from the 113 feature points of Candide-3 face model to characterize face, which improves the efficiency of recognition algorithm obviously without affecting the recognition accuracy. With the significant advantage of the characterization of essential features by learning a deep nonlinear network, this paper presents a stacked denoising autoencoder algorithm model based on deep learning which improves neural networks model. This algorithm conducts the unsupervised preliminary training of face depth data and the supervised training to fine-tuning the network which is better than neural network's random initialization. The experiment indicates that compared with real face data, the reconstruction face model has a small matching error by using SDAE algorithm and it achieves an excellent face recognition effect.","","978-1-5090-1781-2","10.1109/ICCSN.2016.7586606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586606","3D face depth data;deep learning;neural networks;stacked denoising autoencoder;unsupervised preliminary training","Face;Face recognition;Three-dimensional displays;Training;Analytical models;Data models;Machine learning","face recognition;learning (artificial intelligence)","3D face recognition algorithm;deep learning;machine learning;Candide-3 face model;stacked denoising autoencoder algorithm model;supervised training","","4","","18","","10 Oct 2016","","","IEEE","IEEE Conferences"
"HFO Detection in Epilepsy: A Stacked Denoising Autoencoder and Sample Weight Adjusting Factors-Based Method","M. Wu; H. Qin; X. Wan; Y. Du","Engineering Research Center of Intelligent Technology for Geo-Exploration, Ministry of Education, Wuhan, China; Engineering Research Center of Intelligent Technology for Geo-Exploration, Ministry of Education, Wuhan, China; Engineering Research Center of Intelligent Technology for Geo-Exploration, Ministry of Education, Wuhan, China; School of Automation, Guangdong University of Technology, Guangzhou, China","IEEE Transactions on Neural Systems and Rehabilitation Engineering","30 Sep 2021","2021","29","","1965","1976","High-frequency oscillations (HFOs) recorded by the intracranial electroencephalography (iEEG) are the promising biomarkers of epileptogenic zones. Accurate detection of HFOs is the key to pre-operative assessment for epilepsy. Due to the subjective bias caused by manual features and the class imbalance between HFOs and false HFOs, it is difficult to obtain satisfactory detection performance by the existing methods. To solve these problems, we put forward a novel method to accurately detect HFOs based on the stacked denoising autoencoder (SDAE) and the ensemble classifier with sample weight adjusting factors. First, the adjustable threshold of Hilbert envelopes is proposed to isolate the events of interest (EoIs) from background activities. Then, the SDAE network is utilized to automatically extract features of EoIs in the time-frequency domain. Finally, the AdaBoost-based support vector machine ensemble classifier with sample weight adjusting factors is devised to separate HFOs from EoIs by using the extracted features. These adjusting factors are used to solve the class imbalance problem by adjusting sample weights when learning the base classifiers. Our HFO detection method is evaluated by using clinical iEEG data recorded from 20 patients with medically refractory epilepsy. The experimental results show that our detection method outperforms some existing methods in terms of sensitivity and false discovery rate. In addition, the HFOs detected by our method are effective for localizing seizure onset zones.","1558-0210","","10.1109/TNSRE.2021.3113293","National Natural Science Foundation of China(grant numbers:61733016); Hubei Provincial Natural Science Foundation of China(grant numbers:2015CFA010); 111 Project(grant numbers:B17040); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9540702","Epilepsy;high-frequency oscillations;stacked denoising autoencoder;ensemble classifier;sample weight adjusting factors","Feature extraction;Hafnium oxide;Time-frequency analysis;Support vector machines;Sensitivity;Oscillators;Training","diseases;electroencephalography;feature extraction;learning (artificial intelligence);medical disorders;medical signal detection;medical signal processing;neurophysiology;oscillations;pattern classification;signal classification;support vector machines","epilepsy;stacked denoising autoencoder;sample weight adjusting factors-based method;high-frequency oscillations;intracranial electroencephalography;false HFOs;satisfactory detection performance;adjustable threshold;EoIs;AdaBoost-based support vector machine;class imbalance problem;base classifiers;HFO detection method","Drug Resistant Epilepsy;Electrocorticography;Electroencephalography;Epilepsy;Humans;Seizures","2","","46","CCBYNCND","16 Sep 2021","","","IEEE","IEEE Journals"
"Distributed Robust Process Monitoring Based on Optimized Denoising Autoencoder With Reinforcement Learning","S. Chen; Q. Jiang","Key Laboratory of Complex System Safety and Control, Ministry of Education, Chongqing University, Chongqing, China; Key Laboratory of Complex System Safety and Control, Ministry of Education, Chongqing University, Chongqing, China","IEEE Transactions on Instrumentation and Measurement","24 Feb 2022","2022","71","","1","11","Global monitoring for complex large-scale chemical processes is often challenging because of complex correlations among variables. This article proposes an optimized denoising autoencoder (DAE)-based distributed monitoring method to achieve efficient and robust monitoring of multiunit, nonlinear processes. First, a process is decomposed into multiple units, and then stacked DAE is used to extract the robust features of each unit and represent variable correlations within each unit. Second, deep regression neural networks are established between a local unit and its neighboring units to represent the correlations among units. A reinforcement learning-based neural architecture search method is proposed to avoid the tedious manual tuning process and obtain a high-performance neural network. Finally, a numerical simulation example, the Tennessee–Eastman benchmark process, and a laboratory-scale distillation process are used to verify the effectiveness of the proposed method.","1557-9662","","10.1109/TIM.2022.3147887","National Natural Science Foundation of China(grant numbers:61973119); Shanghai Rising-Star Program(grant numbers:20QA1402600); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9698017","Denoising autoencoder (DAE);distributed monitoring;multiunit process;Q-learning;robust monitoring","Monitoring;Correlation;Feature extraction;Noise reduction;Q-learning;Optimization;Process monitoring","chemical industry;deep learning (artificial intelligence);distillation;feature extraction;neural net architecture;optimisation;process monitoring;production engineering computing;regression analysis;reinforcement learning","reinforcement learning-based neural architecture search;correlations representation;distillation process;Tennessee-Eastman benchmark process;deep regression neural networks;nonlinear processes;DAE;denoising autoencoder;chemical processes;distributed robust process monitoring","","2","","33","IEEE","31 Jan 2022","","","IEEE","IEEE Journals"
"Partial Discharge Pattern Recognition of High Voltage Cables Based on the Stacked Denoising Autoencoder Method","W. Ganjun; Y. Fan; P. Xiaosheng; W. Yijiang; L. Taiwei; L. Zibo","Zhongshan Power Supply Bureau of the Guangdong Power Grid Corporation; School of Electrical and Electronic Engineering, Huazhong University of Science and Technology; School of Electrical and Electronic Engineering, Huazhong University of Science and Technology; Zhongshan Power Supply Bureau of the Guangdong Power Grid Corporation; School of Electrical and Electronic Engineering, Huazhong University of Science and Technology; School of Electrical and Electronic Engineering, Huazhong University of Science and Technology","2018 International Conference on Power System Technology (POWERCON)","6 Jan 2019","2018","","","3778","3792","Partial Discharge (PD) pattern recognition is one of the most important steps of PD based condition monitoring of high voltage cables, which is challenging as some types of the PD induced by cable defects are with high similarity. In recently years, deep learning based pattern recognition methods have achieved impressive pattern recognition accuracy on speech recognition and image recognition, which is one of the most potential techniques applicable for PD pattern recognition. The Stacked Denoising Autoencoder (SDAE) based deep learning method for PD pattern recognition of different insulation defects of high voltage cables is presented in the paper. Firstly, five types of artificial insulation defects of ethylene-propylene-rubber cables are manufactured in the laboratory, based on which PD testing in the high voltage lab is carried out to produce 5 types of PD signals, 500 samples for each defect types. PD feature extraction is carried out to generate 34 kinds of PD features, which are the input parameters of the PD pattern recognition methods. Secondly, the principle and network architecture of SDAE method and the flowchart of SDAE based PD pattern recognition are presented in details. Thirdly, the SDAE method is evaluated with the experimental data, 5 different types of PD signals, which achieves a recognition accuracy of 92.19%. Finally, the proposed method is compared with the traditional pattern recognition methods, Support Vector Machine (SVM) and Back Propagation Neural Network (BPNN). The results show that the pattern recognition accuracy of the proposed method is improved by 5.33% and 6.09% compared with the SVM method and the BPNN method respectively, which is applicable for pattern recognition of PD signals with high similarity.","","978-1-5386-6461-2","10.1109/POWERCON.2018.8601546","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8601546","Partial Discharge;Stacked Denoising Autoencoders;Pattern Recognition;Deep Learning","Partial discharges;Pattern recognition;Power cables;Feature extraction;Transient analysis;Power cable insulation","backpropagation;condition monitoring;feature extraction;learning (artificial intelligence);partial discharges;pattern recognition;power cable insulation;power engineering computing;power system security;support vector machines","PD feature extraction;PD pattern recognition methods;SDAE method;PD signals;high voltage cables;PD based condition monitoring;cable defects;deep learning based pattern recognition methods;speech recognition;image recognition;deep learning method;high voltage lab;partial discharge pattern recognition;BPNN;SVM;support vector machine;back propagation neural network;insulation defects;stacked denoising autoencoder method","","2","","5","","6 Jan 2019","","","IEEE","IEEE Conferences"
"Robust DoA Estimation Using Denoising Autoencoder and Deep Neural Networks","D. Chen; S. Shi; X. Gu; B. Shim","School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; Institute of New Media and Communications, Seoul National University, Seoul, South Korea","IEEE Access","23 May 2022","2022","10","","52551","52564","As one of the most critical technology in array signal processing, direction of arrival (DoA) estimation has received a great deal of attention in many areas. Traditional methods perform well when the signal-to-noise ratio (SNR) is high and the receiving array is perfect, which are quite different from the situation in some real applications (e.g., the marine communication scenario). To get satisfying performance of DoA estimation when SNR is low and the array is inaccurate (mutual coupling exist), this paper introduces a scheme consisting of denoising autoencoder (DAE) and deep neural networks (DNN), referred to as DAE-DNN scheme. DAE is used to reconstruct a clean “repaired” input from its corrupted version to increase the robustness, and then divide the input into multiple parts in different sub-areas. DNN is used to learn the mapping between the received signals and the refined grids of angle in each sub-areas, then the outputs of each sub-areas are concatenated to perform the final DoA estimation. By simulations in different SNR regimes, we study the performance of DAE-DNN in terms of the different snapshots, batch size, learning rate, and epoch. Our results demonstrate that the proposed DAE-DNN scheme outperforms traditional methods in accuracy and robustness.","2169-3536","","10.1109/ACCESS.2022.3164897","National Natural Science Foundation of China(grant numbers:62171158); National Research Foundation (NRF); Korean Government through the Ministry of Science, ICT and Future Planning (MSIP)(grant numbers:2020R1A2C2102198); Ministry of Science and ICT (MSIT) through the Information Technology Research Center (ITRC) Program supervised by the Institute for Information & Communications Technology Promotion (IITP)(grant numbers:IITP-2019-2017-0-01637); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9749276","DoA;SNR;denoising autoencoder;deep neural networks;mutual coupling","Direction-of-arrival estimation;Estimation;Signal to noise ratio;Feature extraction;Noise reduction;Covariance matrices;Array signal processing","array signal processing;deep learning (artificial intelligence);direction-of-arrival estimation;signal reconstruction","signal-to-noise ratio;direction of arrival estimation;array signal processing;denoising autoencoder;robust DoA estimation;DAE-DNN scheme;deep neural networks;mutual coupling;receiving array","","1","","37","CCBY","5 Apr 2022","","","IEEE","IEEE Journals"
"Fault Location in VSC-HVDC Using Stacked Denoising Autoencoder","G. Luo; J. Hei; Y. Liu; M. Li; J. He","School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China","2019 IEEE 3rd International Electrical and Energy Conference (CIEEC)","27 Apr 2020","2019","","","36","41","This paper proposed an intelligent algorithm based approach for fault location in a high voltage direct current (HVDC) transmission system. To obtain post-fault signals, the point-to-point HVDC transmission lines, including overhead lines and cables, are modeled on PSCAD/EMTDC. The data set is split into two parts used for training and testing, separately. The proposed method uses stacked denoising autoencoder (SDAE), which takes the raw training data as the input of network and can directly obtain fault locations. SDAE with unsupervised learning is utilized to extract representative features automatically from raw data in pre-training. Then labeled data is applied to network for fine-tuning in a supervised manner. The testing data is used for the evaluation of the proposed method. The simulation results indicate that the SDAE based method performs well in fault location and has robustness against noises, ground resistances, and system parameters.","","978-1-7281-1675-4","10.1109/CIEEC47146.2019.CIEEC-201945","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9077278","fault location;HVDC;stacked denoising autoencoder;robustness","","fault location;HVDC power transmission;neural nets;power cables;power overhead lines;power system CAD;power transmission faults;voltage-source convertors","fault location;VSC-HVDC;intelligent algorithm;high voltage direct current transmission system;point-to-point HVDC transmission lines;overhead lines;stacked denoising autoencoder;power cables;PSCAD-EMTDC;SDAE;ground resistances","","1","","14","","27 Apr 2020","","","IEEE","IEEE Conferences"
"Postfiltering Using an Adversarial Denoising Autoencoder with Noise-aware Training","N. Tawara; H. Tanabe; T. Kobayashi; M. Fujieda; K. Katagiri; T. Yazu; T. Ogawa","Waseda University, Japan; Waseda University, Japan; Waseda University, Japan; OKI Electric Industry Co., Ltd., Japan; OKI Electric Industry Co., Ltd., Japan; OKI Electric Industry Co., Ltd., Japan; Waseda University, Japan","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","3282","3286","An adversarial denoising autoencoder (ADAE) with noise-aware training is proposed and successfully applied to post-filtering for linear noise reduction. The ADAE is effective for attenuating interference sounds, however, it is difficult to learn to handle its various unexpected harmful effects (e.g., various types of noise) using a single network. Legacy speech enhancement was introduced as a pre-processor to make it possible to efficiently train the ADAEs by reducing the unexpected variabilities in the inputs to the ADAEs. Time-frequency masking performed well to suppress the variabilities, however, it induced unpleasant distortion, which is difficult for the ADAE to complement. In this paper, a minimum variance distortionless response (MVDR) beam-former, which can avoid troublesome non-linear distortions, is exploited as a preprocessor, and the MVDR outputs are used as the inputs to the ADAE-based post-filter. In addition, noise-dominant signals derived from the MVDR beamformer can improve the accuracy of the ADAE-based post-filter because the residual noise depends on the original noise signals. Experimental comparisons conducted using multichannel speech enhancement demonstrate that ADAE-based post-filtering yields significant improvements over the MVDR-and ADAE-based speech enhancement systems, and noise-aware training of ADAE works well.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682684","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682684","Adversarial denoising autoencoder;minimum variance distortionless response;noise-aware training;speech enhancement","Training;Interference;Speech enhancement;Testing;Generators;Noise reduction;Nonlinear distortion","array signal processing;filtering theory;speech coding;speech enhancement","ADAE-based post-filter;noise-dominant signals;residual noise;noise-aware training;adversarial denoising autoencoder;linear noise reduction;minimum variance distortionless response beamformer;interference sounds;legacy speech enhancement;time-frequency masking;MVDR beamformer;multichannel speech enhancement","","","","16","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Learning via Denoising Autoencoder on 5G NR Phase Noise Estimation","M. -s. Lin; H. Kwon","Samsung Semiconductor Inc, San Diego, USA; Samsung Semiconductor Inc, San Diego, USA","2021 IEEE Global Communications Conference (GLOBECOM)","2 Feb 2022","2021","","","1","6","In this paper, on phase noise of 5G NR mmWave systems, we propose a learning-based common phase error (CPE) estimation algorithm based on the denoising autoencoder serving as a nonlinear filter on the existing CPE estimators. The proposed algorithm learns the low dimension manifold of phase noise distributions with high probability. Traditional CPE methods have limitation when the time domain pilots are few, which causes degraded system performance with CPE interpolation. Besides accurate CPE estimation, the proposed method is more robust to various FR2 channels, Doppler effects, and the numerologies. Simulation results show that block error rate (BLER) could be improved up to 1.43 dB on SNR.","","978-1-7281-8104-2","10.1109/GLOBECOM46510.2021.9685663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9685663","Common Phase Error;learning;denoising autoencoder;neural network;5G NR;FR2","Phase noise;Manifolds;Interpolation;5G mobile communication;Simulation;Noise reduction;Estimation","5G mobile communication;Doppler effect;error statistics;interpolation;millimetre wave communication;neural nets;phase estimation;phase noise;telecommunication computing","denoising autoencoder;low dimension manifold;phase noise distributions;traditional CPE methods;system performance;CPE interpolation;accurate CPE estimation;5G NR phase noise estimation;5G NR mmWave systems;learning-based common phase error estimation algorithm;nonlinear filter;degraded system performance;FR2 channels;Doppler effects;block error rate","","","","18","IEEE","2 Feb 2022","","","IEEE","IEEE Conferences"
"A Nonnegativity-Constraint Sparse Stacked Denoising Autoencoder for Anomaly Detection in Electric Power Communication Network","Z. Tao; Y. Yan; Y. Yang; Y. Wang; J. Luo","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Grid Zhejiang Electric Power Company, LTD, Zhejiang, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; Science and Technology on Information System Engineering Laboratory, Beijing Institute of Control and Electronic Technology, Beijing, China; Science and Technology on Information System Engineering Laboratory, Beijing Institute of Control and Electronic Technology, Beijing, China","2020 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)","19 Mar 2021","2020","","","1","6","As the scale of the electric power communication network is getting larger and larger, network security issues are becoming more and more complex. as an effective protection method, network traffic anomaly detection can provide important technical support for network situation awareness. In some cases, plenty of labeled data are unavailable, which may lead to low detection accuracy. To deal with this problem, a nonnegativity-constraint sparse stacked denoising autoencoder(NSSDAE) is proposed. Meanwhile, we propose a method called dynamic parameter freezing(DPF) for parameter transfer, which allows to find the best performance that may exist between the freezing and fine-tuning within a layer by adjusting the variable alpha. And discriminative joint probability maximum mean discrepancy is introduced for distribution adaptation. The results for NSL-KDD show that the proposed NSSDAE-TL algorithm is effective.","2155-5052","978-1-7281-5784-9","10.1109/BMSB49480.2020.9379595","Research and Development; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9379595","traffic anomaly detection;nonnegativity-constraint sparse stacked denoising autoencoder;parameter transfer learning;few labeled data","Noise reduction;Telecommunication traffic;Power systems;Communication networks;Security;Multimedia communication;Anomaly detection","computer network security;learning (artificial intelligence);probability;telecommunication security;telecommunication traffic","electric power communication network;larger network security issues;effective protection method;network traffic anomaly detection;important technical support;network situation awareness;low detection accuracy;nonnegativity-constraint sparse;dynamic parameter freezing;DPF;nonnegativity-constraint sparse stacked denoising autoencoder;NSSDAE-TL algorithm;NSL-KDD","","","","10","","19 Mar 2021","","","IEEE","IEEE Conferences"
"Unsupervised Erratic Seismic Noise Attenuation With Robust Deep Convolutional Autoencoders","F. Qian; W. Guo; Z. Liu; H. Yu; G. Zhang; G. Hu","Center for Information Geoscience and the School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Information Geoscience and the School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Information Geoscience and the School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China; Center for Information Geoscience and the School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Geoscience and Technology, Southwest Petroleum University, Chengdu, China; Center for Information Geoscience and the School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China","IEEE Transactions on Geoscience and Remote Sensing","12 Apr 2022","2022","60","","1","16","Erratic seismic noise, following a (known or unknown) non-Gaussian distribution, poses a formidable challenge to conventional methods of random noise attenuation. Many erratic noise cancellation methods, for instance, robust reduced-rank and sparsity-promoting filtering, have been proven to achieve promising results in overcoming this challenge. Among them, deep learning (DL) methods require no assumptions about the underlying clear seismic image and are also more robust against erratic and random noise. However, the success of existing DL-based denoising methods strongly depends on supervised learning from a large number of ground-truth seismic images affected by erratic noise and their clean counterparts, which are typically unavailable in a real-world setting. As an alternative, this article presents an unsupervised DL method for erratic-plus-Gaussian noise removal based on a robust deep convolutional autoencoder (RDCAE). In the RDCAE, the mean squared error (mse) loss in a classic DCAE is replaced by the smooth Welsch function to exploit the concept of robust image denoising. In this way, the erratic noise is downweighted by means of a curbed weight defined in terms of the Welsch function. In contrast, the random noise is diluted by combining the mean square in the Welsch function and the total variation (TV). Subsequently, the training procedures required for solving the RDCAE are derived on the basis of the backpropagation (BP) algorithm for a neural network. Experiments conducted on both synthetic and real field datasets are reported to illustrate the efficacy of the proposed method.","1558-0644","","10.1109/TGRS.2022.3158389","National Natural Science Foundation of China(grant numbers:41874155,42130812,41874168); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9732348","Deep learning (DL);erratic seismic noise;robust deep convolutional autoencoder (RDCAE);total variation (TV);Welsch function","Noise reduction;Attenuation;Transforms;Noise measurement;Training;Image denoising;TV","backpropagation;convolutional neural nets;Gaussian distribution;Gaussian noise;geophysical image processing;image denoising;learning (artificial intelligence);mean square error methods;random noise;seismology","robust image denoising;Welsch function;RDCAE;unsupervised erratic seismic noise attenuation;robust deep convolutional autoencoder;nonGaussian distribution;formidable challenge;random noise attenuation;erratic noise cancellation methods;robust reduced-rank;sparsity-promoting filtering;deep learning methods;underlying clear seismic image;ground-truth seismic images;unsupervised DL method;erratic-plus-Gaussian noise removal;mean squared error loss","","1","","72","IEEE","10 Mar 2022","","","IEEE","IEEE Journals"
"SDCAE: Stack Denoising Convolutional Autoencoder Model for Accident Risk Prediction Via Traffic Big Data","C. Chen; X. Fan; C. Zheng; L. Xiao; M. Cheng; C. Wang","Digital Fujian Institute of Urban Traffic Big Data Research, Xiamen University, Xiamen, China; Digital Fujian Institute of Urban Traffic Big Data Research, Xiamen University, Xiamen, China; Digital Fujian Institute of Urban Traffic Big Data Research, Xiamen University, Xiamen, China; Digital Fujian Institute of Urban Traffic Big Data Research, Xiamen University, Xiamen, China; Digital Fujian Institute of Urban Traffic Big Data Research, Xiamen University, Xiamen, China; Digital Fujian Institute of Urban Traffic Big Data Research, Xiamen University, Xiamen, China","2018 Sixth International Conference on Advanced Cloud and Big Data (CBD)","11 Nov 2018","2018","","","328","333","Traffic accident is considered as one of main causes for traffic congestion in cities. There are many causal factors that may give rise to traffic accidents, e.g. driver characteristics, road conditions, traffic flows and weather conditions, etc. Due to uncertain factors as well as the contingency of accident occurrences, it is very difficult to predict traffic accidents. Many existing works have utilized classical prediction models to predict the risk of accidents on highways or road segments. However, predicting the risk of citywide accidents remains an open issue. To address this problem, we propose SDCAE, a novel Stack Denoise Convolutional Auto-Encoder algorithm to predict the risk of traffic accident in the city-level. First, we divided the city into regions by counting the number of accidents and traffic flows in each region. Second, we employed a deep model of stack denoise convolutional autoencoder which considers spatial dependencies to learn the hidden factors in accidents. Third, we conducted extensive experiments on two real-world cross-domain traffic big datasets from a major city of China for accident risk prediction. Experimental results demonstrate that SDCAE could outperforms five baseline methods.","","978-1-5386-8034-6","10.1109/CBD.2018.00065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8530861","traffic accident, convolutional autoencoder, risk prediction","Accidents;Predictive models;Roads;Data models;Urban areas;Feature extraction;Computer crashes","Big Data;learning (artificial intelligence);neural nets;road accidents;road safety;road traffic;traffic engineering computing","citywide accidents;traffic accident;traffic flows;stack denoising convolutional autoencoder model;cross-domain traffic big datasets;SDCAE algorithm;stack denoise convolutional auto-encoder algorithm;classical prediction models;accident occurrences;traffic congestion;traffic big data;accident risk prediction","","8","","21","","11 Nov 2018","","","IEEE","IEEE Conferences"
"Research on ensemble model of anomaly detection based on autoencoder","Y. Han; Y. Ma; J. Wang; J. Wang","Technology and Engineering Center for Space Utilization, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Technology and Engineering Center for Space Utilization, Chinese Academy of Sciences, Beijing, China; Technology and Engineering Center for Space Utilization, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Technology and Engineering Center for Space Utilization, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China","2020 IEEE 20th International Conference on Software Quality, Reliability and Security (QRS)","11 Dec 2020","2020","","","414","417","In the fields of technology such as aerospace, anomaly detection is critical to the overall system. With the large increase in data volume and dimensions, the traditional detection methods have great limitations, and thus anomaly detection algorithms based on deep learning have received widespread attention. In this paper, based on autoencoder: standard autoencoder, denoising autoencoder, and sparse autoencoder, an ensemble detection model that can extract more feature information is proposed. To make more use of these feature information, inspired by the idea of pooling layer of the CNN, two feature fusion methods are proposed. Finally, the experiment verifies that the result of this model is better than the single autoencoder model.","","978-1-7281-8913-0","10.1109/QRS51102.2020.00060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9282765","anomaly detection;autoencoder;ensemble","Software quality;Feature extraction;Data models;Software reliability;Security;Anomaly detection;Standards","convolutional neural nets;feature extraction;learning (artificial intelligence);security of data","ensemble model;data volume;anomaly detection algorithms;standard autoencoder;sparse autoencoder;ensemble detection model;feature information;single autoencoder model;CNN","","1","","20","IEEE","11 Dec 2020","","","IEEE","IEEE Conferences"
"Radar HRRP Target Recognition Based on Blind-Denoising Deep Network","C. Zhao; J. Liang; G. Zhang; C. Huang; X. He","University of Electronic Science and Technology of China Chengdu, Chengdu, China; University of Electronic Science and Technology of China Chengdu, Chengdu, China; University of Electronic Science and Technology of China Chengdu, Chengdu, China; University of Electronic Science and Technology of China Chengdu, Chengdu, China; University of Electronic Science and Technology of China Chengdu, Chengdu, China","2019 IEEE Globecom Workshops (GC Wkshps)","5 Mar 2020","2019","","","1","5","Feature representation based on the high resolution range profile (HRRP) is important in radar automatic target recognition(RATR). Traditional algorithms of feature extraction utilize hallow architectures and rarely address the challenges of high-noise and unknown-noise distribution. The capability of RATA is restricted by these challenges. In this paper, a novel blind-denoising network(BDNet) is proposed to implement denoising and automatically extract features. As an extension of deep autoencoder, BDNet is based on fully convolutional architecture and employs fusion layers to transfer input features to high dimensional space. Trained with noise-to-noise, BDNet can implement blind-denoising and doesn't rely on noise distribution. Then the output of BDNet is used to classify the targets. In the experiment, we use the measured HRRP signals of four aircrafts to show the effectiveness of our methods. The results prove that BDNet can achieve blind-denoising in highnoise environment and significantly improve the performance of recognition.Andourproposed BDNetAlexNet outperforms other recognition methods.","","978-1-7281-0960-2","10.1109/GCWkshps45667.2019.9024602","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9024602","","Radar;Noise reduction;Feature extraction;Target recognition;Signal to noise ratio;Training;Data models","feature extraction;learning (artificial intelligence);neural nets;radar computing;radar resolution;radar target recognition;signal denoising;signal representation","radar HRRP target recognition;blind-denoising deep network;feature representation;high resolution range profile;feature extraction;unknown-noise distribution;deep autoencoder;fully convolutional architecture;high dimensional space;noise-to-noise;measured HRRP signals;BDNetAlexNet;hallow architectures","","","","25","","5 Mar 2020","","","IEEE","IEEE Conferences"
"DAPAS : Denoising Autoencoder to Prevent Adversarial attack in Semantic Segmentation","S. Cho; T. J. Jun; B. Oh; D. Kim","School of Computing, KAIST, Daejeon, South Korea; Asan Medical Center, Seoul, South Korea; School of Computing, KAIST, Daejeon, South Korea; School of Computing, KAIST, Daejeon, South Korea","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","8","Nowadays, deep learning techniques show dramatic performance in computer vision areas, and they even outperform humans on complex tasks such as ImageNet classification. But it turns out a deep learning based model is vulnerable to some small perturbation called an adversarial attack. This is a problem in the view of the safety and security of artificial intelligence, which has recently been studied a lot. These attacks have shown that they can easily fool models of image classification, semantic segmentation, and object detection. We focus on the adversarial attack in semantic segmentation tasks since there is little work in this task. We point out this attack can be protected by denoise autoencoder, which is used for denoising the perturbation and restoring the original images. We build a deep denoise autoencoder model for removing the adversarial perturbation and restoring the clean image. We experiment with various noise distributions and verify the effect of denoise autoencoder against adversarial attack in semantic segmentation task.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9207291","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207291","Adversarial Attack;Robustness;Computer Vision","Semantics;Image segmentation;Task analysis;Perturbation methods;Neural networks;Image resolution;Image restoration","computer vision;feature extraction;image classification;image denoising;image segmentation;learning (artificial intelligence);neural nets;object detection","semantic segmentation task;deep denoise autoencoder model;adversarial perturbation;adversarial attack;deep learning techniques;computer vision areas;deep learning based model;image classification","","6","","30","","28 Sep 2020","","","IEEE","IEEE Conferences"
"CNN-Based InSAR Denoising and Coherence Metric","S. Mukherjee; A. Zimmer; N. K. Kottayil; X. Sun; P. Ghuman; I. Cheng","Department of Computing Science, University of Alberta, Edmonton, Canada; 3v Geomatics, Vancouver, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada; 3v Geomatics, Vancouver, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada","2018 IEEE SENSORS","27 Dec 2018","2018","","","1","4","Interferometric Synthetic Aperture Radar (InSAR) imagery for estimating ground movement, based on microwaves reflected off ground targets is gaining increasing importance in remote sensing. However, noise corrupts microwave reflections received at satellite and contaminates the signal's wrapped phase. We introduce Convolutional Neural Networks (CNNs) to this problem domain and show the effectiveness of autoencoder CNN architectures to learn InSAR image denoising filters in the absence of clean ground truth images, and for artefact reduction in estimated coherence through intelligent preprocessing of training data. We compare our results with four established methods to illustrate superiority of proposed method.","2168-9229","978-1-5386-4707-3","10.1109/ICSENS.2018.8589920","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8589920","InSAR;denoising;coherence;autoencoder;convolutional neural networks","Coherence;Noise reduction;Filtering;Remote sensing;Noise measurement;Training;Microwave filters","convolutional neural nets;filtering theory;geophysical image processing;image denoising;learning (artificial intelligence);radar imaging;radar interferometry;remote sensing by radar;synthetic aperture radar","CNN-based InSAR denoising;coherence metric;remote sensing;microwave reflections;autoencoder CNN architectures;InSAR image denoising filters;clean ground truth images;artefact reduction;signals wrapped phase;interferometric synthetic aperture radar imagery;convolutional neural networks","","5","1","30","","27 Dec 2018","","","IEEE","IEEE Conferences"
"Soft Autoencoder and Its Wavelet Adaptation Interpretation","F. Fan; M. Li; Y. Teng; G. Wang","Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; Sino-Dutch Biomedical and Information Engineering School, Northeastern University, Shenyang, China; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA","IEEE Transactions on Computational Imaging","20 Aug 2020","2020","6","","1245","1257","Recently, deep learning becomes the main focus of machine learning research and has greatly impacted many important fields. However, deep learning is criticized for lack of interpretability. As a successful unsupervised model in deep learning, the autoencoder embraces a wide spectrum of applications, yet it suffers from the model opaqueness as well. In this article, we propose a new type of convolutional autoencoders, termed as Soft Autoencoder (Soft-AE), in which the activation functions of encoding layers are implemented with adaptable soft-thresholding units while decoding layers are realized with linear units. Consequently, Soft-AE can be naturally interpreted as a learned cascaded wavelet shrinkage system. Our denoising experiments demonstrate that Soft-AE not only is interpretable but also offers a competitive performance relative to its counterparts. Furthermore, we propose a generalized linear unit (GenLU) to make an autoencoder more adaptive in nonlinearly filtering images and data, such as denoising and deblurring.","2333-9403","","10.1109/TCI.2020.3013796","Rensselaer-IBM AI Research Collaboration; IBM AI Horizons Network; NIH/NCI(grant numbers:R01CA233888,R01CA237267); NIH/NIBIB(grant numbers:R01EB026646); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9162438","Deep learning;interpretability;convolutional autoencoder;activation functions","Convolution;Machine learning;Thresholding (Imaging);Noise reduction;Wavelet coefficients","convolutional neural nets;image coding;image denoising;image filtering;image segmentation;learning (artificial intelligence);wavelet transforms","Soft-AE;soft-thresholding units;learned cascaded wavelet shrinkage system;wavelet adaptation interpretation;deep learning;model opaqueness;convolutional autoencoders;soft autoencoder;unsupervised model;activation functions;encoding layers;decoding layers;denoising experiments;generalized linear unit;nonlinearly filtering images;nonlinearly filtering data","","2","","54","IEEE","7 Aug 2020","","","IEEE","IEEE Journals"
"Comparative Analysis of Gaussian Filter, Median Filter and Denoise Autoenocoder","A. Kumar; S. S. Sodhi","Dept. of CSE, GGSIPU, Delhi, India; GGSIPU, New Delhi, India","2020 7th International Conference on Computing for Sustainable Global Development (INDIACom)","4 May 2020","2020","","","45","51","Images can be enhanced and denoised with the help of filters. In this paper, we use a Gaussian filter, a Median Filter and a Denoising Auto encoder for noise removal. Gaussian filter is a linear type of filter which is based on Gaussian function. But the median filter is a non-linear type of filter. It preserves edge while removing noise. Deep Convolutional neural network (CNN) is able to handle Gaussian denoising at a certain noise level. We compare these three types of noise removers with the help of four types of evaluation techniques. We use time performance, Peak signal-to-noise ratio (PSNR), Structure Similarity (SSIM) and Normalization mean square error (NMSE) evaluation techniques for finding the best filter for removing noise from the image on different situations. We found that sometimes a Gaussian filter is better and sometimes the median filter is better depending on the iteration of the filter. Sometimes a denoise autoencoder is also better but it takes more time with respect to a Gaussian filter and a median filter. When we consider only the time parameter, then the Median filter gives better results in less time in comparison to a Gaussian filter and a denoise autoencoder filter.","","978-93-80544-38-0","10.23919/INDIACom49435.2020.9083712","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9083712","Gaussian filter;median filter;Denoise (DnCNN) Autoenocoder;Gaussian noise;salt & pepper noise;Convolutional neural network (CNN);deep learning","Maximum likelihood detection;PSNR;Noise reduction;Neural networks;Nonlinear filters;Mean square error methods;Convolutional neural networks","convolutional neural nets;filtering theory;image denoising;image filtering;mean square error methods;median filters","median filter;Gaussian filter;noise removal;noise removers;autoencoder filter;time performance;peak signal-to-noise ratio;PSNR;structure similarity;SSIM;normalization mean square error evaluation;NMSE evaluation;deep convolutional neural network;CNN;denoise autoencoder filter;comparative analysis","","5","","30","","4 May 2020","","","IEEE","IEEE Conferences"
"Lightweight Lossy Compression of Biometric Patterns via Denoising Autoencoders","D. Del Testa; M. Rossi","Department of Information Engineering, University of Padova, Padova, Italy; Department of Information Engineering, University of Padova, Padova, Italy","IEEE Signal Processing Letters","17 Sep 2015","2015","22","12","2304","2308","Wearable Internet of Things (IoT) devices permit the massive collection of biosignals (e.g., heart-rate, oxygen level, respiration, blood pressure, photo-plethysmographic signal, etc.) at low cost. These, can be used to help address the individual fitness needs of the users and could be exploited within personalized healthcare plans. In this letter, we are concerned with the design of lightweight and efficient algorithms for the lossy compression of these signals. In fact, we underline that compression is a key functionality to improve the lifetime of IoT devices, which are often energy constrained, allowing the optimization of their internal memory space and the efficient transmission of data over their wireless interface. To this end, we advocate the use of autoencoders as an efficient and computationally lightweight means to compress biometric signals. While the presented techniques can be used with any signal showing a certain degree of periodicity, in this letter we apply them to ECG traces, showing quantitative results in terms of compression ratio, reconstruction error and computational complexity. State of the art solutions are also compared with our approach.","1558-2361","","10.1109/LSP.2015.2476667","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7239543","Autoencoders;biometric patterns;lossy compression;wearable devices","Training;Neurons;Principal component analysis;Artificial neural networks;Signal processing algorithms;Data models;Noise reduction","data compression;electrocardiography;encoding;Internet of Things;medical signal processing;signal denoising","lightweight lossy compression;biometric patterns;autoencoder denoising;wearable Internet of Things device;biosignal collection;energy constraint;internal memory space optimization;IoT devices;biometric signals;ECG traces","","42","1","22","IEEE","3 Sep 2015","","","IEEE","IEEE Journals"
"Background Prior-Based Salient Object Detection via Deep Reconstruction Residual","J. Han; D. Zhang; X. Hu; L. Guo; J. Ren; F. Wu","School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; Department of Electronic and Electrical Engineering, University of Strathclyde, Glasgow, U.K.; School of Information Science, University of Science and Technology of China, Hefei, China","IEEE Transactions on Circuits and Systems for Video Technology","31 Jul 2015","2015","25","8","1309","1321","Detection of salient objects from images is gaining increasing research interest in recent years as it can substantially facilitate a wide range of content-based multimedia applications. Based on the assumption that foreground salient regions are distinctive within a certain context, most conventional approaches rely on a number of hand-designed features and their distinctiveness is measured using local or global contrast. Although these approaches have been shown to be effective in dealing with simple images, their limited capability may cause difficulties when dealing with more complicated images. This paper proposes a novel framework for saliency detection by first modeling the background and then separating salient objects from the background. We develop stacked denoising autoencoders with deep learning architectures to model the background where latent patterns are explored and more powerful representations of data are learned in an unsupervised and bottom-up manner. Afterward, we formulate the separation of salient objects from the background as a problem of measuring reconstruction residuals of deep autoencoders. Comprehensive evaluations of three benchmark datasets and comparisons with nine state-of-the-art algorithms demonstrate the superiority of this paper.","1558-2205","","10.1109/TCSVT.2014.2381471","National Science Foundation of China(grant numbers:61103061,91120005,61473231); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6987333","salient object detection;stacked denoising autoencoder;deep reconstruction residual;Background prior;deep reconstruction residual;salient object detection;stacked denoising autoencoder (SDAE)","Feature extraction;Image reconstruction;Training;Noise reduction;Object detection;Encoding;Robustness","feature extraction;image coding;image denoising;image reconstruction;learning (artificial intelligence);multimedia computing;object detection","background prior-based salient object detection;data representation;deep learning architectures;stacked denoising autoencoders;global contrast;local contrast;foreground salient regions;content-based multimedia applications;deep reconstruction residual","","306","","51","IEEE","18 Dec 2014","","","IEEE","IEEE Journals"
"A novel approach for automatic acoustic novelty detection using a denoising autoencoder with bidirectional LSTM neural networks","E. Marchi; F. Vesperini; F. Eyben; S. Squartini; B. Schuller","Machine Intelligence & Signal Processing Group, Technische Universitat Munchen, Germany; A3LAB, Universita Politecnica delle Marche, Italy; Machine Intelligence & Signal Processing Group, Technische Universitat Munchen, Germany; A3LAB, Universita Politecnica delle Marche, Italy; Machine Intelligence & Signal Processing Group, Technische Universitat Munchen, Germany","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","6 Aug 2015","2015","","","1996","2000","Acoustic novelty detection aims at identifying abnormal/novel acoustic signals which differ from the reference/normal data that the system was trained with. In this paper we present a novel unsupervised approach based on a denoising autoencoder. In our approach auditory spectral features are processed by a denoising autoencoder with bidirectional Long Short-Term Memory recurrent neural networks. We use the reconstruction error between the input and the output of the autoencoder as activation signal to detect novel events. The autoencoder is trained on a public database which contains recordings of typical in-home situations such as talking, watching television, playing and eating. The evaluation was performed on more than 260 different abnormal events. We compare results with state-of-the-art methods and we conclude that our novel approach significantly outperforms existing methods by achieving up to 93.4% F-Measure.","2379-190X","978-1-4673-6997-8","10.1109/ICASSP.2015.7178320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178320","Acoustic Novelty Detection;Denoising Autoencorder;Bidirectional LSTM;Recurrent Neural Networks","Noise reduction;Hidden Markov models;Training;Feature extraction;Recurrent neural networks","acoustic signal processing;recurrent neural nets","automatic acoustic novelty detection;denoising autoencoder;bidirectional LSTM neural networks;abnormal-novel acoustic signals;reference-normal data;novel unsupervised approach;auditory spectral features;long short term memory recurrent neural networks","","115","2","29","","6 Aug 2015","","","IEEE","IEEE Conferences"
"Deniosing Autoencoder-based Modification of RRI data with Premature Ventricular Contraction for Precise Heart Rate Variability Analysis","S. MIYATANI; K. FUJIWARA; M. KANO","Kyoto Daigaku, Kyoto, JP; Kyoto Daigaku, Kyoto, JP; Kyoto Daigaku, Kyoto, JP","2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","28 Oct 2018","2018","","","5018","5021","The fluctuation of an RR interval (RRI) on an electrocardiogram (ECG) is called heart rate variability (HRV). HRV reflects the autonomic nerve activity, thus HRV analysis has been used for health monitoring such as stress estimation, drowsiness detection, epileptic seizure prediction, and cardiovascular disease diagnosis. However, RRI and HRV features are easily affected by arrhythmia, which deteriorates the health monitoring performance. Premature ventricular contraction (PVC) is common arrhythmia that many healthy persons have. Thus, a new methodology for dealing with RRI fluctuation disturbed by PVC needs to be developed for realizing precise health monitoring. To modify RRI data affected by PVC, the present work proposes a new method based on a denoising autoencoder (DAE), which reconstructs original input data from the noisy input data by using a neural network. The proposed method, referred to as DAE-based RRI modification (DAERM), aims to correct the disturbed RRI data by regarding PVC as artifacts. The present work demonstrated the usefulness of the proposed DAE-RM through its application to real RRI data with artificial PVC (PVC-RRI). The result showed that DAE-RM successfully modified PVC-RRI data. In fact, the root means squared error (RMSE) of the modified RRI was improved by 83.5% from the PVC-RRI. The proposed DAERM will contribute to realizing precise HRV-based health monitoring in the future.","1558-4615","978-1-5386-3646-6","10.1109/EMBC.2018.8513218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8513218","","Rail to rail inputs;Heart rate variability;Monitoring;Feature extraction;Noise reduction;Electrocardiography;Frequency-domain analysis","bioelectric potentials;cardiovascular system;diseases;electrocardiography;medical disorders;medical signal processing;neurophysiology;signal denoising","premature ventricular contraction;autonomic nerve activity;HRV features;DAE-based RRI modification;heart rate variability analysis;HRV-based health monitoring;root means squared error;stress estimation;drowsiness detection;epileptic seizure prediction;denoising autoencoder-based modification","Electrocardiography;Epilepsy;Heart Rate;Humans;Neural Networks, Computer;Ventricular Premature Complexes","","","14","","28 Oct 2018","","","IEEE","IEEE Conferences"
"An integrated scheme based on stacked denoising autoencoder and deep feature fusion for fault diagnosis of helicopter planetary gear train","C. Sun; Y. Wang; L. Cao","College of Automation Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Automation Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Research Center, Shanghai Aero Measurement & Control Technology Research Institute, Shanghai, China","2019 Prognostics and System Health Management Conference (PHM-Qingdao)","27 Dec 2019","2019","","","1","8","Planetary gear train plays a critical role in the helicopter transmission system. Fault diagnosis of the planetary gear train has long been a research topic in the health monitoring and maintenance of the helicopter. However, due to the intricate kinematics and severe operating conditions, the vibration signals of the planetary gear train are highly complex, dominated by various coupling disturbances and ambient noise. Aiming to address these challenges, an integrated health state identification scheme (IHSIS) is proposed for fault diagnosis of helicopter planetary gear train. Firstly, IHSIS utilizes multiple sensors to collecting vibration signals for sufficient fault information under multi-mode faults and fluctuating working conditions. Secondly, stacked denoising automatic encoder (SDAE) is adopted to explore deep features from frequency spectrum of each individual sensor. Finally, deep features derived from measured signals of all sensors are fused together and input to a softmax classifier for fault diagnosis. The superiority of IHSIS is validated by analyzing results of a few comparative experiments conducted on a helicopter main-rotor testbed with intentionally created localized gear faults of a planetary gear train under different noise levels.","","978-1-7281-0861-2","10.1109/PHM-Qingdao46334.2019.8942963","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942963","Helicopter;Planetary gear train;Fault diagnosis;Stacked denoising autoencoder;Feature fusion.","Fault diagnosis;Gears;Helicopters;Training;Vibrations;Sensors;Feature extraction","condition monitoring;fault diagnosis;gears;helicopters;learning (artificial intelligence);sensor fusion;vibrational signal processing;vibrations","softmax classifier;frequency spectrum;IHSIS;health monitoring;deep feature fusion;stacked denoising autoencoder;localized gear faults;integrated health state identification scheme;vibration signals;helicopter transmission system;helicopter planetary gear train;fault diagnosis","","","","24","","27 Dec 2019","","","IEEE","IEEE Conferences"
"Integration Design of Portable ECG Signal Acquisition With Deep-Learning Based Electrode Motion Artifact Removal on an Embedded System","Y. -S. Jhang; S. -T. Wang; M. -H. Sheu; S. -H. Wang; S. -C. Lai","Department of Electronics Engineering, National Yunlin University of Science and Technology, Douliu, Taiwan; Doctor’s Program of Smart Industry Technology Research and Design, National Formosa University, Huwei, Taiwan; Department of Electronics Engineering, National Yunlin University of Science and Technology, Douliu, Taiwan; Department of Electronics Engineering, National Yunlin University of Science and Technology, Douliu, Taiwan; Department of Automation Engineering, National Formosa University, Huwei, Taiwan","IEEE Access","7 Jun 2022","2022","10","","57555","57564","For long-term electrocardiogram (ECG) signal monitoring, a portable and small size acquisition device with Bluetooth low energy (BLE) communication is designed and integrated with a Nvidia Jetson Xavier NX for realizing the electrode motion artifact removal technique. The digitalized ECG codes are converted from a front-end circuit, which contains several amplifiers and filters in the acquisition system. Thereafter, a zero padding scheme is applied for each 10-bits data to separate them into two-bytes data for BLE transmission. Xavier Edge AI platform receives these transmitted data and removes the electrode motion (EM) noise using the proposed low memory shortcut connection-based denoised autoencoder (LMSC-DAE). The simulation results demonstrate that the proposed algorithm significantly improves the signal-to-noise ratio (SNR) by 5.41 dB under the condition of SNRin = 12 dB, compared with convolutional denoising autoencoder with long short-term memory (CNN-LSTM-DAE) method. For practical test, an Arduino DUE platform is employed to generate noise interference by controlling a commercial digital-to-analog convertor. By combining the proposed ECG acquisition device with a non-inverting weighted summer, it can be applied to verify the reproducibility of measurement for the proposed method. The measurement results clearly indicate that the proposed LMSC-DAE has a higher improvement of SNR and lower percentage root-mean-square difference than the state-of-the-art Fully Convolutional Denoising Autoencoder (FCN-DAE).","2169-3536","","10.1109/ACCESS.2022.3178847","Ministry of Science and Technology, Taiwan(grant numbers:MOST 110-2622-E-224-006,110-2221-E-150-045,109-2221-E-150-043); Smart Machinery and Intelligent Manufacturing Research Center; Higher Education SPROUT Project, National Formosa University; Ministry of Education (MOE) Female Researching Talent Cultivation Project for Science, Technology, Engineering, and Mathematics (STEM) field; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9784947","Electrocardiogram (ECG);ECG signal enhancement;embedded system;deep learning;denoising autoencoder (DAE)","Electrocardiography;Noise measurement;Noise reduction;Embedded systems;Convolution;Adaptive filters;Artificial intelligence","biomedical electrodes;Bluetooth;convolutional neural nets;deep learning (artificial intelligence);electrocardiography;medical signal processing;portable instruments;recurrent neural nets;signal denoising","portable ECG signal acquisition;deep-learning based electrode motion artifact removal;embedded system;electrocardiogram signal monitoring;Bluetooth low energy communication;Nvidia Jetson Xavier NX;digitalized ECG codes;front-end circuit;amplifiers;filters;zero padding;BLE transmission;Xavier Edge AI platform;electrode motion noise;long short-term memory;Arduino DUE platform;noise interference;digital-analog convertor;low memory shortcut connection-based denoised autoencoder;LMSC-DAE method;CNN-LSTM-DAE method;fully convolutional denoising autoencoder;FCN-DAE method;noninverting weighted summer","","","","30","CCBYNCND","30 May 2022","","","IEEE","IEEE Journals"
"Learning the CSI Denoising and Feedback Without Supervision","V. Rizzello; W. Utschick","Department of Electrical and Computer Engineering, Technical University of Munich; Department of Electrical and Computer Engineering, Technical University of Munich","2021 IEEE 22nd International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)","12 Nov 2021","2021","","","16","20","In this work, we develop a joint denoising and feedback strategy for channel state information in frequency division duplex systems. In such systems, the biggest challenge is the overhead incurred when the mobile terminal has to send the downlink channel state information or corresponding partial information to the base station, where the complete estimates can subsequently be restored. To this end, we propose a novel learning-based framework for denoising and compression of channel estimates. Unlike existing studies, we extend a recently proposed approach and show that based solely on noisy uplink data available at the base station, it is possible to learn an autoencoder neural network that generalizes to downlink data. Subsequently, half of the autoencoder can be offloaded to the mobile terminals to generate channel feedback there as efficiently as possible, without any training effort at the terminals or corresponding transfer of training data. Numerical simulations demonstrate the excellent performance of the proposed method.","1948-3252","978-1-6654-2851-4","10.1109/SPAWC51858.2021.9593213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9593213","Machine learning;Massive MIMO;FDD systems;Autoencoders;Denoising;Deep learning","Training;Wireless communication;Base stations;Time-frequency analysis;Noise reduction;Training data;Signal processing","channel estimation;feedback;frequency division multiplexing;learning (artificial intelligence);MIMO communication;neural nets;OFDM modulation;wireless channels","corresponding partial information;base station;complete estimates;novel learning-based framework;denoising compression;channel estimates;noisy uplink data;autoencoder neural network;downlink data;mobile terminal;channel feedback;corresponding transfer;training data;CSI denoising;joint denoising;frequency division duplex systems;downlink channel state information","","3","","28","","12 Nov 2021","","","IEEE","IEEE Conferences"
"SACNN: Self-Attention Convolutional Neural Network for Low-Dose CT Denoising With Self-Supervised Perceptual Loss Network","M. Li; W. Hsu; X. Xie; J. Cong; W. Gao","Department of Electronics Engineering and Computer Science, Peking University, Beijing, China; Department of Radiological Sciences, David Geffen School of Medicine at UCLA, Los Angeles, USA; Department of Electronics Engineering and Computer Science, Peking University, Beijing, China; Department of Computer Science, University of California at Los Angeles, Los Angeles, USA; Department of Electronics Engineering and Computer Science, Peking University, Beijing, China","IEEE Transactions on Medical Imaging","30 Jun 2020","2020","39","7","2289","2301","Computed tomography (CT) is a widely used screening and diagnostic tool that allows clinicians to obtain a high-resolution, volumetric image of internal structures in a non-invasive manner. Increasingly, efforts have been made to improve the image quality of low-dose CT (LDCT) to reduce the cumulative radiation exposure of patients undergoing routine screening exams. The resurgence of deep learning has yielded a new approach for noise reduction by training a deep multi-layer convolutional neural networks (CNN) to map the low-dose to normal-dose CT images. However, CNN-based methods heavily rely on convolutional kernels, which use fixed-size filters to process one local neighborhood within the receptive field at a time. As a result, they are not efficient at retrieving structural information across large regions. In this paper, we propose a novel 3D self-attention convolutional neural network for the LDCT denoising problem. Our 3D self-attention module leverages the 3D volume of CT images to capture a wide range of spatial information both within CT slices and between CT slices. With the help of the 3D self-attention module, CNNs are able to leverage pixels with stronger relationships regardless of their distance and achieve better denoising results. In addition, we propose a self-supervised learning scheme to train a domain-specific autoencoder as the perceptual loss function. We combine these two methods and demonstrate their effectiveness on both CNN-based neural networks and WGAN-based neural networks with comprehensive experiments. Tested on the AAPM-Mayo Clinic Low Dose CT Grand Challenge data set, our experiments demonstrate that self-attention (SA) module and autoencoder (AE) perceptual loss function can efficiently enhance traditional CNNs and can achieve comparable or better results than the state-of-the-art methods.","1558-254X","","10.1109/TMI.2020.2968472","National Basic Research Program of China (973 Program)(grant numbers:2016YFB0402001); Beijing Major Science and Technology Project(grant numbers:Z191100010618003); National Natural Science Foundation of China (NSFC)(grant numbers:61520106004); PKU-UCLA Joint Research Institute; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8964295","Low-dose CT;denoising;self-attention;autoencoder;perceptual loss","Computed tomography;Noise reduction;Three-dimensional displays;Image reconstruction;Feature extraction;Convolutional neural networks","computerised tomography;convolutional neural nets;dosimetry;edge detection;feature extraction;image denoising;learning (artificial intelligence);medical image processing","low-dose CT denoising;self-supervised perceptual loss network;computed tomography;diagnostic tool;volumetric image;internal structures;noninvasive manner;image quality;deep learning;noise reduction;multilayer convolutional neural networks;CT images;CNN-based methods;convolutional kernels;structural information;3D self-attention convolutional neural network;LDCT denoising problem;3D self-attention module;spatial information;CT slices;self-supervised learning scheme;perceptual loss function;CNN-based neural networks;WGAN-based neural networks","Attention;Humans;Image Processing, Computer-Assisted;Neural Networks, Computer;Signal-To-Noise Ratio;Tomography, X-Ray Computed","48","","61","IEEE","22 Jan 2020","","","IEEE","IEEE Journals"
"Deep Residual Autoencoders for Expectation Maximization-Inspired Dictionary Learning","B. Tolooshams; S. Dey; D. Ba","School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; Manifold AI, Oakland, CA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA","IEEE Transactions on Neural Networks and Learning Systems","2 Jun 2021","2021","32","6","2415","2429","We introduce a neural-network architecture, termed the constrained recurrent sparse autoencoder (CRsAE), that solves convolutional dictionary learning problems, thus establishing a link between dictionary learning and neural networks. Specifically, we leverage the interpretation of the alternating-minimization algorithm for dictionary learning as an approximate expectation-maximization algorithm to develop autoencoders that enable the simultaneous training of the dictionary and regularization parameter (ReLU bias). The forward pass of the encoder approximates the sufficient statistics of the E-step as the solution to a sparse coding problem, using an iterative proximal gradient algorithm called FISTA. The encoder can be interpreted either as a recurrent neural network or as a deep residual network, with two-sided ReLU nonlinearities in both cases. The M-step is implemented via a two-stage backpropagation. The first stage relies on a linear decoder applied to the encoder and a norm-squared loss. It parallels the dictionary update step in dictionary learning. The second stage updates the regularization parameter by applying a loss function to the encoder that includes a prior on the parameter motivated by Bayesian statistics. We demonstrate in an image-denoising task that CRsAE learns Gabor-like filters and that the EM-inspired approach for learning biases is superior to the conventional approach. In an application to recordings of electrical activity from the brain, we demonstrate that CRsAE learns realistic spike templates and speeds up the process of identifying spike times by 900× compared with algorithms based on convex optimization.","2162-2388","","10.1109/TNNLS.2020.3005348","NSF Simons Center for Mathematical and Statistical Analysis of Biology, Harvard University(grant numbers:DMS-1764269); Harvard FAS Quantitative Biology Initiative; AWS Machine Learning Research Awards; ARO(grant numbers:W911NF-16-1-0368); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144476","Autoencoders (AEs);convolutional sparse coding (CSC);deep residual networks;dictionary learning;expectation maximization (EM);image denoising;spike sorting","Machine learning;Dictionaries;Convolutional codes;Sorting;Training;Convolution;Decoding","backpropagation;Bayes methods;expectation-maximisation algorithm;gradient methods;image denoising;image representation;iterative methods;minimisation;recurrent neural nets","neural-network architecture;constrained recurrent sparse autoencoder;CRsAE;convolutional dictionary learning problems;alternating-minimization algorithm;expectation-maximization algorithm;regularization parameter;encoder;sparse coding problem;iterative proximal gradient algorithm;recurrent neural network;deep residual network;deep residual autoencoders;expectation maximization-inspired dictionary learning","","6","","44","IEEE","20 Jul 2020","","","IEEE","IEEE Journals"
"Adaptive marginalized stacked denoising autoencoders and its application","Z. -b. Yu; C. -x. Chen; R. Pang; T. -w. Chen","School of Electrical Engineering, Southwest Jiaotong University, Chengdu, Sichuan, CN; School of Economics and Management, Chengdu Technological University, China; School of Electrical Engineering, Southwest Jiaotong University, Chengdu, Sichuan, CN; School of Information, Yunnan University of Finance and Economics, Kunming, Yunnan, CN","2016 35th Chinese Control Conference (CCC)","29 Aug 2016","2016","","","4107","4112","In this paper, we propose a modified marginalized autoencoders. Here, the noise adding way at a fixed rate in marginalized autoencoders is replaced by the adaptive noise injection. Compared with the traditional marginalized autoencoders, the proposed method obviously enlarges the recognition performance. Furthermore, the proposed method is applied to identify high-speed train wheel wear conditions. Features of high speed train wheels wear vibration signals are abstracted by using the adaptive noise marginalized autoencoders, and the features is used to realize the wheel wear characteristics of vibration signal recognitions as the input of support vector machine (SVM). The experimental results show that the accuracy of the new method for identifying high-speed train wheel wear conditions is 99.8% on average.","1934-1768","978-9-8815-6391-0","10.1109/ChiCC.2016.7553994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7553994","adaptive noise;stacked autoencoders;high-speed train;wheel wear state monitoring","Wheels;Noise reduction;Neurons;Training;Vibrations;Noise level;Manifolds","condition monitoring;encoding;railways;signal denoising;support vector machines;vibrational signal processing;wear;wheels","adaptive noise injection;high-speed train wheel wear conditions;high-speed train wheel wear vibration signals;adaptive noise marginalized autoencoders;wheel wear characteristics;vibration signal recognitions;support vector machine;SVM;wheel wear state monitoring","","1","","10","","29 Aug 2016","","","IEEE","IEEE Conferences"
"Speech Enhancement using K-Sparse Autoencoder Techniques","S. K. R. Chowdhury; A. Chatterjee",NA; NA,"2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS)","12 Apr 2021","2021","","","518","525","Speech signals are almost invariably corrupted with either background noise or mixed with other coherent speech. Various techniques are used for speech enhancement like Nonnegative matrix factorization (NMF), Independent component analysis (ICA) etc. One of the techniques is sparse coding and dictionary learning. For this standard algorithmic approaches use iterative techniques like KSVD and Orthogonal Matching Pursuit (OMP) which require significant memory and computation time to process successfully. We, however, use a novel approach of using k-sparse autoencoders which has not been previously used in speech processing. The proposed approach extends k-sparse autoencoders as a denoising autoencoder which allows us to achieve significantly better performance. This research work demonstrate that the use of k-sparse autoencoder has number of advantages especially it does not need any prior knowledge on the statistical characteristics of the noise and it performs much better on signals more heavily corrupted with noise. In addition to standard datasets,it's superior performance over other dictionary learning techniques are demonstrated on speech signals that are sensed on android phones.","","978-1-7281-9537-7","10.1109/ICAIS50930.2021.9396033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9396033","Speech enhancement;Sparse coding;Dictionary learning;K-Sparse autoencoder","Noise reduction;Matching pursuit algorithms;Machine learning;Speech enhancement;Sparse matrices;Standards;Smart phones","iterative methods;neural nets;signal denoising;smart phones;speech enhancement;statistical analysis","speech enhancement;sparse coding;iterative techniques;speech processing;denoising autoencoder;dictionary learning;speech signals;k-sparse autoencoder;background noise;statistical characteristics;Android phones","","","","46","","12 Apr 2021","","","IEEE","IEEE Conferences"
"Signal reconstruction by means of Embedding, Clustering and AutoEncoder Ensembles","C. Mio; G. Gianini","Dipartimento di Informatica,, Universita degli Studi di Milano, Milano (MI), Italy; Hadbat Al Zaafran, EBTIC/Khalifa University of Science and Technology,, Abu Dhabi, UAE","2019 IEEE Symposium on Computers and Communications (ISCC)","27 Jan 2020","2019","","","1","6","We study the denoising and reconstruction of corrupted signals by means of AutoEncoder ensembles. In order to guarantee experts' diversity in the ensemble, we apply, prior to learning, a dimensional reduction pass (to map the examples into a suitable Euclidean space) and a partitional clustering pass: each cluster is then used to train a distinct AutoEncoder. We study the approach with an audio file benchmark: the original signals are artificially corrupted by Doppler effect and reverb. The results support the comparative effectiveness of the approach, w.r.t. the approach based on a single AutoEncoder. The processing pipeline using Local Linear Embedding, k means, then k Convolutional Denoising AutoEncoders reduces the reconstruction error by 35% w.r.t. the baseline approach.","2642-7389","978-1-7281-2999-0","10.1109/ISCC47284.2019.8969655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8969655","","Noise reduction;Clustering algorithms;Spectrogram;Partitioning algorithms;Doppler effect;Training;Task analysis","audio signal processing;feature extraction;learning (artificial intelligence);neural nets;pattern clustering;signal denoising;signal reconstruction","Euclidean space;partitional clustering pass;audio file benchmark;reverb;single autoencoder;convolutional denoising autoencoders;reconstruction error;baseline approach;signal reconstruction;corrupted signals;dimensional reduction pass;autoencoder ensembles;local linear embedding;distinct autoencoder","","2","","14","","27 Jan 2020","","","IEEE","IEEE Conferences"
"Point spread function modelling for wide-field small-aperture telescopes with a denoising autoencoder","P. Jia; X. Li; Z. Li; W. Wang; D. Cai","College of Physics and Optoelectronics, Taiyuan University of Technology, Taiyuan, 030024, China; Key Laboratory of Advanced Transducers and Intelligent Control Systems, Ministry of Education and Shanxi Province, Taiyuan University of Technology, Taiyuan, 030024, China; Department of Physics, Durham University, South Road, Durham, DH1 3LE; robinmartin20@gmail.com; College of Physics and Optoelectronics, Taiyuan University of Technology, Taiyuan, 030024, China; Nanjing Institute of Astronomical Optics and Technology CAS, Nanjing, Jiangsu, 210042, China; Wuxi Internet of Innovation Center Company Limited, Wuxi, Jiangsu, 214135, China; College of Physics and Optoelectronics, Taiyuan University of Technology, Taiyuan, 030024, China","Monthly Notices of the Royal Astronomical Society","9 Jun 2020","2020","493","1","651","660","The point spread function reflects the state of an optical telescope and it is important for the design of data post-processing methods. For wide-field small-aperture telescopes, the point spread function is hard to model because it is affected by many different effects and has strong temporal and spatial variations. In this paper, we propose the use of a denoising autoencoder, a type of deep neural network, to model the point spread function of wide-field small-aperture telescopes. The denoising autoencoder is a point spread function modelling method, based on pure data, which uses calibration data from real observations or numerical simulated results as point spread function templates. According to real observation conditions, different levels of random noise or aberrations are added to point spread function templates, making them realizations of the point spread function (i.e. simulated star images). Then we train the denoising autoencoder with realizations and templates of the point spread function. After training, the denoising autoencoder learns the manifold space of the point spread function and it can map any star images obtained by wide-field small-aperture telescopes directly to its point spread function. This could be used to design data post-processing or optical system alignment methods.","1365-2966","","10.1093/mnras/staa319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9111154","methods: numerical;techniques: image processing;telescopes","","","","","","","","","9 Jun 2020","","","OUP","OUP Journals"
"Robust Belief State Space Representation for Statistical Dialogue Managers Using Deep Autoencoders","F. Lygerakis; V. Diakoloulas; M. Lagoudakis; M. Kotti","School of Electrical & Computer Engineering, Technical University of Crete, Greece; School of Electrical & Computer Engineering, Technical University of Crete, Greece; School of Electrical & Computer Engineering, Technical University of Crete, Greece; Speech Technology Group, Toshiba Research Cambridge, UK","2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)","20 Feb 2020","2019","","","1055","1061","Statistical Dialogue Systems (SDS) have proved their humongous potential over the past few years. However, the lack of efficient and robust representations of the belief state (BS) space refrains them from revealing their full potential. There is a great need for automatic BS representations, which will replace the old hand-crafted, variable-length ones. To tackle those problems, we introduce a novel use of Autoencoders (AEs). Our goal is to obtain a low-dimensional, fixed-length, and compact, yet robust representation of the BS space. We investigate the use of dense AE, Denoising AE (DAE) and Variational Denoising AE (VDAE), which we combine with GP-SARSA to learn dialogue policies in the PyDial toolkit. In this framework, the BS is normally represented in a relatively compact, but still redundant summary space which is obtained through a heuristic mapping of the original master space. We show that all the proposed AE-based representations consistently outperform the summary BS representation. Especially, as the Semantic Error Rate (SER) increases, the DAE/VDAE-based representations obtain state-of-the-art and sample efficient performance.","","978-1-7281-0306-8","10.1109/ASRU46091.2019.9003871","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003871","denoising autoencoder;variational autoencoder;statistical dialogue system;dialogue manager;belief state representation","Noise reduction;Feature extraction;Robustness;Training;Semantics;Standards;Decoding","interactive systems;learning (artificial intelligence);Markov processes;natural language processing","original master space;summary BS representation;robust belief state space representation;deep autoencoders;statistical dialogue systems;humongous potential;efficient representations;robust representations;automatic BS representations;old hand-crafted;low-dimensional length;fixed-length;robust representation;BS space;dialogue policies;redundant summary space;variational denoising AE;statistical dialogue managers;AE-based representations;SER;semantic error rate;DAE-VDAE-based representations;GP-SARSA","","1","","33","","20 Feb 2020","","","IEEE","IEEE Conferences"
"An Improved Sparse Autoencoder and Multilevel Denoising Strategy for Diagnosing Early Multiple Intermittent Faults","G. Xie; J. Yang; Y. Yang","School of Automation and Information Engineering, Xi&#x2019;an University of Technology, Xi&#x2019;an, China; School of Mechatronics and Automotive Engineering, Tianshui Normal University, Tianshui, China; School of Automation and Information Engineering, Xi&#x2019;an University of Technology, Xi&#x2019;an, China","IEEE Transactions on Systems, Man, and Cybernetics: Systems","14 Jan 2022","2022","52","2","869","880","Currently, the diagnosis of single fault marked by distinct characteristics has received mass concern, and the related research achievements are remarkable. However, the diagnosis of early multiple intermittent (EMI) faults commonly existing in industrial systems is still an intractable problem, owing to: 1) the scarcity of fault data and the faintness of features and 2) the mutual interaction of components and the coupling of fault characteristics. In order to address the problem, this article proposes an improved sparse autoencoder and multilevel denoising strategy (MDS-ISAE) for diagnosing EMI faults. First, a relational constraint term is constructed to mitigate the effect of data correlation. Second, a multilevel denoising strategy is designed to enhance the robustness of AE feature learning with strong background noise. Third, a resizable resampling strategy is planned to tackle the skew distribution of diagnosis data. Based on the above strategies, an MDS-ISAE-based model is constructed to achieve EMI faults diagnosis. Further, the evaluation criteria of diagnosis performance are proposed and the applicability of the method is tested. Finally, the effectiveness and practicability of the proposed method are verified by artificial damage and real fault experiments, respectively.","2168-2232","","10.1109/TSMC.2020.3005433","National Key Research and Development Program of China(grant numbers:2018YFB1201500,2018YFB1703000); National Natural Science Foundation of China(grant numbers:61873201,61773313,61773016); Key Research and Development Plan of Shaanxi Province(grant numbers:2018GY-139); Natural Science Foundation of Shaanxi Provincial Department of Education(grant numbers:19JS051); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141448","Early multiple intermittent (EMI) faults;fault diagnosis;multilevel denoising;relational constraint term;resizable resampling;sparse autoencoder","Electromagnetic interference;Fault diagnosis;Feature extraction;Gears;Noise reduction;Vibrations;Noise measurement","electromagnetic interference;fault diagnosis;neural nets;noise;production engineering computing","fault data;fault characteristics;improved sparse autoencoder;relational constraint term;MDS-ISAE-based model;EMI faults diagnosis;fault experiments","","1","","39","IEEE","15 Jul 2020","","","IEEE","IEEE Journals"
"Denoising Sequence-to-Sequence Modeling for Removing Spelling Mistakes","S. Roy","dept. of Computer Science and Engineering, Khulna University of Engineering & Technology, Khulna, Bangladesh","2019 1st International Conference on Advances in Science, Engineering and Robotics Technology (ICASERT)","19 Dec 2019","2019","","","1","5","Rule-based spelling correction system focused on finding the most matched word with the misspelled word. But this approach does not work well inside a sentence with multiple errors that has a combination of possible correct words to replace but only one current sentence. Replacing each word individually will result in errors. So, the spelling corrector system must understand the context of the sentence including the tense and gender of the subject and so on. The most popular example of typing mistake correction is the one Google provides in their search engine. It was introduced quite a while ago but no such good performing system is developed by anyone else. In this work, we have proposed a spelling correction system using deep learning. The basic intuition of our approach is taken from denoising autoencoder. Here we have trained the model with noisy input generated by changing, removing or adding extra character at random position inside the sequence. The job of the model is to model this noisy input to output the original errorless sequence. We have experimented with large English dataset and reported the performance in terms of character level accuracy. The proposed model has shown impressive results in correcting the spelling mistakes.","","978-1-7281-3445-1","10.1109/ICASERT.2019.8934902","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8934902","Sequence modeling;Attention;Spelling correction","Decoding;Noise measurement;Noise reduction;Computational modeling;Deep learning;Image reconstruction;Natural language processing","learning (artificial intelligence);natural language processing;neural nets;search engines;signal denoising;spelling aids","correct words;spelling corrector system;gender;typing mistake correction;search engine;spelling correction system;denoising autoencoder;noisy input;original errorless sequence;spelling mistakes;sequence-to-sequence modeling;matched word;misspelled word;adding extra character","","2","","11","","19 Dec 2019","","","IEEE","IEEE Conferences"
"Hyperspectral Stimulated Raman Scattering Image Enhancement, Denoising and Segmentation via a Deep Neural-Net","P. Abdolghader; A. Ridsdale; T. Grammatikopoulos; F. Légaré; A. Stolow; A. F. Pegoraro; I. Tamblyn","Security and Disruptive Technologies, National Research Council Canada, Ottawa, ON, Canada; Security and Disruptive Technologies, National Research Council Canada, Ottawa, ON, Canada; SGS Canada Inc, Lakefield, ON, Canada; ALLS Laboratory, Institut National de la Recherche Scientifique, Centre EMT, Varennes, QC, Canada; Max-Planck-uOttawa Centre for Extreme and Quantum Photonics, Ottawa, ON, Canada; Security and Disruptive Technologies, National Research Council Canada, Ottawa, ON, Canada; Vector Institute, Toronto, Ontario, Canada","2021 Photonics North (PN)","16 Nov 2021","2021","","","1","1","We demonstrate the use of an unsupervised convolutional autoencoder neural network to denoise and segment hyperspectral Stimulated Raman Scattering images.","2693-8316","978-1-6654-4483-5","10.1109/PN52152.2021.9597933","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9597933","Stimulated Raman Scattering microscopy;deep convolutional neural net;pattern recognition;classification","Image segmentation;Image recognition;Microscopy;Raman scattering;Noise reduction;Neural networks;Image enhancement","convolutional neural nets;deep learning (artificial intelligence);hyperspectral imaging;image denoising;image enhancement;image segmentation;stimulated Raman scattering;unsupervised learning","deep neural-net;unsupervised convolutional autoencoder neural network;image enhancement;image denoising;image segmentation;hyperspectral stimulated Raman scattering images","","","","4","IEEE","16 Nov 2021","","","IEEE","IEEE Conferences"
"Locomotion Activity Recognition Using Stacked Denoising Autoencoders","F. Gu; K. Khoshelham; S. Valaee; J. Shang; R. Zhang","Department of Infrastructure Engineering, University of Melbourne, Parkville, VIC, Australia; Department of Infrastructure Engineering, University of Melbourne, Parkville, VIC, Australia; Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON, Canada; Faculty of Information Engineering, China University of Geosciences and the National Engineering Research Center for Geographic Information System, Wuhan, China; Department of Computing Information Systems, University of Melbourne, Parkville, VIC, Australia","IEEE Internet of Things Journal","8 Jun 2018","2018","5","3","2085","2093","Locomotion activity recognition (LAR) is important for a number of applications, such as indoor localization, fitness tracking, and aged care. Existing methods usually use handcrafted features, which requires expert knowledge and is laborious, and the achieved result might still be suboptimal. To relieve the burden of designing and selecting features, we propose a deep learning method for LAR by using data from multiple sensors available on most smart devices. Experimental results show that the proposed method, which learns useful features automatically, outperforms conventional classifiers that require the hand-engineering of features. We also show that the combination of sensor data from four sensors (accelerometer, gyroscope, magnetometer, and barometer) achieves a higher accuracy than other combinations or individual sensors.","2327-4662","","10.1109/JIOT.2018.2823084","National Natural Science Foundation of China(grant numbers:41271440); China Scholarship Council—University of Melbourne Research Scholarship(grant numbers:CSC 201408420117); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8331081","Activity recognition;autoencoder;deep learning;motion state recognition;neural network;smartphone sensor","Feature extraction;Activity recognition;Magnetic sensors;Intelligent sensors;Machine learning;Accelerometers","accelerometers;feature extraction;feature selection;gyroscopes;image denoising;learning (artificial intelligence);sensors","sensor data;locomotion activity recognition;LAR;indoor localization;fitness tracking;aged care;handcrafted features;expert knowledge;deep learning method;multiple sensors;selecting features;stacked denoising autoencoders;smart devices;hand-engineering;accelerometer;gyroscope;magnetometer;barometer","","48","","47","IEEE","4 Apr 2018","","","IEEE","IEEE Journals"
"Activity Recognition using Deep Denoising Autoencoder","M. H. Mohd Noor; M. A. Ahmadon; M. K. Osman","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Graduate School of Sciences, Technology for Innovation, Yamaguchi University, Japan; Fakulti Kejuruteraan Elektrik Universiti Teknologi MARA, Pulau Pinang, Malaysia","2019 9th IEEE International Conference on Control System, Computing and Engineering (ICCSCE)","16 Apr 2020","2019","","","188","192","Existing feature extraction method for activity recognition is time consuming and laborious and prone to error. This paper proposes an unsupervised deep learning method for feature learning in activity recognition using tri-axial accelerometer. The proposed method extracts the relevant features automatically, eliminating the needs of feature extraction and selection stages. We evaluate and compared the proposed method with the conventional method in terms of recognition accuracy on a public dataset with wide range of activities. Results have shown that the proposed method achieved a better performance, improving the recognition accuracy by 0.03.","","978-1-7281-3500-7","10.1109/ICCSCE47578.2019.9068571","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068571","Activity recognition;autoencoder;deep learning;accelerometer","Feature extraction;Activity recognition;Noise reduction;Microsoft Windows;Training;Accelerometers","accelerometers;feature extraction;feature selection;image coding;image denoising;image recognition;unsupervised learning","deep denoising autoencoder;feature extraction method;activity recognition;unsupervised deep learning method;triaxial accelerometer","","1","","11","","16 Apr 2020","","","IEEE","IEEE Conferences"
"Cosaliency Detection Based on Intrasaliency Prior Transfer and Deep Intersaliency Mining","D. Zhang; J. Han; J. Han; L. Shao","School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; Department of Computer Science and Digital Technologies, Northumbria University, Newcastle upon Tyne, U.K.; Department of Computer Science and Digital Technologies, Northumbria University, Newcastle upon Tyne, U.K.","IEEE Transactions on Neural Networks and Learning Systems","20 May 2017","2016","27","6","1163","1176","As an interesting and emerging topic, cosaliency detection aims at simultaneously extracting common salient objects in multiple related images. It differs from the conventional saliency detection paradigm in which saliency detection for each image is determined one by one independently without taking advantage of the homogeneity in the data pool of multiple related images. In this paper, we propose a novel cosaliency detection approach using deep learning models. Two new concepts, called intrasaliency prior transfer and deep intersaliency mining, are introduced and explored in the proposed work. For the intrasaliency prior transfer, we build a stacked denoising autoencoder (SDAE) to learn the saliency prior knowledge from auxiliary annotated data sets and then transfer the learned knowledge to estimate the intrasaliency for each image in cosaliency data sets. For the deep intersaliency mining, we formulate it by using the deep reconstruction residual obtained in the highest hidden layer of a self-trained SDAE. The obtained deep intersaliency can extract more intrinsic and general hidden patterns to discover the homogeneity of cosalient objects in terms of some higher level concepts. Finally, the cosaliency maps are generated by weighted integration of the proposed intrasaliency prior, deep intersaliency, and traditional shallow intersaliency. Comprehensive experiments over diverse publicly available benchmark data sets demonstrate consistent performance gains of the proposed method over the state-of-the-art cosaliency detection methods.","2162-2388","","10.1109/TNNLS.2015.2495161","National Natural Science Foundation of China(grant numbers:61473231,61522207); Doctorate Foundation through Northwestern Polytechnical University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7327212","Cosaliency detection;deep learning;prior transfer;stacked denoising autoencoder (SDAE).;Cosaliency detection;deep learning;prior transfer;stacked denoising autoencoder (SDAE)","Encoding;Machine learning;Data mining;Feature extraction;Training;Robustness;Visualization","data mining;image coding;image denoising;learning (artificial intelligence);object detection","cosaliency detection;intrasaliency prior transfer;deep intersaliency mining;saliency detection paradigm;data pool;deep learning models;stacked denoising autoencoder;auxiliary annotated datasets;deep reconstruction residual;self-trained SDAE;shallow intersaliency;publicly available benchmark datasets","","126","","53","IEEE","11 Nov 2015","","","IEEE","IEEE Journals"
"Two-Stage Learning to Predict Human Eye Fixations via SDAEs","J. Han; D. Zhang; S. Wen; L. Guo; T. Liu; X. Li","School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; Department of Computer Science, The University of Georgia, Athens, GA, USA; Center for OPTical IMagery Analysis and Learning, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China","IEEE Transactions on Cybernetics","20 May 2017","2016","46","2","487","498","Saliency detection models aiming to quantitatively predict human eye-attended locations in the visual field have been receiving increasing research interest in recent years. Unlike traditional methods that rely on hand-designed features and contrast inference mechanisms, this paper proposes a novel framework to learn saliency detection models from raw image data using deep networks. The proposed framework mainly consists of two learning stages. At the first learning stage, we develop a stacked denoising autoencoder (SDAE) model to learn robust, representative features from raw image data under an unsupervised manner. The second learning stage aims to jointly learn optimal mechanisms to capture the intrinsic mutual patterns as the feature contrast and to integrate them for final saliency prediction. Given the input of pairs of a center patch and its surrounding patches represented by the features learned at the first stage, a SDAE network is trained under the supervision of eye fixation labels, which achieves both contrast inference and contrast integration simultaneously. Experiments on three publically available eye tracking benchmarks and the comparisons with 16 state-of-the-art approaches demonstrate the effectiveness of the proposed framework.","2168-2275","","10.1109/TCYB.2015.2404432","National Natural Science Foundation of China(grant numbers:61473231,61333017); Doctoral Fund of Ministry of Education of China(grant numbers:20136102110037); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7051244","Deep networks;eye fixation prediction;saliency detection;stacked denoising autoencoders (SDAEs);Deep networks;eye fixation prediction;saliency detection;stacked denoising autoencoders (SDAEs)","Feature extraction;Visualization;Computational modeling;Data models;Noise reduction;Image color analysis;Robustness","image denoising;inference mechanisms;learning (artificial intelligence)","two-stage learning;human eye fixation prediction;SDAE;saliency detection models;human eye-attended locations;contrast inference mechanisms;raw image data;deep networks;stacked denoising autoencoder;SDAE model;intrinsic mutual patterns;feature contrast;SDAE network;eye fixation labels;contrast inference;contrast integration","Algorithms;Fixation, Ocular;Humans;Models, Statistical;Pattern Recognition, Automated","98","","60","IEEE","27 Feb 2015","","","IEEE","IEEE Journals"
"Fault detection for ironmaking process based on stacked denoising autoencoders","T. Zhang; W. Wang; H. Ye; D. Huang; H. Zhang; Mingliang Li","Department of Automation, Tsinghua University, Beijing, P. R. China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, P. R. China; Guangxi Liuzhou Iron and Steel (Group) Company, Liuzhou, China; Department of Automation, Tsinghua University, Beijing, P. R. China; Guangxi Liuzhou Iron and Steel (Group) Company, Liuzhou, China; Guangxi Liuzhou Iron and Steel (Group) Company, Liuzhou, China","2016 American Control Conference (ACC)","1 Aug 2016","2016","","","3261","3267","It is quite challenging to monitor an ironmaking process due to some of its special characteristics such as lack of direct measurements and strong disturbances. Hence extracting robust features of the normal process from complex historical data is vitally important. Denoising autoencoder (dA), a recently developed deep learning technique, has become a popular tool to extract and compose robust features. However, its application to fault detection in process control fields are still limited. In this paper, a denoising autoencoder based monitoring approach is proposed for a practical ironmaking process, in which peak-like disturbances due to the switchings between two arbitrary distinct host-blast stoves are involved. To validate the proposed monitoring method, the data corresponding to a cold furnace fault of the process is used and comparative fault detection performances with the existing methods are presented.","2378-5861","978-1-4673-8682-1","10.1109/ACC.2016.7525420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7525420","","Noise reduction;Principal component analysis;Monitoring;Feature extraction;Robustness;Blast furnaces;Stacking","fault diagnosis;learning (artificial intelligence);production engineering computing;signal denoising;steel manufacture","ironmaking process;stacked denoising autoencoders;feature extraction;deep learning technique;monitoring method;cold furnace fault;fault detection performances","","7","","32","","1 Aug 2016","","","IEEE","IEEE Conferences"
"Robust Polyphonic Sound Event Detection by Using Multi Frame Size Denoising Autoencoder","J. Zhou; X. Chen; D. Yang","Institute of Computer Science & Technology, Peking University, Haidian District, Beijing, P.R.China; Institute of Computer Science & Technology, Peking University, Haidian District, Beijing, P.R.China; Institute of Computer Science & Technology, Peking University, Haidian District, Beijing, P.R.China","2018 IEEE 20th International Workshop on Multimedia Signal Processing (MMSP)","29 Nov 2018","2018","","","1","6","Over the past few years, lots of research has been done on polyphonic sound event detection. A main problem with sound event detection is that the detection performance sharply degrades in the presence of noise. As denoising autoencoder reportedly has superior performance in noisy environments, this paper proposes to use denoising autoencoder, which is trained by multi frame size information of audio signals, to extract robust features in a task of polyphonic sound event detection under noisy conditions. Performance of the extracted feature is evaluated by polyphonic sound event detection experiments with different noise levels, and compared with that of baseline features including Mel-band Energy (Mel), Log mel-band Energy (Logmel) and mel-frequency cepstral coefficients (MFCC). The experiemntal results show that the proposed feature has the best robustness among all features and achieves the best detection effect under noisy conditions.","2473-3628","978-1-5386-6070-6","10.1109/MMSP.2018.8547060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8547060","","Feature extraction;Event detection;Noise reduction;Mel frequency cepstral coefficient;Training;Noise measurement;Spectrogram","acoustic signal detection;audio signal processing;cepstral analysis;feature extraction;signal denoising;speech recognition","MFCC;mel-frequency cepstral coefficients;log mel-band energy;mel-band energy;baseline features;robust features extraction;audio signals;robust polyphonic sound event detection experiments;robust features;multiframe size information;detection performance;multiframe size denoising autoencoder;detection effect;noisy conditions","","1","","19","","29 Nov 2018","","","IEEE","IEEE Conferences"
"Hybrid Collaborative Filtering with Semi-Stacked Denoising Autoencoders for Recommendation","H. Zou; C. Chen; C. Zhao; B. Yang; Z. Kang","School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China","2019 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)","4 Nov 2019","2019","","","87","93","Recommender system is one of the solutions to deal with information overload problem, thus has been intensively studied. In recent research, side information has been commonly used besides the rating matrix, so as to mitigate the sparsity problem and to improve the recommendation accuracy. To better making use of side information, deep learning based recommendation methods have been proposed, among which autoencoder-based models have become quite popular. However, most existing autoencoder-based models require the each input corresponds to one output, which may bring in information loss and high cost to extend autoencoders, thus affects the recommendation accuracy. To address this important issue, in this paper we first propose a Semi-Stacked Denoising Autoencoders (Semi-SDAE) model; then a new hybrid CF model incorporating the proposed Semi-SDAE model into matrix factorization, HCF-SS model, is developed. The HCF-SS model can flexibly use various sources of side information and the recommendation accuracy is improved. Experiments on two real-world datasets demonstrate that the proposed HCF-SS model outperforms the compared models.","","978-1-7281-3024-8","10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890263","Collaborative Filtering, Side Information, Rating Prediction, Autoencoder","Feature extraction;Filtering;Computer science;Transforms;Collaboration;Noise reduction;Deep learning","collaborative filtering;learning (artificial intelligence);matrix decomposition;recommender systems","hybrid collaborative filtering;deep learning based recommender system;information overload problem;rating matrix;sparsity problem;information loss;hybrid CF model;HCF-SS model;semistacked denoising autoencoders-based models;semiSDAE model;matrix factorization","","5","","16","","4 Nov 2019","","","IEEE","IEEE Conferences"
"Heartbeat classification system based on modified stacked denoising autoencoders and neural networks","C. Jiang; S. Song; M. Q. . -H. Meng","Harbin Institute of Technology (Shenzhen), Shenzhen, China; Harbin Institute of Technology (Shenzhen), Shenzhen, China; Department of Electronic Engineering, Chinese University of Hong Kong, Hong Kong, China","2017 IEEE International Conference on Information and Automation (ICIA)","23 Oct 2017","2017","","","511","516","This paper introduces a complete heartbeat classification system based on modified stacked denoising autoencoders and neural networks. This system includes three parts and they are preprocessing, feature extraction, and classification. In the preprocessing part, the original ECG signal is filtered and segmented as each single heartbeat. In the feature extraction part, the features are extracted from the original heartbeat signal by using modified stacked denoising autoencoders. In the classification part, the neural networks are selected to classify the heartbeats, and achieves the accuracy of 97.99% on 16 classes of arrhythmic events. The proposed method not only achieves the high accuracy on heartbeats classification, but also gets rid of the works on feature designing compared with other similar methods.","","978-1-5386-3154-6","10.1109/ICInfA.2017.8078961","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8078961","Electrocardiogram;Arrhythmia;Autoencoders;Neural Networks","Feature extraction;Heart beat;Noise reduction;Neural networks;Electrocardiography;Training;Databases","electrocardiography;feature extraction;filtering theory;medical signal processing;neural nets;signal classification","modified stacked denoising autoencoders;neural networks;complete heartbeat classification system;preprocessing part;single heartbeat;feature extraction part;original heartbeat signal;classification part;original ECG signal filtering;original ECG signal segmentation","","2","","16","","23 Oct 2017","","","IEEE","IEEE Conferences"
"Intelligent Fault Diagnosis of Bearing Based on Stacked Denoising Autoencoders","K. Yang; Y. Ma; Y. Han","College of Information Science and Engineering, Hebei University of Science and Technology, Shijiazhaung, China; College of Information Science and Engineering, Hebei University of Science and Technology, Shijiazhaung, China; College of Information Science and Engineering, Hebei University of Science and Technology, Shijiazhaung, China","2018 IEEE 3rd International Conference on Cloud Computing and Internet of Things (CCIOT)","12 Mar 2020","2018","","","346","350","A fault diagnosis method based on stacked denosing autoencoder network is proposed to apply deep learning to equipment fault diagnosis. A deep-layer network model is established, pre-training is performed in a layer-by-layer greedy coding mode to achieve adaptive extraction and mining of high-dimensional deep fault features, and then a back-propagation algorithm is used to supervise fine-tune the model. The method integrates the two steps of feature extraction and state classification, and gets rid of the dependence of traditional machine learning methods on artificially extracted sample features, and effectively overcomes the problems of gradient disappearance and local extremum. Through the rolling bearing data experiment, the method's ability to identify and generalize faults was verified.","","978-1-5386-7141-2","10.1109/CCIOT45285.2018.9032655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9032655","Fault recognition;stacked denosing autoencoder;deep learning;rolling bearing","Fault diagnosis;Feature extraction;Training;Encoding;Machine learning;Rolling bearings;Noise reduction","fault diagnosis;feature extraction;learning (artificial intelligence);mechanical engineering computing;neural nets;pattern classification;rolling bearings","intelligent fault diagnosis;stacked denoising autoencoders;fault diagnosis method;stacked denosing autoencoder network;deep learning;equipment fault diagnosis;deep-layer network model;layer-by-layer greedy coding mode;adaptive extraction;mining;high-dimensional deep fault features;back-propagation algorithm;feature extraction;state classification;rolling bearing data experiment","","2","","5","","12 Mar 2020","","","IEEE","IEEE Conferences"
"One-Dimensional Residual Convolutional Autoencoder Based Feature Learning for Gearbox Fault Diagnosis","J. Yu; X. Zhou","School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China","IEEE Transactions on Industrial Informatics","30 Jun 2020","2020","16","10","6347","6358","Vibration signals are generally utilized for machinery fault diagnosis to perform timely maintenance and then reduce losses. Thus, the feature extraction on one-dimensional vibration signals often determines accuracy of those fault diagnosis models. These typical deep neural networks (DNNs), e.g., convolutional neural networks (CNNs), perform well in feature learning and have been applied in machine fault diagnosis. However, the supervised learning of CNN often requires a large amount of labeled images and thus limits its wide applications. In this article, a new DNN, one-dimensional residual convolutional autoencoder (1-DRCAE), is proposed for learning features from vibration signals directly in an unsupervised-learning way. First, 1-D convolutional autoencoder is proposed in 1-DRCAE for feature extraction. Second, a deconvolution operation is developed as decoder of 1-DRCAE to reconstruct the filtered signals. Third, residual learning is employed in 1-DRCAE to perform feature learning on 1-D vibration signals. The results show that 1-DRCAE has good signal denoising and feature extraction performance on vibration signals. It performs better on feature extraction than the typical DNNs, e.g., deep belief network, stacked autoencoders, and 1-D CNN.","1941-0050","","10.1109/TII.2020.2966326","National Natural Science Foundation of China(grant numbers:71777173); Fundamental Research Funds for the Central Universities; Shanghai science and Technology Innovation Fund(grant numbers:19511106303); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8957534","Convolutional autoencoder (CAE);feature learning;gearbox fault diagnosis;residual learning","Convolution;Feature extraction;Vibrations;Deconvolution;Fault diagnosis;Decoding;Kernel","condition monitoring;convolutional neural nets;fault diagnosis;feature extraction;gears;machinery;signal denoising;signal reconstruction;unsupervised learning;vibrational signal processing","1D convolutional autoencoder;one-dimensional residual convolutional autoencoder;convolutional neural networks;one-dimensional vibration signals;machinery fault diagnosis;gearbox fault diagnosis;signal denoising;feature learning;residual learning;signals reconstruction;1-DRCAE;feature extraction","","63","","28","IEEE","13 Jan 2020","","","IEEE","IEEE Journals"
"Stacked Denoising Autoencoder Enhanced Polar Codes Over Rayleigh Fading Channels","J. Li; W. Cheng","State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China","IEEE Wireless Communications Letters","9 Mar 2020","2020","9","3","354","357","Polar codes, with low encoding/decoding complexity and capacity-achieving potential, have drawn much attention recently. It is very critical to study the impact of fading on polar codes implementation into wireless communications. Existing research works on polar codes over the fading channel use simplified fading channel models while further reducing the frame error rate is highly needed. In this letter, using the structure of polar codes we propose the deep learning based scheme for polar codes over Rayleigh fading channels. Simulation results verify that our proposed scheme can significantly decrease the frame error rate for polar codes over Rayleigh fading channels.","2162-2345","","10.1109/LWC.2019.2954907","National Natural Science Foundation of China(grant numbers:61771368); Young Elite Scientists Sponsorship Program by CAST(grant numbers:2016QNRC001); Key Research and Development Plan of Shaanxi Province(grant numbers:2018ZDCXL-GY-04-06); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908726","Polar codes;deep learning;stacked denoising autoencoder;Rayleigh fading channel","Fading channels;Training;Deep learning;Decoding;Neural networks;Noise reduction","channel coding;error statistics;learning (artificial intelligence);Rayleigh channels;telecommunication computing","deep learning based scheme;simplified fading channel models;wireless communications;fading channel use;Rayleigh fading channels;stacked denoising autoencoder enhanced polar codes","","","","11","IEEE","21 Nov 2019","","","IEEE","IEEE Journals"
"A Connection Between Score Matching and Denoising Autoencoders","P. Vincent","Département d'Informatique, Université de Montréal, Montréal (QC) H3C 3J7, Canada vincentp@iro.umontreal.ca","Neural Computation","19 May 2014","2011","23","7","1661","1674","Denoising autoencoders have been previously shown to be competitive alternatives to restricted Boltzmann machines for unsupervised pretraining of each layer of a deep architecture. We show that a simple denoising autoencoder training criterion is equivalent to matching the score (with respect to the data) of a specific energy-based model to that of a nonparametric Parzen density estimator of the data. This yields several useful insights. It defines a proper probabilistic model for the denoising autoencoder technique, which makes it in principle possible to sample from them or rank examples by their energy. It suggests a different way to apply score matching that is related to learning to denoise and does not require computing second derivatives. It justifies the use of tied weights between the encoder and decoder and suggests ways to extend the success of denoising autoencoders to a larger family of energy-based models.","0899-7667","","10.1162/NECO_a_00142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6795935","","","","","","44","1","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Convolutional deep denoising autoencoders for radio astronomical images","C. Gheller; F. Vazza","Istituto di Radio Astronomia, INAF, Via Gobetti 101, I-40121 Bologna, Italy; claudio.gheller@gmail.com; Istituto di Radio Astronomia, INAF, Via Gobetti 101, I-40121 Bologna, Italy; Hamburger Sternwarte, Gojenbergsweg 112, D-21029 Hamburg, Germany; Dipartimento di Fisica e Astronomia, Universitá di Bologna, Via Gobetti 92/3, I-40121 Bologna, Italy","Monthly Notices of the Royal Astronomical Society","13 Dec 2021","2021","509","1","990","1009","We apply a Machine Learning technique known as Convolutional Denoising Autoencoder to denoise synthetic images of state-of-the-art radio telescopes, with the goal of detecting the faint, diffused radio sources predicted to characterize the radio cosmic web. In our application, denoising is intended to address both the reduction of random instrumental noise and the minimization of additional spurious artefacts like the sidelobes, resulting from the aperture synthesis technique. The effectiveness and the accuracy of the method are analysed for different kinds of corrupted input images, together with its computational performance. Specific attention has been devoted to create realistic mock observations for the training, exploiting the outcomes of cosmological numerical simulations, to generate images corresponding to LOFAR HBA 8 h observations at 150 MHz. Our autoencoder can effectively denoise complex images identifying and extracting faint objects at the limits of the instrumental sensitivity. The method can efficiently scale on large data sets, exploiting high-performance computing solutions, in a fully automated way (i.e. no human supervision is required after training). It can accurately perform image segmentation, identifying low brightness outskirts of diffused sources, proving to be a viable solution for detecting challenging extended objects hidden in noisy radio observations.","1365-2966","","10.1093/mnras/stab3044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9648112","methods: numerical;intergalactic medium;large-scale structure of Universe","","","","","","","","","13 Dec 2021","","","OUP","OUP Journals"
"Generating Classification Weights With GNN Denoising Autoencoders for Few-Shot Learning","S. Gidaris; N. Komodakis","valeo.ai; LIGM, Ecole des Ponts ParisTech, University Paris-Est","2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","21","30","Given an initial recognition model already trained on a set of base classes, the goal of this work is to develop a meta-model for few-shot learning. The meta-model, given as input some novel classes with few training examples per class, must properly adapt the existing recognition model into a new model that can correctly classify in a unified way both the novel and the base classes. To accomplish this goal it must learn to output the appropriate classification weight vectors for those two types of classes. To build our meta-model we make use of two main innovations: we propose the use of a Denoising Autoencoder network (DAE) that (during training) takes as input a set of classification weights corrupted with Gaussian noise and learns to reconstruct the target-discriminative classification weights. In this case, the injected noise on the classification weights serves the role of regularizing the weight generating meta-model. Furthermore, in order to capture the co-dependencies between different classes in a given task instance of our meta-model, we propose to implement the DAE model as a Graph Neural Network (GNN). In order to verify the efficacy of our approach, we extensively evaluate it on ImageNet based few-shot benchmarks and we report state-of-the-art results.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8953942","Deep Learning;Recognition: Detection;Categorization;Retrieval","","graph theory;image classification;learning (artificial intelligence);neural nets;object recognition","image classification;ImageNet based few-shot benchmarks;graph neural network;graph neural network;denoising autoencoder network;classification weights generation;recognition model;few-shot learning;GNN denoising autoencoders;DAE model;target-discriminative classification weights;meta-model;classification weight vectors","","80","1","43","","9 Jan 2020","","","IEEE","IEEE Conferences"
"Combatting Adversarial Attacks through Denoising and Dimensionality Reduction: A Cascaded Autoencoder Approach","R. Sahay; R. Mahfuz; A. E. Gamal","School of Electrical and Computer Engineering, Purdue University; School of Electrical and Computer Engineering, Purdue University; School of Electrical and Computer Engineering, Purdue University","2019 53rd Annual Conference on Information Sciences and Systems (CISS)","18 Apr 2019","2019","","","1","6","Machine Learning models are vulnerable to adversarial attacks that rely on perturbing the input data. This work proposes a novel strategy using Autoencoder Deep Neural Networks to defend a machine learning model against two gradient-based attacks: The Fast Gradient Sign attack and the Fast Gradient attack. First we use an autoencoder to denoise the test data, which is trained with both clean and corrupted data. Then, we reduce the dimension of the denoised data using the hidden layer representation of another autoencoder. We perform this experiment for multiple values of the bound of adversarial perturbations, and consider different numbers of reduced dimensions. When the test data is preprocessed using this cascaded pipeline, the tested deep neural network classifier yields a much higher accuracy, thus mitigating the effect of the adversarial perturbation.","","978-1-7281-1151-3","10.1109/CISS.2019.8692918","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8692918","","Neural networks;Perturbation methods;Noise reduction;Training;Dimensionality reduction;Machine learning algorithms;Testing","feature extraction;gradient methods;learning (artificial intelligence);neural nets;pattern classification;security of data","machine learning model;test data;clean data;corrupted data;denoised data;hidden layer representation;adversarial perturbation;cascaded pipeline;adversarial attacks;dimensionality reduction;input data;machine learning models;autoencoder deep neural networks;cascaded autoencoder approach;deep neural network classifier;fast gradient sign attack","","5","","14","","18 Apr 2019","","","IEEE","IEEE Conferences"
"A Batch Normalization Autoencoder Model for Breast Cancer Multidimensional Follow-up Data","X. Liu; Z. Shi; X. Zhang; C. Yang","University of Science and Technology Beijing, Beijing, China; University of Science and Technology Beijing, Beijing, China; University of Science and Technology Beijing, Beijing, China; University of Science and Technology Beijing, Beijing, China","2018 IEEE International Conference on Smart Internet of Things (SmartIoT)","16 Sep 2018","2018","","","178","185","The traditional follow-up model is insufficient in terms of processing speed and accuracy, which results in poor analysis. In addition, a unidimensional follow-up data limits the reliability of analysis. Aimed at the problems, a deep neural network model is constructed, that is based on stacked denoising sparse autoencoder with batch normalization algorithm to deal with data of ten dimensions. It not only improves the learning ability of the autoencoder, but also enhances the prediction ability of the follow-up model. The follow-up data sets are derived from Peking University First Hospital, the Second Hospital of Shandong University and so on. ROC curve and AUC are used as evaluation indicators. The experiments indicate the model has advanced performance in both accuracy and stability for prediction than traditional machine learning algorithms.","","978-1-5386-8543-3","10.1109/SmartIoT.2018.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8465546","autoencoder, deep network, follow-up, multi-dimension","Breast cancer;Data models;Predictive models;Biological neural networks;Training;Noise reduction;Neurons","cancer;educational institutions;encoding;feature extraction;image denoising;learning (artificial intelligence);medical computing;neural nets;prediction theory;reliability;sensitivity analysis;stability","processing speed;Peking university;hospital;machine learning algorithms;breast cancer multidimensional follow up data;unidimensional follow up data;reliability;Shandong university;ROC curve;AUC;stability;prediction ability;learning ability;batch normalization algorithm;stacked denoising sparse autoencoder;deep neural network model;data limits;batch normalization autoencoder model","","2","","21","","16 Sep 2018","","","IEEE","IEEE Conferences"
"Joint Distribution Learning in the Framework of Variational Autoencoders for Far-Field Speech Enhancement","M. K. Chelimilla; S. Kumar; S. P. Rath","Samsung Research Institute India, Bangalore; Samsung Research Institute India, Bangalore; Samsung Research Institute India, Bangalore","2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)","20 Feb 2020","2019","","","245","251","Far-field speech recognition is a challenging task as speech recognizers trained on close-talk speech do not generalize well to far-field speech. In order to handle such issues, neural network based speech enhancement is typically applied using denoising autoencoder (DA). Recently generative models have become more popular particularly in the field of image generation and translation. One of the popular techniques in this generative framework is variational autoencoder (VAE). In this paper we consider VAE for speech enhancement task in the context of automatic speech recognition (ASR). We propose a novel modification in the conventional VAE to model joint distribution of the far-field and close-talk features for a common latent space representation, which we refer to as joint-VAE. Unlike conventional VAE, joint-VAE involves one encoder network that projects the far-field features onto a latent space and two decoder networks that generate close-talk and far-field features separately. Experiments conducted on the AMI corpus show that it gives a relative WER improvement of 9% compared to conventional DA and a relative improvement of 19.2% compared to mismatched train and test scenario.","","978-1-7281-0306-8","10.1109/ASRU46091.2019.9004024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9004024","Variational autoencoders;speech enhancement;far-field speech;close-talking speech","Speech enhancement;Speech recognition;Decoding;Noise reduction;Task analysis;Neural networks;Computational modeling","learning (artificial intelligence);neural nets;signal denoising;speech enhancement;speech recognition","speech recognizers;close-talk speech;neural network based speech enhancement;denoising autoencoder;automatic speech recognition;common latent space representation;joint-VAE;joint distribution learning;far-field speech enhancement;far-field speech recognition;variational autoencoders;generative models","","","","40","","20 Feb 2020","","","IEEE","IEEE Conferences"
"Bottleneck features from SNR-adaptive denoising deep classifier for speaker identification","Z. Tan; M. -W. Mak","Dept. of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong SAR; Dept. of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong SAR","2015 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)","25 Feb 2016","2015","","","1035","1040","In this paper, we explore the potential of using deep learning for extracting speaker-dependent features for noise robust speaker identification. More specifically, an SNR-adaptive denoising classifier is constructed by stacking two layers of restricted Boltzmann machines (RBMs) on top of a denoising deep autoencoder, where the top-RBM layer is connected to a soft-max output layer that outputs the posterior probabilities of speakers and the top-RBM layer outputs speaker-dependent bottleneck features. Both the deep autoencoder and RBMs are trained by contrastive divergence, followed by backpropagation fine-tuning. The autoencoder aims to reconstruct the clean spectra of a noisy test utterance using the spectra of the noisy test utterance and its SNR as input. With this denoising capability, the output from the bottleneck layer of the classifier can be considered as a low-dimension representation of denoised utterances. These frame-based bottleneck features are than used to train an iVector extractor and a PLDA model for speaker identification. Experimental results based on a noisy YOHO corpus show that the bottleneck features slightly outperform the conventional MFCC under low SNR conditions and that fusion of the two features lead to further performance gain, suggesting that the two features are complementary with each other.","","978-9-8814-7680-7","10.1109/APSIPA.2015.7415429","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7415429","Deep learning;Bottleneck features;denoising autoencoder;speaker identification;deep belief networks","Feature extraction;Noise reduction;Speech;Noise measurement;Backpropagation;Training;Signal to noise ratio","backpropagation;Boltzmann machines;feature extraction;probability;signal classification;signal denoising;speaker recognition;vectors","speaker-dependent feature extraction;signal to noise ratio;SNR-adaptive denoising classifier;deep learning;deep neural network;DNN;speaker identification;restricted Boltzmann machine;RBM;soft-max output layer;posterior probability;backpropagation fine-tuning;noisy test utterance;iVector extractor;PLDA model","","2","","24","","25 Feb 2016","","","IEEE","IEEE Conferences"
"Composite Convolutional Neural Network for Noise Deduction","C. Xiu; X. Su","Key Laboratory of Advanced Electrical Engineering and Energy Technology, Tianjin Polytechnic University, Tianjin, China; School of Electrical Engineering and Automation, Tianjin Polytechnic University, Tianjin, China","IEEE Access","30 Aug 2019","2019","7","","117814","117828","In order to improve the noise reduction performance and the clarity of denoising images, a composite convolutional neural network composed of the convolutional autoencoder network and the feature reconstruction network is proposed. Multiple convolutional layers are added into the autoencoder to extract the image feature information and improve the denoising performance, and the feature reconstruction network is designed to recover the texture and detail information of the image. The cross-connected structure is used to fuse feature information in the convolutional autoencoder network into the feature reconstruction network. Experimental results show that the proposed method has better noise reduction performance than the existing methods for different noise intensity. More texture and detail information could be retained, and the clearer denoising images could be obtained.","2169-3536","","10.1109/ACCESS.2019.2936861","Natural Science Foundation of Tianjin City(grant numbers:18JCYBJC88300,18JCYBJC88400); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809743","Autoencoder;convolutional neural network;feature reconstruction;noise reduction","Convolution;Noise reduction;Image reconstruction;Feature extraction;Convolutional neural networks;Image denoising;Kernel","convolutional neural nets;feature extraction;image denoising;image fusion;image reconstruction;image texture","image feature information;denoising performance;feature reconstruction network;convolutional autoencoder network;noise reduction performance;composite convolutional neural network;noise deduction;multiple convolutional layers;denoising images","","7","","43","CCBY","22 Aug 2019","","","IEEE","IEEE Journals"
"Phylogenetic Minimum Spanning Tree Reconstruction Using Autoencoders","R. Castelletto; S. Milani; P. Bestagini","Dept, of Information Engineering (DEI), University of Padova, Italy; Dept, of Information Engineering (DEI), University of Padova, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano, Italy","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","2817","2821","The history of a shared and re-posted multimedia content can be reconstructed by analyzing the mutual relations between all of its near-duplicate copies and solving a minimum spanning tree (MST) problem, as shown by multimedia phylogeny research field, Unfortunately, MST estimation strategies are severely impaired by the noise affecting dissimilarity measures between pairs of near-duplicate contents, For this reason, researchers have recently been investigating robust dissimilarity metrics.This paper proposes a matrix denoising solution that both mitigates dissimilarity noise and reconstruct the desired phylogenetic tree at the same time, The proposed strategy is a first attempt to estimate a MST via a denoising autoencoder that returns an approximation of the adjacency matrix corresponding to the underlying tree, Experimental results prove that the proposed solution outperforms the previous approaches and easily adapts to different analysis scenarios.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9054389","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054389","noisy minimum spanning tree;image phylogeny;autoencoder;UNET","Noise reduction;Estimation;Time measurement;Phylogeny;Noise measurement;History;Image reconstruction","image denoising;image reconstruction;matrix algebra;multimedia systems;trees (mathematics)","phylogenetic minimum spanning tree reconstruction;multimedia content;near-duplicate copies;multimedia phylogeny research field;MST estimation strategies;noise affecting dissimilarity;near-duplicate contents;robust dissimilarity metrics;matrix denoising solution;phylogenetic tree;denoising autoencoder;dissimilarity noise mitigation;adjacency matrix;image phylogeny","","","","24","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Denoising 3D Human Poses from Low-Resolution Video using Variational Autoencoder","C. Nakatsuka; S. Komorita","KDDI Research, Saitama, Japan; KDDI Research, Saitama, Japan","2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","16 Dec 2021","2021","","","4625","4630","We tackle the problem of refining and denoising a series of 3D human poses estimated from a low-resolution video. Low-resolution often causes the wrong pose estimation, e.g., left-right switching and the absence of keypoints. We propose to use the variational autoencoder (VAE) to remove these challenging noises. The VAE model utilizes time-series information and motion priors in denoising. From our experiments, the VAE model can reduce the pose estimation error (MPJPE) for poor-quality images by 24.37mm, from the original 105.53mm. This improves about 6.5 times over the traditional DCT approach. In addition, it removes jitters and generates smooth movements, which is helpful in recognition of human behaviors.","2153-0866","978-1-6654-1714-3","10.1109/IROS51168.2021.9636144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9636144","","Three-dimensional displays;Pose estimation;Noise reduction;Refining;Switches;Jitter;Noise measurement","image denoising;image resolution;jitter;neural nets;pose estimation;time series","low-resolution video;variational autoencoder;VAE model;time-series information;motion priors;pose estimation error;human behaviors recognition;denoising 3D human poses;MPJPE;poor-quality images;DCT approach","","1","","37","IEEE","16 Dec 2021","","","IEEE","IEEE Conferences"
"Stacked Denoising Autoencoder-Based Deep Collaborative Filtering Using the Change of Similarity","Y. Suzuki; T. Ozaki","Graduate School of Integrated Basic Sciences, Nihon University; Department of Information Science, Nihon University","2017 31st International Conference on Advanced Information Networking and Applications Workshops (WAINA)","18 May 2017","2017","","","498","502","Recommender systems based on deep learning technology pay huge attention recently. In this paper, we propose a collaborative filtering based recommendation algorithm that utilizes the difference of similarities among users derived from different layers in stacked denoising autoencoders. Since different layers in a stacked autoencoder represent the relationships among items with rating at different levels of abstraction, we can expect to make recommendations more novel, various and serendipitous, compared with a normal collaborative filtering using single similarity. The results of experiments using MovieLens dataset show that the proposed recommendation algorithm can improve the diversity of recommendation lists without great loss of accuracy.","","978-1-5090-6231-7","10.1109/WAINA.2017.72","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7929729","Collaborative filtering;Autoencoder","Collaboration;Noise reduction;Prediction algorithms;Machine learning;Correlation;Recommender systems","information filtering;learning (artificial intelligence);recommender systems","deep collaborative filtering;recommender systems;deep learning technology;recommendation algorithm;stacked denoising autoencoders;MovieLens dataset;recommendation lists","","13","","14","","18 May 2017","","","IEEE","IEEE Conferences"
"Denoising Pretraining for Semantic Segmentation","E. A. Brempong; S. Kornblith; T. Chen; N. Parmar; M. Minderer; M. Norouzi",Google Research; Google Research; Google Research; Google Research; Google Research; Google Research,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","23 Aug 2022","2022","","","4174","4185","Semantic segmentation labels are expensive and time consuming to acquire. To improve label efficiency of semantic segmentation models, we revisit denoising autoencoders and study the use of a denoising objective for pretraining UNets. We pretrain a Transformer-based UNet as a denoising autoencoder, followed by fine-tuning on semantic segmentation using few labeled examples. Denoising pretraining outperforms training from random initialization, and even supervised ImageNet-21K pretraining of the encoder when the number of labeled images is small. A key advantage of denoising pretraining over supervised pretraining of the backbone is the ability to pretrain the decoder, which would otherwise be randomly initialized. We thus propose a novel Decoder Denoising Pretraining (DDeP) method, in which we initialize the encoder using supervised learning and pretrain only the decoder using the denoising objective. Despite its simplicity, DDeP achieves state-of-the-art results on label-efficient semantic segmentation, offering considerable gains on the Cityscapes, Pascal Context, and ADE20K datasets.","2160-7516","978-1-6654-8739-9","10.1109/CVPRW56347.2022.00462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9857234","","Training;Image segmentation;Noise reduction;Semantics;Supervised learning;Transformers;Probabilistic logic","image classification;image denoising;image segmentation;learning (artificial intelligence)","semantic segmentation labels;semantic segmentation models;denoising objective;pretraining UNets;Transformer-based UNet;denoising autoencoder;labeled examples;pretraining outperforms;random initialization;supervised ImageNet-21K;labeled images;supervised pretraining;novel Decoder Denoising Pretraining method;label-efficient semantic segmentation;temperature 21.0 K","","","","108","IEEE","23 Aug 2022","","","IEEE","IEEE Conferences"
"Denoised Residual Trace Analysis for Monitoring Semiconductor Process Faults","J. Jang; B. W. Min; C. O. Kim","Department of Industrial Engineering, Yonsei University, Seoul, South Korea; Department of Industrial Engineering, Yonsei University, Seoul, South Korea; Department of Industrial Engineering, Yonsei University, Seoul, South Korea","IEEE Transactions on Semiconductor Manufacturing","18 Jul 2019","2019","32","3","293","301","The detection of wafer faults in early process steps through monitoring and analyzing multivariate process trace data contribute to wafer yield improvements. Standard classification algorithms have been generally used for fault detection and classification (FDC). However, this approach can cause information loss while extracting statistical features from the trace data and cannot consider class imbalance situations where much fewer faulty wafers are generated than normal wafers. In addition, the approach does not consider normal wafer-to-wafer (W2W) variations and sensor noise inherent in the trace data. These drawbacks significantly degrade FDC performance. This paper proposes a method that builds an FDC model only with trace data of normal wafers in which W2W variations and sensor noise exist. The one-class FDC method detects the occurrence of abnormal trace patterns that cause wafer faults by removing W2W variations and sensor noise from raw traces by using denoising autoencoders, and this method finds the fault-introducing process parameters with the occurrence times. In experiments using the trace data of etch and chemical vapor deposition processes, the proposed method exhibited 1% and 6% higher performance than the best-performing method among comparison methods in terms of the geometric mean of the normal and fault detection accuracies.","1558-2345","","10.1109/TSM.2019.2916374","National Research Foundation of Korea; Ministry of Science, ICT and Future Planning(grant numbers:NRF-2016R1A2B4008337); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8713521","Fault detection and classification;denoising autoencoder;sensor noise;wafer-to-wafer variation;multivariate trace data;semiconductor manufacturing","Feature extraction;Fault detection;Semiconductor device modeling;Noise reduction;Monitoring;Classification algorithms;Data models","fault diagnosis;feature extraction;production engineering computing;semiconductor device manufacture;semiconductor industry;semiconductor technology;sensor fusion;signal classification;signal denoising;statistical analysis","sensor noise;fault-introducing process parameters;residual trace analysis;wafer-to-wafer variations;one-class FDC method;abnormal trace patterns;semiconductor process faults monitoring;wafer faults detection;multivariate process trace data monitoring;multivariate process trace data analysis;denoising autoencoders;fault detection and classification","","11","","35","IEEE","13 May 2019","","","IEEE","IEEE Journals"
"Hierarchical Autoencoder for Collaborative Filtering","S. Maheshwari; A. Majumdar","IIIT Delhi, New Delhi, India; IIIT Delhi, New Delhi, India","2018 International Joint Conference on Neural Networks (IJCNN)","14 Oct 2018","2018","","","1","7","In recent years autoencoder based collaborative filtering for recommender systems have shown promise. In the past, several variants of the basic autoencoder based approach has been proposed - marginalized denoising autoencoder and stacked denoising autoencoder. However, these are not new developments; just applications of existing machine learning techniques on collaborative filtering. In this work we propose a fundamentally new architecture of hierarchical autoencoder. In a normal stacked denoising autoencoder, reconstruction only happens at the final layer, the intermediate layers are not directly responsible. In our proposed hierarchical model every layer reconstructs; each layer provides complimentary information. The output from all the layers are fused to yield the final result. Experiments of benchmark collaborative filtering datasets show the superiority of our technique over the state-of-art.","2161-4407","978-1-5090-6014-6","10.1109/IJCNN.2018.8489288","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489288","autoencoder;deep learning;collaborative filtering;recommender systems","Collaboration;Interpolation;Recommender systems;Motion pictures;Decoding;Noise reduction","collaborative filtering;learning (artificial intelligence);recommender systems","hierarchical autoencoder;recommender systems;marginalized denoising autoencoder;collaborative filtering;machine learning","","2","","32","","14 Oct 2018","","","IEEE","IEEE Conferences"
"Self-Supervised Learning for Seismic Data Reconstruction and Denoising","F. Meng; Q. Fan; Y. Li","School of Electronic and Information Engineering, Changchun University, Changchun, China; Department of Mechanical Sciences, Osaka University, Suita, Japan; Department of Information, College of Communication Engineering, Jilin University, Changchun, China","IEEE Geoscience and Remote Sensing Letters","30 Dec 2021","2022","19","","1","5","With their powerful feature extraction ability, convolutional neural network (CNN) models achieve excellent signal reconstruction and recovery performances compared with those of traditional methods. The CNN-based approaches mainly use supervised learning approaches; thus, they require large numbers of ground-truth labeled samples. However, in the seismic denoising field, collecting large numbers of labeled samples is impossible; thus, the main challenge to using deep learning methods is a lack of labeled data. Moreover, the data that are available contain noise. To resolve these shortcomings, this letter proposes a novel self-supervised learning framework to reconstruct and perform blind denoising of seismic data images; this approach requires no labeled training data. We utilize a masking procedure to modify an observation input to a CNN to create a  $\mathcal {J}$ -invariant function and incorporate a specific CNN architecture known as U2Net, which implements a two-level nested autoencoder that extracts complex feature information from different scales. We modify the network to make it more suitable for seismic signal reconstruction. Finally, we use the self-supervised loss between the original observation and the net output to update the weights of U2Net through backpropagation. Tests on both synthetic and field data demonstrate the superior performance of our algorithm on low signal-to-noise ratio data.","1558-0571","","10.1109/LGRS.2021.3068132","“Chunhui Plan” of the Education Ministry of China(grant numbers:JJKH20180945KJ); “Climber Project” of Changchun University(grant numbers:ZK201805); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9394868","Convolutional neural network (CNN);J-invariant function;reconstruction and blind denoising;self-supervised;U² Net","Noise reduction;Training;Noise measurement;Image reconstruction;Feature extraction;Convolution;Signal to noise ratio","backpropagation;convolutional neural nets;deep learning (artificial intelligence);feature extraction;geophysical image processing;image denoising;image reconstruction;neural net architecture;seismology;supervised learning","seismic data reconstruction;feature extraction;convolutional neural network;blind denoising;seismic data images;CNN architecture;two-level nested autoencoder;seismic signal reconstruction;seismic data denoising;self-supervised learning framework;U2Net;J-invariant function;backpropagation","","2","","19","IEEE","2 Apr 2021","","","IEEE","IEEE Journals"
"Improving Image Quality In Low-Field MRI With Deep Learning","A. G. Hernandez; P. Fau; S. Rapacchi; J. Wojak; H. Mailleux; M. Benkreira; M. Adel","Aix Marseille Univ, CNRS, Centrale Marseille, Institut Fresnel, Marseille, France; Bouches du Rhône, Institut Paoli-Calmettes, Marseille, France; Aix Marseille Univ CNRS, CRMBM, Marseille, France; Aix Marseille Univ, CNRS, Centrale Marseille, Institut Fresnel, Marseille, France; Bouches du Rhône, Institut Paoli-Calmettes, Marseille, France; Bouches du Rhône, Institut Paoli-Calmettes, Marseille, France; Aix Marseille Univ, CNRS, Centrale Marseille, Institut Fresnel, Marseille, France","2021 IEEE International Conference on Image Processing (ICIP)","23 Aug 2021","2021","","","260","263","Low-field magnetic resonance (MR) images suffer from inherent low Signal-to-noise ratio (SNR) compared to images acquired using high-field MRI scanners. Denoising these images could help and improve further processing, such as image segmentation. In this paper a Convolutional Neural Network AutoEncoder was designed with a dedicated loss function for noise reduction. A transfer learning approach was employed in which high-field high-SNR MR images, served as targets for learning from their noise-added counterparts. Evaluation of network performances was measured on both noisy high-field and low-field MR images that had not been included in the learning step. The proposed method outperformed major denoising methods applied to MR images. SNR improvements were quantified on low-field MR images.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506659","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506659","Denoising;Low-field MRI;Deep Learning;AutoEncoder","Image quality;Deep learning;Image segmentation;Magnetic resonance imaging;Noise reduction;Transfer learning;Magnetic resonance","biomedical MRI;image classification;image coding;image denoising;image segmentation;iterative methods;learning (artificial intelligence);medical image processing;neural nets;signal restoration","image quality;low-field MRI;deep learning;low-field magnetic resonance images;inherent low Signal-to-noise ratio;high-field MRI scanners;image segmentation;Convolutional Neural Network AutoEncoder;dedicated loss function;noise reduction;transfer learning approach;high-field high-SNR;noise-added counterparts;noisy high-field;learning step;MR images;SNR improvements","","","","16","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"Cyberbullying Detection Based on Semantic-Enhanced Marginalized Denoising Auto-Encoder","R. Zhao; K. Mao","School of Electrical and Electronic Engineering, Nanyang Technological University, Nanyang Avenue, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Nanyang Avenue, Singapore","IEEE Transactions on Affective Computing","1 Sep 2017","2017","8","3","328","339","As a side effect of increasingly popular social media, cyberbullying has emerged as a serious problem afflicting children, adolescents and young adults. Machine learning techniques make automatic detection of bullying messages in social media possible, and this could help to construct a healthy and safe social media environment. In this meaningful research area, one critical issue is robust and discriminative numerical representation learning of text messages. In this paper, we propose a new representation learning method to tackle this problem. Our method named semantic-enhanced marginalized denoising auto-encoder (smSDA) is developed via semantic extension of the popular deep learning model stacked denoising autoencoder (SDA). The semantic extension consists of semantic dropout noise and sparsity constraints, where the semantic dropout noise is designed based on domain knowledge and the word embedding technique. Our proposed method is able to exploit the hidden feature structure of bullying information and learn a robust and discriminative representation of text. Comprehensive experiments on two public cyberbullying corpora (Twitter and MySpace) are conducted, and the results show that our proposed approaches outperform other baseline text representation learning methods.","1949-3045","","10.1109/TAFFC.2016.2531682","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7412690","Cyberbullying detection;text mining;representation learning;stacked denoising autoencoders;word embedding","Semantics;Noise reduction;Numerical models;Feature extraction;Media;Robustness;Analytical models","hidden feature removal;learning (artificial intelligence);security of data;social aspects of automation;social networking (online);text analysis","cyberbullying detection;semantic-enhanced marginalized denoising auto-encoder;text representation learning;hidden feature structure;deep learning model stacked denoising autoencoder;smSDA;discriminative numerical representation;machine learning;social media","","60","","39","IEEE","18 Feb 2016","","","IEEE","IEEE Journals"
"A Hybrid Deep Physics Neural Network Model for Unsupervised Autoencoder to Perform Data Conditioning","S. Madasu; K. P. Rangarajan","Halliburton, Houston, Texas, USA; Houston, Texas, USA","2019 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT)","20 Feb 2020","2019","","","1","7","Denoising, smoothing, missing data, and outlier issues that occur in many fields involve finding models for noise and data. However, the models often make assumptions of the noise, such as white noise, Gaussian noise, etc. Numerical methods [wavelets, Fourier transforms, Kalman filter, principal component analysis (PCA), etc.] are available for data conditioning. However, they suffer from inaccuracies. This paper presents a new approach, in which a hybrid physics-based model and deep physics neural network (DPNN) model are used to simultaneously build a data conditioning autoencoder (DPNNAE) based on DPNN for enhancing the signal strength, compared to a conventional autoencoder (AE). It necessitates integration of domain-specific physics-based models with a data-driven approach. A one-dimensional (1D) stochastic Burgers equation is used as a prototype for demonstrating the new algorithm but can be easily applied to other systems. This paper provides a new data conditioning approach that performs denoising, smoothing, data imputation, and outlier removal using DPNN and AE. This approach offers an improved and efficient methodology to arrive at the noise-free data and fills the missing data. During this work, the DPNN was applied to predict noise-free velocity in the unsteady viscous stochastic Burgers equation. The loss function is obtained from the physics models produced from domain insight and measured data. Thus, the deep neural network (DNN) framework integrates physics-based models into its framework. The hybrid DPNN model uses measured data from sensors; both measured data and physics are simultaneously satisfied by the model resulting in noise-free measured data. The conditioned data can be further used to build the DPNNAE model for further conditioning, and the DPNN can be used for filling the missing data. The DPNN method outperformed other common denoising algorithms. The new hybrid modeling data conditioning algorithm developed during this work can be applied to any real-time modeling system with real-time measurements for denoising.","2641-5542","978-1-7281-5341-4","10.1109/ISSPIT47144.2019.9001770","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9001770","deep neural network;data conditioning;data denoising;autoencoder;data-driven;hybrid model","Data models;Mathematical model;Noise measurement;Real-time systems;Noise reduction;Training","data analysis;neural nets;stochastic processes;white noise","deep physics neural network model;hybrid modeling data conditioning algorithm;DPNN method;DPNNAE model;deep neural network framework;noise-free velocity;noise-free data;data imputation;one-dimensional stochastic Burgers equation;domain-specific physics-based models;data conditioning autoencoder;Gaussian noise;white noise;unsupervised autoencoder","","","","15","","20 Feb 2020","","","IEEE","IEEE Conferences"
"Missing data of quality inspection imputation algorithm base on stacked denoising auto-encoder","X. Ning; Y. Xu; X. Gao; Y. Li","Quality Management Branch, China National Institute of Standardization, Beijing, China; Quality Management Branch, China National Institute of Standardization, Beijing, China; Quality Management Branch, China National Institute of Standardization, Beijing, China; Quality Management Branch, China National Institute of Standardization, Beijing, China","2017 IEEE 2nd International Conference on Big Data Analysis (ICBDA)","23 Oct 2017","2017","","","84","88","Analyzing and processing big data of quality inspection is the key factor in ensuring product quality and People's property security. Big data of quality inspection collected by social network and E-commerce is missing in most cases. And the incompleteness of data brings huge challenge for analyzing and processing. Therefore, the algorithm of data filling based on stacked denoising auto-encoder is proposed in this text. As the experiment shows that the algorithm proposed in this text is effective in dealing with big data of quality inspection.","","978-1-5090-3619-6","10.1109/ICBDA.2017.8078781","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8078781","Big data of quality inspection;Stacked denoising auto-encoder;Filling algorithm","Filling;Algorithm design and analysis;Noise reduction;Training;Clustering algorithms;Inspection;Big Data","Big Data;data analysis;encoding;inspection;product quality;production engineering computing","product quality;Big Data analysis;quality inspection imputation algorithm;Big Data processing;people property security;data filling algorithm;stacked denoising autoencoder","","2","","10","","23 Oct 2017","","","IEEE","IEEE Conferences"
"Bearing Fault Diagnosis Using Fully-Connected Winner-Take-All Autoencoder","C. Li; W. Zhang; G. Peng; S. Liu","State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; Department of Computer Science, Harbin Institute of Technology, Harbin, China","IEEE Access","2 Mar 2018","2018","6","","6103","6115","Intelligent fault diagnosis of bearings has been a heated research topic in the prognosis and health management of rotary machinery systems, due to the increasing amount of available data collected by sensors. This has given rise to more and more business desire to apply data-driven methods for health monitoring of machines. In recent years, various deep learning algorithms have been adapted to this field, including multi-layer perceptrons, autoencoders, convolutional neural networks, and so on. Among these methods, autoencoder is of particular interest for us because of its simple structure and its ability to learn useful features from data in an unsupervised fashion. Previous studies have exploited the use of autoencoders, such as denoising autoencoder, sparsity aotoencoder, and so on, either with one layer or with several layers stacked together, and they have achieved success to certain extent. In this paper, a bearing fault diagnosis method based on fully-connected winner-take-all autoencoder is proposed. The model explicitly imposes lifetime sparsity on the encoded features by keeping only k% largest activations of each neuron across all samples in a mini-batch. A soft voting method is implemented to aggregate prediction results of signal segments sliced by a sliding window to increase accuracy and stability. A simulated data set is generated by adding white Gaussian noise to original signals to test the diagnosis performance under noisy environment. To evaluate the performance of the proposed method, we compare our methods with some state-of-the-art bearing fault diagnosis methods. The experiments result show that, with a simple two-layer network, the proposed method is not only capable of diagnosing with high precision under normal conditions, but also has better robustness to noise than some deeper and more complex models.","2169-3536","","10.1109/ACCESS.2017.2717492","National High-Tech Research and Development Program of China (863 Program)(grant numbers:2015AA042201); National Natural Science Foundation of China(grant numbers:51275119); Self-Planned Task of the State Key Laboratory of Robotics and System(grant numbers:SKLRS201708A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7956142","Autoencoder;fault diagnosis;lifetime sparsity;signal processing;signal representations;supervised learning;vibrations","Fault diagnosis;Robustness;Noise reduction;Training;Feature extraction;Noise measurement;Robots","condition monitoring;fault diagnosis;Gaussian noise;learning (artificial intelligence);machine bearings;machinery;signal denoising;signal representation;vibrational signal processing","bearing fault diagnosis;winner-take-all autoencoder;unsupervised fashion;signal segments;Gaussian noise;vibration signals;two-layer network;diagnosis performance;soft voting method;fully-connected winner;bearing fault diagnosis method;deep learning algorithms;rotary machinery systems;health management;prognosis;bearings;intelligent fault diagnosis;autoencoder","","58","","21","OAPA","23 Jun 2017","","","IEEE","IEEE Journals"
"On latent fingerprint minutiae extraction using stacked denoising sparse AutoEncoders","A. Sankaran; P. Pandey; M. Vatsa; R. Singh","IIIT, Delhi, India; IIIT, Delhi, India; IIIT, Delhi, India; IIIT, Delhi, India","IEEE International Joint Conference on Biometrics","29 Dec 2014","2014","","","1","7","Latent fingerprint identification is of critical importance in criminal investigation. FBI's Next Generation Identification program demands latent fingerprint identification to be performed in lights-out mode, with very little or no human intervention. However, the performance of an automated latent fingerprint identification is limited due to imprecise automated feature (minutiae) extraction, specifically due to noisy ridge pattern and presence of background noise. In this paper, we propose a novel descriptor based minutiae detection algorithm for latent fingerprints. Minutia and non-minutia descriptors are learnt from a large number of tenprint fingerprint patches using stacked denoising sparse autoencoders. Latent fingerprint minutiae extraction is then posed as a binary classification problem to classify patches as minutia or non-minutia patch. Experiments performed on the NIST SD-27 database shows promising results on latent fingerprint matching.","","978-1-4799-3584-0","10.1109/BTAS.2014.6996300","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6996300","","Feature extraction;Databases;Noise reduction;Noise measurement;NIST;Neural networks;Manuals","encoding;feature extraction;fingerprint identification;forensic science;image denoising;image matching","latent fingerprint minutiae extraction;stacked denoising;sparse autoencoders;criminal investigation;next generation identification program;automated latent fingerprint identification;feature extraction;noisy ridge pattern;Minutia descriptor;nonminutia descriptor;NIST SD-27 database;fingerprint matching","","24","1","23","","29 Dec 2014","","","IEEE","IEEE Conferences"
"Stacked Denoising Autoencoder for feature representation learning in pose-based action recognition","A. Budiman; M. I. Fanany; C. Basaruddin","Faculty of Computer Science, University of Indonesia Depok, West Java, Indonesia; Faculty of Computer Science, University of Indonesia Depok, West Java, Indonesia; Faculty of Computer Science, University of Indonesia Depok, West Java, Indonesia","2014 IEEE 3rd Global Conference on Consumer Electronics (GCCE)","5 Feb 2015","2014","","","684","688","In this paper, we studied Stacked Denoising Autoencoder(SDA) model for Human pose-based action recognition. We used public dataset Chalearn 2013 which contains Italian body language actions from 27 persons. We studied two model of SDA for pose clustering: 1) Traditional SDA with epoch and Neural Network supervised classifier and 2) Marginalized SDA which faster and ELM supervised classifier. We used supervised classifier by using initial cluster data from K-means. We deployed global tuning that updating the weight during iterative learning.","2378-8143","978-1-4799-5145-1","10.1109/GCCE.2014.7031302","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7031302","","Training;Tuning;Accuracy;Noise reduction;Joints;Neural networks","feature extraction;image classification;image denoising;image motion analysis;learning (artificial intelligence);multilayer perceptrons;pattern clustering;pose estimation","stacked denoising autoencoder;feature representation learning;SDA model;human pose-based action recognition;Italian body language actions;pose clustering;neural network supervised classifier;multilayer perceptron;k-means clustering;iterative learning;ELM supervised classifier;marginalized SDA;epoch classifier","","11","","17","","5 Feb 2015","","","IEEE","IEEE Conferences"
"Speech Enhancement Based on Denoising Autoencoder With Multi-Branched Encoders","C. Yu; R. E. Zezario; S. -S. Wang; J. Sherman; Y. -Y. Hsieh; X. Lu; H. -M. Wang; Y. Tsao","Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Taiwan International Graduate Program (TIGP), Academia Sinica, Taipei, Taiwan; Graduate Institute of Electronics Engineering (GIEE), National Taiwan University, Taipei, Taiwan; National Institute of Information and Communications Technology, Tokyo, Japan; Institute of Information Science, Academia Sinica, Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan","IEEE/ACM Transactions on Audio, Speech, and Language Processing","27 Oct 2020","2020","28","","2756","2769","Deep learning-based models have greatly advanced the performance of speech enhancement (SE) systems. However, two problems remain unsolved, which are closely related to model generalizability to noisy conditions: (1) mismatched noisy condition during testing, i.e., the performance is generally sub-optimal when models are tested with unseen noise types that are not involved in the training data; (2) local focus on specific noisy conditions, i.e., models trained using multiple types of noises cannot optimally remove a specific noise type even though the noise type has been involved in the training data. These problems are common in real applications. In this article, we propose a novel denoising autoencoder with a multi-branched encoder (termed DAEME) model to deal with these two problems. In the DAEME model, two stages are involved: training and testing. In the training stage, we build multiple component models to form a multi-branched encoder based on a decision tree (DSDT). The DSDT is built based on prior knowledge of speech and noisy conditions (the speaker, environment, and signal factors are considered in this paper), where each component of the multi-branched encoder performs a particular mapping from noisy to clean speech along the branch in the DSDT. Finally, a decoder is trained on top of the multi-branched encoder. In the testing stage, noisy speech is first processed by each component model. The multiple outputs from these models are then integrated into the decoder to determine the final enhanced speech. Experimental results show that DAEME is superior to several baseline models in terms of objective evaluation metrics, automatic speech recognition results, and quality in subjective human listening tests.","2329-9304","","10.1109/TASLP.2020.3025638","Ministry of Science and Technology, Taiwan(grant numbers:MOST 109-2221-E-001-022-,108-2628-E-001-002-MY3,107-2221-E-001-012-MY2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9212562","Deep neural networks;ensemble learning;dynamically-sized decision tree;generalizability;speech enhancement","Noise measurement;Training data;Speech enhancement;Data models;Decoding;Noise reduction","decision trees;learning (artificial intelligence);neural nets;signal denoising;speech enhancement;speech recognition","multibranched encoder;decision tree;denoising autoencoder;DSDT;multiple component models;DAEME model;specific noisy conditions;training data;unseen noise types;model generalizability;speech enhancement systems;deep learning-based models;automatic speech recognition results;noisy speech","","7","","81","CCBY","5 Oct 2020","","","IEEE","IEEE Journals"
"3D Shape Processing by Convolutional Denoising Autoencoders on Local Patches","K. Sarkar; K. Varanasi; D. Stricker","Technische Universität Kaiserslautern; DFKI - German Research Center for Artificial Intelligence, Kaiserslautern; Technische Universität Kaiserslautern","2018 IEEE Winter Conference on Applications of Computer Vision (WACV)","7 May 2018","2018","","","1925","1934","We propose a system for surface completion and inpainting of 3D shapes using denoising autoencoders with convolutional layers, learnt on local patches. Our method uses height map based local patches parameterized using 3D mesh quadrangulation of the low resolution input shape. This provides us sufficient amount of local 3D patch dataset to learn deep generative Convolutional Neural Networks (CNNs) for the task of repairing moderate sized holes. We design generative networks specifically suited for the 3D encoding following ideas from the recent progress in 2D inpainting, and show our results to be better than the previous methods of surface inpainting that use linear dictionary. We validate our method on both synthetic shapes and real world scans.","","978-1-5386-4886-5","10.1109/WACV.2018.00213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354317","","Three-dimensional displays;Shape;Noise reduction;Task analysis;Two dimensional displays;Image reconstruction;Dictionaries","computational geometry;convolution;feedforward neural nets;image coding;image denoising;image reconstruction;image representation;image resolution;learning (artificial intelligence)","local patches;surface completion;convolutional layers;3D mesh quadrangulation;low resolution input shape;local 3D patch dataset;deep generative Convolutional Neural Networks;surface inpainting;synthetic shapes;3D shape processing;Convolutional denoising autoencoders;CNNs;2D inpainting","","5","1","42","","7 May 2018","","","IEEE","IEEE Conferences"
"Towards Sub-Room Level Occupancy Detection with Denoising-Contractive Autoencoder","P. C. Ng; J. She; R. Ran","Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology; School of Electrical and Computer Engineering, Ajou University","ICC 2019 - 2019 IEEE International Conference on Communications (ICC)","15 Jul 2019","2019","","","1","6","Lately, there are many works exploited the radio frequency (RF) fingerprint for occupancy detection. However, most works suffer severe performance variations owing to the unreliable received signal strength (RSS). In this paper, we propose a deep learning approach to occupancy detection: 1) an unsupervised denoising-contractive autoencoder (DCAE) is built to learn a robust fingerprint representation from the raw RSS measurements, and 2) a supervised softmax function is added at the last layer for classification. A real testbed with Bluetooth Low Energy (BLE) beacons was built such that we can collect real-world RSS data for experiments. The data were collected via different devices at different times to better reflect environmental variations. The experimental results show that our proposed approach achieves a substantial performance gain in comparison to the conventional machine learning approaches. Specifically, our proposed DCAE is able to reconstruct the noisy and always changing data with less than 0.047 mean square error. Overall, our occupancy detection combining DCAE and softmax classifier achieves sub-room level accuracy for at least 99.3% of the time.","1938-1883","978-1-5386-8088-9","10.1109/ICC.2019.8761294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8761294","","Feature extraction;Compounds;Chemicals;Throughput;Drugs;Imaging;Deep learning","Bluetooth;fingerprint identification;image classification;image denoising;image representation;learning (artificial intelligence);mobile computing;object detection","radio frequency fingerprint;deep learning approach;unsupervised denoising-contractive autoencoder;DCAE;robust fingerprint representation;raw RSS measurements;real-world RSS data;sub-room level accuracy;received signal strength;machine learning approaches;sub-room level occupancy detection;supervised softmax function;classification;Bluetooth low energy beacon","","5","","18","","15 Jul 2019","","","IEEE","IEEE Conferences"
"Multi-Contrast Mr Reconstruction with Enhanced Denoising Autoencoder Prior Learning","X. Liu; M. Zhang; Q. Liu; T. Xiao; H. Zheng; L. Ying; S. Wang","Department of Electronic Information Engineering, Nanchang University, Nanchang, China; Department of Electronic Information Engineering, Nanchang University, Nanchang, China; Department of Electronic Information Engineering, Nanchang University, Nanchang, China; Paul C. Lauterbur Research Center for Biomedical imaging, SIAT, CAS, Shenzhen, China; Paul C. Lauterbur Research Center for Biomedical imaging, SIAT, CAS, Shenzhen, China; Department of Biomedical Engineering and Department of Electrical Engineering, The State University of New York, Buffalo, New York, USA; Paul C. Lauterbur Research Center for Biomedical imaging, SIAT, CAS, Shenzhen, China","2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)","22 May 2020","2020","","","1","5","This paper proposes an enhanced denoising autoencoder prior (EDAEP) learning framework for accurate multi-contrast MR image reconstruction. A multi-model structure with various noise levels is designed to capture features of different scales from different contrast images. Furthermore, a weighted aggregation strategy is proposed to balance the impact of different model outputs, making the performance of the proposed model more robust and stable while facing noise attacks. The model was trained to handle three different sampling patterns and different acceleration factors on two public datasets. Results demonstrate that our proposed method can improve the quality of reconstructed images and outperform the previous state-of-the-art approaches. The code is available at https://github.com/yqx7150.","1945-8452","978-1-5386-9330-8","10.1109/ISBI45749.2020.9098334","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9098334","Multi-contrast MR reconstruction;Au-toencoder prior;deep learning","Image reconstruction;Magnetic resonance imaging;Noise level;Noise reduction;Acceleration;Machine learning","biomedical MRI;image denoising;image reconstruction;learning (artificial intelligence);medical image processing","image reconstruction;multimodel structure;noise levels;contrast images;weighted aggregation strategy;noise attacks;sampling patterns;acceleration factors;enhanced denoising autoencoder prior learning framework","","2","","19","","22 May 2020","","","IEEE","IEEE Conferences"
"Indoor localization by denoising autoencoders and semi-supervised learning in 3D simulated environment","A. Shantia; R. Timmers; L. Schomaker; M. Wiering","Institute of Artificial Intelligence and Cognitive Engineering, University of Groningen, Groningen, The Netherlands; Institute of Artificial Intelligence and Cognitive Engineering, University of Groningen, Groningen, The Netherlands; Institute of Artificial Intelligence and Cognitive Engineering, University of Groningen, Groningen, The Netherlands; Institute of Artificial Intelligence and Cognitive Engineering, University of Groningen, Groningen, The Netherlands","2015 International Joint Conference on Neural Networks (IJCNN)","1 Oct 2015","2015","","","1","7","Robotic mapping and localization methods are mostly dominated by using a combination of spatial alignment of sensory inputs, loop closure detection, and a global fine-tuning step. This requires either expensive depth sensing systems, or fast computational hardware at run-time to produce a 2D or 3D map of the environment. In a similar context, deep neural networks are used extensively in scene recognition applications, but are not yet applied to localization and mapping problems. In this paper, we adopt a novel approach by using denoising autoencoders and image information for tackling robot localization problems. We use semi-supervised learning with location values that are provided by traditional mapping methods. After training, our method requires much less run-time computations, and therefore can perform real-time localization on normal processing units. We compare the effects of different feature vectors such as plain images, the scale invariant feature transform and histograms of oriented gradients on the localization precision. The best system can localize with an average positional error of ten centimeters and an angular error of four degrees in 3D simulation.","2161-4407","978-1-4799-1960-4","10.1109/IJCNN.2015.7280715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280715","","Training;Gray-scale;Image storage;Image resolution;Neural networks;Weaving","gradient methods;image denoising;indoor navigation;learning (artificial intelligence);neural nets;robots;transforms","indoor localization;denoising autoencoder;semisupervised learning;3D simulated environment;robotic mapping;localization method;spatial alignment;sensory input;loop closure detection;global fine-tuning step;expensive depth sensing system;computational hardware;deep neural network;scene recognition application;image information;robot localization problem;traditional mapping method;run-time computation;real-time localization;normal processing unit;feature vector;scale invariant feature transform;histograms of oriented gradient;localization precision;positional error;ten centimeter;3D simulation","","2","","30","","1 Oct 2015","","","IEEE","IEEE Conferences"
"Primary user detection in cognitive radio using spectral-correlation features and stacked denoising autoencoder","H. Liu; X. Zhu; T. Fujii","Advanced Wireless and Communication Research Center, The University of Electro-Communications, Tokyo, JAPAN; Advanced Wireless and Communication Research Center, The University of Electro-Communications, Tokyo, JAPAN; Advanced Wireless and Communication Research Center, The University of Electro-Communications, Tokyo, JAPAN","2017 IEEE 28th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)","15 Feb 2018","2017","","","1","5","This paper proposes a primary user detection method in cognitive radio system based on the features of cyclic spectral correlation and the stacked denoising autoencoder. The cyclic spectral correlation, which is sensitive to OFDM signal, is utilized as the feature-extraction tool. Then, we use the SDAE as a classifier due to its high classification accuracy. Concretely, we suppose that OFDM is applied by PU because OFDM is more commonly used than other single carrier modulations. Therefore, our mission turns to the classification of OFDM signal. In addition, a long symbols sequence is not required for this method simplifying the detection procedure and rendering rapid detection more achievable. The results of the probability of successful detection, the change in the probability of successful detection corresponding to different corruption levels are presented, demonstrating significant performance advantages over energy detection.","2166-9589","978-1-5386-3531-5","10.1109/PIMRC.2017.8292339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8292339","","Correlation;OFDM;Feature extraction;Training;Noise reduction;AWGN;Sensors","cognitive radio;feature extraction;OFDM modulation;probability;signal classification;signal denoising;signal detection","spectral-correlation features;stacked denoising autoencoder;primary user detection method;cognitive radio system;cyclic spectral correlation;OFDM signal;feature-extraction tool;single carrier modulations;rendering rapid detection;energy detection","","2","","10","","15 Feb 2018","","","IEEE","IEEE Conferences"
"Wavelet-Based Stacked Denoising Autoencoders for Cell Phone Base Station User Number Prediction","J. Li; J. Wang; Z. Xiong","School of Electrical and Computer Engineering, Beihang University, Beijing, China; School of Electrical and Computer Engineering, Beihang University, Beijing, China; School of Electrical and Computer Engineering, Beihang University, Beijing, China","2016 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)","4 May 2017","2016","","","833","838","User number prediction in cell phone base station is a very important problem for cell phone communication system design and base station location selection. Recent years, we have witnessed the encouraging potentials of deep neural networks for real-life applications of various domains. User number prediction, however, is still in its initial stage. In this paper, we propose a wavelet-based stacked denoising autoencoder deep learning framework, named as Wavelet-SDA, which adopted wavelet to decompose the user volume signal as several sub channels, for each channel, an independent SDA model is introduce to achieve accurately signal prediction. In order to exploit the correlations between different base stations, a transfer entropy based knowledge transfer is also adopted by the proposed framework. Extensive experiments on real-life cell phone base station log dataset of Wuxi city demonstrate the strong predictive power of Wavelet-SDA comparison to some state-of-the-art competitors.","","978-1-5090-5880-8","10.1109/iThings-GreenCom-CPSCom-SmartData.2016.173","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7917201","Traffic flow prediction;deep learning;Wavelet","Mobile communication;Entropy;Predictive models;Noise reduction;Base stations;Correlation;Cellular phones","cellular radio;encoding;entropy;learning (artificial intelligence);neural nets;prediction theory;signal denoising;wavelet transforms","wavelet-based stacked denoising autoencoders;cell phone base station;user number prediction;cell phone communication system design;base station location selection;deep neural networks;number prediction;deep learning framework;wavelet-SDA;user volume signal;independent SDA model;signal prediction;transfer entropy;knowledge transfer;log dataset;Wuxi city","","2","","12","","4 May 2017","","","IEEE","IEEE Conferences"
"Deep Denoising Autoencoder Based Post Filtering for Speech Enhancement","R. E. Zezario; J. -W. Huang; X. Lu; Y. Tsao; H. -T. Hwang; H. -M. Wang","Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan, R.O.C.; National Institute of Information and Communications Technology, Japan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Institute of Information Science, Academia Sinica, Taipei, Taiwan; Institute of Information Science, Academia Sinica, Taipei, Taiwan","2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","7 Mar 2019","2018","","","373","377","In this paper, we present a simple yet effective deep denoising autoencoder (DDAE) based post-filter (DPF) approach for speech enhancement (SE). The DPF is designed to estimate the spectral difference of clean-noisy speech pair based on the enhanced-noisy speech pair. The difference estimated by the DPF approach is then used to compensate the noisy speech to obtain the final enhanced speech. We integrate the proposed DPF approach with one traditional SE method (minimum mean square error) and one deep-learning-based SE method (DDAE). Experiments on various noise types and signal-to-noise-ratio conditions were carried out to test the integrated systems. Results of three standardized objective evaluation metrics and automatic speech recognition (ASR) tests confirm that integrating the proposed DPF can improve the performance in further reducing spectral distortions and enhancing the speech quality and intelligibility.","2640-0103","978-9-8814-7685-2","10.23919/APSIPA.2018.8659598","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8659598","","Speech enhancement;Noise measurement;Signal to noise ratio;Computational modeling;Feature extraction;Training","least mean squares methods;signal denoising;speech enhancement;speech recognition","speech enhancement;DDAE;spectral difference;clean-noisy speech pair;enhanced-noisy speech pair;DPF approach;final enhanced speech;traditional SE method;automatic speech recognition;speech quality;deep denoising autoencoder based post-filter approach","","1","","30","","7 Mar 2019","","","IEEE","IEEE Conferences"
"Stacked Denoising Autoencoder based Fault Diagnosis for Rotating Motor","H. Tang; K. Zhang; D. Guo; L. Jia; H. Qiao; Y. Tian","CRRC industry institute co ltd, Beijing, China; Cloud Computing Center, Chinese Academy of Sciences, Dongguan; Research Center for Brain-inspired Intelligence, Chinese Academy of Sciences, Beijing, China; Research Center for Brain-inspired Intelligence, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences; CRRC industry institute co ltd, Beijing, China","2018 37th Chinese Control Conference (CCC)","7 Oct 2018","2018","","","5757","5762","Fault diagnosis is vital for normal operation of the rotating motor. An effective and reliable deep learning method known as stacked denoising autoencoder (SDAE) is investigated in this paper, which can extract the features from the pending signals with disturbances. Deep adaptive networks are designed to extract features automatically from time domain data and frequency domain data of motor vibration signal, respectively. Then, the network parameters of the SDAE are trained to reconstruct the signal features, and clustering results are investigated. Finally, a classification layer is added to the top layer of the SDAE network for the fault isolation. It is shown that, the diagnosis accuracy with input of vibratory frequency signal is higher than that of time domain signal. The features extracted by SDAE can represent complex mapping relationships between signal and various running status, and the accuracy is improved comparing with traditional fault diagnosis methods.","1934-1768","978-988-15639-5-8","10.23919/ChiCC.2018.8482625","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8482625","Rotating motor;Fault diagnosis;SDAE;Deep learning","","fault diagnosis;feature extraction;learning (artificial intelligence);network parameters;pattern clustering;signal classification;signal denoising;signal reconstruction;vibrational signal processing","motor vibration signal;network parameters;signal features;classification layer;SDAE network;fault isolation;vibratory frequency signal;time domain signal;stacked denoising autoencoder;rotating motor;deep adaptive networks;frequency domain data;fault diagnosis methods;deep learning method;feature extraction;clustering","","1","","32","","7 Oct 2018","","","IEEE","IEEE Conferences"
"Early Warning of Critical Blockage in Coal Mills Based on Stacked Denoising Autoencoders","Y. Li; F. Hong; L. Tian; J. Liu; J. Chen","Department of Information Engineering, Ordos Institute of Technology, Ordos, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, North China Electric Power University, Beijing, China; Department of Automation, North China Electric Power University, Baoding, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, North China Electric Power University, Beijing, China; School of Control and Computer Engineering, North China Electric Power University, Beijing, China","IEEE Access","5 Oct 2020","2020","8","","176101","176111","Coal mills have a significant influence on the reliability, efficiency, and safe operation of a coal-fired power plant. Coal blockage is one of the main reasons for coal mill malfunction. It is highly essential to accurately detect the critical blockage in coal mills to ensure a safe and stable operation of the unit. Taking advantage of unsupervised learning methods and historical process data from distributed control systems (DCS), a stacked denoising autoencoder (SDAE) network-based approach for monitoring critical blockage in a coal mill is proposed in this work. The SDAE model with optimized parameters is applied to reconstruct the operating data during normal operating conditions. The intrinsic relationship between all input variables was captured by training a multilayer network model. The monitoring indicator was obtained from the reconstruction errors, and the threshold for monitoring indicators was obtained using kernel density estimation (KDE) during normal operation. The proposed network is independent of fault data, requires a reduced on-line calculation, and demonstrates a better real-time performance compared to conventional methods. The abnormal variables analysis may provide a theoretical evidence for critical blockage. The effectiveness of the proposed method is validated using operating data collected from an actual coal-fired power plant in China. The results demonstrated that the proposed method can effectively detect critical blockage in a coal mill and issue a timely warning, which allows operators to detect potential faults.","2169-3536","","10.1109/ACCESS.2020.3026918","National Natural Science Foundation of China(grant numbers:52006062); Fundamental Research Funds for the Central Universities(grant numbers:2020MS013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9205881","Coal mill;critical blockage recognition;early warning;Mahalanobis distance;SDAE","Coal;Monitoring;Power generation;Boilers;Mathematical model;Reliability;Condition monitoring","coal;distributed control;fault diagnosis;image denoising;milling;neural nets;power engineering computing;steam power stations;unsupervised learning","operating data;coal-fired power plant;coal blockage;coal mill malfunction;safe operation;stable operation;stacked denoising autoencoder network-based approach;critical blockage monitoring;kernel density estimation;KDE","","1","","37","CCBYNCND","25 Sep 2020","","","IEEE","IEEE Journals"
"Vehicular Visible Light Communications Noise Analysis and Autoencoder Based Denoising","B. Turan; E. Kar; S. Coleri","Department of Electrical and Electronics Engineering, Koc University, Sariyer, Istanbul, Turkey; Koc University Ford Otosan Automotive Technologies Laboratory, Sariyer, Istanbul, Turkey; Department of Electrical and Electronics Engineering, Koc University, Sariyer, Istanbul, Turkey","2022 Joint European Conference on Networks and Communications & 6G Summit (EuCNC/6G Summit)","8 Jul 2022","2022","","","19","24","Vehicular visible light communications (V-VLC) is a promising intelligent transportation systems (ITS) technology for vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications with the utilization of light emitting diodes (LEDs). The main degrading factor for the performance of V-VLC systems is noise. Unlike traditional radio frequency (RF) based systems, V-VLC systems include many noise sources: solar radiation, background lighting from vehicle, street, parking garage and tunnel lights. Traditional V-VLC system noise modeling is based on the additive white Gaussian noise assumption in the form of shot and thermal noise. In this paper, to investigate both time correlated and white noise components of the V-VLC channel, we propose a noise analysis based on Allan variance (AVAR), which provides a time-series analysis method to identify noise from the data. We also propose a generalized Wiener process based V-VLC channel noise synthesis methodology to generate different noise components. We further propose convolutional autoencoder (CAE) based denoising scheme to reduce V-VLC signal noise, which achieves reconstruction root mean square error (RMSE) of 0.0442 and 0.0474 for indoor and outdoor channels, respectively.","2575-4912","978-1-6654-9871-5","10.1109/EuCNC/6GSummit54941.2022.9815630","CHIST-ERA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815630","","System performance;Noise reduction;Lighting;Symbols;Vehicular ad hoc networks;White noise;Light emitting diodes","AWGN;free-space optical communication;intelligent transportation systems;light emitting diodes;mean square error methods;shot noise;signal denoising;stochastic processes;thermal noise;time series;vehicular ad hoc networks","outdoor channels;indoor channels;root mean square error;generalized Wiener process based V-VLC channel noise synthesis methodology;Allan variance;parking garage lights;shot noise;V-VLC system noise modeling;solar radiation;light emitting diodes;autoencoder based denoising;time-series analysis method;white noise components;thermal noise;additive white Gaussian noise assumption;tunnel lights;background lighting;noise sources;radio frequency based systems;vehicle-to-infrastructure communications;vehicle-to-vehicle communications;intelligent transportation systems;vehicular visible light communications noise analysis;V-VLC signal noise","","","","16","IEEE","8 Jul 2022","","","IEEE","IEEE Conferences"
"Automotive Radar Interference Mitigation using a Convolutional Autoencoder","J. Fuchs; A. Dubey; M. Lübke; R. Weigel; F. Lurz","Friedrich-Alexander University Erlangen-Nürnberg (FAU), Institute for Electronics Engineering, Erlangen, Germany; Friedrich-Alexander University Erlangen-Nürnberg (FAU), Institute for Electronics Engineering, Erlangen, Germany; Friedrich-Alexander University Erlangen-Nürnberg (FAU), Institute for Electronics Engineering, Erlangen, Germany; Friedrich-Alexander University Erlangen-Nürnberg (FAU), Institute for Electronics Engineering, Erlangen, Germany; Friedrich-Alexander University Erlangen-Nürnberg (FAU), Institute for Electronics Engineering, Erlangen, Germany","2020 IEEE International Radar Conference (RADAR)","11 Jun 2020","2020","","","315","320","Automotive radar interference imposes big challenges on signal processing algorithms as it raises the noise floor and consequently lowers the detection probability. With limited frequency bands and increasing number of sensors per car, avoidance techniques such as frequency hopping or beamforming quickly become insufficient. Detect-and-repair strategies have been studied intensively for the automotive field, to reconstruct the affected signal samples. However depending on the type of interference, reconstruction of the time domain signals is a highly non-trivial task, which can affect following signal processing modules. In this work an autoencoder based convolutional neural network is proposed to perform image based denoising. Interference mitigation is phrased as a denoising task directly on the range-Doppler spectrum. The neural networks shows significant improvement with respect to signal-to-noise-plus-interference ratio in comparison to other state-of-the-art mitigation techniques, while better preserving phase information of the spectrum compared to other techniques.","2640-7736","978-1-7281-6813-5","10.1109/RADAR42522.2020.9114641","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9114641","","Convolution;Noise reduction;Signal processing algorithms;Interference;Radar;Radar signal processing;Task analysis","convolutional neural nets;Doppler shift;image denoising;image reconstruction;probability;radar computing;radar imaging;radar interference;road vehicle radar;time-domain analysis","automotive radar interference mitigation;convolutional autoencoder;signal processing algorithms;noise floor;detection probability;frequency bands;avoidance techniques;automotive field;denoising task;neural networks;signal-to-noise-plus-interference ratio;detect-and-repair strategies;time domain signal reconstruction;autoencoder based convolutional neural network;image based denoising","","21","","13","","11 Jun 2020","","","IEEE","IEEE Conferences"
"Denoising Autoencoders for Overgeneralization in Neural Networks","G. Spigler","Biorobotics Institute of Scuola Superiore Sant’Anna, Pisa, Italy","IEEE Transactions on Pattern Analysis and Machine Intelligence","5 Mar 2020","2020","42","4","998","1004","Despite recent developments that allowed neural networks to achieve impressive performance on a variety of applications, these models are intrinsically affected by the problem of overgeneralization, due to their partitioning of the full input space into the fixed set of target classes used during training. Thus it is possible for novel inputs belonging to categories unknown during training or even completely unrecognizable to humans to fool the system into classifying them as one of the known classes, even with a high degree of confidence. This problem can lead to security problems in critical applications, and is closely linked to open set recognition and 1-class recognition. This paper presents a novel way to compute a confidence score using the reconstruction error of denoising autoencoders and shows how it can correctly identify the regions of the input space close to the training distribution. The proposed solution is tested on benchmarks of `fooling', open set recognition and 1-class recognition constructed from the MNIST and Fashion-MNIST datasets.","1939-3539","","10.1109/TPAMI.2019.2909876","Microsoft Azure for Research(grant numbers:2017/2018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8684304","Overgeneralization;fooling;autoencoder;open set recognition;open world recognition;1-class recognition;confidence score;neural networks","Training;Neural networks;Computational modeling;Noise reduction;Data models;Support vector machines;Mars","learning (artificial intelligence);neural nets;pattern classification","input space close;training distribution;fooling set recognition;open set recognition;1-class recognition;overgeneralization problem;neural networks;security problems;critical applications;confidence score;autoencoders denoising","","7","","30","IEEE","9 Apr 2019","","","IEEE","IEEE Journals"
"State Assessment and Fault Prediction Method of Distribution Terminal Based on SDAE and Hierarchical Bayesian","R. Liu; S. Feng; Y. Cai; M. Liu","NARI Group Co., Ltd, State Grid Electric Power Research Institute, Nanjing, China; NARI Group Co., Ltd, State Grid Electric Power Research Institute, Nanjing, China; NARI Group Co., Ltd, State Grid Electric Power Research Institute, Nanjing, China; NARI Group Co., Ltd, State Grid Electric Power Research Institute, Nanjing, China","2019 IEEE Sustainable Power and Energy Conference (iSPEC)","30 Jan 2020","2019","","","2783","2787","State Assessment and Fault Prediction mechanism of distribution terminal is the premise of ensuring safe and reliable operation of power grid. However, the sample size of fault rate data of distribution terminal is usually small and the data is missing seriously, so it is difficult to accurately evaluate and analyze the fault rate data. A reliability assessment and prediction model based on stacked denoising autoencoder and hierarchical bayesian is proposed in this paper. Firstly, the quantile method is used to detect abnormal values of distribution terminals. Then, features of fault data is extracted by stacked denoising autoencoder(SDAE), and the Hierarchical Bayesian(HB) model is used to evaluate the failure rate data of distribution terminals. Finally, the evaluation method is compared the traditional prior distribution and the second-order linear regression. The results show that the proposed method improves the accuracy of fault assessment by 5.37% and 10.09%, the accuracy of prediction by 10.23% and 19.94%. The proposed method has higher reliability, prediction efficiency and evaluation accuracy.","","978-1-7281-4930-1","10.1109/iSPEC48194.2019.8975050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8975050","Distribution terminal;Hierarchical Bayesian(HB);stacked denoising autoencoder;fault assessment;fault prediction;stacked denoising autoencoder(SDAE)","","Bayes methods;neural nets;power engineering computing;power grids;power system faults;power system reliability","fault prediction method;distribution terminal;state assessment;fault rate data;reliability assessment;prediction model;fault data;failure rate data;fault assessment;prediction efficiency;fault prediction mechanism;SDAE;hierarchical Bayesian;power grid;stacked denoising autoencoder;quantile method","","1","","12","","30 Jan 2020","","","IEEE","IEEE Conferences"
"Learning influential genes on cancer gene expression data with stacked denoising autoencoders","V. Teixeira; R. Camacho; P. G. Ferreira","MIEIC, Faculdade de Engenharia da Universidade do Porto, Portugal; DEI, Faculdade de Engenharia da Universidade do Porto, Portugal; Ipatimup - Institute of Molecular Pathology and Immunology of the University of Porto, Universidade do Porto, Portugal","2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","18 Dec 2017","2017","","","1201","1205","Cancer genome projects are characterizing the genome, epigenome and transcriptome of a large number of samples using the latest high-throughput sequencing assays. The generated data sets pose several challenges for traditional statistical and machine learning methods. In this work we are interested in the task of deriving the most informative genes from a cancer gene expression data set. For that goal we built denoising autoencoders (DAE) and stacked denoising autoencoders and we studied the influence of the input nodes on the final representation of the DAE. We have also compared these deep learning approaches with other existing approaches. Our study is divided into two main tasks. First, we built and compared the performance of several feature extraction methods as well as data sampling methods using classifiers that were able to distinguish the samples of thyroid cancer patients from samples of healthy persons. In the second task, we have investigated the possibility of building comprehensible descriptions of gene expression data by using Denoising Autoencoders and Stacked Denoising Autoencoders as feature extraction methods. After extracting information related to the description built by the network, namely the connection weights, we devised post-processing techniques to extract comprehensible and biologically meaningful descriptions out of the constructed models. We have been able to build high accuracy models to discriminate thyroid cancer from healthy patients but the extraction of comprehensible models is still very limited.","","978-1-5090-3050-7","10.1109/BIBM.2017.8217828","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8217828","Deep Learning;Gene Expression Analysis;Knowledge Extraction;RNA-Seq;Cancer","Cancer;Noise reduction;Principal component analysis;Gene expression;Feature extraction;Bioinformatics;Genomics","bioinformatics;biology computing;cancer;feature extraction;genetics;genomics;learning (artificial intelligence);medical computing;pattern classification;sampling methods","generated data sets;informative genes;cancer gene expression data;DAE;stacked denoising autoencoders;deep learning approaches;feature extraction methods;thyroid cancer patients;cancer genome projects;epigenome;transcriptome;traditional statistical methods;influential genes learning;machine learning;data sampling methods;information extraction;post-processing techniques;biologically meaningful descriptions;comprehensible model extraction;classifiers","","7","","30","","18 Dec 2017","","","IEEE","IEEE Conferences"
"Dropout-Based Robust Self-Supervised Deep Learning for Seismic Data Denoising","G. Chen; Y. Liu; M. Zhang; H. Zhang","State Key Laboratory of Petroleum Resources and Prospecting, China University of Petroleum-Beijing, Beijing, China; School of Petroleum, China University of Petroleum-Beijing, Karamay, Xinjiang, China; School of Petroleum, China University of Petroleum-Beijing, Karamay, Xinjiang, China; State Key Laboratory of Petroleum Resources and Prospecting, China University of Petroleum-Beijing, Beijing, China","IEEE Geoscience and Remote Sensing Letters","29 Apr 2022","2022","19","","1","5","Incoherent noise suppression is an indispensable step in seismic data processing. Recently, deep learning (DL) methods have gained commendable success in seismic data denoising, one of which is the supervised DL denoising method using clean data as the training label, whereas the cost of obtaining clean data is high. We investigate a robust self-supervised DL denoising method without using clean data. Bernoulli-sampled training pairs of the raw noisy data produced by the dropout layer are served to train the NN, and a Monte Carlo (MC) self-integrated technique results in further improving the denoising quality of the trained NN during the testing. Compared with the f-x deconvolution (FXDECON), deep image prior (DIP), and sparse autoencoder (SAE) methods via synthetic and real data examples, the proposed method outperforms these methods for enhancing the signal-to-noise ratio (SNR) and reducing the signal loss.","1558-0571","","10.1109/LGRS.2022.3167999","Important National Science and Technology Specific Project of China(grant numbers:2016ZX05047-002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9758820","Denoising;dropout;Monte Carlo (MC) self-ensemble;seismic;self-supervised deep learning (DL)","Training;Noise reduction;Noise measurement;Electronics packaging;Artificial neural networks;Signal to noise ratio;Testing","deconvolution;geophysical signal processing;geophysical techniques;learning (artificial intelligence);Monte Carlo methods;neural nets;seismology;signal denoising","robust self-supervised deep learning;seismic data denoising;incoherent noise suppression;seismic data processing;deep learning methods;training label;self-supervised DL denoising method;raw noisy data;denoising quality;trained NN;synthetic data examples;Bernoulli-sampled training pairs;Monte Carlo self-integrated technique;signal-to-noise ratio;SNR;signal loss","","","","28","IEEE","18 Apr 2022","","","IEEE","IEEE Journals"
"Evaluation of stacked autoencoders for pedestrian detection","B. Peralta; L. Parra; L. Caro","Universidad Catolica de Temuco, Temuco, CL; Universidad Catolica de Temuco, Temuco, CL; Universidad Catolica de Temuco, Temuco, CL","2016 35th International Conference of the Chilean Computer Science Society (SCCC)","30 Jan 2017","2016","","","1","7","Pedestrian detection has multiple applications as video surveillance, automatic driver-assistance systems in vehicles or visual control of access. This task is challenging due to presence of factors such as poor lighting, occlusion or uncertainty in the environment. Deep learning has reached many state-of-art results in visual recognition, where one popular and simple variant is stacked autoencoders. Nonetheless, it is not clear what is the effect of each stacked autoencoders parameter in pedestrian detection performance. In this work, we propose to revise the feature representation for pedestrian detection considering the use of deep learning using stacked autoencoders with a sensitivity analysis of relevant parameters. Additionally, this paper presents a methodology for feature extraction using stacked autoencoders. The experiments show that this model is capable of creating a meaningful visual descriptor for pedestrian detection, which improves the detection performance in comparison to baseline techniques without an optimal setting of parameters. In presence of occlusion or poor people images, we found diffuse and distorted visual patterns. A future avenue is the learning of the degree of noise for improving the generalization capabilities of the learned features.","","978-1-5090-3339-3","10.1109/SCCC.2016.7836017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836017","Pedestrian Detection;Deep Learning;Autoencoders;Stacked Autoencoders","Visualization;Machine learning;Feature extraction;Video surveillance;Vehicles;Lighting;Uncertainty","feature extraction;image denoising;image recognition;learning (artificial intelligence);pedestrians;road vehicles;video surveillance","distorted visual patterns;baseline techniques;feature extraction;sensitivity analysis;pedestrian detection performance;stacked autoencoder parameter;visual recognition;deep learning;visual control;automatic driver-assistance systems;video surveillance","","","","","","30 Jan 2017","","","IEEE","IEEE Conferences"
"Modulation Signal Denoising Based on Auto-encoder","Z. Mo; H. Li; J. Wang; H. Huang; J. Li","School of Physics, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China","2021 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)","1 Oct 2021","2021","","","1","5","This paper proposed a denoising method for modulated signals based on the autoencoder. The auto-encoder is a cascade structure, which is composed of multiple convolution layers and multiple pooling layers. It is mainly divided into a feature encoder and a generation decoder. We use the features of the modulated signal with noise as the input of the auto-encoder and the features of the clean signal as the label. At the same time, back-propagation algorithm and gradient descent method are used to optimize and update the parameters in the auto-encoder model to minimize the reconstruction error, so as to realize the denoising function of the modulated signal. For a variety of modulation types, this method can improve the modulation signal about 3–9 dB in different SNR environment. The denoising model can generate high-level features of different modulation signals without any artificial feature extraction and prior knowledge and has strong feature representation ability. It has the advantages of strong versatility, low complexity, good denoising effect and good stability.","2155-5052","978-1-6654-4908-3","10.1109/BMSB53066.2021.9547158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9547158","denoising autoencoder;Machine learning for communications;Advanced signal processing for transmission;convolution neural network","Noise reduction;Neural networks;Modulation;Signal processing algorithms;Feature extraction;Stability analysis;Complexity theory","backpropagation;feature extraction;gradient methods;neural nets;signal denoising","feature representation ability;high-level features;SNR environment;reconstruction error;gradient descent method;back-propagation algorithm;generation decoder;cascade structure;feature encoder;multiple pooling layers;multiple convolution layers;modulation signal denoising;auto-encoder model","","","","16","IEEE","1 Oct 2021","","","IEEE","IEEE Conferences"
"Hybrid Pre-Training Strategy for Deep Denoising Neural Networks and Its Application in Machine Fault Diagnosis","B. Zhao; C. Cheng; Z. Peng; Q. He; G. Meng","State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; School of Mechanical Engineering, Ningxia University, Yinchuan, China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China","IEEE Transactions on Instrumentation and Measurement","22 Nov 2021","2021","70","","1","11","Removing or at least attenuating the effect of noise is of significance for machine fault diagnosis under noisy measuring environments. In this article, deep denoising neural networks are developed to decrease the influence of noise on the modeling accuracy of deep neural networks (DNNs). Among the network, a reproducing kernel Hilbert space (RKHS)-based denoising layer is designed as the first layer to reduce noise. However, due to the unstable gradient problem of the earlier layers in DNNs, weights to-be-optimized in the first denoising layer are tough to update. In addition, the overfitting problem caused by multiple layers also affects the generalization ability of the model. To overcome these dilemmas, a novel hybrid pre-training strategy for deep denoising neural networks is proposed. In this strategy, motivated by the greedy algorithm, a shallow supervised network is first adopted to pre-train the weight of the denoising layer for alleviating the learning difficulty of the first layers in deep networks. Second, feature extraction layers with a large number of layers are pre-trained by an autoencoder-based unsupervised network. After that, weights of the denoising and feature extraction layers are transferred to a deep classification network, and the entire network is finally fine-tuned via supervised learning. The hybrid pre-training strategy for deep denoising neural networks is applied to machine fault diagnosis. Experimental studies verify the effectiveness of the proposed hybrid pre-training strategy in intelligent fault diagnosis of machinery under noisy measuring environments.","1557-9662","","10.1109/TIM.2021.3126019","National Natural Science Foundation of China(grant numbers:12072188,11632011,11702171); Natural Science Foundation of Shanghai(grant numbers:20ZR1425200); Shanghai Pujiang Program(grant numbers:20PJ1409000); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9606702","Deep neural networks (DNNs);denoising layer;hybrid pre-training;machine fault diagnosis;weight initialization","Noise reduction;Fault diagnosis;Feature extraction;Noise measurement;Deep learning","deep learning (artificial intelligence);fault diagnosis;feature extraction;greedy algorithms;Hilbert spaces;machinery;mechanical engineering computing;supervised learning","deep denoising neural networks;denoising layer;feature extraction layers;autoencoder-based unsupervised network;deep classification network;machine fault diagnosis;deep neural networks;hybrid pre-training strategy;shallow supervised network;greedy algorithm;supervised learning;intelligent fault diagnosis;DNNs;reproducing kernel Hilbert space;RKHS-based denoising layer","","3","","40","IEEE","8 Nov 2021","","","IEEE","IEEE Journals"
"Data Driven Multivariate Air Quality Forecasting using Dynamic Fine Tuning Autoencoder Layer","K. K. Rani Samal; K. Sathya Babu; A. K. Panda; S. K. Das","Department of CSE, NIT Rourkela, Rourkela, India; Department of CSE, NIT Rourkela, Rourkela, India; Department of ECE, NIT Rourkela, Rourkela, India; Department of ECE, NIT Rourkela, Rourkela, India","2020 IEEE 17th India Council International Conference (INDICON)","5 Feb 2021","2020","","","1","6","Particulate matter 2.5 (PM2.5) has a severe negative impact on human health, so forecasting of particulate matter has become one of the primary concerns worldwide as it has a significant role in effective control of air pollution. In the current era, the application of artificial intelligence techniques is growing fast, improving environmental air quality. So this research work introduced a data-driven SVR-Autoencoder model for trend analysis and dynamic data modeling in the real-time environment. It also introduced Multivariate imputation by chained equations (MICE) as a multiple imputation method, which considers meteorological attributes to impute the missing values of the PM2.5 dataset. We further added LSTM as a Stacked Denoising Autoencoder layer, which dynamically adjusts the weight to provide accurate forecasting results in a real-time environment. The experimental result shows that the SVR-Autoencoder model provides 34-67% better results than the baseline models, which indicates its effectiveness in air quality modeling.","2325-9418","978-1-7281-6916-3","10.1109/INDICON49873.2020.9342046","Ministry of Human Resource Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9342046","MICE;SVR;Autoencoder;Air quality;Time series forecasting","Atmospheric modeling;Noise reduction;Predictive models;Data models;Real-time systems;Mathematical model;Forecasting","aerosols;air pollution;air quality;artificial intelligence","severe negative impact;human health;primary concerns;air pollution;artificial intelligence techniques;environmental air quality;data-driven SVR-Autoencoder model;dynamic data modeling;real-time environment;multivariate imputation by chained equations;multiple imputation method;Stacked Denoising Autoencoder layer;accurate forecasting results;air quality modeling;data driven Multivariate air quality forecasting;dynamic fine tuning Autoencoder layer;particulate matter 2.5;LSTM","","2","","10","","5 Feb 2021","","","IEEE","IEEE Conferences"
"Image Denoising using Deep Auto-Encoder Network for Production Monitoring in Real-Time","S. Jadhav; P. Kulkarni","Technische Universität Chemnitz, Chemnitz, Germany; Vishwakarma Institute of Technology (SPPU), Pune, India","2021 International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT)","6 Apr 2021","2021","","","1","7","Industrial operations today are being smoothed by monitoring the entire process using latest Image Processing (IP) techniques, especially the bottlenecks in the process. The challenges that need to be addressed in order to commercialize and optimize these solutions are equally growing, particularly in image monitoring of the machining and assembly lines in production plants as well as mechanical workshops. One such hindrance in monitoring the jobs on a Lathe machine or a Computer Numerical Control (CNC) machine is the motion blur noise introduced in the images due to the real-time on field vibrations within the setup. In this paper, this problem is addressed with Image denoising in real time frames. Many practical solutions have been addressing the problem of Image denoising or Image reconstruction using different Computer Vision (CV) techniques in the last two decades. Herein, we propose Image restoration of such blurred image using a specific architecture of Deep Autoencoder network with Convolutional Neural layers so as to obtain a fully constructed image without any prior knowledge of the corresponding clean image. For this we have used an averagely deep encoder-decoder neural network to minimize the typical motion blurring noise that gets introduced in the input image captured by the camera setup on the production lines. This particular technique eliminates the need to identify the type of noise, its intensity or any other statistical characteristics. The results evidently show that the reconstructed images are visually convincing, with large improvements retaining the blur image details.","","978-1-7281-5791-7","10.1109/ICAECT49130.2021.9392554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9392554","deep learning;image processing;neural networks;auto-encoder;convolution","Neural networks;Production;Real-time systems;Computer numerical control;Monitoring;Image reconstruction;Image denoising","assembling;computer vision;computerised numerical control;control engineering computing;convolutional neural nets;deep learning (artificial intelligence);image denoising;image motion analysis;image restoration;industrial plants;lathes;machining;neural net architecture;process monitoring;production engineering computing;vibrations","machining;assembly lines;production plants;lathe machine;computer numerical control machine;motion blur noise;image denoising;image reconstruction;computer vision;image restoration;blurred image;fully constructed image;clean image;production lines;blur image details;production monitoring;image processing;image monitoring;motion blurring noise;deep encoder-decoder neural network;real time frames;industrial operations;mechanical workshops;CNC;field vibrations;convolutional neural layers;camera setup;statistical characteristics;deep autoencoder network architecture","","","","17","","6 Apr 2021","","","IEEE","IEEE Conferences"
"Hybrid Deep Neural Network based on SDAE and GRUNN","Y. Zou; J. Yu; J. Tang; Y. Zhang","School of Mechanical and Power Engineering, Harbin University of Science and Technology, Harbin; Key Laboratory of Advanced Manufacturing and Intelligent Technology, Harbin University of Science and Technology, Harbin; Key Laboratory of Advanced Manufacturing and Intelligent Technology, Harbin University of Science and Technology, Harbin; School of Mechanical and Power Engineering, Harbin University of Science and Technology, Harbin","2020 39th Chinese Control Conference (CCC)","9 Sep 2020","2020","","","4222","4226","Stacked autoencoder (SAE) is hard to achieve satisfactory performance, when input data are complex and non-stationary. Besides, the identification performance of recurrent neural network (RNN) may decrease rapidly under noisy environment. In order to deal with these problems, a novel hybrid deep neural network (DNN) based on stacked denoising autoencoder (SDAE) and gated recurrent unit neural network (GRUNN) is presented. First, the structure of the presented hybrid DNN is given. The hybrid DNN contains a SDAE, a GRUNN, and a softmax classifier. Then, the training algorithm based on action discovery (AD) is proposed to train the presented hybrid DNN. The experimental studies indicate the presented hybrid DNN processes strong anti-noise ability and adaptability to time-varying signals.","1934-1768","978-9-8815-6390-3","10.23919/CCC50068.2020.9189494","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9189494","deep neural network;stacked denoising autoencoder;gated recurrent unit neural network;denoising ability;action discovery","Neurons;Feature extraction;Training;Neural networks;Gears;Logic gates;Noise reduction","image classification;image denoising;learning (artificial intelligence);recurrent neural nets","SDAE;GRUNN;hybrid deep neural network;stacked denoising autoencoder;gated recurrent unit neural network;SAE;softmax classifier;training algorithm;action discovery;hybrid DNN processes;time-varying signals","","2","","18","","9 Sep 2020","","","IEEE","IEEE Conferences"
"Data augmentation versus noise compensation for x-vector speaker recognition systems in noisy environments","M. Mohammad Amini; D. Matrouf","LIA (Laboratoire Informatique d’Avignon), Avignon University; LIA (Laboratoire Informatique d’Avignon), Avignon University","2020 28th European Signal Processing Conference (EUSIPCO)","18 Dec 2020","2021","","","1","5","The explosion of available speech data and new speaker modeling methods based on deep neural networks (DNN) have given the ability to develop more robust speaker recognition systems. Among DNN speaker modelling techniques, x-vector system has shown a degree of robustness in noisy environments. Previous studies suggest that by increasing the number of speakers in the training data and using data augmentation more robust speaker recognition systems are achievable in noisy environments. In this work, we want to know if explicit noise compensation techniques continue to be effective despite the general noise robustness of these systems. For this study, we will use two different x-vector networks: the first one is trained on Voxceleb1 (Protocol1), and the second one is trained on Voxceleb1+Voxveleb2 (Protocol2). We propose to add a denoising x-vector subsystem before scoring. Experimental results show that, the x-vector system used in Protocol2 is more robust than the other one used Protocol1. Despite this observation we will show that explicit noise compensation gives almost the same EER relative gain in both protocols. For example, in the Protocol2 we have 21% to 66% improvement of EER with denoising techniques.","2076-1465","978-9-0827-9705-3","10.23919/Eusipco47968.2020.9287690","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287690","speaker recognition;x-vector;data augmentation;noise compensation;denoising autoencoder;deep stacked denoising autoencoder","System performance;Training data;Speech recognition;Signal processing;Speaker recognition;Noise measurement;Standards","neural nets;signal denoising;speaker recognition;vectors","data augmentation;x-vector speaker recognition systems;noisy environments;speaker modeling methods;deep neural networks;robust speaker recognition systems;DNN speaker modelling techniques;noise compensation;general noise robustness;x-vector networks;Voxceleb1+Voxveleb2;x-vector subsystem denoising;EER","","","","24","","18 Dec 2020","","","IEEE","IEEE Conferences"
"Towards Semi-Supervised Classification of Event Streams via Denoising Autoencoders","S. Kauschke; M. Mühlhäuser; J. Fürnkranz","Telecooperation Group, TU Darmstadt, Germany; Telecooperation Group, TU Darmstadt, Germany; Knowledge Engineering Group","2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)","17 Jan 2019","2018","","","131","136","In predictive maintenance, one may face a scenario where a series of anomalous events is indicative of an impending fault. While each of them by itself would not be sufficient for setting off an alarm, their collective occurrence is. However, supervised training of recognizers for these anomalous events is difficult. The number of occurrences of such faults is generally low, and the derived labels are unreliable because they apply to the entire sequence-a so-called mission-and not the individual events. In this paper, we propose an approach for tackling such problems via unsupervised training of autoencoders on data of normal events. Individual anomalies are recognized via the reconstruction error. Missions are then classified via a threshold-based approach on the ensemble of anomaly ratios. Our method handles artificially generated data well and is robust against noisy data. Its main advantage is a low level of supervision, since all the parameters can be extracted experimentally with little knowledge about the ground truth in the data.","","978-1-5386-6805-4","10.1109/ICMLA.2018.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8614052","Event Streams;Autoencoders;Semi-Supervised","Noise reduction;Training;Predictive maintenance;Sensors;Probability distribution;Hidden Markov models;Machine learning","learning (artificial intelligence);pattern classification","event streams;denoising autoencoders;predictive maintenance;anomalous events;threshold-based approach;artificially generated data;semisupervised classification","","2","","21","","17 Jan 2019","","","IEEE","IEEE Conferences"
"Learning Low Rank and Sparse Models via Robust Autoencoders","J. Pu; Y. Panagakis; M. Pantic","Department of Computing, Imperial College London, UK; Samsung AI Research, Cambridge, UK; Samsung AI Research, Cambridge, UK","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","3192","3196","Robust principal component analysis (RPCA), decomposes a data matrix into a superposition of a low-rank matrix and a sparse matrix under certain incoherent conditions. In this paper, we propose a nonlinear generalization of RPCA that uses two autoencoder networks to achieve such a decomposition, in which one autoencoder accounts for the low-rank component and the other for the sparse component. To this end, we provide a principled way of constructing these autoencoders for low-rank and sparse components. The generality of the proposed model is demonstrated by applying it onto three applications, namely 1) music/voice separation 2) image denoising and 3) video foreground separation. Experimental results indicate the effectiveness of the proposed model on these application domains.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682925","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682925","Autoencoders;Low-rank;Sparsity","Principal component analysis;Sparse matrices;Data models;Task analysis;Noise reduction;Standards;Optimization","image denoising;neural nets;principal component analysis;sparse matrices;video signal processing;voice activity detection","low-rank matrix;sparse matrix;RPCA;autoencoder networks;data matrix;music-voice separation;robust principal component analysis;incoherent condition;image denoising;video foreground separation;neural network","","2","","21","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Denoising autoencoder and environment adaptation for distant-talking speech recognition with asynchronous speech recording","L. Wang; B. Ren; Y. Ueda; A. Kai; S. Teraoka; T. Fukushima","Nagaoka University of Technology, Nagaoka, Japan; Nagaoka University of Technology, Nagaoka, Japan; Shizuoka University, Hamamatsu, Japan; Shizuoka University, Hamamatsu, Japan; Shizuoka University, Hamamatsu, Japan; Shizuoka University, Hamamatsu, Japan","Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific","16 Feb 2015","2014","","","1","5","In this paper, we propose a robust distant-talking speech recognition system with asynchronous speech recording. This is implemented by combining denoising autoencoder-based cepstral-domain dereverberation, automatic asynchronous speech (microphone or mobile terminal) selection and environment adaptation. Although applications using mobile terminals have attracted increasing attention, there are few studies that focus on distant-talking speech recognition with asynchronous mobile terminals. For the system proposed in this paper, after applying a denoising autoencoder in the cepstral domain of speech to suppress reverberation and performing Large Vocabulary Continuous Speech Recognition (LVCSR), we adopted automatic asynchronous mobile terminal selection and environment adaptation using speech segments from optimal mobile terminals. The proposed method was evaluated using a reverberant WSJCAMO corpus, which was emitted by a loudspeaker and recorded in a meeting room with multiple speakers by far-field multiple mobile terminals. By integrating a cepstral-domain denoising autoencoder and automatic mobile terminal selection with environment adaptation, the average Word Error Rate (WER) was reduced from 51.8% of the baseline system to 28.8%, i.e., the relative error reduction rate was 44.4% when using multi-condition acoustic models.","","978-6-1636-1823-8","10.1109/APSIPA.2014.7041548","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7041548","","Speech;Speech recognition;Mobile communication;Hidden Markov models;Noise reduction;Reverberation","cepstral analysis;speech coding;speech recognition","denoising autoencoder;environment adaptation;distant-talking speech recognition;asynchronous speech recording;cepstral-domain dereverberation;automatic asynchronous speech;asynchronous mobile terminals;large vocabulary continuous speech recognition;far-field multiple mobile terminals;word error rate","","4","","32","","16 Feb 2015","","","IEEE","IEEE Conferences"
"Detection of Premature Ventricular Complexes using Semisupervised Autoencoders and Random Forests","V. Kalidas; L. S. Tamil","Department of Computer Engineering, The University of Texas at Dallas, Richardson, TX, USA; Faculty of Department of Electrical Engineering, The University of Texas at Dallas, Richardson, TX, USA","2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","27 Aug 2020","2020","","","337","340","In this paper, we propose a technique for detection of premature ventricular complexes (PVC) based on information obtained from single-lead electrocardiogram (ECG) signals. A combination of semisupervised autoencoders and Random Forests models are used for feature extraction and PVC detection. The ECG signal is first denoised using Stationary Wavelet Transforms and denoising convolutional autoencoders. Following this, PVC classification is performed. Individual ECG beat segments along with features derived from three consecutive beats are used to train a hybrid autoencoder network to learn class-specific beat encodings. These encodings, along with the beat-triplet features, are then input to a Random Forests classifier for final PVC classification. Results: The performance of our algorithm was evaluated on ECG records in the MIT-BIH Arrhythmia Database (MITDB) and the St. Petersburg INCART Database (INCARTDB). Our algorithm achieves a sensitivity of 92.67% and a PPV of 95.58% on the MITDB database. Similarly, a sensitivity of 88.08% and a PPV of 94.76% are achieved on the INCARTDB database.","2694-0604","978-1-7281-1990-8","10.1109/EMBC44109.2020.9176054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9176054","","Electrocardiography;Databases;Encoding;Forestry;Training;Morphology;Feature extraction","bioelectric potentials;electrocardiography;feature extraction;learning (artificial intelligence);medical signal detection;medical signal processing;random forests;signal classification;statistical analysis;supervised learning;wavelet transforms","beat-triplet features;ECG records;MIT-BIH Arrhythmia Database;semisupervised autoencoders;single-lead electrocardiogram signals;feature extraction;ECG signal denoising;stationary wavelet transforms;denoising convolutional autoencoders;hybrid autoencoder network;class-specific beat encodings;ECG beat segments;random forests classifier;premature ventricular complex classification;premature ventricular complex detection","Algorithms;Databases, Factual;Electrocardiography;Humans;Ventricular Premature Complexes;Wavelet Analysis","1","","16","","27 Aug 2020","","","IEEE","IEEE Conferences"
"Deep Convolutional Autoencoder for EEG Noise Filtering","N. M. N. Leite; E. T. Pereira; E. C. Gurjão; L. R. Veloso","Department of Electrical Engineering, Federal University of Campina Grande, Campina Grande, Brazil; Department of Systems and Computing, Federal University of Campina Grande, Campina Grande, Brazil; Department of Electrical Engineering, Federal University of Campina Grande, Campina Grande, Brazil; Department of Electrical Engineering, Federal University of Campina Grande, Campina Grande, Brazil","2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","24 Jan 2019","2018","","","2605","2612","Electroencephalography (EEG) signals may be severely affected by noise originated from various sources due to their low amplitude nature, specially if they are collected from scalp sensors. Several methods have been proposed for EEG denoising in order to facilitate diagnosis and communication in brain-computer interfaces, but such algorithms often have high complexity. This work presents a denoising approach based on deep learning using a deep convolutional autoencoder, which should reduce the effort of projecting denoising filters. Experiments were performed using two types of noise, originated from eye blink and from jaw clenching. Performance was evaluated with peak signal-to-noise ratio (PSNR) and the results showed that all confidence intervals for the proposed approach were superior to those obtained by the baseline bandpass traditional filtering method. Best average PSNR results for eye blink were obtained for Cz channels with (20.3 ± 2.6) dB versus (14.3 ± 2.4) dB. For jaw clenching, best average PSNR results were obtained for Fz channels with (21.7 ± 3.1) dB versus (13.9 ± 2.6) dB. The proposed approach seems to open a promising scope of research for noise filtering in EEG.","","978-1-5386-5488-0","10.1109/BIBM.2018.8621080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8621080","Electroencephalogram (EEG);deep learning;deep convolutional autoencoders;noise filtering","Electroencephalography;Biological neural networks;Databases;Convolution;Deep learning;Electrodes;Training","bioelectric potentials;brain-computer interfaces;convolution;electroencephalography;medical signal processing;signal denoising","brain-computer interfaces;deep learning;deep convolutional autoencoder;eye blink;jaw clenching;peak signal-to-noise ratio;baseline bandpass traditional filtering method;electroencephalography signals;scalp sensors;EEG denoising;EEG noise filtering","","8","","19","","24 Jan 2019","","","IEEE","IEEE Conferences"
"Unsupervised 3-D Random Noise Attenuation Using Deep Skip Autoencoder","L. Yang; S. Wang; X. Chen; O. M. Saad; W. Chen; Y. A. S. I. Obou&#x00E9;; Y. Chen","National Engineering Laboratory of Offshore Oil Exploration, China University of Petroleum (Beijing), Beijing, China; National Engineering Laboratory of Offshore Oil Exploration, China University of Petroleum (Beijing), Beijing, China; National Engineering Laboratory of Offshore Oil Exploration, China University of Petroleum (Beijing), Beijing, China; Seismology Department, ENSN Lab, National Research Institute of Astronomy and Geophysics (NRIAG), Helwan, Egypt; Hubei Cooperative Innovation Center of Unconventional Oil and Gas (Ministry of Education), Yangtze University, Wuhan, China; Key Laboratory of Geoscience Big Data and Deep Resource of Zhejiang Province, School of Earth Sciences, Zhejiang University, Hangzhou, China; Bureau of Economic Geology, John A. and Katherine G. Jackson School of Geosciences, The University of Texas at Austin, Austin, TX, USA","IEEE Transactions on Geoscience and Remote Sensing","17 Jan 2022","2022","60","","1","16","Effective random noise attenuation is critical for subsequent processing of seismic data, such as velocity analysis, migration, and inversion. Thus, the removal of seismic random noise with an uncertainty level is meaningful. Attenuating 3-D random noise in a supervised way based on deep learning (DL) is challenging because clean labels are difficult to obtain. Therefore, it is necessary to develop an adaptive unsupervised-based method for random noise attenuation. In this article, we propose a deep-denoising unsupervised learning (DDUL) network to attenuate random noise in 2-D/3-D seismic data. A patching technique is used to split 2-D/3-D seismic data into several patches to be fed into the network, which helps to expand the number of samples for training. We use the fully symmetrical structure of the autoencoder to construct the network. In each corresponding encoder and decoder layer, skip connections are added to enhance the learning of seismic data features. We construct three blocks to extract waveform features in seismic data, i.e., encoder, decoder, and skip blocks. Among them, the skip is connected between the encoder and decoder blocks of each hidden layer. The use of multiple blocks not only improves the network’s ability to extract seismic data features but also solves the problem of excessive training parameters caused by hidden layer stacking. Five 2-D/3-D synthetic and field seismic datasets are used to test the denoising performance of our proposed method. The denoising results demonstrate that our proposed method has good signal-preserving and noise attenuation capabilities in real-world applications.","1558-0644","","10.1109/TGRS.2021.3100455","National Key Research and Development Program of China(grant numbers:2019YFC0312003); Strategic Cooperation Technology Projects of China National Petroleum Corporation (CNPC) and China University of Petroleum (Beijing) (CUPB)(grant numbers:ZLZX2020-03); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9508496","3-D random noise attenuation;autoencoder (AE);deep learning (DL);U-Net","Attenuation;Feature extraction;Noise reduction;Decoding;Noise measurement;Training;Signal to noise ratio","deep learning (artificial intelligence);geophysical signal processing;geophysical techniques;neural nets;random noise;seismology;signal denoising;unsupervised learning","deep skip autoencoder;random noise attenuation;seismic random noise;deep learning;deep-denoising unsupervised learning network;seismic data features;skip blocks;field seismic datasets;DDUL network;3D random noise","","7","","61","IEEE","6 Aug 2021","","","IEEE","IEEE Journals"
"Domain Generalization for Object Recognition with Multi-task Autoencoders","M. Ghifary; W. B. Kleijn; M. Zhang; D. Balduzzi",Victoria University of Wellington; Victoria University of Wellington; Victoria University of Wellington; Victoria University of Wellington,"2015 IEEE International Conference on Computer Vision (ICCV)","18 Feb 2016","2015","","","2551","2559","The problem of domain generalization is to take knowledge acquired from a number of related domains, where training data is available, and to then successfully apply it to previously unseen domains. We propose a new feature learning algorithm, Multi-Task Autoencoder (MTAE), that provides good generalization performance for cross-domain object recognition. The algorithm extends the standard denoising autoencoder framework by substituting artificially induced corruption with naturally occurring inter-domain variability in the appearance of objects. Instead of reconstructing images from noisy versions, MTAE learns to transform the original image into analogs in multiple related domains. It thereby learns features that are robust to variations across domains. The learnt features are then used as inputs to a classifier. We evaluated the performance of the algorithm on benchmark image recognition datasets, where the task is to learn features from multiple datasets and to then predict the image label from unseen datasets. We found that (denoising) MTAE outperforms alternative autoencoder-based models as well as the current state-of-the-art algorithms for domain generalization.","2380-7504","978-1-4673-8391-2","10.1109/ICCV.2015.293","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7410650","","Training;Object recognition;Noise reduction;Feature extraction;Standards;Robustness;Image reconstruction","image denoising;learning (artificial intelligence);object recognition","domain generalization;multitask autoencoder;feature learning algorithm;cross-domain object recognition;standard denoising autoencoder;MTAE;image recognition","","178","","38","","18 Feb 2016","","","IEEE","IEEE Conferences"
"Aero-engine sensor fault diagnosis based on stacked denoising autoencoders","B. Yan; W. Qu","Department of Automation, Shanghai Jiao Tong University, Shanghai, CN; Department of Automation, Shanghai Jiao Tong University, Shanghai, PRC","2016 35th Chinese Control Conference (CCC)","29 Aug 2016","2016","","","6542","6546","In this paper, SDA (stacked denoising auto-encoders) model is introduced to solve the aero-engine sensor fault diagnosis problem. This model uses the principle of greedy layer-wise unsupervised training to initialize the network weight, then uses backpropagation algorithm to optimize the network parameters. This model applies SDA to extract features from aero-engine sensor fault signal and softmax classifier to diagnose fault based on these features. The result of sensor fault diagnosis experiment shows that this approach can make the accuracy of aero-engine sensor fault diagnosis achieve 99.286%.","1934-1768","978-9-8815-6391-0","10.1109/ChiCC.2016.7554387","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7554387","aero-engine sensor fault diagnosis;deep learning;stacked denoising auto-encoders","Circuit faults;Feature extraction;Fault diagnosis;Interference;Training;Backpropagation algorithms;Noise reduction","aerospace computing;aerospace engines;backpropagation;fault diagnosis;feature extraction;greedy algorithms;mechanical engineering computing;sensors;signal classification;unsupervised learning","stacked denoising autoencoders;SDA model;aero-engine sensor fault diagnosis problem;greedy layer-wise unsupervised training;network weight initialization;backpropagation algorithm;feature extraction;softmax classifier","","7","","18","","29 Aug 2016","","","IEEE","IEEE Conferences"
"Research and Implementation of Text Classification Model Based on Combination of DAE and DBN","Z. Yang; X. Pang","School of Information, Qilu University Of Technology, Jinan, China; School of Information, Qilu University Of Technology, Jinan, China","2017 10th International Symposium on Computational Intelligence and Design (ISCID)","8 Feb 2018","2017","2","","190","193","This paper presents a text classification method based on Denoising AutoEncoders(DAE) and Deep Belief Nets(DBN) for the deep learning model. Firstly, using the Denoising AutoEncoders(DAE) to learn other forms of expression of the initial feature of the text. And then use the Deep Belief Nets(DBN) to project the data and reduce the dimension. So that the text data can be expressed more further and better. Finally, the Softmax regression layer was used for classification. The experimental results show that the extracted text feature is applied to the text classification, which significantly improves the classification effect.","2473-3547","978-1-5386-3675-6","10.1109/ISCID.2017.94","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283253","text classification;deep learning;Denoising AutoEncoders(DAE);Deep Belief Nets(DBN)","Handheld computers;Computational intelligence","belief networks;feature extraction;learning (artificial intelligence);pattern classification;regression analysis;text analysis","text classification model;text classification method;deep learning model;text data;classification effect;denoising autoencoders;deep belief nets;text feature extraction;DAE;DBN;Softmax regression layer","","2","","9","","8 Feb 2018","","","IEEE","IEEE Conferences"
"An Efficient Combined Approach For Denoising Fibrous Dysplasia Images","A. Saranya; K. Kottilingam","Computer Science and Enigeering, SRM Institute of Science and Technology, India; Computer Science and Enigeering, SRM Institute of Science and Technology, India","2021 International Conference on System, Computation, Automation and Networking (ICSCAN)","6 Sep 2021","2021","","","1","6","Image denoising and Reconstruction are necessary for medical image processing. It helps to crate a lot of research scope in the medical image analytics. The proposed model of this paper is a combined approach for reducing the noisy details from the bone images. It also predicts the Peak Signal to Noise Ratio (PSNR) ratio between the quality and noise. This approach is greater idea to track the fibrous tissue growth in the bones. This framework is the combination of Auto-Encoder (AE) and Convolutional Neural Network (CNN). AutoEncoder is used for denoising the image with higher quality. Enhanced Convolutional Neural Network predicts the minor noisy details in the image with deep hidden layers. The convolution algorithm creates the major optimism for reconstruction the highly corrupted images. Similarly this framework helps to process denoising and extracting the important features from the image for grouping the regions. Our proposed model achieves the PSNR range for denoised image is 65.369 db.","","978-1-6654-3986-2","10.1109/ICSCAN53069.2021.9526412","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9526412","Auto-Encoder;Convolutional Neural Network;Denoising;Image Reconstruction","Adaptation models;PSNR;Convolution;Computational modeling;Noise reduction;Prediction algorithms;Feature extraction","bone;convolutional neural nets;image denoising;medical image processing","fibrous dysplasia images;image denoising;medical image processing;bone images;peak signal;noise ratio;fibrous tissue growth;convolutional neural network;autoencoder;PSNR;AE;CNN","","","","32","IEEE","6 Sep 2021","","","IEEE","IEEE Conferences"
"MONAURAL SPEECH SEPARATION USING A PHASE-AWARE DEEP DENOISING AUTO ENCODER","D. S. Williamson","Department of Computer Science, Indiana University, USA","2018 IEEE 28th International Workshop on Machine Learning for Signal Processing (MLSP)","1 Nov 2018","2018","","","1","6","Traditional deep denoising autoencoders (DDAE) use magnitude domain features and training targets to separate speech from background noise. Phase enhancement, however, has recently been shown to improve perceptual and objective speech quality. We present an approach that uses a DDAE to estimate phase-aware training targets from phase-aware input features. This network is denoted as a phase-aware deep denoising autoencoder (paDDAE). The short-time Fourier transform (STFT) of noisy speech is the network input, and the network estimates a phase-aware time-frequency mask. The proposed approach is evaluated across multiple conditions, including various signal-to-noise ratios (SNRs), noise types, and speakers. The results show that the paDDAE offers improvements over traditional DDAEs in terms of objective speech quality and intelligibility.","1551-2541","978-1-5386-5477-4","10.1109/MLSP.2018.8516918","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516918","Deep denoising autoencoders;phase enhancement;speech separation","Noise reduction;Noise measurement;Decoding;Training;Encoding;Time-frequency analysis;Speech processing","feature extraction;Fourier transforms;speech coding;speech enhancement;speech intelligibility","objective speech intelligibility;traditional DDAE;short-time Fourier transform;signal-to-noise ratios;phase-aware time-frequency mask;phase-aware deep denoising autoencoder;phase-aware input features;phase-aware training targets;objective speech quality;perceptual speech quality;phase enhancement;background noise;magnitude domain features;monaural speech separation","","3","","26","","1 Nov 2018","","","IEEE","IEEE Conferences"
"Convergence Technology Opportunity Discovery for Firms Based on Technology Portfolio Using the Stacked Denoising AutoEncoder (SDAE)","D. Kwon; S. Y. Sohn","SK Telecom, Seoul, South Korea; Department of Industrial Engineering, Yonsei University, Seoul, South Korea","IEEE Transactions on Engineering Management","","2022","PP","99","1","15","Technology convergence, as a key driving force of innovation, has brought a burgeoning of research attention. Although numerous studies on technology convergence have been carried out, there were limitations in consideration of a firm's capability in technology convergence. This article proposes a framework for “Convergence Technology Opportunity Discovery” (CTOD) based on firms’ technical convergence competence manifested in their patent portfolios, market competition, and technological growth potential. The present research, by employing a stacked denoising autoencoder, a deep neural network-based collaborative filtering method, provides reliable latent preference toward convergence technology for individual firms. Our CTOD framework is applied to three information technology and biotechnology firms to elaborately demonstrate its validity. Ultimately, the proposed framework is expected to provide practical assistance to organizations seeking technology convergence opportunities in various fields.","1558-0040","","10.1109/TEM.2022.3208871","Basic Science Research Program; National Research Foundation of Korea; Ministry of Science and ICT(grant numbers:2020R1A2C2005026); Korea Government (MSIP)(grant numbers:2016R1A2A1A05005270); Department of Industrial Engineering, Yonsei University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9912137","Collaborative filtering (CF);stacked denoising autoencoder (SDAE);technical convergence competences;Technology Opportunity Discovery (TOD);technology recommendation","Convergence;Patents;Companies;Research and development;Industries;Market research;Portfolios","","","","","","","IEEE","5 Oct 2022","","","IEEE","IEEE Early Access Articles"
"Detection of Freezing of Gait Using Unsupervised Convolutional Denoising Autoencoder","M. H. M. Noor; A. Nazir; M. N. A. Wahab; J. O. Y. Ling","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Department of Information Systems, College of Technological Innovation, Zayed University, Abu Dhabi, United Arab Emirates; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia","IEEE Access","24 Aug 2021","2021","9","","115700","115709","At the advanced stage of Parkinson’s disease, patients may suffer from ‘freezing of gait’ episodes: a debilitating condition wherein a patient’s “feet feel as though they are glued to the floor.” The objective, continuous monitoring of the gait of Parkinson’s disease patients with wearable devices has led to the development of many freezing of gait detection models involving the automatic cueing of a rhythmic auditory stimulus to shorten or prevent episodes. The use of thresholding and manually extracted features or feature engineering returned promising results. However, these approaches are subjective, time-consuming, and prone to error. Furthermore, their performance varied when faced with the different walking styles of Parkinson’s disease patients. Inspired by state-of-art deep learning techniques, this research aims to improve the detection model by proposing a feature learning deep denoising autoencoder to learn the salient characteristics of Parkinsonian gait data that is applicable to different walking styles for the elimination of manually handcrafted features. Even with the elimination of manually handcrafted features, a reduction in half of the data window sizes to 2s, and a significant dimensionality reduction of learned features, the detection model still managed to achieve 90.94% sensitivity and 67.04% specificity, which is comparable to the original Daphnet dataset research.","2169-3536","","10.1109/ACCESS.2021.3104975","Universiti Sains Malaysia and the Ministry of Higher Education Malaysia under the Fundamental Research Grant Scheme 203.PKOMP.6711798; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9514558","Parkinson’s disease;freezing of gait;denoising autoencoder;unsupervised learning","Feature extraction;Legged locomotion;Support vector machines;Diseases;Sensitivity;Data models;Sensor phenomena and characterization","","","","","","23","CCBY","16 Aug 2021","","","IEEE","IEEE Journals"
"Relational autoencoder for feature extraction","Q. Meng; D. Catchpoole; D. Skillicom; P. J. Kennedy","Faculty of Engineering and Information Technology, University of Technology Sydney, Sydney, Australia; Children's Cancer Research Unit, The Children's Hospital, Sydney, Australia; School of Computing, Queen's University at Kingston, Ontario, Canada; Faculty of Engineering and Information Technology, University of Technology Sydney, Sydney, Australia","2017 International Joint Conference on Neural Networks (IJCNN)","3 Jul 2017","2017","","","364","371","Feature extraction becomes increasingly important as data grows high dimensional. Autoencoder as a neural network based feature extraction method achieves great success in generating abstract features of high dimensional data. However, it fails to consider the relationships of data samples which may affect experimental results of using original and new features. In this paper, we propose a Relation Autoencoder model considering both data features and their relationships. We also extend it to work with other major autoencoder models including Sparse Autoencoder, Denoising Autoencoder and Variational Autoencoder. The proposed relational autoencoder models are evaluated on a set of benchmark datasets and the experimental results show that considering data relationships can generate more robust features which achieve lower construction loss and then lower error rate in further classification compared to the other variants of autoencoders.","2161-4407","978-1-5090-6182-2","10.1109/IJCNN.2017.7965877","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7965877","","Feature extraction;Data models;Image reconstruction;Training;Decoding;Principal component analysis;Noise reduction","feature extraction;neural nets","relational autoencoder;feature extraction;neural network;sparse autoencoder;denoising autoencoder;variational autoencoder","","46","1","45","","3 Jul 2017","","","IEEE","IEEE Conferences"
"Autoencoder for Vibrotactile Signal Compression","Z. Li; R. Hassen; Z. Wang","Dept. of Electrical & Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Computer Science Department, Assiut University, Egypt; Dept. of Electrical & Computer Engineering, University of Waterloo, Waterloo, ON, Canada","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","4290","4294","Vibrotactile signals contain rich haptic information about textured surfaces but their large data volume makes it a challenging task to transmit such signals to remote locations to create immersive and realistic user experiences. Inspired by the recent success of deep neural network (DNN) based autoencoder, we make the first attempt to apply autoencoder for lossy compression of haptic vibrotactile signals, where a convolutional neural network (CNN) and a rate-distortion (RD) function are used as the transform and cost functions, respectively. Performance comparisons with state-of-the-art methods using both peak signal-to-noise ratio (PSNR) and perceptually motivated spectral temporal similarity (ST-SIM) measures show that the proposed end-to-end vibrotactile autoencoder (EVA) is highly competitive at preserving signal quality while keeping the data rate low.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9413370","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9413370","haptic communication;vibrotactile signals compression;autoencoder;deep neural network;BD-rate","Training;PSNR;Signal processing algorithms;Transforms;Signal processing;Acoustic measurements;Haptic interfaces","convolutional neural nets;data compression;haptic interfaces;signal denoising;spectral analysis;transforms;user experience","data rate low;vibrotactile signal compression;haptic information;immersive user experiences;realistic user experiences;deep neural network based autoencoder;haptic vibrotactile signals;convolutional neural network;rate-distortion function;peak signal-to-noise ratio;spectral temporal similarity measures;end-to-end vibrotactile autoencoder;ST-SIM measures;PSNR","","1","","25","IEEE","13 May 2021","","","IEEE","IEEE Conferences"
"Confirmnet: Convolutional Firmnet and Application to Image Denoising and Inpainting","P. K. Pokala; P. Kumar Uttam; C. S. Seelamantula","Department of Electrical Engineering, Indian Institute of Science, Bangalore, India; Electro-Mechanical Systems Group, DRDO, Pune, India; Department of Electrical Engineering, Indian Institute of Science, Bangalore, India","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","8663","8667","We address the problem of efficient convolutional sparse coding (CSC) and develop a non-convex-penalty-regularized CSC formulation, namely, minimax-concave CSC (MC2SC). MC2SC leads to an optimal sparse representation than the standard ℓ1-penalty based approach. In addition, suitable convergence guarantees can also be provided for MC2SC. We propose a convolutional iterative firm-thresholding algorithm (CIFTA) building on our previously proposed IFTA, and its deep-unfolded version, namely, convolutional-FirmNet (ConFirmNet). As an application, we develop the ConFirmNet based sparse autoencoder (ConFirmNet-SAE) for learning an application-specific convolutional dictionary, the applications being image denoising and inpainting. Further, we also show that training ConFirmNet-SAE with the Huber loss imparts robustness to outliers. It also turns out that ConFirmNet-SAE is robust to mismatch between training and test noise conditions than convolutional learned iterative soft-thresholding algorithm (LISTA).","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9053538","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9053538","Convolutional sparse coding;FirmNet;convolutional IFTA;LISTA;deep unfolding","Convolutional codes;Training;Convolution;Signal processing algorithms;Iterative algorithms;Image denoising;Testing","convolutional codes;image coding;image denoising;image representation;image segmentation;iterative methods;learning (artificial intelligence);minimax techniques","convolutional firmnet;efficient convolutional sparse coding;nonconvex-penalty-regularized CSC formulation;minimax-concave CSC;optimal sparse representation;penalty based approach;convergence guarantees;convolutional iterative firm-thresholding algorithm building;deep-unfolded version;convolutional-FirmNet;sparse autoencoder;application-specific convolutional dictionary;convolutional learned iterative soft-thresholding algorithm;ConFirmNet-SAE training;image inpainting;image denoising;Huber loss;MC2SC;IFTA;standard ℓ1-penalty based approach","","","","30","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Reconstruction of Finite Rate of Innovation Spherical Signals in the Presence of Noise Using Deep Learning Architecture","M. O. Tarar; Z. Khalid","School of Science and Engineering, Lahore University of Management Sciences, Lahore, Pakistan; School of Science and Engineering, Lahore University of Management Sciences, Lahore, Pakistan","2020 28th European Signal Processing Conference (EUSIPCO)","18 Dec 2020","2021","","","1487","1491","We propose a method for the accurate reconstruction (recovery of parameters) of non-bandlimited finite rate of innovation (FRI) signals on the sphere from its measurements contaminated by additive isotropic noise. We propose a framework that takes the optimal number of noisy measurements and employs autoencoder (deep learning architecture) to enhance the signal consisting of a finite number of Diracs before estimating the parameters using the annihilating filter method. We use convolutional and fully connected autoencoders for signal enhancement in the spatial and spectral domains respectively. We analyse the denoising performance of both the overcomplete and undercomplete autoencoders and demonstrate the superior performance, measured as a gain in the signal to noise ratio (SNR) of the output signal, of the fully connected overcomplete autoencoder that filters the signal in the spectral domain. Through numerical experiments, we demonstrate the improvement enabled by the proposed framework in the accuracy of recovery of the parameters of the FRI signal.","2076-1465","978-9-0827-9705-3","10.23919/Eusipco47968.2020.9287581","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287581","Finite rate of innovation;sphere;spherical harmonics;isotropic noise;autoencoders;deep learning","Deep learning;Technological innovation;Noise reduction;Pollution measurement;Noise measurement;Spectral analysis;Signal to noise ratio","deep learning (artificial intelligence);filtering theory;Gaussian noise;signal denoising;signal reconstruction;signal sampling","innovation spherical signals;deep learning architecture;reconstruction accuracy;nonbandlimited finite rate;innovation signals;additive isotropic noise;optimal number;noisy measurements;annihilating filter method;signal enhancement;spatial domains;spectral domains;denoising performance;overcomplete autoencoders;undercomplete autoencoders;signal to noise ratio;fully connected overcomplete autoencoder;FRI signal;convolutional autoencoders","","","","21","","18 Dec 2020","","","IEEE","IEEE Conferences"
"Disentangling inter-subject variations: Automatic localization of ventricular tachycardia origin from 12-lead electrocardiograms","S. Chen; P. K. Gyawali; H. Liu; B. M. Horacek; J. L. Sapp; L. Wang","Zhejiang University, Zhejiang, China; Rochester Institute of Technology, NY, USA; Zhejiang University, Zhejiang, China; Dalhousie University, Halifax, NS, Canada; Dalhousie University, Halifax, NS, Canada; Rochester Institute of Technology, NY, USA","2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)","19 Jun 2017","2017","","","616","619","An automatic, real-time localization of ventricular tachycardia (VT) can improve the efficiency and efficacy of interventional therapies. Because the exit site of VT gives rise to its QRS morphology on electrocardiograms (ECG), it has been shown feasible to predict VT exits from 12-lead ECGs. However, existing work have reported limited resolution and accuracy due to a critical challenge: the significant inter-subject heterogeneity in ECG data. In this paper, we present a method to explicitly separate and represent the factors of variation in data throughout a deep network using denoising autoencoder with contrastive regularization. We demonstrate the performance of this method on an ECG dataset collected from 39 patients and 1012 distinct sites of ventricular origins. An improvement in the accuracy of localizing the origin of activation is obtained in comparison to a traditional approach that uses prescribed QRS features for prediction, as well as the use of a standard autoencoder network without separating the factors of variations in ECG data.","1945-8452","978-1-5090-1172-8","10.1109/ISBI.2017.7950596","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950596","Ventricular tachycardia;Catheter ablation;Denoising autoencoders;Factor disentanglement","Electrocardiography;Standards;Training;Data models;Morphology;Predictive models;Noise reduction","cardiovascular system;diseases;electrocardiography;medical signal processing;signal denoising","intersubject variations;automatic localization;ventricular tachycardia origin;12-lead electrocardiograms;real-time localization;VT;interventional therapies;QRS morphology;12-lead ECG;intersubject heterogeneity;deep network;denoising autoencoder;contrastive regularization;ECG dataset;ventricular origins;standard autoencoder network","","6","","10","IEEE","19 Jun 2017","","","IEEE","IEEE Conferences"
"Automatic Classification of CAD ECG Signals With SDAE and Bidirectional Long Short-Term Network","E. K. Wang; X. Zhang; L. Pan","Harbin Institute of Technology, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; German Cancer Research Center, Heidelberg, Germany","IEEE Access","24 Dec 2019","2019","7","","182873","182880","Coronary artery disease (CAD) has been one of main causes of heart diseases globally. The electrocardiogram (ECG) is a widely used diagnostic tool to monitor patients' heart activities, and medical personnel need to judge whether there are abnormal heartbeats according to captured results. Therefore, it is significant to identify ECG signals accurately and fast. In this paper, a fast and accurate electrocardiogram (ECG) classification system based on deep learning is proposed. In our model, stacked denoising autoencoders (SDAE), as encoder, automatically learns semantic encoding of heartbeats without any complex feature extraction in unsupervised way. Then bidirectional LSTM (Bi-LSTM) classifier achieves classification of heartbeats with semantic encoding. SDAE implements noise-reduction while Bi-LSTM takes full advantage of temporal information in data. At the same time, this method relieves impacts from unbalanced data by employing cost-sensitive loss function. We validate our model on MIT-BIH Arrhythmias Database, SVDB and NSTDB respectively. Compared with state-of-art methods, the final result verify that this newly proposed method not only has high accuracy but also boosts classifying efficiency.","2169-3536","","10.1109/ACCESS.2019.2936525","National Natural Science Foundation of China(grant numbers:61572157); Natural Science Foundation of Guangdong Province(grant numbers:2016A030313660,2017A030313365); Shenzhen Municipal Science and Technology Innovation Project(grant numbers:JCYJ20160608161351559,KQJSCX70726103044992,JCYJ20170811155158682,JCYJ20160428092427867); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807206","Arrythmia;bidirectional long short-term term network (Bi-LSTM);cost-sensitive learning;denoise;electrocardiogram (ECG);stacked denoising autoencoder (SDAE)","Databases;Electrocardiography;Heart beat;Feature extraction;Deep learning;Noise reduction","blood vessels;diseases;electrocardiography;feature extraction;learning (artificial intelligence);medical signal processing;patient monitoring;signal classification;signal denoising","medical personnel;abnormal heartbeats;deep learning;encoder;semantic encoding;complex feature extraction;bidirectional LSTM classifier;Bi-LSTM;noise-reduction;automatic classification;CAD ECG signals;bidirectional long short-term network;coronary artery disease;heart diseases;diagnostic tool;stacked denoising autoencoders;MIT-BIH Arrhythmias Database;electrocardiogram classification system","","11","","30","CCBY","20 Aug 2019","","","IEEE","IEEE Journals"
"Autoencoders as Weight Initialization of Deep Classification Networks Applied to Papillary Thyroid Carcinoma","M. F. Ferreira; R. Camacho; L. F. Teixeira","CESE - INESC TEC, Porto, Portugal; LIAAD - INESC TEC and DEI - Faculty of Engineering, University of Porto, Porto, Portugal; CTM - INESC TEC and DEI - Faculty of Engineering, University of Porto, Porto, Portugal","2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","24 Jan 2019","2018","","","629","632","Cancer is one of the most serious health problems of our time. One approach for automatically classifying tumor samples is to analyze derived molecular information. Previous work by Teixeira et al. compared different methods of Data Oversampling and Feature Reduction, as well as Deep (Stacked) Denoising Autoencoders followed by a shallow layer for classification. In this work, we compare the performance of 6 different types of Autoencoder (AE), combined with two different approaches when training the classification model: (a) fixing the weights, after pretraining an AE, and (b) allowing fine-tuning of the entire network. We also apply two different strategies for embedding the AE into the classification network: (1) by only importing the encoding layers, and (2) by importing the complete AE. Our best result was the combination of unsupervised feature learning through a single-layer Denoising AE, followed by its complete import into the classification network, and subsequent fine-tuning through supervised training, achieving an F1 score of 99.61% ±0.54. We conclude that a reconstruction of the input space, combined with a deeper classification network outperforms previous work, without resorting to data augmentation techniques.","","978-1-5386-5488-0","10.1109/BIBM.2018.8621356","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8621356","Cancer;Deep Learning;Autoencoders;Gene Expression Analysis.","Encoding;Cancer;Noise reduction;Gene expression;Bioinformatics;Training;Genomics","cancer;feature extraction;medical computing;pattern classification;tumours;unsupervised learning","weight initialization;Deep classification networks applied;papillary thyroid carcinoma;serious health problems;automatically classifying tumor samples;derived molecular information;Data Oversampling;Feature Reduction;Deep Denoising Autoencoders;shallow layer;classification model;classification network;subsequent fine-tuning;single-layer Denoising AE;unsupervised feature;encoding layers","","5","","17","","24 Jan 2019","","","IEEE","IEEE Conferences"
"Bearing Fault Diagnosis with Denoising Autoencoders in Few Labeled Sample Case","Y. Zeng; X. Wu; J. Chen","School of Software Engineering, Xi’an Jiaotong University, Xi’an, China; School of Software Engineering, Xi’an Jiaotong University, Xi’an, China; School of Software Engineering, Xi’an Jiaotong University, Xi’an, China","2020 5th IEEE International Conference on Big Data Analytics (ICBDA)","27 May 2020","2020","","","349","353","The application of transfer learning in the fields of computer vision and natural language processing has been successful. It turns out that pre-training some parameters in the network with unsupervised tasks related to downstream tasks is very useful for subsequent task model training. This approach can reduce the dependence of model training on labeled data to a certain extent, which is beneficial to the application of deep learning algorithms. This paper mainly proposes a bearing fault diagnosis model with a small number of labeled samples. The model is trained through pre-training and fine-tuning. It can use a large amount of unlabeled data to obtain sufficient data representation. Finally, fine-tuning is achieved on small sample fault sets Accuracy. At the same time, several optimizations are proposed on the dassic AE fault diagnosis method, and the effectiveness of the optimization content is verifiedin the experimental stage.","","978-1-7281-4111-4","10.1109/ICBDA49040.2020.9101321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9101321","fault diagnosis;denasing autoencoders;SAE;transfer learning;unsupenZised learning","Convolution;Fault diagnosis;Data models;Training;Feature extraction;Vibrations;Decoding","data structures;fault diagnosis;learning (artificial intelligence);machine bearings;mechanical engineering computing;neural nets;optimisation","denoising autoencoders;transfer learning;deep learning algorithms;bearing fault diagnosis model;data representation;optimization content","","4","","18","","27 May 2020","","","IEEE","IEEE Conferences"
"A novel modulation classification method in cognitive radios using higher-order cumulants and denoising stacked sparse autoencoder","X. Zhu; T. Fujii","Advanced Wireless and Communication Research Center, The University of Electro-Communications, Tokyo, Japan; Advanced Wireless and Communication Research Center, The University of Electro-Communications, Tokyo, Japan","2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)","19 Jan 2017","2016","","","1","5","In this paper, we propose a novel modulation classification method based on deep network as well as higher-order cumulants. The proposed algorithm uses the higher-order cumulants as the features, and thus achieves impressive noise suppression. We use Stacked Denoising Sparse Autoencoder as a classifier for single-carrier modulation classification. This classifier can classify different modulated signals by cumulants automatically, and omit the decision of feature thresholds. A very different aspect from conventional neural network is its stacked structure, which simplifies an exponentially large number of hidden units by a multi-layer construction. Moreover, the better performance of backpropagation and network tune can be achieved while using Stacked Sparse Autoencoder. In addition, Denoising process improves the performance of noise suppression by training the network with a corrupted database. The performance of the multi-classes classification is given by simulations, which indicates that there is a significant performance advantage over the conventional methods.","","978-9-8814-7682-1","10.1109/APSIPA.2016.7820860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820860","","Modulation;Training;Cost function;Noise reduction;Feature extraction;Manganese;Cognitive radio","backpropagation;cognitive radio;higher order statistics;modulation;neural nets","cognitive radios;higher-order cumulants;stacked denoising sparse autoencoder;single-carrier modulation classification;neural network;backpropagation;network tune;noise suppression","","8","","20","","19 Jan 2017","","","IEEE","IEEE Conferences"
"A novel stacked denoising autoencoder with swarm intelligence optimization for stock index prediction","J. Li; G. Liu; H. W. F. Yeung; J. Yin; Y. Y. Chung; X. Chen","School of Information Technologies, University of Sydney, Australia; School of Information Technologies, University of Sydney, Australia; School of Information Technologies, University of Sydney, Australia; School of Information Technologies, University of Sydney, Australia; School of Information Technologies, University of Sydney, Australia; Institute of Advanced Technology, University of Science and Technology of China, China","2017 International Joint Conference on Neural Networks (IJCNN)","3 Jul 2017","2017","","","1956","1961","This paper proposes the use of Stacked Denoising Autoencoder to predict the direction of movement of stock indexes based on the historical and volume data of the underlying stocks. The Stacked Denoising Autoencoder is a deep learning method widely used in the field of computer vision which is capable of learning a compact feature representation of the data for stock index prediction. The Hybrid Gravitational Search Algorithm, a swam intelligence based algorithm, is proposed to optimise the hyper-parameters of the deep network which mitigates the hyper-parameter tuning problem of the network.","2161-4407","978-1-5090-6182-2","10.1109/IJCNN.2017.7966090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966090","Deep Learning;SDAE;Swarm Intelligence;PSO;Stock Index Prediction","Indexes;Noise reduction;Particle swarm optimization;Biological neural networks;Optimization;Feature extraction;Training","learning (artificial intelligence);optimisation;search problems;stock markets;swarm intelligence","stacked denoising autoencoder;swarm intelligence optimization;stock index prediction;stock index movement direction;stock historical data;stock volume data;deep learning method;compact feature representation learning;hybrid gravitational search algorithm;swam intelligence based algorithm;deep network hyperparameter optimization;hyperparameter tuning problem","","4","","24","","3 Jul 2017","","","IEEE","IEEE Conferences"
"Marginalized Stacked Denoising Autoencoder With Adaptive Noise Probability for Cross Domain Classification","Y. Zhang; S. Yang; P. Li; X. Hu; H. Wang","School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China","IEEE Access","11 Oct 2019","2019","7","","143015","143024","Cross-domain classification is a challenging problem, in which, how to learn domain invariant features is critical. Recently, significant improvements to this problem have emerged with the wide application of deep learning models, which have been proposed to learn higher level and robust feature representation. Marginalized stacked denoising autoencoder model (mSDA) has proved to be effective to address this problem. However, the performance of mSDA is sensitive to the noise probability. In previous works, the noise probability is usually set as a constant value by cross-validation in the source domain. There is few work focus on the relationship between the noise probability and cross-domain task. In this paper, we try to compute the value of noise probability adaptively. Thus, an approach called Marginalized Stacked Denoising Autoencoders with Adaptive noise Probability (mSDA-AP) is proposed. Firstly, we extract an informative feature space by an improved index, weighted log-likehood ratio (IWLLR), then aggregate these informative features by weighting. Secondly, we compute the value of noise probability adaptively according to the distance between source domain and target domain, and then with the adaptive noise probability, we disturb the input data to learn a stronger feature space with mSDA. Finally, experimental results show the effectiveness of our proposed approach.","2169-3536","","10.1109/ACCESS.2019.2925811","National Basic Research Program of China (973 Program)(grant numbers:2016YFB1000901); National Natural Science Foundation of China(grant numbers:61673152,91746209); Key Laboratory of Data Science and Intelligence Application, Fujian Province University(grant numbers:1902); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8751976","Domain adaptation;mSDA;noise probability;adaptive parameter","Feature extraction;Noise reduction;Deep learning;Task analysis;Indexes;Adaptation models;Neural networks","feature extraction;learning (artificial intelligence);pattern classification;probability","IWLLR;index weighted log-likehood ratio;mSDA-AP;cross domain classification;marginalized stacked denoising autoencoder;target domain;adaptive noise probability;cross-domain task;source domain;deep learning models;domain invariant features;cross-domain classification","","1","","42","CCBY","1 Jul 2019","","","IEEE","IEEE Journals"
"Feature Analysis of Marginalized Stacked Denoising Autoenconder for Unsupervised Domain Adaptation","P. Wei; Y. Ke; C. K. Goh","School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; Rolls-Royce Advanced Technology Centre, Singapore","IEEE Transactions on Neural Networks and Learning Systems","22 Apr 2019","2019","30","5","1321","1334","Marginalized stacked denoising autoencoder (mSDA), has recently emerged with demonstrated effectiveness in domain adaptation. In this paper, we investigate the rationale for why mSDA benefits domain adaptation tasks from the perspective of adaptive regularization. Our investigations focus on two types of feature corruption noise: Gaussian noise (mSDAg) and Bernoulli dropout noise (mSDAbd). Both theoretical and empirical results demonstrate that mSDAbd successfully boosts the adaptation performance but mSDAg fails to do so. We then propose a new mSDA with data-dependent multinomial dropout noise (mSDAmd) that overcomes the limitations of mSDAbd and further improves the adaptation performance. Our mSDAmd is based on a more realistic assumption: different features are correlated and, thus, should be corrupted with different probabilities. Experimental results demonstrate the superiority of mSDAmd to mSDAbd on the adaptation performance and the convergence speed. Finally, we propose a deep transferable feature coding (DTFC) framework for unsupervised domain adaptation. The motivation of DTFC is that mSDA fails to consider the distribution discrepancy across different domains in the feature learning process. We introduce a new element to mSDA: domain divergence minimization by maximum mean discrepancy. This element is essential for domain adaptation as it ensures the extracted deep features to have a small distribution discrepancy. The effectiveness of DTFC is verified by extensive experiments on three benchmark data sets for both Bernoulli dropout noise and multinomial dropout noise.","2162-2388","","10.1109/TNNLS.2018.2868709","National Research Foundation Singapore; Ministry of Education of Singapore through AcRF Tier-1(grant numbers:RG135/14); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8475034","Deep feature learning and feature analysis;marginalized denoising autoencoder (mDA);unsupervised domain adaptation","Noise reduction;Feature extraction;Adaptation models;Learning systems;Task analysis;Gaussian noise;Minimization","feature extraction;Gaussian noise;image denoising;minimisation;neural nets;probability;unsupervised learning","Bernoulli dropout noise;marginalized stacked denoising autoenconder;unsupervised domain adaptation;adaptive regularization;feature corruption noise;adaptation performance;data-dependent multinomial dropout noise;domain adaptation tasks;feature analysis;mSDA;Gaussian noise;probabilities;deep transferable feature coding framework;DTFC framework;feature learning process;distribution discrepancy;deep feature extraction;domain divergence minimization","","13","","52","IEEE","27 Sep 2018","","","IEEE","IEEE Journals"
"Improving Voice Activity Detection by using Denoising-Based Techniques with Convolutional LSTM","N. Kurpukdee; S. Boonkla; V. Chunwijitras; P. Sertsi; S. Kasuriya","National Electronics and Computer Technology Center (NECTEC), National Science and Technology Development Agency (NSTDA) 112 Pahonyothin Road, Pathumthani, Thailand; National Electronics and Computer Technology Center (NECTEC), National Science and Technology Development Agency (NSTDA) 112 Pahonyothin Road, Pathumthani, Thailand; National Electronics and Computer Technology Center (NECTEC), National Science and Technology Development Agency (NSTDA) 112 Pahonyothin Road, Pathumthani, Thailand; National Electronics and Computer Technology Center (NECTEC), National Science and Technology Development Agency (NSTDA) 112 Pahonyothin Road, Pathumthani, Thailand; National Electronics and Computer Technology Center (NECTEC), National Science and Technology Development Agency (NSTDA) 112 Pahonyothin Road, Pathumthani, Thailand","2019 14th International Joint Symposium on Artificial Intelligence and Natural Language Processing (iSAI-NLP)","26 Mar 2020","2019","","","1","6","The performance of voice activity detection (VAD) is drastically degraded when observed speech signals are from unseen noisy environments. In this paper, we propose denoisingbased VAD to cope with the unseen noises. The proposed VAD system mainly consists of two stages for denoising and speech/non-speech classification. In the first stage, either logmagnitude spectral estimator (LSA) or convolutional long shortterm memory neural network autoencoder (CLAE) is applied to eliminate the noises. The convolutional bidirectional long-shortterm memory deep neural network (CBLDNN) is employed for the speech/non-speech classification. The results showed that the proposed VAD was better than the baseline. Furthermore, our CLAE tends to outperform the LSA in denoising algorithms when the signal-to-noise ratio is 5dB.","","978-1-7281-5631-6","10.1109/iSAI-NLP48611.2019.9045413","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9045413","Voice Activity Detection;Convolutional LSTM;DNN;Bidirectional LSTM;Convolutional Autoencoder","Noise reduction;Convolution;Noise measurement;Training;Signal to noise ratio;Distortion;Indexes","convolutional neural nets;recurrent neural nets;signal denoising;speech recognition","voice activity detection;denoising-based techniques;convolutional LSTM;observed speech signals;unseen noisy environments;VAD system;neural network autoencoder;signal-to-noise ratio;long-short term memory deep neural network;logmagnitude spectral estimator;LSA;noise figure 5.0 dB","","3","","23","","26 Mar 2020","","","IEEE","IEEE Conferences"
"A novel approach for trajectory feature representation and anomalous trajectory detection","W. Feng; C. Han","MOE KLINNS Lab, Xi'an Jiaotong University, Xi'an, China; MOE KLINNS Lab, Xi'an Jiaotong University, Xi'an, China","2015 18th International Conference on Information Fusion (Fusion)","17 Sep 2015","2015","","","1093","1099","Trajectories obtained from low level tracking algorithm provide an opportunity for us to analyze meaningful behaviors and monitor adverse or malicious events. How to abstract meaningful features from the raw data of trajectories is a challenge due to the high dimensionality and noise. In this paper, a novel approach, stacked denoising autoencoder(SDA) is applied to address this problem. This method can reduce the dimensionality of the trajectories significantly, so that they can be handled easily. More importantly, the denoising process of the SDA can capture the structure of the raw data, so the features they producing generalize well for detecting anomalous trajectories. The results of the numerical experiments prove the validity of the proposed approach.","","978-0-9824-4386-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7266680","anomalous trajectory detection;feature representation;stacked denoising autoencoder","Trajectory;Noise reduction;Feature extraction;Noise;Training;Shape;Decoding","signal denoising","trajectory feature representation;anomalous trajectory detection;tracking algorithm;malicious event;stacked denoising autoencoder;SDA;denoising process;raw data","","","","12","","17 Sep 2015","","","IEEE","IEEE Conferences"
"Comparison of collaborative deep learning and nonnegative matrix factorization for recommender systems","M. Öggretir; A. T. Cemgil","Bogazici Universitesi, Istanbul, TR; Bilgisayar Mühendisliği Bölümü, Boğaziçi Üniversitesi, İstanbul, Türkiye","2017 25th Signal Processing and Communications Applications Conference (SIU)","29 Jun 2017","2017","","","1","4","Collaborative filtering and content-based methods are two main approaches for recommender systems, and hybrid models use advantages of both. In this paper, we made a comparison of a hybrid model, which uses Bayesian Staked Denoising Autoencoders for content learning, and a collaborative filtering method, Bayesian Nonnegative Matrix Factorisation. It is shown that the tightly coupled hybrid model, Collaborative Deep Learning, gave more successful results comparing to collaborative filtering methods.","","978-1-5090-6494-6","10.1109/SIU.2017.7960695","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7960695","Recommender Systems;Stacked Denoising Autoencoders;Hybrid Models","Collaboration;Recommender systems;Noise reduction;Dogs;Machine learning;Bayes methods;Computational modeling","belief networks;collaborative filtering;content-based retrieval;learning (artificial intelligence);matrix decomposition;recommender systems","collaborative deep learning;nonnegative matrix factorization;recommender systems;collaborative filtering;content-based methods;Bayesian staked denoising autoencoders;content learning","","2","","18","","29 Jun 2017","","","IEEE","IEEE Conferences"
"Serverless Data Parallelization for Training and Retraining of Deep Learning Architecture in Patient-Specific Arrhythmia Detection","M. Marefat; A. Juneja","Electrical and Computer Engineering, University of Arizona, Tucson, Arizona, United States; Electrical and Computer Engineering, University of Arizona, Tucson, Arizona, United States","2019 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)","12 Sep 2019","2019","","","1","4","Stacked Denoising Autoencoders (SDA) are deep networks which have superior generative properties and therefore can be trained and retrained to learn the structure of a patient's heart beat signal with minimal training data. This approach is particularly useful in continuous remote devices because they gather large amounts of data for longer periods of time. Serverless applications are the desired way of building applications due to its cost effectiveness after advancements in commercially available serverless host providers like Amazon AWS. This work proposes a serverless architecture for the training and retraining of SDA, for classification of arrhythmias in a patient-specific manner. This work also proposes a technique for data parallelization in the serverless architecture to achieve a speedup of up-to 13x in training time. This work uses MIT-BIH Arrhythmia database. Retraining with this architecture shows high classification accuracies for Ventricular Ectopic Beats (VEB) (97.41%) and Supraventricular Ectopic Beats (SVEB) (98.77%).","2641-3604","978-1-7281-0848-3","10.1109/BHI.2019.8834566","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8834566","Stacked Denoising Autoencoders;Retraining;Arrhythmia Classification;Remote Continuous Health Devices;Patient Specific;Serverless;Deep Learning","Training;Computer architecture;Detectors;Testing;Feature extraction;Distributed databases;Servers","diseases;electrocardiography;learning (artificial intelligence);medical signal detection;medical signal processing;parallel processing;patient monitoring;signal classification","deep learning architecture;deep networks;minimal training data;continuous remote devices;data parallelization;MIT-BIH arrhythmia database;stacked denoising autoencoders;patient-specific arrhythmia detection;Amazon AWS;supraventricular ectopic beats","","2","","7","","12 Sep 2019","","","IEEE","IEEE Conferences"
"Reading Imagined Letter Shapes from the Mind’s Eye Using Real-time 7 Tesla fMRI","R. Goebel; R. van Hoof; S. Bhat; M. Lührs; M. Senden","Department of Cognitive Neuroscience, Maastricht University, Maastricht, Netherlands; Department of Cognitive Neuroscience, Maastricht University, Maastricht, Netherlands; Department of Cognitive Neuroscience, Maastricht University, Maastricht, Netherlands; Department of Cognitive Neuroscience, Maastricht University, Maastricht, Netherlands; Department of Cognitive Neuroscience, Maastricht University, Maastricht, Netherlands","2022 10th International Winter Conference on Brain-Computer Interface (BCI)","17 Mar 2022","2022","","","1","3","We present a 7 Tesla fMRI proof-of-concept study of the first letter speller BCI that decodes imagined letter shapes from activity patterns in early visual cortical areas. New tools are developed to enable real-time population receptive field retinotopic mapping for encoding and decoding. Using two different letter shapes (H and T), classification performance of generated activity patterns during imagery reaches 80% accuracy in each individual. Using a denoising autoencoder, recognizable letter shapes could be reconstructed and displayed as feedback to participants in the scanner.","2572-7672","978-1-6654-1337-4","10.1109/BCI53720.2022.9735031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9735031","fMRI;letter speller;imagery;population receptive fields;denoising autoencoder","Visualization;Shape;Sociology;Noise reduction;Functional magnetic resonance imaging;Real-time systems;Encoding","biomedical MRI;brain;brain-computer interfaces;decoding;image classification;neurophysiology","real-time fMRI;BCI;early visual cortical areas;real-time population receptive field retinotopic mapping;denoising autoencoder;magnetic flux density 7 T","","","","7","IEEE","17 Mar 2022","","","IEEE","IEEE Conferences"
"Similarity-based Local Feature Extraction for Wafer Bin Map Pattern Recognition","J. Kim; J. -G. Baek","Department of Industrial and Management Engineering, Korea University, Seoul, South Korea; Department of Industrial and Management Engineering, Korea University, Seoul, South Korea","2022 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)","1 Mar 2022","2022","","","056","059","A wafer bin map consists of a local chip containing key information and a global chip present in all patterns. The defect pattern shows a specific pattern shape on the wafer bin map and is defined based on the existing area information. Global information is not differentiated from local information in classification problems and is recognized as a major characteristic, so it affects the identification of the characteristics of defective patterns. In preparation for this, a method of extracting key local information has been proposed. In this paper, we propose a Skip Connections Denoising Autoencoder-based methodology to extract regional information of defect patterns. Randomly distributed chips are recognized as noise by defining anomaly scores based on the probability of each chip appearing in the wafer bin map. We propose a data transformation and reconstruction methodology for extracting local information based on the anomaly score, which is an uncertainty score index. Through the proposed methodology, it was confirmed that the main information that could not be extracted from the convolutional neural network (CNN) was extracted, and it was confirmed that the method proposed in this paper for WM-811K data is superior to the existing method.","","978-1-6654-5818-4","10.1109/ICAIIC54071.2022.9722665","National Research Foundation of Korea; Samsung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9722665","Semiconductor manufacturing process;Defect pattern recognition;Data augmentation;Anomaly localization;Skip connections denoising autoencoder","Location awareness;Learning systems;Uncertainty;Shape;Noise reduction;Semiconductor device manufacture;Feature extraction","convolutional neural nets;electronic engineering computing;feature extraction;image classification;learning (artificial intelligence);semiconductor technology","similarity-based local feature extraction;wafer bin map pattern recognition;local chip;defect pattern;pattern shape;area information;defective patterns;regional information;randomly distributed chips;anomaly score;skip connections denoising autoencoder;global chip;classification problems;data transformation;reconstruction methodology;convolutional neural network;WM-811K data","","","","7","IEEE","1 Mar 2022","","","IEEE","IEEE Conferences"
"Machine Learning for Data Reduction in Quantum State Tomography","X. Liu; S. Lu; R. Wu","Institute of Microelectronics, Tsinghua University, Beijing, P. R. China; Department of Automation, Tsinghua University, Beijing, P. R. China; Department of Automation, Tsinghua University, Beijing, P. R. China","2018 37th Chinese Control Conference (CCC)","7 Oct 2018","2018","","","227","231","The purpose of quantum state tomography (QST) is to obtain a complete quantum state by reconstructing a density matrix from experimental data and therefore gives researchers a powerful tool to analyze complex synthetic quantum systems. In the past decades, many methods have been developed to improve the efficiency of quantum state tomography (QST), such as old methods: compress sensing on almost pure state and low-rank systems, new method: using restricted Boltzmann machine on systems of quantum many-body. However, they are both limited to some certain systems. In this paper, we introduce an universal method using deep neural networks based on stacked denoising autoencoder, which probably can help finish QST on all types of systems with a much smaller number of measurements and therefore is very efficient.","1934-1768","978-988-15639-5-8","10.23919/ChiCC.2018.8483570","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8483570","quantum state tomography;deep neural networks;stacked denoising autoencoder","Noise reduction;Neural networks;Computational modeling;Tomography;Data models;Density measurement;Quantum mechanics","Boltzmann machines;learning (artificial intelligence);quantum computing","quantum state tomography;QST;complex synthetic quantum systems;quantum many-body;machine learning;density matrix reconstruction;restricted Boltzmann machine;deep neural networks;stacked denoising autoencoder","","","","6","","7 Oct 2018","","","IEEE","IEEE Conferences"
"Combating the Impact of Jittering in UAV-based Sensing Systems Using Deep Denoising Network","W. Chen; D. -K. Chang; Y. -J. Chen","Department of Communication Engineering, National Central University, Taoyuan, Taiwan; Department of Communication Engineering, National Central University, Taoyuan, Taiwan; Department of Communication Engineering, National Central University, Taoyuan, Taiwan","2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall)","15 Feb 2021","2020","","","1","3","In this paper, we exploit the deep learning based technologies to mitigate the impact of unmanned aerial vehicle (UAV) jittering on wireless sensing performance. In recent years, UAV has been widely utilized for remote sensing applications due to its high flexibility and maneuverability. However, the mobility and vibration of the UAV's body may cause the jittering effect which can severely degrade the sensing performance. To our best knowledge, the impact of UAV jittering has not been fully examined in literature so far. To alleviate this problem, we propose to leverage adversarial denoising autoencoder (ADAE) for corrupted signal reconstruction. To validate the effectiveness of our proposed scheme, we consider a device-free human sensing scenario in which a UAV is used to sense surrounding human activity by analyzing the received signal strength (RSS). Experiments demonstrate that the proposed ADAE based scheme can effectively reduce the impact of UAV jittering, recovering up to 97% of the performance loss due to the UAV jittering.","2577-2465","978-1-7281-9484-4","10.1109/VTC2020-Fall49728.2020.9348556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9348556","Unmanned aerial vehicles (UAVs);wireless sensing;jittering","Performance evaluation;Wireless communication;Vibrations;Wireless sensor networks;Noise reduction;Unmanned aerial vehicles;Sensors","autonomous aerial vehicles;neural nets;radio links;remote sensing;sensors;signal denoising;signal reconstruction","jittering effect;UAV's body;remote sensing applications;wireless sensing performance;unmanned aerial vehicle;deep learning;deep denoising network;UAV-based;UAV jittering;ADAE based scheme;device-free human sensing scenario","","","","8","","15 Feb 2021","","","IEEE","IEEE Conferences"
"Diagnosis of Incipient Fault Based on Sliding-Scale Resampling Strategy and Improved Deep Autoencoder","J. Yang; Y. Yang; G. Xie","School of Mechatronics and Automotive Engineering, Tianshui Normal University, Tianshui, China; School of Automation and Information Engineering, Xi’an University of Technology, Xi’an, China; School of Automation and Information Engineering, Xi’an University of Technology, Xi’an, China","IEEE Sensors Journal","2 Jul 2020","2020","20","15","8336","8348","Currently, the fault diagnosis with balanced data and distinct characteristics has received mass concern, and the related research achievements are remarkable. However, because of the weakness and scarcity of incipient fault signals, the diagnosis of incipient fault commonly existing in industrial systems is still an intractable problem. In order to solve the problem, an incipient fault diagnosis method based on a sliding-scale resampling strategy and improved sparse autoencoder with multi-particle noise addition (MpNA-SAE) is proposed in this paper. Firstly, the original time domain signals are preprocessed, and a sliding-scale resampling strategy is designed to construct the balanced sample sets. Secondly, a multi-particle noise addition strategy and an adaptive loss function are designed, and then an improved sparse autoencoder with multi-particle noise addition (MpNA-SAE) fault diagnosis model is constructed to identify the fault pattern and determine the severity degree. Thirdly, a diagnostic performance evaluation criterion is proposed to quantify the application range of the model. Finally, the effectiveness and practicability of the proposed method are verified by incipient artificial damage and real fault experiments, respectively.","1558-1748","","10.1109/JSEN.2020.2976523","National Key R&D Program of China(grant numbers:2018YFB1201500,2018YFB1703000); National Natural Science Foundation of China(grant numbers:61873201,61773313,61773016); Key research and development plan of Shaanxi Province(grant numbers:2018GY-139); Natural Science Foundation of Shaanxi Provincial Department of Education(grant numbers:19JS051); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9018051","Deep autoencoder;fault diagnosis;incipient fault;multi-particle noise addition;multiple constraint/regularization term;sliding-scale resampling","Fault diagnosis;Feature extraction;Vibrations;Rolling bearings;Sensors;Time-domain analysis;Noise measurement","fault diagnosis;learning (artificial intelligence);neural nets;production engineering computing;signal denoising","industrial systems;multiparticle noise addition fault diagnosis;sparse autoencoder;incipient artificial damage;fault pattern identification;original time domain signals;MpNA-SAE;incipient fault diagnosis;incipient fault signals;deep autoencoder;sliding-scale resampling strategy","","12","","41","IEEE","28 Feb 2020","","","IEEE","IEEE Journals"
"Pixel-Wise Wasserstein Autoencoder for Highly Generative Dehazing","G. Kim; S. W. Park; J. Kwon","School of Computer Science and Engineering, Chung-Ang University, Seoul, South Korea; School of Computer Science and Engineering, Chung-Ang University, Seoul, South Korea; School of Computer Science and Engineering, Chung-Ang University, Seoul, South Korea","IEEE Transactions on Image Processing","9 Jun 2021","2021","30","","5452","5462","We propose a highly generative dehazing method based on pixel-wise Wasserstein autoencoders. In contrast to existing dehazing methods based on generative adversarial networks, our method can produce a variety of dehazed images with different styles. It significantly improves the dehazing accuracy via pixel-wise matching from hazy to dehazed images through 2-dimensional latent tensors of the Wasserstein autoencoder. In addition, we present an advanced feature fusion technique to deliver rich information to the latent space. For style transfer, we introduce a mapping function that transforms existing latent spaces to new ones. Thus, our method can produce highly generative haze-free images with various tones, illuminations, and moods, which induces several interesting applications, including low-light enhancement, daytime dehazing, nighttime dehazing, and underwater image enhancement. Experimental results demonstrate that our method quantitatively outperforms existing state-of-the-art methods for synthetic and real-world datasets, and simultaneously generates highly generative haze-free images, which are qualitatively diverse.","1941-0042","","10.1109/TIP.2021.3084743","National Research Foundation of Korea(grant numbers:NRF-2020R1C1C1004907); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9447190","Dehazing;wasserstein autoencoder;image enhancement","Tensors;Image enhancement;Lighting;Network architecture;Estimation;Channel estimation;Transforms","feature extraction;geophysical image processing;image colour analysis;image denoising;image enhancement;image fusion;image matching;image representation;image resolution;image restoration","pixel-wise wasserstein autoencoder;highly generative dehazing method;pixel-wise Wasserstein autoencoders;existing dehazing methods;generative adversarial networks;dehazed images;dehazing accuracy;pixel-wise matching;2-dimensional latent tensors;advanced feature fusion technique;latent space;highly generative haze-free images;daytime dehazing;nighttime dehazing;underwater image enhancement","","5","","54","IEEE","4 Jun 2021","","","IEEE","IEEE Journals"
"Noise Cleaning of ECG on Edge Device Using Convolutional Sparse Contractive Autoencoder","R. Banerjee; A. Mukherjee; A. Ghose","Tata Consultancy Services, TCS Research; Tata Consultancy Services, TCS Research; Tata Consultancy Services, TCS Research","2022 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)","6 May 2022","2022","","","491","496","Single-lead Electrocardiogram (ECG) can be easily measured by a commercial smartwatch or a dedicated wearable device. The waveforms are often susceptible to background noise and motion artifacts introducing errors in disease interpretation. An effective yet light-weight de-noising of ECG is an open area of research. In this paper, we propose a novel convolutional autoencoder structure considering a number of regularization terms like sparsity constraint, contractive regularization and L2 norm for ECG de-noising. The deep learning model is duly optimized to efficiently run on low-power edge devices. The proposed approach is evaluated on a simulated and a real-world single-lead ECG database recorded from normal subjects as well as patients having Atrial Fibrillation (AF) and other kinds of abnormal heart rhythms. A thorough comparison is performed with a number of related signal processing and deep learning based prior approaches. Experimental results show that the proposed autoencoder yields the least Root Mean Square Error (RMSE) in reconstruction of clean signals from input ECG corrupted due to addition of noise. Our approach is also able to preserve the relevant morphological properties in the reconstructed ECG data for successful detection of AF and other abnormal rhythms. The optimized model is deployed on a low-power single-board computer for real-time noise cleaning.","","978-1-6654-1647-4","10.1109/PerComWorkshops53856.2022.9767313","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9767313","Electrocardiogram;Autoencoder;Convolutional Neural Network;Noise cleaning;TinyML","Deep learning;Heart beat;Convolution;Conferences;Computational modeling;Noise reduction;Electrocardiography","diseases;electrocardiography;learning (artificial intelligence);medical signal processing;signal denoising","single-lead Electrocardiogram;commercial smartwatch;dedicated wearable device;background noise;motion artifacts;light-weight de-noising;novel convolutional autoencoder structure;regularization terms;contractive regularization;deep learning model;low-power edge devices;single-lead ECG database;Root Mean Square Error;clean signals;input ECG;reconstructed ECG data;real-time noise cleaning;edge device;convolutional sparse contractive autoencoder","","","","12","IEEE","6 May 2022","","","IEEE","IEEE Conferences"
"Autoencoder Based Dimensionality Reduction of Feature Vectors for Object Recognition","R. K. Keser; B. U. Töreyin","Signal Processing for Computational Intelligence Group, Informatics Institute Istanbul Technical University, Istanbul, Turkey; Signal Processing for Computational Intelligence Group, Istanbul Technical University, Istanbul, Turkey","2019 15th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)","16 Apr 2020","2019","","","577","584","Object recognition can be performed with high accuracy thanks to the robust feature descriptors defining the significant areas in images. However, these features suffer from high dimensional structure, in other words ""curse of dimensionality"" for further processes. Autoencoders (AE) are proposed in this study to solve the dimensionality reduction problem of visual features. To assess the efficacy, object recognition is performed using reduced dimensional visual features. For this purpose, dimensionalities of three well-known feature vectors, namely, HOG, SIFT and SURF, are reduced to half. Moreover, deep learning based features are also reduced. Then, reduced vectors, which are called as AE-HOG, AE-SIFT, AE-SURF and AE-DEEP are fed to object recognition task. Also, dimensionality reduction is implemented by a variant of AE, variational autoencoder (VAE) and PCA, which is the most studied unsupervised method for these features, and the results are compared. Furthermore, all experiments are repeated on noisy images. Results suggest that dimensionality reduction of these feature vectors can be accomplished successfully owing to the proposed method.","","978-1-7281-5686-6","10.1109/SITIS.2019.00097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9067860","dimensionality reduction;autoencoder;HOG;SIFT;SURF","Object recognition;Dimensionality reduction;Feature extraction;Principal component analysis;Visualization;Robustness","feature extraction;image coding;image denoising;image recognition;neural nets;object recognition;principal component analysis;transforms;unsupervised learning","object recognition task;dimensionality reduction problem;deep learning based features;autoencoder based dimensionality reduction;AE-HOG;AE-SIFT;AE-SURF;AE-DEEP;variational autoencoder;VAE;PCA","","","","53","","16 Apr 2020","","","IEEE","IEEE Conferences"
"Signal Modulation Recognition based on Convolutional Autoencoder and Time-Frequency Analysis","X. Wu; J. Zhang; C. Hou; G. Liu; J. Zhang; J. Liu","College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; Key Laboratory of Advanced Marine Communication and Information Technology, Ministry of Industry and Information Technology, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China","2021 8th International Conference on Dependable Systems and Their Applications (DSA)","1 Dec 2021","2021","","","664","668","With the development of communication technology, patterns of communication signals have become more complex and diverse. Therefore, the technology of identifying the modulation mode of the communication signal in transmission, especially the modulation recognition technology based on artificial intelligence, has become an extremely important technology in the communication field. For a variety of modulation methods, the traditional method is extremely complicated to implement, and cannot meet the requirements of accurate identification in a short time. In order to increase the speed and reduce the redundancy, this paper proposes a method based on the convolutional autoencoder and the residual network which can realize the denoising, identification and classification of different modulated signals. This method generates ten different modulation types of signals under each signal-to-noise ratio. After the model is trained, the data set is input to the convolutional autoencoder to denoise, and then the data set denoised by the autoencoder is input to the residual network to obtain the classification and recognition accuracy of each modulation type. And an average recognition rate of 92.86% was achieved at -2dB.","2767-6684","978-1-6654-4391-3","10.1109/DSA52907.2021.00096","National Natural Science Foundation of China; Research and Development; Natural Science Foundation of Heilongjiang Province; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622928","Time-frequency diagram;Convolutional autoencoder;Residual network;Modulation recognition","Deep learning;Time-frequency analysis;Convolution;Noise reduction;Redundancy;Modulation;Data models","artificial intelligence;modulation;signal classification;signal denoising;time-frequency analysis","signal classification;recognition accuracy;modulation type;signal modulation recognition;convolutional autoencoder;time-frequency analysis;communication technology;communication signal;artificial intelligence;residual network;modulated signals;signal-to-noise ratio;data set","","","","20","IEEE","1 Dec 2021","","","IEEE","IEEE Conferences"
"A Deep End-to-End Model for Transient Stability Assessment With PMU Data","Q. Zhu; J. Chen; L. Zhu; D. Shi; X. Bai; X. Duan; Y. Liu","State Key Laboratory of Advanced Electromagnetic Engineering and Technology, Electric Power Security and High Efficiency Key Laboratory, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, Electric Power Security and High Efficiency Key Laboratory, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; Department of Electrical Engineering and Computer Science, The University of Tennessee, Knoxville, TN, USA; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, Electric Power Security and High Efficiency Key Laboratory, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, Electric Power Security and High Efficiency Key Laboratory, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; Department of Electrical Engineering and Computer Science, The University of Tennessee, Knoxville, TN, USA","IEEE Access","21 Nov 2018","2018","6","","65474","65487","Accurate transient stability assessment (TSA) is a fundamental requirement for ensuring secure and stable operation of power systems. Tremendous efforts have been made to apply artificial intelligence approaches for TSA with phasor measurement unit data. However, many previous approaches may be failed to provide favorable accuracy due to the shallow architectures and error-prone hand-crafting features. This paper proposed a model for TSA, which is termed multi-branch stacked denoising autoencoder (MSDAE). This model is a unified framework integrating multiple stacked denoising autoencoders (SDAEs), one fusion layer, and one logistic regression (LR) layer. Initially, the SDAEs at the bottom of MSDAE extract features from multiple kinds of measurements respectively. Then, the extracted features are encoded into unified fusion features by the fusion layer. Finally, the LR layer performs TSA by using the fusion features. The depth of the architecture contributes to the remarkable ability for feature learning, while the width of the architecture (i.e., the multiple branches) enables MSDAE to deal with different kinds of measurements by a reasonable mechanism. In this way, MSDAE achieves feature extraction and classification intrinsically and simultaneously, namely, achieves TSA in an end-to-end manner. The results of experiments on IEEE 50-machine system demonstrate the superiority of the proposed model over the prior methods.","2169-3536","","10.1109/ACCESS.2018.2872796","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8492415","Deep learning;feature extraction;PMU data;stacked denoising autoencoder;transient stability assessment","Feature extraction;Power system stability;Stability analysis;Machine learning;Phasor measurement units;Voltage measurement","feature extraction;learning (artificial intelligence);pattern classification;phasor measurement;power engineering computing;power system transient stability","feature classification;power system secure operation;power system stable operation;unified fusion features;logistic regression layer;fusion layer;multiple stacked denoising autoencoders;unified framework;multibranch stacked denoising autoencoder;error-prone hand-crafting;shallow architectures;favorable accuracy;phasor measurement unit data;artificial intelligence approaches;accurate transient stability assessment;PMU data;deep end-to-end model;feature extraction;MSDAE;multiple branches;feature learning;TSA;LR layer","","26","","55","OAPA","14 Oct 2018","","","IEEE","IEEE Journals"
"An Integrated PCA-DAEGCN Model for Movie Recommendation in the Social Internet of Things","W. Sun; J. Jiang; Y. Huang; J. Li; M. Zhang","School of Media and Communication, Shenzhen University, Shenzhen, China; College of Communication Science and Art, Chengdu University of Technology, Chengdu, China; School of Media and Communication, Shenzhen University, Shenzhen, China; College of Culture and Media, Guiyang University, Guizhou, China; School of Literature and Journalism, Hunan University of Technology and Business, Changsha, China","IEEE Internet of Things Journal","7 Jun 2022","2022","9","12","9410","9418","With the development of the Social Internet of Things (SIoT) and mobile technologies in recent years, movie recommendation systems have become popular in online movie recommendation that users may like to watch based on their historical movie viewing data monitored by the SIoT. This technology can bring considerable profits to online movie providers and has attracted the attention of a large number of related scholars. However, previous movie recommendation models based on autoencoders have insufficient model learning ability due to their defective features. Due to the errors in users’ operation, the user’s movie rating data will have some errors. The previous models cannot deal with this corrupted information, which leads to the degradation of their generalization performance. Presently, graph convolutional networks have made full progress in many fields, and they can outperform traditional methods. Therefore, in this work, we introduce a principal component analysis and denoising autoencoder integrated graph convolutional networks (PCA-DAEGCNs) for movie recommendation in the SIoT. The PCA-DAEGCN model uses the network structure of the graph autoencoder to obtain effective hidden features and, subsequently, uses denoising autoencoders to handle small changes in the feedback information. Finally, the captured hidden features of users and movies are used to derive the finally predicted scores. Comprehensive experiments show that the proposed PCA-DAEGCN is able to obtain far better efficiency than many comparative models.","2327-4662","","10.1109/JIOT.2021.3111614","New Media Innovation Talents Training Base(grant numbers:202002328035); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534871","Autoencoder;graph convolutional network;movie recommendations;principal component analysis;Social Internet of Things (SIoT)","Motion pictures;Feature extraction;Monitoring;Internet of Things;Principal component analysis;Mathematical model;Media","image denoising;learning (artificial intelligence);principal component analysis;recommender systems","integrated PCA-DAEGCN model;Social Internet;SIoT;mobile technologies;movie recommendation systems;online movie recommendation;historical movie viewing data;movie providers;previous movie recommendation models;autoencoders;insufficient model learning ability;users;user;principal component analysis;denoising autoencoder integrated graph convolutional networks;graph autoencoder;comparative models","","","","52","IEEE","10 Sep 2021","","","IEEE","IEEE Journals"
"A Power System Disturbance Classification Method Robust to PMU Data Quality Issues","Z. Li; H. Liu; J. Zhao; T. Bi; Q. Yang","State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, North China Electric Power University, Beijing, China; Department Electrical and Computer Engineering, Mississippi State University, Starkville, MS, USA; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, North China Electric Power University, Beijing, China","IEEE Transactions on Industrial Informatics","5 Oct 2021","2022","18","1","130","142","Data quality issues exist in practical phasor measurement units (PMUs) due to communication errors or signal interferences. As a result, the performances of existing data-driven disturbance classification methods can be significantly affected. In this article, a fast disturbance classification method that is robust to PMU data quality issues is proposed. The impacts of bad PMU measurements on disturbance classification are investigated by analyzing the feature distributions of deep learning methods. A new feature extraction scheme that uses the univariate temporal convolutional denoising autoencoder (UTCN-DAE) is proposed. It allows encoding and decoding univariate disturbance data through a temporal convolutional network to capture the temporal feature representation and is robust to bad data. Based on the features of the frequency and voltage measurements encoded by the UTCN-DAE, a two-stream enhanced network, i.e., the multivariable temporal convolutional denoising network is proposed to achieve optimal feature extraction of multivariate time series by feature fusion. The classification is performed using a multilayered deep neural network and Softmax classifier. Extensive results obtained on the IEEE 39-bus system as well as a large-scale power system in China with field PMU measurements show that the proposed method achieves the highest classification accuracy and computational efficiency as compared to other deep learning algorithms.","1941-0050","","10.1109/TII.2021.3072397","National Natural Science Foundation of China(grant numbers:51627811,51725702); 5G-based wide-area synchronous waveform measurement device, transmission technology research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9400766","Data quality problems;disturbance classification;multivariable temporal convolutional denoising network (MTCDN);phasor measurement units (PMUs);univariate temporal convolutional denoising autoencoder (UTCN-DAE)","Phasor measurement units;Feature extraction;Noise reduction;Convolution;Power systems;Data integrity;Informatics","computerised instrumentation;convolutional neural nets;deep learning (artificial intelligence);feature extraction;phasor measurement;power engineering computing;power system faults;time series","large-scale power system;field PMU measurements;power system disturbance classification method robust;PMU data quality issues;phasor measurement units;PMU measurements;feature distributions;deep learning methods;feature extraction scheme;UTCN-DAE;univariate disturbance data;temporal feature representation;voltage measurements;multivariable temporal convolutional denoising network;optimal feature extraction;feature fusion;multilayered deep neural network;univariate temporal convolutional denoising autoencoder network;fast data-driven disturbance classification methods;China;Softmax classifier;IEEE 39-bus system","","","","35","IEEE","12 Apr 2021","","","IEEE","IEEE Journals"
"Robust sound event classification by using denoising autoencoder","J. Zhou; L. Peng; X. Chen; D. Yang","Institute of Computer Science & Technology, Peking University, Haidian District Beijing, P. R. China; Institute of Computer Science & Technology, Peking University, Haidian District Beijing, P. R. China; Institute of Computer Science & Technology, Peking University, Haidian District Beijing, P. R. China; Institute of Computer Science & Technology, Peking University, Haidian District Beijing, P. R. China","2016 IEEE 18th International Workshop on Multimedia Signal Processing (MMSP)","16 Jan 2017","2016","","","1","6","Over the last decade, a lot of research has been done on sound event classification. But a main problem with sound event classification is that the performance sharply degrades in the presence of noise. As spectrogram-based image features and denoising auto encoder reportedly have superior performance in noisy conditions, this paper proposes a new robust feature called denoising auto encoder image feature (DIF) for sound event classification which is an image feature extracted from an image-like representation produced by denoising auto encoder. Performance of the feature is evaluated by a classification experiment using a SVM classifier on audio examples with different noise levels, and compared with that of baseline features including mel-frequency cepstral coefficients (MFCC) and spectrogram image feature. The proposed DIF demonstrates better performance under noise-corrupted conditions.","2473-3628","978-1-5090-3724-7","10.1109/MMSP.2016.7813376","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7813376","","Feature extraction;Noise reduction;Spectrogram;Mel frequency cepstral coefficient;Robustness;Noise measurement;Image reconstruction","feature extraction;image classification;image coding;image denoising;support vector machines","sound event classification;spectrogram-based image features;denoising auto encoder image feature;DIF;image-like representation;SVM classifier;mel-frequency cepstral coefficients;MFCC;spectrogram image feature","","2","","23","","16 Jan 2017","","","IEEE","IEEE Conferences"
"An ensemble detection method for shilling attacks based on features of automatic extraction","Y. Hao; F. Zhang; J. Chao","Yanshan University, Qinhuangdao, Hebei, CN; Yanshan University, Qinhuangdao, Hebei, CN; Yanshan University, Qinhuangdao, Hebei, CN","China Communications","30 Aug 2019","2019","16","8","130","146","Faced with the evolving attacks in recommender systems, many detection features have been proposed by human engineering and used in supervised or unsupervised detection methods. However, the detection features extracted by human engineering are usually aimed at some specific types of attacks. To further detect other new types of attacks, the traditional methods have to re-extract detection features with high knowledge cost. To address these limitations, the method for automatic extraction of robust features is proposed and then an Adaboost-based detection method is presented. Firstly, to obtain robust representation with prior knowledge, unlike uniform corruption rate in traditional mLDA (marginalized Linear Denoising Autoencoder), different corruption rates for items are calculated according to the ratings' distribution. Secondly, the ratings sparsity is used to weight the mapping matrix to extract low-dimensional representation. Moreover, the uniform corruption rate is also set to the next layer in mSLDA (marginalized Stacked Linear Denoising Autoencoder) to extract the stable and robust user features. Finally, under the robust feature space, an Adaboost-based detection method is proposed to alleviate the imbalanced classification problem. Experimental results on the Netflix and Amazon review datasets indicate that the proposed method can effectively detect various attacks.","1673-5447","","10.23919/JCC.2019.08.012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820766","shilling attack;ensemble detection;features of automatic extraction;marginalized linear denoising autoencoder","Feature extraction;Noise reduction;Classification algorithms;Data mining;Recommender systems;Ergonomics;Computational modeling","feature extraction;image classification;image denoising;image representation;learning (artificial intelligence)","robust feature space;robust user features;uniform corruption rate;Adaboost-based detection method;unsupervised detection methods;supervised detection methods;human engineering;detection features;evolving attacks;automatic extraction;ensemble detection method","","1","","","","30 Aug 2019","","","IEEE","IEEE Magazines"
"A sparse autoencoder based denosing the spectrum signal in LIBS","S. Ye; Z. Niu; P. Yang; J. Sun","Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Tianjin University of Technology, Tianjin; Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Tianjin University of Technology, Tianjin; Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Tianjin University of Technology, Tianjin; Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Tianjin University of Technology, Tianjin","2018 Chinese Control And Decision Conference (CCDC)","9 Jul 2018","2018","","","3572","3577","Based on laser induced breakdown spectroscopy (LIBS) technique, the content of the main elements in the liquid steel of carbon steel alloy can be detected in real time during melting process. In order to detect the liquid alloy steel and forecast the content of the main elements in the alloy steel more accurately, we use the method of sparse autoencoder to reduce noise in the spectral data which were collected in the detecting process. The experimental results show that the sparse autoencoder method can effectively improve the accuracy and precision of the spectral data.","1948-9447","978-1-5386-1244-6","10.1109/CCDC.2018.8407742","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8407742","LIBS;sparse autoencoder;spectral data;denosing","Surface emitting lasers;Steel;Spectroscopy;Plasmas;Free electron lasers;Electric breakdown","alloy steel;carbon steel;laser beam effects;liquid alloys;melting;metallurgical industries;neural nets;precision engineering;real-time systems;signal denoising","laser induced breakdown spectroscopy technique;carbon steel alloy;melting process;liquid alloy steel;spectral data;sparse autoencoder method;spectrum signal denoising;real time detecting process;precision engineering","","","","13","","9 Jul 2018","","","IEEE","IEEE Conferences"
"Binary codes for tagging x-ray images via deep de-noising autoencoders","A. Sze-To; H. R. Tizhoosh; A. K. C. Wong","Systems Design Engineering, University of Waterloo, Waterloo, Ontario, Canada; KIMIA Lab, University of Waterloo, Waterloo, Ontario, Canada; Systems Design Engineering, University of Waterloo, Waterloo, Ontario, Canada","2016 International Joint Conference on Neural Networks (IJCNN)","3 Nov 2016","2016","","","2864","2871","A Content-Based Image Retrieval (CBIR) system which identifies similar medical images based on a query image can assist clinicians for more accurate diagnosis. The recent CBIR research trend favors the construction and use of binary codes to represent images. Deep architectures could learn the non-linear relationship among image pixels adaptively, allowing the automatic learning of high-level features from raw pixels. However, most of them require class labels, which are expensive to obtain, particularly for medical images. The methods which do not need class labels utilize a deep autoencoder for binary hashing, but the code construction involves a specific training algorithm and an ad-hoc regularization technique. In this study, we explored using a deep de-noising autoencoder (DDA), with a new unsupervised training scheme using only backpropagation and dropout, to hash images into binary codes. We conducted experiments on more than 14,000 x-ray images. By using class labels only for evaluating the retrieval results, we constructed a 16-bit DDA and a 512-bit DDA independently. Comparing to other unsupervised methods, we succeeded to obtain the lowest total error by using the 512-bit codes for retrieval via exhaustive search, and speed up 9.27 times with the use of the 16-bit codes while keeping a comparable total error. We found that our new training scheme could reduce the total retrieval error significantly by 21.9%. To further boost the image retrieval performance, we developed Radon Autoencoder Barcode (RABC) which are learned from the Radon projections of images using a de-noising autoencoder. Experimental results demonstrated its superior performance in retrieval when it was combined with DDA binary codes.","2161-4407","978-1-5090-0620-5","10.1109/IJCNN.2016.7727561","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727561","","Binary codes;Training;Noise reduction;X-ray imaging;Image retrieval;Medical diagnostic imaging","backpropagation;binary codes;content-based retrieval;feature extraction;image coding;image denoising;image matching;image representation;image retrieval;medical image processing;Radon transforms;unsupervised learning;X-ray imaging","X-ray image tagging;deep denoising autoencoders;content-based image retrieval system;CBIR system;medical images;query image;deep architectures;image pixels;automatic learning;high-level features;raw pixels;binary hashing;ad-hoc regularization;unsupervised training scheme;backpropagation;dropout;total retrieval error;Radon autoencoder barcode;RABC;Radon projections;DDA binary codes;word length 512 bit;word length 16 bit","","8","","42","","3 Nov 2016","","","IEEE","IEEE Conferences"
"Stacked sparse autoencoder based fault detection and location method for modular five-level converters","Q. Yin; B. Duan; M. Shen; X. Qu","College of Information Engineering, Xiangtan University, Xiangtan, China; College of Information Engineering, Xiangtan University, Xiangtan, China; Collaborative Innovation Center of Wind Power Equipment and Energy Conversion, Xiangtan, China; Collaborative Innovation Center of Wind Power Equipment and Energy Conversion, Xiangtan, China","IECON 2017 - 43rd Annual Conference of the IEEE Industrial Electronics Society","18 Dec 2017","2017","","","1580","1585","This paper presents a novel method for fault detection and location in modular five-level converters (MFLC) based on stacked sparse autoencoder (SSAE). SSAE is composed of multiple SAE and a softmax classifier. The capacitor voltage signals of all sub-modules (SMs) in the MFLC circuit are combined into a multi-channel signal. By moving window along the multi-channel signal, a set of signal segments are acquired. Then these segments are flattened into vectors and used as SSAE model's input. The SAE can unsupervised learn features from the input data and the fault detection and location problem is converted into a classification problem. In order to improve the anti-noise performance of the proposed method, the stacked denoising SAE (SDSAE) is implemented. Results show that the proposed method can quickly and accurately detect and locate the faulty SM. Comparison with existing methods shows that the proposed method has higher robustness and generalization ability, and is practical for online MFLC protection.","","978-1-5386-1127-2","10.1109/IECON.2017.8216268","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8216268","Stacked Sparse Autoencoder (SSAE);Fault Detection and Location;Modular Five-Level Converters (MFLC);Unsupervised feature learning","Fault detection;Feature extraction;Training;Capacitors;Bridge circuits;Data models;Image reconstruction","encoding;fault location;signal classification;signal denoising;unsupervised learning;voltage-source convertors","five-level converters;multiple SAE;capacitor voltage signals;MFLC circuit;multichannel signal;signal segments;SSAE model;location problem;stacked denoising SAE;stacked sparse autoencoder based fault detection and location method;softmax classifier;classification problem;anti-noise performance","","","","30","","18 Dec 2017","","","IEEE","IEEE Conferences"
"A clustering-based deep autoencoder for one-class image classification","M. Gutoski; M. Ribeiro; N. M. Romero Aquino; A. E. Lazzaretti; H. S. Lopes","Graduate Program in Electrical and Computer Engineering, Federal University of Technology - Parana (UTFPR), Curitiba, PR, Brazil; Catarinense Federal Institute of Education, Science and Technology - (IFC), Videira, SC, Brazil; Grad. Program in Electr. & Comput. Eng., Fed. Univ. of Technol.-Parana, Curitiba, Brazil; Graduate Program in Electrical and Computer Engineering, Federal University of Technology - Parana (UTFPR), Curitiba, PR, Brazil; Graduate Program in Electrical and Computer Engineering, Federal University of Technology - Parana (UTFPR), Curitiba, PR, Brazil","2017 IEEE Latin American Conference on Computational Intelligence (LA-CCI)","8 Feb 2018","2017","","","1","6","Anomaly detection in images is a topic of great interest in Computer Vision. It can be defined as an One-Class problem, where the goal is to detect deviations from known patterns, which are defined as normal. Recently, Deep Learning methods became popular due to their performance on classification tasks. This works presents an image anomaly detection classifier based on a previously known method, the Deep Embedded Clustering, which is based on a Deep Autoencoder. We show the effectiveness of the method through three different experiments. Results suggest that the method improves classification performance when compared to a Stacked Denoising Autoencoder in the image anomaly detection context.","","978-1-5386-3734-0","10.1109/LA-CCI.2017.8285680","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8285680","","Training;Noise reduction;Optimization;Feature extraction;Decoding;Machine learning;Anomaly detection","computer vision;image classification;image denoising;learning (artificial intelligence);neural nets;pattern clustering","clustering-based deep autoencoder;deviation detection;deep learning methods;Stacked Denoising Autoencoder;classification performance;Deep Embedded Clustering;image anomaly detection classifier;classification tasks;One-Class problem;Computer Vision;one-class image classification","","10","","28","","8 Feb 2018","","","IEEE","IEEE Conferences"
"Denoising Autoencoders for Laser-Based Scan Registration","A. Nicolai; G. A. Hollinger","Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, OR, USA","IEEE Robotics and Automation Letters","14 Sep 2018","2018","3","4","4391","4398","In this letter, we build on recent advances in deep learning to improve SE(3) transformations, enabling more accurate motion estimation in mobile robots. We propose using denoising autoencoders (DAEs) to address the challenges presented by modern LIDARs. Our proposed approach is comprised of two stages: a novel pre-processing stage for robust feature identification and a scan matching stage for motion estimation. In the pre-processing stage, LIDAR data are projected into a two-dimensional (2-D) image format and a DAE is used to extract salient features. These features are used as a mask for the original data, which is then re-projected into full 3-D space. Scan matching is performed on the re-projected data to estimate motion in SE(3). We analyze the performance of our approach using the real-world data from the University of Michigan North Campus long-term vision and LIDAR dataset and test generalization on LIDAR data from the KITTI dataset. We show that our approach generalizes across domains, is capable of reducing the per-estimate error of standard iterative closest point (ICP) methods on average by 25.5% for the translational component and 57.53% for the rotational component, and is capable of reducing the computation time of state-of-the-art ICP methods by a factor of 7.94 on average while achieving competitive performance.","2377-3766","","10.1109/LRA.2018.2867856","National Aeronautics and Space Administration(grant numbers:NNX14AI10G); DWFritz Automation; Oregon Metals Initiative; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8451962","Autonomous vehicle navigation;learning and adaptive systems;localization","Feature extraction;Three-dimensional displays;Laser radar;Iterative closest point algorithm;Robustness;Standards;Machine learning","feature extraction;image denoising;image matching;image registration;iterative methods;learning (artificial intelligence);mobile robots;motion estimation;optical radar;pose estimation;robot vision","test generalization;LIDAR data;KITTI dataset;per-estimate error;standard iterative closest point methods;competitive performance;autoencoders;laser-based scan registration;deep learning;mobile robots;DAE;robust feature identification;scan matching stage;image format;salient features;University of Michigan North Campus long-term vision;preprocessing stage;motion estimation","","1","","37","IEEE","30 Aug 2018","","","IEEE","IEEE Journals"
"Network Anomaly Detection with Stochastically Improved Autoencoder Based Models","R. C. Aygun; A. G. Yavuz","Computer Engineering Department Yildiz Technical University Istanbul, Turkey; Computer Engineering Department Yildiz Technical University Istanbul, Turkey","2017 IEEE 4th International Conference on Cyber Security and Cloud Computing (CSCloud)","24 Jul 2017","2017","","","193","198","Intrusion detection systems do not perform well when it comes to detecting zero-day attacks, therefore improving their performance in that regard is an active research topic. In this study, to detect zero-day attacks with high accuracy, we proposed two deep learning based anomaly detection models using autoencoder and denoising autoencoder respectively. The key factor that directly affects the accuracy of the proposed models is the threshold value which was determined using a stochastic approach rather than the approaches available in the current literature. The proposed models were tested using the KDDTest+ dataset contained in NSL-KDD, and we achieved an accuracy of 88.28% and 88.65% respectively. The obtained results show that, as a singular model, our proposed anomaly detection models outperform any other singular anomaly detection methods and they perform almost the same as the newly suggested hybrid anomaly detection models.","","978-1-5090-6644-5","10.1109/CSCloud.2017.39","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7987197","autoencoder;deep learning;anomaly detection;network security;intrusion detection systems","Training;Data models;Stochastic processes;Computational modeling;Intrusion detection;Noise reduction","learning (artificial intelligence);security of data;stochastic processes","network anomaly detection;stochastically improved autoencoder;intrusion detection systems;zero day attacks;two deep learning;anomaly detection models;denoising autoencoder;stochastic approach;KDDTest+ dataset;singular anomaly detection methods","","56","","23","","24 Jul 2017","","","IEEE","IEEE Conferences"
"Robust Precipitation Bias Correction Through an Ordinal Distribution Autoencoder","Y. Luo; X. Xu; Y. Liu; H. Chao; H. Chu; L. Chen; J. Zhang; L. Ma; J. Z. Wang","Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China; Shanghai Central Meteorological Observatory, Shanghai, China; Shanghai Central Meteorological Observatory, Shanghai, China; Fudan University, Shanghai, China; Shanghai Central Meteorological Observatory, Shanghai, China; The Pennsylvania State University, University Park, PA, USA","IEEE Intelligent Systems","12 Apr 2022","2022","37","1","60","70","Numerical precipitation prediction plays a crucial role in weather forecasting and has broad applications in public services including aviation management and urban disaster early-warning systems. However, numerical weather prediction (NWP) models are often constrained by a systematic bias due to coarse spatial resolution, lack of parameterizations, and limitations of observation and conventional meteorological models, including constrained sample size and long-tail distribution. To address these issues, we present a data-driven deep learning model, named the ordinal distribution autoencoder (ODA), which principally includes a precipitation confidence network and a combinatorial network that contains two blocks, i.e., a denoising autoencoder block and an ordinal distribution regression block. As an expert-free model for bias correction of precipitation, it can effectively correct numerical precipitation prediction based on meteorological data from the European Centre for Medium-Range Weather Forecasts (ECMWF) and SMS-WARMS, an NWP model used in East China. Experiments in the two NWP models demonstrate that, compared with several classical machine-learning algorithms and deep learning models, our proposed ODA generally performs better in bias correction.","1941-1294","","10.1109/MIS.2021.3088543","Shanghai Municipal Science and Technology(grant numbers:18DZ1200404); Shanghai Municipal Science and Technology(grant numbers:2018SHZDZX01); ZJLab; Pennsylvania State University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9453192","Precipitation bias correction;ordinal distribution autoencoder;weather prediction;deep learning","Predictive models;Numerical models;Weather forecasting;Noise reduction;Task analysis;Deep learning;Data models","atmospheric precipitation;deep learning (artificial intelligence);disasters;geophysics computing;meteorology;regression analysis;weather forecasting","robust precipitation bias correction;ordinal distribution autoencoder;numerical precipitation prediction;weather forecasting;urban disaster early-warning systems;numerical weather prediction;long-tail distribution;data-driven deep learning model;denoising autoencoder block;ordinal distribution regression block;expert-free model;meteorological data;medium-range weather forecasts","","","","20","IEEE","11 Jun 2021","","","IEEE","IEEE Magazines"
"Stability Analysis of Denoising Autoencoders Based on Dynamical Projection System","S. Park; J. Lee","Department of Convergence Security Engineering, Sungshin Women's University, Seoul, Korea; Department of Industrial Engineering, Seoul National University, Seoul, Korea","IEEE Transactions on Knowledge and Data Engineering","8 Jul 2021","2021","33","8","3155","3159","In this study, we give a stability analysis of denoising autoencoder(DAE) from the novel perspective of dynamical systems when the input density is defined as a distribution on a manifold. We demonstrate the connection between the corrupted distribution and the learned reconstruction function of a nonlinear DAE, which motivates the use of a dynamic projection system (DPS) associated with the learned reconstruction function. Utilizing the constructed DPS, we prove that the high-density region of the corrupted data distribution asymptotically converges to the data manifold. Then, we show that the region is the attracting stable equilibrium manifold of the DPS which is completely stable. These results serve a theoretical basis of the DAE in recognizing the high-density region of the highly corrupted data with large deviations through the DPS. The effectiveness of this analysis is verified by conducting experiments on several toy examples and real image datasets with various types of noise.","1558-2191","","10.1109/TKDE.2020.3010277","National Research Foundation of Korea(grant numbers:2018R1D1A1A02085851); National Research Foundation of Korea(grant numbers:NRF-2019R1A2C2002358); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144448","Nonlinear projection;autoencoders;stability analysis;dynamical systems;data manifold","Manifolds;Stability analysis;Data models;Image reconstruction;Noise reduction;Noise measurement;Perturbation methods","data handling;learning (artificial intelligence);neural nets;nonlinear dynamical systems","stability analysis;autoencoders;dynamical projection system;learned reconstruction function;nonlinear DAE;corrupted data distribution;data manifold","","","","22","IEEE","20 Jul 2020","","","IEEE","IEEE Journals"
"Visual object tracking via deep neural network","T. Xu; X. Wu","School of IoT Engineering, Jiangnan University, Wuxi, China; School of IoT Engineering, Jiangnan University, Wuxi, China","2015 IEEE First International Smart Cities Conference (ISC2)","28 Dec 2015","2015","","","1","6","Visual tracking is a fundamental research problem in computer vision field. In this paper, we propose an approach to incorporate visual prior into visual object tracking via deep neural network. Visual prior knowledge is expressed as the parameters of a stacked denoising autoencoder, which is trained from a large collection of natural images. By utilizing natural images, we can obtain generic image features which are more robust against variations. Then we design a classifier for tracking using the same structure as the stacked denoising autoencoder, tracking is then carried out under a particle filter framework by determining the current target's location and updating the parameters. In addition, in order to alleviate the computational burden caused by deep structure, an adaptive updating mechanism is proposed. As a result, we apply a general-to-special strategy for our stacked denoising autoencoder tracker (SDAT), the learned visual prior provides a reasonable initial value for parameters of the neural network, and the deep structure of our tracker is robust to appearance variations. Experiments over 50 challenging videos indicate the effectiveness and robustness of our tracker, and the resulting tracker is outstanding especially against variations with the existing state-of-the-art methods.","","978-1-4673-6552-9","10.1109/ISC2.2015.7366162","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7366162","Object tracking;visual prior;stacked denoising autoencoder","Target tracking;Visualization;Noise reduction;Robustness;Training;Neural networks","image denoising;neural nets;object tracking;particle filtering (numerical methods)","computer vision field;visual object tracking;deep neural network;visual prior knowledge;natural images;generic image features;classifier;particle filter framework;adaptive updating mechanism;stacked denoising autoencoder tracker;SDAT","","1","","27","","28 Dec 2015","","","IEEE","IEEE Conferences"
"Computational Framework for Machine Fault Diagnosis with Autoencoder Variants","N. K. Verma; S. Dixit; R. K. Sevakula; A. Salour","Department of Electrical Engineering, Indian Institute of Technology, Kanpur, India; Department of Electrical Engineering, Indian Institute of Technology, Kanpur, India; Cognitive Computing, IBM, India; Boeing Research & Technology, The Boeing Company, U.S.A.","2018 International Conference on Sensing,Diagnostics, Prognostics, and Control (SDPC)","14 Mar 2019","2018","","","353","358","Fault diagnosis is an integral component of Condition Monitoring systems used in industries. Deep learning techniques have recently been proven to be very effective in handling heterogeneous real time monitoring data. This paper presents a computational framework for machine fault diagnosis based on deep learning approaches and autoencoder variants. The framework includes methods for extraction of time domain and frequency domain features from raw data, training of autoencoders, and finally, detecting the presence of fault(s) using classifiers. A total of four different variants of autoencoders have been tested and analyzed for fault diagnosis framework; additionally, the option of reducing the learning complexity in autoencoder with layer wise feature selection strategy with ITER ranking has also been applied. For validation purpose, four standard fault diagnosis datasets were used. To obtain inferences, statistical tests was performed across all tested feature extraction techniques, autoencoder variants, and classifiers. The analysis suggests that stacked denoising sparse encoder in conjunction with frequency domain features and support vector classifiers gives consistent classification accuracy thus builds effective fault diagnosis system.","","978-1-5386-6057-7","10.1109/SDPC.2018.8664980","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8664980","condition based monitoring;deep learning;feature extraction;feature selection;stacked sparse autoencoder;denoising constraints","Feature extraction;Fault diagnosis;Training;Deep learning;Time-frequency analysis;Vibrations;Noise reduction","condition monitoring;data analysis;fault diagnosis;feature extraction;feature selection;frequency-domain analysis;learning (artificial intelligence);machinery;mechanical engineering computing;pattern classification;support vector machines;time-domain analysis","deep learning techniques;computational framework;machine fault diagnosis;autoencoder variants;frequency domain features;fault diagnosis framework;learning complexity;support vector classifiers;condition monitoring systems;feature selection strategy;time domain features","","4","","47","","14 Mar 2019","","","IEEE","IEEE Conferences"
"Motion Artifact Removal for Bio Signals using Regularized Autoencoder","D. Evangelin; P. Ithayarani; J. N. S. Jebastin","Department of Computer Science and Engineering, Sethu Institute of Technology, Kariapatti, India; Department of Computer Science and Engineering, Sethu Institute of Technology, Kariapatti, India; Department of Bioinformatics, Annamalai University, Chidambaram, India","2019 Third International conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)","12 Mar 2020","2019","","","496","500","The advancements in wireless communication technology and micro electro mechanical system (MEMS) based sensor technology led to the rise of body area communication in healthcare field. The bio signals acquired through this on-body communication mainly suffers from motion artifacts caused by shadowing due to the body shape and body movement. These noises may lead to wrong prediction on data. Therefore, it is important to consider denoising the bio signals in order to perform accurate diagnosis and analysis. This paper proposes regularized denoising autoencoder (DAE) to reconstruct the clean signal from its noisy form. Here two regularization terms L1 and L2 which updates the cost function to avoid over fitting problem. This paper proves that L1 is better than L2 in terms of recovering the signal quality and it is measured by Signal to Noise Ratio (SNR). The dataset used here are taken from a neurokit a python tool box for statistics and neurophysiological signal processing.","","978-1-7281-4365-1","10.1109/I-SMAC47947.2019.9032625","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9032625","MEMS;body area communication;DAE;bio signals;artifact","Signal to noise ratio;Electrocardiography;Wireless communication;Noise reduction;Noise measurement;Cost function;Wireless sensor networks","health care;medical signal processing;neural nets;neurophysiology;signal denoising;signal reconstruction","denoising autoencoder;healthcare field;biosignals denoising;regularization terms;signal reconstruction;body area communication;motion artifact removal;neurophysiological signal processing;signal quality","","","","30","","12 Mar 2020","","","IEEE","IEEE Conferences"
"A New Framework to Train Autoencoders Through Non-Smooth Regularization","S. Amini; S. Ghaemmaghami","Department of Electrical Engineering and the Electrical Research Institute, Sharif University of Technology, Tehran, Iran; Department of Electrical Engineering and the Electrical Research Institute, Sharif University of Technology, Tehran, Iran","IEEE Transactions on Signal Processing","1 Mar 2019","2019","67","7","1860","1874","Deep structures consisting of many layers of nonlinearities have a high potential of expressing complex relations if properly initialized. Autoencoders play a complementary role in training a deep structure by initializing each layer in a greedy unsupervised manner. Due to the high capacity presented by autoencoders, these structures need to be regularized. While mathematical regularizers (based on weight decay, sparsity, etc.) and structural ones (by way of, e.g., denoising and dropout) have been well studied in the literature, quite a few papers have addressed the problem of training autoencoder with non-smooth regularization. In this paper, we address the problem of training autoencoder with non-smooth regularization. We propose an efficient algorithm and mathematically prove that it is convergent, where the regularizer needs to be proximable. As one of major applications of the proposed method, we get focused on the problem of sparse autoencoders and show that the new training method leads to better disentangling of factors of variation.","1941-0476","","10.1109/TSP.2019.2899294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642441","Autoencoder;regularizer;gradient descent;proximal operator","Training;Convergence;Decoding;Signal processing algorithms;Neural networks;Encoding;Feature extraction","neural nets;unsupervised learning","train autoencoders;nonsmooth regularization;deep structure;mathematical regularizers;training autoencoder;sparse autoencoders;training method","","6","","68","IEEE","14 Feb 2019","","","IEEE","IEEE Journals"
"A Deep Learning Approach Based on Stacked Denoising Autoencoders for Protein Function Prediction","L. J. Miranda; J. Hu","Graduate School of Information, Production, and Systems, Waseda University, Fukuoka, Japan; Graduate School of Information, Production, and Systems, Waseda University, Fukuoka, Japan","2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)","22 Jun 2018","2018","01","","480","485","Predicting protein functions is a fundamental task with applications in medicine and healthcare. However, the accelerating pace of protein-discovery renders slow and expensive biochemical techniques unsustainable. Machine learning is suitable for such data-intensive task, but the presence of noise in protein datasets adds another level of difficulty. Hence, we propose a deep learning system based on a stacked denoising autoencoder that extracts robust features to improve predictive performance. We then feed the resulting features to a multilabel support-vector machine for classification. We evaluated on two protein benchmarks, and experimental results show that our system consistently produced the best performance against techniques that do not have a denoising or feature learning capability. This research demonstrates that learning robust representations from raw data can benefit the process of predicting protein functions.","0730-3157","978-1-5386-2667-2","10.1109/COMPSAC.2018.00074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8377699","bioinformatics;medical computing;artificial intelligence;multi-label classification;feature extraction;machine learning","Conferences;Software","bioinformatics;feature extraction;health care;learning (artificial intelligence);medical computing;pattern classification;proteins;support vector machines","stacked denoising autoencoder;multilabel support-vector machine;protein function prediction;medicine;healthcare;machine learning;deep learning system;feature extraction","","6","","12","","22 Jun 2018","","","IEEE","IEEE Conferences"
"REDAEP: Robust and Enhanced Denoising Autoencoding Prior for Sparse-View CT Reconstruction","F. Zhang; M. Zhang; B. Qin; Y. Zhang; Z. Xu; D. Liang; Q. Liu","Department of Electronic Information Engineering, Nanchang University, Nanchang, China; Department of Electronic Information Engineering, Nanchang University, Nanchang, China; School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; College of Computer Science, Sichuan University, Chengdu, China; Department of Electronic Information Engineering, Nanchang University, Nanchang, China; Research Center for Biomedical Imaging, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Department of Electronic Information Engineering, Nanchang University, Nanchang, China","IEEE Transactions on Radiation and Plasma Medical Sciences","30 Dec 2020","2021","5","1","108","119","In X-ray computed tomography, radiation doses are harmful but can be significantly reduced by intuitively decreasing the number of projections. However, less projection views usually lead to low-resolution images. To address this issue, we propose a robust and enhanced mechanism on the basis of denoising autoencoding prior, or robust EDAEP (REDAEP) for sparse-view computed tomography reconstruction. REDAEP can substantially improve the reconstruction quality with two novel contributions. First, by employing the variable augmentation technique, REDAEP learns higher-dimensional network with three-channel image and proceeds to the single-channel image reconstruction. Second, REDAEP replaces the L2 regression loss function with a more robust Lp (0 <; p <; 2) regression to preserve more texture details. The empirical results demonstrate that REDAEP can achieve better performance than state-of-the-arts, in terms of quantitative measures and subjective visual quality.","2469-7303","","10.1109/TRPMS.2020.2989634","National Natural Science Foundation of China(grant numbers:61871206,61661031,61671312); Basic Research Program of Shenzhen(grant numbers:JCYJ20150831154213680); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9076295","Computed tomography (CT) reconstruction;denoising autoencoder (AE) network;multichannel;proximal gradient descent;sparse-view;variable augmentation","Image reconstruction;Computed tomography;X-ray imaging;Biomedical imaging;Noise reduction;Training;Convolution","computerised tomography;image denoising;image reconstruction;image resolution;learning (artificial intelligence);medical image processing;regression analysis","REDAEP;enhanced denoising autoencoding;sparse-view CT reconstruction;X-ray computed tomography;radiation doses;low-resolution images;robust EDAEP;sparse-view computed tomography reconstruction;three-channel image;single-channel image reconstruction","","4","","62","IEEE","22 Apr 2020","","","IEEE","IEEE Journals"
"Denoising auto-associative measurement screening and repairing","J. Krstulović; V. Miranda","FESB, University of Split, Croatia; FESB, University of Split, Croatia","2015 18th International Conference on Intelligent System Application to Power Systems (ISAP)","12 Nov 2015","2015","","","1","6","This paper offers an efficient and robust concept for a decentralized bad data processing, able to supply in real-time a power system state estimator with a repaired measurement set. Corrupted measurement vectors are funneled through a denoising auto-associative neural network in order to project the biased vector back to the data manifold learned during an offline training process. In order to improve accuracy, a maximum similarity with the solution manifold, measured with Correntropy, is searched for by a meta-heuristic. The extreme robustness and scalability of the process is demonstrated in multiple characteristic case studies.","","978-1-5090-0191-0","10.1109/ISAP.2015.7325548","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325548","Gross Errors;State Estimation;Autoencoders;Neural Networks;Denoising;Information Theoretic Learning","Pollution measurement;Noise reduction;Measurement uncertainty;Manifolds;Training;Robustness;Power measurement","associative processing;neural nets;power engineering computing;power system measurement;signal denoising","autoassociative measurement screening;decentralized bad data processing;power system state estimation;signal denoising","","1","","16","","12 Nov 2015","","","IEEE","IEEE Conferences"
"Perception-Aware Losses Facilitate CT Denoising and Artifact Removal","S. Ghosh; A. Krug; G. Rose; S. Stober","Institute for Medical Engineering and Research Campus STIMULATE, Otto-von-Guericke University, Magdeburg, Germany; AILab, Faculty of Computer Science, Otto-von-Guericke University, Magdeburg, Germany; AILab, Faculty of Computer Science, Otto-von-Guericke University, Magdeburg, Germany; AILab, Faculty of Computer Science, Otto-von-Guericke University, Magdeburg, Germany","2021 IEEE 2nd International Conference on Human-Machine Systems (ICHMS)","27 Oct 2021","2021","","","1","6","The concerns over radiation-related health risks associated with the increasing use of computed tomography (CT) have accelerated the development of low-dose strategies. There is a higher need for low dosage in interventional applications as repeated scanning is performed. However, using the noisier and under-sampled low-dose datasets, the standard reconstruction algorithms produce low-resolution images with severe streaking artifacts. This adversely affects the CT assisted interventions. Recently, variational autoencoders (VAEs) have achieved state of-the-art results for the reconstruction of high fidelity images. The existing VAE approaches typically use mean squared error (MSE) as the loss, because it is convex and differentiable. However, pixel wise MSE does not capture the perceptual quality difference between the target and model predictions. In this work, we propose two simple but effective MSE based perception aware losses, which facilitate a better reconstruction quality. The proposed losses are motivated by perceptual fidelity measures used in image quality assessment. One of the losses involves calculation of the MSE in the spectral domain. The other involves calculation of the MSE in the pixel space and the Laplacian of Gaussian transformed domain. We use a hierarchical vector-quantized VAE equipped with the perception-aware losses for the artifact removal task. The best performing perception-aware loss improves the structural similarity index measure (SSIM) from 0.74 to 0.80. Further, we provide an analysis of the role of the pertinent components of the architecture in the denoising and artifact removal task.","","978-1-6654-0170-8","10.1109/ICHMS53169.2021.9582444","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582444","computed tomography;perception-aware;image reconstruction;deep learning;denoising;artifact removal","Computed tomography;Noise reduction;Computer architecture;Reconstruction algorithms;Predictive models;Loss measurement;Task analysis","computerised tomography;image denoising;image reconstruction;image resolution;mean square error methods;medical image processing;phantoms;tomography","existing VAE approaches;mean squared error;pixel wise MSE;perceptual quality difference;model predictions;simple but effective MSE;perception aware losses;reconstruction quality;perceptual fidelity measures;image quality assessment;hierarchical vector-quantized VAE;high fidelity images;state of-the-art results;VAEs;variational autoencoders;severe streaking artifacts;low-resolution images;standard reconstruction algorithms;low-dose datasets;repeated scanning;interventional applications;low dosage;low-dose strategies;computed tomography;radiation-related health risks;perception-aware losses facilitate CT denoising;performing perception-aware loss;artifact removal task","","1","","44","","27 Oct 2021","","","IEEE","IEEE Conferences"
"Multi-Channel and Multi-Model-Based Autoencoding Prior for Grayscale Image Restoration","S. Li; B. Qin; J. Xiao; Q. Liu; Y. Wang; D. Liang","Department of Electronic Information Engineering, Nanchang University, Nanchang, China; School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Computer Science, Wuhan University, Wuhan, China; Department of Electronic Information Engineering, Nanchang University, Nanchang, China; Department of Electronic Information Engineering, Nanchang University, Nanchang, China; Paul C. Lauterbur Research Center for Biomedical Imaging, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China","IEEE Transactions on Image Processing","12 Sep 2019","2020","29","","142","156","Image restoration (IR) is a long-standing challenging problem in low-level image processing. It is of utmost importance to learn good image priors for pursuing visually pleasing results. In this paper, we develop a multi-channel and multi-model-based denoising autoencoder network as image prior for solving IR problem. Specifically, the network that trained on RGB-channel images is used to construct a prior at first, and then the learned prior is incorporated into single-channel grayscale IR tasks. To achieve the goal, we employ the auxiliary variable technique to integrate the higher-dimensional network-driven prior information into the iterative restoration procedure. In addition, according to the weighted aggregation idea, a multi-model strategy is put forward to enhance the network stability that favors to avoid getting trapped in local optima. Extensive experiments on image deblurring and deblocking tasks show that the proposed algorithm is efficient, robust, and yields state-of-the-art restoration quality on grayscale images.","1941-0042","","10.1109/TIP.2019.2931240","National Natural Science Foundation of China(grant numbers:61871206,61661031); Project of Innovative Special Funds for Graduate Students in Jiangxi Province(grant numbers:YC2017-S108); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8782831","Grayscale image restoration;denoising autoencoder network;channel prior;auxiliary variable technique;multi-model;proximal gradient descent","Image restoration;Gray-scale;Task analysis;Noise reduction;Image denoising;Training;Minimization","image colour analysis;image denoising;image restoration;iterative methods;learning (artificial intelligence)","autoencoder network;IR problem;RGB-channel images;single-channel grayscale IR tasks;higher-dimensional network-driven prior information;iterative restoration procedure;multimodel strategy;network stability;image deblurring;deblocking tasks;grayscale images;grayscale image restoration;low-level image processing;restoration quality;image priors;multichannel multimodel-based autoencoding prior","","17","","52","IEEE","31 Jul 2019","","","IEEE","IEEE Journals"
"Radar Emitter Signal Recognition based on Contour Lines of Ambiguity Function and Stacked Denoising Auto-encoders","Y. Pu; J. Guo; T. Liu; H. Wu","Computing Center, Kunming University of Science and Technology, Kunming, China; Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Kunming, China; Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Kunming, China; Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Kunming, China","2021 IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)","19 Jul 2021","2021","4","","1048","1053","Aiming at many problems of complex radar emitter signal recognition methods, like poor anti-noise performance and low recognition rate. In this paper, a new recognition method based on contour lines of ambiguity function and stacked denoising auto-encoders is proposed. First, an ambiguity function is processed by the Gaussian smoothing and calculate contour lines by linear interpolation. Then, principal component analysis is used to reduce its feature dimension, retain the main ambiguity energy information. Finally, deep learning stacked denoising auto-encoders are built to learn and extract the deep and more ubiquitous features of contour lines, and classify them through the Softmax classifier. The simulated experiments show that the overall average recognition rate of the six typical radar signals is maintained above 99.83% when the signal-noise ratio is 0dB. Even in the -6dB environment, it also can reach 83.67%, which proves this method has good performance and feasibility under the extremely low signal-noise ratio conditions.","2693-2776","978-1-7281-8535-4","10.1109/IMCEC51613.2021.9482229","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9482229","radar emitter signal;ambiguity function;signal recognition;deep learning;stacked denoising auto-ecoders","Deep learning;Image recognition;Smoothing methods;Noise reduction;Radar;Transforms;Radar imaging","deep learning (artificial intelligence);feature extraction;Gaussian processes;interpolation;principal component analysis;radar computing;radar signal processing;signal denoising;smoothing methods","signal-noise ratio;contour lines;ambiguity function;complex radar emitter signal recognition methods;antinoise performance;main ambiguity energy information;stacked denoising autoencoders;Gaussian smoothing;linear interpolation;Softmax classifier","","1","","7","","19 Jul 2021","","","IEEE","IEEE Conferences"
"Spectral-spatial classification of hyperspectral images based on joint bilateral filter and stacked sparse autoencoder","C. Zhao; X. Wan; Y. Yan","College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China","2017 First International Conference on Electronics Instrumentation & Information Systems (EIIS)","22 Feb 2018","2017","","","1","5","Reducing noise in hyperspectral image (HSI) while preserving the details and extracting useful spectral-spatial information have always been one of the important problems of the classification task. This paper proposes a method by combining joint bilateral filter (JBF) and stacked sparse autoencoder via an ensemble strategy for the HSI classification. First, the novel JBF has an ability to preserve the important texture features and to restore the corrupted pixel, while extracting spectral and spatial information from hyperspectral data due to consider spectral as well as the spatial closeness for smoothing the HSI simultaneously. Second, stacked sparse autoencoderand (SSA) is adopted to adaptively extract high-level spectral-spatial feature representations from the smoothed image. Finally, the random forest (RF) classifier is adopted to perform supervised fine-tuning and classification. Experimental results on two real hyperspectral data sets demonstrate the effectiveness of the proposed classification approach.","","978-1-5386-0843-2","10.1109/EIIS.2017.8298563","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8298563","hyperspectral imagery;wave atoms (WA);bilateral filtering;stacked sparse autoencoder (SSA);random forest (RF)","Feature extraction;Hyperspectral imaging;Transforms;Support vector machines;Filtering;Spinning","hyperspectral imaging;image classification;image coding;image denoising;image filtering;image representation;image restoration;image texture;random processes","HSI classification;novel JBF;important texture features;corrupted pixel;spatial closeness;high-level spectral-spatial feature representations;smoothed image;supervised fine-tuning;hyperspectral data sets;hyperspectral image;joint bilateral filter;sparse autoencoder;spectral-spatial information;ensemble strategy;stacked sparse autoencoder;spectral-spatial classification;random forest classifier","","3","","10","","22 Feb 2018","","","IEEE","IEEE Conferences"
"Domain Adaptation and Autoencoder-Based Unsupervised Speech Enhancement","Y. Li; Y. Sun; K. Horoshenkov; S. M. Naqvi","Intelligent Sensing and Communications Group, School of Engineering, Newcastle University, Newcastle upon Tyne, U.K.; Big Data Institute, University of Oxford, Oxford, U.K.; University of Sheffield, Sheffield, U.K.; Intelligent Sensing and Communications Group, School of Engineering, Newcastle University, Newcastle upon Tyne, U.K.","IEEE Transactions on Artificial Intelligence","20 Jan 2022","2022","3","1","43","52","As a category of transfer learning, domain adaptation plays an important role in generalizing the model trained in one task and applying it to other similar tasks or settings. In speech enhancement, a well-trained acoustic model can be exploited to obtain the speech signal in the context of other languages, speakers, and environments. Recent domain-adaptation research was developed more effectively with various neural networks and high-level abstract features. However, the related studies are more likely to transfer the well-trained model from a rich and more diverse domain to a limited and similar domain. Therefore, in this article, the domain-adaptation method is proposed in unsupervised speech enhancement for the opposite circumstance, that is, transferring to a larger and richer domain. On the one hand, the importance-weighting (IW) approach is exploited with a variance-constrained autoencoder to reduce the shift of shared weights between the source and target domains. On the other hand, in order to train the classifier with the worst-case weights and minimize the risk, the minimax method is proposed. Both the proposed IW and minimax methods are evaluated from the VOICE BANK and IEEE datasets to the TIMIT dataset. The experimental results show that the proposed methods outperform the state-of-the-art approaches.","2691-4581","","10.1109/TAI.2021.3119927","IAA EPSRC U.K.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582824","Domain adaptation;importance-weighting (IW);minimax;speech enhancement;variance-constrained autoencoder (VAE)","Speech enhancement;Adaptation models;Transfer learning;Training;Task analysis;Feature extraction;Testing","learning (artificial intelligence);neural nets;pattern classification;signal denoising;speech enhancement;speech recognition;unsupervised learning","autoencoder-based unsupervised speech enhancement;transfer learning;domain adaptation;acoustic model;speech signal;recent domain-adaptation research;high-level abstract features;rich domain;more diverse domain;limited domain;similar domain;domain-adaptation method;larger domain;richer domain;importance-weighting approach;variance-constrained autoencoder;target domains;minimax methods","","1","","46","IEEE","20 Oct 2021","","","IEEE","IEEE Journals"
"Drone Ego-Noise Cancellation for Improved Speech Capture using Deep Convolutional Autoencoder Assisted Multistage Beamforming","Y. Song; S. Kindt; N. Madhu","IDLab, Ghent University - imec, Ghent, Belgium; IDLab, Ghent University - imec, Ghent, Belgium; IDLab, Ghent University - imec, Ghent, Belgium","2022 25th International Conference on Information Fusion (FUSION)","9 Aug 2022","2022","","","1","8","We propose a multistage approach for enhancing speech captured by a drone-mounted microphone array. The key challenge is suppressing the drone ego-noise, which is the major source of interference in such captures. Since the location of the target is not known a priori, we first apply a UNet-based deep convolutional autoencoder (AE) individually to each microphone signal. The AE generates a time-frequency mask ∈ [0, 1] per signal, where high values correspond to time-frequency points with relatively good signal-to-noise ratios (SNRs). The masks are pooled across all microphones and the aggregated mask is used to steer an adaptive, frequency domain beamformer, yielding a signal with an improved SNR. This beamformer output, after being fed back to the AE, now yields an improved mask - which is used for re-focussing the beamformer. This combination of AE and beamformer, which can be applied to the signals in multiple ‘passes' is termed multistage beamforming. The approach is developed and evaluated on a self-collected database. For the AE - when used to steer a beamformer - a training target that preserves more speech at the cost of less noise suppression outperforms an aggressive training target that suppresses more noise at the cost of more speech distortion. This, in combination with max-pooling of the multi-channel mask - which also lets through more speech (and noise) compared with median pooling - performs best. The experiments further demonstrate that the multistage approach brings extra benefit to the speech quality and intelligibility when the input SNR is 2:-10 dB, and yields comprehensible outputs when the input has a SNR above -5 dB.","","978-1-7377497-2-1","10.23919/FUSION49751.2022.9841383","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9841383","Drone;unmanned aerial vehicle (UAV);ego-noise reduction;beamformer;speech enhancement;UNet;MVDR;MWF;autoencoders","Training;Time-frequency analysis;Costs;Databases;Convolution;Speech enhancement;Microphone arrays","array signal processing;convolutional neural nets;deep learning (artificial intelligence);feature extraction;microphone arrays;remotely operated vehicles;signal denoising;source separation;speech intelligibility;speech processing;time-frequency analysis","drone ego-noise cancellation;improved speech capture;deep convolutional autoencoder assisted multistage beamforming;multistage approach;drone-mounted microphone array;UNet-based deep convolutional autoencoder;microphone signal;time-frequency mask;time-frequency points;signal-to-noise ratios;microphones;aggregated mask;improved SNR;improved mask;noise suppression;aggressive training target;speech distortion;multichannel mask;median pooling;speech quality;sppech intelligibility;adaptive frequency domain beamformer;self-collected database","","","","23","","9 Aug 2022","","","IEEE","IEEE Conferences"
"VDGAN: A Collaborative Filtering Framework Based on Variational Denoising with GANs","W. Sun; S. Yu; B. Dong","School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; Montclair State University, Montclair, NJ, USA","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","8","Generative Adversarial Networks (GANs) effectively capture the true posterior distribution. When applied to Collaborative Filtering (CF), GANs can generate a recommendation list through implicit feedback. However, the discriminators in the existing GANs-based CF methods are not utilized fully, and the generators perform poorly on sparse data mining. In this paper, we propose an improved collaborative filtering framework based on variational denoising for GANs (VDGAN). Specifically, VDGAN integrates the variational encoder and the self-attention mechanism into the GANs. By using the positive-negative sampling mechanism to add specific noise to the input data, the variational encoder obtains a robust feature matrix and improves the sparse data processing capability of the generator. In VDGAN, the denoising generator reconstructs the user-items interaction matrix through the feature matrix. And the discriminator is composed of the self-attention mechanism to obtain the explicit features of user preferences, which extends the ability of the discriminator. Furthermore, reinforcement learning replaces the traditional objective function of GANs, which better optimizes the generator and further improves the recommendation accuracy of the model. From our comprehensive experiments on three real-world datasets, we demonstrate that the performance of VDGAN significantly outperforms the state-of-the-art methods based on GANs and Auto-Encoders.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533585","Fundamental Research Funds for the Central Universities(grant numbers:DUT18JC28,DUT19ZD103,DUT21LAB115); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533585","collaborative filtering;generative adversarial networks;variational autoencoders;self-attention;reinforcement learning","Collaborative filtering;Noise reduction;Neural networks;Reinforcement learning;Linear programming;Generative adversarial networks;Data processing","collaborative filtering;data mining;image denoising;information filtering;learning (artificial intelligence);recommender systems","denoising generator reconstructs;self-attention mechanism;VDGAN;collaborative filtering framework;variational denoising;Generative Adversarial Networks;discriminator;existing GANs-based CF methods;generators;sparse data mining;improved collaborative;variational encoder;sparse data processing capability","","","","23","IEEE","20 Sep 2021","","","IEEE","IEEE Conferences"
"A Hybrid LSTM-ResNet Deep Neural Network for Noise Reduction and Classification of V-Band Receiver Signals","H. Arab; I. Ghaffari; R. M. Evina; S. O. Tatu; S. Dufour","Département de Mathématiques et de Génie Industriel, École Polytechnique de Montréal, Montréal, QC, Canada; Département de Mathématiques et de Génie Industriel, École Polytechnique de Montréal, Montréal, QC, Canada; Telecommunications Department, Institut National de la Recherche Scientifique, Montréal, QC, Canada; Telecommunications Department, Institut National de la Recherche Scientifique, Montréal, QC, Canada; Département de Mathématiques et de Génie Industriel, École Polytechnique de Montréal, Montréal, QC, Canada","IEEE Access","11 Feb 2022","2022","10","","14797","14806","Noise reduction is one of the most important process used for signal processing in communication systems. The signal-to-noise ratio (SNR) is a key parameter to consider for minimizing the bit error rate (BER). The inherent noise found in millimeter-wave systems is mainly a combination of white noise and phase noise. Increasing the SNR in wireless data transfer systems can lead to reliability and performance improvements. To address this issue, we propose to use a recurrent neural network (RNN) with a long short-term memory (LSTM) autoencoder architecture to achieve signal noise reduction. This design is based on a composite LSTM autoencoder with a single encoder layer and two decoder layers. A V-band receiver test bench is designed and fabricated to provide a high-speed wireless communication system. Constellation diagrams display the output signals measured for various random sequences of PSK and QAM modulated signals. The LSTM autoencoder is trained in real time using various noisy signals. The trained system is then used to reduce noise levels in the tested signals. The SNR of the designed receiver is of the order of 11.8dB, and it increases to 13.66dB using the three-level LSTM autoencoder. Consequently, the proposed algorithm reduces the bit error rate from 10−8 to 10−11. The performance of the proposed algorithm is comparable to other noise reduction strategies. Augmented denoised signals are fed into a ResNet-152 deep convolutional network to perform the final classification. The demodulation types are classified with an accuracy of 99.93%. This is confirmed by experimental measurements.","2169-3536","","10.1109/ACCESS.2022.3147980","Fonds de Recherche du Québec—Nature et technologies (FRQNT); Financement de Recherche Postdoctorale IVADO 2021; Fonds d’excellence en recherche Apogée Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9705207","Artificial intelligence;convolutional neural network (CNN);deep learning;denoising;Doppler frequency;long short-term memory (LSTM);machine learning;millimeter wave;modulator;receiver;recurrent neural network (RNN);ResNet;signal classification;signal processing","Receivers;Noise reduction;Phase shift keying;Solid modeling;Quadrature amplitude modulation;Predictive models;Millimeter wave technology","convolutional neural nets;deep learning (artificial intelligence);demodulation;error statistics;millimetre wave communication;neural net architecture;phase shift keying;quadrature amplitude modulation;radio networks;random sequences;recurrent neural nets;signal classification;signal denoising;telecommunication computing;telecommunication network reliability;white noise","hybrid LSTM-ResNet deep neural network;signal processing;signal-to-noise ratio;SNR;bit error rate;millimeter-wave systems;white noise;phase noise;wireless data transfer systems;recurrent neural network;short-term memory autoencoder architecture;signal noise reduction;composite LSTM autoencoder;single encoder layer;V-band receiver test bench;high-speed wireless communication system;output signals;noisy signals;trained system;noise levels;three-level LSTM autoencoder;noise reduction strategies;augmented denoised signals;ResNet-152 deep convolutional network;V-band receiver signal classification;reliability;constellation diagrams;demodulation types;QAM modulated signals;PSK random sequences;noise figure 11.8 dB;noise figure 13.66 dB","","","","34","CCBY","4 Feb 2022","","","IEEE","IEEE Journals"
"Deep Spatio-Temporal Representation for Detection of Road Accidents Using Stacked Autoencoder","D. Singh; C. K. Mohan","Visual Learning and Intelligence Group, IIT Hyderabad, Hyderabad, India; Visual Learning and Intelligence Group, IIT Hyderabad, Hyderabad, India","IEEE Transactions on Intelligent Transportation Systems","28 Feb 2019","2019","20","3","879","887","Vision-based detection of road accidents using traffic surveillance video is a highly desirable but challenging task. In this paper, we propose a novel framework for automatic detection of road accidents in surveillance videos. The proposed framework automatically learns feature representation from the spatiotemporal volumes of raw pixel intensity instead of traditional hand-crafted features. We consider the accident of the vehicles as an unusual incident. The proposed framework extracts deep representation using denoising autoencoders trained over the normal traffic videos. The possibility of an accident is determined based on the reconstruction error and the likelihood of the deep representation. For the likelihood of the deep representation, an unsupervised model is trained using one class support vector machine. Also, the intersection points of the vehicle's trajectories are used to reduce the false alarm rate and increase the reliability of the overall system. We evaluated out proposed approach on real accident videos collected from the CCTV surveillance network of Hyderabad City in India. The experiments on these real accident videos demonstrate the efficacy of the proposed approach.","1558-0016","","10.1109/TITS.2018.2835308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8367975","Accident detection;anomaly detection;deep learning;stacked autoencoder","Accidents;Videos;Trajectory;Feature extraction;Target tracking;Urban areas","feature extraction;image classification;image representation;neural nets;object detection;road accidents;support vector machines;traffic engineering computing;unsupervised learning;video coding;video signal processing;video surveillance","denoising autoencoders;normal traffic videos;accident videos;CCTV surveillance network;deep spatio-temporal representation;stacked autoencoder;vision-based detection;traffic surveillance video;feature representation;raw pixel intensity;road accident detection;one class support vector machine;false alarm rate reduction;Hyderabad city;India","","60","","41","IEEE","28 May 2018","","","IEEE","IEEE Journals"
"Real-Time Outlier Detection Applied to a Doppler Velocity Log Sensor Based on Hybrid Autoencoder and Recurrent Neural Network","N. Davari; A. P. Aguiar","Faculty of Engineering, University of Porto, Porto, Portugal; Faculty of Engineering, University of Porto, Porto, Portugal","IEEE Journal of Oceanic Engineering","12 Oct 2021","2021","46","4","1288","1301","This article presents a real-time outlier detection deep-learning (OD-DL)-based method using a hybridized artificial neural network (ANN) approach. We propose an unsupervised ANN scheme that runs in parallel, a denoising autoencoder (DAE) and a recurrent neural network (RNN). The DAE aims to reconstruct relevant/normal input data, whereas it seeks to ignore outliers; the RNN, with a recursive structure, is used to predict time-series data. As measurements arrive, two tasks are performed: 1) the outlier decision, which is based on a reconstruction error and an energy score criteria from the output difference between the DAE and the RNN; and 2) the training procedure for both DAE and RNN. The proposed OD-DL scheme is specifically targeted to address the outlier problem of the data generated by a Doppler velocity log (DVL) sensor installed on board of an autonomous underwater vehicle (AUV) to enhance the AUV navigation system performance. In particular, the DVL data enter into the OD-DL scheme whose output is fed into an AUV navigation system that runs an error-state Kalman filter that integrates the corrected DVL data with the measurements of an inertial measurement unit and a depth meter. The experimental results show that the AUV navigation system with the OD-DL method outperforms in terms of a more accurate estimated position when compared with the case that there is no outlier detection and with the case of a navigation system using a conventional outlier detection method, or other simpler deep-learning methods.","1558-1691","","10.1109/JOE.2021.3057909","FEDER funds through COMPETE2020 – POCI and by the Portuguese national funds (PIDDAC); FCT(grant numbers:PTDC/EEI-AUT/3522/2020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9385789","Autoencoder;autonomous underwater vehicle (AUV);error-state Kalman filter (ESKF);integrated navigation system;outlier detection (OD);recurrent neural network (RNN)","Navigation;Recurrent neural networks;Kalman filters;Autonomous underwater vehicles;Real-time systems","autonomous underwater vehicles;data analysis;Doppler radar;Kalman filters;learning (artificial intelligence);path planning;recurrent neural nets;remotely operated vehicles;sensors;time series;underwater vehicles","deep-learning methods;Doppler velocity log sensor;hybrid autoencoder;recurrent neural network;real-time outlier detection deep-learning-based method;hybridized artificial neural network approach;unsupervised ANN scheme;denoising autoencoder;DAE;RNN;time-series data;conventional outlier detection method;OD-DL method;corrected DVL data;error-state Kalman filter;AUV navigation system performance;outlier problem;OD-DL scheme;energy score criteria;reconstruction error;outlier decision","","1","","44","IEEE","24 Mar 2021","","","IEEE","IEEE Journals"
"A Physics-Based Deep Learning Approach to Shadow Invariant Representations of Hyperspectral Images","L. Windrim; R. Ramakrishnan; A. Melkumyan; R. J. Murphy","Australian Centre for Field Robotics, The University of Sydney, Sydney, NSW, Australia; Australian Centre for Field Robotics, The University of Sydney, Sydney, NSW, Australia; Australian Centre for Field Robotics, The University of Sydney, Sydney, NSW, Australia; Australian Centre for Field Robotics, The University of Sydney, Sydney, NSW, Australia","IEEE Transactions on Image Processing","15 Nov 2017","2018","27","2","665","677","This paper proposes the Relit Spectral AngleStacked Autoencoder, a novel unsupervised feature learning approach for mapping pixel reflectances to illumination invariant encodings. This work extends the Spectral Angle-Stacked Autoencoder so that it can learn a shadow-invariant mapping. The method is inspired by a deep learning technique, Denoising Autoencoders, with the incorporation of a physics-based model for illumination such that the algorithm learns a shadow invariant mapping without the need for any labelled training data, additional sensors, a priori knowledge of the scene or the assumption of Planckian illumination. The method is evaluated using datasets captured from several different cameras, with experiments to demonstrate the illumination invariance of the features and how they can be used practically to improve the performance of high-level perception algorithms that operate on images acquired outdoors.","1941-0042","","10.1109/TIP.2017.2761542","Rio Tinto Centre for Mine Automation; Australian Centre for Field Robotics, The University of Sydney; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8063434","Autoencoders;Illumination invariance;unsupervised feature learning;hyperspectral;deep learning","Lighting;Sensors;Hyperspectral imaging;Geometry;Atmospheric modeling;Cameras","image classification;image coding;image denoising;learning (artificial intelligence);unsupervised learning","hyperspectral images;Relit Spectral AngleStacked Autoencoder;novel unsupervised feature learning approach;illumination invariant encodings;Spectral Angle-Stacked Autoencoder;shadow-invariant mapping;deep learning technique;shadow invariant mapping;Planckian illumination;illumination invariance;shadow invariant representations;physics-based deep learning;denoising autoencoders","","20","","55","IEEE","9 Oct 2017","","","IEEE","IEEE Journals"
"DefGAN: Defect Detection GANs With Latent Space Pitting for High-Speed Railway Insulator","D. Zhang; S. Gao; L. Yu; G. Kang; X. Wei; D. Zhan","School of Electrical Engineering, Southwest Jiaotong University, Chengdu, China; School of Electrical Engineering, Southwest Jiaotong University, Chengdu, China; School of Electrical Engineering, Southwest Jiaotong University, Chengdu, China; School of Electrical Engineering, Southwest Jiaotong University, Chengdu, China; School of Electrical Engineering, Southwest Jiaotong University, Chengdu, China; School of Electrical Engineering, Southwest Jiaotong University, Chengdu, China","IEEE Transactions on Instrumentation and Measurement","25 Dec 2020","2021","70","","1","10","As a key component of the high-speed railway catenary, the insulator plays an important role in supporting the catenary and maintaining the insulation between the catenary and earth. Regular inspection using computer vision technology is an effective way to detect insulator defects and improve the catenary operation safety. However, achieving full automation of insulator defects detection is still a difficult task due to the defective sample scarcity and subtle defect features. To overcome the problem, this article proposes defect detection GANs (DefGANs) that consist of a denoising autoencoder, a discriminator, and a classifier to detect defects, which can generate defective samples from pitted latent representations, thereby improving the reliability of defect detection classifier. The proposed DefGAN can pit the latent representations of normal samples to generate defective samples. Our proposal mainly consists of two stages. In the first stage, we use cascaded deep segmentation networks (CDSNets) to extract the insulator from the catenary images. Then, the insulator area is sampled into small patches. In the second stage, the patches are fed into the proposed DefGAN to detect defects. Moreover, the defect score is determined by the anomaly probability of the classifier and reconstruction error of the denoising autoencoder. The effectiveness of our work is measured across the catenary data sets.","1557-9662","","10.1109/TIM.2020.3038008","Key Projects of National Natural Science Foundation of China(grant numbers:U1734202); Sichuan Province Science and Technology Achievement Transformation Demonstration Project(grant numbers:18ZHSF0154); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9259012","Anomaly detection;classifier;denoising autoencoder;generator adversarial training;insulator;latent space","Insulators;Image segmentation;Image reconstruction;Gallium nitride;Anomaly detection;Rail transportation;Training","computer vision;feature extraction;flaw detection;image classification;image denoising;image segmentation;inspection;insulators;learning (artificial intelligence);mechanical engineering computing;neural nets;power engineering computing;probability;railway engineering","catenary data sets;defect score;insulator area;catenary images;normal samples;defect detection classifier;pitted latent representations;defective samples;denoising autoencoder;subtle defect features;defective sample scarcity;insulator defects detection;catenary operation safety;insulation;high-speed railway catenary;high-speed railway insulator;latent space pitting;defect detection GANs;DefGAN","","2","","34","IEEE","13 Nov 2020","","","IEEE","IEEE Journals"
"Compensate multiple distortions for speaker recognition systems","M. Mohammadamini; D. Matrouf; J. -F. Bonastre; R. Serizel; S. Dowerah; D. Jouvet","LIA (Laboratoire Informatique d'Avignon), Avignon University; LIA (Laboratoire Informatique d'Avignon), Avignon University; LIA (Laboratoire Informatique d'Avignon), Avignon University; Université de Lorraine, CNRS, Inria, Loria, Nancy, France; Université de Lorraine, CNRS, Inria, Loria, Nancy, France; Université de Lorraine, CNRS, Inria, Loria, Nancy, France","2021 29th European Signal Processing Conference (EUSIPCO)","8 Dec 2021","2021","","","141","145","The performance of speaker recognition systems reduces dramatically in severe conditions in the presence of additive noise and/or reverberation. In some cases, there is only one kind of domain mismatch like additive noise or reverberation, but in many cases, there are more than one distortion. Finding a solution for domain adaptation in the presence of different distortions is a challenge. In this paper we investigate the situation in which there is none, one or more of the following distortions: early reverberation, full reverberation, additive noise. We propose two configurations to compensate for these distortions. In the first one a specific denoising autoencoder is used for each distortion. In the second configuration, a denoising autoencoder is used to compensate for all of these distortions simultaneously. Our experiments show that, in the co-existence of noise and reverberation, the second configuration gives better results. For example, with the second configuration we obtained 76.6% relative improvement of EER for utterances longer than 12 seconds. For other situations in the presence of only one distortion, the second configuration gives almost the same results achieved by using a specific model for each distortion.","2076-1465","978-9-0827-9706-0","10.23919/EUSIPCO54536.2021.9615983","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9615983","additive noise;early reverberation;full reverberation;x-vector;denoising autoencoder","Additive noise;Additives;Noise reduction;Europe;Distortion;Speaker recognition;Reverberation","neural nets;signal denoising;speaker recognition","speaker recognition systems;additive noise;domain mismatch;domain adaptation;early reverberation;denoising autoencoder;EER;full reverberation;time 12.0 s","","","","18","","8 Dec 2021","","","IEEE","IEEE Conferences"
"Recovery Method for Missing Sensor Data in Multi-Sensor Based Walking Recognition System","C. Xie; S. Bi; M. Dong; Y. Li","School of Computer Science & Engineering, South China University of Technology, Guangzhou; School of Computer Science & Engineering, South China University of Technology, Guangzhou; School of Computer Science & Engineering, South China University of Technology, Guangzhou; School of Computer Science & Engineering, South China University of Technology, Guangzhou","2018 IEEE 8th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)","11 Apr 2019","2018","","","558","563","Missing data is a major challenge in activity recognition and becomes an increasingly important study. Most current research on activity recognition is based on multiple sensors, which may bring the problem of missing data for one or more sensors. This paper presents Multi-source Denoising AutoEncoder (MSDA) for filling missing sensor data in walking recognition system based on previously proposed Hierarchical AdaBoost. The recovery method uses Denoising AutoEncoder to build a neural network which output is the embedding of features that include missing sensors, so that it can predict the features for missing sensor data. The experimental results show that MSDA can not only improve the recognition accuracy, but has higher performance comparing with other missing data processing method such as EM-PCA and filling missing data with a special value.","2379-7711","978-1-5386-7057-6","10.1109/CYBER.2018.8688042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8688042","data recovery;Denoising AutoEncoder;missing sensor data;walking recognition","","gait analysis;image coding;image denoising;image fusion;image recognition;image sensors","recovery method;missing sensor data;walking recognition system;activity recognition;multiple sensors;missing data processing method;multisource denoising autoencoder;MSDA;hierarchical AdaBoost;neural network;EM-PCA","","","","12","","11 Apr 2019","","","IEEE","IEEE Conferences"
"CF-SSDAE: Symmetric SDAE for Collaborative Filtering Algorithm","J. Sun; X. Wang; Z. Ning; R. Zhao","College of Software, Taiyuan University of Technology, Taiyuan, China; College of Information and Computer, Taiyuan University of Technology, Taiyuan, China; College of Software, Taiyuan University of Technology, Taiyuan, China; College of Information and Computer, Taiyuan University of Technology, Taiyuan, China","2020 Eighth International Conference on Advanced Cloud and Big Data (CBD)","21 Apr 2021","2020","","","137","142","Collaborative Deep Learning (CDL) uses the stacked denoising autoencoder to encode information matrix of items, which reduces the dimension of the matrix, but the method does not consider the user information. In order to get the user information, a new acquisition method is proposed: the user information matrix is obtained from the item information matrix and the rating matrix, so that the user information matrix and the item information matrix are in the same space. And a symmetric SDAE for collaborative filtering algorithm(CF-SSDAE) is proposed, which uses the two stacked denoising autoencoders to simultaneously train the user information matrix and the item information matrix to obtain the feature matrix of users and items. In order to compare with the state-of-the-art algorithms, experiments show that our algorithm has higher accuracy on the CiteULike dataset.","","978-1-6654-2313-7","10.1109/CBD51900.2020.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9406910","recommendation systems;collaborative filtering;topic model;denoising autoencoder","Deep learning;Privacy;Symmetric matrices;Collaborative filtering;Noise reduction;Collaboration;Filtering algorithms","collaborative filtering;feature extraction;groupware;image denoising;information filtering;learning (artificial intelligence);matrix decomposition;recommender systems","CF-SSDAE;symmetric SDAE;collaborative filtering algorithm;stacked denoising autoencoder;user information matrix;item information matrix;rating matrix;feature matrix","","","","15","","21 Apr 2021","","","IEEE","IEEE Conferences"
"Multi-Stage Gaussian Noise Reduction with Recurrent Neural Networks","A. Ranganath; O. DeGuchy; M. Singhal; R. F. Marcia","Electrical Engineering and Computer Science, University of California, Merced, Merced, CA, USA; Applied Mathematics, University of California, Merced, Merced, CA, USA; Electrical Engineering and Computer Science, University of California, Merced, Merced, CA, USA; Applied Mathematics, University of California, Merced, Merced, CA, USA","2021 55th Asilomar Conference on Signals, Systems, and Computers","4 Mar 2022","2021","","","135","139","In this paper, we implement multi-stage deep learning methods to recover signals from noisy observations. We seek an alternative to the traditional iterative optimization-based methods by exploiting the denoising properties of autoencoders. The novelty of our method is in the reformulation of the denoising problem as a multi-stage process and in the use of recurrent neural networks to gradually recover the intended signal. Numerical experiments on a modified version of the CIFAR-10 dataset show that signal recovery in multiple stages produces sharper images than a standard autoencoder approach. We present quantitative evidence of improvement using both the mean squared error and the structural similarity index.","2576-2303","978-1-6654-5828-3","10.1109/IEEECONF53345.2021.9723266","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9723266","Image denoising;recurrent neural networks;autoencoders;convolutional neural networks","Deep learning;Recurrent neural networks;Gaussian noise;Noise reduction;Noise measurement;Iterative methods;Indexes","Gaussian noise;image classification;image denoising;image representation;iterative methods;learning (artificial intelligence);neural nets;optimisation;recurrent neural nets","recurrent neural networks;multistage deep learning methods;noisy observations;traditional iterative optimization-based methods;denoising problem;multistage process;intended signal;CIFAR-10 dataset show;signal recovery;standard autoencoder approach;multistage gaussian noise reduction","","","","27","IEEE","4 Mar 2022","","","IEEE","IEEE Conferences"
"Deep-Learning-Enabled Security Issues in the Internet of Things","Z. Lv; L. Qiao; J. Li; H. Song","School of Data Science and Software Engineering, Qingdao University, Qingdao, China; School of Data Science and Software Engineering, Qingdao University, Qingdao, China; School of Data Science and Software Engineering, Qingdao University, Qingdao, China; Department of Electrical, Computer, Software, and Systems Engineering, Embry–Riddle Aeronautical University, Daytona Beach, FL, USA","IEEE Internet of Things Journal","4 Jun 2021","2021","8","12","9531","9538","In order to explore the application value of deep learning denoising autoencoder (DAE) in Internet-of-Things (IoT) fusion security, in this study, a hierarchical intrusion security detection model stacked DAE supporting vector machine (SDAE-SVM) is constructed based on the three-layer neural network of self-encoder. The sample data after dimension reduction are obtained by layer by layer pretraining and fine-tuning. The traditional deep learning algorithms [stacked noise autoencoder (SNAE), stacked autoencoder (SAE), stacked contractive autoencoder (SCAE), stacked sparse autoencoder (SSAE), deep belief network (DBN)] are introduced to carry out the comparative simulation with the model in this study. The results show that when the encoder in the model is a 4-layer network structure, the accuracy rate (Ac) of the model is the highest (97.83%), the false-negative rate (Fn) (1.27%) and the false-positive rate (Fp) (3.21%) are the lowest. When the number of nodes in the first hidden layer is about 110, the model accuracy is about 98%. When comparing the model designed in this study with the common feature dimension reduction methods, the Ac, Fn, and Fp of this model are the best, which are 98.12%, 3.21%, and 1.27%, respectively. When compared with other deep learning algorithms of the same type, the recognition rate, Ac, error rate, and rejection rate show good results. In multiple data sets, the recognition rate, Ac, error rate, and rejection rate of the model in this study are always better than the traditional deep learning algorithms. In conclusion, when deep learning SDAE is applied to IoT convergence-based intrusion security detection, the detection load can be reduced, the detection effect can be improved, and the operation is more secure and stable.","2327-4662","","10.1109/JIOT.2020.3007130","National Natural Science Foundation of China(grant numbers:61902203); Key Research and Development Plan—Major Scientific and Technological Innovation Projects of Shandong Province(grant numbers:2019JZZY020101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9137336","Deep learning;Internet of Things (IoT);intrusion security detection;SDAE","Security;Feature extraction;Deep learning;Training;Noise reduction;Internet of Things;Dimensionality reduction","belief networks;feature extraction;image classification;image denoising;learning (artificial intelligence);neural nets;support vector machines","security issues;application value;deep learning denoising autoencoder;Internet-of-Things fusion security;hierarchical intrusion security detection model;DAE supporting vector machine;three-layer neural network;layer pretraining;fine-tuning;traditional deep learning algorithms;noise autoencoder;stacked autoencoder;stacked contractive autoencoder;stacked sparse autoencoder;comparative simulation;4-layer network structure;false-negative rate;false-positive rate;hidden layer;model accuracy;common feature dimension reduction methods;recognition rate;error rate;rejection rate;deep learning SDAE;convergence-based intrusion security detection","","37","","44","IEEE","9 Jul 2020","","","IEEE","IEEE Journals"
"Robust Speaker Identification of IoT based on Stacked Sparse Denoising Auto-encoders","Z. Wang; S. Duan; C. Zeng; X. Yu; Y. Yang; H. Wu","Hubei Research Center for Educational Informationization, Central China Normal University, Wuhan, China; CCNU Wollongong Joint Institute, Central China Normal University, Wuhan, China; Hubei Key Laboratory for High-efficiency Utilization of Solar Energy and Operation Control of Energy Storage System, Hubei University of Technology, Wuhan, China; CCNU Wollongong Joint Institute, Central China Normal University, Wuhan, China; CCNU Wollongong Joint Institute, Central China Normal University, Wuhan, China; CCNU Wollongong Joint Institute, Central China Normal University, Wuhan, China","2020 International Conferences on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData) and IEEE Congress on Cybermatics (Cybermatics)","28 Dec 2020","2020","","","252","257","Robust speaker identification of Internet of Things (IoT) becomes an active research problem in the field of biometrics, and it has wide applications in commercial fields and public security. In order to improve the robustness of speaker identification of IoT, we propose a novel Stacked Sparse Denoising Auto-encoder (SSDAE) for robust speaker identification in this paper. Firstly, the i-vector features are estimated based on the universal background model and total variability space model. For the second stage, sparsity constraints and corrupting operations are fused together into the general auto-encoder, and then the single sparse denoising auto-encoder is constructed. Then, the SSDAE is built with multi-hidden sparse denoising auto-encoder layers by layer wisely stacking operation. In the final layer of the designed deep neural network, the Softmax layer is included for classification purpose. The experimental results have shown that the proposed robust speaker identification method achieves better performance in robust speaker identification task than the state-of-the-art approaches for different kinds and levels of noisy inputs.","","978-1-7281-7647-5","10.1109/iThings-GreenCom-CPSCom-SmartData-Cybermatics50389.2020.00056","CCNU; MOE(grant numbers:CCNU20ZT010); National Natural Science Foundation of China(grant numbers:61901165,61501199); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9291611","Auto-encoder;speaker identification;sparsity;Internet of Things","Feature extraction;Noise reduction;Internet of Things;Acoustics;Training;Speech enhancement;Robustness","feature extraction;Gaussian processes;Internet of Things;neural nets;signal denoising;speaker recognition","stacked sparse denoising autoencoders;multihidden sparse denoising auto-encoder layers;robust speaker identification task;IoT;Internet of Things;SSDAE;i-vector features;universal background model;total variability space model;Softmax layer;deep neural network","","","","16","","28 Dec 2020","","","IEEE","IEEE Conferences"
"Vector representation of non-standard spellings using dynamic time warping and a denoising autoencoder","M. B. Lazreg; M. Goodwin; O. -C. Granmo","University of Agder, Grimstad, Norway; University of Agder, Grimstad, Norway; University of Agder, Grimstad, Norway","2017 IEEE Congress on Evolutionary Computation (CEC)","7 Jul 2017","2017","","","1444","1450","The presence of non-standard spellings in Twitter causes challenges for many natural language processing tasks. Traditional approaches mainly regard the problem as a translation, spell checking, or speech recognition problem. This paper proposes a method that represents the stochastic relationship between words and their non-standard versions in real vectors. The method uses dynamic time warping to preprocess the non-standard spellings and autoencoder to derive the vector representation. The derived vectors encode word patterns and the Euclidean distance between the vectors represents a distance in the word space that challenges the prevailing edit distance. After training the autoencoder on 1051 different words and their non-standard versions, the results show that the new distance can be used to obtain the correct standard word among the closest five words in 89.53% of the cases compared to only 68.22% using the edit distance.","","978-1-5090-4601-0","10.1109/CEC.2017.7969473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7969473","","Noise reduction;Standards;Twitter;Speech recognition;Context;Neural networks;Hidden Markov models","natural language processing;social networking (online);stochastic processes;text analysis;unsupervised learning","vector representation;nonstandard spellings;dynamic time warping;denoising autoencoder;natural language processing;stochastic relationship;nonstandard real vectors;word patterns;Euclidean distance;word space","","3","","22","","7 Jul 2017","","","IEEE","IEEE Conferences"
"Short-Term Electricity Price Forecasting With Stacked Denoising Autoencoders","L. Wang; Z. Zhang; J. Chen","Department of Systems Engineering and Engineering Management, City University of Hong Kong, Kowloon, Hong Kong; Department of Systems Engineering and Engineering Management, City University of Hong Kong, Kowloon, Hong Kong; Microsoft Corp., Redmond, WA, USA","IEEE Transactions on Power Systems","16 Jun 2017","2017","32","4","2673","2681","A short-term forecasting of the electricity price with data-driven algorithms is studied in this research. A stacked denoising autoencoder (SDA) model, a class of deep neural networks, and its extended version are utilized to forecast the electricity price hourly. Data collected in Nebraska, Arkansas, Louisiana, Texas, and Indiana hubs in U.S. are utilized. Two types of forecasting, the online hourly forecasting and day-ahead hourly forecasting, are examined. In online forecasting, SDA models are compared with data-driven approaches including the classical neural networks, support vector machine, multivariate adaptive regression splines, and least absolute shrinkage and selection operator. In the day-ahead forecasting, the effectiveness of SDA models is further validated through comparing with industrial results and a recently reported method. Computational results demonstrate that SDA models are capable to accurately forecast electricity prices and the extended SDA model further improves the forecasting performance.","1558-0679","","10.1109/TPWRS.2016.2628873","Early Career Scheme from the Research Grants Council; Hong Kong Special Administrative Region under Project CityU(grant numbers:138313); CityU Strategic Research(grant numbers:7004551); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7744689","Comparative analysis;data mining;electricity price;hourly forecasting;neural networks","Forecasting;Predictive models;Artificial neural networks;Wind forecasting;Data models","load forecasting;neural nets;power engineering computing;power markets;pricing;regression analysis;support vector machines","short-term electricity price forecasting;stacked denoising autoencoders;SDA model;deep neural networks;data-driven algorithms;Nebraska hubs;Arkansas hubs;Indiana hubs;Louisiana hubs;Texas hubs;online hourly forecasting;day-ahead hourly forecasting;selection operator;least absolute shrinkage;adaptive regression splines;support vector machine;classical neural networks","","109","","57","IEEE","15 Nov 2016","","","IEEE","IEEE Journals"
"Improving transfer learning accuracy by reusing Stacked Denoising Autoencoders","C. Kandaswamy; L. M. Silva; L. A. Alexandre; R. Sousa; J. M. Santos; J. M. de Sá","Instituto de Engenharia Biomédica (INEB) and universidade do Porro, Portugal; INEB and also with Dep. de Matemática at Universidade de Aveiro, Portugal; Universidade da Beira Interior and Instituto de Telecomunicações, Covilhã; INEB at Universidade do Porto, Portugal; INEB and also with Dep. de Matemática at Instituto Superior de Engenharia do Instituto Politécnico do Porto, Portugal; INEB and also with Dep. de Engenharia Electronica e de Computadores at FEUP, Porto, Portugal","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","4 Dec 2014","2014","","","1380","1387","Transfer learning is a process that allows reusing a learning machine trained on a problem to solve a new problem. Transfer learning studies on shallow architectures show low performance as they are generally based on hand-crafted features obtained from experts. It is therefore interesting to study transference on deep architectures, known to directly extract the features from the input data. A Stacked Denoising Autoencoder (SDA) is a deep model able to represent the hierarchical features needed for solving classification problems. In this paper we study the performance of SDAs trained on one problem and reused to solve a different problem not only with different distribution but also with a different tasks. We propose two different approaches: 1) unsupervised feature transference, and 2) supervised feature transference using deep transfer learning. We show that SDAs using the unsupervised feature transference outperform randomly initialized machines on a new problem. We achieved 7% relative improvement on average error rate and 41% on average computation time to classify typed uppercase letters. In the case of supervised feature transference, we achieved 5.7% relative improvement in the average error rate, by reusing the first and second hidden layer, and 8.5% relative improvement for the average error rate and 54% speed up w.r.t the baseline by reusing all three hidden layers for the same data. We also explore transfer learning between geometrical shapes and canonical shapes, we achieved 7.4% relative improvement on average error rate in case of supervised feature transference approach.","1062-922X","978-1-4799-3840-7","10.1109/SMC.2014.6974107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974107","Transfer Learning;Deep Learning","Training;Shape;Yttrium;Error analysis;Noise reduction;Computer architecture;Visualization","computational geometry;feature extraction;image classification;image representation;neural nets;unsupervised learning","deep transfer learning accuracy improvement;stacked denoising autoencoder reuse;learning machine;feature extraction;hierarchical feature representation;SDA;unsupervised feature transference;supervised feature transference;typed uppercase letter classification;geometrical shapes;canonical shapes","","25","","17","","4 Dec 2014","","","IEEE","IEEE Conferences"
"Recovering loss to followup information using denoising autoencoders","L. Gondara; K. Wang",Simon Fraser University; Simon Fraser University,"2017 IEEE International Conference on Big Data (Big Data)","15 Jan 2018","2017","","","1936","1945","Loss to followup is a significant issue in healthcare and has serious consequences for a study's validity and cost. Methods available at present for recovering loss to followup information are restricted by their expressive capabilities and struggle to model highly non-linear relations and complex interactions. In this paper we propose a model based on overcomplete denoising autoencoders to recover loss to followup information. Designed to work with high volume data, results on various simulated and real life datasets show our model is appropriate under varying dataset and loss to followup conditions and outperforms the state-of-the-art methods by a wide margin (≥ 20% in some scenarios) while preserving the dataset utility for final analysis.","","978-1-5386-2715-0","10.1109/BigData.2017.8258139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8258139","","Noise reduction;Data models;Biological system modeling;Decoding;Training;Solid modeling;Clinical trials","data handling;health care","loss to followup;followup information;loss recovery;highly nonlinear relations;dataset utility;real life datasets;simulated life datasets;high volume data;overcomplete denoising autoencoders;complex interactions;expressive capabilities;healthcare","","8","","41","","15 Jan 2018","","","IEEE","IEEE Conferences"
"Recognition of Cognitive Task Load levels using single channel EEG and Stacked Denoising Autoencoder","Z. Yin; J. Zhang","Engineering Research Center of Optical Instrument and System, Shanghai Key Lab of Modern Optical System, University of Shanghai for Science and Technology, Shanghai, Shanghai, CN; Department of Automation, East China University of Science and Technology, Shanghai, Shanghai, CN","2016 35th Chinese Control Conference (CCC)","29 Aug 2016","2016","","","3907","3912","Evaluation of operator Cognitive Task Load (CTL) level is quite crucial in Human-Machine (HM) collaborative task environment since operator mental overload or inattention caused by abnormal CTL states may lead to human performance degradation or even catastrophic accidents. One of the most practical approaches tackling this issue is to use ongoing electroencephalogram (EEG) in which human cognitive state can be objectively estimated. However, the accurate recognition of CTL via single channel EEG with the lowest-intrusivity to task condition is particularly challenging as EEG is characterized by individual dependency and nonstationarity. In this paper, a deep learning model designed by Stacked Denoising AutoEncoder (SDAE) is employed on single EEG channel signal to estimate binary levels (low vs. high) of CTL. By adopting a simulated HM process control system, the operator EEG data for 8 healthy subjects under different task demands were collected on two experimental sessions across two consecutive days. Based on the computed full power spectral of EEG. the number of nodes in SDAE is determined by greedy search according to the optimal training error of each layer. The shallow layers of the designed deep network are used to extract the subject-specific information related to CTL variation while the stable power features were reconstructed in those deep layers. Finally, the proposed method is demonstrated to be effective and 74% classification rate across sessions in average of all subjects were achieved.","1934-1768","978-9-8815-6391-0","10.1109/ChiCC.2016.7553961","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7553961","Cognitive task load;mental workload;electroencephalogram;deep learning;operator functional state","Decision support systems;5G mobile communication","accidents;cognition;electroencephalography;estimation theory;greedy algorithms;man-machine systems;neurophysiology;optimal control;personnel","cognitive task load level recognition;single channel EEG;stacked denoising autoencoder;SDAE;human-machine collaborative task environment;operator mental overload;abnormal CTL states;human performance degradation;catastrophic accidents;electroencephalogram;human cognitive state;CTL accurate recognition;deep learning model;binary levels estimation;simulated HM process control system;operator EEG data;greedy search;optimal training error;subject-specific information","","6","","14","","29 Aug 2016","","","IEEE","IEEE Conferences"
"Degradation Estimation of Turbines in Wind Farm Using Denoising Autoencoder Model","S. Sato; K. Sanda","Toyota Central R&D Labs., Inc, Nagakute, Aichi, Japan; Toyota Central R&D Labs., Inc, Nagakute, Aichi, Japan","2019 IEEE International Conference on Prognostics and Health Management (ICPHM)","29 Aug 2019","2019","","","1","6","We propose a method to estimate the power performance degradation in wind turbines (WTs) that arises from damage in the turbine blade and other components. In general, the single anemometer mounted on the nacelle is unable to measure precise wind speed distributions that the WT receives, thus, degradation of the power output is difficult to evaluate. By focusing on the fact that the power output data of adjacent WTs have some correlation although the wake effect on downstream turbines sometimes exists, our method uses the power output data of every WT in a farm to estimate the amount of degraded power performance of each turbine by the introduction of the virtual variable which corresponds to each turbine's degraded amount. The feature of the correlation among each WT's non-degradation data was learned by a denoising autoencoder (DAE). The virtual variables along with the power output are fed into the trained DAE model and these variables were updated by minimizing the reconstruction error. Moreover, the proposed method can perform the estimation even when some WTs are down, i.e., due to the periodical maintenance, and can classify between non-degraded and degraded WTs without enforcing diagnostics to set suitable threshold parameters. We demonstrated the superiority of this novel method over traditional methods by using real and artificial data inputs.","","978-1-5386-8357-6","10.1109/ICPHM.2019.8819375","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8819375","","Degradation;Wind turbines;Correlation;Data models;Wind farms;Wind power generation;Conferences","anemometers;blades;maintenance engineering;neural nets;wakes;wind power plants;wind turbines","wind farm;denoising autoencoder model;wind turbines;turbine blade damage;anemometer;nacelle;wake effect;maintenance method","","1","","19","","29 Aug 2019","","","IEEE","IEEE Conferences"
"A Stacked Denoising Autoencoder and Long Short-Term Memory Approach With Rule-Based Refinement to Extract Valid Semantic Trajectories","Y. Yustiawan; H. Ramadhan; J. Kwon","Department of Big Data, Pusan National University, Busan, South Korea; Department of Big Data, Pusan National University, Busan, South Korea; School of Computer Science and Engineering, Pusan National University, Busan, South Korea","IEEE Access","21 May 2021","2021","9","","73152","73168","Indoor location-based services have been widely investigated to take advantage of semantic trajectories for providing user oriented services in indoor environments. Although indoor semantic trajectories can provide seamless understanding to users regarding the provided location-based services, studies on the application of deep learning approaches for robust and valid semantic indoor localization are lacking. In this study, we combined a stacked denoising autoencoder and long short term memory technique with a rule-based refinement method applying a rule-based hidden Markov model (HMM) to perform robust and valid semantic trajectory extraction. In particular, our rule-based HMM approach incorporates a direct set of rules into HMM to resolve invalid movements of the extracted semantic trajectories and is extensible to various deep learning techniques. We compared the performance of our proposed approach with that of other cutting-edge deep learning approaches on two different real-world data sets. The experimental results demonstrate the feasibility of our proposed approach to produce more robust and valid semantic trajectories.","2169-3536","","10.1109/ACCESS.2021.3080288","Basic Science Research Program through the National Research Foundation of Korea (NRF) by the Ministry of Education(grant numbers:NRF-2020R1I1A3072457); Institute of Information and Communications Technology Planning and Evaluation (IITP) Grant by the Korean Government through Ministry of Science and ICT (MSIT) (Development of data improvement and dataset correction technology based on data quality assessment)(grant numbers:2020-0-00121); Ministry of Science and ICT (MSIT) through the Information Technology Research Center (ITRC) Support Program supervised by the Institute of Information and Communications Technology Planning and Evaluation (IITP)(grant numbers:IITP-2020-0-01797); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9431193","Deep learning;indoor localization;the Internet of Things;rule-based refinement;semantic trajectories","Semantics;Trajectory;Location awareness;Hidden Markov models;Deep learning;Noise measurement;Indoor environment","deep learning (artificial intelligence);hidden Markov models;knowledge based systems;location based services;recurrent neural nets","hidden Markov model;semantic indoor localization;cutting-edge deep learning approach;indoor semantic trajectories;user oriented services;indoor location-based services;long short-term memory approach;stacked denoising autoencoder;rule-based HMM approach;semantic trajectory extraction;robust trajectory extraction;rule-based refinement method","","1","","42","CCBY","14 May 2021","","","IEEE","IEEE Journals"
"Model Predictive Control implementation on neural networks using denoising autoencoder","D. Ushida; E. Konaka","School of Science and Technology, Meijo University, Nagoya, JAPAN; School of Science and Technology, Meijo University, Nagoya, JAPAN","2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","9 Feb 2017","2016","","","000149","000154","Model Predictive Control (MPC) is an effective control method for nonlinear control systems including quantized control systems; however, the optimization process requires huge computation for such cases and is therefore hard to realize. In this study, a controller design method based on a machine learning technique, in particular a neural network with denoising autoencoder (DAE), is proposed. The simulation results show that the neural controller emulates the behaviors of MPC. The mean and standard deviation of the control result are improved by applying DAE, compared to simple neural network. The proposed method requires short computation time, shorter than 1[ms], therefore it can be applied to fast mechanical control systems with nonlinear characteristics where MPC requires 100[ms] or longer.","","978-1-5090-1897-0","10.1109/SMC.2016.7844234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7844234","","Neural networks;Training data;Control systems;Noise reduction;Mathematical model;Training","control system synthesis;learning (artificial intelligence);neurocontrollers;nonlinear control systems;optimisation;predictive control","model predictive control;neural networks;denoising autoencoder;MPC;nonlinear control systems;quantized control systems;optimization;controller design method;machine learning technique;mechanical control systems","","1","","13","","9 Feb 2017","","","IEEE","IEEE Conferences"
"Stacked Denoising Autoencoder network for short-term prediction of electrical Algerian load","C. Hiba; K. M. Tarek; C. Belkacem","Laboratoire de Gestion Electronique de Documents, Université Badji Mokhtar Annaba; Laboratoire de Gestion Electronique de Documents, Université Badji Mokhtar Annaba; Département Science, LICEF Research Institute, Technologie Université TÉLUQ 5800","2020 7th International Conference on Control, Decision and Information Technologies (CoDIT)","27 Nov 2020","2020","1","","189","194","Short-term load forecasting is a topic of considerable interest; it ensures the balance between the production and consumption one day ahead. In this paper, time series models have been developed to provide an efficient forecast for electricity consumption in Algeria using Deep Neural Networks in the form of Stacked Denoising Autoencoder (SDAE) and a regular Multilayer Perceptron (MLP) as a benchmark model. The obtained models are established and evaluated using the hourly temperature and electricity consumption data provided by the Algerian National Electricity and Gas Company (SONELGAZ). Convincing forecasting results for the Algerian national load were found and conclusions drawn.","2576-3555","978-1-7281-5953-9","10.1109/CoDIT49905.2020.9263850","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9263850","short-term load forecasting;electricity consumption;time series;autoregressive variable;MLP;SDAE","Time series analysis;Load modeling;Biological system modeling;Neural networks;Temperature distribution;Forecasting;Predictive models","learning (artificial intelligence);load forecasting;multilayer perceptrons;power consumption;power engineering computing;time series","stacked denoising autoencoder network;short-term load forecasting;time series models;deep neural networks;multilayer perceptron;electricity consumption data;Algerian national load;electrical Algerian load short-term prediction;SONELGAZ;Algerian National Electricity and Gas Company;MLP","","1","","15","","27 Nov 2020","","","IEEE","IEEE Conferences"
"Cell Subtype Classification via Representation Learning Based on a Denoising Autoencoder for Single-Cell RNA Sequencing","J. Choi; J. -K. Rhee; H. Chae","Division of Computer Science, Sookmyung Women's University, Seoul, Republic of Korea; School of Systems Biomedical Science, Soongsil University, Seoul, Republic of Korea; Division of Computer Science, Sookmyung Women's University, Seoul, Republic of Korea","IEEE Access","26 Jan 2021","2021","9","","14540","14548","Identification of single-cell subtypes is one of the fundamental processes required to understand a heterogeneous population composed of multiple cells, based on single-cell RNA sequencing data. Previously, cell subtype identification was mainly carried out by dimension reduction and clustering approaches that grouped cells with similar expressed profiles together. However, for high robustness to noises and systematic annotation of the subtype in each cell, supervised classification approaches have been widely used. Recently, deep neural network (DNN) models have been widely presented in various fields, including biology. By capturing the composite relationship between sample features and target outcomes, a DNN model enables significant performance improvements in biological data mining analyses. In this paper, we constructed a DNN model, called scDAE for single-cell subtype identification combined with representative feature extraction using a multilayer denoising autoencoder (DAE). The feature sets were learned by the DAE and were further tuned by fully connected layers using a softmax classifier. The model was compared against four state-of-the-art cell subtype identification methods and two conventional machine learning algorithms. From multiple tests, scDAE significantly outperformed competing methods especially on data sets having a large number of cell subtypes and noises. Extracted cell features from the proposed model were clearly clustered with respect to subtype. The results of the experiments indicated that our proposed model is effective in identifying single-cell subtypes and molecular signatures representative of each cell subtype. scDAE is publicly available at https://github.com/cbi-bioinfo/scDAE.","2169-3536","","10.1109/ACCESS.2021.3052923","Bio and Medical Technology Development Program of the National Research Foundation (NRF) funded by the Ministry of Science and ICT (MSIT), Korean Government(grant numbers:2019M3E5D3073365); Agenda Project of the Rural Development Administration, Republic of Korea(grant numbers:PJ0143072019); National Research Foundation of Korea (NRF) funded by MSIT, Republic of Korea(grant numbers:NRF-2018R1C1B6005304); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9328422","Cell subtype;classification;gene expression;scRNA-seq;single-cell","Feature extraction;Gene expression;Biology;Data models;Biological system modeling;RNA;Neural networks","bioinformatics;data mining;deep learning (artificial intelligence);feature extraction;genetics;genomics;pattern classification;pattern clustering;RNA;supervised learning","biological data mining analyses;DNN;single-cell subtype identification;cell feature extraction;single-cell subtypes;cell subtype classification;multiple cells;single-cell RNA sequencing data;supervised classification;deep neural network;representation learning;denoising autoencoder;dimension reduction;dimension clustering;machine learning;softmax classifier","","","","58","CCBY","19 Jan 2021","","","IEEE","IEEE Journals"
"MIMO Speech Compression and Enhancement Based on Convolutional Denoising Autoencoder","Y. -J. Li; S. -S. Wang; Y. Tsao; B. Su","Graduate Institute of Communication Engineering, National Taiwan University, Taiwan; Department of Electrical Engineering, Yuan Ze University, Taoyuan, Taiwan; Academia Sinica, Research Center for Information Technology Innovation, Taipei, Taiwan; Graduate Institute of Communication Engineering, National Taiwan University, Taiwan","2021 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","3 Feb 2022","2021","","","1245","1250","For speech-related applications in Internet of things environments, identifying effective methods to handle interference noises and compress the amount of data in transmissions is essential for achieving high-quality services. In this paper, we propose a novel multi-input multi-output speech compression and enhancement (MIMO-SCE) system based on a convolutional denoising autoencoder (CDAE) model to simultaneously improve speech quality and reduce the dimension of transmission data. Compared with conventional single-channel and multiinput single-output systems, MIMO systems can be employed for applications where multiple acoustic signals need to be handled. We investigated two CDAE models, fully convolutional network (FCN) and Sinc FCN, as the core models in MIMO systems. The experimental results confirm that the proposed MIMO-SCE framework effectively improves speech quality and intelligibility, and reduces the amount of recording data to one-seventh for transmission.","2640-0103","978-988-14768-9-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9689657","","Visualization;Convolution;Noise reduction;Data compression;Speech enhancement;Data models;Reproducibility of results","acoustic signal processing;feature extraction;learning (artificial intelligence);MIMO communication;MIMO systems;speech coding","MIMO speech compression;speech-related applications;things environments;interference noises;high-quality services;novel multiinput multioutput speech compression;convolutional denoising autoencoder model;speech quality;transmission data;conventional single-channel;single-output systems;MIMO systems;CDAE models;fully convolutional network;core models;MIMO-SCE framework","","","","54","","3 Feb 2022","","","IEEE","IEEE Conferences"
"Classification of Alzheimer's Disease Based on Stacked Denoising Autoencoder","T. Zheng-Lin; W. Hai-Xing; Y. Shao-Xun; S. Xiao; X. Jian-Ming","State Key Laboratory of Bioelectronics, Southeast University, Nanjing, P. R. China; State Key Laboratory of Bioelectronics, Southeast University, Nanjing, P. R. China; State Key Laboratory of Bioelectronics, Southeast University, Nanjing, P. R. China; State Key Laboratory of Bioelectronics, Southeast University, Nanjing, P. R. China; State Key Laboratory of Bioelectronics, Southeast University, Nanjing, P. R. China","2018 4th Annual International Conference on Network and Information Systems for Computers (ICNISC)","19 Sep 2019","2018","","","248","253","Alzheimer's disease (AD) is a typical chronic neurodegenerative disease. Mild cognitive impairment (MCI) is a transitional stage between health and AD. Early diagnosis and early treatment can significantly prolong the survival of patients with Alzheimer's disease. By mining gene expression data and extracting the expression pattern of AD/MCI related genes, it is of great significance for early detection of AD. Here we applied a three-layer stacked denoising autoencoder (SDAE), which is a promising approach extract useful features, to the gene expression data of AD patients in the database of Alzheimer's Disease Neuroimaging Initiative (ADNI). By optimizing numbers of hidden layer nodes and corruption levels, we constructed a model with low loss. Using the features generated from SDAE, an SVM classifier was constructed to classify health status and AD/MCI samples. Results showed that the characteristics of SDAE were significantly better for the classification of AD than the raw gene expression data. Different hidden layer of SDAE was able to extract different dimensional features. Integrating all the three-layer features, the classification accuracy of 744 samples in the ADNI dataset reached 100% in 10-fold cross validation.","","978-1-5386-6956-3","10.1109/ICNISC.2018.00056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8842983","Alzheimer's Disease;Gene Expression;Autoencode;SVM","Gene expression;Feature extraction;Support vector machines;Alzheimer's disease;Noise reduction;Kernel","cognition;data mining;diseases;feature extraction;genetics;image classification;medical disorders;medical image processing;neurophysiology;patient diagnosis;pattern classification;support vector machines","raw gene expression data;SDAE;three-layer features;typical chronic neurodegenerative disease;mild cognitive impairment;early treatment;expression pattern;three-layer stacked denoising autoencoder;AD patients;hidden layer nodes;AD-MCI related genes;Alzheimers disease neuroimaging initiative;ADNI;SVM classifier","","","","14","","19 Sep 2019","","","IEEE","IEEE Conferences"
"Assessment of Wind Power Ramp Events Based on Stacked Denoising Autoencoder","Z. Liang; Y. Liu; X. Liu; X. Cao; L. Zhang; H. Wu; Q. Zhang; M. Yang","Key Laboratory of Power System Intelligent Dispatch and Control, (Shandong University) Ministry of Education, Jinan, China; Key Laboratory of Power System Intelligent Dispatch and Control, (Shandong University) Ministry of Education, Jinan, China; State Grid Shandong Electric Power Company, Economic & Technology Research Institute, Jinan, China; State Grid Shandong Electric Power Company, Economic & Technology Research Institute, Jinan, China; State Grid Jiangsu Electric Power Company, Nanjing, China; State Grid Jiangsu Electric Power Company, Nanjing, China; State Grid Jiangsu Electric Power Company, Nanjing, China; State Grid Jiangsu Electric Power Company, Nanjing, China","2019 IEEE 8th International Conference on Advanced Power System Automation and Protection (APAP)","15 Oct 2020","2019","","","1031","1035","Wind power ramp events had a significant impact on the power balance of power system and may lead to load shedding. A data driven method was proposed for wind power ramp events assessment in this paper. The K-means clustering algorithm was used to divide the samples to several classes. The stacked denoising autoencoder was used to extract layer features to train support vector machine. Historical and forecast data of wind power, load power, conventional unit and pumped storage station power were taken as inputs. The output was whether ramp event occurred. A severity function was constructed to assess the severity grade which was predicted to be a wind power ramp event based on effect theory. The credibility of the assessment result was represented by confidence interval. Simulation results of a provincial power grid showed that the prediction method in this paper was more accurate and credibility was high enough to help the dispatchers to take measures for the security of power grid.","","978-1-7281-1722-5","10.1109/APAP47170.2019.9225188","State Grid Corporation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9225188","deep learning;K-means clustering algorithm;power system;wind power ramping;severity grading","Wind power generation;Feature extraction;Support vector machines;Power grids;Security;Prediction algorithms;Clustering algorithms","load shedding;neural nets;pattern clustering;power grids;pumped-storage power stations;support vector machines;wind power plants","confidence interval;provincial power grid;storage station power;load power;wind power ramp events assessment;power system;power balance;stacked denoising autoencoder;wind power ramp event","","","","10","","15 Oct 2020","","","IEEE","IEEE Conferences"
"Autoencoder Based Network Anomaly Detection","M. Ganesh; A. Kumar; V. Pattabiraman","School of Computer Science Engineering, Vellore Institute of Technology, Chennai, India; School of Computer Science Engineering, Vellore Institute of Technology, Chennai, India; School of Computer Science Engineering, Vellore Institute of Technology, Chennai, India","2020 IEEE International Conference on Technology, Engineering, Management for Societal impact using Marketing, Entrepreneurship and Talent (TEMSMET)","6 Oct 2021","2020","","","1","6","Network security is one of the most critical fields of computer science. With the advent of IoT technologies and peer-to-peer networks, the significance of mitigating security threats has never been higher. Network Intrusion Detection Systems are used to monitor the traffic in a network to detect any malicious or anomalous behavior. Anomalous behaviour includes different types of attacks such as Denial of Service (DoS), Probe, Remote-to-Local and User-to-Root. If an attack/anomaly is detected, custom alerts can be sent to the desired personals. In this paper, we explored the effectiveness of various types of Autoencoders in detecting network intrusions. Artificial Neural Networks can parse through vast amounts of data to detect various types of anomalies and classify them accordingly. An autoencoder is a type of artificial neural network which can learn both linear and non-linear representations of the data, and use the learned representations to reconstruct the original data. These hidden representations are different from the ones attained by Principal Component Analysis due to the presence of nonlinear activation functions in the network. Reconstruction error (the measure of difference between the original input and the reconstructed input) is generally used to detect anomalies if the autoencoder is trained on normal network data. Here, we compared the performance of 4 different autoencoders on the NLS-KDD dataset to detect attacks in the network. With just reconstruction error, we were able to achieve an accuracy of 89.34% by using a Sparse Deep Denoising Autoencoder.","","978-1-6654-0482-2","10.1109/TEMSMET51618.2020.9557464","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9557464","Network Intrusion Detection;Artificial Neural Network;Autoencoders;Anomaly Detection;Reconstruction","Noise reduction;Measurement uncertainty;Network intrusion detection;Artificial neural networks;Network security;Peer-to-peer computing;Probes","neural nets;principal component analysis;security of data","network anomaly Detection;network security;computer science;IoT technologies;peer-to-peer networks;security threats;network intrusion detection systems;malicious behavior;anomalous behaviour;artificial neural network;nonlinear representations;learned representations;reconstruction error;normal network data;sparse deep denoising autoencoder;principal component analysis;nonlinear activation functions","","","","13","","6 Oct 2021","","","IEEE","IEEE Conferences"
"A Class Incremental Learning Approach Based on Autoencoder Without Manual Feature Extraction for Rail Vehicle Fault Diagnosis","J. Kang; Z. Liu; W. Sun; M. J. Zuo; Y. Qin","School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; State Key Laboratory of Rail Traffic Control and Safety, Beijing Jiaotong University, Beijing; School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Mechanical Engineering, University of Alberta, Edmonton, Alberta, Canada; Beijing Jiaotong University, Beijing, Beijing, CN","2018 Prognostics and System Health Management Conference (PHM-Chongqing)","6 Jan 2019","2018","","","45","49","Traditional intelligent diagnosis methods and current popular deep learning based diagnosis methods basically adopt the approach of batch learning, which may waste time and computing resources since they need to discard the previous learned model and retrain a new model based on the newly added data and prior data. Moreover, manual feature extraction is often a necessary step for intelligent diagnosis, and such a process relies much on prior knowledge. To solve the above mentioned problems, this paper proposes a fault diagnosis method based on class incremental learning without manual feature extraction. Based on denoising autoencoder, the proposed method obtains the autoencoders using the raw data acquired for each health state. In the class incremental learning process, only the autoencoder of new health state need to be trained while the former trained autoencoders are retained. Test data is classified according to the minimal reconstruction error calculated through the autoencoders. At the end of this paper, the proposed method is validated through vibration data of rolling bearings for rail vehicle. The experimental results show that the presented method is effective.","2166-5656","978-1-5386-5380-7","10.1109/PHM-Chongqing.2018.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8603322","fault diagnosis;bearing;incremental learning;autoencoder;rail vehicle;automatic feature extraction","Feature extraction;Noise reduction;Support vector machines;Fault diagnosis;Data models;Rolling bearings;Axles","condition monitoring;fault diagnosis;feature extraction;learning (artificial intelligence);railway engineering;rolling bearings","manual feature extraction;rail vehicle fault diagnosis;batch learning;denoising autoencoder;class incremental learning process;vibration data;intelligent diagnosis methods;deep learning;rolling bearings;health state","","","","17","","6 Jan 2019","","","IEEE","IEEE Conferences"
"Unsupervised Real Image Super-Resolution via Generative Variational AutoEncoder","Z. -S. Liu; W. -C. Siu; L. -W. Wang; C. -T. Li; M. -P. Cani; Y. -L. Chan","The Hong Kong Polytechnic University; The Hong Kong Polytechnic University; The Hong Kong Polytechnic University; The Hong Kong Polytechnic University; LIX, École polytechnique; The Hong Kong Polytechnic University","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","28 Jul 2020","2020","","","1788","1797","Benefited from the deep learning, image Super-Resolution has been one of the most developing research fields in computer vision. Depending upon whether using a discriminator or not, a deep convolutional neural network can provide an image with high fidelity or better perceptual quality. Due to the lack of ground truth images in real life, people prefer a photo-realistic image with low fidelity to a blurry image with high fidelity. In this paper, we revisit the classic example based image super-resolution approaches and come up with a novel generative model for perceptual image super-resolution. Given that real images contain various noise and artifacts, we propose a joint image denoising and super-resolution model via Variational AutoEncoder. We come up with a conditional variational autoencoder to encode the reference for dense feature vector which can then be transferred to the decoder for target image denoising. With the aid of the discriminator, an additional overhead of super-resolution subnetwork is attached to super-resolve the denoised image with photo-realistic visual quality. We participated the NTIRE2020 Real Image Super-Resolution Challenge [24] . Experimental results show that by using the proposed approach, we can obtain enlarged images with clean and pleasant features compared to other supervised methods. We also compared our approach with state-of-the-art methods on various datasets to demonstrate the efficiency of our proposed unsupervised super-resolution model.","2160-7516","978-1-7281-9360-1","10.1109/CVPRW50498.2020.00229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9150958","","Noise reduction;Training;Mathematical model;Spatial resolution;Decoding;Distortion","computer vision;feature extraction;image classification;image denoising;image reconstruction;image resolution;learning (artificial intelligence);neural nets;realistic images","ground truth images;photo-realistic image;blurry image;perceptual image super-resolution;super-resolution model;image denoising;generative variational autoencoder;NTIRE2020 Real Image Super-Resolution Challenge","","8","","38","","28 Jul 2020","","","IEEE","IEEE Conferences"
"An Overview of Unsupervised Deep Feature Representation for Text Categorization","S. Wang; J. Cai; Q. Lin; W. Guo","Fujian Provincial Key Laboratory of Network Computing and Intelligent Information Processing, Fuzhou University, Fuzhou, China; Fujian Provincial Key Laboratory of Network Computing and Intelligent Information Processing, Fuzhou University, Fuzhou, China; Fujian Provincial Key Laboratory of Network Computing and Intelligent Information Processing, Fuzhou University, Fuzhou, China; Fujian Provincial Key Laboratory of Network Computing and Intelligent Information Processing, Fuzhou University, Fuzhou, China","IEEE Transactions on Computational Social Systems","10 Jun 2019","2019","6","3","504","517","High-dimensional features are extensively accessible in machine learning and computer vision areas. How to learn an efficient feature representation for specific learning tasks is invariably a crucial issue. Due to the absence of class label information, unsupervised feature representation is exceedingly challenging. In the last decade, deep learning has captured growing attention from researchers in a broad range of areas. Most of the deep learning methods are supervised, which is required to be fed with a large amount of accurately labeled data points. Nevertheless, acquiring sufficient accurately labeled data is unaffordable in numerous real-world applications, which is suggestive of the needs of unsupervised learning. Toward this end, quite a few unsupervised feature representation approaches based on deep learning have been proposed in recent years. In this paper, we attempt to provide a comprehensive overview of unsupervised deep learning methods and compare their performances in text categorization. Our survey starts with the autoencoder and its representative variants, including sparse autoencoder, stacked autoencoder, contractive autoencoder, denoising autoencoder, variational autoencoder, graph autoencoder, convolutional autoencoder, adversarial autoencoder, and residual autoencoder. Aside from autoencoders, deconvolutional networks, restricted Boltzmann machines, and deep belief nets are introduced. Then, the reviewed unsupervised feature representation methods are compared in terms of text clustering. Extensive experiments in eight publicly available data sets of text documents are conducted to provide a fair test bed for the compared methods.","2329-924X","","10.1109/TCSS.2019.2910599","National Natural Science Foundation of China(grant numbers:U1705262,61672159); Technology Innovation Platform Project of Fujian Province(grant numbers:2014H2005,2009J1007); Fujian Collaborative Innovation Center for Big Data Application in Governments; Fujian Engineering Research Center of Big Data Analysis and Processing; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8700490","Autoencoder;deconvolutional network;deep belief nets;deep learning;feature representation;text categorization;unsupervised learning","Biological neural networks;Deep learning;Decoding;Task analysis;Optimization;Unsupervised learning;Neurons","belief networks;Boltzmann machines;computer vision;feature extraction;text analysis;unsupervised learning","unsupervised deep feature representation;text categorization;high-dimensional features;machine learning;computer vision areas;class label information;accurately labeled data points;unsupervised deep learning methods;sparse autoencoder;stacked autoencoder;contractive autoencoder;variational autoencoder;graph autoencoder;convolutional autoencoder;adversarial autoencoder;residual autoencoder;deep belief nets;reviewed unsupervised feature representation methods;feature representation;restricted Boltzmann machines","","17","","93","IEEE","26 Apr 2019","","","IEEE","IEEE Journals"
"Exploring the Use of Autoencoders for Botnets Traffic Representation","R. Dargenio; S. Srikant; E. Hemberg; U. -M. O'Reilly","CSAIL, MIT; CSAIL, MIT; CSAIL, MIT; CSAIL, MIT","2018 IEEE Security and Privacy Workshops (SPW)","6 Aug 2018","2018","","","57","62","Botnets are a significant threat to cyber security. Compromised, a.k.a. malicious hosts in a network have, of late, been detected by machine learning from hand-crafted features directly sourced from different types of network logs. Our interest is in automating feature engineering while examining flow data from hosts labeled to be malicious or not. To automatically express full temporal character and dependencies of flow data requires time windowing and a very high dimensional set of features, in our case 30,000. To reduce dimensionality, we generate a lower dimensional embedding (64 dimensions) via autoencoding. This improves detection. We next increase the volume in the flows originating from hosts in our dataset known to be malicious or not by injecting noise we mix in from background traffic. The resulting lower metaphorical signal to noise ratio makes the presence of a bot even more challenging to detect so we resort to a filter encoder or an off-the-shelf denoising autoencoder. Both the filter encoding and denoising autoencoder improve upon detection compared to when hand-crafted features are used and are comparable in performance to the autoencoder.","","978-1-5386-8276-0","10.1109/SPW.2018.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8424633","Botnet;autoencoder;netflow","Feature extraction;Botnet;Windows;Noise measurement;Machine learning;Computer security;Signal to noise ratio","invasive software;learning (artificial intelligence)","malicious hosts;machine learning;network logs;temporal character;time windowing;autoencoding;background traffic;filter encoder;off-the-shelf denoising autoencoder;filter encoding;botnets traffic representation;feature engineering;metaphorical signal","","2","","15","","6 Aug 2018","","","IEEE","IEEE Conferences"
"Modulation recognition of emitter signals based on SDAE-ODCNN","X. Wang; J. Gao; L. Gao; F. Wang","Harbin Engineering University, College of Information and Communication Engineering, Harbin, China; Harbin Engineering University, College of Information and Communication Engineering, Harbin, China; Beijing Institute of Space Long March Vehicle, National Key Laboratory of Science and Technology on Test Physics and Numerical Mathematics, Beijing, China; Harbin Engineering University, College of Information and Communication Engineering, Harbin, China","IET International Radar Conference (IET IRC 2020)","22 Sep 2021","2020","2020","","1302","1307","In order to improve the recognition rate of emitter signals modulation under low signal noise ratio (SNR), an end-to-end method based on the stacked denoising autoencoder (SDAE) - one dimensional convolutional neural network (ODCNN) is proposed in this paper. The SADE-ODCNN is designed in this method and trained through a two-step training. In the SDAE-ODCNN model, the encoder of the SDAE can extract the denoised and compressed features of the received emitter signals. Then the ODCNN can further extract features to realize the recognition. The simulation results show that the average recognition rate of the method can reach 0.94 under 0dB. Thus the proposed method has a good application in the field of emitter signals modulation recognition.","","","10.1049/icp.2021.0642","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9545607","","","feature extraction;image classification;image denoising;learning (artificial intelligence);modulation;neural nets;radar computing","stacked denoising autoencoder;dimensional convolutional neural network;SADE-ODCNN;two-step training;SDAE-ODCNN model;denoised compressed features;received emitter signals;average recognition rate;emitter signals modulation recognition;low signal noise ratio;end-to-end method","","","","","","22 Sep 2021","","","IET","IET Conferences"
"Intelligent Fault Diagnosis of Rotating Machines Based on Wavelet Time-Frequency Diagram and Optimized Stacked Denoising Auto-Encoder","N. Jia; Y. Cheng; Y. Liu; Y. Tian","Chongqing University of Technology, Chongqing, China; Chongqing University of Technology, Chongqing, China; Chongqing University of Technology, Chongqing, China; Chongqing University of Technology, Chongqing, China","IEEE Sensors Journal","1 Sep 2022","2022","22","17","17139","17150","When a stacked denoising auto-encoder (SDAE) manually sets several parameters, the gradient of neuron weight becomes dispersed, reducing the ability to retrieve sensitive fault feature information from a bearing vibration signal under multiple working conditions and strong noise. A bearing health monitoring and defect diagnostic model based on variational mode decomposition (VMD) combined with continuous wavelet transform (CWT) and SDAE optimized by sparrow search algorithm (SSA) is presented to tackle this problem. The wavelet time-frequency diagram is obtained by VMD and CWT, which maps the fault characteristic information to different local positions in time and scale, and then the wavelet time-frequency diagrams are input into the SDAE for in-depth training. To achieve the ideal structure of SDAE and increase the feature extraction capabilities of SDAE for weak signals, SSA is utilized for the global combination and adaptive selection of several SDAE parameters. The bearing failure diagnostic model based on VMD-CWT-SSA-SDAE outperforms BPNN, SVM, the traditional SDAE, GA-SDAE, PSO-SDAE, and SSA-DBN in diagnosis accuracy, generalization performance, and anti-noise performance when tested on various data sets.","1558-1748","","10.1109/JSEN.2022.3193943","Chongqing Research Fund(grant numbers:cstc2016jcyjA0497); Graduate Student Innovation Program of Chongqing University of Technology(grant numbers:clgycx 20202088,CYS22653); Graduate Student Innovation Program of Chongqing(grant numbers:CYS21464); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9846870","Rotating machines;fault diagnosis;the wavelet time-frequency diagram;sparrow search algorithm;stacked denoising auto-encoder","Feature extraction;Time-frequency analysis;Fault diagnosis;Continuous wavelet transforms;Wavelet transforms;Optimization;Vibrations","condition monitoring;fault diagnosis;feature extraction;information retrieval;machine bearings;neural nets;search problems;signal denoising;support vector machines;vibrational signal processing;vibrations;wavelet transforms","bearing failure diagnostic model;VMD-CWT-SSA-SDAE;GA-SDAE;PSO-SDAE;intelligent fault diagnosis;wavelet time-frequency diagram;bearing vibration signal;bearing health monitoring;continuous wavelet;stacked denoising autoencoder optimization;sensitive fault feature information retrieval;continuous wavelet transform;CWT;rotating machines;variational mode decomposition;sparrow search algorithm;feature extraction","","","","31","IEEE","1 Aug 2022","","","IEEE","IEEE Journals"
"Filter Guided Manifold Optimization in the Autoencoder Latent Space","N. Lannan; G. Fan","School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, OK; School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, OK","2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","9 Apr 2020","2019","","","949","955","An autoencoder is a class of neural network that is trained to output an accurate reproduction of the input while learning key lower dimensional features, otherwise known as a manifold. A lower dimensional representation of the original input, referred to as the latent space, encodes the intrinsic data structure over the manifold. This paper proposes filter-guided manifold optimization in the latent space of a convolutional autoencoder to recover noisy motion data collected by a depth sensor. Autoencoder output is smoothed using four traditional filters and employed as target motion data in an objective function. The difference between the actual output and target is minimized through stochastic gradient descent over the latent space, using manifold optimization to produce the expected smooth output. The advantage of this filter-guided approach over traditional filtering is that the resultant motion data still adheres to the manifold in the latent space learned by the autoencorder from training on motion data.","2160-7516","978-1-7281-2506-0","10.1109/CVPRW.2019.00125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9025685","","Skeleton;Manifolds;Kernel;Optimization;Neural networks;Kalman filters;Noise measurement","data structures;encoding;feature extraction;gradient methods;image denoising;image motion analysis;learning (artificial intelligence);neural nets","stochastic gradient descent;filter-guided manifold optimization;resultant motion data;expected smooth output;target motion data;autoencoder output;noisy motion data;convolutional autoencoder;manifold optimization;intrinsic data structure;lower dimensional representation;key lower dimensional features;autoencoder latent space","","5","","18","","9 Apr 2020","","","IEEE","IEEE Conferences"
"HDR Image Compression with Convolutional Autoencoder","F. Han; J. Wang; R. Xiong; Q. Zhu; B. Yin","Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Institute of Digital Media, Peking University, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China","2020 IEEE International Conference on Visual Communications and Image Processing (VCIP)","29 Dec 2020","2020","","","25","28","As one of the next-generation multimedia technology, high dynamic range (HDR) imaging technology has been widely applied. Due to its wider color range, HDR image brings greater compression and storage burden compared with traditional LDR image. To solve this problem, in this paper, a two-layer HDR image compression framework based on convolutional neural networks is proposed. The framework is composed of a base layer which provides backward compatibility with the standard JPEG, and an extension layer based on a convolutional variational autoencoder neural networks and a post-processing module. The autoencoder mainly includes a nonlinear transform encoder, a binarized quantizer and a nonlinear transform decoder. Compared with traditional codecs, the proposed CNN autoencoder is more flexible and can retain more image semantic information, which will improve the quality of decoded HDR image. Moreover, to reduce the compression artifacts and noise of reconstructed HDR image, a post-processing method based on group convolutional neural networks is designed. Experimental results show that our method outperforms JPEG XT profile A, B, C and other methods in terms of HDR-VDP-2 evaluation metric. Meanwhile, our scheme also provides backward compatibility with the standard JPEG.","2642-9357","978-1-7281-8068-7","10.1109/VCIP49819.2020.9301853","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9301853","","Image reconstruction;Image coding;Transform coding;Decoding;Convolutional codes;Standards;Neural networks","codecs;convolutional neural nets;data compression;image coding;image denoising;image reconstruction","two-layer HDR image compression framework;backward compatibility;standard JPEG;convolutional variational autoencoder neural networks;post-processing module;traditional codecs;CNN autoencoder;image semantic information;decoded HDR image;compression artifacts;reconstructed HDR image;post-processing method;group convolutional neural networks;HDR-VDP-2 evaluation metric;convolutional autoencoder;next-generation multimedia technology;high dynamic range imaging technology;HDR image compression;binarized quantizer;nonlinear transform decoder","","","","15","","29 Dec 2020","","","IEEE","IEEE Conferences"
"Joint visual denoising and classification using deep learning","G. Chen; Y. Li; S. N. Srihari","Department of Computer Science, Buffalo, NY; School of Communication and Information Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; Department of Computer Science, Buffalo, NY","2016 IEEE International Conference on Image Processing (ICIP)","19 Aug 2016","2016","","","3673","3677","Visual restoration and recognition are traditionally addressed in pipeline fashion, i.e. denoising followed by classification. Instead, observing correlations between the two tasks, for example clearer image will lead to better categorization and vice visa, we propose a joint framework for visual restoration and recognition for handwritten images, inspired by advances in deep autoencoder and multi-modality learning. Our model is a 3-pathway deep architecture with a hidden-layer representation which is shared by multi-inputs and outputs, and each branch can be composed of a multi-layer deep model. Thus, visual restoration and classification can be unified using shared representation via non-linear mapping, and model parameters can be learnt via backpropagation. Using MNIST and USPS data corrupted with structured noise, the proposed framework performs at least 20% better in classification than separate pipelines, as well as clearer recovered images.","2381-8549","978-1-4673-9961-6","10.1109/ICIP.2016.7533045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7533045","","Image restoration;Noise reduction;Visualization;Noise measurement;Machine learning;Image recognition;Training","backpropagation;handwritten character recognition;image classification;image denoising;image restoration;text detection","joint visual denoising;deep learning;visual restoration;visual recognition;pipeline fashion;image denoising;image classification;handwritten image recognition;deep autoencoder;multimodality learning;3-pathway deep architecture;hidden-layer representation;nonlinear mapping;backpropagation;MNIST data;USPS data","","5","1","22","","19 Aug 2016","","","IEEE","IEEE Conferences"
"Senone I-vectors for robust speaker verification","Z. Tan; Y. Zhu; M. -W. Mak; B. K. -W. Mak","Dept. of Electronic and Information Engineering, The Hong Kong Polytechnic University; Dept. of Computer Science and Engineering, The Hong Kong University of Science and Technology; Dept. of Electronic and Information Engineering, The Hong Kong Polytechnic University; Dept. of Computer Science and Engineering, The Hong Kong University of Science and Technology","2016 10th International Symposium on Chinese Spoken Language Processing (ISCSLP)","4 May 2017","2016","","","1","5","Recent research has shown that using senone posteriors for i-vector extraction can achieve outstanding performance. In this paper, we extend this idea to robust speaker verification by constructing a deep neural network (DNN) comprising a deep belief network (DBN) stacked on top of a denoising autoencoder (DAE). The proposed method addresses noise robustness in two perspectives: (1) denoising the MFCC vectors through the DAE and (2) extracting noise robust bottleneck (BN) features and senone posteriors from the DBN for total-variability matrix training and i-vector extraction. The DAE comprises several layers of restricted Boltzmann machines (RBM), which are trained to minimize the mean squared error between the denoised and clean MFCCs. After training the DAE, three layers of RBMs are put on top of it to form the DNN. The whole network is fine-tuned by backpropagation to minimize the cross-entropy between the senone labels and network outputs. This architecture allows us to extract BN features and estimates senone posteriors given noisy MFCCs as input, resulting in robust BN-based senone i-vectors. Results on NIST 2012 SRE show that these senone i-vectors outperform the conventional i-vectors and the BN-based i-vectors in which the posteriors are obtained from a GMM.","","978-1-5090-4294-4","10.1109/ISCSLP.2016.7918462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7918462","speaker verification;i-vectors;senone posteriors;deep learning;denoising autoencoders","Feature extraction;Noise reduction;Speech;Mel frequency cepstral coefficient;Training;Noise measurement","belief networks;Boltzmann machines;feature extraction;matrix algebra;mean square error methods;neural nets;signal denoising;speaker recognition;vectors","robust speaker verification;senone i-vector extraction;deep neural network;deep belief network;denoising autoencoder;noise robustness;MFCC vectors;DAE;noise robust bottleneck feature extraction;DBN;total-variability matrix training;i-vector extraction;restricted Boltzmann machines;mean squared error;backpropagation;cross-entropy minimization;senone labels;network output;BN feature extraction;senone estimates;GMM","","3","","26","","4 May 2017","","","IEEE","IEEE Conferences"
"Self-Supervised Deep Depth Denoising","V. Sterzentsenko; L. Saroglou; A. Chatzitofis; S. Thermos; N. Zioulis; A. Doumanoglou; D. Zarpalas; P. Daras","Centre for Research and Technology Hellas (CERTH), Information Technologies Institute (ITI), Greece; Centre for Research and Technology Hellas (CERTH), Information Technologies Institute (ITI), Greece; Centre for Research and Technology Hellas (CERTH), Information Technologies Institute (ITI), Greece; Centre for Research and Technology, Information Technologies Institute (ITI); Centre for Research and Technology Hellas (CERTH), Information Technologies Institute (ITI), Greece; Centre for Research and Technology Hellas (CERTH), Information Technologies Institute (ITI), Greece; Centre for Research and Technology Hellas (CERTH), Information Technologies Institute (ITI), Greece; Centre for Research and Technology Hellas (CERTH), Information Technologies Institute (ITI), Greece","2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","1242","1251","Depth perception is considered an invaluable source of information for various vision tasks. However, depth maps acquired using consumer-level sensors still suffer from non-negligible noise. This fact has recently motivated researchers to exploit traditional filters, as well as the deep learning paradigm, in order to suppress the aforementioned non-uniform noise, while preserving geometric details. Despite the effort, deep depth denoising is still an open challenge mainly due to the lack of clean data that could be used as ground truth. In this paper, we propose a fully convolutional deep autoencoder that learns to denoise depth maps, surpassing the lack of ground truth data. Specifically, the proposed autoencoder exploits multiple views of the same scene from different points of view in order to learn to suppress noise in a self-supervised end-to-end manner using depth and color information during training, yet only depth during inference. To enforce self-supervision, we leverage a differentiable rendering technique to exploit photometric supervision, which is further regularized using geometric and surface priors. As the proposed approach relies on raw data acquisition, a large RGB-D corpus is collected using Intel RealSense sensors. Complementary to a quantitative evaluation, we demonstrate the effectiveness of the proposed self-supervised denoising approach on established 3D reconstruction applications. Code is avalable at https://github.com/VCL3D/DeepDepthDenoising.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.00133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9008557","","Sensors;Noise reduction;Image color analysis;Task analysis;Three-dimensional displays;Noise measurement;Color","cameras;computer vision;convolutional neural nets;data acquisition;image colour analysis;image denoising;image reconstruction;rendering (computer graphics);stereo image processing","depth perception;vision tasks;depth maps;consumer-level sensors;nonnegligible noise;traditional filters;deep learning paradigm;nonuniform noise;geometric details;clean data;fully convolutional deep autoencoder;ground truth data;self-supervised end-to-end manner;color information;photometric supervision;geometric surface priors;raw data acquisition;Intel RealSense sensors;self-supervised deep depth denoising;RGB-D corpus;differentiable rendering technique","","8","","49","","27 Feb 2020","","","IEEE","IEEE Conferences"
"Reducing Tongue Shape Dimensionality from Hundreds of Available Resources Using Autoencoder","M. Yang; D. Zhang; J. Tao","The Center for Excellence in Brain Science and Intelligent Technology, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition (NLPR), Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China","2018 24th International Conference on Pattern Recognition (ICPR)","29 Nov 2018","2018","","","2875","2880","In spite of various observation tools, tongue shapes are still scarce resource in reality. Autoencoder, a kind of deep neural networks (DNN), performs well on data reduction and pattern discovery. However, since autoencoder usually needs large scale data in training, challenges exist for traditional autoencoder to obtain tongues' motion patterns only from tens or hundreds of available tongue shapes. To overcome this problem, we propose a two-steps autoencoder, where we first construct a stacked denoising autoencoder (dAE) to learn the essential presentation of the tongue shapes from their possible deformations; then an additional autoencoder with small number of hidden units is added upon the previous stacked autoencoder, and used for dimensionality reduction. Experiments run on 240 vowels' tongue shapes obtained from Chinese speakers' pronunciation X-ray films, and the proposed model is compared with traditional dAE and the classical principal component analysis (PCA) on dimensionality reduction and reconstruction in details. Results validate the performance of the proposed tongue model.","1051-4651","978-1-5386-3788-3","10.1109/ICPR.2018.8545185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8545185","vocal tract;tongue shape;PCA;neural network","Tongue;Shape;Strain;Dimensionality reduction;Training;Image reconstruction;Noise reduction","data reduction;neural nets;principal component analysis","tongue shape dimensionality;deep neural networks;data reduction;pattern discovery;two-steps autoencoder;stacked denoising autoencoder;dimensionality reduction;tongue model;principal component analysis","","","","34","","29 Nov 2018","","","IEEE","IEEE Conferences"
"An Enhanced Noise Removal on Complex Environment with a Novel Autoencoder in Detecting Ship with Visual Search Mechanism","K. S. Manikanta; M. R","Department of Computer Science and Engineering, Saveetha School of Engineering, Saveetha Institute of Medical and Technical Sciences, Saveetha University, Chennai, Tamilnadu, India; Department of Computer Science and Engineering, Saveetha School of Engineering, Saveetha Institute of Medical and Technical Sciences, Saveetha University, Chennai, Tamilnadu, India","2022 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS)","27 Apr 2022","2022","","","904","908","The aim of this study is to predict the ship using a machine learning algorithm and the objective of this research is to improve the accuracy of ship prediction in various environments. The study used 2652 samples with two groups of algorithms with the g-power value of 83%. To predict the ship the convolutional neural network algorithm (CNN) has found 83.5% of accuracy and this study achieves better accuracy for ship prediction with the novel Autoencoder algorithm. This research study found 91.5% of accuracy for ship prediction using the novel Autoencoder algorithm and is higher than the accuracy of convolutional neural networks with a p-value of 0.002. This study concludes that the Autoencoder algorithm on ship prediction is significantly better than the convolutional neural network algorithm.","","978-1-6654-7884-7","10.1109/ICSCDS53736.2022.9760946","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9760946","Machine Learning;Convolutional Neural Network;Novel Autoencoder;Accuracy;Ship Detection;Feature Extraction;Image Classification","Visualization;Machine learning algorithms;Satellites;Prediction algorithms;Classification algorithms;Convolutional neural networks;Data mining","convolutional neural nets;image classification;image coding;image denoising;learning (artificial intelligence);ships","convolutional neural network algorithm;enhanced noise removal;machine learning algorithm;ship prediction;autoencoder algorithm;complex environment;visual search mechanism;CNN;p-value;g-power value","","","","33","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Robust Automatic Recognition of Speech with background music","J. Malek; J. Zdansky; P. Cerva","Faculty of Mechatronics, Technical University of Liberec, Liberec, Czech Republic; Faculty of Mechatronics, Technical University of Liberec, Liberec, Czech Republic; Faculty of Mechatronics, Technical University of Liberec, Liberec, Czech Republic","2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","19 Jun 2017","2017","","","5210","5214","This paper addresses the task of Automatic Speech Recognition (ASR) with music in the background, where the accuracy of recognition may deteriorate significantly. To improve the robustness of ASR in this task, e.g. for broadcast news transcription or subtitles creation, we adopt two approaches: 1) multi-condition training of the acoustic models and 2) denoising autoencoders followed by acoustic model training on the preprocessed data. In the latter case, two types of autoencoders are considered: the fully connected and the convolutional network. Presented experimental results show that all the investigated techniques are able to improve the recognition of speech distorted by music significantly. For example, in the case of artificial mixtures of speech and electronic music (low Signal-to-Noise Ratio (SNR) of 0 dB), we achieved absolute improvement of accuracy by 35.8%. For real-world broadcast news and a high SNR (about 10 dB), we achieved improvement by 2.4%. The important advantage of the studied approaches is that they do not deteriorate the accuracy in scenarios with clean speech (the decrease is about 1%).","2379-190X","978-1-5090-4117-6","10.1109/ICASSP.2017.7953150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7953150","Robust recognition;background music;feature enhancement;denoising autoencoder;multi-condition training","Speech;Training;Data models;Acoustics;Signal to noise ratio;Hidden Markov models;Robustness","music;signal denoising;speech recognition","clean speech;real-world broadcast news;SNR;signal-to-noise ratio;electronic music;convolutional network;acoustic model training;denoising autoencoders;acoustic models;multicondition training;broadcast news transcription;ASR;automatic speech recognition;background music;robust automatic recognition","","4","","24","","19 Jun 2017","","","IEEE","IEEE Conferences"
"Feature extraction of gameplays for similarity calculation in gameplay recommendation","K. Mori; S. Ito; T. Harada; R. Thawonmas; K. -J. Kim","Graduate School of Information Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan; Graduate School of Information Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan; College School of Information Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan; College School of Information Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, Japan; Dept. of Computer Science and Engineering, Seoul, South Korea","2017 IEEE 10th International Workshop on Computational Intelligence and Applications (IWCIA)","14 Dec 2017","2017","","","171","176","This paper proposes a method for extraction of relevant features that represent a gameplay and are needed in gameplay recommendation. In our work, content based filtering (CBF) is adopted as the recommender algorithm. CBF exploits a heuristic that the user's previous ratings of items, gameplay clips in our case, can be used to derive the rating of an unrated similar item. In this work, in order to calculate the similarity between a pair of gameplays, a kind of autoencoder called Denoising Autoencoder is employed. Our experimental results confirm that the method can successfully extract features, based on which the resulting similarity between a pair of gameplays matches with their content and human perception.","","978-1-5386-0469-4","10.1109/IWCIA.2017.8203580","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8203580","Procedural Play Generation;Recom-mender Systems;Denoising Autoencoder","Games;Feature extraction;Artificial intelligence;Projectiles;Training;Color;Noise reduction","computer games;feature extraction;image denoising;neural nets;recommender systems;video signal processing","gameplay recommendation;content based filtering;CBF;recommender algorithm;gameplay clips;feature extraction;similarity calculation;heuristic;denoising autoencoder;video clip","","2","","16","","14 Dec 2017","","","IEEE","IEEE Conferences"
"Stochastic Learning with Back Propagation","G. Kim; C. S. Hwang; D. S. Jeong","Center for electronic materials, Korea Institute of Science and Technology, Seoul, Republic of Korea; School of Materials Science and Engineering, Seoul National University, Seoul, Republic of Korea; Division of Materials Science and Engineering, Hanyang university, Seoul, Republic of Korea","2019 IEEE International Symposium on Circuits and Systems (ISCAS)","1 May 2019","2019","","","1","5","Despite of remarkable progress on deep learning, its hardware implementation beyond deep learning acceleration is still behind the software deep learning due in part to lack of hardware-compatible learning algorithm. In this paper, a learning method called the stochastic learning with backpropagation (SLBP) algorithm was proposed. The network of concern consists of ternary synaptic weight, favorable to be implemented in a resistance-based crossbar array. Every training epoch, the SLBP algorithm evaluates weight update probability at which the corresponding weight is updated in a stochastic manner. The algorithm was used to train a denoising autoencoder, which identified the successful reduction in noise (increase in peak signal-to-noise ratio by approximately 68%). Notably, the SLBP algorithm achieves an 86% reduction in memory usage compared with a real-valued autoencoder trained using a backpropagation algorithm.","2158-1525","978-1-7281-0397-6","10.1109/ISCAS.2019.8702253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8702253","Stochastic learning with backpropagation;ternary weight;crossbar array;denoising autoencoder","Noise reduction;Switches;Deep learning;Approximation algorithms;Backpropagation;Image reconstruction;Hardware","backpropagation;image denoising;learning (artificial intelligence);probability","stochastic learning;hardware implementation;deep learning acceleration;software deep learning;hardware-compatible learning algorithm;backpropagation algorithm;resistance-based crossbar array;SLBP algorithm;weight update probability;denoising autoencoder","","1","","17","","1 May 2019","","","IEEE","IEEE Conferences"
"Construction Method of Turbine Engine Health Indicator Based on Deep Learning","Y. Gao; J. Zhou; K. Wu; G. Zhao; C. Hu","School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; Shanghai Institute of Satellite Engineering, Shanghai, China; Shanghai Institute of Satellite Engineering, Shanghai, China; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; Guangxi key Laboratory of Automatic Detecting Technology and Instruments, Guilin University of Electronic Technology, Guilin, China","2019 Prognostics and System Health Management Conference (PHM-Qingdao)","27 Dec 2019","2019","","","1","6","Traditional turbine engine health indicator (HI) construction methods generally require manual feature extraction, feature selection and even feature fusion, besides, training labels need to be designed in advance, which make the whole procedure time consuming and not universal. Therefore, this paper proposes a novel unsupervised construction method of turbine engine health indicator based on stacked denoising autoencoders (SDAE). In this method, the deep structure of autoencoders adaptively extracts features of raw turbine engine monitoring signals in an unsupervised way to obtain its health indicator. Experimental results on CMAPSS engine dataset show that the HI curves constructed by the proposed method can well reflect the degradation process of turbine engine during the whole life cycle, and have better correlation and monotonicity compared to the traditional HI construction methods. Moreover, the proposed method does not need to rely on complex signal processing measures, the whole process is carried out in an unsupervised manner with a certain degree of versatility.","","978-1-7281-0861-2","10.1109/PHM-Qingdao46334.2019.8943055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943055","health indicator;deep learning;stacked denoising autoencoders;unsupervised learning","Engines;Feature extraction;Turbines;Monitoring;Training;Degradation;Deep learning","aerospace engines;feature extraction;image denoising;learning (artificial intelligence);neural nets","traditional turbine engine health indicator construction methods;manual feature extraction;feature selection;novel unsupervised construction method;raw turbine engine monitoring signals;CMAPSS engine dataset;stacked denoising autoencoders;deep learning;HI curves;complex signal processing measures;feature fusion","","","","14","IEEE","27 Dec 2019","","","IEEE","IEEE Conferences"
"DriveGuard: Robustification of Automated Driving Systems with Deep Spatio-Temporal Convolutional Autoencoder","A. Papachristodoulou; C. Kyrkou; T. Theocharides",KIOS Research and Innovation Center of Excellence; KIOS Research and Innovation Center of Excellence; KIOS Research and Innovation Center of Excellence,"2021 IEEE Winter Conference on Applications of Computer Vision Workshops (WACVW)","21 Apr 2021","2021","","","107","116","Autonomous vehicles increasingly rely on cameras to provide the input for perception and scene understanding and the ability of these models to classify their environment and objects, under adverse conditions and image noise is crucial. When the input is, either unintentionally or through targeted attacks, deteriorated, the reliability of autonomous vehicle is compromised. In order to mitigate such phenomena, we propose DriveGuard, a lightweight spatio-temporal autoencoder, as a solution to robustify the image segmentation process for autonomous vehicles. By first processing camera images with DriveGuard, we offer a more universal solution than having to re-train each perception model with noisy input. We explore the space of different autoencoder architectures and evaluate them on a diverse dataset created with real and synthetic images demonstrating that by exploiting spatio-temporal information combined with multi-component loss we significantly increase robustness against adverse image effects reaching within 5-6% of that of the original model on clean images.","2690-621X","978-1-6654-1967-3","10.1109/WACVW52041.2021.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9407818","","Image segmentation;Computer vision;Computational modeling;Conferences;Semantics;Computer architecture;Cameras","feature extraction;image classification;image denoising;image segmentation;road vehicles;spatiotemporal phenomena;traffic engineering computing","camera images;DriveGuard;universal solution;perception model;autoencoder architectures;synthetic images;spatio-temporal information;adverse image effects;automated driving systems;deep spatio-temporal convolutional autoencoder;autonomous vehicle;image noise;lightweight spatio-temporal autoencoder;image segmentation","","1","","43","","21 Apr 2021","","","IEEE","IEEE Conferences"
"Radar HRRP Target Recognition via Semi-Supervised Multi-Task Deep Network","C. Zhao; X. He; J. Liang; T. Wang; C. Huang","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Access","26 Aug 2019","2019","7","","114788","114794","Feature representation based on the high resolution range profile (HRRP) is the key technology in radar automatic target recognition(RATR). In this paper, we design a deep-u-blind denoising network(DUBDNet) to extract features with high-noise-stability. The fully convolutional DUBDNet is based on autoencoder and employs fusion layers to transfer input features to high dimensional space. Then radar HRRP shift-robust convolutional neural network(RSRNet) is proposed as the classifier. In the experiment, two radar sensors are used to measure HRRP signals of warplanes and civil airplanes. RSRNet performs high robustness to HRRP time-shift sensitivity via testing translation data. This is also a proof that convolutional neural network(CNN) is shift-robust on HRRP target recognition. Trained with noise-to-noise, DUBDNet can achieve blind-denoising in low signal-to-noise ratio(SNR) and significantly improve the correct recognition rate of targets. When the SNR of input HRRP signals is less than 5 dB, DUBDNet can increase the SNR by 10 dB. When the input SNR is -15 dB, output SNR can be increased by 15 dB and the correct recognition rate of targets can be increased by 15%.","2169-3536","","10.1109/ACCESS.2019.2933866","National Natural Science Foundation of China(grant numbers:61731006,61671138); 111 Project(grant numbers:B17008); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8792090","Radar sensor;HRRP target recognition;blind-denoising;autoencoder","Target recognition;Radar;Feature extraction;Noise reduction;Convolution;Sensitivity;Sensors","convolutional neural nets;feature extraction;radar computing;radar receivers;radar resolution;radar target recognition;sensor fusion;signal classification;signal denoising;signal representation;supervised learning","radar HRRP target recognition;semisupervised multitask deep network;feature representation;high-noise-stability;fully convolutional DUBDNet;fusion layers;high dimensional space;radar sensors;HRRP time-shift sensitivity;signal-to-noise ratio;SNR;RSRNet;radar HRRP shift-robust convolutional neural network;CNN;radar automatic target recognition;RATR;autoencoder;deep-u-blind denoising network","","10","","28","CCBY","8 Aug 2019","","","IEEE","IEEE Journals"
"An Improved Deep Canonical Correlation Fusion Method for Underwater Multisource Data","K. Song; N. Wang; Y. Zhang","Department of Information Engineering, Hulunbuir Vocational Technical College, Hulunbuir, China; College of Computer Science and Technology, Harbin Engineering University, Harbin, China; College of Computer Science and Technology, Harbin Engineering University, Harbin, China","IEEE Access","17 Aug 2020","2020","8","","146300","146307","In complex underwater environments, the single mode of a single sensor cannot meet the precision requirement of object identification, and multisource fusion is currently the mainstream research approach. Deep canonical correlation analysis is an efficient feature fusion method but suffers from problems such as not strong scalability and low efficiency. Therefore, an improved deep canonical correlation analysis fusion method is proposed for underwater multisource sensor data containing noise. First, a denoising autoencoder is used for denoising and to reduce the data dimension to extract new feature expressions of raw data. Second, given that underwater acoustic data can be characterized as 1-dimensional time series, a 1-dimensional convolutional neural network is used to improve the deep canonical correlation analysis model, and multilayer convolution and pooling are implemented to decrease the number of parameters and increase the efficiency. To improve the scalability and robustness of the model, a stochastic decorrelation loss function is used to optimize the objective function, which reduces the algorithm complexity from O(n3) to O(n2). The comparison experiment of the proposed algorithm and other typical algorithms on MNIST containing noise and underwater multisource data in different scenes shows that the proposed algorithm is superior to others regardless of the efficiency or precision of target classification.","2169-3536","","10.1109/ACCESS.2020.3014495","National Natural Science Foundation of China(grant numbers:61772152); National Key Research and Development Program of China(grant numbers:2018YFC0806800); Technical Basic Research Project(grant numbers:SQB2017206C002); Pre-research Project(grant numbers:10201050201); Project funded by China Postdoctoral Science Foundation(grant numbers:019M651262); Youth Fund Project of Humanities and Social Sciences Research of the Ministry of Education of China(grant numbers:0YJCZH172); Postdoctoral Foundation of Heilongjiang Province(grant numbers:BH-Z19015); Fundamental Research Funds for the Central Universities(grant numbers:3072020CF0605); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9160959","Convolutional neural network;deep canonical correlation analysis;denoising autoencoder;multisource fusion;underwater data","Feature extraction;Correlation;Neural networks;Convolution;Object recognition;Scalability;Decorrelation","convolutional neural nets;correlation methods;learning (artificial intelligence);sensor fusion;signal denoising;time series;underwater acoustic communication","underwater multisource data;complex underwater environments;object identification;multisource fusion;mainstream research approach;efficient feature fusion method;improved deep canonical correlation analysis fusion method;underwater multisource sensor data;data dimension;feature expressions;underwater acoustic data;1-dimensional time series;1-dimensional convolutional neural network;deep canonical correlation analysis model;denoising autoencoder;multilayer convolution;multilayer pooling;objective function;MNIST algorithms;target classification","","1","","28","CCBY","6 Aug 2020","","","IEEE","IEEE Journals"
"A Deep Learning Technique for Electricity Price Forecasting in Consideration of Spikes","K. Yamada; H. Mori","Department of Network Design, Meiji University, Tokyo, Japan; Department of Network Design, Meiji University, Tokyo, Japan","TENCON 2021 - 2021 IEEE Region 10 Conference (TENCON)","16 Feb 2022","2021","","","744","749","This paper presents a Deep Neural Network (DNN) method for electricity price forecasting in power markets. They are inclined to generate spikes that are dozens to hundred times as large as the normal prices so that the prediction is hard to handle. This paper focuses attention on the prediction of spikes to suppress the forecasting errors. This paper deals with the pretraining technique of Autoencoder (AE) in Deep Learning. To enhance the performance of AE, this paper presents a Denoising-Autoencoder (DAE)-based method that consists of DAE and Multilayer Perceptron (MLP) of ANN with the clustering technique. DAE is an extension of AE in a sense that noisy learning data is used with random numbers. The use of clustering enhances the model accuracy due to data similarity. The effectiveness of the proposed method is tested for data of New England ISO, USA.","2159-3450","978-1-6654-9532-5","10.1109/TENCON54134.2021.9707319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9707319","electricity price forecasting;deep neural network;Autoencoder;Denoising Autoencoder;LMP;power markets;spikes","Deep learning;Training;ISO;Simulation;Neural networks;Multilayer perceptrons;Power markets","deep learning (artificial intelligence);multilayer perceptrons;pattern clustering;power engineering computing;power markets;pricing","electricity price forecasting;deep neural network method;power markets;forecasting errors;pretraining technique;DAE;clustering technique;noisy learning data;DNN;denoising-autoencoder-based method;multilayer perceptron;MLP;ANN;New England;USA;deep learning technique","","","","25","IEEE","16 Feb 2022","","","IEEE","IEEE Conferences"
"Speech Enhancement Autoencoder with Hierarchical Latent Structure","K. Oostermeijer; J. Du; Q. Wang; C. -H. Lee","University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; University of Science and Technology of China, Hefei, China; Georgia Institute of Technology, Atlanta, USA","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","671","675","A new hierarchical convolutional neural network-based autoencoder architecture called SEHAE (Speech Enhancement Hierarchical AutoEncoder) is introduced, in which the latent representation is decomposed into several parts that correspond to different scales. The model consists of three functionally different components. First, a stack of encoders generates a set of latent vectors that contain information from an increasingly larger receptive field. Second, the decoders construct the clean speech in a stage-wise and additive fashion, starting from a learned initial vector. The third component, which we call funnel networks, is tasked with ""knitting"" together the outputs of the previous decoder and the encoder to compute latent vectors for the next decoder. Several options for initial vectors are explored. Experiments show that SEHAE achieves significant improvements for the considered speech quality and intelligibility measures, outperforming a denoising autoencoder and other step-wise models. Furthermore, its internal workings are investigated using the intermediate results from the decoders.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414695","Tencent; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414695","Speech enhancement;Hierarchical autoencoder;Convolutional layers;SEHAE","Additives;Conferences;Computational modeling;Noise reduction;Computer architecture;Speech enhancement;Signal processing","convolutional neural nets;learning (artificial intelligence);signal representation;speech enhancement;speech intelligibility;vectors","latent vectors;SEHAE;speech quality;speech intelligibility measures;hierarchical latent structure;hierarchical convolutional neural network-based autoencoder architecture;Speech Enhancement Hierarchical AutoEncoder;latent representation","","","","37","","13 May 2021","","","IEEE","IEEE Conferences"
"Boundary-Preserved Deep Denoising of Stochastic Resonance Enhanced Multiphoton Images","S. -Y. Niu; L. -Z. Guo; Y. Li; Z. Zhang; T. -D. Wang; K. -C. Liu; Y. -J. Li; Y. Tsao; T. -M. Liu","Department of Computer Science and Engineering, University of California San Diego, San Diego, CA, USA; Department of Biomedical Engineering, National Taiwan University, Taipei, Taiwan; Institute of Translational Medicine, Faculty of Health Sciences & Ministry of Education Frontiers Science Center for Precision Oncology, University of Macau, Taipa, Macau, China; Institute of Translational Medicine, Faculty of Health Sciences & Ministry of Education Frontiers Science Center for Precision Oncology, University of Macau, Taipa, Macau, China; Department of Internal Medicine, Cardiovascular Center and Division of Cardiology, College of Medicine, National Taiwan University Hospital, Taipei, Taiwan; Research Center for Information Technology Innovation (CITI), Academia Sinica, Taipei, Taiwan; Research Center for Information Technology Innovation (CITI), Academia Sinica, Taipei, Taiwan; Department of Electrical Engineering, Chung Yuan Christian University, Taoyuan, Taiwan; Institute of Translational Medicine, Faculty of Health Sciences & Ministry of Education Frontiers Science Center for Precision Oncology, University of Macau, Taipa, Macau, China","IEEE Journal of Translational Engineering in Health and Medicine","6 Oct 2022","2022","10","","1","12","Objective: With the rapid growth of high-speed deep-tissue imaging in biomedical research, there is an urgent need to develop a robust and effective denoising method to retain morphological features for further texture analysis and segmentation. Conventional denoising filters and models can easily suppress the perturbative noise in high-contrast images; however, for low photon budget multiphoton images, a high detector gain will not only boost the signals but also bring significant background noise. In such a stochastic resonance imaging regime, subthreshold signals may be detectable with the help of noise, meaning that a denoising filter capable of removing noise without sacrificing important cellular features, such as cell boundaries, is desirable. Method: We propose a convolutional neural network-based denoising autoencoder method — a fully convolutional deep denoising autoencoder (DDAE) — to improve the quality of three-photon fluorescence (3PF) and third-harmonic generation (THG) microscopy images. Results: The average of 200 acquired images of a given location served as the low-noise answer for the DDAE training. Compared with other conventional denoising methods, our DDAE model shows a better signal-to-noise ratio (28.86 and 21.66 for 3PF and THG, respectively), structural similarity (0.89 and 0.70 for 3PF and THG, respectively), and preservation of the nuclear or cellular boundaries (F1-score of 0.662 and 0.736 for 3PF and THG, respectively). It shows that DDAE is a better trade-off approach between structural similarity and preserving signal regions. Conclusions: The results of this study validate the effectiveness of the DDAE system in boundary-preserved image denoising. Clinical Impact: The proposed deep denoising system can enhance the quality of microscopic images and effectively support clinical evaluation and assessment.","2168-2372","","10.1109/JTEHM.2022.3206488","Faculty of Health Sciences, University of Macau, the startup Grants of the University of Macau; Science and Technology Development Fund, Macau SAR(grant numbers:122/2016/A3,018/2017/A1,0011/2019/AKP,0120/2020/A3,0026/2021/A); Cardiovascular Center, Division of Cardiology, Department of Internal Medicine, National Taiwan University Hospital, Ministry of Science and Technology, R.O.C(grant numbers:MOST 107-2314-B-002-262-MY2); Academia Sinica(grant numbers:AS-GC-111-M01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9889701","Third harmonic generation;three-photon fluorescence;deep denoising autoencoder","Microscopy;Noise reduction;Imaging;Photonics;Fluorescence;Optical filters;Microprocessors","","","","","","44","CCBY","14 Sep 2022","","","IEEE","IEEE Journals"
"Marginalised stack denoising autoencoders for metagenomic data binning","S. Kouchaki; S. Tirunagari; A. Tapinos; D. L. Robertson","Department of Engineering Science, University of Oxford, UK; Department of Computer Science, University of Surrey, UK; Evolution and Genomic Sciences, The University of Manchester, UK; MRC-University of Glasgow Centre for Virus Research, Glasgow, UK","2017 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)","5 Oct 2017","2017","","","1","6","Shotgun sequencing has facilitated the analysis of complex microbial communities. Recently we have shown how local binary patterns (LBP) from image processing can be used to analyse the sequenced samples. LBP codes represent the data in a sparse high dimensional space. To improve the performance of our pipeline, marginalised stacked autoencoders are used here to learn frequent LBP codes and map the high dimensional space to a lower dimension dense space. We demonstrate its performance using both low and high complexity simulated metagenomic data and compare the performance of our method with several existing techniques including principal component analysis (PCA) in the dimension reduction step and fc-mer frequency in feature extraction step.","","978-1-4673-8988-4","10.1109/CIBCB.2017.8058552","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8058552","","Genomics;Feature extraction;Bioinformatics;Prototypes;Data visualization;Noise reduction","bioinformatics;feature extraction;genomics;learning (artificial intelligence);microorganisms;principal component analysis","metagenomic data binning;local binary patterns;image processing;sequenced samples;principal component analysis;dimension reduction step;fc-mer frequency;LBP;marginalised stack denoising autoencoders;PCA;feature extraction","","1","","22","","5 Oct 2017","","","IEEE","IEEE Conferences"
"Path Planning Method Combining Depth Learning and Sarsa Algorithm","D. Xu; Y. Fang; Z. Zhang; Y. Meng","College of Computer Science and Technology, Harbin Engineering University, Harbin; College of Computer Science and Technology, Harbin Engineering University, Harbin; College of Computer Science and Technology, Harbin Engineering University, Harbin; College of Computer Science and Technology, Harbin Engineering University, Harbin","2017 10th International Symposium on Computational Intelligence and Design (ISCID)","8 Feb 2018","2017","2","","77","82","When the traditional Sarsa(λ) algorithm is applied to the path planning, there are some problems such as slow learning of environmental knowledge and neglecting a lot of useful information. This paper proposes a method to combine the algorithm of Stacking Denoising AutoEncoders, Extract real-time environmental features by stack denoising sparse autoencoders. While eliminating the impact of environmental noise. The position information is obtained by mapping the SOM neural network, whereby the position information yields the R value. Sarsa(λ) updates the Q value based on the R value and carries out the corresponding path planning. At the same time, SOM neural network mapping can effectively avoid the long time iterative operation and output error of other neural networks. This method makes the algorithm more effective to extract the environmental characteristic information, and makes the path planning more accurate and efficient. The simulation experiment takes the agent path planning in 2D and 3D complex environment as the background, the traditional Sarsa(λ) algorithm is compared with the DSAE-Sarsa(λ) that proposed in this paper. Through the path planning performance, the algorithm convergence and the convergence speed, the reward value situation and so on, verifies the ability and superiority of the algorithm that proposed in this paper.","2473-3547","978-1-5386-3675-6","10.1109/ISCID.2017.145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283229","Sarsa(?) algorithm;depth learning;Stacking Denoising AutoEncoders","Noise reduction;Feature extraction;Neurons;Algorithm design and analysis;Path planning;Data mining;Stacking","feature extraction;iterative methods;learning (artificial intelligence);mobile robots;multi-robot systems;path planning;self-organising feature maps","path planning method;depth learning;Sarsa algorithm;environmental knowledge;sparse autoencoders;environmental noise;position information;R value;SOM neural network mapping;neural networks;environmental characteristic information;agent path planning;path planning performance;reward value situation;stacking denoising autoencoders;environmental feature extraction","","4","","7","","8 Feb 2018","","","IEEE","IEEE Conferences"
"Integration of Variational Autoencoder and Spatial Clustering for Adaptive Multi-Channel Neural Speech Separation","K. Zmolikova; M. Delcroix; L. Burget; T. Nakatani; J. H. Černocky","Faculty of IT, IT4I Centre of Excellence, Brno University of Technology; NTT Communication Science Laboratories, NTT Corporation, Kyoto, Japan; Faculty of IT, IT4I Centre of Excellence, Brno University of Technology; NTT Communication Science Laboratories, NTT Corporation, Kyoto, Japan; Faculty of IT, IT4I Centre of Excellence, Brno University of Technology","2021 IEEE Spoken Language Technology Workshop (SLT)","25 Mar 2021","2021","","","889","896","In this paper, we propose a method combining variational autoencoder model of speech with a spatial clustering approach for multi-channel speech separation. The advantage of integrating spatial clustering with a spectral model was shown in several works. As the spectral model, previous works used either factorial generative models of the mixed speech or discriminative neural networks. In our work, we combine the strengths of both approaches, by building a factorial model based on a generative neural network, a variational autoencoder. By doing so, we can exploit the modeling power of neural networks, but at the same time, keep a structured model. Such a model can be advantageous when adapting to new noise conditions as only the noise part of the model needs to be modified. We show experimentally, that our model significantly outperforms previous factorial model based on Gaussian mixture model (DOLPHIN), performs comparably to integration of permutation invariant training with spatial clustering, and enables us to easily adapt to new noise conditions.","","978-1-7281-7066-4","10.1109/SLT48900.2021.9383612","National Science Foundation; Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9383612","Multi-channel speech separation;variational autoencoder;spatial clustering;DOLPHIN","Training;Adaptation models;Speech coding;Neural networks;Noise measurement;Dolphins;Software development management","adaptive signal processing;Gaussian processes;mixture models;neural nets;pattern clustering;signal denoising;source separation;speech processing","adaptive multichannel neural speech separation;spatial clustering;multichannel speech separation;spectral model;factorial generative models;mixed speech;discriminative neural networks;generative neural network;noise conditions;Gaussian mixture model;variational autoencoder","","1","","40","","25 Mar 2021","","","IEEE","IEEE Conferences"
"Yarn-Dyed Shirt cut Pieces Defect Detection Using Attention Vector Quantized-Variational Autoencoder","H. Zhang; S. Liu; Z. Ge; P. Li","Zhejiang University, state key laboratory of industrial control technology, Hangzhou, ZheJiang, China; Xi'an Polytechnic University, Institute of Machine Vision and Intelligent Detection, Xi'an, ShaanXi, China; Zhejiang University, state key laboratory of industrial control technology, Hangzhou, ZheJiang, China; Xi'an Polytechnic University, Institute of Machine Vision and Intelligent Detection, Xi'an, ShaanXi, China","2021 IEEE 10th Data Driven Control and Learning Systems Conference (DDCLS)","25 Jun 2021","2021","","","1356","1361","For yarn-dyed shirt cut defects detection problems in production process, this paper proposes a yarn-dyed shirt cut defects detection method based on attention vector-quantized variational autoencoder reconstructed model and residual analysis. To solve the actual problem that the defect sample quantity scarce, defect categories imbalances, high cost and poor generalization ability of artificial design defect features. Firstly, for a certain yarn-dyed shirt cut, salt and pepper noise is artificially added to the defect-free samples to construct a training data set, and then a reconstruction model based on the attention vector quantized variational autoencoder is established and trained. Secondly, a residual map between the original image and the correspondingly reconstructed image is calculated. Finally, the defective area could be detected and located by thresholding and opening operation processing. Experimental results on several yarn-dyed shirt cut pieces data sets show that the proposed method can effectively reconstruct the yarn-dyed shirt cut pieces, detect and locate the defect area of yarn-dyed shirt cut pieces quickly.","2767-9861","978-1-6654-2423-3","10.1109/DDCLS52934.2021.9455583","National Natural Science Foundation of China(grant numbers:61803292); Key Research and Development Program of Shaanxi Province(grant numbers:2019ZDLGY01-08); Shaanxi Provincial Science and Technology Department(grant numbers:2019JM-263); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9455583","Fabric defect detection;Unsupervised learning;Variational autoencoder;Attention model","Training;Computational modeling;Training data;Morphology;Production;Inspection;Fabrics","clothing;design engineering;feature extraction;image denoising;image reconstruction;image segmentation;neural nets;production engineering computing;yarn","defect detection;artificial design defect features;yarn dyed shirt;residual analysis;salt and pepper noise;attention vector quantized variational autoencoder training;image reconstruction;thresholding;production process","","","","17","","25 Jun 2021","","","IEEE","IEEE Conferences"
"Deep Autoencoder for Non-destructive Testing of Defects in Polymer Composites","M. Zheng; K. Liu; N. Li; Y. Yao; Y. Liu","Institute of Process Equipment and Control Engineering, Zhejiang University of Technology, Hangzhou, China; Institute of Process Equipment and Control Engineering, Zhejiang University of Technology, Hangzhou, China; Shanghai Branch, China E-Port Information Data Center, Shanghai, China; Department of Chemical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Institute of Process Equipment and Control Engineering, Zhejiang University of Technology, Hangzhou, China","2021 8th International Conference on Information, Cybernetics, and Computational Social Systems (ICCSS)","1 Mar 2022","2021","","","91","95","Infrared thermography (IRT) is an efficient non-destructive testing technique, which is widely applied in defect detection of polymer composites. However, the nonlinear nature of the thermographic data and the adverse effects of noise and inhomogeneous background prevent IRT from delivering satisfactory results. A novel deep autoencoder thermography (DAT) method is developed to enhance the contrast between defects and background. The multi-layer structure of the deep autoencoder is used to extract the features. Then, the results of the middle-hidden layer are visualized to show the effects of removing noise and uneven background. As a result, the defect is highlighted in the visualized images. The feasibility of the DAT method is verified using the experiment of carbon fiber reinforced polymer specimen.","2639-4235","978-1-6654-0245-3","10.1109/ICCSS53909.2021.9721991","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9721991","non-destructive testing;infrared thermography;autoencoder;feature extraction;deep learning;composite material","Data analysis;Data visualization;Feature extraction;Nonhomogeneous media;Polymers;Data mining;Optical fiber testing","carbon fibre reinforced plastics;data visualisation;deep learning (artificial intelligence);feature extraction;image denoising;infrared imaging;materials science computing;nondestructive testing","polymer composites;infrared thermography;IRT;nondestructive testing;defect detection;thermographic data;inhomogeneous background;multilayer structure;DAT;deep autoencoder thermography;feature extraction;middle-hidden layer visualization;noise removal;image visualization;carbon fiber reinforced polymer specimen","","","","19","IEEE","1 Mar 2022","","","IEEE","IEEE Conferences"
"Convolutional Autoencoder-Based Image Reconstruction for Unsupervised Multimodal Change Detection","A. Radoi",University Politehnica of Bucharest,"2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","4372","4375","Due to the numerous technological developments, the last years have witnessed an increase in the diversity of remote sensing data, whereas the need to interpret multimodal remote sensing data emerged. In this article, we propose a new multimodal unsupervised change detection strategy that projects a pre-event image in the post-event imaging modality. From a reconstruction perspective, the blocks in the pre-event scene are rebuilt from denoised versions of post-event blocks by means of convolutional denoising autoencoders. In order to perform this reconstruction, a dictionary of locations of similar blocks is learned from the pre-event image by analyzing compressed representations. The experiments, conducted over remote sensing images acquired by different sensors, show the effectiveness and the reliability of the proposed approach in various scenarios reflecting diverse types of changes.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553400","Ministry of Research, Innovation and Digitization, CNCS/CCCDI-UEFISCDI(grant numbers:PN-III-P1-1.1-PD-2019-0843); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553400","Multimodal change detection;image reconstruction;autoencoder;convolutional neural networks","Image sensors;Image coding;Dictionaries;Noise reduction;Neural networks;Sensors;Reliability","","","","","","13","","12 Oct 2021","","","IEEE","IEEE Conferences"
"Autoencoder-based bone removal algorithm from x-ray images of the lung","S. Kalisz; M. Marczyk","Department of Data Science and Engineering, Silesian University of Technology, Gliwice, Poland; Yale Cancer Center, Yale University, New Haven, CT, USA","2021 IEEE 21st International Conference on Bioinformatics and Bioengineering (BIBE)","15 Dec 2021","2021","","","1","6","The application of machine learning methods in biomedical image analysis has recently become of particular interest to researchers. One of the most common diagnostic methods with low cost and high availability is X-ray imaging. It allows the acquisition of frontal images of the chest, which can be used in the medical diagnosis of various diseases and prognosis. Due to the presence of ribs on the image, some pathologic changes may go unnoticed. The goal of this work is to develop a method, using deep learning techniques, to remove ribs from chest X-ray images. The Bone Suppression dataset, consisting of 35 pairs of standard X-ray and soft-tissue only images, was used to develop the model. COVIDx was used as an external test set. Due to the small number of images in the training cohort, a data augmentation technique was used to generate new, noisy image pairs. A deep learning model using convolutional denoising autoencoder architecture was developed to remove the ribs from the X-ray image. The effects of two image down-sampling methods and learning rate changes were evaluated. The resulting images are characterized by partial or complete suppression of the ribs. It should be noted that the problem was not posed by images of patients suffering from COVID-19, which are characterized by much more complex structures.","2471-7819","978-1-6654-4261-9","10.1109/BIBE52308.2021.9635451","Silesian University of Technology(grant numbers:02/070/BKM21/0028,BKM-639/RAU4/2021); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9635451","X-ray imaging;bone suppression;autoencoders;deep learning","COVID-19;Deep learning;Training;Biological system modeling;Noise reduction;Bones;X-ray imaging","bone;computerised tomography;diagnostic radiography;diseases;image denoising;learning (artificial intelligence);lung;medical image processing;patient diagnosis","autoencoder-based bone removal algorithm;x-ray images;biomedical image analysis;common diagnostic methods;X-ray imaging;frontal images;ribs;deep learning techniques;X-ray image;noisy image pairs;down-sampling methods;learning rate changes","","","","17","IEEE","15 Dec 2021","","","IEEE","IEEE Conferences"
"Multimodal autoencoder: A deep learning approach to filling in missing sensor data and enabling better mood prediction","N. Jaques; S. Taylor; A. Sano; R. Picard","Media Lab, Massachusetts Institute of Technology, Cambridge, Massachusetts; Media Lab, Massachusetts Institute of Technology, Cambridge, Massachusetts; Media Lab, Massachusetts Institute of Technology, Cambridge, Massachusetts; Media Lab, Massachusetts Institute of Technology, Cambridge, Massachusetts","2017 Seventh International Conference on Affective Computing and Intelligent Interaction (ACII)","1 Feb 2018","2017","","","202","208","To accomplish forecasting of mood in real-world situations, affective computing systems need to collect and learn from multimodal data collected over weeks or months of daily use. Such systems are likely to encounter frequent data loss, e.g. when a phone loses location access, or when a sensor is recharging. Lost data can handicap classifiers trained with all modalities present in the data. This paper describes a new technique for handling missing multimodal data using a specialized denoising autoencoder: the Multimodal Autoencoder (MMAE). Empirical results from over 200 participants and 5500 days of data demonstrate that the MMAE is able to predict the feature values from multiple missing modalities more accurately than reconstruction methods such as principal components analysis (PCA). We discuss several practical benefits of the MMAE's encoding and show that it can provide robust mood prediction even when up to three quarters of the data sources are lost.","2156-8111","978-1-5386-0563-9","10.1109/ACII.2017.8273601","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8273601","","Mood;Data models;Stress;Training;Noise reduction;Principal component analysis;Noise measurement","affective computing;data handling;learning (artificial intelligence)","Multimodal autoencoder;sensor data;affective computing systems;location access;missing multimodal data;specialized denoising autoencoder;Multimodal Autoencoder;MMAE;multiple missing modalities;robust mood prediction;data sources;multimodal data handling;deep learning","","36","","21","","1 Feb 2018","","","IEEE","IEEE Conferences"
"Hallucinating Very Low-Resolution Unaligned and Noisy Face Images by Transformative Discriminative Autoencoders","X. Yu; F. Porikli",Australian National University; Australian National University,"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","9 Nov 2017","2017","","","5367","5375","Most of the conventional face hallucination methods assume the input image is sufficiently large and aligned, and all require the input image to be noise-free. Their performance degrades drastically if the input image is tiny, unaligned, and contaminated by noise. In this paper, we introduce a novel transformative discriminative autoencoder to 8X super-resolve unaligned noisy and tiny (16X16) low-resolution face images. In contrast to encoder-decoder based autoencoders, our method uses decoder-encoder-decoder networks. We first employ a transformative discriminative decoder network to upsample and denoise simultaneously. Then we use a transformative encoder network to project the intermediate HR faces to aligned and noise-free LR faces. Finally, we use the second decoder to generate hallucinated HR images. Our extensive evaluations on a very large face dataset show that our method achieves superior hallucination results and outperforms the state-of-the-art by a large margin of 1.82dB PSNR.","1063-6919","978-1-5386-0457-1","10.1109/CVPR.2017.570","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8100053","","Face;Decoding;Image resolution;Noise measurement;Training;Convolutional codes;Image reconstruction","decoding;encoding;face recognition;image coding;image denoising;image resolution","noisy face images;transformative discriminative autoencoders;encoder-decoder based autoencoders;decoder-encoder-decoder networks;transformative discriminative decoder network;transformative encoder network;hallucinated HR images;low-resolution face images;face hallucination methods;intermediate HR faces;face dataset;noise figure 1.82 dB","","84","","30","","9 Nov 2017","","","IEEE","IEEE Conferences"
"Research on Fault Method of Electro-hydraulic Servo Valve Based on Deep Neural Network","G. Chen; D. Yang; W. Gao; L. Chen; Z. Hua; C. Ai","Institute of Mechanical Engineering, YanShan University, Qinhuangdao, China; Institute of Mechanical Engineering, YanShan University, Qinhuangdao, China; Institute of Mechanical Engineering Nanjing Institute of Technology Institute of Mechanical Engineering, YanShan University, Nanjing, China; Institute of Mechanical Engineering Nanjing Institute of Technology Institute of Mechanical Engineering, YanShan University, Nanjing, China; Institute of Mechanical Engineering, YanShan University, Qinhuangdao, China; Institute of Mechanical Engineering, YanShan University, Qinhuangdao, China","2019 IEEE 8th International Conference on Fluid Power and Mechatronics (FPM)","16 Mar 2020","2019","","","393","397","In view of the current artificial neural network to achieve electro-hydraulic servo valve fault diagnosis, there are long training time, poor training effect, gradient diffusion in training process, etc. This paper proposes a combined optimization deep neural network method, which adopts stack autoencoder method. The training of hierarchical unsupervised learning is carried out to avoid the problem that the traditional neural network disappears in the process of error back propagation, and the training time of the model is shortened. The denoising autoencoder method is applied to each layer of the encoder to improve the robustness of the model. At the same time, in order to prevent the model from over-fitting the noise, a sparse penalty penalty is added to the autoencoder, which makes the obtained model more sparse and prevents over-fitting. Compared with artificial neural network, this method has higher recognition rate and is more suitable for servo valve fault diagnosis. The effectiveness and practicability of the method is verified by the fault diagnosis of the MOOG D661 servo valve.","","978-1-7281-0311-2","10.1109/FPM45753.2019.9035721","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9035721","electro hydraulic servo valve;fault diagnosis;deep learning;neural network;stack autoencoder","","fault diagnosis;mechanical engineering computing;neural nets;servomechanisms;unsupervised learning;valves","MOOG D661 servo valve;fault method;current artificial neural network;electro-hydraulic servo valve fault diagnosis;long training time;gradient diffusion;training process;combined optimization deep neural network method;stack autoencoder method;hierarchical unsupervised learning;traditional neural network;denoising autoencoder method;sparse penalty penalty;error back propagation","","","","8","","16 Mar 2020","","","IEEE","IEEE Conferences"
"Self-Supervised Learning for Action Recognition by Video Denoising","T. T. Trang Phung; T. Hong Thu Ma; V. T. Nguyen; D. Quang Vu","Thai Nguyen University, Thai Nguyen, Vietnam; Tan Trao University, Tuyen Quang, Vietnam; Thai Nguyen University of Education, Thai Nguyen, Vietnam; Dept. of CSIE, National Central University, Taoyuan, Taiwan","2021 RIVF International Conference on Computing and Communication Technologies (RIVF)","21 Dec 2021","2021","","","1","6","Deep learning is a data-hungry technique that is more effective when being applied to large datasets. However, large-scale annotation datasets are not always available. A new approach, such as self-supervised learning of which labels can be automatically generated, is essential. Therefore, using self- supervised learning is a new approach to state-of-the-art methods. In this paper, we introduce a new self-supervised method namely video denoising. This method requires an autoencoder model to restore original videos. The second model is proposed, which is called the discriminator. It is used for the quality evaluation of output videos from the autoencoder. By reconstructing videos, the autoencoder is learned both spatial and temporal relations of video frames to process the downstream task easily. In the experiments, we have demonstrated that our model is well transferred to the action recognition task and outperforms state- of-the-art methods on the UCF-101 and HMDB-51 datasets.","2162-786X","978-1-6654-0435-8","10.1109/RIVF51545.2021.9642129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9642129","","Representation learning;Deep learning;Annotations;Noise reduction;Transfer learning;Supervised learning;Communications technology","feature extraction;image classification;image denoising;image motion analysis;image recognition;image representation;learning (artificial intelligence);neural nets;unsupervised learning;video signal processing","video denoising;deep learning;data-hungry technique;large-scale annotation datasets;self-supervised learning;self-supervised method;autoencoder model;original videos;output videos;video frames;action recognition task;state- of-the-art methods;HMDB-51 datasets","","","","27","IEEE","21 Dec 2021","","","IEEE","IEEE Conferences"
"Keyword spotting in historical document collections withoutsegmentation using the Siamese Network","A. Sapkal; Chhavi; S. Sharma; P. Kumar; S. Yadav","Department of Information Technology, Army Institute of Technology, Pune, India; Department of Information Technology, Army Institute of Technology, Pune, India; Department of Information Technology, Army Institute of Technology, Pune, India; Department of Information Technology, Army Institute of Technology, Pune, India; Department of Information Technology, Army Institute of Technology, Pune, India","2021 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)","16 Dec 2021","2021","","","1","5","Keyword spotting is the method of estimating whether the text query occurs in the document or not. The query- by-example model is used in this paper to present an efficient segmentation-free keyword spotting approach that can be applied in historical document collections. For image de-noising and binarization, we use an autoencoder network in our approach. We are using a patch-based system to create patches for the binarized image, followed by a Siamese network. To determine the degree of similarity between two input word images, a Siamese network employs two identical convolutional networks. Once trained, the network can detect not only words from different writing styles and contexts, but also words that are not in the training set. The method proposed is evaluated on the Bengali Handwritten dataset.","","978-1-6654-3521-5","10.1109/ICSES52305.2021.9633920","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9633920","Historical documents;Keyword spotting;Segmentation-free;Autoencoder;Siamese Convolutional network;Deep learning","Training;Image segmentation;Vocabulary;Writing;Image representation;Image denoising","document image processing;handwritten character recognition;image retrieval;image segmentation;learning (artificial intelligence);natural language processing;text analysis","keyword spotting;text query;query- by-example model;efficient segmentation-free keyword;historical document collections;image de-noising;autoencoder network;patch-based system;binarized image;siamese network;input word images;identical convolutional networks","","","","10","IEEE","16 Dec 2021","","","IEEE","IEEE Conferences"
"Image Resolution Enhancement Using Convolutional Autoencoders with Skip Connections","H. Bhojwani; V. Bhavsar; R. Gajjar; M. Patel","Electronics and Communication Engineering Department, Institute of Technology, Nirma University, Ahmedabad, India; Electronics and Communication Engineering Department, Institute of Technology, Nirma University, Ahmedabad, India; Electronics and Communication Engineering Department, Institute of Technology, Nirma University, Ahmedabad, India; Electronics and Communication Engineering Department, Institute of Technology, Nirma University, Ahmedabad, India","2021 2nd International Conference on Range Technology (ICORT)","5 Nov 2021","2021","","","1","5","Improving image resolution, restoring images, denoising images has been a topic of wide study in deep learning domain. Due to the lack of ground truth images in practical scenarios, the enhanced images help tremendously in understanding and studying the phenomenon in an effective and efficient way. The paper presented here uses autoencoders which in turn comprise of encoder and decoder parts. In order to improve performance of autoencoder, skip connections from initial layers of encoder to the final layers of decoder have also been used. The deconvolutional part can be understood as combination of upsampling layers and convolutional layers. The proposed technique achieves impressive performance on a dataset (WHU-RS19) that has images of different geographies and are highly unrelated. The method proposed in this paper that uses symmetric convolutional and deconvolution layers, is able to achieve an accuracy of 89%; showing the merit of proposed network.","","978-1-6654-4956-4","10.1109/ICORT52730.2021.9582015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582015","Auto-encoder;Convolutional Neural Networks;Image Resolution Enhancement;Regularization;Skip Connections","Geography;Training;Deep learning;Image resolution;Deconvolution;Decoding;Image restoration","convolution;deconvolution;feature extraction;image denoising;image enhancement;image resolution;image restoration;neural nets","convolutional autoencoders;skip connections;deep learning;ground truth images;decoder;upsampling layers;symmetric convolutional deconvolution layers;image resolution enhancement;restoring images;denoising images;WHU-RS19;encoder","","","","19","IEEE","5 Nov 2021","","","IEEE","IEEE Conferences"
"Skip-Connected Deep Convolutional Autoencoder for Restoration of Document Images","G. Zhao; J. Liu; J. Jiang; H. Guan; J. -R. Wen","Beijing Key Laboratory of Big Data Management and Analysis Methods, Renmin University of China, Beijing, China; Beijing Key Laboratory of Big Data Management and Analysis Methods, Renmin University of China, Beijing, China; Beijing Key Laboratory of Big Data Management and Analysis Methods, Renmin University of China, Beijing, China; Beijing Key Laboratory of Big Data Management and Analysis Methods, Renmin University of China, Beijing, China; Beijing Key Laboratory of Big Data Management and Analysis Methods, Renmin University of China, Beijing, China","2018 24th International Conference on Pattern Recognition (ICPR)","29 Nov 2018","2018","","","2935","2940","The denoising and deblurring of images are the two essential restoration tasks in the document image processing task. As the preprocessing stages of the processing pipeline, the quality of denoising and deblurring heavily influences the result of subsequent tasks, such as character detection and recognition. In this paper, we propose a novel neural method for restoring document images. We named our network Skip-Connected Deep Convolutional Autoencoder (SCDCA), which is composed of multiple layers of convolution followed by a batch normalization layer and the leaky rectified linear unit (Leaky ReLU) activation function. Inspired by the idea of residual learning, we use two types of skip connections in the network. One is identity mapping between convolution layers and the other is used to connect the input and output. Through these connections, the network learns the residual between the noisy and clean images instead of learning an ordinary transformation function. We empirically evaluate our algorithm on an open and challenging document images dataset. We also assess our restoring results using the optical character recognition (OCR) test. Experimental results have demonstrated the effectiveness and efficiency of our proposed algorithm by comparing with several state-of-the-art methods.","1051-4651","978-1-5386-3788-3","10.1109/ICPR.2018.8546199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8546199","","Image restoration;Convolution;Decoding;Noise reduction;Kernel;Optical character recognition software;Task analysis","document image processing;feedforward neural nets;image denoising;image restoration;learning (artificial intelligence);optical character recognition","essential restoration tasks;document image processing task;preprocessing stages;processing pipeline;character detection;batch normalization layer;leaky rectified linear unit activation function;Leaky ReLU;residual learning;skip connections;convolution layers;optical character recognition test;image deblurring;document images dataset;network skip-connected deep convolutional autoencoder;image denoising","","3","1","33","","29 Nov 2018","","","IEEE","IEEE Conferences"
"Assessment of Defect Detection in Post-Filtering and Deep Learning Denoising Strategies for Reduced Dose Myocardial Perfusion SPECT Employing Human and Polar Map Observers","P. H. Pretorius; J. Liu; K. Kalluri; M. A. King; B. Auer; C. Lindsay; A. Konik; Y. Yang; M. N. Wernick","University of Massachusetts Medical School, Worcester, MA, USA; Illinois Institute of Technology, Chicago, Il, USA; University of Massachusetts Medical School, Worcester, MA, USA; University of Massachusetts Medical School, Worcester, MA, USA; Department of Radiology, Division of Nuclear Medicine, Brigham and Women’s Hospital and Harvard Medical School, Boston, MA, USA; University of Massachusetts Medical School, Worcester, MA, USA; Harvard Medical School, Dana-Farber Cancer Institute, Boston, MA, USA; Illinois Institute of Technology, Chicago, Il, USA; Illinois Institute of Technology, Chicago, Il, USA","2021 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC)","9 Sep 2022","2021","","","1","3","We have shown that administered activity levels can be reduced using optimized reconstruction strategies, personalized injected dose models, and denoising deep learning networks. In this study we continue our task-based assessment of reduced dose reconstruction and denoising strategies using receiver operator characteristic (ROC) methods. We also introduced remote observer participation over a wide range of viewing stations employing a virtual private network (VPN), or in some cases make use of an Amazon Web Server (AWS) to facilitate observer access.Seventy-eight patients with a normal stress Tc-99m cardiac perfusion SPECT outcomes were selected for the insertion of artificial cardiac perfusion defects, while a further 78 patients with normal cardiac perfusion SPECT distributions were selected to complete the test set. Some of these patients were used to train observers. From list mode acquisitions, dose was incrementally reduced and processed using previously optimized parameters. Six strategies were evaluated, using ordered-subset expectation maximization (OSEM) reconstructed data with attenuation compensation (AC), distance dependent resolution compensation (RC), and scatter compensation (SC), while another only included RC. Gaussian post filtering and a three-dimensional convolutional autoencoder (CAE) model were used for denoising. Both human observers and a polar map clinical observer were used to rank the strategies.Ranking of the processing strategies with the polar map clinical observer revealed that the OSEM strategy without dose reduction with all physics (AC, RC, SC) ranked first, while it was not so clear for human observers. In general, ranking follow the amount reduced dose, except for the strategy where only RC was used without reducing dose.The deep learning approach showed promise, however more work and more data are needed to come to a definitive conclusion.","2577-0829","978-1-6654-2113-3","10.1109/NSS/MIC44867.2021.9875872","National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9875872","","Deep learning;Solid modeling;Noise reduction;Receivers;Observers;Web servers;Virtual private networks","cardiology;convolutional neural nets;deep learning (artificial intelligence);dosimetry;expectation-maximisation algorithm;Gaussian processes;haemorheology;image denoising;image filtering;image reconstruction;image resolution;medical image processing;sensitivity analysis;set theory;single photon emission computed tomography;virtual private networks","defect detection;deep learning denoising strategies;administered activity levels;optimized reconstruction strategies;dose models;task-based assessment;reduced dose reconstruction;receiver operator characteristic methods;remote observer participation;virtual private network;Amazon Web Server;observer access;normal stress Tc-99m cardiac perfusion SPECT outcomes;artificial cardiac perfusion defects;normal cardiac perfusion SPECT distributions;optimized parameters;distance dependent resolution compensation;three-dimensional convolutional autoencoder model;human observers;polar map clinical observer;processing strategies;OSEM strategy;reduced dose myocardial perfusion SPECT;ordered-subset expectation maximization reconstructed data;Gaussian post filtering;attenuation compensation;scatter compensation","","","","15","IEEE","9 Sep 2022","","","IEEE","IEEE Conferences"
"miTarDigger: A Fusion Deep-learning Approach for Predicting Human miRNA Targets","J. Yan; Y. Li; M. Zhu","College of Computer Science, Sichuan University, Chengdu, Country; College of Computer Science, Sichuan University, Chengdu, Country; College of Computer Science, Sichuan University, Chengdu, Country","2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","13 Jan 2021","2020","","","2891","2897","MicroRNAs (miRNAs) are small non-coding RNAs that achieve post-transcriptional regulation of RNA silencing and gene expression by targeting messenger RNAs (mRNAs). Rapid and effective detection of miRNAs target sites is a significantly important topic in bioinformatics. In this study, a deep learning approach based on fusion of stacked denoising autoencoders (SDA) and Convolutional denoising autoencoders (CAE) is developed for sequence and structure data respectively with the help of an existing duplex sequence model. Compared with four conventional machine learning methods, the proposed fusion model performs better in terms of the accuracy, precision, recall, AUC (Area under the curve) and Fl-score. A web system is also developed to identify and display the microRNA target sites effectively and Rapidly.","","978-1-7281-6215-7","10.1109/BIBM49941.2020.9313504","Ministry of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9313504","convolutional denoising autoencoders;deep learning;miRNA;miRNA target site;stacked denoising autoencoders","Feature extraction;Noise reduction;Regulation;RNA;Decoding;Predictive models;Immune system","bioinformatics;genetics;learning (artificial intelligence);molecular biophysics;molecular configurations;RNA","existing duplex sequence model;conventional machine learning methods;fusion model performs;microRNA target sites;miTarDigger;fusion deep-learning approach;human miRNA Targets;microRNAs;noncoding RNAs;post-transcriptional regulation;gene expression;messenger RNAs;miRNAs target sites;deep learning approach;structure data","","","","23","","13 Jan 2021","","","IEEE","IEEE Conferences"
"EIT-CDAE: A 2-D Electrical Impedance Tomography Image Reconstruction Method Based on Auto Encoder Technique","Y. Gao; Y. Lu; H. Li; B. Liu; Y. Li; M. Chen; G. Wang; Y. Lian","Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China; Department of Micro-Nano Electronics and MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China","2019 IEEE Biomedical Circuits and Systems Conference (BioCAS)","5 Dec 2019","2019","","","1","4","Electrical Impedance Tomography is considered to be an alternative substitution to CT and MRI technologies as it is a non-invasive, safe medical imaging technology, and free of ionizing or heating radiation. Similar to CT and MRI technologies, reconstructing a two-dimensional EIT image is also considered an ill-posed and non-linear inverse problem, where the image quality is highly sensitive to the measurement data, and often random noise artifacts appear in the image with the different non-linear algorithms. Therefore, in this work, we have proposed a new EIT image reconstruction algorithm based on the convolution denoising autoencoder (CDAE) deep learning algorithm. Our EIT-CDAE used a convolutional neural network in the encoder and decoder network. From our experimental data using phantom data, our EIT-CDAE model has reconstructed a better EIT image quality, removing any noise artifacts, making it more robust compared to the conventional stacked autoencoder and traditional non-linear algorithms. The source code is available in the github: https://github.com/yongfu-li/eit-cdae-algorithm.","2163-4025","978-1-5090-0617-5","10.1109/BIOCAS.2019.8918979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918979","Electrical impedance tomography;image reconstruction;autoencoder;convolutional neural network;deep learning","Tomography;Image reconstruction;Image quality;Impedance;Machine learning;Inverse problems;Computational modeling","computerised tomography;convolutional neural nets;electric impedance imaging;encoding;image denoising;image reconstruction;inverse problems;learning (artificial intelligence);medical image processing;phantoms","auto encoder technique;two-dimensional EIT image;random noise artifacts;nonlinear algorithms;EIT image reconstruction algorithm;convolution denoising autoencoder deep learning algorithm;convolutional neural network;decoder network;phantom data;EIT-CDAE model;EIT image quality;2D electrical impedance tomography image reconstruction method;encoder network;conventional stacked autoencoder;nonlinear inverse problem;ill-posed problem","","5","","21","","5 Dec 2019","","","IEEE","IEEE Conferences"
"Deep Learning Prediction of Chlorophyll Content in Tomato Leaves","M. I. Khoshrou; P. Zarafshan; M. Dehghani; G. Chegini; A. Arabhosseini; B. Zakeri","Department of Agrotechnology, College of Aburaihan, University of Tehran, Tehran, Iran; Department of Agrotechnology, College of Aburaihan, University of Tehran, Tehran, Iran; Department of Food Technology, College of Aburaihan, University of Tehran, Tehran, Iran; Department of Agrotechnology, College of Aburaihan, University of Tehran, Tehran, Iran; Department of Agrotechnology, College of Aburaihan, University of Tehran, Tehran, Iran; Department of Food Technology, College of Aburaihan, University of Tehran, Tehran, Iran","2021 9th RSI International Conference on Robotics and Mechatronics (ICRoM)","7 Jan 2022","2021","","","580","585","Precision agriculture has improved crops production around the world. Non-destructive evaluation of chlorophyll contents of plant leaves can be a useful solution, in the field of precision farming. In order to take the required measures, sometimes it is essential to precisely evaluate the chlorophyll content, without cutting the target leaves. In this work, a deep learning methodology is proposed to assess the quantity of chlorophyll in the leaves of the tomato plants, through image processing. This methodology can be extended to any other type of leaves. The proposed method consists of a convolutional denoising autoencoder, to reduce the ambient light noises. Then, using a deep autoencoder network, the valuable features of the plant leaf image are extracted and fed as input to another neural network that evaluates the chlorophyll content of the leaf, taking advantage of support vector regression. To validate the accuracy of the proposed method, measurements were performed using the SPAD chlorophyll meter. The validation results prove the desired accuracy and efficiency of the developed approach.","2572-6889","978-1-6654-2094-5","10.1109/ICRoM54204.2021.9663468","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9663468","Chlorophyll estimation;Convolutional neural network (CNN);Deep autoencoder;Support vector regression (SVR)","Support vector machines;Deep learning;Noise reduction;Neural networks;Production;Feature extraction;Agriculture","agriculture;convolutional neural nets;crops;deep learning (artificial intelligence);feature extraction;image coding;image denoising;learning (artificial intelligence);precision engineering;regression analysis;support vector machines","chlorophyll content;tomato leaves;precision agriculture;nondestructive evaluation;plant leaves;precision farming;target leaves;deep learning methodology;tomato plants;deep autoencoder network;plant leaf image;SPAD chlorophyll meter;convolutional denoising autoencoder;support vector regression","","","","16","IEEE","7 Jan 2022","","","IEEE","IEEE Conferences"
"Adversarial autoencoder for reducing nonlinear distortion","N. Tawara; T. Kobayashi; M. Fujieda; K. Katagiri; T. Yazu; T. Ogawa","Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; OKI Electric Industry Co., Ltd., Saitama, Japan; OKI Electric Industry Co., Ltd., Saitama, Japan; OKI Electric Industry Co., Ltd., Saitama, Japan; Waseda University, Tokyo, Japan","2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","7 Mar 2019","2018","","","1669","1673","A novel post-filtering method using generative adversarial networks (GANs) is proposed to correct the effect of a nonlinear distortion caused by time-frequency (TF) masking. TF masking is a powerful framework for attenuating interfering sounds, but it can yield an unpleasant distortion of speech (e.g., a musical noise). A GAN-based autoencoder was recently shown to be effective for single-channel speech enhancement, however, using this technique for the post-processing of TF masking cannot help in nonlinear distortion reduction because some TF components are missing after TF-masking. Furthermore, the missing information is difficult embed using an autoencoder. In order to recover such missing components, an auxiliary reference signal that includes the target source components is concatenated with an enhanced signal, is then used as the input to the GAN-based autoencoder. Experimental comparisons show that the proposed post-filtering yields improvements in speech quality over TF-masking.","2640-0103","978-9-8814-7685-2","10.23919/APSIPA.2018.8659540","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8659540","","Speech enhancement;Nonlinear distortion;Training;Microphones;Noise measurement;Generators","filtering theory;neural nets;nonlinear distortion;signal denoising;speech enhancement","speech quality;target source components;auxiliary reference signal;speech unpleasant distortion;interfering sound attenuation;single-channel speech enhancement;TF masking;time-frequency masking;generative adversarial networks;novel post-filtering method;adversarial autoencoder;GAN-based autoencoder;TF components;nonlinear distortion reduction","","2","","19","","7 Mar 2019","","","IEEE","IEEE Conferences"
"An Unsupervised-Learning-Based Approach for Automated Defect Inspection on Textured Surfaces","S. Mei; H. Yang; Z. Yin","State Key Laboratory of Digital Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Instrumentation and Measurement","10 May 2018","2018","67","6","1266","1277","Automated defect inspection has long been a challenging task especially in industrial applications, where collecting and labeling large amounts of defective samples are usually harsh and impracticable. In this paper, we propose an approach to detect and localize defects with only defect-free samples for model training. This approach is carried out by reconstructing image patches with convolutional denoising autoencoder networks at different Gaussian pyramid levels, and synthesizing detection results from these different resolution channels. Reconstruction residuals of the training patches are used as the indicator for direct pixelwise defect prediction, and the reconstruction residual map generated in each channel is combined to generate the final inspection result. This novel method has two prominent characteristics, which benefit the implementation of automatic defect inspection in practice. First, it is absolutely unsupervised that no human intervention is needed throughout the inspection process. Second, multimodal strategy is utilized in this method to synthesize results from multiple pyramid levels. This strategy is capable of improving the robustness and accuracy of the method. To evaluate this approach, experiments on convergence, noise immunity, and defect inspection accuracy are conducted. Furthermore, comparative tests with some excellent algorithms on actual and simulated data sets are performed. Experimental results demonstrated the effectiveness and superiority of the proposed method on homogeneous and nonregular textured surfaces.","1557-9662","","10.1109/TIM.2018.2795178","National Science Foundation of China(grant numbers:51327801,51475193); Major Project Foundation of Hubei Province(grant numbers:2016AAA009); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8281622","Convolutional denoising autoencoder (CDAE);defect inspection;texture analysis;unsupervised learning;automatic optical inspection","Inspection;Image reconstruction;Training;Surface texture;Noise reduction;Robustness;Spatial resolution","automatic optical inspection;feature extraction;Gaussian processes;image classification;image denoising;image matching;image reconstruction;image texture;inspection;learning (artificial intelligence);production engineering computing;unsupervised learning","inspection process;multiple pyramid levels;inspection accuracy;automated defect inspection;defective samples;defect-free samples;convolutional denoising autoencoder networks;synthesizing detection results;different resolution channels;reconstruction residuals;training patches;direct pixelwise defect prediction;reconstruction residual map;final inspection result;automatic defect inspection;Gaussian pyramid levels","","100","","51","IEEE","5 Feb 2018","","","IEEE","IEEE Journals"
"Two-Stream Deep Architecture for Hyperspectral Image Classification","S. Hao; W. Wang; Y. Ye; T. Nie; L. Bruzzone","College of Communication and Electronic Engineering, Qingdao University of Technology, Qingdao, China; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy; Faculty of Geosciences and Environmental Engineering, Southwest Jiaotong University, Chengdu, China; College of Communication and Electronic Engineering, Qingdao University of Technology, Qingdao, China; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy","IEEE Transactions on Geoscience and Remote Sensing","23 Mar 2018","2018","56","4","2349","2361","Most traditional approaches classify hyperspectral image (HSI) pixels relying only on the spectral values of the input channels. However, the spatial context around a pixel is also very important and can enhance the classification performance. In order to effectively exploit and fuse both the spatial context and spectral structure, we propose a novel two-stream deep architecture for HSI classification. The proposed method consists of a two-stream architecture and a novel fusion scheme. In the two-stream architecture, one stream employs the stacked denoising autoencoder to encode the spectral values of each input pixel, and the other stream takes as input the corresponding image patch and deep convolutional neural networks are employed to process the image patch. In the fusion scheme, the prediction probabilities from two streams are fused by adaptive class-specific weights, which can be obtained by a fully connected layer. Finally, a weight regularizer is added to the loss function to alleviate the overfitting of the class-specific fusion weights. Experimental results on real HSIs demonstrate that the proposed two-stream deep architecture can achieve competitive performance compared with the state-of-the-art methods.","1558-0644","","10.1109/TGRS.2017.2778343","National Natural Science Foundation of China(grant numbers:61572269,61701272); Fundamental Research Funds for the Central Universities(grant numbers:2682016CX083); Natural Science Foundation of Shandong Province(grant numbers:ZR2017PF004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240968","Class-specific fusion;convolutional neural networks (CNNs);deep learning;hyperspectral image (HSI) classification;remote sensing;stacked denoising autoencoder (SdAE);two-stream architecture","Feature extraction;Machine learning;Hyperspectral imaging;Training","hyperspectral imaging;image classification;image denoising;image fusion;learning (artificial intelligence);neural net architecture;probability","spectral structure;two-stream deep architecture;HSI classification;two-stream architecture;fusion scheme;deep convolutional neural networks;hyperspectral image classification;classification performance enhancement;HSI pixels;stacked denoising autoencoder;spectral value encoding;image patch processing;prediction probabilities;adaptive class-specific weights;fully connected layer;weight regularizer;class-specific fusion weight overfitting","","70","","58","IEEE","27 Dec 2017","","","IEEE","IEEE Journals"
"Deep Filter Banks for Land-Use Scene Classification","H. Wu; B. Liu; W. Su; W. Zhang; J. Sun","Institute of Medical Equipment, Academy of Military Medical Science, Tianjin, China; Institute of Medical Equipment, Academy of Military Medical Science, Tianjin, China; Institute of Medical Equipment, Academy of Military Medical Science, Tianjin, China; State Key Laboratory of Intelligent Technology and System, Computer Science and Technology School, Tsinghua University, Beijing, China; Institute of Medical Equipment, Academy of Military Medical Science, Tianjin, China","IEEE Geoscience and Remote Sensing Letters","19 May 2017","2016","13","12","1895","1899","Land-use (LU) scene classification is one of the most challenging tasks in the field of remote sensing (RS) image processing due to its high intraclass variability and low interclass distance. Motivated by the challenge posed by this problem, we propose a novel hybrid architecture, deep filter banks, combining multicolumn stacked denoising sparse autoencoder (SDSAE) and Fisher vector (FV) to automatically learn the representative and discriminative features in a hierarchical manner for LU scene classification. SDSAE kernels describe local patches and a robust global feature of the RS image is built through the FV pooling layer. Unlike previous handcrafted features, we use machine-learning mechanisms to optimize our proposed feature extractor so that it can learn more suitable internal features from the RS data, boosting the final performance. Our approach achieves superior performance compared with the state-of-the-art methods, obtaining average classification accuracies of 92.7% and 90.4%, respectively, on the UC Merced and RSSCN7 data sets.","1558-0571","","10.1109/LGRS.2016.2616440","Science and Technology Pillar Program, Tianjin, China(grant numbers:16YFZCSF00590); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7676333","Deep filter banks;Fisher vector (FV);land-use (LU) scene classification;stacked denoising sparse autoencoder (SDSAE)","Feature extraction;Noise reduction;Robustness;Kernel;Semantics;Data models;Encoding","feature extraction;geophysical image processing;image classification;image denoising;image filtering;land use;learning (artificial intelligence);remote sensing","image classification accuracy;feature extractor;machine-learning mechanisms;Fisher vector;stacked denoising sparse autoencoder;multicolumn SDSAE kernel;image processing;remote sensing image;land-use scene classification;deep filter bank","","38","","23","OAPA","25 Oct 2016","","","IEEE","IEEE Journals"
"Spiking Neural Network Using Synaptic Transistors and Neuron Circuits for Pattern Recognition With Noisy Images","H. Kim; S. Hwang; J. Park; S. Yun; J. -H. Lee; B. -G. Park","Department of Electrical and Computer Engineering, University of California, Santa Barbara, CA, USA; Department of Electrical and Computer Engineering and the Inter-University Semiconductor Research Center, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering and the Inter-University Semiconductor Research Center, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering and the Inter-University Semiconductor Research Center, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering and the Inter-University Semiconductor Research Center, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering and the Inter-University Semiconductor Research Center, Seoul National University, Seoul, South Korea","IEEE Electron Device Letters","22 Mar 2018","2018","39","4","630","633","We demonstrate the hardware implementation of spiking neural network (SNN) with synaptic transistors and neuron circuits. The method of conversion from software fully-connected network (FCN) to hardware SNN with little degradation is discussed. The degradation of classification accuracy is analyzed in terms of device variation and noisy images. In addition, the accuracy degradation is significantly improved by stacking denoising autoencoder (DAE) layer. FCN-SNN conversion with very little performance drop is demonstrated using weight normalization, and SNN with DAE layer shows a great tolerance to input image noise.","1558-0563","","10.1109/LED.2018.2809661","Brain Korea 21 Plus Project in 2017; Nanomaterial Technology Development Programthrough the National Research Foundation of Korea through the Ministry of Science; ICT(grant numbers:2016M3A7B4910348); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302891","Denoising autoencoder (DAE);synaptic device;neuron circuit;neuromorphic system;spiking neural network (SNN);pattern recognition","Hardware;Noise measurement;Neurons;Transistors;Software;Biological neural networks;Degradation","image coding;image denoising;image recognition;neural nets","fully-connected network;hardware SNN;noisy images;FCN-SNN conversion;synaptic transistors;neuron circuits;pattern recognition;hardware implementation;spiking neural network;stacking denoising autoencoder layer;DAE layer;weight normalization","","37","","29","IEEE","26 Feb 2018","","","IEEE","IEEE Journals"
"SLAC: Calibration-Free Pedometer-Fingerprint Fusion for Indoor Localization","S. He; S. . -H. G. Chan; L. Yu; N. Liu","Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Kowloon, Hong Kong SAR, China; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Kowloon, Hong Kong SAR, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China","IEEE Transactions on Mobile Computing","3 Apr 2018","2018","17","5","1176","1189","To improve the accuracy of fingerprint-based localization, one may fuse step counterwith fingerprints. However, the walking step model may vary among people. Such user heterogeneity may lead to measurement error in walking distance. Previous works often require a step counter tediously calibrated offline or through explicit user input. Besides, as device heterogeneity may introduce various signal readings, these studies often need to calibrate the fingerprint RSSI model. Many of them have not addressed how to jointly calibrate the above heterogeneities and locate the user. We propose SLAC, a novel system which simultaneously localizes the user and calibrates the sensors. SLAC works transparently, and is calibration-free with heterogeneous devices and users. Its novel formulation is embedded with sensor calibration, where location estimations, fingerprint signals, and walking motion are jointly optimized with resultant consistent and correct model parameters. To reduce the localization search scope, SLAC first maps the target to a coarse region (say, floor) via stacked denoising autoencoders and then executes the fine-grained localization. Extensive experimental trials at our campus and the international airport further confirm that SLAC accommodates device and user heterogeneity, and outperforms other state-of-the-art fingerprint-based and fusion algorithms by lower localization errors (often by more than 30 percent).","1558-0660","","10.1109/TMC.2017.2757023","National Natural Science Foundation of China(grant numbers:61472455); Natural Science Foundation of Guangdong Province(grant numbers:2014A030313154); Guangzhou Science Technology and Innovation Commission(grant numbers:GZSTI16EG14/201704030079); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8052139","Indoor localization;joint optimization;device RSSI dependency;step counter calibration;fingerprinting;calibration-free fusion;walk detection;area identification;stacked denoising autoencoders","Radiation detectors;Calibration;Legged locomotion;Radio frequency;Estimation;Wireless fidelity","RSSI;sensor fusion;signal denoising","SLAC;calibration-free pedometer-fingerprint fusion;indoor localization;walking step model;user heterogeneity;measurement error;walking distance;explicit user input;signal readings;fingerprint RSSI model;heterogeneous devices;sensor calibration;location estimations;fingerprint signals;correct model parameters;localization search scope;fine-grained localization;state-of-the-art fingerprint;stacked denoising autoencoders;international airport","","23","","50","IEEE","27 Sep 2017","","","IEEE","IEEE Journals"
"Generative Modeling of Pseudo-Whisper for Robust Whispered Speech Recognition","S. Ghaffarzadegan; H. Bořil; J. H. L. Hansen","Center for Robust Speech Systems, The University of Texas at Dallas, Richardson, TX, USA; Electrical Engineering Department, University of Wisconsin-Platteville, Platteville, WI, USA; Center for Robust Speech Systems, The University of Texas at Dallas, Richardson, TX, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20 May 2017","2016","24","10","1705","1720","Whisper is a common means of communication used to avoid disturbing individuals or to exchange private information. As a vocal style, whisper would be an ideal candidate for human-handheld/computer interactions in open-office or public area scenarios. Unfortunately, current speech technology is predominantly focused on modal (neutral) speech and completely breaks down when exposed to whisper. One of the major barriers for successful whisper recognition engines is the lack of available large transcribed whispered speech corpora. This study introduces two strategies that require only a small amount of untranscribed whisper samples to produce excessive amounts of whisper-like (pseudo-whisper) utterances from easily accessible modal speech recordings. Once generated, the pseudo-whisper samples are used to adapt modal acoustic models of a speech recognizer toward whisper. The first strategy is based on Vector Taylor Series (VTS) where a whisper “background” model is first trained to capture a rough estimate of global whisper characteristics from a small amount of actual whisper data. Next, that background model is utilized in the VTS to establish specific broad phone classes' (unvoiced/voiced phones) transformations from each input modal utterance to its pseudo-whispered version. The second strategy generates pseudo-whisper samples by means of denoising autoencoders (DAE). Two generative models are investigated-one produces pseudo-whisper cepstral features on a frame-by-frame basis, while the second generates pseudo-whisper statistics for whole phone segments. It is shown that word error rates of a TIMIT-trained speech recognizer are considerably reduced for a whisper recognition task with a constrained lexicon after adapting the acoustic model toward the VTS or DAE pseudo-whisper samples, compared to model adaptation on an available small whisper set.","2329-9304","","10.1109/TASLP.2016.2580944","Air Force Research Laboratory(grant numbers:FA8750-15-1-0205); University of Texas at Dallas from the Distinguished University Chair in Telecommunications Engineering; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7491308","Denoising autoencoders;generative models;vector Taylor series;whispered speech recognition","Speech;Speech recognition;Adaptation models;Hidden Markov models;Speech processing;Acoustics;Microphones","acoustic signal processing;cepstral analysis;human computer interaction;signal denoising;speech coding;speech recognition;vectors","generative modeling;robust whispered speech recognition;private information exchange;human-handheld interaction;human-computer interaction;open-office scenarios;public area scenarios;whisper recognition engines;large transcribed whispered speech corpora;untranscribed whisper samples;whisper-like utterances;modal speech recordings;modal acoustic models;Vector Taylor Series;VTS;whisper background model;global whisper characteristics estimation;denoising autoencoders;DAE;pseudowhisper cepstral features;pseudowhisper statistics;phone segments;word error rates;TIMIT-trained speech recognizer;constrained lexicon","","10","1","62","IEEE","14 Jun 2016","","","IEEE","IEEE Journals"
"Cell-Coupled Long Short-Term Memory With  $L$ -Skip Fusion Mechanism for Mood Disorder Detection Through Elicited Audiovisual Features","M. -H. Su; C. -H. Wu; K. -Y. Huang; T. -H. Yang","Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan; Telecommunication Laboratories Chunghwa Telecom Co., Ltd., Taoyuan, Taiwan","IEEE Transactions on Neural Networks and Learning Systems","3 Jan 2020","2020","31","1","124","135","In early stages, patients with bipolar disorder are often diagnosed as having unipolar depression in mood disorder diagnosis. Because the long-term monitoring is limited by the delayed detection of mood disorder, an accurate and one-time diagnosis is desirable to avoid delay in appropriate treatment due to misdiagnosis. In this paper, an elicitation-based approach is proposed for realizing a one-time diagnosis by using responses elicited from patients by having them watch six emotion-eliciting videos. After watching each video clip, the conversations, including patient facial expressions and speech responses, between the participant and the clinician conducting the interview were recorded. Next, the hierarchical spectral clustering algorithm was employed to adapt the facial expression and speech response features by using the extended Cohn-Kanade and eNTERFACE databases. A denoizing autoencoder was further applied to extract the bottleneck features of the adapted data. Then, the facial and speech bottleneck features were input into support vector machines to obtain speech emotion profiles (EPs) and the modulation spectrum (MS) of the facial action unit sequence for each elicited response. Finally, a cell-coupled long short-term memory (LSTM) network with an L-skip fusion mechanism was proposed to model the temporal information of all elicited responses and to loosely fuse the EPs and the MS for conducting mood disorder detection. The experimental results revealed that the cell-coupled LSTM with the L-skip fusion mechanism has promising advantages and efficacy for mood disorder detection.","2162-2388","","10.1109/TNNLS.2019.2899884","Ministry of Science and Technology, Taiwan(grant numbers:107-2218-E-006-008); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8668691","Cell-coupled LSTM;denoizing autoencoder (DAE);L-skip multimodal fusion;mood disorder detection","Mood;Videos;Databases;Feature extraction;Medical services;Monitoring;Delays","image coding;image denoising;image fusion;image sequences;modulation;pattern clustering;speech coding;support vector machines","support vector machines;MS;modulation spectrum;EP;autoencoder denoizing;extended Cohn-Kanade databases;eNTERFACE databases;cell-coupled LSTM;speech emotion profiles;facial speech bottleneck features;speech response features;patient facial expressions;emotion-eliciting videos;elicitation-based approach;long-term monitoring;mood disorder diagnosis;bipolar disorder;elicited audiovisual features;mood disorder detection;L-skip fusion mechanism;cell-coupled long short-term memory","Adult;Algorithms;Bipolar Disorder;Emotions;Facial Expression;Female;Humans;Male;Memory, Long-Term;Memory, Short-Term;Mood Disorders;Neural Networks, Computer;Signal Processing, Computer-Assisted;Speech;Support Vector Machine;Video Recording","8","","62","IEEE","17 Mar 2019","","","IEEE","IEEE Journals"
"Generative modeling of pseudo-target domain adaptation samples for whispered speech recognition","S. Ghaffarzadegan; H. Boşil; J. H. L. Hansen","Center for Robust Speech Systems (CRSS), University of Texas at Dallas, Richardson, Texas, U.S.A; Center for Robust Speech Systems (CRSS), University of Texas at Dallas, Richardson, Texas, U.S.A; Center for Robust Speech Systems (CRSS), University of Texas at Dallas, Richardson, Texas, U.S.A","2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","6 Aug 2015","2015","","","5024","5028","The lack of available large corpora of transcribed whispered speech is one of the major roadblocks for development of successful whisper recognition engines. Our recent study has introduced a Vector Taylor Series (VTS) approach to pseudo-whisper sample generation which requires availability of only a small number of real whispered utterances to produce large amounts of whisper-like samples from easily accessible transcribed neutral recordings. The pseudo-whisper samples were found particularly effective in adapting a neutral-trained recognizer to whisper. Our current study explores the use of denoising autoencoders (DAE) for pseudo-whisper sample generation. Two types of generative models are investigated - one which produces pseudo-whispered cepstral vectors on a frame basis and another which generates pseudo-whisper statistics of whole phone segments. It is shown that the DAE approach considerably reduces word error rates of the baseline system as well as the system adapted on real whisper samples. The DAE approach provides competitive results to the VTS-based method while cutting its computational overhead nearly in half.","2379-190X","978-1-4673-6997-8","10.1109/ICASSP.2015.7178927","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7178927","whispered speech recognition;denoising autoencoders;generative models;Vector Taylor Series","Speech;Indexes;Mel frequency cepstral coefficient","error statistics;signal denoising;speech recognition","pseudo-target domain adaptation sample generative model;whispered speech recognition engine;vector Taylor series approach;VTS approach;whispered utterance;neutral-trained recognizer;denoising autoencoder;DAE approach;pseudo-whisper sample generation;pseudo-whisper statistics;phone segments;word error rate reduction;computational overhead","","7","","26","","6 Aug 2015","","","IEEE","IEEE Conferences"
"A deep learning approach to ultrasound image recovery","D. Perdios; A. Besson; M. Arditi; J. -P. Thiran","Signal Processing Laboratory (LTS5), Ecole Polytechnique Fédérale de Lausanne, Lausanne, Switzerland; Signal Processing Laboratory (LTS5), Ecole Polytechnique Fédérale de Lausanne, Lausanne, Switzerland; Signal Processing Laboratory (LTS5), Ecole Polytechnique Fédérale de Lausanne, Lausanne, Switzerland; Signal Processing Laboratory (LTS5), Ecole Polytechnique Fédérale de Lausanne, Lausanne, Switzerland","2017 IEEE International Ultrasonics Symposium (IUS)","2 Nov 2017","2017","","","1","4","Based on the success of deep neural networks for image recovery, we propose a new paradigm for the compression and decompression of US signals which relies on a stacked denoising autoencoders. The first layer of the network is used to compress the signals and the remaining layers perform the reconstruction. We train the network on simulated US signals and evaluate its quality on images of the publicly available PICMUS dataset. We demonstrate that such a simple architecture outperforms state-of-the art methods, based on the compressed sensing framework, both in terms of image quality and computational complexity.","1948-5727","978-1-5386-3383-0","10.1109/ULTSYM.2017.8092746","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8092746","Compressed sensing;Deep learning;Ultrafast ultrasound imaging;Stacked denoising autoencoders","Image reconstruction;Ultrasonic imaging;Image coding;Imaging;Training;Noise reduction;Ultrasonic variables measurement","image denoising;image reconstruction;learning (artificial intelligence);neural nets","simulated US signals;publicly available PICMUS dataset;compressed sensing framework;image quality;deep learning approach;ultrasound image recovery;deep neural networks;stacked denoising autoencoders","","5","1","14","","2 Nov 2017","","","IEEE","IEEE Conferences"
"Fast Direction-of-arrival Estimation of Multiple Targets Using Deep Learning and Sparse Arrays","G. K. Papageorgiou; M. Sellathurai","School of Engineering and Physical Sciences, Heriot-Watt University, UK; School of Engineering and Physical Sciences, Heriot-Watt University, UK","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","4632","4636","In this work, we focus on improving the Direction-of-Arrival (DoA) estimation of multiple targets/sources from a small number of snapshots. Estimation via the sample covariance matrix is known to perform poorly, since the true manifold structure is not revealed for a small number of samples. First, we explicitly model the sample covariance matrix that is used for the DoA estimation as a noisy version of the true one. Next, we employ a stacked denoising autoencoder (DAE) that predicts a statistically ""richer"" version of the sampled matrix that is subsequently used for the DoA estimation. Moreover, we consider a limited number of sensors (comparable to the number of sources) in a non-uniform linear configuration and introduce an end-to-end hybrid DoA prediction-estimation scheme. Results demonstrate significant improvement compared to the conventional approach.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9054380","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054380","Direction-of-arrival DoA estimation;sparse arrays;maximum interelement spacing constraint MISC arrays;denoising autoencoder DAE;deep learning","Direction-of-arrival estimation;Array signal processing;Estimation;Sensors;Sparse matrices;Covariance matrices;Speech processing","covariance matrices;direction-of-arrival estimation;image denoising;learning (artificial intelligence);neural nets","fast direction-of-arrival estimation;deep learning;sparse arrays;sample covariance matrix;manifold structure;DoA estimation;noisy version;stacked denoising autoencoder;statistically richer version;sampled matrix;end-to-end hybrid DoA prediction-estimation scheme","","5","","18","","9 Apr 2020","","","IEEE","IEEE Conferences"
"A Data Augmentation-Based Method for Robust Device-Free Localization in Changing Environments of Passive Radio Frequency Identification System","Y. Ma; W. Ning; B. Wang; X. Liang","Tianjin Key Laboratory of Imaging and Sensing Microelectronic Technology, Tianjin University, Tianjin, China; Tianjin Key Laboratory of Imaging and Sensing Microelectronic Technology, Tianjin University, Tianjin, China; Tianjin Key Laboratory of Imaging and Sensing Microelectronic Technology, Tianjin University, Tianjin, China; Tianjin Key Laboratory of Imaging and Sensing Microelectronic Technology, Tianjin University, Tianjin, China","IEEE Transactions on Instrumentation and Measurement","23 Mar 2021","2021","70","","1","13","Device-free localization (DFL) is playing a critical role in many applications which do not require any device attached to the target. Because of environmental changes, the fingerprint database established in the original environments is unable to remain effective when used in the changing environments. Looking at dropout as a prior-knowledge-free data augmentation operation, we propose a convolutional denoising autoencoder (DAE)-based DFL architecture AugRF. Our method combines the merits of the convolutional neural network and the DAE in which convolutional operation is beneficial to feature extraction and dropout operation is equivalent to generating augmented versions of the training data. It is noted that our method can improve the localization performance in changed environments without resampling and retraining processes. Simulations and real-world experiments verify the superiority of the proposed architecture. Our localization system can be implemented with a commercial ultrahigh-frequency radio frequency identification system. When the signal-to-noise ratio of the fingerprint data drops significantly due to environmental changes, AugRF contributes to improving localization accuracy. In addition, the time cost for one positioning meets the requirement of real-time indoor localization.","1557-9662","","10.1109/TIM.2021.3065426","National Key Research and Development Project of China(grant numbers:2019YFB2102405); Natural Science Foundation of China(grant numbers:61972279,61671318); Tianjin Natural Science Foundation(grant numbers:20JCYBJC00860); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9374989","Convolutional neural network (CNN);denoising autoencoder (DAE);device-free localization (DFL);environmental changes;ultrahigh-frequency radio frequency identification (RFID) system","Location awareness;Databases;Position measurement;Fingerprint recognition;Feature extraction;Antenna measurements;Pollution measurement","convolutional neural nets;indoor radio;radiofrequency identification;signal denoising;telecommunication computing","real-time indoor localization;fingerprint data;ultrahigh-frequency radio frequency identification system;training data;augmented versions;convolutional operation;convolutional neural network;DAE;convolutional denoising autoencoder-based DFL architecture AugRF;prior-knowledge-free data augmentation operation;fingerprint database;environmental changes;passive radio frequency identification system;robust device-free localization;data augmentation-based method","","4","","33","IEEE","10 Mar 2021","","","IEEE","IEEE Journals"
"Deep Learning Approach Based on Tensor-Train for Sparse Signal Recovery","C. Zou; F. Yang","Department of Electronic Engineering, Tsinghua University, Beijing, China; Key Laboratory of Digital TV System of Guangdong Province and Shenzhen City, Research Institute of Tsinghua University in Shenzhen, Shenzhen, China","IEEE Access","27 Mar 2019","2019","7","","34753","34761","Compressive sensing is a desirable technique to acquire and reconstruct signals at sub-Nyquist rates. Recently, several deep learning-based studies on solving the compressive sensing problem have been carried out, which dramatically reduce the intensive computational complexity of the traditional greedy or convex recovery algorithms and even improve the signal recovery performance. However, as the signal size increases, most of these methods recover signals block by block due to the large computational complexity and memory consumption, which usually imposes block effect on the recovered signals. To deal with this issue, in this paper, we apply a tensor decomposition method named Tensor-Train (TT) on the neural network, by which the number of parameters is reduced by a tremendous factor and the computational complexity is further decreased so that the large signals can be recovered as a whole. In particular, the TT-decomposition is jointly applied on a stacked denoising autoencoder (SDA) network called TT-SDA in this paper. The experiments indicate that the proposed TT-SDA network can preserve the reconstruction performance of the conventional SDA network and outperform the traditional methods, especially with low measurement rates. Meanwhile, it can also significantly reduce the computational complexity and occupied memory space, which becomes a time and memory efficient method in compressive sensing problem.","2169-3536","","10.1109/ACCESS.2019.2903906","National Natural Science Foundation of China(grant numbers:61871255); National Key Research and Development Program of China(grant numbers:2017YFE0113300); Shenzhen International Cooperation Project(grant numbers:GJHZ20170314153251478); Guangdong Key Laboratory Project(grant numbers:2017B030314147); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8663363","Compressive sensing;deep learning;Tensor-Train;stacked denoising autoencoder","Deep learning;Compressed sensing;Image reconstruction;Computational complexity;Neural networks;Image coding","compressed sensing;greedy algorithms;learning (artificial intelligence);neural nets;signal denoising;signal reconstruction;signal sampling;tensors","memory consumption;block effect;recovered signals;tensor decomposition method;neural network;TT-decomposition;stacked denoising autoencoder network;TT-SDA network;reconstruction performance;conventional SDA network;low measurement rates;memory efficient method;compressive sensing problem;sparse signal recovery;desirable technique;sub-Nyquist rates;deep learning-based studies;intensive computational complexity;traditional greedy recovery algorithms;convex recovery algorithms;signal recovery performance;signal size;deep learning approach;tensor-train","","3","","30","OAPA","8 Mar 2019","","","IEEE","IEEE Journals"
"A low-complexity visual tracking approach with single hidden layer neural networks","L. Dai; Y. Zhu; G. Luo; C. He","Lab of Communication and Information Security, Peking University, China; Lab of Communication and Information Security, Peking University, China; Lab of Communication and Information Security, Peking University, China; Lab of Communication and Information Security, Peking University, China","2014 13th International Conference on Control Automation Robotics & Vision (ICARCV)","23 Mar 2015","2014","","","810","814","Visual tracking algorithms based on deep learning have robust performance against variations in a complex environment because deep learning can learn generic features from numerous unlabeled images. However, due to the multilayer architecture, the deep learning trackers suffer from expensive computational costs and are not suitable for real-time applications. In this paper, a low-complexity visual tracking scheme with single hidden layer neural network is proposed based on denoising autoencoder. To further reduce the computational costs, feature selection is applied to simplify the networks and two optimization methods are used during the online tracking process. The experimental results have demonstrated that the proposed algorithm is about six times faster than the trackers based on deep nets and rapid enough for real-time applications with encouraging accuracy.","","978-1-4799-5199-4","10.1109/ICARCV.2014.7064408","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7064408","visual tracking;neural network;denoising autoencoder;single hidden layer","Target tracking;Visualization;Robustness;Training;Neural networks;Optimization methods;Video sequences","feature selection;image coding;image denoising;learning (artificial intelligence);neural nets;object tracking;optimisation","low-complexity visual tracking approach;hidden layer neural networks;deep learning;unlabeled images;denoising autoencoder;feature selection;optimization methods;online tracking process","","1","","16","","23 Mar 2015","","","IEEE","IEEE Conferences"
"Video Analytics in Train Cabin Using Deep Learning","L. T. Hsien; I. Atmosukarto","University of Glasgow-Singapore Institute of Technology, Singapore, Singapore; Singapore Institute of Technology, Singapore, Singapore","2019 4th International Conference on Intelligent Transportation Engineering (ICITE)","24 Oct 2019","2019","","","94","98","The motivation behind our work is to improve commuters overall train ride experience by providing crowd density information of incoming trains. Given the incoming train information, commuters can make an informed decision about which train cabin to board preferring those cabins with lower crowd density. Our proposed solution is to process extracted images from train cabin security footages using Convolutional Denoising Autoencoder-Convolutional Neural Network (CDAE-CNN) to predict crowd density in image frames. Experiment results show that adding the CDAE processing to the framework improves the performance in reconstructing noisy images before feeding the images as input data to CNN, thus overall improving the classification accuracy. Experimental results show that CDAE-CNN consistently outperforms CNN in labeling the train cabin image frames in various image datasets.","","978-1-7281-4553-2","10.1109/ICITE.2019.8880216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880216","crowd density;convolutional denoising autoencoder-convolutional neural network;image processing","Training;Neural networks;Noise measurement;Graphics processing units;Security;Image reconstruction;Testing","convolutional neural nets;feature extraction;image classification;image denoising;image reconstruction;learning (artificial intelligence);video coding","video analytics;deep learning;train ride experience;incoming train information;cabins;lower crowd density;extracted images;train cabin security footages;CDAE processing;noisy images;CDAE-CNN;train cabin image frames;image datasets;convolutional denoising autoencoder-convolutional neural network","","1","","18","","24 Oct 2019","","","IEEE","IEEE Conferences"
"Multi-modal service operation estimation using DNN-based acoustic bag-of-features","S. Tamura; T. Uno; M. Takehara; S. Hayamizu; T. Kurata","Department of Information Science Gifu University, Japan; Department of Information Science Gifu University, Japan; Department of Information Science Gifu University, Japan; Department of Information Science Gifu University, Japan; Center for Service Research AIST, Japan","2015 23rd European Signal Processing Conference (EUSIPCO)","28 Dec 2015","2015","","","2291","2295","In service engineering it is important to estimate when and what a worker did, because they include crucial evidences to improve service quality and working environments. For Service Operation Estimation (SOE), acoustic information is one of useful and key modalities; particularly environmental or background sounds include effective cues. This paper focuses on two aspects: (1) extracting powerful and robust acoustic features by using stacked-denoising-autoencoder and bag-of-feature techniques, and (2) investigating a multi-modal SOE scheme by combining the audio features and the other sensor data as well as non-sensor information. We conducted evaluation experiments using multi-modal data recorded in a restaurant. We improved SOE performance in comparison to conventional acoustic features, and effectiveness of our multimodal SOE scheme is also clarified.","2076-1465","978-0-9928-6263-3","10.1109/EUSIPCO.2015.7362793","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7362793","Service operation estimation;multimodal signal processing;stacked denoising autoencoder;bag of features;environmental sounds","Feature extraction;Speech;Mel frequency cepstral coefficient;Signal processing;Estimation;Support vector machines","acoustic signal processing;audio signal processing;neural nets;signal denoising","multimodal service operation estimation;DNN-based acoustic bag-of-features;service engineering;service quality;working environments;acoustic information;stacked-denoising-autoencoder;multimodal SOE scheme;audio feature;acoustic feature;deep neural network","","1","","12","","28 Dec 2015","","","IEEE","IEEE Conferences"
"A Pipeline Defect Inversion Method With Erratic MFL Signals Based on Cascading Abstract Features","H. Zhang; L. Wang; J. Wang; F. Zuo; J. Wang; J. Liu","College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; Development and Production Department, China National Offshore Oil Corporation, Beijing, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; Pipeline Pressure Inspection Room, Shanghai Institute of Special Equipment Inspection and Technical Research, Shanghai, China; College of Information Science and Engineering, Northeastern University, Shenyang, China","IEEE Transactions on Instrumentation and Measurement","8 Mar 2022","2022","71","","1","11","Defect inversion, as a key step in magnetic flux leakage (MFL) inspection widely used in nondestructive testing (NDT) systems, is critical to quantitative analysis of pipeline risk level. However, the conventional methods are difficult to achieve desirable results with complex and changeable MFL signals, mainly because the defect inversion procedure relies on prior knowledge and the features of MFL signals are not fully mined. To resolve the above problem, a novel direct inversion method based on cascading abstract features is proposed in this article, capable of handling feature extraction and defect size estimation problems effectively under complicated conditions. First, an adaptive abstract defect feature extraction network with stacked multipath denoising sparse autoencoder (sMPDS-AE) is constructed, and several extra feature transmitting channels are created, so that abstract features can be transferred across multiple layers. Second, multifeature fusion and sparsity rules are designed to strengthen the sMPDS-AE model and unify abstract feature dimensions. Third, a novel ensemble-backed predictor is developed to study the complex nonlinear relationship between abstract features and defect sizes. With above-mentioned structure, the proposed method can mining out abstract features of pipeline defects from MFL signals adequately and distinguish defects with different sizes more accurately. Finally, several comparison experiments are conducted on a pipeline network with MFL signals. Experimental results and comprehensive analysis with other mainstream inversion methods validate the superiority of this method.","1557-9662","","10.1109/TIM.2022.3152243","National Natural Science Foundation of China(grant numbers:U21A20481,61973071); LiaoNing Revitalization Talents Program(grant numbers:XLYC2002046); Fundamental Research Funds for the Central Universities of China(grant numbers:N2104020); Program of Shanghai Technology Research Leader(grant numbers:19XD1432600); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9721151","Abstract feature extraction;cascade-stacking;defect inversion;magnetic flux leakage (MFL);stacked multipath denoising sparse autoencoder (sMPDS-AE)","Feature extraction;Pipelines;Inspection;Estimation;Adaptation models;Magnetic sensors;Magnetic resonance imaging","data mining;feature extraction;flaw detection;inspection;magnetic flux;magnetic leakage;mechanical engineering computing;neural nets;pipelines;pipes;sensor fusion;signal denoising","pipeline defect inversion method;erratic MFL signals;cascading abstract features;magnetic flux leakage inspection;nondestructive testing systems;direct inversion method;defect size estimation;adaptive abstract defect feature extraction network;abstract feature dimensions;pipeline network;feature transmitting channels;NDT systems;MFL signal feature;pipeline risk level quantitative analysis;stacked multipath denoising sparse autoencoder;sMPDS-AE;multifeature fusion;sparsity rules;abstract feature mining","","1","","36","IEEE","24 Feb 2022","","","IEEE","IEEE Journals"
"Combining feature selection and representation for speech emotion recognition","Wenjing Han; Huabin Ruan; Xiaojie Yu; Xuan Zhu","Language Computing Lab, Samsung R&D Institute of China-Beijing (SRC-B), Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Language Computing Lab, Samsung R&D Institute of China-Beijing (SRC-B), Beijing, China; Language Computing Lab, Samsung R&D Institute of China-Beijing (SRC-B), Beijing, China","2016 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)","26 Sep 2016","2016","","","1","5","In this paper, we propose a feature selection and representation combination method to generate discriminative features for speech emotion recognition. In feature selection stage, a Multiple Kernel Learning (MKL) based strategy is used to obtain the optimal feature subset. Specifically, features selected at least n times among 10-fold cross validation are collected to build a new feature subset named n-subset, then the n-subset resulting in the highest classification accuracy is viewed as the optimal one. In feature representation stage, the optimal feature subset is mapped to a hidden representation using a denoising autoencoder (DAE). The model parameters are learned by minimizing the squared error between the original and the reconstructed input. The hidden representation is then used as the final feature set in the MKL model for emotion recognition. Our experimental results show significant performance improvement compared to using the original features in both of the inner-corpus and cross-corpus scenarios.","","978-1-5090-1552-8","10.1109/ICMEW.2016.7574773","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7574773","speech emotion recognition;multiple kernel learning;denoising autoencoder;feature selection;feature representation","Kernel;Feature extraction;Speech;Emotion recognition;Training;Databases;Support vector machines","emotion recognition;feature extraction;learning (artificial intelligence);signal denoising;signal representation;speech recognition","feature selection;feature representation combination method;speech emotion recognition;multiple kernel learning based strategy;MKL based strategy;denoising autoencoder;DAE","","1","","19","","26 Sep 2016","","","IEEE","IEEE Conferences"
"Speech enhancement based on analysis-synthesis framework with improved pitch estimation and spectral envelope enhancement","B. Liu; F. Mo; J. Tao","Chinese Academy of Sciences, Institute of Automation, Beijing; Chinese Academy of Sciences, Institute of Acoustics, Beijing; Chinese Academy of Sciences, Institute of Automation, Beijing","2014 12th International Conference on Signal Processing (ICSP)","22 Jan 2015","2014","","","461","466","This paper presents a speech enhancement approach based on analysis-synthesis framework. An improved multi-band summary correlogram (MBSC) algorithm is proposed for pitch estimation and voiced/unvoiced (V/UV) detection. The proposed pitch detection algorithm achieves a lower pitch detection error compared with the reference algorithm. The denoising autoencoder (DAE) is applied to enhance the line spectrum frequencies (LSFs). The reconstruction loss could be decreased compare with the swallow model. The proposed approach is evaluated using the perceptual evaluation of speech quality (PESQ) and the experimental results show that the proposed approach improves the performance of speech enhancement compared with the conventional speech enhancement approach. In addition, it could be applied to parametric speech coding even at low bit rate and low SNR environments.","2164-523X","978-1-4799-2186-7","10.1109/ICOSP.2014.7015048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7015048","analysis-synthesis framework;multi-band summary correlogram;denoising autoencoder;speech enhancement;speech coding","Speech;Noise;Estimation;Speech enhancement;Noise measurement;Finite impulse response filters;Speech coding","estimation theory;hearing;signal denoising;signal detection;speech coding;speech enhancement;speech synthesis;vocoders","speech enhancement;analysis-synthesis framework;pitch estimation;spectral envelope enhancement;multiband summary correlogram algorithm;MBSC algorithm;voiced-unvoiced detection;V-UV detection;pitch detection algorithm;pitch detection error;reference algorithm;denoising autoencoder;DAE;line spectrum frequencies;LSF;reconstruction loss;swallow model;perceptual evaluation;speech quality;PESQ;speech coding;SNR","","","","23","","22 Jan 2015","","","IEEE","IEEE Conferences"
"Collaborative Filtering Algorithm Based on SDAE and Time Mean Model","J. Sun; Z. Ning; C. Wang; X. Wang","College of Software, Taiyuan University of Technology, Taiyuan, China; College of Software, Taiyuan University of Technology, Taiyuan, China; Security and Sensing Business Unit, Beijing Smartchip Microelectronics Technology Co., Ltd, Beijing, China; College of Information and Computer, Taiyuan University of Technology, Taiyuan, China","2020 Eighth International Conference on Advanced Cloud and Big Data (CBD)","21 Apr 2021","2020","","","131","136","Aiming at solving the problem of data sparsity and ignorance of user interest drift in traditional collaborative filtering recommendation, this paper propose a novel collaborative filtering algorithm by combing the automatic feature extraction capability of stacked denoising autoencoder (SDAE) and the ability of real-time recommendation and rapid processing of big data of time mean model (TMM). Time factor of ratings are fully considered, and the proposed model can effectively alleviate the information distortion in feature extraction of traditional recommendation algorithms. Experimental results show that SDAE-TMM can greatly improve the performance of real-time recommendation system.","","978-1-6654-2313-7","10.1109/CBD51900.2020.00032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9406984","recommender system;collaborative filtering;sparse data;stacked denoising autoencoder;time mean model","Deep learning;Collaborative filtering;Noise reduction;Big Data;Feature extraction;Distortion;Data models","collaborative filtering;feature extraction;image denoising;information filtering;recommender systems","traditional recommendation algorithms;SDAE-TMM;real-time recommendation system;time mean model;data sparsity;ignorance;user interest drift;traditional collaborative filtering recommendation;novel collaborative filtering algorithm;automatic feature extraction capability;stacked denoising autoencoder;big data","","","","14","","21 Apr 2021","","","IEEE","IEEE Conferences"
"HCC Recognition Within Ultrasound Images Employing Advanced Textural Features with Deep Learning Techniques","D. Mitrea; S. Nedevschi; P. Mitrea; M. P. Lupşor; R. Badea","Computer Science Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Computer Science Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Computer Science Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Department of Medical Imaging, University of Medicine and Pharmacy, Iuliu Hatieganu, of Cluj-Napoca, Romania; Department of Medical Imaging, University of Medicine and Pharmacy, Iuliu Hatieganu, of Cluj-Napoca, Romania","2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","23 Jan 2020","2019","","","1","6","HCC (Hepatocellular carcinoma) is the liver cancer form that is the most often met. The actual standard for a highly accurate diagnosis of HCC is the biopsy, this being, however, invasive, as well as dangerous. We develop computerized methods, based on advanced image processing, in order to perform automatic, respectively computer aided diagnosis of HCC based on ultrasound images. In this research paper, we analyze the role of several advanced texture analysis specific methods, combined with powerful conventional classifiers, respectively deep learning techniques, for HCC automatic recognition. Regarding the deep learning methods, we focus on Stacked Denoising Autoencoders (SAE), so we study its impact upon the performance of HCC computerized diagnosis. In our experiments, we compare the HCC tumor with both the cirrhotic liver parenchyma on which it evolved and with the hemangioma tumor, the obtained accuracy being around 85%. The actual results are compared, as well, with the previously obtained results in the literature.","","978-1-7281-4852-6","10.1109/CISP-BMEI48845.2019.8965874","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8965874","Hepatocellular Carcinoma (HCC);deep learning;Stacked Denoising Autoencoders (SAE);classification performance;automatic diagnosis;ultrasound images","","biomedical ultrasonics;cancer;feature extraction;image classification;image coding;image denoising;image texture;learning (artificial intelligence);liver;medical image processing;tumours","HCC recognition;ultrasound images;hepatocellular carcinoma;liver cancer;computerized methods;advanced image processing;computer aided diagnosis;advanced texture analysis specific methods;conventional classifiers;HCC automatic recognition;deep learning methods;HCC computerized diagnosis;HCC tumor;cirrhotic liver parenchyma;textural features;biopsy;hemangioma tumor;stacked denoising autoencoders","","","","21","","23 Jan 2020","","","IEEE","IEEE Conferences"
"Initial Investigation of Low-Dose SPECT-MPI via Deep Learning","A. J. Ramon; Y. Yang; P. H. Pretorius; K. L. Johnson; M. A. King; M. N. Wernick","Illinois Institute of Technology, Chicago, IL, USA; Illinois Institute of Technology, Chicago, IL, USA; Department of Radiology, University of Massachusetts Medical School, Worcester, MA, USA; Department of Radiology, University of Massachusetts Medical School, Worcester, MA, USA; Department of Radiology, University of Massachusetts Medical School, Worcester, MA, USA; Illinois Institute of Technology, Chicago, IL, USA","2018 IEEE Nuclear Science Symposium and Medical Imaging Conference Proceedings (NSS/MIC)","5 Sep 2019","2018","","","1","3","Reduction of radiation exposure in SPECT-myocardial perfusion imaging (MPI) is critically important. However, lowering radiation dose significantly degrades image quality. Many deep learning structures have been implemented for denoising of low-dose CT data. However, to the best of our knowledge, there are no studies implementing deep learning structures for denoising of low-dose SPECT-MPI images. This paper reports a deep learning method to denoise SPECT-MPI images inspired by the recent work on low-dose CT. The proposed method is a 3D convolutional neural network based on stacked convolutional autoencoders, which is trained to map low-dose images to standard-dose images. Low-dose data was simulated for 1/8 and 1/16 of standard clinical dose. The performance of the proposed method was quantified by the average correlation (across patients in a test set) between predicted images and standard-dose images and was compared to that obtained from conventional denoising methods (i.e., spatial post-filtering). Preliminary results show that image quality improves significantly in the low-dose studies over conventional noise reduction methods. In particular, at 1/16 of clinical dose, the proposed method achieves similar image quality to that from 1/8 dose with conventional denoising. This suggests that further dose reduction could be achieved if the proposed method is used for post-processing of reconstructed images.","2577-0829","978-1-5386-8494-8","10.1109/NSSMIC.2018.8824548","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8824548","","Image reconstruction;Noise reduction;Computed tomography;Standards;Three-dimensional displays;Convolutional neural networks;Correlation","cardiology;convolutional neural nets;image denoising;image reconstruction;learning (artificial intelligence);medical image processing;single photon emission computed tomography","low-dose images;image quality;stacked convolutional autoencoders;low-dose CT data;radiation dose;SPECT-myocardial perfusion imaging;radiation exposure;reconstructed images;dose reduction;conventional noise reduction methods;conventional denoising methods;predicted images;standard clinical dose;low-dose data;standard-dose images;3D convolutional neural network;deep learning method;low-dose SPECT-MPI images;deep learning structures","","6","","8","","5 Sep 2019","","","IEEE","IEEE Conferences"
"Mapping between ultrasound and vowel speech using DNN framework","X. Zheng; J. Wei; W. Lu; Q. Fang; J. Dang","School of Computer Science and Technology, Tianjin University; School of Computer Science and Technology, Tianjin University; School of Computer Software, Tianjin University; Chinese Academy of Social Science; School of Computer Science and Technology, Tianjin University","The 9th International Symposium on Chinese Spoken Language Processing","27 Oct 2014","2014","","","372","376","Building up the mapping between articulatory movements and corresponding speech could great facility the speech training and speech aid for voiceless patients. In this paper, we propose a deep learning framework for building up a mapping between articulatory information and corresponding speech, which were recorded by ultrasound system. The dataset includes six Chinese vowels. We use Bimodal Deep Autoencoder algorithm based on RBM to learn the relationship between speech and articulation, the weights matrix of representation of them. Speech and ultrasound images have been reconstructed using the extracted features. The reconstruction error of articulation by our method is less than that of PCA based approach. The reconstructed speech is similar to the original one. We propose a mapping from ultrasound tongue image to acoustic signal with a revised Denoising Autoencoder, the results show that it is a promising approach. In contrast, another experiment is conducted to synthesize the ultrasound tongue image from the speech, but the result should be improved.","","978-1-4799-4219-0","10.1109/ISCSLP.2014.6936700","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6936700","DBN;articulatory-acoustic mapping;Denoising Autoencoder","Ultrasonic imaging;Tongue;Image reconstruction;Speech;Feature extraction;Acoustics;Synchronization","acoustic signal processing;feature extraction;handicapped aids;image reconstruction;natural language processing;neural nets;speech processing;ultrasonic imaging","vowel speech;DNN framework;deep neural network framework;articulatory movements;speech training;speech aid;voiceless patients;ultrasound system;Chinese vowels;bimodal deep autoencoder algorithm;RBM;speech reconstruction;ultrasound image reconstruction;feature extraction;ultrasound tongue image;acoustic signal;denoising autoencoder","","1","","9","","27 Oct 2014","","","IEEE","IEEE Conferences"
"Denoising autoencoders for fast real-time traffic estimation on urban road networks","S. Ghosh; M. T. Asif; L. Wynter","Nanyang Technological University, Singapore (NTU); IBM Research; IBM Research","2017 IEEE 56th Annual Conference on Decision and Control (CDC)","22 Jan 2018","2017","","","6307","6312","We propose a new method for traffic state estimation applicable to large urban road networks where a significant amount of the real-time and historical data is missing. Our proposed approach involves estimating the missing historical data through low-rank matrix completion, coupled with an online estimation approach for estimating the missing real-time data. In contrast to the traditional approach, the proposed method does not require re-calibration every time new streaming data becomes available. Empirical results from two metropolitan cities show that the proposed two-step approach provides comparable accuracy to a state of the art benchmark method while achieving two orders of magnitude improvement in computational speed.","","978-1-5090-2873-3","10.1109/CDC.2017.8264610","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8264610","","Noise reduction;Estimation;Roads;Real-time systems;Matrix decomposition;Benchmark testing;Data models","matrix algebra;road traffic;state estimation;traffic engineering computing","online estimation approach;two-step approach;real-time traffic estimation;urban road networks;traffic state estimation;missing historical data;low-rank matrix completion;autoencoder denoising","","4","","34","","22 Jan 2018","","","IEEE","IEEE Conferences"
"Mitigating Data Integrity Attacks in Building Automation Systems using Denoising Autoencoders","C. M. Calimbahin; S. Pancho-Festin; J. R. Pedrasa","Department of Computer, Science University of the Philippines, Quezon City, Philippines; Department of Computer, Science University of the Philippines, Quezon City, Philippines; Electrical and Electronics Engineering, Institute University of the Philippines, Quezon City, Philippines","2019 Eleventh International Conference on Ubiquitous and Future Networks (ICUFN)","22 Aug 2019","2019","","","390","395","Building automation systems (BAS) are a class of cyber-physical systems that aim to improve the efficiency of buildings through intelligent control. Typically, sensor measurements are used to compute for the optimal control action for equipment that minimizes the energy consumption while maintaining the comfort of occupants. Given the heavy reliance on sensor data, ensuring their validity is an essential concern in BAS. Several work have explored sensor validation, mostly for the purpose of automatic fault detection and diagnostics (AFDD). However, recent studies show BAS vulnerable to adversarial attacks - an area that has lacked consideration in the early design of BAS. In this work, we propose a sensor correction model, based on deep learning framework, for mitigating against data integrity attacks in BAS. We test our approach on real-world data obtained from a retrofitted air conditioning (AC) control testbed, with injected data simulating different attacker types and number of attacked sensors. We show that the model is capable of mitigating attacks by comparing with a baseline where no model is employed.","2165-8536","978-1-7281-1340-1","10.1109/ICUFN.2019.8806072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8806072","sensors;data integrity attack;building automation system;cyber-physical system","Data models;Training;Computational modeling;Noise reduction;Buildings;Sensitivity","air conditioning;building management systems;control engineering computing;data integrity;fault diagnosis;learning (artificial intelligence);optimal control;security of data;sensors","cyber-physical systems;intelligent control;sensor measurements;sensor data;sensor validation;automatic fault detection;adversarial attacks;sensor correction model;retrofitted air conditioning control;building automation systems;denoising autoencoders;data integrity attacks","","","","24","","22 Aug 2019","","","IEEE","IEEE Conferences"
"Multi-Condition Training of Denoising Autoencoder by Augmenting Simulated Reverberant Speech Data","R. Nahar; T. Kawai; A. Kai","Graduate School of Science and Technology, Shizuoka University, Japan; Graduate School of Science and Technology, Shizuoka University, Japan; Graduate School of Science and Technology, Shizuoka University, Japan","2018 IEEE 7th Global Conference on Consumer Electronics (GCCE)","13 Dec 2018","2018","","","334","338","When speech recognition task is done by an automatic speech recognition system (ASR), it always has to process the noise and reverberation mixed with the speech in natural environment, which is a challenge. Recently, DNN-based ASR systems are showing better performance than other methods. Also, increasing training data for the DNN has been proven effective. But in real world, there can be many exceptions when it comes to collect data for training the DNN. In that case, if the characteristics of reverberant data for which the performance increases can be found, it will be a great help in the field of speech recognition. In this research, we analyze the effect of artificial reverberation condition on the data those are used for training DNN-based ASR front-end. There are possibilities to enhance the dataset by using suitable artificial data created by adding simulated reverberation to clean speech instead of using just real noisy recordings for training dataset. In case of simulated reverberation, the range of room impulse response (RIR) and direct-to-reverberant energy ratio (DRR) play important roles in training the system affecting the accuracy of recognition. Our analysis in this paper discusses the way of finding optimum RIR conditions to simulate the data without increasing training data amount.","2378-8143","978-1-5386-6309-7","10.1109/GCCE.2018.8574776","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8574776","Reverberant speech;dereverberation;multi-conditional training;artificial reverberation;Automatic Speech Recognition;ASR","Training;Reverberation;Speech recognition;Noise measurement;Mel frequency cepstral coefficient;Task analysis","neural nets;reverberation;speech recognition;transient response","automatic speech recognition system;natural environment;reverberant data;artificial reverberation condition;suitable artificial data;simulated reverberation;direct-to-reverberant energy ratio;optimum RIR conditions;multicondition training;denoising autoencoder;simulated reverberant speech data;speech recognition task;DNN-based ASR systems;DNN-based ASR front-end;room impulse response;deep neural network","","","","28","","13 Dec 2018","","","IEEE","IEEE Conferences"
"SE-DAE: Style-Enhanced Denoising Auto-Encoder for Unsupervised Text Style Transfer","J. Li; Y. Feng; J. Ou","University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","8","Text style transfer aims to change the style of sentences while preserving the semantic meanings. Due to the lack of parallel data, the Denoising Auto-Encoder (DAE) is widely used in this task to model distributions of different sentence styles. However, because of the conflict between the target of the conventional denoising procedure and the target of style transfer task, the vanilla DAE can not produce satisfying enough results. To improve the transferability of the model, most of the existing works combine DAE with various complicated unsupervised networks, which makes the whole system become over-complex. In this work, we design a novel DAE model named Style-Enhanced DAE (SE-DAE), which is specifically designed for the text style transfer task. Compared with previous complicated style-transfer models, our model do not consist of any complicated unsupervised networks, but only relies on the high-quality pseudo-parallel data generated by a novel data refinement mechanism. Moreover, to alleviate the conflict between the targets of the conventional denoising procedure and the style transfer task, we propose another novel style denoising mechanism, which is more compatible with the target of the style transfer task. We validate the effectiveness of our model on two style benchmark datasets. Both automatic evaluation and human evaluation show that our proposed model is highly competitive compared with previous strong the state of the art (SOTA) approaches and greatly outperforms the vanilla DAE.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533731","","Training;Noise reduction;Semantics;Neural networks;Benchmark testing;Data models;Task analysis","feature extraction;text analysis;unsupervised learning","style-enhanced DAE;sentence styles;style-enhanced denoising autoencoder;style benchmark datasets;style denoising mechanism;novel data refinement mechanism;high-quality pseudoparallel data;previous complicated style-transfer models;DAE model;complicated unsupervised networks;vanilla DAE;style transfer task;conventional denoising procedure;model distributions;parallel data;unsupervised text style transfer;SE-DAE","","","","31","IEEE","20 Sep 2021","","","IEEE","IEEE Conferences"
"Classification of PolSAR Images Based on Adaptive Nonlocal Stacked Sparse Autoencoder","Y. Hu; J. Fan; J. Wang","School of Control Science and Engineering, Dalian University of Technology, Dalian, China; National Marine Environmental Monitoring Center, Dalian, China; School of Control Science and Engineering, Dalian University of Technology, Dalian, China","IEEE Geoscience and Remote Sensing Letters","22 Jun 2018","2018","15","7","1050","1054","Land cover classification using polarimetric synthetic aperture radar (PolSAR) images is an important tool for remote sensing analysis. In view that PolSAR image effective interpretation is commonly affected by the absence of discriminative features and the presence of speckle noises, this letter proposes an adaptive nonlocal stacked sparse autoencoder (ANSSAE) to achieve PolSAR image classification. It extracts the adaptive nonlocal spatial information by adaptively calculating weighted average values of each pixel from nonlocal regions, which can reduce the influence of speckle noises and retain edge details. In the first layer of the ANSSAE, the adaptive nonlocal spatial information is introduced into the objective function to obtain the robust feature representation, whose effects would transfer to the rest of layers. Therefore, the ANSSAE can automatically capture spatial-related, robust, and distinguishable features, which can suppress speckle noises and gain accurate classification results. Experimental results on two real PolSAR images demonstrate that the proposed approach can significantly improve the classification accuracy.","1558-0571","","10.1109/LGRS.2018.2829182","National Key Research and Development Program of China(grant numbers:2016YFC1401007,2017YFC1404902); National Natural Science Foundation of China(grant numbers:41706195); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356045","Adaptive nonlocal spatial information;polarimetric synthetic aperture radar (PolSAR) image classification;stacked sparse autoencoder","Speckle;Feature extraction;Covariance matrices;Robustness;Linear programming;Synthetic aperture radar;Fans","feature extraction;geophysical image processing;image classification;image denoising;land cover;radar imaging;radar polarimetry;remote sensing;speckle;synthetic aperture radar","adaptive nonlocal spatial information;nonlocal regions;speckle noises;ANSSAE;PolSAR images;adaptive nonlocal stacked sparse autoencoder;land cover classification;polarimetric synthetic aperture radar images;remote sensing analysis;PolSAR image classification","","21","","15","IEEE","8 May 2018","","","IEEE","IEEE Journals"
"Multi-Way Multi-View Deep Autoencoder for Image Feature Learning with Multi-Level Graph Regularization","Z. Fang; S. Zhou; X. Li; H. Zhu","College of Computer Science and Technology, Zhejiang University, China; R&D Center, NetEase Inc. Hangzhou, China; College of Computer Science and Technology, Zhejiang University, China; R&D Center, NetEase Inc. Hangzhou, China","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","2093","2097","Multi-view feature learning has garnered much attention recently since many real world data are comprised of different representations or views. How to explore the consensus structure and eliminate the inconsistency noise in different views remains a challenging problem in multi-view feature learning. In this paper, we propose a multi-way deep autoencoder for multi-view feature learning to explore the deep consensus structure and reconcile the efficiency of encoding process meanwhile. Through a multi-way encoding process, we embed the original data feature views to nonnegative representations of multiple levels which are structured hierarchically. Along the structure of embedded representations, we recover the diversity and important information layer by layer in the decoding process. The experiments on two image datasets show the superior performance of our method.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9052958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9052958","multi-view;feature learning;autoencoder;hierarchical;deep structure","Conferences;Signal processing;Encoding;Acoustics;Decoding;Speech processing;Image reconstruction","graph theory;image denoising;image representation;learning (artificial intelligence);neural nets","multilevel graph regularization;multiview feature learning;multiway multiview deep autoencoder;image feature learning;decoding process;image datasets","","1","","27","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Sparse Representation Convolutional Autoencoder for Feature Learning of Vibration Signals and its Applications in Machinery Fault Diagnosis","M. Miao; Y. Sun; J. Yu","School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China","IEEE Transactions on Industrial Electronics","12 Jul 2022","2022","69","12","13565","13575","Vibration signals are widely utilized in many fields, which can reflect machine health state. Those typical deep learning techniques cannot learn impulsive features from vibration signals due to interference of strong background noise. Supervised learning greatly rely on vast labeled data, which limits the implementation of deep learning in industry applications. Hence, in this article, a new deep neural network (DNN), sparse representation convolutional autoencoder (SRCAE), is proposed to extract impulsive components of vibration signals for machinery fault diagnosis in an unsupervised manner. A sparse representation (SR) block is proposed to extract impulsive components of vibration signals and transform the time-domain signal to a sparse domain by sparse mapping of a convolutional graph. The SR block is inserted into a deep network to remove noise and learn impulsive features for machinery fault diagnosis. Furthermore, an unsupervised selective feature transmission mechanism is proposed to improve training efficiency and realize feature filtering simultaneously. Finally, the effectiveness of SRCAE is verified on rotary machine fault diagnosis experiments. The testing results show that SRCAE has good noise filtering and impulsive components extraction performance. The recognition accuracy of SRCAE reached 97.16% based on the fivefold cross validation, which demonstrates the outperformance of SRCAE in comparison with state-of-the-art DNNs.","1557-9948","","10.1109/TIE.2021.3128895","National Natural Science Foundation of China(grant numbers:71777173); Action Plan for Scientific and Technological Innovation of Shanghai Science and Technology Commission(grant numbers:21SQBS01402); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9625778","Convolutional autoencoder;deep learning;machinery fault diagnosis;selective residual learning;sparse representation (SR)","Vibrations;Convolution;Fault diagnosis;Feature extraction;Machinery;Filtering;Training","convolutional neural nets;deep learning (artificial intelligence);fault diagnosis;feature extraction;filtering theory;graph theory;machinery;signal denoising;signal representation;supervised learning;time-domain analysis;transforms;unsupervised learning;vibrational signal processing;vibrations","ST block;noise filtering;training efficiency;feature filtering;impulsive feature learning;noise removal;convolutional graph sparse mapping;unsupervised learning;supervised learning;DNN;deep neural network;strong background noise interference;machine health state;impulsive component extraction performance;rotary machine fault diagnosis experiments;unsupervised selective feature transmission mechanism;sparse domain;time-domain signal;sparse representation block;typical deep learning techniques;machinery fault diagnosis;vibration signals;sparse representation convolutional autoencoder;SRCAE","","","","38","IEEE","23 Nov 2021","","","IEEE","IEEE Journals"
"Robust segmentation method for noisy images based on an unsupervised denosing filter","L. Zhang; J. Liu; F. Shang; G. Li; J. Zhao; Y. Zhang","College of Software, Taiyuan University of Technology, Taiyuan, China; College of Software, Taiyuan University of Technology, Taiyuan, China; College of Software, Taiyuan University of Technology, Taiyuan, China; College of Software, Taiyuan University of Technology, Taiyuan, China; College of Software, Taiyuan University of Technology, Taiyuan, China; Information Technology Department, Shanxi Tizones Technology Co., Ltd., Taiyuan, China","Tsinghua Science and Technology","20 Apr 2021","2021","26","5","736","748","Level-set-based image segmentation has been widely used in unsupervised segmentation tasks. Researchers have recently alleviated the influence of image noise on segmentation results by introducing global or local statistics into existing models. Most existing methods are based on the assumption that the distribution of image noise is known or observable. However, real-time images do not meet this assumption. To bridge this gap, we propose a novel level-set-based segmentation method with an unsupervised denoising mechanism. First, a denoising filter is acquired under the unsupervised learning paradigm. Second, the denoising filter is integrated into the level-set framework to separate noise from the noisy image input. Finally, the level-set energy function is minimized to acquire segmentation contours. Extensive experiments demonstrate the robustness and effectiveness of the proposed method when applied to noisy images.","1007-0214","","10.26599/TST.2021.9010021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9409762","image segmentation;noisy image;level set;autoencoder","Image segmentation;Noise measurement;Noise reduction;Convolution;Training;Gray-scale;Feature extraction","image denoising;image segmentation;unsupervised learning","level-set-based segmentation method;segmentation contours;level-set energy function;noisy image input;separate noise;level-set framework;unsupervised learning paradigm;unsupervised denoising mechanism;real-time images;local statistics;global statistics;image noise;unsupervised segmentation tasks;level-set-based image segmentation;unsupervised denosing filter;noisy images;robust segmentation method","","1","","","","20 Apr 2021","","","TUP","TUP Journals"
"A Deep Learning Framework for Univariate Time Series Prediction Using Convolutional LSTM Stacked Autoencoders","A. Essien; C. Giannetti","Zienkiewicz Centre for Computational Engineering (ZCCE), Swansea University, Swansea, United Kingdom; Zienkiewicz Centre for Computational Engineering (ZCCE), Swansea University, Swansea, United Kingdom","2019 IEEE International Symposium on INnovations in Intelligent SysTems and Applications (INISTA)","29 Jul 2019","2019","","","1","6","This paper proposes a deep learning framework where wavelet transforms (WT), 2-dimensional Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) stacked autoencoders (SAE) are combined towards single-step time series prediction. Within the framework, the input dataset is denoised using wavelet decomposition, before learning in an unsupervised manner using SAEs comprising bidirectional Convolutional LSTM (ConvLSTM) layers to predict a single-step ahead value. To evaluate our proposed framework, we compared its performance to two (2) state-of-the-art deep learning predictive models using three open-source univariate time series datasets. The experimental results support the value of the approach when applied to univariate time series prediction.","","978-1-7281-1862-8","10.1109/INISTA.2019.8778417","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8778417","time series prediction;stacked autoencoders;data science;deep learning;Convolutional-LSTM","Time series analysis;Wavelet transforms;Predictive models;Deep learning;Recurrent neural networks;Logic gates;Prediction algorithms","convolutional neural nets;data handling;recurrent neural nets;time series;unsupervised learning;wavelet transforms","univariate time series prediction;deep learning framework;wavelet transforms;SAE;single-step time series prediction;wavelet decomposition;open-source univariate time series datasets;bidirectional convolutional LSTM layers;long short-term memory stacked autoencoders;2-dimensional convolutional neural networks;convolutional LSTM stacked autoencoders;convLSTM layers","","17","","43","","29 Jul 2019","","","IEEE","IEEE Conferences"
"Smile recognition based on deep Auto-Encoders","Shufen Liang; Xiangqun Liang; Min Guo","Wuyi University, Jiangmen, Guangdong, CN; Wuyi University, Jiangmen, Guangdong, CN; Wuyi University, Jiangmen, Guangdong, CN","2015 11th International Conference on Natural Computation (ICNC)","11 Jan 2016","2015","","","176","181","Most of smile recognition methods are based on constrained databases. Thus there are a lot of limitations when applying those algorithms into the real-world smile recognition. For the purpose of improving the accuracy in real-world smile recognition, we conducted our experiments on two databases (GENKI-4K database and our own built database). Depending on deep learning theory, we constructed a new deep model by stacking Contractive Auto-Encoder (CAE) on Contractive Denoising Auto-Encoder (CDAE) to extract useful features. Firstly, we pre-trained a CDAE to extract the feature of the first layer, then the extracted feature were used as input of the next basic model CAE, by pre-training the CAE model, we got more abstract feature, then the feature were used to classification. Experiments showed that our approach was useful for smile recognition. On the other hand, we also explored the influence of different number of training samples.","2157-9563","978-1-4673-7679-2","10.1109/ICNC.2015.7377986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7377986","Smile Recogniton;Deep Learning Algorithms;Contractive Auto-Encoder;Contactive Denoising Auto-Encoder","Databases;Feature extraction;Training;Computer aided engineering;Robustness;Error analysis;Machine learning","emotion recognition;face recognition;feature extraction;image classification;image coding;image denoising;learning (artificial intelligence);visual databases","smile recognition methods;constrained databases;GENKI-4K database;deep learning theory;contractive autoencoder;stacking;contractive denoising autoencoder;feature extraction;CDAE;CAE model;pretraining;classification;training samples;deep autoencoders","","","","15","","11 Jan 2016","","","IEEE","IEEE Conferences"
"DSCD: A Novel Deep Subspace Clustering Denoise Network for Single-Cell Clustering","Z. Wang; Y. Lu; C. Yu; T. Zhou; R. Li; S. Hou","Department of Computer Science, Tongji University, Shanghai, China; Department of Computer Science, Tongji University, Shanghai, China; Department of Mathematical Sciences, Tongji University, Shanghai, China; Department of Mathematical Sciences, Tongji University, Shanghai, China; Department of Computer Science, Tongji University, Shanghai, China; Department of Computer Science, Tongji University, Shanghai, China","IEEE Access","22 Jun 2020","2020","8","","109857","109865","Single-cell RNA sequencing(scRNA-seq) technology has boomed in the past decade which makes it possible to study biological problems at the resolution of cellular-level. Currently, the research mainly focuses on exploring the cellular heterogeneity, involving studies about identifying cell type identification, cell lineage tracing, spatial model reconstruction of complex organizations, etc. Clustering analysis is always the most effective way in grouping single cells in previous studies. However, existing scRNA-seq clustering methods separate pre-processing and clustering tasks that complicated the problem. In addition, the emergence of big data further limits the traditional clustering algorithms' application on scRNA-seq data. Therefore, developing novel clustering methods and improving clustering accuracy for growing scRNA-seq data is a continuous task. In this paper, we propose a highly integrated Deep Subspace Clustering Denoise Network named DSCD, which integrates denoise, dimension reduction and clustering in a unified framework. Based on the neural network architecture of autoencoder, DSCD discovers the low dimensional latent structure within scRNA-seq data from the compressed representation. Furthermore, we add a novel self-expressive denoise layer to learning the global relationships between single cells, which is the main innovation of DSCD. Experimental results on the synthetic data demonstrate the effectiveness of the novel denoise layer. From the clustering results on 5 real scRNA-seq datasets, we find that DSCD outperforms the related subspace clustering algorithms and state of the art methods. In conclusion, DSCD responds well to the rapidly increasing scRNA-seq data scale, greatly reduces human interference in dimension reduction and handles the noisy scRNA-seq data in proper way thus obtain a higher clustering accuracy.","2169-3536","","10.1109/ACCESS.2020.3001986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9115662","Single cell RNA-seq data;auto-encoder;sparse self-express;spectral clustering","Computer architecture;Microprocessors;Training;Clustering algorithms;Decoding;Computer science;RNA","Big Data;biology computing;cellular biophysics;data reduction;neural net architecture;pattern clustering;RNA","DSCD;self-expressive denoise layer;scRNA-seq datasets;noisy scRNA-seq data;single-cell clustering;single-cell RNA sequencing;cell type identification;cell lineage tracing;big data;deep subspace clustering denoise network;scRNA-seq clustering;cellular-level;cellular heterogeneity;dimension reduction;neural network architecture;low dimensional latent structure;autoencoder","","","","31","CCBY","12 Jun 2020","","","IEEE","IEEE Journals"
"AutoEncoders for Training Compact Deep Learning RF Classifiers for Wireless Protocols","S. Kokalj-Filipovic; R. Miller; J. Morman","Perspecta Labs, Inc; Perspecta Labs, Inc; Perspecta Labs, Inc","2019 IEEE 20th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)","29 Aug 2019","2019","","","1","5","We show that compact fully connected (FC) deep learning networks trained to classify wireless protocols using a hierarchy of multiple denoising autoencoders (AEs) outperform reference FC networks trained in a typical way, i.e., with a stochastic gradient based optimization of a given FC architecture. Not only is the complexity of such FC network, measured in number of trainable parameters and scalar multiplications, much lower than the reference FC and residual models, its accuracy also outperforms both models for nearly all tested SNR values (0 dB to 50dB). Such AE-trained networks are suited for in-situ protocol inference performed by simple mobile devices based on noisy signal measurements. Training is based on the data transmitted by real devices, and collected in a controlled environment, and systematically augmented by a policy-based data synthesis process by adding to the signal any subset of impairments commonly seen in a wireless receiver.","1948-3252","978-1-5386-6528-2","10.1109/SPAWC.2019.8815550","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8815550","","","gradient methods;learning (artificial intelligence);neural nets;optimisation;protocols;radio receivers;signal classification;signal denoising;stochastic processes;telecommunication computing","AE-trained networks;in-situ protocol inference;noisy signal measurements;policy-based data synthesis process;wireless receiver;wireless protocols;multiple denoising autoencoders;stochastic gradient based optimization;FC network;scalar multiplications;residual models;FC architecture;SNR values;deep learning RF classifiers;fully connected deep learning networks;noise figure 0.0 dB to 50.0 dB","","7","","15","","29 Aug 2019","","","IEEE","IEEE Conferences"
"Kansei clothing retrieval system using features extracted by autoencoder","S. Ota; H. Takenouchi; M. Tokumaru","Science and Engineering, Graduate school of Kansai University, Osaka, Japan; Department of System Management, Fukuoka Institute of Technology, Fukuoka, Japan; Faculty of Engineering Science, Kansai University, Osaka, Japan","2017 IEEE Symposium Series on Computational Intelligence (SSCI)","8 Feb 2018","2017","","","1","7","In this paper, we propose a Kansei clothing retrieval system. The system estimates the user's cloth preference using cloth features. In a previous study, the features were extracted by image processing and 20-bit information. However, the features are insufficient for improving the system accuracy. Hence, in this study, we propose using features that are extracted by a deep neural network (DNN). The DNN is optimized by a stacked denoising autoencoder (SdA). The features are used for retrieval by another neural network (NN), which estimates preference. To verify the effectiveness of this system, we simulated Kansei retrieval. The result of the simulation demonstrated that this system is superior to those reported in the previous study. Thus, the proposed system's effectiveness was confirmed. In addition, we considered and verified a way to improve this system.","","978-1-5386-2726-6","10.1109/SSCI.2017.8285320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8285320","Kansei retrieval;neural net-work;feature extraction","Clothing;Feature extraction;Data models;Artificial neural networks;Noise reduction;Databases","clothing;feature extraction;image coding;image denoising;learning (artificial intelligence);neural nets","Kansei clothing retrieval system;cloth features;feature extraction;user cloth preference;deep neural network;DNN;stacked denoising autoencoder;SdA","","2","","16","","8 Feb 2018","","","IEEE","IEEE Conferences"
"Convolutional Autoencoder-Based Phase Shift Feedback Compression for Intelligent Reflecting Surface-Assisted Wireless Systems","X. Yu; D. Li; Y. Xu; Y. -C. Liang","Faculty of Information Technology, Macau University of Science and Technology, Macau; Faculty of Information Technology, Macau University of Science and Technology, Macau; School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; Center for Intelligent Networking and Communications (CINC), University of Electronic Science and Technology of China, Chengdu, China","IEEE Communications Letters","7 Jan 2022","2022","26","1","89","93","In recent years, intelligent reflecting surface (IRS) has emerged as a promising technology for 6G due to its potential/ability to significantly enhance energy- and spectrum-efficiency. To this end, it is crucial to adjust the phases of reflecting elements of the IRS, and most of the research works focus on how to optimize/quantize the phase for different optimization objectives. In particular, the quantized phase shift (QPS) is assumed to be available at the IRS, which, however, does not always hold and should be fed back to the IRS in practice. Unfortunately, the feedback channel is generally bandwidth-limited, which cannot support a huge amount of feedback overhead of the QPS particularly for a large number of reflecting elements and/or the quantization level of each reflecting element. In order to break this bottleneck, in this letter, we propose a convolutional autoencoder-based scheme, in which the QPS is compressed on the receiver side and reconstructed on the IRS side. In order to solve the problems of mismatched distribution and vanishing gradient, we remove the batch normalization (BN) layers and introduce a denoising module. By doing so, it is possible to achieve a high compression ratio with a reliable reconstruction accuracy in the bandwidth-limited feedback channel, and it is also possible to accommodate existing works assuming available QPS at the IRS. Simulation results confirm the high reconstruction accuracy of the feedback/compressed QPS through a feedback channel, and show that the proposed scheme can significantly outperform the existing compression algorithms.","1558-2558","","10.1109/LCOMM.2021.3123941","The Science and Technology Development Fund, Macau SAR(grant numbers:0003/2019/A1,0018/2019/AMJ,0009/2020/A1,0110/2020/A3); Natural Science Foundation of China(grant numbers:61601071,62071078); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9592779","Intelligent reflecting surface;quantized phase shift;feedback compression;autoencoder;convolutional neural network","Wireless communication;Convolutional neural networks;Computer architecture;Quantization (signal);Noise reduction;Image coding;Decoding","6G mobile communication;convolutional neural nets;data compression;intelligent materials;optimisation;quantisation (signal);telecommunication computing;wireless channels","intelligent reflecting surface-assisted wireless systems;different optimization objectives;quantized phase shift;feedback channel;feedback overhead;quantization level;reflecting element;convolutional autoencoder-based scheme;IRS side;high compression ratio;available QPS;existing compression algorithms;phase shift feedback compression;6G technology;reflecting elements;receiver side;batch normalization layers;denoising module;bandwidth-limited feedback channel;high reconstruction accuracy;feedback-compressed QPS","","1","","19","IEEE","28 Oct 2021","","","IEEE","IEEE Journals"
"Author Identification Using Deep Learning","A. M. Mohsen; N. M. El-Makky; N. Ghanem","Faculty of Engineering, Alexandria University; Faculty of Engineering, Alexandria University; Faculty of Engineering, Alexandria University","2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)","2 Feb 2017","2016","","","898","903","Authorship identification is the task of identifying the author of a given text from a set of suspects. The main concern of this task is to define an appropriate characterization of texts that captures the writing style of authors. Although deep learning was recently used in different natural language processing tasks, it has not been used in author identification (to the best of our knowledge). In this paper, deep learning is used for feature extraction of documents represented using variable size character n-grams. We apply A Stacked Denoising Auto-Encoder (SDAE) for extracting document features with different settings, and then a support vector machine classifier is used for classification. The results show that the proposed system outperforms its counterparts.","","978-1-5090-6167-9","10.1109/ICMLA.2016.0161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7838265","denoising autoencoder;author identification;deep learning","Feature extraction;Machine learning;Training;Neural networks;Encoding;Noise reduction;Decoding","document image processing;feature extraction;image classification;image denoising;learning (artificial intelligence);neural nets;support vector machines","author identification;deep learning;text characterization;natural language processing;document feature extraction;variable size character n-grams;stacked denoising autoencoder;SDAE;support vector machine classifier","","10","","24","","2 Feb 2017","","","IEEE","IEEE Conferences"
"Deep learning of tissue specific speckle representations in optical coherence tomography and deeper exploration for in situ histology","D. Sheet; S. P. K. Karri; A. Katouzian; N. Navab; A. K. Ray; J. Chatterjee","Department of Electrical Engineering, Indian Institute of Technology Kharagpur, India; Indian Institute of Technology Kharagpur, Kharagpur, West Bengal, IN; Computer Aided Medical Procedures, Technische Universität München, Germany; Computer Aided Medical Procedures, Technische Universität München, Germany; Electronics and Electrical Comm. Engg., Indian Institute of Technology Kharagpur, India; School of Medical Science and Technology, Indian Institute of Technology Kharagpur, India","2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)","23 Jul 2015","2015","","","777","780","Optical coherence tomography (OCT) relies on speckle image formation by coherent sensing of photons diffracted from a broadband laser source incident on tissues. Its non-ionizing nature and tissue specific speckle appearance has leveraged rapid clinical translation for non-invasive highresolution in situ imaging of critical organs and tissue viz. coronary vessels, healing wounds, retina and choroid. However the stochastic nature of speckles introduces inter- and intra-observer reporting variability challenges. This paper proposes a deep neural network (DNN) based architecture for unsupervised learning of speckle representations in swept-source OCT using denoising auto-encoders (DAE) and supervised learning of tissue specifics using stacked DAEs for histologically characterizing healthy skin and healing wounds with the aim of reducing clinical reporting variability. Performance of our deep learning based tissue characterization method in comparison with conventional histology of healthy and wounded mice skin strongly advocates its use for in situ histology of live tissues.","1945-8452","978-1-4799-2374-8","10.1109/ISBI.2015.7163987","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7163987","Representation learning;denoising autoencoders;optical coherence tomography;tissue characterization;in situ histology;cutaneous wounds","Speckle;Optical imaging;Biomedical optical imaging;Adaptive optics;Wounds;Skin;Machine learning","biomedical optical imaging;image coding;image denoising;medical image processing;neural nets;optical tomography;skin;speckle;tissue engineering;unsupervised learning;wounds","deep learning;tissue specific speckle representations;optical coherence tomography;in situ histology;OCT;speckle image formation;coherent sensing;photon diffraction;laser source incident;tissue specific speckle appearance;leveraged rapid clinical translation;noninvasive high-resolution in situ imaging;critical organs;coronary vessels;healing wounds;retina;choroid;stochastic nature;interobserver reporting variability challenges;intraobserver reporting variability challenges;deep neural network-based architecture;unsupervised learning;speckle representations;swept-source OCT;denoising autoencoders;histologically characterizing healthy skin;clinical reporting variability;conventional histology;wounded mice skin;live tissues","","5","","11","","23 Jul 2015","","","IEEE","IEEE Conferences"
"A Three-Stage Ensemble Short-Term Wind Power Prediction Method Based on VMD-WT Transform and SDAE Deep Learning","P. Xiaosheng; Z. Zuowei; X. Qiyou; W. Bo; C. Jianfeng; Y. Fan; L. Wenze; H. Zian","State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Operation and Control of Renewable Energy & Storage Systems, China Electric Power Research Institute, Beijing, China; State Key Laboratory of Operation and Control of Renewable Energy & Storage Systems, China Electric Power Research Institute, Beijing, China; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China","2020 IEEE/IAS Industrial and Commercial Power System Asia (I&CPS Asia)","29 Sep 2020","2020","","","1350","1356","Accurate wind power prediction (WPP) will contribute not only to the economic dispatching of power system but also to the safe and stable operation of the power grid. A novel three-stage ensemble short-term WPP method is proposed in this paper to effectively improve the WPP accuracy. First, in stage one, variational mode decomposition (VMD) and wavelet transform (WT) are applied to decompose the original wind power sequence into multiple subsequences. Second, in stage two, multiple stacked denoising auto-encoders (SDAE) are constructed based on the subsequences to perform WPPs separately. Third, in stage three, and the support vector machine (SVM) is applied to assign weights to each sub-prediction value to obtain the final ensemble prediction result. The case study shows that, compared with back propagation neural network (BPNN) and SVM, the average normalized root mean square error (NRMSE) and normalized mean absolute error (NMAE) of proposed ensemble WPP method, in the step range of 12 hours, are reduced by 19.66% and 19.91% compared to BPNN, and 14.43% and 14.65% compared to SVM, respectively, which illustrates the effectiveness and advancement of the proposed method.","","978-1-7281-4303-3","10.1109/ICPSAsia48933.2020.9208460","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9208460","Wind power prediction;ensemble model;stacked denoising autoencoder;variational mode decomposition;wavelet transform","Predictive models;Support vector machines;Machine learning;Wind power generation;Training;Noise reduction;Wind forecasting","backpropagation;image denoising;learning (artificial intelligence);mean square error methods;neural nets;power engineering computing;power grids;support vector machines;wavelet transforms;wind power;wind power plants","short-term wind power prediction method;VMD-WT;SDAE deep learning;accurate wind power prediction;economic dispatching;power system;safe operation;stable operation;power grid;short-term WPP method;WPP accuracy;one mode decomposition;variational mode decomposition;original wind power sequence;multiple subsequences;multiple stacked denoising autoencoders;SVM;normalized mean absolute error;ensemble WPP method;subprediction value;ensemble prediction","","1","","28","","29 Sep 2020","","","IEEE","IEEE Conferences"
"Missing-Insensitive Short-Term Load Forecasting Leveraging Autoencoder and LSTM","K. Park; J. Jeong; D. Kim; H. Kim","Department of Electronic Engineering, Sogang University, Seoul, South Korea; Department of Electronic Engineering, Sogang University, Seoul, South Korea; Smart Power Distribution Laboratory, Korea Power Electric Corporation (KEPCO) Research Institute, Daejeon, South Korea; Department of Electronic Engineering, Sogang University, Seoul, South Korea","IEEE Access","19 Nov 2020","2020","8","","206039","206048","In most deep learning-based load forecasting, an intact dataset is required. Since many real-world datasets contain missing values for various reasons, missing imputation using deep learning is actively studied. However, missing imputation and load forecasting have been considered independently so far. In this article, we provide a deep learning framework that jointly considers missing imputation and load forecasting. We consider a family of autoencoder/long short-term memory (LSTM) combined models for missing-insensitive load forecasting. Specifically, autoencoder (AE), denoising autoencoder (DAE), convolutional autoencoder (CAE), and denoising convolutional autoencoder (DCAE) are considered for extracting features, of which the encoded outputs are fed into the input of LSTM. Our experiments show that the proposed DCAE/LSTM combined model significantly improves forecasting accuracy no matter what missing rate or type (random missing, consecutive block missing) occurs compared to the baseline LSTM.","2169-3536","","10.1109/ACCESS.2020.3036885","Smart City Research and Development project of the Korea Agency for Infrastructure Technology Advancement (KAIA) grant funded by the Ministry of Land, Infrastructure, and Transport(grant numbers:19NSPS-B152996-02); Korea Institute of Energy Technology Evaluation and Planning (KETEP); Ministry of Trade, Industry and Energy (MOTIE), South Korea(grant numbers:20192010107290); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9252883","Deep learning;short-term load forecasting;missing data imputation;feature extraction","Load forecasting;Load modeling;Forecasting;Predictive models;Feature extraction;Training;Time series analysis","convolutional neural nets;learning (artificial intelligence);load forecasting;power engineering computing;recurrent neural nets","LSTM;deep learning-based load forecasting;missing-insensitive short-term load forecasting leveraging autoencoder;consecutive block;random missing block;forecasting accuracy;convolutional autoencoder;missing-insensitive load forecasting;long short-term memory;deep learning framework;missing imputation;intact dataset","","6","","31","CCBY","9 Nov 2020","","","IEEE","IEEE Journals"
"Deep Spatio-Temporal Representation and Ensemble Classification for Attention Deficit/Hyperactivity Disorder","S. Liu; L. Zhao; X. Wang; Q. Xin; J. Zhao; D. S. Guttery; Y. -D. Zhang","Machine Vision Engineering Research Center of Hebei Province, Hebei University, Baoding, China; Machine Vision Engineering Research Center of Hebei Province, Hebei University, Baoding, China; Machine Vision Engineering Research Center of Hebei Province, Hebei University, Baoding, China; Institute of Information Science, Beijing Jiaotong University, Beijing, China; Machine Vision Engineering Research Center of Hebei Province, Hebei University, Baoding, China; Leicester Cancer Research Institute, Leicester, U.K.; Department of Informatics, University of Leicester, Leicester, U.K.","IEEE Transactions on Neural Systems and Rehabilitation Engineering","25 Feb 2021","2021","29","","1","10","Attention deficit/Hyperactivity disorder (ADHD) is a complex, universal and heterogeneous neurodevelopmental disease. The traditional diagnosis of ADHD relies on the long-term analysis of complex information such as clinical data (electroencephalogram, etc.), patients' behavior and psychological tests by professional doctors. In recent years, functional magnetic resonance imaging (fMRI) has been developing rapidly and is widely employed in the study of brain cognition due to its non-invasive and non-radiation characteristics. We propose an algorithm based on convolutional denoising autoencoder (CDAE) and adaptive boosting decision trees (AdaDT) to improve the results of ADHD classification. Firstly, combining the advantages of convolutional neural networks (CNNs) and the denoising autoencoder (DAE), we developed a convolutional denoising autoencoder to extract the spatial features of fMRI data and obtain spatial features sorted by time. Then, AdaDT was exploited to classify the features extracted by CDAE. Finally, we validate the algorithm on the ADHD-200 test dataset. The experimental results show that our method offers improved classification compared with state-of-the-art methods in terms of the average accuracy of each individual site and all sites, meanwhile, our algorithm can maintain a certain balance between specificity and sensitivity.","1558-0210","","10.1109/TNSRE.2020.3019063","Natural Science Foundation of China(grant numbers:61401308,61572063); Natural Science Foundation of Hebei Province(grant numbers:F2020201025,F2016201187,F2018210148); Science Research Project of Hebei Province(grant numbers:QN2020030,QN2016085); Natural Science Foundation of Hebei University(grant numbers:2014-303); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9175033","Adaptive boosting decision tree;ADHD;convolutional denoising autoencoder;fMRI classification","Feature extraction;Functional magnetic resonance imaging;Convolution;Data mining;Classification algorithms;Noise reduction;Machine learning","biomedical MRI;cognition;decision trees;diseases;feature extraction;learning (artificial intelligence);medical disorders;medical image processing;neural nets;pattern classification;support vector machines","fMRI data;spatial features;convolutional denoising autoencoder;convolutional neural networks;ADHD classification;functional magnetic resonance imaging;psychological tests;clinical data;long-term analysis;heterogeneous neurodevelopmental disease;deep spatio-temporal representation;ADHD-200 test dataset","Attention Deficit Disorder with Hyperactivity;Brain;Brain Mapping;Electroencephalography;Humans;Magnetic Resonance Imaging","7","","53","CCBY","24 Aug 2020","","","IEEE","IEEE Journals"
"Multi-model aggregation method for non-intrusive load monitoring based on stacking","M. Weiwei; Z. Zeng; T. Changzhi; Z. Rui; L. Shihao; B. Sibo; Z. He; W. Lihui","State Grid Jiangsu Electric Power CO. LTD. Information & Telecommunication Branch, Nanjing, China; State Grid Jiangsu Electric Power CO. LTD. Information & Telecommunication Branch, Nanjing, China; State Grid Jiangsu Electric Power CO. LTD. Information & Telecommunication Branch, Nanjing, China; State Grid Jiangsu Electric Power CO. LTD. Information & Telecommunication Branch, Nanjing, China; State Grid Jiangsu Electric Power CO. LTD. Information & Telecommunication Branch, Nanjing, China; State Grid Jiangsu Electric Power CO. LTD. Information & Telecommunication Branch, Nanjing, China; School of Instrument Science and Engineering, Southeast University, Nanjing, China; School of Instrument Science and Engineering, Southeast University, Nanjing, China","2022 IEEE 5th International Electrical and Energy Conference (CIEEC)","11 Aug 2022","2022","","","1907","1911","Aiming at the problems that different non-intrusive load decomposition models are applicable to different loads and different states of the same load, a load decomposition integrated model based on stacking integrated denoising autoencoder model and gated neural network model is proposed. The model first uses the denoising autoencoder model and the gated neural network model to decompose the target load of the bus active power sequence, and obtains the active power sequence of the target load corresponding to the two models; Then the fully connected neural network is used to initially aggregate the two active power sequences into an active power sequence of the target load, and the denoising autoencoder model is used for optimization to obtain the final decomposition result of the target load. Experimental results show that the integration model based on stacking can combine the decomposition advantages of the base model, give full play to the respective advantages of DAE model and Gru model, and realize accurate load decomposition.","","978-1-6654-1104-2","10.1109/CIEEC54735.2022.9846264","Science and Technology Project of State Grid; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9846264","non-intrusive load monitoring;denoising autoencoder;gate recurrent unit;ensemble learning","Load monitoring;Aggregates;Stacking;Neural networks;Noise reduction;Logic gates;Smart grids","neural nets;optimisation;power engineering computing;stacking","multimodel aggregation method;nonintrusive load monitoring;nonintrusive load decomposition models;integrated model;denoising autoencoder model;gated neural network model;active power sequence;fully connected neural network;integration model;DAE model;Gru model;load decomposition;stacking","","","","10","IEEE","11 Aug 2022","","","IEEE","IEEE Conferences"
"Context-aware feature query to improve the prediction performance","M. Kachuee; A. Hosseini; B. Moatamed; S. Darabi; M. Sarrafzadeh","University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles; University of California, Los Angeles","2017 IEEE Global Conference on Signal and Information Processing (GlobalSIP)","8 Mar 2018","2017","","","838","842","The decision to select which features to use and query can be effectively addressed based on the available features or context. This paper presents a novel approach based on denoising autoencoders and sensitivity analysis in neural networks to efficiently query for unknown features given the context. In this setting, a denoising autoencoder is responsible for handling unknown features. On the other hand, the sensitivity of output predictions with respect to each unknown feature is used as a measure of feature importance. We evaluated the suggested method on human activity recognition and handwritten digit recognition tasks. According to the results, using the proposed method can reduce the number of extracted features in these datasets by approximately 70% and 60%, respectively. This reduction in the number of required features can be crucially important in mobile and battery-powered IoT systems as it reduces the amount of required data acquisition and computational load substantially.","","978-1-5090-5990-4","10.1109/GlobalSIP.2017.8309078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8309078","Feature Query;Context Aware;Sensitivity Analysis;Autoencoder;Neural Network","Feature extraction;Noise reduction;Sensitivity;Heuristic algorithms;Prediction algorithms;Training;Computational modeling","data acquisition;feature extraction;handwritten character recognition;Internet of Things;neural nets","context-aware feature query;denoising autoencoder;human activity recognition;handwritten digit recognition tasks;battery-powered IoT systems;mobile IoT systems","","2","","17","","8 Mar 2018","","","IEEE","IEEE Conferences"
"AnoDDPM: Anomaly Detection with Denoising Diffusion Probabilistic Models using Simplex Noise","J. Wyatt; A. Leach; S. M. Schmon; C. G. Willcocks","Department of Computer Science, Durham University, Durham, UK; Department of Computer Science, Durham University, Durham, UK; Department of Mathematical Sciences, Durham University, Durham, UK; Department of Computer Science, Durham University, Durham, UK","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","23 Aug 2022","2022","","","649","655","Generative models have been shown to provide a powerful mechanism for anomaly detection by learning to model healthy or normal reference data which can subsequently be used as a baseline for scoring anomalies. In this work we consider denoising diffusion probabilistic models (DDPMs) for unsupervised anomaly detection. DDPMs have superior mode coverage over generative adversarial networks (GANs) and higher sample quality than variational autoencoders (VAEs). However, this comes at the expense of poor scalability and increased sampling times due to the long Markov chain sequences required. We observe that within reconstruction-based anomaly detection a full-length Markov chain diffusion is not required. This leads us to develop a novel partial diffusion anomaly detection strategy that scales to high-resolution imagery, named AnoDDPM. A secondary problem is that Gaussian diffusion fails to capture larger anomalies; therefore we develop a multi-scale simplex noise diffusion process that gives control over the target anomaly size. AnoDDPM with simplex noise is shown to significantly outperform both f-AnoGAN and Gaussian diffusion for the tumorous dataset of 22 T1-weighted MRI scans (CCBS Edinburgh) qualitatively and quantitatively (improvement of +25.5% Sørensen–Dice coefficient, +17.6% IoU and +7.4% AUC).","2160-7516","978-1-6654-8739-9","10.1109/CVPRW56347.2022.00080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9857019","","Training;Image segmentation;Shape;Magnetic resonance imaging;Gaussian noise;Noise reduction;Markov processes","biodiffusion;biomedical MRI;image denoising;image reconstruction;Markov processes;medical image processing;tumours","generative adversarial networks;reconstruction-based anomaly detection;full-length Markov chain diffusion;novel partial diffusion anomaly detection strategy;Gaussian diffusion;AnoDDPM;denoising diffusion probabilistic models;generative models;normal reference data;unsupervised anomaly detection;Markov chain sequences;multiscale simplex noise diffusion;variational autoencoders;T1-weighted MRI scans","","","","29","IEEE","23 Aug 2022","","","IEEE","IEEE Conferences"
"Demography-based facial retouching detection using subclass supervised sparse autoencoder","A. Bharati; M. Vatsa; R. Singh; K. W. Bowyer; X. Tong","University of Notre Dame; University of Notre Dame; University of Notre Dame; IIIT, Delhi; IIIT, Delhi","2017 IEEE International Joint Conference on Biometrics (IJCB)","1 Feb 2018","2017","","","474","482","Digital retouching of face images is becoming more widespread due to the introduction of software packages that automate the task. Several researchers have introduced algorithms to detect whether a face image is original or retouched. However, previous work on this topic has not considered whether or how accuracy of retouching detection varies with the demography of face images. In this paper, we introduce a new Multi-Demographic Retouched Faces (MDRF) dataset, which contains images belonging to two genders, male and female, and three ethnicities, Indian, Chinese, and Caucasian. Further, retouched images are created using two different retouching software packages. The second major contribution of this research is a novel semi-supervised autoencoder incorporating “sub-class” information to improve classification. The proposed approach outperforms existing state-of-the-art detection algorithms for the task of generalized retouching detection. Experiments conducted with multiple combinations of ethnicities show that accuracy of retouching detection can vary greatly based on the demographics of the training and testing images.","2474-9699","978-1-5386-1124-1","10.1109/BTAS.2017.8272732","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8272732","","Face;Tools;Databases;Feature extraction;Skin;Shape;Support vector machines","demography;face recognition;feature extraction;image classification;image coding;image denoising;image representation;learning (artificial intelligence)","demography;facial retouching detection;sparse autoencoder;digital retouching;face image;MultiDemographic Retouched Faces dataset;retouched images;generalized retouching detection;training;testing images;retouching software packages;semisupervised autoencoder","","11","","40","","1 Feb 2018","","","IEEE","IEEE Conferences"
"Fully-Convolutional Denoising Auto-Encoders for NILM in Large Non-Residential Buildings","D. García-Pérez; D. Pérez-López; I. Díaz-Blanco; A. González-Muñiz; M. Domínguez-González; A. A. Cuadrado Vega","Electrical Engineering Department, University of Oviedo, Gijón, Spain; SUPPRESS Research Group, University of León, León, Spain; Electrical Engineering Department, University of Oviedo, Gijón, Spain; Electrical Engineering Department, University of Oviedo, Gijón, Spain; SUPPRESS Research Group, University of León, León, Spain; Electrical Engineering Department, University of Oviedo, Gijón, Spain","IEEE Transactions on Smart Grid","20 Apr 2021","2021","12","3","2722","2731","Great concern regarding energy efficiency has led the research community to develop approaches which enhance the energy awareness by means of insightful representations. An example of intuitive energy representation is the parts-based representation provided by Non-Intrusive Load Monitoring (NILM) techniques which decompose non-measured individual loads from a single total measurement of the installation, resulting in more detailed information about how the energy is spent along the electrical system. Although there are previous works that have achieved important results on NILM, the majority of the NILM systems were only validated in residential buildings, leaving a niche for the study of energy disaggregation in non-residential buildings, which present a specific behavior. In this article, we suggest a novel fully-convolutional denoising auto-encoder architecture (FCN-dAE) as a convenient NILM system for large non-residential buildings, and it is compared, in terms of particular aspects of large buildings, to previous denoising auto-encoder approaches (dAE) using real electrical consumption from a hospital facility. Furthermore, by means of three use cases, we show that our approach provides extra helpful funcionalities for energy management tasks in large buildings, such as meter replacement, gap filling or novelty detection.","1949-3061","","10.1109/TSG.2020.3047712","Principado de Asturias Government through the Predoctoral Grant “Severo Ochoa”; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9309369","Energy efficiency;building energy consumption;NILM;energy disaggregation;denoising auto-encoders","Noise reduction;Buildings;Load modeling;Hidden Markov models;Feature extraction;Computer architecture;Architecture","building management systems;buildings (structures);control engineering computing;convolutional neural nets;energy conservation;energy management systems;load management;power engineering computing;power system control;power system measurement","nonresidential buildings;energy efficiency;energy awareness;FCN-dAE;hospital facility;real electrical consumption;fully-convolutional denoising autoencoder architecture;energy management tasks;energy disaggregation;residential buildings;NILM systems;single total measurement;nonIntrusive load monitoring","","4","","47","IEEE","28 Dec 2020","","","IEEE","IEEE Journals"
"Collaborative filtering recommendation algorithm based on improved denoising auto encoder","Z. Tian; H. Liu","School of Computer Science (National Pilot Software Engineering School), Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science (National Pilot Software Engineering School), Beijing University of Posts and Telecommunications, Beijing, China","2020 2nd International Conference on Information Technology and Computer Application (ITCA)","7 May 2021","2020","","","23","28","Aiming at the problems of sparse scoring matrix and low recommendation accuracy of traditional collaborative filtering algorithms, this paper proposes a collaborative filtering recommendation algorithm based on improved denoising auto encoder. First of all, this topic adds a balance matrix to the encoding and decoding process of the denoising auto encoder to compress the high-dimensional and sparse user behavior vector into a low-dimensional and dense user feature vector. Then, the user similarity is calculated in the process, celebrity factors are considered to obtain user similarity based on celebrity effect. Finally, a program recommendation list is generated based on the final user similarity. Experimental results show that the algorithm enhances the performance of scoring prediction, and improves the accuracy and recall rate of recommendation results.","","978-1-6654-0378-8","10.1109/ITCA52113.2020.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9421970","component;Denoising auto encoder;Collaborative filtering;Recommended system","Collaborative filtering;Noise reduction;Computer applications;Filtering algorithms;Prediction algorithms;Information filters;Encoding","collaborative filtering;compressed sensing;neural nets;recommender systems;vectors","collaborative filtering recommendation;sparse scoring matrix;denoising autoencoder;balance matrix;low-dimensional user feature vector;dense user feature vector;program recommendation list;sparse user behavior vector compression;high-dimensional user behavior vector compression","","","","12","IEEE","7 May 2021","","","IEEE","IEEE Conferences"
"DCA-CLA: A scRNA-seq Classification Framework based on Deep Count Autoencoder","Y. Wu; Y. Guo; J. Li; S. Lao; J. Guo; H. Wang","College of Systems Engineering National University of Defense Technology, Changsha, China; College of Systems Engineering National University of Defense Technology, Changsha, China; College of Systems Engineering National University of Defense Technology, Changsha, China; College of Systems Engineering National University of Defense Technology, Changsha, China; College of Systems Engineering National University of Defense Technology, Changsha, China; College of Systems Engineering National University of Defense Technology, Changsha, China","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","10","Identifying cell types is crucial for single-cell RNA sequencing (scRNA-seq) analysis and can be potentially utilized to understand high-level biological processes. Supervised models based on neural networks have recently been successfully applied in the scRNA-seq cell type classification problem and achieved promising results. While most existing works directly use the raw or transformed data, we argue that the original data are too sparse and high-dimensional, and extracting their effective low-dimensional features can better train downstream classifiers, thereby improving the cell type classification performance. In this paper, we propose a novel framework, named Deep Count Autoencoder-based Classifier (DCA-CLA), to leverage the discriminative low-dimensional features for classification. Specifically, DCA-CLA first denoises the original count matrix and extracts the data features from the hidden layer using a deep count autoencoder module, then it feeds these bottleneck features into the classifier network to train the learnable parameters and test the performance. Experimental results on eight separate datasets and four pairs of datasets demonstrate that the proposed DCA-CLA framework achieves competitive performance over the state-of-the-art frameworks.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533488","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533488","Denoising autoencoder;single-cell RNA sequencing classification;supervised learning;bioinformatics","Sequential analysis;Analytical models;RNA;Neural networks;Supervised learning;Feature extraction;Data models","","","","","","26","","20 Sep 2021","","","IEEE","IEEE Conferences"
"A Hybrid-driven Soft Sensor with Complex Process Data Based on DAE and Mechanism-introduced GRU","R. Guo; H. Liu; W. Wang; G. Xie; Y. Zhang","School of Automation and Information Engineering, Xi'an University of Technology, Xi'an; School of Automation and Information Engineering, Xi'an University of Technology, Xi'an; School of Automation and Information Engineering, Xi'an University of Technology, Xi'an; School of Automation and Information Engineering, Xi'an University of Technology, Xi'an; Department of Mechanical, Industrial, and Aerospace Engineering, Concordia University, Montreal, Quebec","2021 IEEE 10th Data Driven Control and Learning Systems Conference (DDCLS)","25 Jun 2021","2021","","","553","558","With the increasing complexity of industrial processes, process big data inevitably has strong nonlinear, dynamic and noise problems, which restrict the accurate establishment of data-driven or mechanism-driven soft sensor models. Therefore, a soft sensor based on the denoising autoencoder and mechanism-introduced gated recurrent units is proposed. The denoising autoencoder is used to denoise the data. The mechanism-introduced gated recurrent units are used to introduce the information contained in the mechanism model and extract the dynamic characteristics of the process data by deep learning. This soft sensing method can deal with various problems of complex process data and introduce mechanism model for hybrid-driven modeling, which improves the prediction performance of the soft sensor. The effectiveness and superiority of the method are verified by the industrial case of predicting the thermal deformation of an air preheater rotor.","2767-9861","978-1-6654-2423-3","10.1109/DDCLS52934.2021.9455690","National Natural Science Foundation (NNSF) of China(grant numbers:61973248,61833013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9455690","Hybrid-driven soft sensor;Complex process data;Deep learning;Denoising autoencoder;Gated recurrent unit;Dynamic feature extractor","Atmospheric modeling;Rotors;Process control;Predictive models;Logic gates;Feature extraction;Data models","Big Data;deep learning (artificial intelligence);production engineering computing;recurrent neural nets;soft sensors","complex process data;hybrid-driven soft sensor;industrial processes;process Big Data;denoising autoencoder;mechanism-introduced GRU;mechanism-introduced gated recurrent units;deep learning","","2","","23","","25 Jun 2021","","","IEEE","IEEE Conferences"
"Waveform Recognition in Multipath Fading using Autoencoder and CNN with Fourier Synchrosqueezing Transform","G. Kong; M. Jung; V. Koivunen","Department of Signal Processing and Acoustics, Aalto University, Finland; Department of Electrical and Computer Engineering, Wireless@VT, Virginia Tech, VA, USA; Department of Signal Processing and Acoustics, Aalto University, Finland","2020 IEEE International Radar Conference (RADAR)","11 Jun 2020","2020","","","612","617","In this paper the problem of recognizing radar waveforms is addressed for multipath fading channels. Waveform classification is needed in spectrum sharing, radar-communications coexistence, cognitive radars, spectrum monitoring and signal intelligence. Different radar waveforms exhibit different properties in time-frequency domain. We propose a deep learning method for waveform classification. The received signal is first equalized to mitigate the effect of multipath fading channels by using a denoising auto-encoder (DAE). Then, the equalized signal is processed with Fourier synchrosqueezing transform that has excellent properties in revealing time-varying behavior, rate of, strength and number of oscillatory components in signals. The resulting time-frequency description is represented as a bivariate image that is fed into a convolutional neural network. The proposed method has superior performance over the widely used the Choi-Williams distribution (CWD) method in distinguishing among different radar waveforms even at low signal-to-noise ratio regime.","2640-7736","978-1-7281-6813-5","10.1109/RADAR42522.2020.9114783","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9114783","","Fading channels;Deep learning;Time-frequency analysis;Noise reduction;Radar;Transforms;Radar imaging","cognitive radar;convolutional neural nets;encoding;fading channels;Fourier transforms;learning (artificial intelligence);multipath channels;radar signal processing;radio spectrum management;signal denoising;synchronisation;telecommunication computing;time-frequency analysis","bivariate image;CNN;DAE;denoising autoencoder;CWD method;Choi-Williams distribution method;time-frequency description;signal intelligence;spectrum monitoring;cognitive radars;radar-communication coexistence;spectrum sharing;waveform recognition;signal-to-noise ratio;radar waveforms;time-varying behavior;Fourier synchrosqueezing transform;equalized signal;multipath fading channels;waveform classification;deep learning method;time-frequency domain","","3","","18","","11 Jun 2020","","","IEEE","IEEE Conferences"
"scCDG: A Method based on DAE and GCN for scRNA-seq data Analysis","H. Wang; J. Zhao; Y. Su; C. -H. Zheng","College of Mathematics and Systems Science, Xinjiang University, 47907 Urumqi, Xinjiang, China, (e-mail: haiyun_wang_xju@163.com); College of Mathematics and Systems Science, Xinjiang University, 47907 Urumqi, Xinjiang, China, 830046 (e-mail: zhaojianping@126.com); Anhui University, 12487 Hefei, Anhui, China, (e-mail: suyansen1985@163.com); the School of Artificial Intelligence, Anhui University, Hefei, Anhui, China, (e-mail: zhengch99@126.com)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2021","PP","99","1","1","Identifying cell types is one of the main goals of single-cell RNA sequencing (scRNA-seq) analysis, and clustering is a common method for this item. However, the massive amount of data and the excess noise level bring challenge for single cell clustering. To address this challenge, in this paper, we introduced a novel method named single-cell clustering based on denoising autoencoder and graph convolution network (scCDG), which consists of two core models. The first model is a denoising autoencoder (DAE) used to fit the data distribution for data denoising. The second model is a graph autoencoder using graph convolution network (GCN), which projects the data into a low-dimensional space (compressed) preserving topological structure information and feature information in scRNA-seq data simultaneously. Extensive analysis on seven real scRNA-seq datasets demonstrate that scCDG outperforms state-of-the-art methods in some research sub-fields, including single cell clustering, visualization of transcriptome landscape, and trajectory inference.","1557-9964","","10.1109/TCBB.2021.3126641","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9609691","Clustering;scRNA-seq;denoising autoencoder (DAE);graph convolution network (GCN)","Noise reduction;Convolution;Computer architecture;Microprocessors;Sequential analysis;Encoding;Decoding","","","","","","","IEEE","9 Nov 2021","","","IEEE","IEEE Early Access Articles"
"Cases without Borders: Automating Knowledge Acquisition Approach using Deep Autoencoders and Siamese Networks in Case-Based Reasoning","K. Amin","German Research Center for Artificial Intelligence, Technische Universitat Kaiserslautern, Kaiserslautern, Germany","2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)","13 Feb 2020","2019","","","133","140","Finding an ideal text case-base representation for a new domain is important for a CBR [1] system. To do this, the choice of an ideal representation is guided by the domain characteristics and the complexity of its cases. Recently, the explosion of deep learning techniques and other forms of vectorised representations, has provided a new source for case insights. Richer text features can be extracted and used for each case if required. In this paper, we build on recent work in this area and generate richer case representation by automatically acquiring domain knowledge from unstructured sentences. We describe how the Deep Knowledge Acquisition Framework obtains its representation vectors from stemmed words and improving these vectors iteratively, suggesting high quality outputs and relevance to domain experts based on either explicit queries or their past intentions. We evaluate these ideas using two, not related, datasets from the automotive and legal domains respectively. The results show the benefits of combining Autoencoders and Siamese Networks in CBR while achieving better textual data dimensionality reduction, data de-noising and similarity measures.","2375-0197","978-1-7281-3798-8","10.1109/ICTAI.2019.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8995321","Case-based Reasoning, Textual CBR, Multi-lingual Text Analysis, Deep Learning, Natural Language Processing, Siamese Networks, Autoencoders","","case-based reasoning;information retrieval;knowledge acquisition;learning (artificial intelligence);neural nets;text analysis","deep learning techniques;vectorised representations;case representation;domain knowledge;representation vectors;domain experts;legal domains;siamese networks;case-based reasoning;CBR system;deep knowledge acquisition framework;text features extraction;deep autoencoders networks;stemmed words;text case-base representation;textual data dimensionality reduction;data denoising","","2","","27","","13 Feb 2020","","","IEEE","IEEE Conferences"
"Predicted-occupancy grids for vehicle safety applications based on autoencoders and the Random Forest algorithm","P. Nadarajan; M. Botsch; S. Sardina","Technische Hochschule Ingolstadt, Ingolstadt, Germany; Technische Hochschule Ingolstadt, Ingolstadt, Germany; RMIT University, Melbourne, Australia","2017 International Joint Conference on Neural Networks (IJCNN)","3 Jul 2017","2017","","","1244","1251","In this paper, a probabilistic space-time representation of complex traffic scenarios is predicted using machine learning algorithms. Such a representation is significant for all active vehicle safety applications especially when performing dynamic maneuvers in a complex traffic scenario. As a first step, a hierarchical situation classifier is used to distinguish the different types of traffic scenarios. This classifier is responsible for identifying the type of the road infrastructure and the safety-relevant traffic participants of the driving environment. With each class representing similar traffic scenarios, a set of Random Forests (RFs) is individually trained to predict the probabilistic space-time representation, which depicts the future behavior of traffic participants. This representation is termed as a Predicted-Occupancy Grid (POG). The input to the RFs is an Augmented Occupancy Grid (AOG). In order to increase the learning accuracy of the RFs and to perform better predictions, the AOG is reduced to low-dimensional features using a Stacked Denoising Autoencoder (SDA). The excellent performance of the proposed machine learning approach consisting of SDAs and RFs is demonstrated in simulations and in experiments with real vehicles. An application of POGs to estimate the criticality of traffic scenarios and to determine safe trajectories is also presented.","2161-4407","978-1-5090-6182-2","10.1109/IJCNN.2017.7965995","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7965995","","Roads;Feature extraction;Radio frequency;Geometry;Computational modeling;Prediction algorithms;Machine learning algorithms","image classification;image coding;learning (artificial intelligence);road safety;traffic engineering computing","predicted-occupancy grid;vehicle safety application;autoencoders;random forest algorithm;probabilistic space-time representation;traffic scenario;machine learning algorithm;hierarchical situation classifier;road infrastructure;safety-relevant traffic participants;POG;augmented occupancy grid;AOG;stacked denoising autoencoder;SDA","","3","","19","","3 Jul 2017","","","IEEE","IEEE Conferences"
"Application of a regressive neural network with autoencoder for monochromatic images in ultrasound tomography","T. Rymarczyk; G. Klosowski; T. Cieplak; E. Kozlowski; K. Kania","Research and Development Center, Netrix S.A., Lublin, University of Economics and Innovation in Lublin, Lublin, Poland; Faculty of Management, Lublin University of Technology, Lublin, Poland; Faculty of Management, Lublin University of Technology, Lublin, Poland; Faculty of Management, Lublin University of Technology, Lublin, Poland; Research and Development Center, Lublin, Poland","2019 Applications of Electromagnetics in Modern Engineering and Medicine (PTZE)","1 Aug 2019","2019","","","156","160","The article presents a novel approach to ultrasound tomography in industrial applications. In order to visualize the interior of a tank (reactor) filled with tap water, a single neural network enhanced with autoencoder was used. A novelty is the use of an autoencoder to improve the quality of the measurement vector. Thanks to the use of the autoencoder for denoising the input measurements in connection with the appropriately adapted neural network, the quality of the output image was improved. A robust algorithm was developed that properly reconstructs hidden objects in monochrome images with high efficiency.","","978-83-88131-00-4","10.23919/PTZE.2019.8781750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8781750","ultrasound tomography;artificial neural networks;process tomography;autoencoders","Artificial neural networks;Image reconstruction;Neurons;Tomography;Training;Electromagnetics;Ultrasonic imaging","acoustic tomography;image coding;image reconstruction;industrial engineering;neural nets;regression analysis;ultrasonic imaging","single neural network;autoencoder;measurement vector;input measurements;output image;monochrome images;regressive neural network;monochromatic images;ultrasound tomography;industrial applications;tank;tap water","","","","23","","1 Aug 2019","","","IEEE","IEEE Conferences"
"Application of temporal convolutional neural network combined with autoencoder in short-term bus load forecasting","P. Tian; G. Wu; H. Chen; T. Xie; X. Tang; R. Wang","State Grid Chongqing Electric Power Company, Chongqing, China; State Grid Chongqing Electric Power Research Institute, Chongqing, China; College of Automation, Chongqing University of Posts and Telecommunications, Chongqing, China; College of Automation, Chongqing University of Posts and Telecommunications, Chongqing, China; College of Automation, Chongqing University of Posts and Telecommunications, Chongqing, China; College of Union with University of Cincinnati, university of Chongqing, Chongqing, China","2020 Chinese Automation Congress (CAC)","29 Jan 2021","2020","","","526","531","Improving the accuracy of bus load forecasting is a crucial step to achieve the goal of fine intelligent power grid dispatching. Aiming at the problem of small base and large fluctuation of bus load data, a short-term bus load forecasting model (AE-TCN) based on the combination of Auto-Encoder (AE) and Temporal Convolution Network (TCN) is proposed. Firstly, the Wavelet Threshold Denoising (WTD) is used to process the original bus load data to remove the burr, then, the data with high similarity is categorized into one cluster by using the Bisecting K-means clustering algorithm. AE-TCN model is formed to fit the processed data and obtain the predicted value of the load. Finally, to verify the effectiveness of the proposed method, two bus load data of 220kV and 110kV in a city of china are employed. The simulation results show that the proposed method has higher prediction accuracy than traditional prediction models.","2688-0938","978-1-7281-7687-1","10.1109/CAC51589.2020.9326723","Science and Technology Project of State Grid; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9326723","short-term bus load forecasting;wavelet threshold denoising;bisecting k-means;temporal convolutional network","Load modeling;Load forecasting;Convolution;Predictive models;Noise reduction;Wavelet coefficients;Time series analysis","convolutional neural nets;load forecasting;pattern clustering;power engineering computing;power grids;wavelet transforms","bus load data;AE-TCN model;temporal convolutional neural network;autoencoder;fine intelligent power grid dispatching;short-term bus load forecasting model;wavelet threshold denoising;K-means clustering algorithm;prediction models","","","","13","","29 Jan 2021","","","IEEE","IEEE Conferences"
"Target/clutter disentanglement using deep adversarial training on micro-Doppler signatures","L. Cifola; R. I. A. Harmanny","Thales Nederland B.V., Delft; Thales Nederland B.V., Delft","2019 16th European Radar Conference (EuRAD)","21 Nov 2019","2019","","","201","204","In this manuscript we argue that, under certain conditions, machine learning techniques can help to increase the signal to background level of a target signal to aid the detection and classification process in the radar signal processing chain. Specifically, the deep adversarial training concept, through the use of Denoising Adversarial Autoencoders (DAEs), has been applied for the problem of separation the micro-Doppler signatures of wind-turbine and drones, in order to be able to extract the latter for further detection and classification purposes.","","978-2-87487-057-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8904837","micro-Doppler;Deep Learning;Adversarial training;wind-turbines;mini-UAVs;classification","","Doppler radar;learning (artificial intelligence);radar clutter;radar computing;radar signal processing;signal classification;signal denoising","microDoppler signatures;machine learning techniques;background level;target signal;classification process;radar signal processing chain;deep adversarial training concept;denoising adversarial autoencoders;classification purposes","","","","5","","21 Nov 2019","","","IEEE","IEEE Conferences"
"Control System Response Improvement via Denoising Using Deep Neural Networks","K. Fathi; M. Mahdavi","Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran; Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran","2019 IEEE 10th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)","13 Feb 2020","2019","","","0377","0382","Noise is an inseparable part of control systems. Every sensor reading used for determining the state of a control system is corrupted with noise., therefor increasing the signal to noise ratio of sensor readings can significantly improve the performance of systems. The proposed filter in this paper captures the underlying probability distribution of the noise-free input signal in the training stage and therefor is capable of refining the corrupted input signal regardless of the distribution of the added noise. In order to acquire better data-driven based results in the suggested approach, it has been decided to use different neural network structures and stack these layers to form a hybrid multilayer filter. The properties of the stacked neural network sublayers guarantee a robust and general solution for the intended purpose. The key elements of the proposed filter are two auto-encoders., a dense neural network and a convolutional layer. Effects of every sublayer on the corrupted input signal., along with fine-tuning of these sublayers are discussed in detail. Afterwards in order to assess the generality and the robustness of the method., the proposed filter is exposed to a non-Gaussian noise. Finally., the proposed filter is tested on a linear and a nonlinear system. The comparison between systems” output to the reconstructed signal with that of the original noise-free signal., suggests the substantial improvement in the performance of the given systems. This improvement is in terms of systems” output resemblance to the reference noise-free output signal when the reconstructed signal is applied to the systems.","","978-1-7281-3885-5","10.1109/UEMCON47517.2019.8993083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8993083","Deep learning;Auto-encoder;Dense neural network;Control system;Sensor reading;Signal Processing;Denoising","","filtering theory;neural nets;probability;signal denoising;signal reconstruction","noise-free input signal;neural network structures;hybrid multilayer filter;stacked neural network sublayers;nonGaussian noise;nonlinear system;signal reconstruction;reference noise-free output signal;control system response improvement;deep neural networks;signal to noise ratio;sensor readings;probability distribution;autoencoders;convolutional layer","","","","17","","13 Feb 2020","","","IEEE","IEEE Conferences"
"Face frontalization enhanced by deep learning","A. Çelik; N. Arıca","Bilgisayar Mühendisliği Bölümü, Bahçeşehir Üniversitesi, İstanbul, Türkiye; Bilgisayar Mühendisliği Bölümü, Bahçeşehir Üniversitesi, İstanbul, Türkiye","2017 25th Signal Processing and Communications Applications Conference (SIU)","29 Jun 2017","2017","","","1","4","In this study, a new approach based on 3-D models and deep learning to frontalize face images is proposed. Specifically designed for facial expression analysis, the proposed approach aims to reduce possible negative effects that a posed face image can generate, by normalizing the face region. In the first phase, the face image is semi-frontalized, with a pre-established 3-D reference model based approach. Then, missing regions on semi-frontalized images due to geometric transformation are reconstructed with the help of a denoising stacked autoencoder network. In this phase, missing regions created by line of sight are learned, with a deep architecture, using numerous images. When examined, it can be said that, faces acquired with the proposed approach, are objectively better than the faces acquired with a deep learning or 3-D based method alone. Therefore, it is assumed that the proposed approach can be used in face based computer vision methods as a beneficial pre-processing step.","","978-1-5090-6494-6","10.1109/SIU.2017.7960615","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7960615","face frontalization;deep learning;pre-processing","Face;Face recognition;Machine learning;Computer vision;Solid modeling;Image reconstruction","computer vision;emotion recognition;face recognition;image denoising;learning (artificial intelligence)","face frontalization enhancement;deep learning;frontalize face images;facial expression analysis;preestablished 3-D reference model based approach;semi-frontalized images;geometric transformation;stacked autoencoder network denoising;face-based computer vision","","","","11","","29 Jun 2017","","","IEEE","IEEE Conferences"
"Recognizing Emotions From Whispered Speech Based on Acoustic Feature Transfer Learning","J. Deng; S. Frühholz; Z. Zhang; B. Schuller","Chair of Complex and Intelligent Systems, University of Passau, Passau, Germany; ETH Zürich, Zürich, Switzerland; Chair of Complex and Intelligent Systems, University of Passau, Passau, Germany; Chair of Complex and Intelligent Systems, University of Passau, Passau, Germany","IEEE Access","20 May 2017","2017","5","","5235","5246","Whispered speech, as an alternative speaking style for normal phonated (non-whispered) speech, has received little attention in speech emotion recognition. Currently, speech emotion recognition systems are exclusively designed to process normal phonated speech and can result in significantly degraded performance on whispered speech because of the fundamental differences between normal phonated speech and whispered speech in vocal excitation and vocal tract function. This study, motivated by the recent successes of feature transfer learning, sheds some light on this topic by proposing three feature transfer learning methods based on denoising autoencoders, shared-hidden-layer autoencoders, and extreme learning machines autoencoders. Without the availability of labeled whispered speech data in the training phase, in turn, the three proposed methods can help modern emotion recognition models trained on normal phonated speech to reliably handle also whispered speech. Throughout extensive experiments on the Geneva Whispered Emotion Corpus and the Berlin Emotional Speech Database, we compare our methods to alternative methods reported to perform well for a wide range of speech emotion recognition tasks and find that the proposed methods provide significant superior performance on both normal phonated and whispered speech.","2169-3536","","10.1109/ACCESS.2017.2672722","Bundesministerium für Bildung und Forschung within IKT 2020 through the Emotionssensitives Assistenzsystem for Mensches met Behinderungen Project(grant numbers:16SV7213); European Community’s Seventh Framework Programme within the European Research Council Starting Grant through the iHEARu Project(grant numbers:338164); European Union’s Horizon 2020 Programme within the Research and Innovation Action through the Multi-Modal Human-Robot Interaction for Teaching and Expanding Social Imagination in Autistic Children Project(grant numbers:688835); Swiss National Science Foundation(grant numbers:PP00P1 157409/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7879177","Speech emotion recognition;whispered speech;feature transfer learning;autoencoders;extreme learning machines","Speech;Speech recognition;Emotion recognition;Speech processing;Acoustics;Training;Databases","emotion recognition;encoding;speech recognition","Berlin emotional speech database;Geneva whispered emotion corpus;extreme learning machines autoencoders;shared-hidden-layer autoencoders;denoising autoencoders;vocal tract function;vocal excitation;speech emotion recognition;normal phonated speech;alternative speaking style;acoustic feature transfer learning;whispered speech","","26","","64","OAPA","15 Mar 2017","","","IEEE","IEEE Journals"
"Revisiting Role of Autoencoders in Adversarial Settings","B. C. Kim; J. U. Kim; H. Lee; Y. M. Ro","Image and Video Systems Lab, School of Electrical Engineering, KAIST, South Korea; Image and Video Systems Lab, School of Electrical Engineering, KAIST, South Korea; Image and Video Systems Lab, School of Electrical Engineering, KAIST, South Korea; Image and Video Systems Lab, School of Electrical Engineering, KAIST, South Korea","2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","1856","1860","To combat against adversarial attacks, autoencoder structure is widely used to perform denoising which is regarded as gradient masking. In this paper, we revisit the role of autoencoders in adversarial settings. Through the comprehensive experimental results and analysis, this paper presents the inherent property of adversarial robustness in the autoencoders. We also found that autoencoders may use robust features that cause inherent adversarial robustness. We believe that our discovery of the adversarial robustness of the autoencoders can provide clues to the future research and applications for adversarial defense.","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9191259","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9191259","Deep learning;adversarial robustness;adversarial example","Robustness;Training;Perturbation methods;Noise reduction;Gold;Entropy;Image reconstruction","security of data","autoencoders;adversarial attacks;autoencoder structure;adversarial robustness;adversarial defense","","2","","22","","30 Sep 2020","","","IEEE","IEEE Conferences"
"A Deep Imbalanced Learning Framework for Transient Stability Assessment of Power System","B. Tan; J. Yang; Y. Tang; S. Jiang; P. Xie; W. Yuan","School of Electrical Engineering and Automation, Wuhan University, Wuhan, China; School of Electrical Engineering and Automation, Wuhan University, Wuhan, China; Department of Computer and Electrical Engineering and Computer Science, Institute for Sensing and Embedded Network Systems Engineering, Florida Atlantic University, Boca Raton, FL, USA; School of Electrical Engineering and Automation, Wuhan University, Wuhan, China; State Grid Hunan Electric Power Company Ltd., Changsha, China; State Grid Hunan Electric Power Company Ltd., Changsha, China","IEEE Access","1 Jul 2019","2019","7","","81759","81769","Maintaining transient stability is a core requirement for ensuring safe operation of power systems. Hence, quick and accurate assessment of the transient stability of power systems is particularly critical. As the deployment of wide area measurement systems (WAMS) expands, transient stability assessment (TSA) based on machine learning with data of phasors measurement units (PMUs) also develops rapidly. However, unstable samples of the power system are rarely seen in practice which affects greatly the effectiveness of transient instability recognition. To address this problem, we propose a deep imbalanced learning-based TSA framework. First, an improved denoising autoencoder (DAE) is constructed to map the training set to hidden space for dimension reduction. Then, adaptive synthetic sampling (ADASYN) is further used to synthesize unstable samples in hidden space to balance the proportion of different classes. Third, the synthesized data are decoded into the original space to enhance the training set. Finally, an ensemble cost-sensitive classifier based on a stacked denoising autoencoder (SDAE) is designed to extract different feature patterns, and the SDAEs are merged with a fusion layer to classify the status of the power system. The simulation results of two benchmark power systems indicate that the proposed method can effectively improve the recognition accuracy of unstable cases by combining nonlinear data synthesis with ensemble cost-sensitive learning methods. Compared with other imbalanced learning methods, the proposed framework enjoys superiority both in accuracy and G-mean.","2169-3536","","10.1109/ACCESS.2019.2923799","State Grid Hunan Electric Power Company Ltd.; Hunan Electric Power Company of China State Grid; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8740932","Deep imbalanced learning;transient stability of power system;denoising autoencoder (DAE);ensemble cost-sensitive SDAE;feature patterns;G-mean","Power system stability;Transient analysis;Phasor measurement units;Numerical stability;Stability criteria","feature extraction;learning (artificial intelligence);neural nets;pattern classification;phasor measurement;power engineering computing;power system transient stability;sampling methods","wide area measurement systems;transient instability recognition;deep imbalanced learning-based TSA framework;power system transient stability assessment;WAMS;machine learning;phasors measurement units;PMUs;stacked denoising autoencoder;adaptive synthetic sampling;ADASYN;ensemble cost-sensitive classifier;SDAE;nonlinear data synthesis;G-mean;feature patterns extraction","","43","","41","CCBY","19 Jun 2019","","","IEEE","IEEE Journals"
"Pre-training Long Short-term Memory Neural Networks for Efficient Regression in Artificial Speech Postfiltering","M. Coto-Jiménez","Escuela de Ingenieráa Eléctrica, Universidad de Costa Rica, San Jose, Costa Rica","2018 IEEE International Work Conference on Bioinspired Intelligence (IWOBI)","13 Sep 2018","2018","","","1","7","Several attempts to enhance statistical parametric speech synthesis have contemplated deep-learning-based postfilters, which learn to perform a mapping of the synthetic speech parameters to the natural ones, reducing the gap between them. In this paper, we introduce a new pre-training approach for neural networks, applied in LSTM-based postfilters for speech synthesis, with the objective of enhancing the quality of the synthesized speech in a more efficient manner. Our approach begins with an auto-regressive training of one LSTM network, whose is used as an initialization for postfilters based on a denoising autoencoder architecture. We show the advantages of this initialization on a set of multi-stream postfilters, which encompass a collection of denoising autoencoders for the set of MFCC and fundamental frequency parameters of the artificial voice. Results show that the initialization succeeds in lowering the training time of the LSTM networks and achieves better results in enhancing the statistical parametric speech in most cases, when compared to the common random-initialized approach of the networks.","","978-1-5386-7506-9","10.1109/IWOBI.2018.8464204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8464204","Deep learning;Denoising autoencoders;LSTM;Machine learning;Signal processing;Speech Synthesis","Training;Hidden Markov models;Speech synthesis;Mel frequency cepstral coefficient;Noise reduction;Neural networks;Speech enhancement","learning (artificial intelligence);neural nets;regression analysis;speech synthesis","long short-term memory neural networks;artificial speech postfiltering;MFCC;deep-learning-based postfilters;auto-regressive training;LSTM network;denoising autoencoder architecture;fundamental frequency parameters;random-initialized approach;statistical parametric speech synthesis","","3","","34","","13 Sep 2018","","","IEEE","IEEE Conferences"
"Improved Extreme Learning Machine Based on Deep Learning and Its Application in Handwritten Digits Recognition","X. Xiao; B. Liao; Q. Long; Y. He; J. Li; L. Han","College of Information Science and Engineering, Jishou University, Jishou, China; College of Information Science and Engineering, Jishou University, Jishou, China; College of Information Science and Engineering, Jishou University, Jishou, China; College of Information Science and Engineering, Jishou University, Jishou, China; College of Information Science and Engineering, Jishou University, Jishou, China; College of Information Science and Engineering, Jishou University, Jishou, China","2021 11th International Conference on Intelligent Control and Information Processing (ICICIP)","16 Dec 2021","2021","","","360","366","Traditional extreme learning machine (ELM) requires a large number of hidden layer neurons in its applications, and the ability to process high-dimensional big data samples is weak. In response to the above problems, this paper proposes an improved extreme learning machine algorithm based on deep learning. This algorithm combines the double pseudo-inverse extreme learning machine (DPELM) algorithm, which has high classification accuracy and simple network structure, with the denoising autoencoder (DAE) which can extract more essential data features. Among them, DAE is used to extract the features of the data that needs to be recognized, and the DPELM mainly plays as a classifier to quickly classify and recognize the extracted features. Experimental results show that in the recognition of handwritten digits, the double pseudo-inverse extreme learning machine based on denoising autoencoder (DAE-DPELM) algorithm needs only a small number of hidden layer neurons. In addition, compared with the traditional ELM algorithm and DAE-ELM algorithm, DAE-DPELM algorithm has a higher classification accuracy.","","978-1-6654-2515-5","10.1109/ICICIP53388.2021.9642213","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9642213","extreme learning machine;deep learning;denoising autoencoder;handwritten digits recognition","Deep learning;Handwriting recognition;Extreme learning machines;Noise reduction;Neurons;Feature extraction;Classification algorithms","deep learning (artificial intelligence);feature extraction;handwritten character recognition;pattern classification","deep learning;handwritten digits recognition;traditional extreme learning machine;hidden layer neurons;high-dimensional big data samples;improved extreme learning machine algorithm;double pseudoinverse extreme learning machine algorithm;high classification accuracy;essential data features;denoising autoencoder algorithm;traditional ELM algorithm;DAE-ELM algorithm;DAE-DPELM algorithm","","","","17","IEEE","16 Dec 2021","","","IEEE","IEEE Conferences"
"Non-linear prediction with LSTM recurrent neural networks for acoustic novelty detection","E. Marchi; F. Vesperini; F. Weninger; F. Eyben; S. Squartini; B. Schuller","Machine Intelligence & Signal Processing Group, TU München, Germany; A3LAB, Università Politecnica, delle Marche, Italy; Machine Intelligence & Signal Processing Group, TU München, Germany; Machine Intelligence & Signal Processing Group, TU München, Germany; A3LAB, Università Politecnica, delle Marche, Italy; Chair of Complex and Intelligent Systems, University of Passau, Germany","2015 International Joint Conference on Neural Networks (IJCNN)","1 Oct 2015","2015","","","1","7","Acoustic novelty detection aims at identifying abnormal/novel acoustic signals which differ from the reference/normal data that the system was trained with. In this paper we present a novel approach based on non-linear predictive denoising autoencoders. In our approach, auditory spectral features of the next short-term frame are predicted from the previous frames by means of Long-Short Term Memory (LSTM) recurrent denoising autoencoders. We show that this yields an effective generative model for audio. The reconstruction error between the input and the output of the autoencoder is used as activation signal to detect novel events. The autoencoder is trained on a public database which contains recordings of typical in-home situations such as talking, watching television, playing and eating. The evaluation was performed on more than 260 different abnormal events. We compare results with state-of-the-art methods and we conclude that our novel approach significantly outperforms existing methods by achieving up to 94.4% F-Measure.","2161-4407","978-1-4799-1960-4","10.1109/IJCNN.2015.7280757","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280757","","","acoustic signal processing;recurrent neural nets;signal denoising;signal detection","nonlinear prediction;LSTM recurrent neural networks;acoustic novelty detection;abnormal/novel acoustic signals;reference/normal data;nonlinear predictive denoising;long-short term memory;recurrent denoising autoencoders;public database","","36","","36","","1 Oct 2015","","","IEEE","IEEE Conferences"
"Feature representation for speech emotion recognition","M. Abdollahpour; J. Zamani; H. S. Rad","Department of Electrical Engineering, Amirkabir University of Technology (Tehran Polytechnic); Department of Electrical Engineering, Amirkabir University of Technology (Tehran Polytechnic); Department of Medical Physics and Biomedical Engineering, Research Center for Science and Technology in Medicine (RCSTIM), Tehran, Iran","2017 Iranian Conference on Electrical Engineering (ICEE)","20 Jul 2017","2017","","","1465","1468","In this paper we proposed a method for feature representation and enhancement algorithm based on denoising auto encoder (DAE) for speech emotion recognition. We defined new similarity and dissimilarity cost functions that enforce features relating to the same class be similar and features corresponding to different classes be dissimilar. We represented a new supervised DAE architecture that learns features robust to speaker and linguistic variations. Experimental results demonstrate significant improvement over original features.","","978-1-5090-5963-8","10.1109/IranianCEE.2017.7985273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7985273","denoising autoencoder;speech emotion recognition;feature enhancement","Speech;Noise reduction;Databases;Feature extraction;Speech recognition;Emotion recognition;Neural networks","emotion recognition;learning (artificial intelligence);medical computing;speech recognition","feature representation;feature enhancement algorithm;denoising auto encoder;speech emotion recognition;supervised DAE architecture;linguistic variations","","1","","13","","20 Jul 2017","","","IEEE","IEEE Conferences"
"Denoising Auto-Encoder with Recurrent Skip Connections and Residual Regression for Music Source Separation","J. -Y. Liu; Y. -H. Yang","Academia Sinica, Research Center for IT Innovation, Taipei, Taiwan; Academia Sinica, Research Center for IT Innovation, Taipei, Taiwan","2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)","17 Jan 2019","2018","","","773","778","Convolutional neural networks with skip connections have shown good performance in music source separation. In this work, we propose a denoising Auto-encoder with Recurrent skip Connections (ARC). We use 1D convolution along the temporal axis of the time-frequency feature map in all layers of the fully-convolutional network. The use of 1D convolution makes it possible to apply recurrent layers to the intermediate outputs of the convolution layers. In addition, we also propose an enhancement network and a residual regression method to further improve the separation result. The recurrent skip connections, the enhancement module, and the residual regression all improve the separation quality. The ARC model with residual regression achieves 5.74 siganl-to-distoration ratio (SDR) in vocals with MUSDB (used in SiSEC 2018). We also evaluate the ARC model alone on the older dataset DSD100 (used in SiSEC 2016) and it achieves 5.91 SDR in vocals.","","978-1-5386-6805-4","10.1109/ICMLA.2018.00123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8614148","Music source separation, recurrent neural network, skip connections, residual regression","Convolution;Spectrogram;Training;Source separation;Noise reduction;Training data","audio signal processing;convolutional neural nets;music;recurrent neural nets;regression analysis;signal denoising;source separation;time-frequency analysis","recurrent neural network;residual regression;denoising autoencoder;convolution layers;recurrent layers;time-frequency feature map;convolutional neural networks;music source separation;recurrent skip connections","","13","","27","","17 Jan 2019","","","IEEE","IEEE Conferences"
"Deep Convolutional Autoencoder Applied for Noise Reduction in Range-Doppler Maps of FMCW Radars","M. L. L. de Oliveira; M. J. G. Bekooij","Computer Architecture for Embedded Systems, University of Twente, Enschede, The Netherlands; Department of Embedded Software and Signal Processing, NXP Semiconductors, Eindhoven, The Netherlands","2020 IEEE International Radar Conference (RADAR)","11 Jun 2020","2020","","","630","635","In this paper, we discuss the usage of deep Convolutional Autoencoders (CAE) for denoising Range-Doppler (RD) maps of an FMCW radar in a near-field situation with pedestrians and cyclists as moving objects. Traditional methods for noise reduction such as CFAR with Peak Detection (PD) have poor performance under highly noisy environments, especially when objects have low reflectivity, like pedestrians. We propose the use of Convolutional Autoencoders, in various configurations, to overcome those limitations. Due to its Artificial Neural Network nature, CAE can extract features, learn to identify patterns and recognize moving objects - such as humans and bicycles - while the traditional method acts passively. The results indicate that the usage of CAE overcame CFAR with PD by 76.8%, on average, for reconstructing objects in their correct positions. The results of this work may have many applications, for instance, detecting distant moving objects that are too faint for regular detection.","2640-7736","978-1-7281-6813-5","10.1109/RADAR42522.2020.9114719","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9114719","","Reflectivity;Noise reduction;Radar detection;Detectors;Feature extraction;Radar tracking;Object recognition","convolutional neural nets;CW radar;feature extraction;FM radar;image denoising;learning (artificial intelligence);object detection;target tracking","CAE;CFAR;PD;noise reduction;Range-Doppler maps;FMCW radar;deep convolutional autoencoders;RD;near-field situation;pedestrians;peak detection;noisy environments;artificial neural network;feature extraction","","8","","19","","11 Jun 2020","","","IEEE","IEEE Conferences"
"Neighborhood Geometric Structure-Preserving Variational Autoencoder for Smooth and Bounded Data Sources","X. Chen; C. Wang; X. Lan; N. Zheng; W. Zeng","Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Microsoft Research Asia, Beijing, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Microsoft Research Asia, Beijing, China","IEEE Transactions on Neural Networks and Learning Systems","3 Aug 2022","2022","33","8","3598","3611","Many data sources, such as human poses, lie on low-dimensional manifolds that are smooth and bounded. Learning low-dimensional representations for such data is an important problem. One typical solution is to utilize encoder–decoder networks. However, due to the lack of effective regularization in latent space, the learned representations usually do not preserve the essential data relations. For example, adjacent video frames in a sequence may be encoded into very different zones across the latent space with holes in between. This is problematic for many tasks such as denoising because slightly perturbed data have the risk of being encoded into very different latent variables, leaving output unpredictable. To resolve this problem, we first propose a neighborhood geometric structure-preserving variational autoencoder (SP-VAE), which not only maximizes the evidence lower bound but also encourages latent variables to preserve their structures as in ambient space. Then, we learn a set of small surfaces to approximately bound the learned manifold to deal with holes in latent space. We extensively validate the properties of our approach by reconstruction, denoising, and random image generation experiments on a number of data sources, including synthetic Swiss roll, human pose sequences, and facial expression images. The experimental results show that our approach learns more smooth manifolds than the baselines. We also apply our approach to the tasks of human pose refinement and facial expression image interpolation where it gets better results than the baselines.","2162-2388","","10.1109/TNNLS.2021.3053591","Trico-Robot Plan of NSFC(grant numbers:91748208); NSFC(grant numbers:61973246,62088102); Shaanxi Project(grant numbers:2018ZDCXLGY0607); Program of the Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350115","Bounded representation;manifold learning;variational autoencoder (VAE)","Task analysis;Manifolds;Principal component analysis;Noise reduction;Interpolation;Image reconstruction;Decoding","approximation theory;face recognition;graph theory;interpolation;learning (artificial intelligence);pose estimation","slightly perturbed data;different latent variables;neighborhood geometric structure-preserving variational autoencoder;ambient space;learned manifold;latent space;human pose sequences;smooth manifolds;bounded data sources;human poses;low-dimensional manifolds;low-dimensional representations;encoder-decoder networks;learned representations;essential data relations;adjacent video frames","","","","53","IEEE","8 Feb 2021","","","IEEE","IEEE Journals"
"Denoising and Voltage Estimation in Modular Multilevel Converters Using Deep Neural-Networks","S. Langarica; G. Pizarro; P. M. Poblete; F. Radrigán; J. Pereda; J. Rodriguez; F. Núñez","Department of Electrical Engineering, Pontificia Universidad Católica de Chile, Santiago, Chile; Department of Electrical Engineering, Pontificia Universidad Católica de Chile, Santiago, Chile; Department of Electrical Engineering, Pontificia Universidad Católica de Chile, Santiago, Chile; Department of Electrical Engineering, Pontificia Universidad Católica de Chile, Santiago, Chile; UC Energy Research Center, Pontificia Universidad Católica de Chile, Santiago, Chile; College of Engineering, Universidad Andres Bello, Santiago, Chile; Department of Electrical Engineering, Pontificia Universidad Católica de Chile, Santiago, Chile","IEEE Access","24 Nov 2020","2020","8","","207973","207981","Modular Multilevel Converters (MMCs) have become one of the most popular power converters for medium/high power applications, from transmission systems to motor drives. However, to operate properly, MMCs require a considerable number of sensors and communication of sensitive data to a central controller, all under relevant electromagnetic interference produced by the high frequency switching of power semiconductors. This work explores the use of neural networks (NNs) to support the operation of MMCs by: i) denoising measurements, such as stack currents, using a blind autoencoder NN; and ii) estimating the sub-module capacitor voltages, using an encoder-decoder NN. Experimental results obtained with data from a three-phase MMC show that NNs can effectively clean sensor measurements and estimate internal states of the converter accurately, even during transients, drastically reducing sensing and communication requirements.","2169-3536","","10.1109/ACCESS.2020.3038552","ANID PIA ACT192013 and ANID/FONDECYT/1171142; ANID/Doctorado Nacional/21200565; ANID/Doctorado Nacional/21201967; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9261401","Modular multilevel converters;neural networks;cyber-physical systems","Decoding;Noise reduction;Multilevel converters;Capacitors;Voltage measurement;Estimation;Artificial neural networks","electromagnetic interference;HVDC power convertors;neural nets;power engineering computing;switching convertors;voltage-source convertors","deep neural-networks;modular multilevel converters;power converters;transmission systems;motor drives;electromagnetic interference;high frequency switching;power semiconductors;sub-module capacitor voltages;sensor measurements;blind autoencoder;denoising estimation;voltage estimation;medium power application;high power applications;denoising measurements;encoder-decoder;three-phase MMC;sensing requirements;communication requirements","","4","","23","CCBY","17 Nov 2020","","","IEEE","IEEE Journals"
"Face Verification via Learned Representation on Feature-Rich Video Frames","G. Goswami; M. Vatsa; R. Singh","Indraprastha Institute of Information Technology Delhi, Delhi, India; Indraprastha Institute of Information Technology Delhi, Delhi, India; Indraprastha Institute of Information Technology Delhi, Delhi, India","IEEE Transactions on Information Forensics and Security","19 May 2017","2017","12","7","1686","1698","Abundance and availability of video capture devices, such as mobile phones and surveillance cameras, have instigated research in video face recognition, which is highly pertinent in law enforcement applications. While the current approaches have reported high accuracies at equal error rates, performance at lower false accept rates requires significant improvement. In this paper, we propose a novel face verification algorithm, which starts with selecting feature-rich frames from a video sequence using discrete wavelet transform and entropy computation. Frame selection is followed by representation learning-based feature extraction, where three contributions are presented: 1) deep learning architecture, which is a combination of stacked denoising sparse autoencoder (SDAE) and deep Boltzmann machine (DBM); 2) formulation for joint representation in an autoencoder; and 3) updating the loss function of DBM by including sparse and low rank regularization. Finally, a multilayer neural network is used as the classifier to obtain the verification decision. The results are demonstrated on two publicly available databases, YouTube Faces and Point and Shoot Challenge. Experimental analysis suggests that: 1) the proposed feature-richness-based frame selection offers noticeable and consistent performance improvement compared with frontal only frames, random frames, or frame selection using perceptual no-reference image quality measures and 2) joint feature learning in SDAE and sparse and low rank regularization in DBM helps in improving face verification performance. On the benchmark Point and Shoot Challenge database, the algorithm yields the verification accuracy of over 97% at 1% false accept rate whereas, on the YouTube Faces database, over 95% verification accuracy is observed at equal error rate.","1556-6021","","10.1109/TIFS.2017.2668221","MEITY, India, NVIDIA GPU grant, and Infosys CAI, IIIT-Delhi; IBM Ph.D. fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7850956","Deep learning;autoencoder;deep Boltzmann machine;face recognition;frame selection","Face;Face recognition;Databases;Feature extraction;YouTube;Machine learning;Neural networks","Boltzmann machines;discrete wavelet transforms;entropy;face recognition;feature selection;image denoising;image sequences;learning (artificial intelligence);multilayer perceptrons;video signal processing","face verification algorithm;representation learning;feature-rich video frames;video capture devices;video face recognition;feature-rich frames selection;video sequence;discrete wavelet transform;entropy computation;feature extraction;deep learning architecture;stacked denoising sparse autoencoder;SDAE;deep Boltzmann machine;DBM;multilayer neural network","","31","","50","IEEE","13 Feb 2017","","","IEEE","IEEE Journals"
"Encoding High-Level Features: An Approach To Robust Transfer Learning","L. Y. E. Ramos Cheret; T. E. A. de Oliveira","Department of Computer Science, Lakehead University, Thunder Bay, Canada; Department of Computer Science, Lakehead University, Thunder Bay, Canada","2022 IEEE International Conference on Omni-layer Intelligent Systems (COINS)","18 Aug 2022","2022","","","1","6","Transfer Learning (TL) plays a vital role in image classification systems based on Deep Convolutional Neural Networks (DCNNs). Systems employing such technique may be susceptible to distortions on images, motivating the development of robust DCNNs capable of facing these problems. Unfortunately, changes in the architecture of DCNNs are sometimes specific to a kind of distortion and result in models that need to be retrained from scratch. This work proposes the use of autoencoders as intermediaries between pre-trained DCNNs and classifiers, delegating the denoising task to this architecture trained to encode feature maps. The classifiers are then trained to map the inputs from the autoencoder latent spaces to their respective classes. Models employing this approach achieved 3% to 4% increase in accuracy and 50% to 70% reduction in loss on the CIFAR10 and CIFAR100 datasets. The results also showed an up to 80% reduction in loss and up to 15% increase in accuracy for images with unseen distortions compared to the classical TL approach. This work improves classification results and increases robustness to distortions in a straightforward manner.","","978-1-6654-8356-8","10.1109/COINS54846.2022.9854982","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9854982","Image Classification;Variational Autoencoder;Transfer Learning;Deep Convolutional Networks;Impulse Noise;Gaussian;JPEG Compression","Training;Adaptation models;Image coding;Sensitivity;Transfer learning;Transform coding;Distortion","convolutional neural nets;deep learning (artificial intelligence);encoding;feature extraction;image classification;image coding;image denoising;learning (artificial intelligence)","image distortion;autoencoders;denoising task;CIFAR100 datasets;image classification systems;pretrained DCNN;high-level features encoding;robust transfer learning;deep convolutional neural networks;CIFAR10 datasets","","","","16","IEEE","18 Aug 2022","","","IEEE","IEEE Conferences"
"Autoencoders Without Reconstruction for Textural Anomaly Detection","P. A. Adey; S. Akçay; M. J. R. Bordewich; T. P. Breckon","Department of Computer Science, Durham University; Intel, UK; Department of Computer Science, Durham University; Department of Engineering, Durham University, UK","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","8","Automatic anomaly detection in natural textures is a key component within quality control for a range of high-speed, high-yield manufacturing industries that rely on camera-based visual inspection techniques. Targeting anomaly detection through the use of autoencoder reconstruction error readily facilitates training on an often more plentiful set of non-anomalous samples, without the explicit need for a representative set of anomalous training samples that may be difficult to source. Unfortunately, autoencoders struggle to reconstruct high-frequency visual information and therefore, such approaches often fail to achieve a low enough reconstruction error for non-anomalous pixels. In this paper, we propose a new approach in which the autoencoder is trained to directly output the desired per-pixel measure of abnormality without first having to perform reconstruction. This is achieved by corrupting training samples with noise and then predicting how pixels need to be shifted so as to remove the noise. Our direct approach enables the model to compress anomaly scores for normal pixels into a tight bound close to zero, resulting in very clean anomaly segmentations that significantly improve performance. We also introduce the Reflected ReLU output activation function that better facilitates training under this direct regime by leaving values that fall within the image dynamic range unmodified. Overall, an average area under the ROC curve of 96% is achieved on the texture classes of the MVTecAD benchmark dataset, surpassing that achieved by all current state-of-the-art methods.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533804","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533804","","Training;Manufacturing industries;Visualization;Image segmentation;Image coding;Neural networks;Quality control","cameras;feature extraction;image denoising;image reconstruction;image representation;image segmentation;image texture;inspection;neural nets;transfer functions","representative set;anomalous training samples;high-frequency visual information;nonanomalous pixels;anomaly scores;normal pixels;clean anomaly segmentations;Reflected ReLU output activation function;image dynamic range;texture classes;textural anomaly detection;automatic anomaly detection;natural textures;quality control;high-yield manufacturing industries;camera-based visual inspection techniques;autoencoder reconstruction error;high-speed manufacturing industries;per-pixel measure;training samples;MVTecAD benchmark dataset","","","","29","IEEE","20 Sep 2021","","","IEEE","IEEE Conferences"
"Frequency Hopping Signal Modulation Recognition Based on Time-Frequency Analysis","J. Zhang; C. Hou; Y. Lin; J. Zhang; Y. Xu; S. Chen","Harbin Engineering University College of Information and Communication Engineering, Harbin, Heilongjiang, China; Key Laboratory of Advanced Marine Communication and Information Technology, Ministry of Industry and Information Technology, Harbin Engineering University, Harbin, Heilongjiang, China; Harbin Engineering University College of Information and Communication Engineering, Harbin, Heilongjiang, China; Harbin Engineering University College of Information and Communication Engineering, Harbin, Heilongjiang, China; Harbin Engineering University College of Information and Communication Engineering, Harbin, Heilongjiang, China; Harbin Engineering University College of Information and Communication Engineering, Harbin, Heilongjiang, China","2021 IEEE 18th International Conference on Mobile Ad Hoc and Smart Systems (MASS)","13 Dec 2021","2021","","","46","52","Compared with the fixed frequency signal, the carrier frequency of frequency hopping (FH) signal is controlled by the pseudo-random codes, so it has better concealment and anti-interference. As an important parameter of FH communication, the modulation mode of FH signal can provide powerful support for combat response, such as identification of friend or foe attribute, positioning and jamming guidance, intelligence information extraction, etc. However, there is still a big gap in modulation recognition of FH signals at the domestic and foreign countries. In this paper, a modulation recognition method of FH signal based on time-frequency transform is proposed. The time-frequency images of different modulation types of FH signals are obtained by SPWVD time-frequency transform, and then the time-frequency images are denoised by convolution autoencoder. Finally, the denoised images are sent to convolution neural network for feature extraction and classification recognition. Simulation experiments prove that the proposed method achieves a good classification effect at low signal-to-noise ratios (SNRs), and achieves a recognition rate of 93.67% at -2dB.","2155-6814","978-1-6654-4935-9","10.1109/MASS52906.2021.00015","National Natural Science Foundation of China; Research and Development; Natural Science Foundation of Heilongjiang Province; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9637769","frequency hopping signal;modulation recognition;time frequency analysis;convolution autoencoder;feature extraction","Time-frequency analysis;Frequency modulation;Convolution;Computational modeling;Noise reduction;Transforms;Spread spectrum communication","convolutional neural nets;feature extraction;frequency hop communication;image classification;image denoising;radiofrequency interference;random codes;time-frequency analysis;transforms","modulation recognition method;time-frequency images;signal-to-noise ratios;frequency hopping signal modulation recognition;time-frequency analysis;fixed frequency signal;frequency hopping communication;SPWVD time-frequency transform;convolution autoencoder;denoised images;convolution neural network;feature extraction;classification recognition;pseudorandom codes","","1","","28","IEEE","13 Dec 2021","","","IEEE","IEEE Conferences"
"Hierarchical feature exttratction for object recogition in complex SAR image using modified convolutional auto-encoder","S. R. Tian; C. Wang; H. Zhang","Department of Electronic Engineering, School of Electronic and Optical Engineering, Nanjing, China; Chinese Academy of Sciences, Institute of Remote Sensing and Digital Earth, Beijing, China; Department of Electronic Engineering, School of Electronic and Optical Engineering, Nanjing, China","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","854","857","Automatic target recognition is a crucial task for SAR remote sensing. Unlike other methods, the unsupervised representation learning based on deep architecture can obtain robust high-level features directly from raw data. A drawback of most unsupervised representation learning methods in SAR ATR is that they only deal with amplitude images. In addition, many methods utlize a single layer architecture to extract pixel-level/mid-level features which are probably sensitive to condition variation. In this paper, a feature extraction method based on modified stacked convolutional denoising auto-encoder (MSCDAE) for complex SAR images is proposed, where convolutional kernels of MSCDAE are learned by 1-D modified denoising auto-encoders. By stacking the convolutional layers and pooling layers, high-level representation of objects are learned. The features are subsequently sent to a trained SVM for object classification. Experimental results demonstrate that the proposed method can provide a significant improvement in the ATR performance.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127087","Modified convolutional denoising autoencoder (MCSAE);Deep learning;synthetic aperture radar(SAR);automatic target recognition(ATR)","","feature extraction;geophysical image processing;image denoising;image representation;learning (artificial intelligence);neural nets;object recognition;radar imaging;remote sensing by radar;support vector machines;synthetic aperture radar","object classification;convolutional layers;auto-encoders;MSCDAE;modified stacked convolutional denoising auto-encoder;feature extraction method;pixel-level/mid-level features;single layer architecture;amplitude images;SAR ATR;raw data;unsupervised representation;SAR remote sensing;crucial task;automatic target recognition;convolutional auto-encoder;complex SAR image;object recognition;hierarchical feature extraction","","","","14","","4 Dec 2017","","","IEEE","IEEE Conferences"
"Research on anomaly detection method combining distance correlation coefficient and autoencode","X. Shu; S. Zhang; Y. Li; G. Shen; P. Liu; G. Ran","College of Intelligence Science and Technology, National University of Defense Technology Laboratory of Science and Technology on Integrated Logistics Support, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology Laboratory of Science and Technology on Integrated Logistics Support, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology Laboratory of Science and Technology on Integrated Logistics Support, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology Laboratory of Science and Technology on Integrated Logistics Support, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology Laboratory of Science and Technology on Integrated Logistics Support, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology Laboratory of Science and Technology on Integrated Logistics Support, National University of Defense Technology, Changsha, China","2022 Prognostics and Health Management Conference (PHM-2022 London)","1 Jul 2022","2022","","","136","142","This study proposes a method of anomaly detection based on a combination of distance correlation coefficient-based feature selection algorithm and autoencoder. In this paper, we use the distance correlation coefficient to analyze the correlation of the original feature set, and divides the feature set into multiple feature subsets according to the correlation between features. The features within each feature subset are filtered by the constructed feature representativeness evaluation indexes to remove redundant features. Then, we built a convolutional denoising autoencoder to enhance the anomaly detection ability of the autoencoder in the time dimension. In the constructed autoencoder, a modular design approach is used to divide the encoder and decoder structures into encoding and decoding units, and the accuracy of fitting the network to the training data can be tuned by adjusting the number of these two units. Finally, the proposed method is validated with a turbofan engine. The results show that the proposed method outperforms other traditional methods in accuracy and has application value.","2166-5656","978-1-6654-7954-7","10.1109/PHM2022-London52454.2022.00032","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9808599","autoencoder;distance correlation coefficient;anomaly detection","Correlation coefficient;Training;Correlation;Training data;Feature extraction;Data models;Decoding","data handling;encoding;filtering theory","anomaly detection ability;constructed autoencoder;anomaly detection method;autoencode;distance correlation coefficient;original feature;multiple feature subsets;feature subset;convolutional denoising autoencoder;feature representativeness evaluation indexes;feature selection algorithm","","","","16","IEEE","1 Jul 2022","","","IEEE","IEEE Conferences"
"Audio enhancing with DNN autoencoder for speaker recognition","O. Plchot; L. Burget; H. Aronowitz; P. Matëjka","Vysoke uceni technicke v Brne, Brno, MoravskoslezskÃ½, CZ; Vysoke uceni technicke v Brne, Brno, MoravskoslezskÃ½, CZ; IBM Research - Haifa; Vysoke uceni technicke v Brne, Brno, MoravskoslezskÃ½, CZ","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","19 May 2016","2016","","","5090","5094","In this paper we present a design of a DNN-based autoencoder for speech enhancement and its use for speaker recognition systems for distant microphones and noisy data. We started with augmenting the Fisher database with artificially noised and reverberated data and trained the autoencoder to map noisy and reverberated speech to its clean version. We use the autoencoder as a preprocessing step in the later stage of modelling in state-of-the-art text-dependent and text-independent speaker recognition systems. We report relative improvements up to 50% for the text-dependent system and up to 48% for the text-independent one. With text-independent system, we present a more detailed analysis on various conditions of NIST SRE 2010 and PRISM suggesting that the proposed preprocessig is a promising and efficient way to build a robust speaker recognition system for distant microphone and noisy data.","2379-190X","978-1-4799-9988-0","10.1109/ICASSP.2016.7472647","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472647","speaker recognition;denoising;de-reverberation;neural networks;DNN","Speech;Microphones;Speaker recognition;Noise measurement;Artificial neural networks;Training;Speech enhancement","microphones;speaker recognition;speech enhancement","DNN autoencoder;audio enhancing;speech enhancement;distant microphones;noisy data;Fisher database;text-independent speaker recognition systems;speaker recognition system;distant microphone","","29","","","","19 May 2016","","","IEEE","IEEE Conferences"
"Improved anomaly detection by training an autoencoder with skip connections on images corrupted with Stain-shaped noise","A. -S. Collin; C. De Vleeschouwer","ICTEAM Institute, UCLouvain, Louvain-La-Neuve, Belgium; ICTEAM Institute, UCLouvain, Louvain-La-Neuve, Belgium","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","7915","7922","In industrial vision, the anomaly detection problem can be addressed with an autoencoder trained to map an arbitrary image, i.e. with or without any defect, to a clean image, i.e. without any defect. In this approach, anomaly detection relies conventionally on the reconstruction residual or, alternatively, on the reconstruction uncertainty. To improve the sharpness of the reconstruction, we consider an autoencoder architecture with skip connections. In the common scenario where only clean images are available for training, we propose to corrupt them with a synthetic noise model to prevent the convergence of the network towards the identity mapping, and introduce an original Stain noise model for that purpose. We show that this model favors the reconstruction of clean images from arbitrary real-world images, regardless of the actual defects appearance. In addition to demonstrating the relevance of our approach, our validation provides the first consistent assessment of reconstruction-based methods, by comparing their performance over the MVTec AD dataset [1], both for pixel- and image-wise anomaly detection. Our implementation is available at https://github.com/anncollin/AnomalyDetection-Keras.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9412842","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9412842","","Training;Location awareness;Uncertainty;Monte Carlo methods;Pattern recognition;Image reconstruction;Anomaly detection","computer vision;image classification;image denoising;image reconstruction;learning (artificial intelligence);neural net architecture","skip connections;Stain-shaped noise;industrial vision;arbitrary image;clean image;reconstruction residual;reconstruction uncertainty;autoencoder architecture;synthetic noise model;identity mapping;actual defects appearance;image-wise anomaly detection;MVTec AD dataset;pixel- and image-wise anomaly detection","","6","","27","","5 May 2021","","","IEEE","IEEE Conferences"
"Collaborative Apportionment Noise-Based Soft Sensor Framework","S. Gao; Q. Zhang; R. Tian; Z. Ma; Y. Liu; Z. Hao","College of Computer Science and Engineering, Northwest Normal University, Lanzhou, China; College of Computer Science and Engineering, Northwest Normal University, Lanzhou, China; College of Computer Science and Engineering, Northwest Normal University, Lanzhou, China; College of Computer Science and Engineering, Northwest Normal University, Lanzhou, China; College of Computer Science and Engineering, Northwest Normal University, Lanzhou, China; School of Finance and Business, Vocational College, Jinan, China","IEEE Transactions on Instrumentation and Measurement","31 Aug 2022","2022","71","","1","12","Recently, feature extraction-based soft sensor techniques have developed rapidly in the control, optimization, and detection processes of industrial production. However, the raw data obtained from the complex industrial processes are often contaminated by noise, which significantly impacts the results of soft sensor models. We introduce the collaborative apportionment noise (CAN) method based on the density peaks clustering (DPC) theory, based on which we have proposed a CAN-based soft sensor framework (CAN-SSF) and designed an example model called the CAN-based convolutional neural networks (CAN-CNNs) model for industry data prediction. In the CAN method, we determined the magnitude and direction of the noise by the bias degree and deviation of the data. Then, the noise is collaboratively apportioned by the credibility degree of the data. Finally, to further explore the feasibility of the CAN method, we added a hyperparameter called reduction degree and conducted two groups of independent experiments for the example model CAN-CNN. The results have shown that the adaptability and stability of the CAN method are higher than the traditional wavelet transform (WT) denoising and denoising autoencoders (DAEs). In addition, the prediction performance of the proposed CAN-SSF is better than that of the traditional CNN and stacked autoencoders (SAEs) models to solve the industrial soft sensor problems.","1557-9662","","10.1109/TIM.2022.3200088","National Natural Science Foundation of China(grant numbers:71961028); Scientific Research Projects of Colleges and Universities in Gansu Province(grant numbers:2019B-038); Backbone Fund of Youth Teachers’ Capability Promotion(grant numbers:NWNU-LKQN2020-14); Natural Science Foundation of Gansu Province(grant numbers:21JR7RA119); Gansu Provincial Outstanding Graduate Student “Innovation Star” Project(grant numbers:2021CXZX-329); Graduate Research Funding Project of Northwest Normal University(grant numbers:2020KYZZ001031); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9862994","Collaborative apportionment noise (CAN);CAN-based convolutional neural network (CAN-CNN);CAN-based soft sensor framework (CAN-SSF);denoising;soft sensor","Adaptation models;Mathematical models;Soft sensors;Wavelet transforms;Process control;Collaboration;Refining","convolutional neural nets;deep learning (artificial intelligence);feature extraction;production engineering computing","collaborative apportionment noise-based soft sensor framework;industrial production;soft sensor models;collaborative apportionment noise method;convolutional neural networks model;industry data prediction;CAN method;bias degree;reduction degree;traditional wavelet transform;WT denoising;denoising autoencoders;DAE;data credibility degree;feature extraction-based soft sensor techniques","","","","53","IEEE","18 Aug 2022","","","IEEE","IEEE Journals"
"Model-Based Deep Learning for Reconstruction of Joint k-q Under-sampled High Resolution Diffusion MRI","M. P. Mani; H. K. Aggarwal; S. Ghosh; M. Jacob","University of Iowa, Iowa, USA; University of Iowa, Iowa, USA; University of Iowa, Iowa, USA; University of Iowa, Iowa, USA","2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)","22 May 2020","2020","","","913","916","We propose a model-based deep learning architecture for the reconstruction of highly accelerated diffusion magnetic resonance imaging (MRI) that enables high resolution imaging. The proposed reconstruction jointly recovers all the diffusion weighted images in a single step from a joint k-q under-sampled acquisition in a parallel MRI setting. We propose the novel use of a pre-trained denoiser as a regularizer in a model-based reconstruction for the recovery of highly under-sampled data. Specifically, we designed the denoiser based on a general diffusion MRI tissue microstructure model for multi-compartmental modeling. By using a wide range of biologically plausible parameter values for the multi-compartmental microstructure model, we simulated diffusion signal that spans the entire microstructure parameter space. A neural network was trained in an unsupervised manner using an autoencoder to learn the diffusion MRI signal subspace. We employed the autoencoder in a model-based reconstruction and show that the autoencoder provides a strong denoising prior to recover the q-space signal. We show reconstruction results on a simulated brain dataset that shows high acceleration capabilities of the proposed method.","1945-8452","978-1-5386-9330-8","10.1109/ISBI45749.2020.9098593","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9098593","K-q space deep learning;diffusion MRI;autoencoder;model-based deep learning","Image reconstruction;Magnetic resonance imaging;Acceleration;Data models;Brain modeling;Biological system modeling;Image resolution","biodiffusion;biological tissues;biomedical MRI;brain;image denoising;image reconstruction;learning (artificial intelligence);medical image processing;neural nets","multicompartmental microstructure model;diffusion MRI signal subspace;high-resolution diffusion MRI;model-based deep learning architecture;diffusion magnetic resonance imaging;high-resolution imaging;diffusion weighted images;under-sampled acquisition;parallel MRI setting;microstructure parameter space;diffusion MRI tissue microstructure model;multicompartmental modeling;model-based reconstruction","","3","","12","","22 May 2020","","","IEEE","IEEE Conferences"
"Rough Deep Neural Architecture for Short-Term Wind Speed Forecasting","M. Khodayar; O. Kaynak; M. E. Khodayar","Electrical and Computer Engineering Department, Khajeh Nasir Toosi University of Technology, Tehran, Iran; Department of Electrical and Electronic Engineering, Bogazici University, Istanbul, Turkey; Department of Electrical Engineering, Southern Methodist University, Dallas, TX, USA","IEEE Transactions on Industrial Informatics","7 Dec 2017","2017","13","6","2770","2779","Accurate wind speed forecasting is a fundamental requirement for large-scale integration of wind power generation. However, the intermittent and stochastic nature of wind speed makes this task challenging. Artificial neural networks (ANNs) are widely used in this area; however, they may fail to provide the accuracy that may be required. This is due to applying shallow architectures with error-prone hand-engineered features. This paper proposes a deep neural network (DNN) architecture with stacked autoencoder (SAE) and stacked denoising autoencoder (SDAE) for ultrashort-term and short-term wind speed forecasting. Autoencoders (AEs) are applied for unsupervised feature learning from the unlabeled wind data and a supervised regression layer is applied at the top of the AEs for wind speed forecasting. Several uncertain factors exist in the wind data that degrade the accuracy of current methodologies. In order to improve the accuracy, rough neural networks are incorporated in the proposed deep learning models to develop novel rough extensions of SAE and SDAE that are robust to wind uncertainties. Experimental results show that the proposed rough DNN models outperform classic DNNs and previous models that apply shallow architectures in the view of lower RMSE and mean absolute error measurements.","1941-0050","","10.1109/TII.2017.2730846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990193","Deep neural network (DNN);forecasting;rough neural network (RNN);uncertainty;wind","Wind speed;Forecasting;Neural networks;Wind forecasting;Predictive models;Autoregressive processes;Machine learning","encoding;learning (artificial intelligence);mean square error methods;neural nets;power engineering computing;regression analysis;signal denoising;unsupervised learning;wind power plants","wind speed forecasting;rough extensions;stacked denoising autoencoder;unsupervised feature learning;mean absolute error measurements;RMSE;short-term wind speed forecasting;rough neural networks;unlabeled wind data;ultrashort-term;stacked autoencoder;deep neural network architecture;artificial neural networks;stochastic nature;wind power generation;deep neural architecture;shallow architectures;rough DNN models;SDAE;SAE;deep learning models","","163","","36","IEEE","24 Jul 2017","","","IEEE","IEEE Journals"
"Stochastic Gradient Variational Bayes for deep learning-based ASR","A. Tjandra; S. Sakti; S. Nakamura; M. Adriani","Faculty of Computer Science, Universitas Indonesia, Indonesia; Graduate School of Information Science, Nara Institute of Science and Technology, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Japan; Faculty of Computer Science, Universitas Indonesia, Indonesia","2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)","11 Feb 2016","2015","","","175","180","Many successful methods for training deep neural networks (DNN) rely on an unsupervised pretraining algorithm. It is particularly effective when the number of labeled training samples is not large enough, because pretraining method helps to initialize the parameter values in the appropriate range near a local good minimum, for further discriminative finetuning. However, while the improvement is impressive, training DNN is difficult because the objective function of DNN is highly non-convex function of the parameters. To avoid placing the parameter that generalizes poorly, a robust generative modelling is necessary. This paper explore an alternative of generative modelling for pretraining DNN-based acoustic modelling using Stochastic Gradient Variational Bayes (SGVB) within autoencoder framework called Variational Bayes Autoencoder (VBAE). It performs an efficient approximate inference and learning with directed probabilistic graphical models. During fine-tuning, probabilistic encoder parameters with latent variable components are then used in discriminative training for acoustic model. Here, we investigate the performances of DNN-based acoustic model using the proposed pretrained VBAE in comparison with widely used pretraining algorithms like Restricted Boltzmann Machine (RBM) and Stacked Denoising Autoencoder (SDAE). The results reveal that VBAE pretraining with Gaussian latent variables gave the best performance.","","978-1-4799-7291-3","10.1109/ASRU.2015.7404791","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7404791","acoustic model;deep neural network;variational Bayes;autoencoder","Hidden Markov models;Probabilistic logic;Acoustics;Training;Data models;Decoding;Neural networks","directed graphs;gradient methods;inference mechanisms;learning (artificial intelligence);neural nets;speech recognition;stochastic processes","stochastic gradient variational Bayes model;deep learning-based ASR;automatic speech recognition;deep neural networks;DNN training;unsupervised pretraining algorithm;robust generative modelling;SGVB model;autoencoder framework;inference;directed probabilistic graphical model;latent variable components;pretraining algorithm;restricted Boltzmann machine;RBM algorithm;stacked denoising autoencoder algorithm;SDAE algorithm","","4","","23","","11 Feb 2016","","","IEEE","IEEE Conferences"
"Collaborative Deep Learning for speech enhancement: A run-time model selection method using autoencoders","M. Kim","Department of Intelligent Systems Engineering, School of Informatics and Computing","2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","19 Jun 2017","2017","","","76","80","We show that a Modular Neural Network (MNN) can combine various speech enhancement modules, each of which is a Deep Neural Network (DNN) specialized on a particular enhancement job. Differently from an ordinary ensemble technique that averages variations in models, the propose MNN selects the best module for the unseen test signal to produce a greedy ensemble. We see this as Collaborative Deep Learning (CDL), because it can reuse various already-trained DNN models without any further refining. In the proposed MNN selecting the best module during run time is challenging. To this end, we employ a speech AutoEncoder (AE) as an arbitrator, whose input and output are trained to be as similar as possible if its input is clean speech. Therefore, the AE can gauge the quality of the module-specific denoised result by seeing its AE reconstruction error, e.g. low error means that the module output is similar to clean speech. We propose an MNN structure with various modules that are specialized on dealing with a specific noise type, gender, and input Signal-to-Noise Ratio (SNR) value, and empirically prove that it almost always works better than an arbitrarily chosen DNN module and sometimes as good as an oracle result.","2379-190X","978-1-5090-4117-6","10.1109/ICASSP.2017.7952121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7952121","Speech Enhancement;Source Separation;Deep Learning;Modular Neural Networks;Autoencoders","Speech;Multi-layer neural network;Speech enhancement;Machine learning;Signal to noise ratio;Noise reduction","learning (artificial intelligence);neural nets;speech enhancement","AE reconstruction error;speech autoencoder;CDL;MNN;modular neural network;run-time model selection method;speech enhancement;collaborative deep learning","","11","","27","","19 Jun 2017","","","IEEE","IEEE Conferences"
"Designing Multi-Task Convolutional Variational Autoencoder for Radio Tomographic Imaging","H. Wu; X. Ma; S. Liu","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Mechatronic Engineering, China University of Mining and Technology, Xuzhou, China","IEEE Transactions on Circuits and Systems II: Express Briefs","4 Jan 2022","2022","69","1","219","223","Radio tomographic imaging (RTI) emerges to model the environment and detect the passive targets by a wireless network. In this work, the received signal strength (RSS) measurements are collected from an uncalibrated network, and a multi-task convolutional variational autoencoder model is proposed to realize RTI. The presented model is trained end-to-end to denoise the RSS measurements, reconstruct the static tomographic images, estimate the parameters of the wireless network, and classify the measurement noise level, simultaneously. The multi-task variational learning strategy is able to improve the generalization of the model. Numerical experiments demonstrate the efficacy of our RTI method.","1558-3791","","10.1109/TCSII.2021.3081997","China Scholarship Council(grant numbers:201806420061); Priority Academic Program Development of Jiangsu Higher Education Institutions (PAPD); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9435803","Radio tomographic imaging;variational autoencoder;convolutional neural network;multi-task learning","Wireless networks;Image reconstruction;Noise level;Convolution;Calibration;Attenuation;Tomography","computerised tomography;convolutional neural nets;image reconstruction;RSSI","RTI method;multitask variational learning strategy;measurement noise level;static tomographic images;RSS measurements;multitask convolutional variational autoencoder model;received signal strength measurements;wireless network;passive targets;radio tomographic imaging","","2","","14","IEEE","19 May 2021","","","IEEE","IEEE Journals"
"Unsupervised feature selection for tumor profiles using autoencoders and kernel methods","M. Palazzo; P. Beauseroy; P. Yankilevich","Universidad Tecnologica Nacional, Facultad Regional Buenos Aires, Buenos Aires, Argentina; Institut Charles Delaunay, Universite de Technologie de Troyes, Troyes, France; Instituto de Investigación en Biomedicina de Buenos Aires (IBioBA)—CONICET—Partner Institute of the Max Planck Society, Buenos Aires, Argentina","2020 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)","7 Dec 2020","2020","","","1","8","Molecular data from tumor profiles is high dimensional. Tumor profiles can be characterized by tens of thousands of gene expression features. Due to the size of the gene expression feature set machine learning methods are exposed to noisy variables and complexity. Tumor types present heterogeneity and can be subdivided in tumor subtypes. In many cases tumor data does not include tumor subtype labeling thus unsupervised learning methods are necessary for tumor subtype discovery. This work aims to learn meaningful and low dimensional representations of tumor samples and find tumor subtype clusters while keeping biological signatures without using tumor labels. By using Autoencoders a low dimensional and denoised latent space is learned as a target representation to guide a Multiple Kernel Learning model that selects a subset of genes. By using the selected genes a clustering method is used to group samples. In order to evaluate the performance of the proposed unsupervised feature selection method the obtained features and clusters are analyzed by clinical significance. The proposed method has been applied on three tumor datasets which are Brain, Renal and Lung, each one composed by two tumor subtypes. The results obtained by the proposed method reveal lower redundancy in the selected features and each obtained cluster is significantly enriched by just one tumor subtype when compared with benchmark unsupervised feature selection methods. The proposed method named Latent Kernel Feature Selection (LKFS) is an unsupervised approach for gene selection in tumor gene expression profiles.","","978-1-7281-9468-4","10.1109/CIBCB48159.2020.9277699","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9277699","Unsupervised Feature Selection;Gene Expression;Kernel Methods;Autoencoders","Tumors;Feature extraction;Cancer;Gene expression;Kernel;Decoding;Genomics","bioinformatics;cancer;data analysis;feature extraction;feature selection;genetics;learning (artificial intelligence);medical computing;neural nets;pattern clustering;tumours","tumor profiles;kernel methods;tumor subtype clusters;latent space learning;multiple kernel learning model;clustering method;unsupervised feature selection;tumor datasets;gene selection;tumor gene expression profiles;autoencoders;latent kernel feature selection","","","","45","","7 Dec 2020","","","IEEE","IEEE Conferences"
"Learning Speckle Suppression in Sar Images Without Ground Truth: Application to Sentinel-1 Time-Series","A. Boulch; P. Trouvé; E. Koeniguer; F. Janez; B. L. Saux","DTIS, University Paris Saclay, Palaiseau, France; DTIS, University Paris Saclay, Palaiseau, France; DTIS, University Paris Saclay, Palaiseau, France; DTIS, University Paris Saclay, Palaiseau, France; DTIS, ONERA, University Paris Saclay, Palaiseau, F-91123, France","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","2366","2369","This paper proposes a method of denoising SAR images, using a deep learning method, which takes advantage of the abundance of data to learn on large stacks of images of the same scene. The approach is based on the use of convolutional networks, used as auto-encoders. Learning is led on a large pile of images acquired on the same area, and assumes that the images of this stack differ only by the speckle noise. Several pairs of images are chosen randomly in the stack, and the network tries to predict the slave image from the master image. In this prediction, the network can not predict the noise because of its random nature. Also the application of this network to a new image fulfills the speckle filtering function. Results are given on Sentinel 1 images. They show that this approach is qualitatively competitive with literature.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8519370","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8519370","SAR;speckle filtering;deep learning","Synthetic aperture radar;Speckle;Noise reduction;Histograms;Training;Machine learning;Standards","image coding;image denoising;image filtering;learning (artificial intelligence);radar computing;radar imaging;speckle;synthetic aperture radar;time series","Sentinel 1 imaging;slave image prediction;autoencoders;SAR image denoising;speckle filtering function;speckle noise;convolutional networks;deep learning method;Sentinel-1 time-series;learning speckle suppression","","2","","11","","4 Nov 2018","","","IEEE","IEEE Conferences"
"An Automated Defect Detection Approach for Catenary Rod-Insulator Textured Surfaces Using Unsupervised Learning","W. Liu; Z. Liu; H. Wang; Z. Han","School of Electrical Engineering, Southwest Jiaotong University, Chengdu, China; State Key Laboratory of Traction Power, Southwest Jiaotong University, Chengdu, China; School of Electrical Engineering, Southwest Jiaotong University, Chengdu, China; School of Electrical Engineering, Southwest Jiaotong University, Chengdu, China","IEEE Transactions on Instrumentation and Measurement","14 Sep 2020","2020","69","10","8411","8423","This article aims to present a defect detection approach for catenary rod-insulators based on unsupervised learning. The idea of the proposed detection method is that 1) the regions of catenary insulator pieces are separated first; 2) then, the real samples of the segmented catenary insulator pieces are reconstructed as the foreground, and through the difference between the segmented and reconstructed images, the defect regions are separated as the background; and 3) the defect levels are evaluated according to the separated defect regions. The separation effectiveness of the foreground and background in the second stage is the most vital key. Therefore, a reconstruction and classification convolutional autoencoder network (RCCAEN) is built. Compared with standard autoencoders (AEs), the proposed convolutional AE network can improve the system real time and the ambiguity of the edges of the recovered images. Moreover, it can avoid the interference from the incorrectly segmented components by incorporating a small classification network after the latent support vector. Besides, the dropout layer is added behind the input images to enhance the robustness of the proposed network to noise. In this article, first, the regions of catenary insulator pieces are segmented by combining Mask regions with CNN features (R-CNN) and curving fitting method. And then, the defect regions are extracted by the proposed network RCCAEN. Finally, the defect levels are judged by the indexes of the density-based spatial clustering of applications with noise. The experimental results show that the proposed approach can accurately detect the defects of catenary insulator severe pollution.","1557-9662","","10.1109/TIM.2020.2987503","National Natural Science Foundation of China(grant numbers:51977182,U1734202); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9064597","Catenary insulator;convolutional autoencoder (AE) networks;defect detection;foreground and background separation;unsupervised learning","Insulators;Feature extraction;Image reconstruction;Unsupervised learning;Image segmentation;Image edge detection;Gallium nitride","convolutional neural nets;curve fitting;fault diagnosis;feature extraction;image classification;image denoising;image reconstruction;image representation;image segmentation;insulators;least squares approximations;object detection;pattern clustering;railways;support vector machines;surface texture;unsupervised learning","network RCCAEN;defect levels;catenary insulator severe pollution;automated defect detection approach;catenary rod-insulator textured surfaces;unsupervised learning;catenary rod-insulators;segmented catenary insulator pieces;segmented reconstructed images;separated defect regions;separation effectiveness;classification convolutional autoencoder network;classification network;mask regions;standard autoencoders;convolutional AE network;interference avoidance;small classification network;latent support vector;dropout layer;CNN features;curving fitting method;defect region extraction;density-based spatial clustering","","14","","21","IEEE","13 Apr 2020","","","IEEE","IEEE Journals"
"A Deep Learning Approach to Radio Signal Denoising","E. Almazrouei; G. Gianini; N. Almoosa; E. Damiani","Emirates ICT Innovation Center (EBTIC), Khalifa University, Abu Dhabi, UAE; Emirates ICT Innovation Center (EBTIC), Khalifa University, Abu Dhabi, UAE; Emirates ICT Innovation Center (EBTIC), Khalifa University, Abu Dhabi, UAE; Emirates ICT Innovation Center (EBTIC), Khalifa University, Abu Dhabi, UAE","2019 IEEE Wireless Communications and Networking Conference Workshop (WCNCW)","18 Nov 2019","2019","","","1","8","This paper proposes a Deep Learning approach to radio signal de-noising. This approach is data-driven, thus it allows de-noising signals, corresponding to distinct protocols, without requiring explicit use of expert knowledge, in this way granting higher flexibility. The core component of the Artificial Neural Network architecture used in this work is a Convolutional De-noising AutoEncoder. We report about the performance of the system in spectrogram-based denoising of the protocol preamble across protocols of the IEEE 802.11 family, studied using simulation data. This approach can be used within a machine learning pipeline: the denoised data can be fed to a protocol classifier. A further perspective advantage of using the AutoEncoders in such a pipeline is that they can be co-trained with the downstream classifier (protocol detector), to optimize its accuracy.","","978-1-7281-0922-0","10.1109/WCNCW.2019.8902756","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902756","","Noise reduction;Protocols;Convolution;Deep learning;Signal denoising;Standards","","","","4","","39","","18 Nov 2019","","","IEEE","IEEE Conferences"
"Personalized Stride-Length Estimation Based on Active Online Learning","Q. Wang; H. Luo; L. Ye; A. Men; F. Zhao; Y. Huang; C. Ou","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology Chinese Academy of Sciences, Beijing, China; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology Chinese Academy of Sciences, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Software Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronics Engineering and Computer Science, Peking University, Beijing, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore","IEEE Internet of Things Journal","12 Jun 2020","2020","7","6","4885","4897","The ability to accurately estimate a user's stride length plays a great important role in various applications. For a new target pedestrian or device, their heterogeneity dramatically reduces the performance of the current stride-length estimation (SLE) methods. To address the issue of heterogeneity, in this article, we propose an SLE method based on a long short-term memory (LSTM) network and denoising autoencoders (DAEs). The LSTM network is used to mine temporal dependencies and extract significant eigenvectors from the corrupted inertial sensor observations. Then, DAEs are adopted to automatically eliminate the inherent noise in eigenvectors and obtain denoised eigenvectors. Finally, a regression module maps the denoised eigenvectors to the resulting stride length. To mitigate the heterogeneity, we propose an unperceived model updating framework based on active online learning to establish a personalized model for a given target pedestrian or device. The proposed framework utilizes a magnetism-aided map-matching approach to automatically generate personalized training data and utilizes online learning technologies to evolve the stride-length model. The extensive experimental results demonstrate that the proposed method outperforms other state-of-the-art algorithms and achieves a promising accuracy with a stride-length error rate of 4.59% at a confidence level of 80%.","2327-4662","","10.1109/JIOT.2020.2971318","National Basic Research Program of China (973 Program)(grant numbers:2016YFB0502000); Action Plan Project of the Beijing University of Posts and Telecommunications; Fundamental Research Funds for the Central Universities(grant numbers:2019XD-A06); Special Project for Youth Research and Innovation, Beijing University of Posts and Telecommunications;; Fundamental Research Funds for the Central Universities(grant numbers:2019PTB-011); National Natural Science Foundation of China(grant numbers:61872046,61761038,61671264,61671077); Key Research and Development Project from Hebei Province(grant numbers:19210404D); Open Project of the Beijing Key Laboratory of Mobile Computing and Pervasive Device; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8981953","Indoor positioning;Internet of Things (IoT);online learning;pedestrian dead reckoning (PDR);stride-length estimation (SLE);walking-distance estimation","Data models;Estimation;Legged locomotion;Hidden Markov models;Internet of Things;Acceleration;Training data","data mining;eigenvalues and eigenfunctions;feature extraction;image denoising;learning (artificial intelligence);recurrent neural nets;regression analysis","personalized stride-length estimation;active online learning;SLE method;denoising autoencoders;DAE;LSTM network;significant eigenvectors;corrupted inertial sensor observations;denoised eigenvectors;regression module maps;resulting stride length;unperceived model updating framework;personalized model;target pedestrian;magnetism-aided map-matching approach;personalized training data;stride-length model;stride-length error rate;stride-length estimation methods","","11","","39","IEEE","4 Feb 2020","","","IEEE","IEEE Journals"
"A deep learning based noise reduction approach to improve speech intelligibility for cochlear implant recipients in the presence of competing speech noise","S. -S. Wang; Y. Tsao; H. -L. S. Wang; Y. -H. Lai; L. P. -H. Li","Research Center for Information Technology Innovation, Academia Sinica, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taiwan; Department of Special Education, National Taiwan Normal University; Department of Biomedical Engineering, National Yang-Ming University, Taiwan; Department of Otolaryngology, Cheng Hsin General Hospital, Taipei, Taiwan","2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","8 Feb 2018","2017","","","808","812","This paper presents the clinical results of the application of a deep-learning-based noise reduction (NR) approach to improve speech intelligibility for cochlear implant (CI) recipients in the presence of competing speech noise. The deep denoising autoencoder (DDAE) model was used as a representative deep-learning-based NR model to reduce the noise components from the noisy input. The enhanced speech was subsequently played to six Mandarin- speaking CI recipients to perform recognition tests. All the subjects used their own clinical speech processors during testing. Two traditional NR approaches were also implemented to test the performance for a comparison. The Taiwan Mandarin version of the hearing in noise test (TMHINT) sentences were adopted and further corrupted by competing two talker speech noise at signal-to-noise ratio (SNR) levels of 0 and 5 dB. The experimental results showed that the DDAE NR approach can yield higher intelligibility scores than the two classical NR techniques in the presence of competing speech. The results of qualitative analysis further showed that the DDAE NR approach notably reduced the envelope distortions. The good results also suggest that the proposed DDAE NR approach can combine well with the existing CI processors to overcome the issue of degradation of speech perception, which is caused by competing speech noise.","","978-1-5386-1542-3","10.1109/APSIPA.2017.8282144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8282144","","Speech;Speech enhancement;Conferences;Speech recognition;Auditory system","cochlear implants;image denoising;learning (artificial intelligence);medical signal processing;signal denoising;speech intelligibility;speech recognition","speech noise;cochlear implant recipients;speech intelligibility;deep learning based noise reduction approach;speech perception;DDAE NR approach;signal-to-noise ratio levels;talker speech noise;noise test sentences;traditional NR approaches;clinical speech processors;noise components;NR model;deep denoising autoencoder model","","4","","26","","8 Feb 2018","","","IEEE","IEEE Conferences"
"Learning Category-level Implicit 3D Rotation Representations for 6D Pose Estimation from RGB Images","X. Li; Y. Cai; S. Wang; T. Lu","State Key Laboratory of Management and Control for Complex Systems, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Chinese Academy of Sciences, Beijing, China","2019 IEEE International Conference on Robotics and Biomimetics (ROBIO)","20 Jan 2020","2019","","","2310","2315","We exploit the embedding ability of a de-noising autoencoder for an implicit 3D rotation representation learning at the category level. Contrast to the exact 3D reconstruction model of each instance-level physical object, we leverage the inexact CAD/Reconstruction models of an object as the representative model for some category. Under our assumptions that objects within the same category share resemble geometry, we train a de-noising autoencoder on synthetic 3D views of category-level objects to extract the homogenous features at the bottleneck layer. The latent representation is agnostic not only to heterogeneous textures, colors, and illuminations, but also ambiguous pose caused by object symmetry. To extend the instance-level 3D translation estimation to the category level, we considered the 3D diagonal length ratio between the source and target object. We achieved a frame rate of 17Hz.","","978-1-7281-6321-5","10.1109/ROBIO49542.2019.8961408","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8961408","Pose Estimation;Autoencoder;6D Object Detection;Category Level","","computational geometry;feature extraction;image colour analysis;image denoising;image reconstruction;image representation;learning (artificial intelligence);neural nets;pose estimation;stereo image processing","6D pose estimation;synthetic 3D views;object symmetry;instance-level 3D translation estimation;3D diagonal length ratio;category-level implicit 3D rotation representations;3D reconstruction model;3D rotation representation learning;feature extraction;denoising autoencoder training","","","","25","","20 Jan 2020","","","IEEE","IEEE Conferences"
"Domain Adaptation Using Representation Learning for the Classification of Remote Sensing Images","A. Elshamli; G. W. Taylor; A. Berg; S. Areibi","School of Engineering, University of Guelph, Guelph, ON, Canada; School of Engineering, University of Guelph, Guelph, ON, Canada; Department of Geography, University of Guelph, Guelph, ON, Canada; School of Engineering, University of Guelph, Guelph, ON, Canada","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","26 Sep 2017","2017","10","9","4198","4209","Traditional machine learning (ML) techniques are often employed to perform complex pattern recognition tasks for remote sensing images, such as land-use classification. In order to obtain acceptable classification results, these techniques require there to be sufficient training data available for every particular image. Obtaining training samples is challenging, particularly for near real-time applications. Therefore, past knowledge must be utilized to overcome the lack of training data in the current regime. This challenge is known as domain adaptation (DA), and one of the common approaches to this problem is based on finding invariant representations for both the training and test data, which are often assumed to come from different “domains.” In this study, we consider two deep learning techniques for learning domain-invariant representations: Denoising autoencoders (DAE) and domain-adversarial neural networks (DANN). While the DAE is a typical two-stage DA technique (unsupervised invariant representation learning followed by supervised classification), DANN is an end-to-end approach where invariant representation learning and classification are considered jointly during training. The proposed techniques are applied to both hyperspectral and multispectral images under different DA scenarios. Results obtained show that the proposed techniques outperform traditional approaches, such as principal component analysis (PCA) and kernel PCA, and can also compete with a fully supervised model in the multispatial scenario.","2151-1535","","10.1109/JSTARS.2017.2711360","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7954001","Adversarial neural network;autoencoders (AEs);deep learning;domain adaptation (DA);land-use classification;representation learning","Remote sensing;Training;Principal component analysis;Neural networks;Earth;Agriculture;Machine learning","geophysical image processing;hyperspectral imaging;image classification;image denoising;land use;neural nets;principal component analysis;remote sensing;unsupervised learning","domain adaptation;remote sensing image classification;machine learning technique;pattern recognition task;land use classification;deep learning technique;denoising autoencoder;domain-adversarial neural networks;unsupervised invariant representation learning;supervised classification;hyperspectral image;multispectral image;principal component analysis;kernel PCA","","44","","36","IEEE","20 Jun 2017","","","IEEE","IEEE Journals"
"Deep Learning for Radar Signal Detection in Electronic Warfare Systems","M. A. Nuhoglu; Y. K. Alp; F. C. Akyon","Radar, Electronic Warfare and Intelligence Systems Division, ASELSAN A.S., Ankara, Turkey; Radar, Electronic Warfare and Intelligence Systems Division, ASELSAN A.S., Ankara, Turkey; Electrical and Electronics Engineering, Ihsan Dogramaci Bilkent University, Ankara, Turkey","2020 IEEE Radar Conference (RadarConf20)","4 Dec 2020","2020","","","1","6","Detection of radar signals is the initial step for passive systems. Since these systems do not have prior information about received signal, application of matched filter and general likelihood ratio tests are infeasible. In this paper, we propose a new method for detecting received pulses automatically with no restriction of having intentional modulation or pulse on pulse situation. Our method utilizes a cognitive detector incorporating bidirectional long-short term memory based deep denoising autoencoders. Moreover, a novel loss function for detection is developed. Performance of the proposed method is compared to two well known detectors, namely: energy detector and time-frequency domain detector. Qualitative experiments show that the proposed method is able to detect presence of a signal with low probability of false alarm and it outperforms the other methods in all signal-to-noise ratio cases.","2375-5318","978-1-7281-8942-0","10.1109/RadarConf2043947.2020.9266381","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9266381","passive systems;detection;deep learning;long-short term memory;autoencoder","Detectors;Radar;Time-frequency analysis;Radar detection;Frequency modulation;Noise reduction;Modulation","electronic warfare;learning (artificial intelligence);matched filters;military computing;military radar;modulation;passive radar;probability;radar computing;radar detection;radar signal processing;recurrent neural nets;signal denoising;signal detection;time-frequency analysis","radar signal detection;electronic warfare systems;passive systems;received signal;matched filter;general likelihood ratio tests;intentional modulation;cognitive detector;bidirectional long-short term memory;deep denoising autoencoders;energy detector;time-frequency domain detector;signal-to-noise ratio;deep learning;received pulse detection;low probability of false alarm","","","","22","","4 Dec 2020","","","IEEE","IEEE Conferences"
"Deep neural ensemble for retinal vessel segmentation in fundus images towards achieving label-free angiography","A. Lahiri; A. G. Roy; D. Sheet; P. K. Biswas","Dept. of Electronics and Electrical Communication Engineering, Indian Institute of Technology, Kharagpur, India; Indian Institute of Technology Kharagpur, Kharagpur, West Bengal, IN; Dept. of Electrical Engineering, Indian Institute of Technology, Kharagpur, India; Dept. of Electronics and Electrical Communication Engineering, Indian Institute of Technology, Kharagpur, India","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","18 Oct 2016","2016","","","1340","1343","Automated segmentation of retinal blood vessels in label-free fundus images entails a pivotal role in computed aided diagnosis of ophthalmic pathologies, viz., diabetic retinopathy, hypertensive disorders and cardiovascular diseases. The challenge remains active in medical image analysis research due to varied distribution of blood vessels, which manifest variations in their dimensions of physical appearance against a noisy background. In this paper we formulate the segmentation challenge as a classification task. Specifically, we employ unsupervised hierarchical feature learning using ensemble of two level of sparsely trained denoised stacked autoencoder. First level training with bootstrap samples ensures decoupling and second level ensemble formed by different network architectures ensures architectural revision. We show that ensemble training of auto-encoders fosters diversity in learning dictionary of visual kernels for vessel segmentation. SoftMax classifier is used for fine tuning each member autoencoder and multiple strategies are explored for 2-level fusion of ensemble members. On DRIVE dataset, we achieve maximum average accuracy of 95.33% with an impressively low standard deviation of 0.003 and Kappa agreement coefficient of 0.708. Comparison with other major algorithms substantiates the high efficacy of our model.","1558-4615","978-1-4577-0220-4","10.1109/EMBC.2016.7590955","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590955","","Training;Feature extraction;Kernel;Retinal vessels;Image segmentation;Standards;Biomedical imaging","biomedical optical imaging;blood vessels;cardiovascular system;diseases;eye;feature extraction;image classification;image coding;image denoising;image segmentation;medical image processing;unsupervised learning","deep neural ensemble;retinal vessel segmentation;label-free angiography;automated segmentation;retinal blood vessels;label-free fundus images;computed aided diagnosis;ophthalmic pathologies;diabetic retinopathy;hypertensive disorders;cardiovascular diseases;medical image analysis;physical appearance;noisy background;classification task;unsupervised hierarchical feature learning;sparsely trained denoised stacked autoencoder;first level training;bootstrap samples;network architectures;architectural revision;autoencoders fosters diversity;learning dictionary;visual kernels;SoftMax classifier;2-level fusion;DRIVE dataset;maximum average accuracy;standard deviation;Kappa agreement coefficient","Algorithms;Angiography;Diabetic Retinopathy;Diagnosis, Computer-Assisted;Fundus Oculi;Humans;Image Processing, Computer-Assisted;Retinal Diseases;Retinal Vessels","38","1","22","","18 Oct 2016","","","IEEE","IEEE Conferences"
"High-Resolution Image Synthesis with Latent Diffusion Models","R. Rombach; A. Blattmann; D. Lorenz; P. Esser; B. Ommer","Ludwig Maximilian University of Munich & IWR, Heidelberg University, Germany; Ludwig Maximilian University of Munich & IWR, Heidelberg University, Germany; Ludwig Maximilian University of Munich & IWR, Heidelberg University, Germany; Runway ML; Ludwig Maximilian University of Munich & IWR, Heidelberg University, Germany","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","10674","10685","By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve new state of the art scores for image inpainting and class-conditional image synthesis and highly competitive performance on various tasks, including unconditional image generation, text-to-image synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based DMs.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01042","German Research Foundation(grant numbers:421703927.); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9878449","Image and video synthesis and generation","Training;Visualization;Image synthesis;Computational modeling;Noise reduction;Superresolution;Process control","computer vision;convolution;greedy algorithms;image classification;image denoising;image representation;image resolution;image restoration;image texture;learning (artificial intelligence);visual databases","high-resolution image synthesis;latent diffusion models;image formation process;sequential application;denoising autoencoders;state-of-the-art synthesis results;image data;image generation process;pixel space;powerful DMs;sequential evaluations;DM training;latent space;powerful pretrained autoencoders;training diffusion models;model architecture;powerful generators;flexible generators;high-resolution synthesis;image inpainting;class-conditional image synthesis;unconditional image generation;text-to-image synthesis","","","","105","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Towards Transferable Speech Emotion Representation: On Loss Functions for Cross-Lingual Latent Representations","S. Das; N. Nadine Lønfeldt; A. Katrine Pagsberg; L. H. Clemmensen","Department of Applied Mathematics and Computer Science, Technical University of Denmark; Child and Adolescent Mental Health Center, Copenhagen University Hospital, Capital Region; Department of Clinical Medicine, Faculty of Health, Copenhagen University; Department of Applied Mathematics and Computer Science, Technical University of Denmark","ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","27 Apr 2022","2022","","","6452","6456","In recent years, speech emotion recognition (SER) has been used in wide ranging applications, from healthcare to the commercial sector. In addition to signal processing approaches, methods for SER now also use deep learning techniques which provide transfer learning possibilities. However, generalizing over languages, corpora and recording conditions is still an open challenge. In this work we address this gap by exploring loss functions that aid in transferability, specifically to non-tonal languages. We propose a variational autoencoder (VAE) with KL annealing and a semi-supervised VAE to obtain more consistent latent embedding distributions across data sets. To ensure transferability, the distribution of the latent embedding should be similar across non-tonal languages (data sets). We start by presenting a low-complexity SER based on a denoising-autoencoder, which achieves an unweighted classification accuracy of over 52.09% for four-class emotion classification. This performance is comparable to that of similar baseline methods. Following this, we employ a VAE, the semi-supervised VAE and the VAE with KL annealing to obtain a more regularized latent space. We show that while the DAE has the highest classification accuracy among the methods, the semi-supervised VAE has a comparable classification accuracy and a more consistent latent embedding distribution over data sets.1","2379-190X","978-1-6654-0540-9","10.1109/ICASSP43922.2022.9746450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9746450","cross-lingual;latent representation;loss functions;speech emotion recognition (SER);transfer learning","Deep learning;Emotion recognition;Annealing;Transfer learning;Speech recognition;Medical services;Signal processing","acoustic signal processing;deep learning (artificial intelligence);emotion recognition;natural language processing;semi-supervised learning (artificial intelligence);signal classification;signal denoising;signal representation;speech processing;speech recognition","nontonal languages;variational autoencoder;KL annealing;semisupervised VAE;low-complexity SER;denoising-autoencoder;four-class emotion classification;cross-lingual latent representations;speech emotion recognition;deep learning;transfer learning;transferable speech emotion representation;latent embedding distribution;transferable SER;signal processing","","","","32","IEEE","27 Apr 2022","","","IEEE","IEEE Conferences"
"Real-Time Radio Modulation Classification With An LSTM Auto-Encoder","Z. Ke; H. Vikalo","Department of Electrical and Computer Engineering, The University of Texas, Austin; Department of Electrical and Computer Engineering, The University of Texas, Austin","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","4935","4939","Identifying modulation type of a received radio signal is a challenging problem encountered in many applications including radio interference mitigation and spectrum allocation. This problem is rendered challenging by the existence of a large number of modulation schemes and numerous sources of interference. Existing methods for monitoring spectrum readily collect large amounts of radio signals. However, existing state-of-the-art approaches to modulation classification struggle to reach desired levels of accuracy with computational efficiency practically feasible for implementation on low-cost computational platforms. To this end, we propose a learning framework based on an LSTM denoising autoencoder designed to extract robust and stable features from the noisy received signals, and detect the underlying modulation scheme. The method uses a compact architecture that may be implemented on low-cost computational devices while achieving or exceeding state-of-the-art classification accuracy. Experimental results on realistic synthetic and over-the-air radio data show that the proposed framework reliably and efficiently classifies radio signals, and often significantly outperform state-of-the-art approaches.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9414351","Arm; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9414351","modulation classification;denoising auto-encoder;LSTM","Noise reduction;Modulation;Computer architecture;Feature extraction;Real-time systems;Computational efficiency;Resource management","feature extraction;interference suppression;learning (artificial intelligence);modulation;radiofrequency interference;recurrent neural nets;signal classification;signal denoising;telecommunication computing","received radio signal;applications including radio interference mitigation;modulation schemes;radio signals;modulation classification struggle;computational efficiency;low-cost computational platforms;LSTM denoising autoencoder;robust features;stable features;noisy received signals;underlying modulation scheme;low-cost computational devices;state-of-the-art classification accuracy;over-the-air radio data;time radio modulation classification;LSTM auto-encoder;modulation type","","1","","22","IEEE","13 May 2021","","","IEEE","IEEE Conferences"
"Compression by and for Deep Boltzmann Machines","Q. Li; Y. Chen; Y. Kim","Western Digital Research, Milpitas, CA, USA; Michigan Institute for Data Science, University of Michigan, Ann Arbor, MI, USA; Department of Information and Communication Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea","IEEE Transactions on Communications","15 Dec 2020","2020","68","12","7498","7510","We answer two questions in this work: what Deep Boltzmann Machines (DBMs) can do for compression and vise versa. We show that (1) DBMs can be applied to learn the rate distortion approaching posterior as in the Blahut-Arimoto (BA) algorithm, and to construct a lossy source compression scheme based on the Deep AutoEncoder; (2) compression can improve DBMs’ training performances via compression-based denoising algorithms. The implementation of the BA algorithm in the form of DBMs is the foundation of the two applications.","1558-0857","","10.1109/TCOMM.2020.3020796","57th Annual Allerton Conference on Communication, Control and Computing (Allerton’19), Monticello, IL, USA, October 2019; Data Compression Conference (DCC), Snowbird, UT, USA, March 2020; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183947","Rate distortion;lossy source coding;deep Boltzmann machines;deep auto-encoder;Blahut-Arimoto algorithm;denoising","Image coding;Rate-distortion;Noise reduction;Machine learning;Training;Distortion;Source coding","Boltzmann machines;data compression;deep learning (artificial intelligence);image coding;image denoising;rate distortion theory;source coding","Deep Boltzmann Machines;rate distortion;Blahut-Arimoto algorithm;lossy source compression scheme;Deep AutoEncoder;DBMs;compression-based denoising algorithms","","","","56","IEEE","1 Sep 2020","","","IEEE","IEEE Journals"
"Dual-Mode iterative denoiser: Tackling the weak label for anomaly detection","S. Lin; H. Yang","Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai key lab of digital media processing and transmission, Shanghai, China; Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai key lab of digital media processing and transmission, Shanghai, China","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","6742","6749","Crowd anomaly detection suffers from limited training data under weak supervision. In this paper, we propose a dual-mode iterative denoiser to tackle the weak label challenge for anomaly detection. First, we use a convolution autoencoder (CAE) in image space to act as a cluster for grouping similar video clips, where the spatial-temporal similarity helps the cluster metric to represent the reconstruction error. Then we use the graph convolution neural network (GCN) to explore the temporal correlation and the feature similarity between video clips within different rough labels, where the classifier can be constantly updated in the label denoising process. Without specific image-level labels, our model can predict the clip-level anomaly probabilities for videos. Extensive experiment results on two public datasets show that our approach performs favorably against the state-of-the-art methods.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9412673","National Natural Science Foundation of China(grant numbers:61771303); Science and Technology Commission of Shanghai Municipality(grant numbers:19DZ1209303,18DZ1200102,18DZ2270700,20DZ1200203); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9412673","anomaly detection;weak supervision;label denoising;cluster;GCN","Training;Convolution;Noise reduction;Neural networks;Training data;Predictive models;Pattern recognition","convolutional neural nets;feature extraction;image classification;image denoising;image representation;learning (artificial intelligence);pattern clustering;probability;video signal processing","crowd anomaly detection;training data;dual-mode iterative denoiser;weak label challenge;convolution autoencoder;image space;spatial-temporal similarity;graph convolution neural network;temporal correlation;feature similarity;rough labels;label denoising process;specific image-level labels;clip-level anomaly probabilities;similar video clips grouping","","","","31","","5 May 2021","","","IEEE","IEEE Conferences"
"Robust Recognition of Speech with Background Music in Acoustically Under-Resourced Scenarios","J. Malek; J. Zdansky; P. Cerva","Faculty of Mechatronics, Technical University of Liberec, Liberec, Czech Republic; Faculty of Mechatronics, Technical University of Liberec, Liberec, Czech Republic; Faculty of Mechatronics, Technical University of Liberec, Liberec, Czech Republic","2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 Sep 2018","2018","","","5624","5628","This paper addresses the task of Automatic Speech Recognition (ASR) with music in the background. We consider two different situations: 1) scenarios with very small amount of labeled training utterances (duration 1 hour) and 2) scenarios with large amount of labeled training utterances (duration 132 hours). In these situations, we aim to achieve robust recognition. To this end we investigate the following techniques: a) multi-condition training of the acoustic model, b) denoising autoencoders for feature enhancement and c) joint training of both above mentioned techniques. We demonstrate that the considered methods can be successfully trained with the small amount of labeled acoustic data. We present substantially improved performance compared to acoustic models trained on clean speech. Further, we show a significant increase of accuracy in the under-resourced scenario, when utilizing additional amount of non-labeled data. Here, the non-labeled dataset is used to improve the accuracy of the feature enhancement via autoencoders. Subsequently, the autoencoders are jointly fine-tuned along with the acoustic model using the small amount of labeled utterances.","2379-190X","978-1-5386-4658-8","10.1109/ICASSP.2018.8462674","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8462674","robust speech recognition;feature enhancement;denoising autoencoder;multi-condition training;joint training","Training;Acoustics;Hidden Markov models;Robustness;Convolution;Speech recognition;Signal to noise ratio","acoustic signal processing;music;signal denoising;speech enhancement;speech recognition","automatic speech recognition;feature enhancement;acoustically under-resourced scenarios;background music","","","","22","","13 Sep 2018","","","IEEE","IEEE Conferences"
"Deep Neural Networks for Low-resolution Photon-limited Imaging","O. DeGuchy; F. Santiago; M. Banuelos; R. F. Marcia","Department of Applied Mathematics, University of California, Merced, CA, USA; Department of Applied Mathematics, University of California, Merced, CA, USA; Department of Mathematics, California State University, Fresno, Fresno, CA, USA; Department of Applied Mathematics, University of California, Merced, CA, USA","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","3247","3251","In this paper, we implement deep learning methods to recover downsampled noisy signals often present in compressed sensing applications. As an alternative to relying on previously established optimization based algorithms, we implement stacked denoising autoencoders and convolutional neural networks to perform signal reconstructions. Moreover, we propose a Poisson autoencoder inverting network (PAIN) architecture to reconstruct compressed signals imposed with Poisson noise. We observe less computational costs associated with this method while improving on reconstructions from a traditional stacked denoising autoencoder and remaining competitive with a more complex architecture in terms of Mean Squared Error (MSE). We train all proposed architectures on the MNIST dataset and establish deep neural networks as a reconstruction method.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682767","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682767","Deep Learning;Photon-limited imaging;Poisson noise;Autoencoders","Pain;Image reconstruction;Computer architecture;Neural networks;Image coding;Photonics;Noise reduction","compressed sensing;convolutional neural nets;image denoising;image reconstruction;learning (artificial intelligence);mean square error methods;optimisation","deep neural networks;low-resolution photon-limited imaging;deep learning methods;downsampled noisy signals;compressed sensing applications;established optimization based algorithms;convolutional neural networks;signal reconstructions;Poisson autoencoder inverting network architecture;compressed signals;Poisson noise;reconstruction method","","2","","23","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Deformable Patterned Fabric Defect Detection With Fisher Criterion-Based Deep Learning","Y. Li; W. Zhao; J. Pan","North China University of Technology, School of Electronic and Information Engineering, Beijing, China; Shijiazhuang Tiedao University, Institute of Structure Health Monitoring and Control, Shijiazhuang, China; North China University of Technology, School of Electronic and Information Engineering, Beijing, China","IEEE Transactions on Automation Science and Engineering","5 Apr 2017","2017","14","2","1256","1264","In this paper, we propose a discriminative representation for patterned fabric defect detection when only limited negative samples are available. Fabric patches are efficiently classified into defectless and defective categories by Fisher criterion-based stacked denoising autoencoders (FCSDA). First, fabric images are divided into patches of the same size, and both defective and defectless samples are utilized to train FCSDA. Second, test patches are classified through FCSDA into defective and defectless categories. Finally, the residual between the reconstructed image and defective patch is calculated, and the defect is located by thresholding. Experimental results demonstrate the effectiveness of the proposed scheme in the defect detection for periodic patterned fabric and more complex jacquard warp-knitted fabric.","1558-3783","","10.1109/TASE.2016.2520955","Beijing Education Committee Science and Technology Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7398188","Deep learning;denoising autoencoder (DA);fabric defect detection;Fisher criterion;patterned fabric","Fabrics;Neural networks;Training;Machine learning;Inspection;Transforms;Noise reduction","fabrics;flaw detection;image classification;image reconstruction;image segmentation;object detection;production engineering computing;quality control","deformable patterned fabric defect detection;Fisher criterion-based deep learning;fabric patches classification;Fisher criterion-based stacked denoising autoencoders;FCSDA;image reconstruction;thresholding;jacquard warp-knitted fabric;quality control","","158","","28","IEEE","3 Feb 2016","","","IEEE","IEEE Journals"
"A Data-Driven Soft Sensor Modeling Method Based on Deep Learning and its Application","W. Yan; D. Tang; Y. Lin","Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Webank, Shenzhen, China","IEEE Transactions on Industrial Electronics","12 Apr 2017","2017","64","5","4237","4245","Soft sensors have been widely used in industrial processes. The core issue of data-driven soft sensors is building soft sensor models with excellent performance and robustness. This paper introduces deep learning to soft sensor modeling and proposes a novel soft sensor modeling method based on a deep learning network that integrates denoising autoencoders with a neural network (DAE-NN). An improved gradient descent is employed to update the model parameters. The proposed modeling method is able to capture the essential information of input data through deep architecture, building soft sensors with excellent performance. The DAE-NN-based soft sensor is applied in practical applications to estimate the oxygen content in flue gasses in 1000-MW ultrasuperficial units. Comparing conventional soft sensor modeling methods, i.e., shallow learning methods, DAE-NN-based soft sensor significantly improves the performance and generalization of data-driven soft sensors. Deep learning provides a very effective and promising method for soft sensor modeling.","1557-9948","","10.1109/TIE.2016.2622668","National Natural Science Foundation of China(grant numbers:60974119); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7723870","Deep learning;denoising autoencoder (DAE);soft sensor;unlabeled data","Machine learning;Biological system modeling;Computational modeling;Data models;Noise reduction;Training;Robustness","gradient methods;industrial engineering;learning (artificial intelligence);neural nets","data-driven soft sensor modeling;industrial process;robustness;deep learning network;denoising autoencoders;neural network;DAE-NN;gradient descent method","","136","","31","IEEE","27 Oct 2016","","","IEEE","IEEE Journals"
"Deep Learning of Transferable Representation for Scalable Domain Adaptation","M. Long; J. Wang; Y. Cao; J. Sun; P. S. Yu","School of Software, Tsinghua National Laboratory for Information Science and Techonolgy (TNList), Tsinghua University, Beijing, China; School of Software, Tsinghua National Laboratory for Information Science and Techonolgy (TNList), Tsinghua University, Beijing, China; School of Software, Tsinghua National Laboratory for Information Science and Techonolgy (TNList), Tsinghua University, Beijing, China; School of Software, Tsinghua National Laboratory for Information Science and Techonolgy (TNList), Tsinghua University, Beijing, China; Institute for Data Science, Tsinghua University, Haidian, Beijing, China","IEEE Transactions on Knowledge and Data Engineering","6 Jul 2016","2016","28","8","2027","2040","Domain adaptation generalizes a learning model across source domain and target domain that are sampled from different distributions. It is widely applied to cross-domain data mining for reusing labeled information and mitigating labeling consumption. Recent studies reveal that deep neural networks can learn abstract feature representation, which can reduce, but not remove, the cross-domain discrepancy. To enhance the invariance of deep representation and make it more transferable across domains, we propose a unified deep adaptation framework for jointly learning transferable representation and classifier to enable scalable domain adaptation, by taking the advantages of both deep learning and optimal two-sample matching. The framework constitutes two inter-dependent paradigms, unsupervised pre-training for effective training of deep models using deep denoising autoencoders, and supervised fine-tuning for effective exploitation of discriminative information using deep neural networks, both learned by embedding the deep representations to reproducing kernel Hilbert spaces (RKHSs) and optimally matching different domain distributions. To enable scalable learning, we develop a linear-time algorithm using unbiased estimate that scales linearly to large samples. Extensive empirical results show that the proposed framework significantly outperforms state of the art methods on diverse adaptation tasks: sentiment polarity prediction, email spam filtering, newsgroup content categorization, and visual object recognition.","1558-2191","","10.1109/TKDE.2016.2554549","National Natural Science Foundation of China(grant numbers:61325008,61502265); China Postdoctoral Science Foundation(grant numbers:2015T80088); National Science and Technology Supporting Program(grant numbers:2015BAH14F02); NSF(grant numbers:III-1526499); Tsinghua National Laboratory (TNList) Special Fund for Big Data Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7452659","Domain adaptation;deep learning;denoising autoencoder;neural network;two-sample test;multiple kernel learning","Kernel;Machine learning;Adaptation models;Neural networks;Noise reduction;Labeling;Object recognition","data mining;learning (artificial intelligence);neural nets","deep learning;transferable representation learning;scalable domain adaptation;cross-domain data mining;labeled information reuse;labeling consumption mitigation;deep neural networks;abstract feature representation learning;cross-domain discrepancy;optimal two-sample matching;deep denoising autoencoders;reproducing kernel Hilbert spaces;RKHS;scalable learning;linear-time algorithm;sentiment polarity prediction task;email spam filtering task;newsgroup content categorization task;visual object recognition task","","108","","49","IEEE","14 Apr 2016","","","IEEE","IEEE Journals"
"A Deep Learning Model for Robust Wafer Fault Monitoring With Sensor Measurement Noise","H. Lee; Y. Kim; C. O. Kim","Department of Information and Industrial Engineering, Yonsei University, Seoul, South Korea; Department of Information and Industrial Engineering, Yonsei University, Seoul, South Korea; Department of Information and Industrial Engineering, Yonsei University, Seoul, South Korea","IEEE Transactions on Semiconductor Manufacturing","1 Feb 2017","2017","30","1","23","31","Standard fault detection and classification (FDC) models detect wafer faults by extracting features useful for fault detection from time-indexed measurements of the equipment recorded by in situ sensors (sensor signals) and feeding the extracted information into a classifier. However, the preprocessing-and-classification approach often results in the loss of information in the sensor signals that is important for detecting wafer faults. Furthermore, the sensor signals usually contain noise induced by mechanical and electrical disturbances. In this paper, we propose the use of a stacked denoising autoencoder (SdA), which is a deep learning algorithm, to establish an FDC model for simultaneous feature extraction and classification. The SdA model can identify global and invariant features in the sensor signals for fault monitoring and is robust against measurement noise. Through experiments using wafer samples collected from a work-site photolithography tool, we confirmed that as the sensor measurement noise severity increased, the SdA's classification accuracy could be as much as 14% higher than those of the twelve models considered for comparison, each of which employed one of three feature extractors and one of four classifiers.","1558-2345","","10.1109/TSM.2016.2628865","Technology Innovation Program (Development of Big-Data-Based Analysis and Control Platforms for Semiconductor Manufacturing Plants) by the Ministry of Trade, Industry, and Energy, MOTIE, South Korea(grant numbers:10045913); National Research Foundation of Korea through the Korean Government (MSIP)(grant numbers:NRF-2016R1A2B4008337); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7744687","Semiconductor manufacturing;fault detection and classification;sensor measurement noise;deep learning;stacked denoising autoencoder","Feature extraction;Semiconductor device modeling;Machine learning;Biological neural networks;Semiconductor device measurement;Noise reduction","fault diagnosis;feature extraction;semiconductor device manufacture;semiconductor device measurement;semiconductor device noise;sensors","deep learning model;robust wafer fault monitoring;sensor measurement noise;standard fault detection and classification models;time-indexed measurements;stacked denoising autoencoder;feature extraction;feature classification","","64","","30","IEEE","15 Nov 2016","","","IEEE","IEEE Journals"
"A New Online Detection Approach for Rolling Bearing Incipient Fault via Self-Adaptive Deep Feature Matching","W. Mao; J. Chen; X. Liang; X. Zhang","School of Computer and Information Engineering, Henan Normal University, Xinxiang, China; School of Computer and Information Engineering, Henan Normal University, Xinxiang, China; Department of Mechanical Engineering, University of Manitoba, Winnipeg, Canada; School of Computer and Information Engineering, Henan Normal University, Xinxiang, China","IEEE Transactions on Instrumentation and Measurement","6 Jan 2020","2020","69","2","443","456","This paper presents a new online detection approach for rolling bearing's incipient fault based on self-adaptive deep feature matching (SDFM). This approach includes offline and online stages. At the offline stage, a new health state assessment algorithm is first proposed based on singular value decomposition (SVD) and Kurtosis criterion. Based on the assessment results, a kind of deep learning algorithm, i.e., stacked denoising autoencoder (SDAE), is introduced to extract the common deep features of normal state and early fault state. Support vector data description (SVDD) is applied to establish the offline detection model using the obtained features. At the online stage, a self-adaptive matching strategy with 1-Dimensional anchor is proposed. By utilizing the SDAE model established at offline stage, this strategy can extract more representative deep features of the target bearing via generating various proposal fragments and then determining the fault occurrence time in a self-adaptive way by feeding the online features into the SVDD model. Experiments run on the bearing data set of IEEE prognostic and health management (PHM) Challenge 2012. The results show the proposed approach has good detection performance in real time and much lower false alarm rate, with no need to acquire fault characteristic frequency in advance.","1557-9662","","10.1109/TIM.2019.2903699","National Natural Science Foundation of China(grant numbers:U1704158,11702087); China Postdoctoral Science Foundation(grant numbers:2016T90944); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8676259","Deep learning;health state assessment;incipient fault detection;online detection;stacked denoising autoencoder (SDAE);support vector data description (SVDD)","Feature extraction;Fault detection;Deep learning;Fault diagnosis;Support vector machines;Employee welfare;Adaptation models","condition monitoring;fault diagnosis;feature extraction;learning (artificial intelligence);rolling bearings;singular value decomposition;support vector machines;vibrational signal processing","self-adaptive matching strategy;offline stage;representative deep features;fault occurrence time;online features;fault characteristic frequency;rolling bearing incipient fault;self-adaptive deep feature matching;health state assessment algorithm;deep learning algorithm;normal state;early fault state;support vector data description;offline detection model;online detection approach;stacked denoising autoencoder;SVDD model","","37","","38","IEEE","29 Mar 2019","","","IEEE","IEEE Journals"
"Leveraging blockchain for retraining deep learning architecture in patient-specific arrhythmia classification","A. Juneja; M. Marefat","Department of Electrical and Computer Engineering, University of Arizona, Tucson, AZ, USA; Department of Electrical and Computer Engineering, University of Arizona, Tucson, AZ, USA","2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI)","9 Apr 2018","2018","","","393","397","Stacked Denoising Autoencoders (SDA) are deep networks which have gained popularity owing to their superior performance in image classification applications, but they haven't been used much in healthcare applications. SDA can be efficiently retrained to adapt to large streams of data, and this property is used in this work to develop a technique for classification of arrhythmias in a patient-specific manner. This approach is particularly useful in continuous remote systems because they gather large amounts of data for longer periods of time. Blockchain is a decentralized distributed ledger which secures transactions with cryptography. It is proposed as an access control manager to securely store and access data required by the classifier during retraining in real-time from an external data storage. This work uses MIT-BIH Arrhythmia database and the results show an increased accuracy for Ventricular Ectopic Beats (VEB) (99.15%) and Supraventricular Ectopic Beats (SVEB) (98.55%), which is higher than the published results of deep networks that are not retrained.","","978-1-5386-2405-0","10.1109/BHI.2018.8333451","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8333451","Stacked Denoising Autoencoders;Retraining;Arrhythmia Classification;Remote Continuous Health Systems;Patient Specific;Blockchain","Detectors;Testing;Feature extraction;Peer-to-peer computing;Training;Heart rate variability","authorisation;cryptography;electrocardiography;learning (artificial intelligence);medical computing;medical signal detection;medical signal processing;patient monitoring;signal classification","decentralized distributed ledger;access control manager;external data storage;MIT-BIH Arrhythmia database;deep networks;blockchain;deep learning architecture;patient-specific arrhythmia classification;Stacked Denoising Autoencoders;SDA;image classification applications;healthcare applications;continuous remote systems;Ventricular Ectopic Beats;VEB","","33","","19","","9 Apr 2018","","","IEEE","IEEE Conferences"
"A network traffic flow prediction with deep learning approach for large-scale metropolitan area network","W. Wang; Y. Bai; C. Yu; Y. Gu; P. Feng; X. Wang; R. Wang","School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China","NOMS 2018 - 2018 IEEE/IFIP Network Operations and Management Symposium","9 Jul 2018","2018","","","1","9","Accurate and timely internet traffic information is important for many applications, such as bandwidth allocation, anomaly detection, congestion control and admission control. Over the last few years, internet flow data have been exploding, and we have truly entered the era of big data. Existing traffic flow prediction methods mainly use simple traffic prediction models and are still unsatisfying for many real-world applications. This situation inspires us to rethink the internet traffic flow prediction problem based on deep architecture models with big traffic data. In this paper, we propose a novel deep-learning-based internet traffic flow prediction method, which is called SDAPM. It consider the spatial and temporal correlations inherently and internet flow data character. A stacked denoising autoencoder prediction model (SDA) is used to learn generic internet traffic flow features, and it is trained in a greedy layer-wise fashion. Moreover, experiments demonstrate that the SDAPM for traffic flow prediction has effective performance. Our prediction model is in production as part of the traffic scheduling system at China Unicom, one of the largest Internet companies in China, helping improving the network bandwidth utilization.","2374-9709","978-1-5386-3416-5","10.1109/NOMS.2018.8406252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8406252","Deep learning;Stacked denoising autoencoder (SDA);Network traffic prediction;Big data","Predictive models;Machine learning;Biological system modeling;Data models;Internet;Noise reduction;Artificial neural networks","bandwidth allocation;Big Data;Internet;learning (artificial intelligence);metropolitan area networks;telecommunication congestion control;telecommunication traffic;traffic engineering computing","network bandwidth utilization;network traffic flow prediction;large-scale metropolitan area network;congestion control;admission control;big data;traffic flow prediction methods;simple traffic prediction models;internet traffic flow prediction problem;deep architecture models;big traffic data;deep-learning-based internet traffic flow prediction method;internet flow data character;stacked denoising autoencoder prediction model;generic internet traffic flow features;traffic scheduling system;Internet companies;deep learning;Internet traffic information","","20","","42","","9 Jul 2018","","","IEEE","IEEE Conferences"
"Solving Large-Scale Multiobjective Optimization Problems With Sparse Optimal Solutions via Unsupervised Neural Networks","Y. Tian; C. Lu; X. Zhang; K. C. Tan; Y. Jin","Department of Computer Science, City University of Hong Kong, Hong Kong; Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, Institutes of Physical Science and Information Technology, Anhui University, Hefei, China; Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, Institutes of Physical Science and Information Technology, Anhui University, Hefei, China; Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Computer Science, University of Surrey, Guildford, U.K.","IEEE Transactions on Cybernetics","18 May 2021","2021","51","6","3115","3128","Due to the curse of dimensionality of search space, it is extremely difficult for evolutionary algorithms to approximate the optimal solutions of large-scale multiobjective optimization problems (LMOPs) by using a limited budget of evaluations. If the Pareto-optimal subspace is approximated during the evolutionary process, the search space can be reduced and the difficulty encountered by evolutionary algorithms can be highly alleviated. Following the above idea, this article proposes an evolutionary algorithm to solve sparse LMOPs by learning the Pareto-optimal subspace. The proposed algorithm uses two unsupervised neural networks, a restricted Boltzmann machine, and a denoising autoencoder to learn a sparse distribution and a compact representation of the decision variables, where the combination of the learnt sparse distribution and compact representation is regarded as an approximation of the Pareto-optimal subspace. The genetic operators are conducted in the learnt subspace, and the resultant offspring solutions then can be mapped back to the original search space by the two neural networks. According to the experimental results on eight benchmark problems and eight real-world problems, the proposed algorithm can effectively solve sparse LMOPs with 10000 decision variables by only 100000 evaluations.","2168-2275","","10.1109/TCYB.2020.2979930","Key Project of Science and Technology Innovation 2030 supported by the Ministry of Science and Technology of China(grant numbers:2018AAA0100105); National Natural Science Foundation of China(grant numbers:61672033,61822301,61876123,61906001,U1804262); Hong Kong Scholars Program(grant numbers:XJ2019035); Anhui Provincial Natural Science Foundation(grant numbers:1808085J06,1908085QF271); State Key Laboratory of Synthetical Automation for Process Industries(grant numbers:PAL-N201805); Research Grants Council of the Hong Kong Special Administrative Region, China(grant numbers:CityU11202418,CityU11209219); Royal Society International Exchanges Program(grant numbers:IEC\NSFC\170279); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9047876","Denoising autoencoder (DAE);large-scale multiobjective optimization;Pareto-optimal subspace;restricted Boltzmann machine (RBM);sparse Pareto-optimal solutions","Optimization;Neural networks;Evolutionary computation;Search problems;Computer science;Sociology;Statistics","approximation theory;evolutionary computation;neural nets;Pareto optimisation;search problems;unsupervised learning","large scale multiobjective optimization problems;sparse optimal solutions;unsupervised neural networks;evolutionary algorithm;approximate the optimal solutions;evolutionary process;compact representation;learnt sparse distribution;resultant offspring solutions;original search space;sparse LMOP;Pareto optimal subspace;Boltzmann machine;denoising autoencoder;decision variables;search space","","20","","62","IEEE","26 Mar 2020","","","IEEE","IEEE Journals"
"Unsupervised Feature Learning to Improve Transferability of Landslide Susceptibility Representations","Q. Zhu; L. Chen; H. Hu; S. Pirasteh; H. Li; X. Xie","Beijing Advanced Innovation Center for Imaging Technology, Capital Normal University, Beijing, China; Faculty of Geosciences and Environmental Engineering, Southwest Jiaotong University, Chengdu, China; Faculty of Geosciences and Environmental Engineering, Southwest Jiaotong University, Chengdu, China; Faculty of Geosciences and Environmental Engineering, Southwest Jiaotong University, Chengdu, China; School of Geosciences and Info-Physics, Central South University, Changsha, China; Zhejiang Hi-target Space Information Technology Company Ltd., Huzhou, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","17 Jul 2020","2020","13","","3917","3930","A landslide susceptibility map (LSM) is of vital importance for risk recognition and prevention. In the last decade, statistical methods have gradually exerted their impact on mapping the landslide susceptibility to locate the high-risk places of landslide. However, due to the complexity of getting full access to the thematic information in large scenarios, most of these statistical methods generally suffer from overfitting, inadequate representative power, and the inability to transfer the learned representation to other places. To solve these challenges, this study designed an unsupervised representation learning module, which features independence, compactness, robustness, and transferability. Specifically, we first stack restricted Boltzmann machines and denoising autoencoder to unsupervised discover the underlying representations embedded in the thematic maps. Then, we applied the transferring strategy in an adversarial manner to generalize the learned representations to the sample-scarce area. Experimental results and analyses using data in different regions have revealed that the proposed method can be generalized well between different LSM scenarios. In terms of precision, it outperforms other methods by a large margin, e.g., by around 7% compared to multilayer perceptrons with the same configuration, and by 3%–4% to the state of art algorithm random forest. Besides, compared to other methods, the landslide susceptibility map that is predicted by the proposed method featuring smoothness and stableness seems more reliable, and is more according to some prior knowledge that, for example, distance to the drainage, slope, and stratum, should exert dominant effects on the occurrence of a landslide.","2151-1535","","10.1109/JSTARS.2020.3006192","National Natural Science Foundation of China(grant numbers:41941019); National Key Research and Development Program of China(grant numbers:2018YFB0505404); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9130821","Denoised autoencoder (DAE);landslide susceptibility;restricted Boltzmann machines (RBMs);transferring learning;unsupervised representation learning","Terrain factors;Remote sensing;Training;Data models;Task analysis;Adaptation models;Indexes","Boltzmann machines;geomorphology;geophysics computing;learning (artificial intelligence);mechanical engineering computing;multilayer perceptrons;statistical analysis;unsupervised learning","unsupervised feature learning;landslide susceptibility map;risk recognition;statistical methods;high-risk places;thematic information;inadequate representative power;learned representation;unsupervised representation learning module;denoising autoencoder;thematic maps;transferring strategy;stableness;landslide susceptibility representation transferability;risk prevention;LSM scenarios;drainage;slope;stratum","","17","","53","CCBY","1 Jul 2020","","","IEEE","IEEE Journals"
"Gas turbine engine gas path anomaly detection using deep learning with Gaussian distribution","H. Luo; S. Zhong","School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China; School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China","2017 Prognostics and System Health Management Conference (PHM-Harbin)","23 Oct 2017","2017","","","1","6","Gas turbine engine anomaly detection is a critical means to ensure the safety and economic efficiency of a flight. As gas path faults make up a sizeable proportion of all the engine faults, an engine gas path anomaly detection method was proposed in the present article. Inspired by recent progress in deep learning, we explored a method that combined deep learning with traditional anomaly detection to improve the accuracy of engine gas path anomaly detection. Firstly a stacked denoising autoencoders model was built to learn robust features from datasets without labels. Then, we used learned features as the input to an anomaly detection algorithm based on Gaussian distribution to identify anomalies. To assure the engineering practicability of the proposed method, an experiment was performed to analyze real quick access recorder data of a certain type of turbofan gas turbine engine. Results demonstrated that this method could improve anomaly detection accuracy compared with traditional methods. The method could have the potential to be effectively applied in the engineering practice of engine health management.","2166-5656","978-1-5386-0370-3","10.1109/PHM.2017.8079166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8079166","stacked denoising autoencoders;deep learning;anomaly detection;gas turbine engine;QAR;engine health management","Engines;Anomaly detection;Feature extraction;Machine learning;Gaussian distribution;Noise reduction;Aircraft propulsion","aerospace safety;condition monitoring;fault diagnosis;feature extraction;gas turbines;Gaussian distribution;jet engines;learning (artificial intelligence);mechanical engineering computing","deep learning;Gaussian distribution;gas path faults;engine faults;engineering practicability;turbofan gas turbine engine;anomaly detection accuracy;engineering practice;engine health management;gas turbine engine gas path anomaly detection;flight economic efficiency;flight safety;stacked denoising autoencoders model","","13","","11","","23 Oct 2017","","","IEEE","IEEE Conferences"
"Deep learning based total transfer capability calculation model","J. Yan; C. Li; Y. Liu","Graduate School of Maritime Sciences, Kobe University, Kobe, Japan; School of Marine Science and Technology, Tokai University, Shizuoka, Japan; Graduate School of Maritime Sciences, Kobe University, Kobe, Japan","2018 International Conference on Power System Technology (POWERCON)","6 Jan 2019","2018","","","952","957","A total transfer capability (TTC) calculation model based on stacked denoising autoencoder (SDAE) is proposed in this paper, considering static security, static voltage stability and transient stability constraints. The TTC calculation model consists of feature pre-screening, SDAE and the regression layer. Fast correlation-based filter (FCBF) is used to eliminate irrelevant and redundant features to improve the training efficiency of SDAE. SDAE takes advantage of the deep structure to extract high-order features relevant to TTC from original features. The regression layer is utilized to create the mapping between high-order features and the TTC value. Experiment results of a real power system demonstrate that the proposed TTC calculation model has higher computational accuracy than shallow machine learning models and feature pre-screening decreases the training time of the TTC calculation model obviously.","","978-1-5386-6461-2","10.1109/POWERCON.2018.8601615","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8601615","total transfer capability;deep learning;stacked denoising autoencoder;fast correlation-based filter","Computational modeling;Feature extraction;Power system stability;Stability analysis;Training;Deep learning","learning (artificial intelligence);power engineering computing;power system security;power system transient stability;power transmission reliability","deep learning;total transfer capability calculation model;stacked denoising autoencoder;SDAE;static voltage stability;transient stability constraints;TTC calculation model;feature pre-screening;regression layer;fast correlation-based filter;irrelevant features;redundant features;high-order features;original features;TTC value;shallow machine learning models","","9","","14","","6 Jan 2019","","","IEEE","IEEE Conferences"
"S-vector: A discriminative representation derived from i-vector for speaker verification","Y. Z. Işik; H. Erdogan; R. Sarikaya","UBITAK BILGEM, Gebze, Turkey; Faculty of Engineering and Natural Sciences, Sabanci University, Turkey; Microsoft Corporation, Redmond, WA, USA","2015 23rd European Signal Processing Conference (EUSIPCO)","28 Dec 2015","2015","","","2097","2101","Representing data in ways to disentangle and factor out hidden dependencies is a critical step in speaker recognition systems. In this work, we employ deep neural networks (DNN) as a feature extractor to disentangle and emphasize the speaker factors from other sources of variability in the commonly used i-vector features. Denoising autoencoder based unsupervised pre-training, random dropout fine-tuning, and Nesterov accelerated gradient based momentum is used in DNN training. Replacing the i-vectors with the resulting speaker vectors (s-vectors), we obtain superior results on NIST SRE corpora on a wide range of operating points using probabilistic linear discriminant analysis (PLDA) back-end.","2076-1465","978-0-9928-6263-3","10.1109/EUSIPCO.2015.7362754","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7362754","speaker verification;denoising autoencoder;random dropout","Training;Neural networks;Noise reduction;NIST;Feature extraction;Robustness;Noise measurement","feature extraction;neural nets;speaker recognition","S-vector;I-vector;speaker verification;speaker recognition systems;deep neural networks;feature extractor;denoising autoencoder based unsupervised pre-training;random dropout fine-tuning;Nesterov accelerated gradient based momentum;NIST SRE corpora;probabilistic linear discriminant analysis","","6","","18","","28 Dec 2015","","","IEEE","IEEE Conferences"
"Hyperspectral classification via learnt features","Y. Liu; G. Cao; Q. Sun; M. Siegel","Key Laboratory of Image and Video Understanding for Social Safety, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, US","2015 IEEE International Conference on Image Processing (ICIP)","10 Dec 2015","2015","","","2591","2595","This paper presents a new hyperspectral image (HSI) classification method which is capable of automatic feature learning while achieving high classification accuracy. The method contains two major modules: the spectral classification module and the spatial constraint module. Spectral classification module uses a deep network named stacked denoising autoencoders (SdA) to learn feature representation of the data. Through SdA, the data are projected nonlinearly from its original hyperspectral space to some higher dimensional space where more compact distribution is obtained. An interesting aspect of this method is that it does not need a feature design/extraction process guided by human prior. The suitable feature for the classification is learned by the deep network itself. Superpixel is utilized to generate the spatial constraints to refine the spectral classification results. By exploiting the spatial consistency of neighborhood pixels, the accuracy of classification is further improved by a big margin. Experiments on the public datasets reveal the superior performance of the proposed method.","","978-1-4799-8339-1","10.1109/ICIP.2015.7351271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7351271","Deep learning;stacked denoising autoencoders (SdA);hyperspectral image classification;superpixel;remote sensing","Hyperspectral imaging;Noise reduction;Image segmentation;Training;Spatial resolution;Machine learning","feature extraction;hyperspectral imaging;image classification;learning (artificial intelligence)","hyperspectral image classification method;HSI classification method;automatic feature learning;spectral classification module;spatial constraint module;stacked denoising autoencoder;SdA;hyperspectral space;higher dimensional space;deep network;superpixel;neighborhood pixel spatial consistency","","6","","21","","10 Dec 2015","","","IEEE","IEEE Conferences"
"Detection of mood disorder using speech emotion profiles and LSTM","T. -H. Yang; C. -H. Wu; K. -Y. Huang; M. -H. Su","Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan","2016 10th International Symposium on Chinese Spoken Language Processing (ISCSLP)","4 May 2017","2016","","","1","5","In mood disorder diagnosis, bipolar disorder (BD) patients are often misdiagnosed as unipolar depression (UD) on initial presentation. It is crucial to establish an accurate distinction between BD and UD to make a correct and early diagnosis, leading to improvements in treatment and course of illness. To deal with this misdiagnosis problem, in this study, we experimented on eliciting subjects' emotions by watching six eliciting emotional video clips. After watching each video clips, their speech responses were collected when they were interviewing with a clinician. In mood disorder detection, speech emotions play an import role to detect manic or depressive symptoms. Therefore, speech emotion profiles (EP) are obtained by using the support vector machine (SVM) which are built via speech features adapted from selected databases using a denoising autoencoder-based method. Finally, a Long Short-Term Memory (LSTM) recurrent neural network is employed to characterize the temporal information of the EPs with respect to six emotional videos. Comparative experiments clearly show the promising advantage and efficacy of the LSTM-based approach for mood disorder detection.","","978-1-5090-4294-4","10.1109/ISCSLP.2016.7918439","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7918439","denoising autoencoder;long short-term memory recurrent neural network;mood disorder detection","Speech;Mood;Databases;Noise reduction;Feature extraction;Logic gates;Training","emotion recognition;medical diagnostic computing;medical disorders;medical signal processing;recurrent neural nets;speech recognition;support vector machines","mood disorder detection;LSTM recurrent neural network;long short-term memory;denoising autoencoder-based method;speech features;support vector machine;speech emotion profiles;UD;BD;unipolar depression;bipolar disorder;mood disorder diagnosis","","6","","35","","4 May 2017","","","IEEE","IEEE Conferences"
"Accurately Clustering Single-cell RNA-seq data by Capturing Structural Relations between Cells through Graph Convolutional Network","Y. Zeng; X. Zhou; J. Rao; Y. Lu; Y. Yang","School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Key Laboratory of Machine Intelligence and Advanced Computing, Sun Yat-sen University Ministry of Education, China","2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","13 Jan 2021","2020","","","519","522","Recent advances in single-cell RNA sequencing (scRNA-seq) technologies provide a great opportunity to study gene expression at cellular resolution, and the scRNA-seq data has been routinely conducted to unfold cell heterogeneity and diversity. A critical step for the scRNA-seq analyses is to cluster the same type of cells, and many methods have been developed for cell clustering. However, existing clustering methods are limited to extract the representations from expression data of individual cells, while ignoring the high-order structural relations between cells. Here, we proposed a new method (GraphSCC) to cluster cells based on scRNA-seq data by accounting structural relations between cells through a graph convolutional network. The representation learned from the graph convolutional network, together with another representation output from a denoising autoencoder network, are optimized by a dual self-supervised module for better cell clustering. Extensive experiments indicate that GraphSCC model outperforms state-of-the-art methods in various evaluation metrics on both simulated and real datasets.","","978-1-7281-6215-7","10.1109/BIBM49941.2020.9313569","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9313569","Graph Convolutional Network;Single-cell RNA-seq Clustering;Denoising Autoencoder;Self-supervised Learning","Noise reduction;Clustering methods;Gene expression;Data models;Cells (biology);RNA;Neural networks","bioinformatics;cellular biophysics;genetics;genomics;learning (artificial intelligence);macromolecules;molecular biophysics;pattern clustering;RNA","high-order structural relations;structural relations;graph convolutional network;denoising autoencoder network;cell clustering;single-cell RNA-seq data;capturing structural relations;single-cell RNA sequencing;gene expression;cell heterogeneity;scRNA-seq analyses;expression data;GraphSCC","","5","","23","","13 Jan 2021","","","IEEE","IEEE Conferences"
"RUL prediction for IMA based on deep regression method","Z. Gao; C. Ma; Y. Luo","School of aeronautics, Northwestern Polytechnical University, Xi'an, China; School of aeronautics, Northwestern Polytechnical University, Xi'an, China; School of aeronautics, Northwestern Polytechnical University, Xi'an, China","2017 IEEE 10th International Workshop on Computational Intelligence and Applications (IWCIA)","14 Dec 2017","2017","","","25","31","Integrated modular avionics (IMA) is one of the most significant systems which can affect the performance of civil aircraft. The structure of IMA is an open standard platform, on which amount of functionalities are hosted. This structure makes avionics more flexible and more powerful, while it makes avionics more complexity and more critical. For improving the safety and reliability of aircraft, a deep regression method is utilized for predicting the remaining useful life (RUL) of IMA. The deep regression method adopts stacked denoising autoencoders (SDAE) to extract deep features and further improve the quality of the learned features. Then the deep features are fed into support vector machine (SVM) to predict the RUL. An IMA degradation model which accompanied with intermittent faults (IFs) is built based on probability distribution approaches. The simulation is realized by Monte Carlo method. The deep regression method is applied to the RUL prediction of IMA. The results confirm that the deep regression method is more effective and robust compared with the existing methods.","","978-1-5386-0469-4","10.1109/IWCIA.2017.8203556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8203556","Integrated modular avionics;stacked denoising autoencoders;intermittent faults;fault prognostic","Feature extraction;Aerospace electronics;Degradation;Support vector machines;Fault diagnosis;Aircraft","aerospace computing;aerospace safety;aircraft;avionics;feature extraction;learning (artificial intelligence);mechanical engineering computing;neural nets;regression analysis;remaining life assessment;statistical distributions;support vector machines","RUL prediction;deep regression method;integrated modular avionics;IMA degradation model;deep feature extraction;civil aircraft;remaining useful life;stacked denoising autoencoders;support vector machine;SVM;intermittent faults;probability distribution approaches","","5","","20","","14 Dec 2017","","","IEEE","IEEE Conferences"
"DLIN: Deep Ladder Imputation Network","E. Hallaji; R. Razavi-Far; M. Saif","Department of Electrical and Computer Engineering, University of Windsor, Windsor, Canada; School of Computer Science, University of Windsor, Windsor, Canada; Department of Electrical and Computer Engineering, University of Windsor, Windsor, Canada","IEEE Transactions on Cybernetics","18 Aug 2022","2022","52","9","8629","8641","Many efforts have been dedicated to addressing data loss in various domains. While task-specific solutions may eliminate the respective issue in certain applications, finding a generic method for missing data estimation is rather complex. In this regard, this article proposes a novel missing data imputation algorithm, which has supreme generalization ability for a vast variety of applications. Making use of both complete and incomplete parts of data, the proposed algorithm reduces the effect of missing ratio, which makes it suitable for situations with very high missing ratios. In addition, this feature enables model construction on incomplete training sets, which is rarely addressed in the literature. Moreover, the nonparametric nature of this new algorithm brings about supreme flexibility against all variations of missing values and data distribution. We incorporate the advantages of denoising autoencoders and ladder architecture into a novel formulation based on deep neural networks. To evaluate the proposed algorithm, a comparative study is performed using a number of reputable imputation techniques. In this process, real-world benchmark datasets from different domains are selected. On top of that, a real cyber-physical system is also evaluated to study the generalization ability of the proposed algorithm for distinct applications. To do so, we conduct studies based on three missing data mechanisms, namely: 1) missing completely at random; 2) missing at random; and 3) missing not at random. The attained results indicate the superiority of the proposed method in these experiments.","2168-2275","","10.1109/TCYB.2021.3054878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9370000","Deep learning;denoising autoencoders (DAE);imputation;ladder networks;missing data;nonparametric models","Data models;Training;Estimation;Electromagnetic interference;Random forests;Generators;Vegetation","cyber-physical systems;data handling;deep learning (artificial intelligence)","deep ladder imputation network;data loss;task-specific solutions;data estimation;missing data imputation algorithm;supreme generalization ability;incomplete training sets;supreme flexibility;data distribution;ladder architecture;deep neural networks;data mechanisms;denoising autoencoders;cyber-physical system","Algorithms;Research Design","4","","43","IEEE","4 Mar 2021","","","IEEE","IEEE Journals"
"A stock forecasting method based on combination of SDAE and BP","Z. Li; X. Dang","School of Computer Science and Software Engineering, Tianjin Polytechnic University, Tianjin, China; School of Computer Science and Software Engineering, Tianjin Polytechnic University, Tianjin, China","2018 International Conference on Orange Technologies (ICOT)","6 May 2019","2018","","","1","6","The neural network, as a non-linear system with large-scale parallel distributed processing, has been widely used in the field of prediction. This paper proposes a stock forecasting method based on the combination of Stacked Denoising AutoEncoders (SDAE) and Back Propagation Neural Network (BPNN). Using more than 4100 historical data of Sinopec Group from 2001/8/8 to 2018/8/16 for Seventeen years, then process the data and select six features of them for training and prediction. The experiment first uses SDAE for training in the pre-training stage to obtain the weights. Then the trained weights of SDAE are assigned to the Back Propagation Neural Network (BPNN) for fine-tuning to optimize the entire network structure. Then optimize the network parameters for further step and chose the best optimal hyperparameter combination. Finally, the prediction is performed on the test set, the Mean Absolute Error (MAE), Error Variance (EV), and Absolute Maximum Error (AME) between the predicted value and the actual value are used as evaluation performance evaluation criteria. The results show that this neural network model can achieve high precision, and provides an effective method for predicting the stock market artificial neural network with many influencing factors and unclear mechanism.","","978-1-5386-7319-5","10.1109/ICOT.2018.8705891","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8705891","Neural Network;Stock Prediction;Stacked Denoising AutoEncoder (SDAE);Back Propagation Neural Network (BPNN)","Training;Noise reduction;Biological neural networks;Backpropagation;Neurons;Predictive models","backpropagation;data analysis;economic forecasting;financial data processing;neural nets;stock markets","BPNN;optimal hyperparameter combination;stock market artificial neural network;stock forecasting method;SDAE;nonlinear system;parallel distributed processing;back propagation neural network;stacked denoising autoencoders","","2","","19","","6 May 2019","","","IEEE","IEEE Conferences"
"Deep architectures for super-symmetric particle classification with noise labelling","I. Ni'mah; R. Sadikin","Research Centre for Informatics, Indonesian Institute of Sciences, Indonesia; Research Centre for Informatics, Indonesian Institute of Sciences, Indonesia","2016 International Conference on Computer, Control, Informatics and its Applications (IC3INA)","28 Feb 2017","2016","","","169","174","Deep learning algorithms modelled with deep architectures have demonstrated impressive results to alleviate common problems of Feedforward Neural Networks, i.e. escaping poor solutions of local minima. Basic architecture concepts behind these powerful models have been set up by preliminary research on Neural Networks, including the application of unsupervised pretraining algorithms and greedy layer-wise strategy and on small scale benchmark datasets. We present practical experiments to evaluate deep classifiers on large scale Super-symmetric (SUSY) particle data sets with variations of noise labelling to examine the robustness of its regularizer. Deep architecture models that are compared in this study include one single hidden layer Multilayer Perceptrons (MLP), Deep stacked Neural Networks (DNN), Stacked Denoising Autoencoders (SDAE), and Deep Belief Networks (DBN). The result shows that deep architecture models (DNN and SDAE) can reduce error gap between low-level and complete feature learning up to 78%, as compared to shallow model (MLP). In our experiment, SDAE can also maintain its superiority in less noisy data set and exhibits nearly linear convergence through the benefits of unsupervised pretraining layers and early stopping of hyperparameter learning.","","978-1-5090-2323-3","10.1109/IC3INA.2016.7863044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7863044","deep learning;deep neural networks;denoising autoencoders;deep belief networks;unsupervised pretraining","Computer architecture;Training;Data models;Neural networks;Decoding;Noise reduction;Noise measurement","multilayer perceptrons;unsupervised learning","deep learning algorithms;super-symmetric particle classification;noise labelling;feedforward neural networks;unsupervised pretraining algorithms;greedy layer-wise strategy;small scale benchmark datasets;one single hidden layer multilayer perceptrons;deep stacked neural networks;stacked denoising autoencoders;deep belief networks;MLP;DNN;SDAE;DBN","","2","","19","","28 Feb 2017","","","IEEE","IEEE Conferences"
"Tensor-Train Based Deep Learning Approach for Compressive Sensing in Mobile Computing","C. Zou; F. Yang","Department of Electronic Engineering, Tsinghua University & Beijing National Research Center for Information Science and Technology (BNRist), Beijing, P. R. China; Department of Electronic Engineering, Tsinghua University & Beijing National Research Center for Information Science and Technology (BNRist), Beijing, P. R. China","2019 15th International Wireless Communications & Mobile Computing Conference (IWCMC)","22 Jul 2019","2019","","","1544","1549","Several recent studies have been conducted on solving the compressive sensing problem with deep learning framework , which enhance the signal recovery performance and greatly shorten the running time compared with traditional algorithms. However, as the size of signals increases, so does the neural network, which will impose large memory space and high computational complexity, making it hard to use this method on mobile devices. To address this issue, in this paper, the neural network is decomposed by Tensor-Train (TT) format, which reduces the number of parameters to a great extent. In particular, the neural network decomposed by TT format is a stacked denoising autoencoder (SDA) network, which called TT-SDA. The experiments demonstrate that, especially with low measurement rates, the proposed TT-SDA network can improve the reconstruction results, reduce the computational complexity and save the memory space.","2376-6506","978-1-5386-7747-6","10.1109/IWCMC.2019.8766668","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8766668","Compressive sensing;deep learning;Tensor-Train;stacked denoising autoencoder","Computational complexity;Deep learning;Neural networks;Matrix decomposition;Compressed sensing;Image reconstruction","compressed sensing;computational complexity;learning (artificial intelligence);mobile computing;neural nets;tensors","mobile computing;compressive sensing problem;deep learning framework;signal recovery performance;traditional algorithms;neural network;memory space;high computational complexity;mobile devices;TT format;stacked denoising autoencoder network;TT-SDA network;tensor-train format;tensor-train based deep learning approach","","1","","30","","22 Jul 2019","","","IEEE","IEEE Conferences"
"A Data-Physical Hybrid-Driven Air Balancing Method for the Ventilation System","B. Li; C. Cui; X. Zhang; W. Cai","School of Electrical and Electronic Engineering and Energy Research Institute @ NTU, Interdisciplinary Graduate Programme, Nanyang Technological University,, Singapore, Singapore; Building and Construction Authority (BCA),, Singapore, Singapore; Hangzhou Global Scientific and Technological Innovation Center, Zhejiang University, Hangzhou; School of Electrical and Electronic Engineering, Nanyang Technological University,, Singapore, Singapore","IEEE Transactions on Industrial Informatics","12 Jul 2021","2021","17","10","6583","6593","This article proposes a data-physical hybrid-driven air balancing (DPH-AB) method for the ventilation system. First, a data-driven model is proposed to establish the relationship among the airflow, path pressure drop, pressure, and damper angle in the duct system. Specifically, the airflow-path pressure drop relationship is modeled by the denoising autoencoder neural network (DAENN) while the pressure-angle relationship is obtained by the ridge regression method. Then, the physical information of the duct system is considered together with the proposed data-driven model to find the optimal angle for each damper to minimize the total fan power. With the proposed DPH-AB method, the airflow of all terminals can be accurately adjusted to the desired value while the energy consumption of the duct system can reach the lowest value. It is easy to identify which damper needs to be fully open to save the energy. The experiments verify the accuracy of the proposed DPH-AB method and its energy saving potential. The experiments also demonstrate that the DPH-AB method is robust against the noise in the actual duct system.","1941-0050","","10.1109/TII.2020.3032551","Building and Construction Authority – Singapore(grant numbers:BCA 94.23.1.3.); Zhejiang University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9234013","Air balancing;data-physical hybrid-driven;denoising autoencoder neural network (DAENN);duct system;energy saving","Energy consumption;Fans;Atmospheric modeling;Ducts;Neural networks;Noise reduction;Shock absorbers","ducts;energy consumption;fans;mechanical engineering computing;neural nets;optimisation;regression analysis;ventilation","data-physical hybrid-driven air balancing method;ventilation system;data-driven model;damper angle;airflow-path pressure drop relationship;denoising autoencoder neural network;pressure-angle relationship;ridge regression method;physical information;optimal angle;DPH-AB method;actual duct system;energy consumption;total fan power minimization","","1","","36","IEEE","20 Oct 2020","","","IEEE","IEEE Journals"
"Power System Disturbance Identification With Missing PMU Data","W. Xiong; L. Wang; R. Wu; Z. Li; H. Liu; T. Bi","Guangzhou Power Supply Bureau Guangdong Power Grid Co., Ltd., Guangzhou, China; Guangzhou Power Supply Bureau Guangdong Power Grid Co., Ltd., Guangzhou, China; Guangzhou Power Supply Bureau Guangdong Power Grid Co., Ltd., Guangzhou, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources North China Electric Power University, Beijing, China","2020 IEEE Sustainable Power and Energy Conference (iSPEC)","18 Feb 2021","2020","","","2330","2335","With the wide coverage of wide-area measurement systems, considerable real-time monitoring of the entire network has been realized, making it possible to quickly and accurately identify the type of power system disturbance. However, many factors such as loss of synchronization signal and communication protocol error may result in PMU data loss problem, which may affect PMU based disturbance identification. Aiming at this problem, a power system disturbance identification method based on stacked denoising autoencoder (SDAE) and random forest is proposed. The nonlinear mapping relationship between a corrupted sample and a complete sample is established by SDAE. This avoids the limitations of constructing features based on human experience and enables extract high level feature representation that are more robust to samples containing missing data. In addition, a classification method based on random forest with integrated learning ideas is proposed to improve recognition accuracy. Finally, the simulation test is carried out on the IEEE-39 bus system, and compared with the traditional feature extraction method under different data loss levels. The accuracy, rapidity and good generalization ability of the proposed method are verified.","","978-1-7281-9164-5","10.1109/iSPEC50848.2020.9351130","National Key Research and Development Program of China(grant numbers:2017YF0902900,2017YFB0902901); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9351130","Data loss;deep learning;disturbance identification;phasor measurement units (PMUs);power system;stacked denoising autoencoder","Noise reduction;Feature extraction;Phasor measurement units;Loss measurement;Power systems;Wide area measurements;Random forests","deep learning (artificial intelligence);feature extraction;power engineering computing;power system faults;power system measurement;random forests","power system disturbance identification;stacked denoising autoencoder;SDAE;random forest;nonlinear mapping relationship;high level feature representation;missing data;classification method;IEEE-39 bus system;feature extraction;missing PMU data;wide-area measurement systems;real-time monitoring;synchronization signal;communication protocol error;PMU data loss problem;PMU based disturbance identification;data loss levels","","","","18","","18 Feb 2021","","","IEEE","IEEE Conferences"
"A New Unsupervised Online Early Fault Detection Framework of Rolling Bearings Based on Granular Feature Forecasting","K. Liu; W. Mao; H. Shi; X. Liang","School of Computer and Information Engineering, Henan Normal University, Xinxiang, China; Engineering Laboratory of Intelligence Business and Internet of Things of Henan Province, Xinxiang, China; School of Computer and Information Engineering, Henan Normal University, Xinxiang, China; Department of Mechanical Engineering, University of Manitoba, Winnipeg, MB, Canada","IEEE Access","10 Dec 2021","2021","9","","159684","159698","In online scenarios, the monitoring signals are collected in the form of streaming data and would raise some requirements for early fault detection (EFD) of rolling bearings: 1) enhancing the detection accuracy of online data; 2) lowering the computational cost of real-time detection; 3) reducing false alarm rate; 4) deploying easily and working adaptively without manual initialization. To solve this problem, a new unsupervised online EFD framework of rolling bearings is proposed based on granular feature forecasting. First, the proposed framework considers two different online scenarios in extracting granular feature representations of online data. If the offline monitoring data are available, a deep stacked denoising autoencoder (SDAE) network with domain adaptation is introduced to extract common feature representation via decreasing the data distribution differences between offline and online working conditions. If only initial online data are available, a SDAE model is directly used to extract deep features. Second, for the obtained features, a forecasting model with tensor Tucker decomposition and ARIMA is run to predict the degradation trend of all feature sequences quickly and simultaneously. Finally, the deviation degree between the predicted sequence and sequentially-arrived data is calculated for setting alarm threshold. The proposed framework adopts an unsupervised learning mode and has three advantages: 1) flexible applicability to two different online scenarios; 2) automatic detection and easy deployment without manual intervention; 3) high reliability and extremely low false alarm rate. Experimental results on the IEEE PHM Challenge 2012 dataset and XJTU-SY dataset verify the advantages of this proposed framework.","2169-3536","","10.1109/ACCESS.2021.3132353","National Nature Science Foundation of China(grant numbers:U1704158); Henan Province Technologies Research and Development Project of China(grant numbers:212102210103); NSFC Development Funding of Henan Normal University(grant numbers:2020PL09); 2021 Scientific Research Project for Postgraduates of Henan Normal University of China(grant numbers:YL202106); Natural Science and Engineering Research Council of Canada(grant numbers:RGPIN-2019-05361); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9634014","Early fault detection;anomaly detection;streaming data;denoising autoencoder;alarm threshold","Degradation;Transfer learning;Time series analysis;Employee welfare;Training;Task analysis;Prognostics and health management","condition monitoring;fault diagnosis;feature extraction;mechanical engineering computing;neural nets;rolling bearings;tensors;unsupervised learning","rolling bearings;granular feature forecasting;unsupervised online EFD framework;granular feature representations;deep stacked denoising autoencoder network;data distribution differences;deep features;forecasting model;feature sequences;unsupervised learning mode;false alarm rate;unsupervised online early fault detection framework;SDAE network","","","","31","CCBYNCND","3 Dec 2021","","","IEEE","IEEE Journals"
"An ELM-based Deep SDAE Ensemble for Inter-Subject Cognitive Workload Estimation with Physiological Signals","Z. Zheng; Z. Yin; J. Zhang","Engineering Research Center of Optical Instrument and System, Ministry of Education, Shanghai Key Lab of Modern Optical System, University of Shanghai for Science and Technology, Shanghai, P. R. China; Engineering Research Center of Optical Instrument and System, Ministry of Education, Shanghai Key Lab of Modern Optical System, University of Shanghai for Science and Technology, Shanghai, P. R. China; OsloMet Artificial Intelligence Lab, Department of Computer Science, Oslo Metropolitan University, Oslo, Norway","2020 39th Chinese Control Conference (CCC)","9 Sep 2020","2020","","","6237","6242","Evaluating operator cognitive workload (CW) levels in human-machine systems based on neurophysiological signals is becoming the basis to prevent serious accidents due to abnormal state of human operators. This study proposes an inter-subject CW classifier, extreme learning machine (ELM)-based deep stacked denoising autoencoder ensemble (ED-SDAE), to adapt the variations of the electroencephalogram (EEG) feature distributions across different subjects. The ED-SDAE consists of two cascade-connected modules, which are termed as high level personalized feature abstractions and abstraction fusion. The combination of SDAE and locality preserving projection (LPP) technique is regarded as base learner to obtain ensemble members for training meta-classifier by stacking-based approach. The ELM model with Q-statistics diversity measurement is acted as meta-classifier to fuse above inputs to improve classification performance. The feasibility of the SD-SDAE is tested by two EEG databases. The multi-class classification rate achieves 0.6353 and 0.6747 for T1 and T2 respectively, and significantly outperforms several shallow and deep CW estimators. By computing the main time complexity, the computational workload of the ED-SDAE is also acceptable for high-dimensional EEG features.","1934-1768","978-9-8815-6390-3","10.23919/CCC50068.2020.9188806","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9188806","Cognitive workload;EEG;ensemble learning;extreme learning machine;stacked denoising autoencoder","Training;Databases;Fuses;Noise reduction;Electroencephalography;Time measurement;Physiology","cognition;electroencephalography;feature extraction;learning (artificial intelligence);man-machine systems;medical signal processing;neurophysiology;signal classification;support vector machines","training meta-classifier;stacking-based approach;ELM model;SD-SDAE;deep CW estimators;ED-SDAE;high-dimensional EEG features;ELM-based deep SDAE ensemble;inter-subject cognitive workload estimation;physiological signals;operator cognitive workload levels;human-machine systems;neurophysiological signals;abnormal state;human operators;inter-subject CW classifier;cascade-connected modules;high level personalized feature abstractions;abstraction fusion;locality preserving projection technique;base learner;extreme learning machine-based deep stacked denoising autoencoder ensemble","","","","18","","9 Sep 2020","","","IEEE","IEEE Conferences"
"Detection and classification of place and manner of articulation for Bengali continuous speech","T. Bhowmik; S. Kumar Das Mandal","Centre for Educational Technology, Indian Institute of Technology, Kharagpur; Centre for Educational Technology, Indian Institute of Technology, Kharagpur","2017 4th International Conference on Signal Processing and Integrated Networks (SPIN)","28 Sep 2017","2017","","","578","583","In this paper the place and manner of articulation based phonological features are detected and classified. Deep Neural Network based model has been used for detection and classification task. The deep structured model is pre-trained by stacked denoising autoencoder. The system obtained 89.17% overall accuracy in detection task. In case of classification task, 50.2% of classification accuracy is observed for classifying the place of articulation based features. The manner of articulation is divided into 15 groups based on some manner based knowledge combination and classification task is performed to achieve 98.9% of classification accuracy.","","978-1-5090-2797-2","10.1109/SPIN.2017.8050016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8050016","Phonological features;place of articulation;manner of articulation;stacked denoising autoencoder;detection and classification;deep neural network","Speech;Speech recognition;Neural networks;Noise reduction;Feature extraction;Loss measurement","feature extraction;learning (artificial intelligence);neural nets;speech coding;voice activity detection","stacked denoising autoencoder;deep structured model;deep neural network based model;articulation based phonological feature classification;articulation based phonological feature detection;Bengali continuous speech articulation","","","","34","IEEE","28 Sep 2017","","","IEEE","IEEE Conferences"
"A DAE-based Approach for Improving the Grammaticality of Summaries","J. Huang; Y. Jiang","Department of Linguistics and Philology, Uppsala University, Uppsala, Sweden; Department of Linguistics, University of Washington, Seattle, The United States","2021 International Conference on Computers and Automation (CompAuto)","8 Mar 2022","2021","","","50","53","While recent neural sequence-to-sequence models have achieved better and better Rouge performance in summarization task, there is little work emphasizing the grammaticality of the generated summaries. This paper proposes a simple method of pre-training the summarizer as a Denoising Autoencoder (DAE) to reduce the grammar errors. We apply two types of DAE: one is to simply reconstruct the input sentences where randomly sampled tokens are replaced with [MASK] elements, the other is to recover the words or phrases that are replaced with wrong expressions, namely designed for the grammatical error correction task. We evaluate the experiment outputs with three automatic metrics, and the result reveals better grammatical performance while having ROUGE scores higher than that of the baseline model.","","978-1-6654-2371-7","10.1109/CompAuto54408.2021.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9726841","deep learning;denoising autoencoder;abstractive summarization;grammaticality","Measurement;Computers;Automation;Noise reduction;Data models;Grammar;Error correction","grammars;learning (artificial intelligence);natural language processing;neural nets;text analysis","DAE-based approach;grammaticality;sequence-to-sequence models;Rouge performance;summarization task;generated summaries;summarizer;Denoising Autoencoder;grammar errors;input sentences;randomly sampled tokens;[MASK] elements;wrong expressions;grammatical error correction task;grammatical performance;ROUGE scores;baseline model","","","","24","IEEE","8 Mar 2022","","","IEEE","IEEE Conferences"
"Fine-Tuning Self-Supervised Multilingual Sequence-To-Sequence Models for Extremely Low-Resource NMT","S. Thillainathan; S. Ranathunga; S. Jayasena","Dept. of Computer Science and Eng., University of Moratuwa, Katubedda, Sri Lanka; Dept. of Computer Science and Eng., University of Moratuwa, Katubedda, Sri Lanka; Dept. of Computer Science and Eng., University of Moratuwa, Katubedda, Sri Lanka","2021 Moratuwa Engineering Research Conference (MERCon)","14 Sep 2021","2021","","","432","437","Neural Machine Translation (NMT) tends to perform poorly in low-resource language settings due to the scarcity of parallel data. Instead of relying on inadequate parallel corpora, we can take advantage of monolingual data available in abundance. Training a denoising self-supervised multilingual sequence-to-sequence model by noising the available large scale monolingual corpora is one way to utilize monolingual data. For a pair of languages for which monolingual data is available in such a pre-trained multilingual denoising model, the model can be fine-tuned with a smaller amount of parallel data from this language pair. This paper presents fine-tuning self-supervised multilingual sequence-to-sequence pre-trained models for extremely low-resource domain-specific NMT settings. We choose one such pre-trained model: mBART. We are the first to implement and demonstrate the viability of non-English centric complete fine-tuning on multilingual sequence-to-sequence pre-trained models. We select Sinhala, Tamil and English languages to demonstrate fine-tuning on extremely low-resource settings in the domain of official government documents. Experiments show that our fine-tuned mBART model significantly outperforms state-of-the-art Transformer based NMT models in all pairs in all six bilingual directions, where we report a 4.41 BLEU score increase on Tamil→Sinhala and a 2.85 BLUE increase on Sinhala→ Tamil translation.","2691-364X","978-1-6654-3753-0","10.1109/MERCon52712.2021.9525720","World Bank; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9525720","neural machine translation;pre-trained models;fine-tuning;denoising autoencoder;low-resource languages","Training;Noise reduction;Government;Transformers;Data models;Machine translation","language translation;learning (artificial intelligence);natural language processing","available large scale monolingual corpora;monolingual data;pre-trained multilingual denoising model;parallel data;language pair;fine-tuning self-supervised multilingual sequence-to-sequence pre-trained models;low-resource domain-specific NMT settings;nonEnglish centric complete fine-tuning;low-resource settings;fine-tuned mBART model;NMT models;extremely low-resource NMT;low-resource language settings;inadequate parallel corpora;denoising self-supervised;sequence-to-sequence model","","","","29","IEEE","14 Sep 2021","","","IEEE","IEEE Conferences"
"Detecting multiple changes from multi-temporal images by using stacked denosing autoencoder based change vector analysis","L. Su; J. Shi; Puzhao Zhang; Zhao Wang; M. Gong","Key Laboratory of Intelligent Perception and Image Understanding, Xidian University, Xi'an, China; Northwestern Polytechnical University, Xi'an, Shaanxi, CN; Key Laboratory of Intelligent Perception and Image Understanding, Xidian University, Xi'an, China; Key Laboratory of Intelligent Perception and Image Understanding, Xidian University, Xi'an, China; Key Laboratory of Intelligent Perception and Image Understanding, Xidian University, Xi'an, China","2016 International Joint Conference on Neural Networks (IJCNN)","3 Nov 2016","2016","","","1269","1276","In this paper, we propose a novel approach for detecting multiple changes from two multi-temporal images. Despite the development of the change vector analysis (CVA) framework and its improved version the compressed CVA (C2VA) framework, it is found that they are limited when tackling the multi-change detection task for the images with one channel. Also, the intensity itself is fragile due to the existing noise, which especially influences the detection of subtle changes. Therefore, the stacked denosing autoencoder (SDAE) which serves as a fine tool for feature extraction is employed to generate a multi-dimensional feature representations. In this way, the C2VA framework can be applied to the inner robust features so that a satisfactory performance can be guaranteed. Experimental results from two datasets show its high accuracy and moderate time complexity, which demonstrates the effectiveness of the proposed SDAE-C2VA approach.","2161-4407","978-1-5090-0620-5","10.1109/IJCNN.2016.7727343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727343","","Feature extraction;Robustness;Neural networks;Bayes methods;Electronic mail;Image coding;Image segmentation","computational complexity;feature extraction;image coding;image denoising;image representation","stacked denosing autoencoder based change vector analysis;multitemporal images;multiple change detection;multi-temporal images;compressed CVA;feature extraction;multidimensional feature representations;inner robust features;time complexity;SDAE-C2VA approach","","9","","36","","3 Nov 2016","","","IEEE","IEEE Conferences"
"Dual-Band Wi-Fi Based Indoor Localization via Stacked Denosing Autoencoder","H. Zhang; K. Liu; Q. Shang; L. Feng; C. Chen; Z. Wu; S. Guo","College of Computer Science, Chongqing University, Chongqing, China; College of Computer Science, Chongqing University, Chongqing, China; College of Computer Science, Chongqing University, Chongqing, China; College of Computer Science, Chongqing University, Chongqing, China; College of Computer Science, Chongqing University, Chongqing, China; College of Automation, Chongqing University, Chongqing, China; College of Computer Science, Chongqing University, Chongqing, China","2019 IEEE Global Communications Conference (GLOBECOM)","27 Feb 2020","2019","","","1","6","With the ever-increasing demand of location-based services (LBS), Wi-Fi based indoor localization has attracted increasing attentions. This paper is dedicated to addressing two critical problems: a) signal fluctuation due to unforeseeable interferences during the offline training phase; b) insufficient real-time signal measurements at certain point due to the target movement during the online localization phase. Specifically, we first give an intensive analysis on the characteristics of received signal strength indicator (RSSI) in indoor environments with respect to both time-domain and frequency-domain. Then, inspired from the advantages of Stacked Denosing Autoencoder (SDA) in terms of recognizing and stabilizing the original features, we propose a dual-band SDA (DBSDA) based model to create more distinguishable fingerprints by extracting the RSSI features at each reference point (RP). In this model, both 2.4GHz and 5GHz RSSIs are exploited to train the SDA neural network and construct the offline fingerprint database. On this basis, we propose a data generation scheme, which is designed based on the observation that environmental interferences are similar in proximate spots. So, the designed scheme can generate signal values at certain point based on its nearby RSSI measurements when there are not enough inputs for the SDA neural network. Finally, we propose a locally weighted liner regression (LWLR) based method to predict the coordinate of the target. For performance evaluation, we implement the system prototype and give comprehensive experiments in real-world environments, which demonstrate the effectiveness and robustness of the proposed solutions.","2576-6813","978-1-7281-0962-6","10.1109/GLOBECOM38437.2019.9013872","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9013872","","Dual band;Databases;Wireless fidelity;Training;Frequency-domain analysis;Phase measurement;Feature extraction","indoor radio;neural nets;radiofrequency interference;regression analysis;RSSI;signal denoising;wireless LAN","SDA neural network;offline fingerprint database;data generation scheme;environmental interferences;signal values;nearby RSSI measurements;location-based services;signal fluctuation;unforeseeable interferences;offline training phase;target movement;online localization phase;received signal strength indicator;indoor environments;time-domain;frequency-domain;dual-band SDA based model;distinguishable fingerprints;RSSI features;stacked denosing autoencoder;locally weighted linear regression based method;dual-band Wi-Fi based indoor localization;frequency 5.0 GHz;frequency 2.4 GHz","","3","","16","","27 Feb 2020","","","IEEE","IEEE Conferences"
"A Noise Removal Approach from EEG Recordings Based on Variational Autoencoders","J. F. Hwaidi; T. M. Chen","Department of Electrical and Electronic Engineering, City, University of London, London, United Kingdom; Department of Electrical and Electronic Engineering, City, University of London, London, United Kingdom","2021 13th International Conference on Computer and Automation Engineering (ICCAE)","10 May 2021","2021","","","19","23","This paper presents a novel approach for reducing noise in electroencephalography (EEG) signals using the Variational AutoEncoders (VAE) algorithm. VAE's are attractive as they are designed on top of standard function approximators neural networks and can be trained with stochastic gradient descent to produce the desired output. Moreover, VAE has been compared with standard fast fixed-point algorithm for independent component analysis (FastICA) algorithm to measure the performance quantitatively by using machine learning algorithms like Support Vector Machines, Naive Bayes, and Decision Tree. The catch of this algorithm is utilised using the concept of misclassification as opposed to the classification accuracy of the above mentioned algorithms.","","978-1-6654-1295-7","10.1109/ICCAE51876.2021.9426150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9426150","EEG;Noise removal;misclassification;FastICA;VAE","Support vector machines;Machine learning algorithms;Neural networks;Independent component analysis;Approximation algorithms;Electroencephalography;Classification algorithms","decision trees;electroencephalography;function approximation;gradient methods;image denoising;independent component analysis;learning (artificial intelligence);medical signal processing;neural nets;pattern classification;support vector machines","noise removal approach;EEG recordings;electroencephalography signals;Variational AutoEncoders algorithm;VAE;standard function approximators neural networks;stochastic gradient descent;fixed-point algorithm;independent component analysis algorithm;Support Vector Machines;mentioned algorithms","","3","","22","","10 May 2021","","","IEEE","IEEE Conferences"
"Gated Variational AutoEncoders: Incorporating Weak Supervision to Encourage Disentanglement","M. J. Vowels; N. C. Camgoz; R. Bowden","University of Surrey: CVSSP, Guildford, Surrey, UK; University of Surrey: CVSSP, Guildford, Surrey, UK; University of Surrey: CVSSP, Guildford, Surrey, UK","2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)","18 Jan 2021","2020","","","125","132","Variational AutoEncoders (VAEs) provide a means to generate representational latent embeddings. Previous research has highlighted the benefits of achieving representations that are disentangled, particularly for downstream tasks. However, there is some debate about how to encourage disentanglement with VAEs, and evidence indicates that existing implementations do not achieve disentanglement consistently. The evaluation of how well a VAE's latent space has been disentangled is often evaluated against our subjective expectations of which attributes should be disentangled for a given problem. Therefore, by definition, we already have domain knowledge of what should be achieved and yet we use unsupervised approaches to achieve it. We propose a weakly-supervised approach that incorporates any available domain knowledge into the training process to form a Gated-VAE. The process involves partitioning the representational embedding and gating backpropagation. All partitions are utilised on the forward pass but gradients are backpropagated through different partitions according to selected image/target pairings. The approach can be used to modify existing VAE models such as beta-VAE, InfoVAE and DIP-VAE-II. Experiments demonstrate that using gated backpropagation, latent factors are represented in their intended partition. The approach is applied to images of faces for the purpose of disentangling head-pose from facial expression. Quantitative metrics show that using Gated-VAE improves average disentanglement, completeness and informativeness, as compared with un-gated implementations. Qualitative assessment of latent traversals demonstrate its disentanglement of head-pose from expression, even when only weak/noisy supervision is available.","","978-1-7281-3079-8","10.1109/FG47880.2020.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9320221","VAE;disentanglement;representation learning;generative models","Training;Logic gates;Measurement;Task analysis;Image reconstruction;Decoding;Faces","backpropagation;face recognition;feature selection;image denoising;image representation;neural nets;supervised learning;unsupervised learning","weak supervision;disentanglement;representational latent embeddings;unsupervised approach;weakly-supervised approach;Gated-VAE;representational embedding;gated backpropagation;gated variational autoencoders;VAE;image pairing selection;target pairing selection;face image","","1","","29","","18 Jan 2021","","","IEEE","IEEE Conferences"
"Residual convolutional autoencoder combined with a non-negative matrix factorization to estimate fetal heart rate","H. Lafaye de Micheaux; M. Resendiz; B. Rivet; J. Fontecave-Jallon","Univ. Grenoble Alpes, CNRS, CHU Grenoble Alpes, Grenoble INP, TIMC, Grenoble, France; GIPSA-Lab, Univ. Grenoble Alpes, CNRS, Grenoble INP, Grenoble, France; GIPSA-Lab, Univ. Grenoble Alpes, CNRS, Grenoble INP, Grenoble, France; Univ. Grenoble Alpes, CNRS, CHU Grenoble Alpes, Grenoble INP, TIMC, Grenoble, France","2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","8 Sep 2022","2022","","","1292","1295","The fetal heart rate (fHR) plays an important role in the determination of the good health of the fetus. Beside the traditional Doppler ultrasound technique, non-invasive fetal electrocardiography (fECG) has become an interesting alternative. However, extracting clean fECG from abdominal ECG (aECG) recordings is a challenging task due to the presence of the maternal ECG component and various noise sources. In this context, we propose a deep residual convolutional autoencoder network trained on synthetic aECG simulations followed by a transfer learning phase on real aECG recordings to extract the cleanest fECG. Afterwards, we propose to use a non-negative matrix factorization based approach on the obtained fECG to estimate the fHR. Our method is evaluated on three publicly available databases demonstrating that it can provide significant performance improvement against comparative methodologies. Clinical relevance— The presented method has the advantage of estimating the fetal heart rate from a single-channel abdominal electrocardiogram without prior knowledge on the noise sources nor the maternal R-peak locations.","2694-0604","978-1-7281-2782-8","10.1109/EMBC48229.2022.9871887","French National Research Agency(grant numbers:ANR-17-CE19-0012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9871887","","Ultrasonic imaging;Fetal heart rate;Databases;Transfer learning;Electrocardiography;Fetus;Recording","biomedical ultrasonics;electrocardiography;learning (artificial intelligence);matrix decomposition;medical signal detection;medical signal processing;obstetrics;patient monitoring;signal denoising","aECG recordings;cleanest fECG;nonnegative matrix factorization based approach;fHR;fetal heart rate;noise sources;good health;traditional Doppler ultrasound technique;noninvasive fetal electrocardiography;clean fECG;abdominal ECG recordings;maternal ECG component;deep residual convolutional autoencoder network;synthetic aECG simulations;transfer learning phase","Algorithms;Disease Progression;Electrocardiography;Female;Fetus;Heart Rate, Fetal;Humans;Pregnancy","","","13","IEEE","8 Sep 2022","","","IEEE","IEEE Conferences"
"Speech Enhancement Using Hybrid Model with Cochleagram Speech Feature","S. R. Chiluveru; M. Tripathy","Department of Electrical Engg., Indian Institute of Technology, Roorkee, India; Department of Electrical Engg., Indian Institute of Technology, Roorkee, India","2021 IEEE 2nd International Conference on Technology, Engineering, Management for Societal impact using Marketing, Entrepreneurship and Talent (TEMSMET)","9 May 2022","2021","","","1","6","The present work proposes a robust Cochleagram based speech enhancement method using a hybrid model, which is a combination of Denoising Autoencoder (DAE) and Long Short Term Memory (LSTM). The denoising autoencoder model is used for noise removal, but it lacks temporal dependency while the LSTM model shows good temporal connectivity, hence in this work, a hybrid model is proposed which helps to improve the sequential dependence as well as denoising the noisy speech signal. The performance of the proposed Hybrid model is evaluated with unknown noises, and the results of the proposed model are compared with the existing basic Denoising autoencoder and LSTM based speech enhancement algorithms. The proposed model shows improved intelligibility in both low and high signal-to-noise ratio (SNR) environments; higher intelligibility is observed in the negative SNR conditions, whereas the quality results show a slight improvement at all SNR values.","","978-1-6654-2778-4","10.1109/TEMSMET53515.2021.9768782","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9768782","Speech Enhancement;Deep Neural Network;Regression;Short-Time Objective Intelligibility;Perceptual Evaluation of Speech Quality","Engineering management;Noise reduction;Sea measurements;Entrepreneurship;Ear;Speech enhancement;Noise measurement","signal denoising;speech enhancement","noisy speech signal;hybrid model;Cochleagram speech feature;robust Cochleagram based speech enhancement method;Long Short Term Memory;denoising autoencoder model;LSTM model;signal-to-noise ratio environments;egative SNR conditions","","","","23","IEEE","9 May 2022","","","IEEE","IEEE Conferences"
"Diffusion Autoencoders: Toward a Meaningful and Decodable Representation","K. Preechakul; N. Chatthee; S. Wizadwongsa; S. Suwajanakorn","VISTEC, Thailand; VISTEC, Thailand; VISTEC, Thailand; VISTEC, Thailand","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","10609","10619","Diffusion probabilistic models (DPMs) have achieved remarkable quality in image generation that rivals GANs'. But unlike GANs, DPMs use a set of latent variables that lack semantic meaning and cannot serve as a useful representation for other tasks. This paper explores the possibility of using DPMs for representation learning and seeks to extract a meaningful and decodable representation of an input image via autoencoding. Our key idea is to use a learnable encoder for discovering the high-level semantics, and a DPM as the decoder for modeling the remaining stochastic variations. Our method can encode any image into a two-part latent code where the first part is semantically meaningful and linear, and the second part captures stochastic details, allowing near-exact reconstruction. This capability enables challenging applications that currently foil GAN-based methods, such as attribute manipulation on real images. We also show that this two-level encoding improves denoising efficiency and naturally facilitates various downstream tasks including few-shot conditional sampling. Please visit our page: https://Diff-AE.github.io/","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9878402","Image and video synthesis and generation; Representation learning","Representation learning;Image synthesis;Semantics;Noise reduction;Stochastic processes;Probabilistic logic;Encoding","encoding;feature extraction;image classification;image denoising;image representation;learning (artificial intelligence);probability;stochastic processes","autoencoding;learnable encoder;high-level semantics;decoder;remaining stochastic variations;two-part latent code;foil GAN-based methods;two-level encoding;diffusion autoencoders;meaningful representation;decodable representation;diffusion probabilistic models;DPMs;remarkable quality;image generation;GANs;latent variables;semantic meaning;useful representation;representation learning;input image","","","","61","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"A Deep Learning Approach to Anomaly Detection in Nuclear Reactors","F. Calivá; F. S. De Ribeiro; A. Mylonakis; C. Demazi’ere; P. Vinai; G. Leontidis; S. Kollias","School of Computer Science MLearn Group, University of Lincoln LN67TS, Lincoln, UK; School of Computer Science MLearn Group, University of Lincoln LN67TS, Lincoln, UK; Division of Subatomic and Plasma Physics Department of Physics SE-412 96 Gothenburg,, Chalmers University of Technology, Sweden; Chalmers tekniska hogskola, Goteborg, SE; Division of Subatomic and Plasma Physics Department of Physics SE-412 96 Gothenburg,, Chalmers University of Technology, Sweden; School of Computer Science MLearn Group, University of Lincoln LN67TS, Lincoln, United Kingdom; School of Computer Science MLearn Group, University of Lincoln LN67TS, Lincoln, United Kingdom","2018 International Joint Conference on Neural Networks (IJCNN)","14 Oct 2018","2018","","","1","8","In this work, a novel deep learning approach to unfold nuclear power reactor signals is proposed. It includes a combination of convolutional neural networks (CNN), denoising autoencoders (DAE) and $k$-means clustering of representations. Monitoring nuclear reactors while running at nominal conditions is critical. Based on analysis of the core reactor neutron flux, it is possible to derive useful information for building fault/anomaly detection systems. By leveraging signal and image pre-processing techniques, the high and low energy spectra of the signals were appropriated into a compatible format for CNN training. Firstly, a CNN was employed to unfold the signal into either twelve or forty-eight perturbation location sources, followed by a $k$-means clustering and $k$-Nearest Neighbour coarse-to-fine procedure, which significantly increases the unfolding resolution. Secondly, a DAE was utilised to denoise and reconstruct power reactor signals at varying levels of noise and/or corruption. The reconstructed signals were evaluated w.r.t. their original counter parts, by way of normalised cross correlation and unfolding metrics. The results illustrate that the origin of perturbations can be localised with high accuracy, despite limited training data and obscured$/$noisy signals, across various levels of granularity.","2161-4407","978-1-5090-6014-6","10.1109/IJCNN.2018.8489130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489130","deep learning;convolutional neural networks;clustering trained representations;denoising autoencoders;signal processing;nuclear reactors;unfolding;anomaly detection","Neutrons;Inductors;Perturbation methods;Sensors;Noise measurement;Signal to noise ratio;Green's function methods","feedforward neural nets;fission reactor monitoring;image denoising;learning (artificial intelligence);neutron flux;nuclear engineering computing;power engineering computing","obscured-noisy signals;building fault-anomaly detection systems;Neighbour coarse-to-fine procedure;perturbation location sources;CNN training;low energy spectra;high energy spectra;image pre-processing techniques;leveraging signal;core reactor neutron flux;nominal conditions;monitoring nuclear reactors;convolutional neural networks;unfold nuclear power reactor signals;deep learning approach;unfolding metrics;normalised cross correlation;reconstructed signals;DAE;unfolding resolution","","22","","27","","14 Oct 2018","","","IEEE","IEEE Conferences"
"Manifold Modeling in Embedded Space: An Interpretable Alternative to Deep Image Prior","T. Yokota; H. Hontani; Q. Zhao; A. Cichocki","RIKEN Center for Advanced Intelligence Project, Tokyo, Japan; Nagoya Institute of Technology, Nagoya, Japan; School of Automation, Guangdong University of Technology, Guangzhou, China; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China","IEEE Transactions on Neural Networks and Learning Systems","28 Feb 2022","2022","33","3","1022","1036","Deep image prior (DIP), which uses a deep convolutional network (ConvNet) structure as an image prior, has attracted wide attention in computer vision and machine learning. DIP empirically shows the effectiveness of the ConvNet structures for various image restoration applications. However, why the DIP works so well is still unknown. In addition, the reason why the convolution operation is useful in image reconstruction, or image enhancement is not very clear. This study tackles this ambiguity of ConvNet/DIP by proposing an interpretable approach that divides the convolution into “delay embedding” and “transformation” (i.e., encoder–decoder). Our approach is a simple, but essential, image/tensor modeling method that is closely related to self-similarity. The proposed method is called manifold modeling in embedded space (MMES) since it is implemented using a denoising autoencoder in combination with a multiway delay-embedding transform. In spite of its simplicity, MMES can obtain quite similar results to DIP on image/tensor completion, super-resolution, deconvolution, and denoising. In addition, MMES is proven to be competitive with DIP, as shown in our experiments. These results can also facilitate interpretation/characterization of DIP from the perspective of a “low-dimensional patch-manifold prior.”","2162-2388","","10.1109/TNNLS.2020.3037923","Japan Science and Technology Agency (JST) ACT-I(grant numbers:JPMJPR18UU); Hori Sciences and Arts Foundation; JSPS KAKENHI(grant numbers:20H04249,20H04208); MES Russian Federation(grant numbers:14.756.31.0001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9281370","Autoencoder (AE);convolutional neural network (CNN);deblurring;deconvolution;delay embedding;denoising AE (DAE);Hankelization;image inpainting;manifold model;super-resolution;tensor completion","Electronics packaging;Manifolds;Convolution;Tensors;Task analysis;Image reconstruction;Computational modeling","computer vision;convolutional neural nets;deep learning (artificial intelligence);image denoising;image enhancement;image reconstruction;image representation;image resolution;image restoration;tensors","manifold modeling;embedded space;interpretable alternative;deep image prior;deep convolutional network structure;computer vision;machine learning;ConvNet structures;image restoration applications;convolution operation;image reconstruction;image enhancement;interpretable approach;delay embedding transformation;MMES;multiway delay-embedding;DIP","","3","","85","CCBY","4 Dec 2020","","","IEEE","IEEE Journals"
"ECG Noise Removal Using FCN DAE Method","S. Kollem; M. R. Baig; D. Lasya; E. A. Kalyan; K. N. Varma","Dept. of ECE, SR University, Warangal, India; Dept. of ECE, SR Engineering College, Warangal, India; Dept. of ECE, SR Engineering College, Warangal, India; Dept. of ECE, SR Engineering College, Warangal, India; Dept. of ECE, SR Engineering College, Warangal, India","2022 2nd International Conference on Intelligent Technologies (CONIT)","18 Aug 2022","2022","","","1","8","An electrocardiogram (ECG) is a straightforward test that measures your heart rate and electrical activity. Electrical signals produced by your heart are detected by skin-connected nerves each time it beats. ECG signals are susceptible to noise contamination in real-world conditions, which can lead to misunderstanding. Baseline wanders and power line interference are the two main sources of noise in the ECG signal. To tackle these problems and eliminate inaccuracies, special emphasis has been dedicated to interpreting the ECG in order to achieve a precise diagnosis and analysis. To recycle pure data in its audio version, a denoising autoencoder (DAE) might be utilized. The results of experiments on ECG signals with various degrees of SNR input reveal that FCN outperforms fully connected neural network-and convolutional neural-based denoising network models significantly.","","978-1-6654-8407-7","10.1109/CONIT55038.2022.9847756","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9847756","ECG;FCN (Fully Convolutional Network) DAE (Denoising Autoencoders);SNR(Signal-to-Noise Ratio)","Heart rate;Convolution;Noise reduction;Electric variables measurement;Interference;Electrocardiography;Recycling","electrocardiography;medical signal processing;neural nets;recycling;signal denoising","ECG noise removal;FCN DAE method;straightforward test;heart rate;electrical activity;electrical signals;skin-connected nerves each time;ECG signal;noise contamination","","","","27","IEEE","18 Aug 2022","","","IEEE","IEEE Conferences"
"Building Floor Identification Method Based on DAE-LSTM in Cellular Network","Y. Zhang; L. Ma; B. Wang; D. Qin","School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; School of Electronics Engineering, Heilongiiang University, Harbin, China","2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring)","30 Jun 2020","2020","","","1","5","Quick and accurate floor identification in a multistory building is a challenging task for 3D indoor positioning. The performances of the available methods are low accuracy or even unworkable in the large and complex urban environment due to the noisy received data. Furthermore, the relationship between received data from different reference points is not considered to make the floor identification better. Therefore, in this paper, we focus on improving floor identification accuracy and propose a novel floor identification method. For better describing the property of the signal propagating difference coming from the same base station to different floors, we analyze both the channel characteristics and geographic characteristics and then select five important parameters for floor identification. Based on these parameters, a floor identification method is proposed. We use Denoising Autoencoder (DAE) on these parameters for noise reduction and feature extraction. Then, we use the Long Short-Term Memory (LSTM) on the denoised features for floor identification, which can better explore and utilize data feature relationship. Based on the real cellular network data, the experiment results show that our proposed floor identification method is very accurate for different structural buildings, which outperforms the traditional methods.","2577-2465","978-1-7281-5207-3","10.1109/VTC2020-Spring48590.2020.9129414","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9129414","Indoor position;Floor identification;Denoising Autoencoder;Long Short-Term Memory;LTE","Floors;Base stations;Feature extraction;Mathematical model;Long Term Evolution;Noise measurement","cellular radio;feature extraction;floors;image denoising;indoor navigation;indoor radio;radio networks","data feature relationship;cellular network data;different structural buildings;building floor identification method;accurate floor identification;noisy received data;different reference points;floor identification accuracy;novel floor identification method","","","","15","","30 Jun 2020","","","IEEE","IEEE Conferences"
"Unsupervised Learning for 2D Image Texture Enhancement","B. Labinghisa; J. -S. Kim; D. M. Lee","Research Team EasyGeo Co, Busan, Republic of Korea; President Office EasyGeo Co, Busan, Republic of Korea; Dept. of Computer Engineering, Tongmyong University, Busan, Republic of Korea","2021 International Conference on Information and Communication Technology Convergence (ICTC)","7 Dec 2021","2021","","","587","589","One disadvantage of supervised learning is the capability of the neural network to only recognize objects labeled during the training phase. In order to identify objects outside of the training dataset, unsupervised learning is needed. In this paper, autoencoder is used as the unsupervised neural network and it also functions as a 2D image texture enhancer. Autoencoder is capable of clustering and dimensional reduction, where reducing dimensions of images can be categorized as feature selection and feature extraction. The role of autoencoder as an unsupervised network is to train different High-Resolution (HR) images and preserve texture features that can be used later to enhance Low-Resolution (LR) input images and process them into an enhanced 2D image (E2D). Low-resolution images due to degradation or blurring can be enhanced with the proposed algorithm under 2 parts of autoencoder: encoder and decoder. The encoder stage downsizes the HR dataset while maintaining the extracted features during the training phase. The decoder stage makes use of the extracted feature and denoises the LR input image to produce an E2D image. 100 LR images were tested with a 100% success rate of E2D enhancement.","2162-1233","978-1-6654-2383-0","10.1109/ICTC52510.2021.9621093","Busan Metropolitan City; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9621093","unsupervised learning;autoencoder;image enhancement;2D image;neural network","Training;Degradation;Image texture;Neural networks;Supervised learning;Feature extraction;Decoding","feature extraction;feature selection;image enhancement;image resolution;image texture;neural nets;unsupervised learning","unsupervised learning;2D image texture enhancement;supervised learning;training phase;training dataset;autoencoder;unsupervised neural network;2D image texture enhancer;feature selection;feature extraction;unsupervised network;high-resolution images;texture features;enhanced 2D image;E2D;low-resolution images;extracted feature;LR input image;low-resolution input images","","","","6","IEEE","7 Dec 2021","","","IEEE","IEEE Conferences"
"Optimal configuration planning of multi-energy microgird based on deep joint generation of source-load-temperature scenarios","N. Huang; W. Wang; G. Cai","School of Electrical Engineering, Key Laboratory of Modern Power System Simulation and Control & Renewable Energy Technology (Northeast Electric Power University), Jilin 132012, China; School of Electrical Engineering, Key Laboratory of Modern Power System Simulation and Control & Renewable Energy Technology (Northeast Electric Power University), Jilin 132012, China; School of Electrical Engineering, Key Laboratory of Modern Power System Simulation and Control & Renewable Energy Technology (Northeast Electric Power University), Jilin 132012, China","CSEE Journal of Power and Energy Systems","","2020","PP","99","1","12","An optimal configuration method of a multi-energy microgrid system based on the deep joint generation of source-load-temperature scenarios is proposed to improve the multi-energy complementation and the reliability of energy supply in extreme scenarios. Firstly, based on the historical meteorological data, the typical meteorological clusters and extreme temperature types are obtained. Then, to reflect the uncertainty of energy consumption and renewable energy output in different weather types, a deep joint generation model of radiation-electric load-temperature scenario based on denoising variational autoencoder is established for each weather module. At the same time, to cover the potential high energy consumption scenarios with extreme temperatures, the extreme scenarios with fewer data samples are expanded. After that, the scenarios are reduced by clustering analysis. The typical days of different typical scenarios and extreme temperature scenarios are determined, and the cooling and heating loads are determined by temperature. Finally, the optimal configuration of a multi-energy microgrid system is carried out. Experiments show that the optimal configuration based on the extreme scenarios and typical scenarios can improve the power supply reliability of the system. The proposed method can accurately capture the complementary potential of energy sources. And the economy of the system configuration is improved by 14.56%.","2096-0042","","10.17775/CSEEJPES.2020.01090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9171690","Multi-energy microgrid system;Optimal configuration planning;deep joint generation;Denoising variational autoencoders","Load modeling;Cogeneration;Micromechanical devices;Microgrids;Reliability engineering","","","","2","","","","19 Aug 2020","","","CSEE","CSEE Early Access Articles"
"Research on software defect prediction technology based on deep learning","P. Jiang","College of Engineering, Northeastern University, Boston, USA","2021 2nd International Conference on Computing and Data Science (CDS)","5 Jul 2021","2021","","","104","107","To solve the problem that the traditional feature selection methods, such as PCA and LDA, are unable to get the nonlinear relationship between characteristics. Deep belief networks cannot eliminate the noise and missing value, which affect the accuracy of the software defect prediction (SDP) model. Not only the methods of feature selection, but data preprocessing and learning algorithm can also affect the precision of the defect prediction model. This thesis uses deep belief networks and SVM to construct an SDP model (DBN-SVM) to increase prediction precision. Using denoising autoencoders and SVM to build an SDP model (DA - SVM), compared with the DBN - SVM, DA - SVM model not only improves the prediction precision, but also enhance the robustness of the model. The thesis also proposes an SDP model framework which includes data preprocessing, feature selection and learning algorithm.","","978-1-6654-0428-0","10.1109/CDS52072.2021.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9463239","software defect prediction;deep belief networks;support vector machine;denoising autoencoders;feature selection","Support vector machines;Software algorithms;Data preprocessing;Predictive models;Feature extraction;Prediction algorithms;Software","belief networks;feature extraction;learning (artificial intelligence);principal component analysis;support vector machines","learning algorithm;software defect prediction technology;deep learning;traditional feature selection methods;nonlinear relationship;deep belief networks;missing value;software defect prediction model;data preprocessing;DBN-SVM;prediction precision;DA - SVM;DBN - SVM;SVM model;SDP model framework","","1","","16","IEEE","5 Jul 2021","","","IEEE","IEEE Conferences"
"An Effective Model for Detect Dump Truck Plate","J. S. Kim; T. K. Whangbo","Dept. of Computer Science, Gachon University, Seongnam-si, Republic of Korea; Dept. of Computer Science, Gachon University, Seongnam-si, Republic of Korea","2019 International Symposium on Multimedia and Communication Technology (ISMAC)","6 Jan 2020","2019","","","1","4","This paper suggests a method for enhancing vehicle license plate recognition performance and detection accuracy under unfavorable conditions through improving images by using the vehicle license plate region detection and denoising autoencoder technologies of Faster R-CNN in order to improve misrecognition in detection performance due to the slanting or breakage of license plates, or the influence of illumination, which are chronic problems in automatic license plate recognition system at construction sites. The learning of 3,000 images collected from actual construction sites were conducted for this paper, and the improvement of illumination resulted in more than 30% improvement in accuracy.","","978-1-7281-1918-2","10.1109/ISMAC.2019.8836171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8836171","FasterR-CNN;Autoencoder;Denoising;License Plate Detection","License plate recognition;Lighting;Object detection;Image recognition;Proposals;Noise reduction;Character recognition","","","","","","14","IEEE","6 Jan 2020","","","IEEE","IEEE Conferences"
"Wind turbine failure detection based on SCADA data and data mining method","S. Tao; Z. Qian; Y. Pei; A. Wang; F. Zhang","School of Instrumentation and Optoelectronic Engineering, Beihang University, Beijing, China; School of Instrumentation and Optoelectronic Engineering, Beihang University, Beijing, China; State Key Laboratory of Operation and Control of Renewable Energy & Storage Systems, China Electric Power Research Institute, Haidian Dist., Beijing, China; School of Instrumentation and Optoelectronic Engineering, Beihang University, Beijing, China; CSIC HaiZhuang Windpower Co., Ltd, Chongqing, China","8th Renewable Power Generation Conference (RPG 2019)","19 Mar 2020","2019","","","1","7","WTFD (Wind Turbine Failure Detection) system is important for improving wind turbine reliability and reducing operation & maintenance cost. A WTFD method using only SCADA data and data mining algorithm is proposed. Firstly, select representative variables from a wide variety of SCADA variables using ARD (Automatic Relevance Determination) method. Then, the denoising autoencoders (DAE) model using the selected variables with sliding window is developed to capture nonlinear correlations among multiple variables and autocorrelation of each variable. Finally, using the Mahalanobs distance (MD) of reconstruction error to make the WTFD. Real world dataset is used to validate the efficiency of the proposed method. The results show that the proposed method can provide advanced failure alarm for wind turbines many hours before failure happens. The results of our proposed WTFD method can reduce operation & maintenance cost and improve wind turbine reliability.","","978-1-83953-124-8","10.1049/cp.2019.0660","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9041650","WINDTURBINE FAILUR DETECTION;DATA MINING;MAHALANOBIS DISTANCE;DENOISING AUTOENCODERS;RECONSTRUCTION ERROR","","","","","","","","","19 Mar 2020","","","IET","IET Conferences"
"Learning High-Dimensional Evolving Data Streams With Limited Labels","S. U. Din; J. Kumar; J. Shao; C. B. Mawuli; W. D. Ndiaye","School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China, also with the Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Huzhou 313001, China, and also with the Department of Computer Science, COMSATS University Islamabad, Islamabad 45550, Pakistan.; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China, and also with the Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Huzhou 313001, China.; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China, and also with the Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Huzhou 313001, China (e-mail: junmshao@uestc.edu.cn); School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China, and also with the Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Huzhou 313001, China.; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China, and also with the Yangtze Delta Region Institute (Huzhou), University of Electronic Science and Technology of China, Huzhou 313001, China.","IEEE Transactions on Cybernetics","","2021","PP","99","1","12","In the context of streaming data, learning algorithms often need to confront several unique challenges, such as concept drift, label scarcity, and high dimensionality. Several concept drift-aware data stream learning algorithms have been proposed to tackle these issues over the past decades. However, most existing algorithms utilize a supervised learning framework and require all true class labels to update their models. Unfortunately, in the streaming environment, requiring all labels is unfeasible and not realistic in many real-world applications. Therefore, learning data streams with minimal labels is a more practical scenario. Considering the problem of the curse of dimensionality and label scarcity, in this article, we present a new semisupervised learning technique for streaming data. To cure the curse of dimensionality, we employ a denoising autoencoder to transform the high-dimensional feature space into a reduced, compact, and more informative feature representation. Furthermore, we use a cluster-and-label technique to reduce the dependency on true class labels. We employ a synchronization-based dynamic clustering technique to summarize the streaming data into a set of dynamic microclusters that are further used for classification. In addition, we employ a disagreement-based learning method to cope with concept drift. Extensive experiments performed on many real-world datasets demonstrate the superior performance of the proposed method compared to several state-of-the-art methods.","2168-2275","","10.1109/TCYB.2021.3070420","Fundamental Research Funds for the Central Universities(grant numbers:ZYGX2019Z014); National Natural Science Foundation of China(grant numbers:61976044,52079026); Fok Ying-Tong Education Foundation for Young Teachers in the Higher Education Institutions of China(grant numbers:161062); National Key Research and Development Program of China(grant numbers:2016YFB0502300); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9440866","Concept drift;denoising autoencoder (DAE);evolving data streams;semisupervised learning (SSL);synchronization","Clustering algorithms;Heuristic algorithms;Feature extraction;Classification algorithms;Data models;Data mining;Noise reduction","","","","","","","IEEE","25 May 2021","","","IEEE","IEEE Early Access Articles"
"Deep Generative Learning Models for Cloud Intrusion Detection Systems","L. Vu; Q. U. Nguyen; D. N. Nguyen; D. T. Hoang; E. Dutkiewicz","Information Technology Department, Le Quy Don Technical University, Hanoi 10000, Vietnam, and also with the School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, NSW 2007, Australia.; Information Technology Department, Le Quy Don Technical University, Hanoi 10000, Vietnam; School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, NSW 2007, Australia.; School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, NSW 2007, Australia.; School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, NSW 2007, Australia.","IEEE Transactions on Cybernetics","","2022","PP","99","1","13","Intrusion detection (ID) on the cloud environment has received paramount interest over the last few years. Among the latest approaches, machine learning-based ID methods allow us to discover unknown attacks. However, due to the lack of malicious samples and the rapid evolution of diverse attacks, constructing a cloud ID system (IDS) that is robust to a wide range of unknown attacks remains challenging. In this article, we propose a novel solution to enable robust cloud IDSs using deep neural networks. Specifically, we develop two deep generative models to synthesize malicious samples on the cloud systems. The first model, conditional denoising adversarial autoencoder (CDAAE), is used to generate specific types of malicious samples. The second model (CDAEE-KNN) is a hybrid of CDAAE and the K-nearest neighbor algorithm to generate malicious borderline samples that further improve the accuracy of a cloud IDS. The synthesized samples are merged with the original samples to form the augmented datasets. Three machine learning algorithms are trained on the augmented datasets and their effectiveness is analyzed. The experiments conducted on four popular IDS datasets show that our proposed techniques significantly improve the accuracy of the cloud IDSs compared with the baseline technique and the state-of-the-art approaches. Moreover, our models also enhance the accuracy of machine learning algorithms in detecting some currently challenging distributed denial of service (DDoS) attacks, including low-rate DDoS attacks and application layer DDoS attacks.","2168-2275","","10.1109/TCYB.2022.3163811","Vietnam National Foundation for Science and Technology Development NAFOSTED(grant numbers:102.05-2019.05); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9760282","Cloud systems;conditional denoising adversarial autoencoder (CDAAE);deep learning;generative models;intrusion detection (ID)","Cloud computing;Denial-of-service attack;Computer crime;Machine learning algorithms;Deep learning;Intrusion detection;Support vector machines","","","","","","","IEEE","19 Apr 2022","","","IEEE","IEEE Early Access Articles"
"Deep neural network and random forest hybrid architecture for learning to detect retinal vessels in fundus images","D. Maji; A. Santara; S. Ghosh; D. Sheet; P. Mitra","Indian Institute of Technology Kharagpur, Kharagpur, WB, India; Indian Institute of Technology Kharagpur, Kharagpur, WB, India; Department of Ophthalmology, North Bengal Medical College and Hospital, Darjeeling, India; Indian Institute of Technology Kharagpur, Kharagpur, WB, India; Indian Institute of Technology Kharagpur, Kharagpur, West Bengal, IN","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","5 Nov 2015","2015","","","3029","3032","Vision impairment due to pathological damage of the retina can largely be prevented through periodic screening using fundus color imaging. However the challenge with large-scale screening is the inability to exhaustively detect fine blood vessels crucial to disease diagnosis. In this work we present a computational imaging framework using deep and ensemble learning based hybrid architecture for reliable detection of blood vessels in fundus color images. A deep neural network (DNN) is used for unsupervised learning of vesselness dictionaries using sparse trained denoising auto-encoders (DAE), followed by supervised learning of the DNN response using a random forest for detecting vessels in color fundus images. In experimental evaluation with the DRIVE database, we achieve the objective of vessel detection with max. avg. accuracy of 0.9327 and area under ROC curve of 0.9195.","1558-4615","978-1-4244-9271-8","10.1109/EMBC.2015.7319030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7319030","Computational imaging;deep learning;denoising auto-encoder;random forests;vessel detection","Biomedical imaging;Vegetation;Retinal vessels;Image analysis;Radio frequency","biomedical optical imaging;blood vessels;diseases;eye;image denoising;learning (artificial intelligence);medical image processing;vision defects","deep network;random forest hybrid architecture;retinal vessel detection;vision impairment;pathological damage;periodic screening;fundus color imaging;large-scale screening;blood vessels;disease diagnosis;computational imaging framework;learning based hybrid architecture;deep neural network;unsupervised learning;sparse trained denoising autoencoders;DNN response;DRIVE database;ROC curve","Fundus Oculi;Humans;Neural Networks (Computer);Retina;Retinal Vessels","27","","16","","5 Nov 2015","","","IEEE","IEEE Conferences"
"Deep neural networks for precipitation estimation from remotely sensed information","Y. Tao; X. Gao; A. Ihler; K. Hsu; S. Sorooshian","Department of Civil and Environmental Engineering, University of California, Irvine, Irvine, California; Department of Civil and Environmental Engineering, University of California, Irvine, Irvine, California; Department of Computer Science, University of California, Irvine, Irvine, California; Department of Civil and Environmental Engineering, University of California, Irvine, Irvine, California; Department of Civil and Environmental Engineering, University of California, Irvine, Irvine, California","2016 IEEE Congress on Evolutionary Computation (CEC)","21 Nov 2016","2016","","","1349","1355","This paper investigates the application of deep neural networks to precipitation estimation from remotely sensed information. Specifically, a stacked denoising auto-encoder is used to automatically extract features from the infrared cloud images and estimate the amount of precipitation, referred as PERSIANN-SDAE. Due to the challenging imbalance in precipitation data, a Kullback-Leibler divergence is incorporated in the objective function to preserve the distribution of it. PERSIANN-SDAE is compared with a shallow neural network with hand designed features and an operational satellite-based precipitation estimation product. The experimental results demonstrate the effectiveness of PERSIANN-SDAE in estimating precipitation accurately while preserving its distribution. It outperforms both the shallow neural network and the operational product.","","978-1-5090-0623-6","10.1109/CEC.2016.7743945","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7743945","stacked denoising auto-encoders;precipitation;deep neural networks;remote sensing;Kullback-Leibler divergence","Clouds;Feature extraction;Estimation;Neural networks;Remote sensing;Satellites;Rain","atmospheric precipitation;clouds;feature extraction;geophysical image processing;geophysical techniques;image coding;image denoising;infrared imaging;neural nets;remote sensing","remotely sensed information;deep neural networks;stacked denoising autoencoder;automatic feature extraction;infrared cloud images;PERSIANN-SDAE;precipitation data;Kullback-Leibler divergence;operational satellite-based precipitation estimation product","","11","","21","","21 Nov 2016","","","IEEE","IEEE Conferences"
"Fully Convolutional Network for Recognition of Small Buildings in Aerial Images","Z. -q. WANG; W. -w. GONG; Y. -f. JIAO; Q. -l. WU; W. -y. LI","School of Information Science and Engineering, Shandong Agricultural University, Tai’ an, Shandong, China; School of Information Science and Engineering, Shandong Agricultural University, Tai’ an, Shandong, China; School of Information Science and Engineering, Shandong Agricultural University, Tai’ an, Shandong, China; School of Information Science and Engineering, Shandong Agricultural University, Tai’ an, Shandong, China; School of Information Science and Engineering, Shandong Agricultural University, Tai’ an, Shandong, China","2018 Fifth International Workshop on Earth Observation and Remote Sensing Applications (EORSA)","3 Jan 2019","2018","","","1","5","Aiming at the question that the existing building targets recognition method is difficult to perform a pixel-by-pixel semantic recognition on an image, which leads to the problem of low recognition accuracy of small buildings, the small building recognition method of high-resolution aerial images based on deep convolutional neural network has been carried in this paper. To address the problem of information loss of the feature map in the process of pooling, the multi-scale fusion of the pooling layer and the deconvolutional layer is proposed. The activation function is also improved to extract more reliable features. Furthermore, to address the information loss problem in small buildings, multiple stacked denoising sparse auto-encoders are proposed. The experiment enhances the information of small target in the image and improves the input module of the fully convolutional network (FCN) model. Experimental results on aerial images of Wangdagua Village, Pingyuan County show that the proposed method outperforms the compared methods such as the conventional convolutional neural network (CNN) and the artificial neural network (ANN). The results also show that the accuracy of the improved model is not only significantly higher than shallow machine learning methods, but also can be more effective in mining the law of high-resolution aerial images of small and medium-sized pieces of building space distribution and eliminate the false targets in the image up to a point.","","978-1-5386-6642-5","10.1109/EORSA.2018.8598558","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598558","Fully convolutional network;Aerial images;Stacked Denoising Sparse Auto-encoder;Small buildings;Targets recognition","Buildings;Feature extraction;Target recognition;Mathematical model;Image recognition;Convolutional neural networks;Training","convolutional neural nets;feature extraction;image coding;image denoising;image recognition;image resolution;learning (artificial intelligence);object recognition","building space distribution;pixel-by-pixel semantic recognition;high-resolution aerial images;deep convolutional neural network;multiscale fusion;pooling layer;deconvolutional layer;fully convolutional network model;artificial neural network;shallow machine learning methods;convolutional neural network;building target recognition method;ANN;CNN;FCN;multiple stacked denoising sparse autoencoders;Wangdagua Village;Pingyuan County","","1","","14","","3 Jan 2019","","","IEEE","IEEE Conferences"
"Single channel speech enhancement using convolutional neural network","T. Kounovsky; J. Malek","Faculty of Mechatronics, Technical University of Liberec, Liberec, Czech Republic; Faculty of Mechatronics, Technical University of Liberec, Liberec, Czech Republic","2017 IEEE International Workshop of Electronics, Control, Measurement, Signals and their Application to Mechatronics (ECMSM)","15 Jun 2017","2017","","","1","5","Neural networks can be used to identify and remove noise from noisy speech spectrum (denoisisng autoencoders, DAEs). The DAEs are typically implemented using the fully-connected feed-forward topology. Usually one of the following possibilities is used as DA target: 1) Ideal frequency ratio mask, which is applied to noisy spectrum to estimate the clean speech spectrum (masking) or 2) Clean speech spectrum directly (mapping). Recent research in the area of automatic speech recognition shows that convolutional neural networks are very promising in speech modeling. In this paper we thus suggest, construct the DAs with the convolutional topology. We investigate the suitability of both above described target types and compare the results with the fully connected DAs. Our experiments indicate that mapping-based convolutional networks estimating log-power spectra achieve significant improvement over all competing topologies and target types. Performance gains of 8% in PESQ scores over the ideal ratio masking are observed. We also investigate the ability of DAEs to enhance speech of unseen language based on the language diversity of the training set. Our experiments suggest that training DAEs with language-diverse training sets does not yield any significant benefit for the task of speech enhancement.","","978-1-5090-5582-1","10.1109/ECMSM.2017.7945915","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7945915","Denoising autoencoder;Single channel speech enhancement;Convolutional neural network;Multilingual training","Speech;Training;Speech enhancement;Noise measurement;Signal to noise ratio;Distortion;Biological neural networks","feedforward neural nets;natural language processing;speech enhancement;speech recognition","single channel speech enhancement;convolutional neural network;noisy speech spectrum;denoising autoencoders;DAE;fully-connected feed-forward topology;ideal frequency ratio mask;clean speech spectrum estimation;automatic speech recognition;speech modeling;mapping-based convolutional networks;log-power spectra;PESQ scores;language diversity","","27","1","20","","15 Jun 2017","","","IEEE","IEEE Conferences"
"Binarization of Degraded Photographed Document Images- A Variational Denoising Auto Encoder","N. S. Rani; B. N. B J; K. S. K; S. A","Department of Computer Science, Amrita School of Arts and Sciences, Amrita Vishwa Vidyapeetham, Mysuru, India; Department of Computer Science, Amrita School of Arts and Sciences, Amrita Vishwa Vidyapeetham, Mysuru, India; Department of Computer Science, Amrita School of Arts and Sciences, Amrita Vishwa Vidyapeetham, Mysuru, India; Department of Computer Science, Amrita School of Arts and Sciences, Amrita Vishwa Vidyapeetham, Mysuru, India","2021 Third International Conference on Inventive Research in Computing Applications (ICIRCA)","1 Oct 2021","2021","","","119","124","Document image enhancement is one of the prime researches in the area of optical character recognition and computer vision. Preprocessing procedure for a document depends on document layout, aging and document material type. This paper proposes a preprocessing technique for the enhancement of ancient and degraded document images. Initially the degraded patches from the document image is collected and used for learning through a variational de-noising autoencoder followed by document image enhancement. Ground truth images of the degraded patches are trained with the help of an adamax optimizer. A deep learning architecture comprised of five levels of convolution is devised for encoding and decoding process. Down sampling is initially performed in the encoding stage after each level of convolution. Further up sampling is conducted in the decoding stage. Experimentations are conducted on DIBCO (2016, 2013, 2012, 2011, 2010 and 2009) datasets and the results of enhancement are found to be promising with an average RMSE of 0.106 for batch size 1 and 24 epochs.","","978-1-6654-3877-3","10.1109/ICIRCA51532.2021.9544864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9544864","Document binarization;Degraded images;Auto encoders;DIBCO;De-noising","Convolution;Noise reduction;Stochastic processes;Lighting;Computer architecture;Optical imaging;Encoding","document image processing;feature extraction;image classification;image denoising;image enhancement;learning (artificial intelligence);optical character recognition","document image enhancement;ground truth images;degraded patches;degraded photographed document images;variational denoising auto encoder;optical character recognition;computer vision;document layout, aging;ancient document images;degraded document images","","","","32","","1 Oct 2021","","","IEEE","IEEE Conferences"
"Study of speaker recognition system based on Feed Forward deep neural networks exploring text-dependent mode","B. J. Makrem; J. Imen; O. Kaïs","Research Unit: Signals and Mechatronic Systems, University of Carthage Charguiall, Tunisia; Research Unit: Signals and Mechatronic Systems, University of Carthage Charguiall, Tunisia; Research Unit: Signals and Mechatronic Systems, University of Carthage Charguiall, Tunisia","2016 7th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT)","8 Jun 2017","2016","","","355","360","We aim by this work to follow the significant progress in speaker recognition systems getting the benefits of the advancement in the artificial intelligence (AI). Indeed, the deep learning algorithms have proved a real performance in the recognition and classification data. In this contest, we present a study of three different speaker recognition system based in Feed Forward neural networks. The first one is the logic regression, the second one is the Multilayer Perceptron (MLP) and the third one is the Stacked Denoising Autoencodeurs (SDA). We evaluated these recognition rates using the parameterization technique Mel Frequency Cepstral Coefficients (MFCC). To find the best results and to better optimize automatic recognition algorithms, we tested our speaker recognition system under the text-dependent database RSR2015. We studied the recognition rates by varying the values of neural networks parameters, number of neurons and number of hidden layers...etc. We discussed the different results obtained and we selected best parameter values which lead the minimum rate error of recognition.","","978-1-5090-4712-3","10.1109/SETIT.2016.7939893","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7939893","Speaker recognition;text-dependent mode;feed forward networks;logistic regression;multilayers perceptron;stacked denoising autoencoders","Biological neural networks;Logistics;Speaker recognition;Feeds;Noise reduction;Neurons;Training","cepstral analysis;feedforward neural nets;learning (artificial intelligence);multilayer perceptrons;regression analysis;speaker recognition;text analysis","speaker recognition system;Feed Forward deep neural networks;text-dependent mode;artificial intelligence;AI;deep learning algorithms;logic regression;Multilayer Perceptron;MLP;Stacked Denoising Autoencoders;SDA;parameterization technique Mel Frequency Cepstral Coefficients;MFCC;automatic recognition algorithms;text-dependent database RSR2015;neural networks parameter values;neuron number","","4","","21","","8 Jun 2017","","","IEEE","IEEE Conferences"
"Action Recognition Scheme Based on Skeleton Representation With DS-LSTM Network","X. Jiang; K. Xu; T. Sun","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; National Engineering Laboratory for Information Content Analysis Technology, School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE Transactions on Circuits and Systems for Video Technology","1 Jul 2020","2020","30","7","2129","2140","Skeleton-based human action recognition has been a popular research field during the past few years. With the help of cameras equipping deep sensors, such as the Kinect, human action can be represented by a sequence of human skeleton data. Inspired by the skeleton descriptors based on Lie group, a spatial-temporal skeleton transformation descriptor (ST-STD) is proposed in this paper. The ST-STD describes the relative transformations of skeletons, including the rotation and translation during movement. It gives a comprehensive view of the skeleton in both spatial and temporal domain for each frame. To capture the temporal connections in the skeleton sequence, a denoising sparse long short term memory (DS-LSTM) network is proposed in this paper. The DS-LSTM is designed to deal with two problems in action recognition. First, to decrease the intra-class diversity, the spatial-temporal auto-encoder (STAE) is proposed in this paper to generate representations with higher abstractness. The denoising constraint and the sparsity constraint are applied on both spatial and temporal domain to enhance the robustness and to reduce action misalignment. Second, to model the action sequence, a three-layer LSTM structure is trained with STAE representations for temporal modeling and classification. The experiments are carried out on four popular datasets. The results show that our approach performs better than several existing skeleton-based action recognition methods, which prove the effectiveness of our method.","1558-2205","","10.1109/TCSVT.2019.2914137","Nature Science Foundation of China(grant numbers:61572321,61572320); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8703407","Action recognition;skeleton;DS-LSTM;ST-STD;Lie group;STAE","Skeleton;Hidden Markov models;Long short term memory;Noise reduction;Gesture recognition;Recurrent neural networks;Image motion analysis","cameras;gesture recognition;image classification;image denoising;image motion analysis;image representation;image sequences;image thinning;learning (artificial intelligence);object recognition;recurrent neural nets","skeleton representation;DS-LSTM network;skeleton-based human action recognition;human skeleton data;skeleton descriptors;ST-STD;spatial domain;temporal domain;temporal connections;skeleton sequence;denoising sparse long short term memory network;action misalignment;action sequence;three-layer LSTM structure;STAE representations;temporal modeling;classification;skeleton-based action recognition;spatial-temporal autoencoder;spatial-temporal skeleton transformation descriptor;deep sensors;Kinect;Lie group;denoising constraint;sparsity constraint","","14","","45","IEEE","30 Apr 2019","","","IEEE","IEEE Journals"
"Deep Denoising Sparse Coding","Y. Wang; B. Yang","School of Software Engineering, Xi'an Jiaotong University, Xi'an, China; School of Computer Science, Xi'an Polytechnic University, Xi'an, China","2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)","24 Dec 2020","2020","","","681","685","Single-cell Ribonucleic Acid sequencing (scRNA-seq) has great potential to discover cell types, identify cell states, trace development lineages, and reconstruct the spatial organization of cells. Clustering transcriptomes profiled by scRNA-seq has been routinely conducted to reveal cell heterogeneity and diversity. In fact, scRNA-seq data contain an abundance of dropout events that lead to zero expression measurements. These dropout events may be the result of technical sampling effects or real biology arising from stochastic transcriptional activity. Therefore clustering analysis of scRNA-seq data remains a statistical and computational challenge. Here, we have developed Deep Denoising Sparse Coding (DDSC), a deep clustering method combine autoencoder and sparse coding approach. Based on six real datasets from five representative single-cell sequencing platforms, DDSC outperformed some state-of-the-art methods under various clustering performance metrics and exhibited improved scalability. Its accuracy and efficiency make DDSC a promising algorithm for clustering large-scale scRNA-seq data.","2375-0197","978-1-7281-9228-4","10.1109/ICTAI50040.2020.00109","National Natural Science Foundation of China (NSFC)(grant numbers:61806159); China Postdoctoral Science Foundation(grant numbers:2018M631192); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288173","deep learning;clustering;sparse coding","Sequential analysis;Clustering methods;Noise reduction;Clustering algorithms;Encoding;Sparse matrices;Unsupervised learning","bioinformatics;biology computing;genetics;genomics;molecular biophysics;pattern clustering;RNA;statistical analysis","single-cell ribonucleic acid sequencing;cell types;cell states;cell heterogeneity;dropout events;stochastic transcriptional activity;DDSC;deep clustering;sparse coding;representative single-cell sequencing;clustering performance metrics;large-scale scRNA-seq data;autoencoder;deep denoising sparse coding;transcriptomes clustering","","","","31","","24 Dec 2020","","","IEEE","IEEE Conferences"
"Examining the Size of the Latent Space of Convolutional Variational Autoencoders Trained With Spectral Topographic Maps of EEG Frequency Bands","T. Ahmed; L. Longo","Artificial Intelligence and Cognitive Load Research Laboratory, School of Computer Science, Technological University Dublin, Dublin 7, Ireland; Artificial Intelligence and Cognitive Load Research Laboratory, School of Computer Science, Technological University Dublin, Dublin 7, Ireland","IEEE Access","13 Oct 2022","2022","10","","107575","107586","Dimensionality reduction and the automatic learning of key features from electroencephalographic (EEG) signals have always been challenging tasks. Variational autoencoders (VAEs) have been used for EEG data generation and augmentation, denoising, and automatic feature extraction. However, investigations of the optimal shape of their latent space have been neglected. This research tried to understand the minimal size of the latent space of convolutional VAEs, trained with spectral topographic EEG head maps of different frequency bands, that leads to the maximum reconstruction capacity of the input and maximum utility for classification tasks. Head maps are generated employing a sliding window technique with a 125ms shift. Person-specific convolutional VAEs are trained to learn latent spaces of varying dimensions while a dense neural network is trained to investigate their utility on a classification task. The empirical results suggest that when VAEs are deployed on spectral topographic maps with shape  $32\times 32$ , deployed for 32 electrodes from 2 seconds cerebral activity, they were capable of reducing the input up to almost 99%, with a latent space of 28 means and standard deviations. This did not compromise the salient information, as confirmed by a structural similarity index, and mean squared error between the input and reconstructed maps. Additionally, along the 28 means maximized the utility of latent spaces in the classification task, with an average 0.93% accuracy. This study contributes to the body of knowledge by offering a pipeline for effective dimensionality reduction of EEG data by employing convolutional variational autoencoders.","2169-3536","","10.1109/ACCESS.2022.3212777","Technological University Dublin, Ireland(grant numbers:PB04433); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9913434","Electroencephalography;convolutional variational autoencoder;latent space;deep learning;frequency bands;spectral topographic maps;and neural networks","Electroencephalography;Brain modeling;Convolutional neural networks;Deep learning;Feature extraction;Encoding;Data models;Neural networks;Frequency bands;Terrain mapping","","","","","","44","CCBY","6 Oct 2022","","","IEEE","IEEE Journals"
"Unsupervised Phase Extraction Using Dual Autoencoder","P. Jatesiktat; W. T. Ang","School of Mechanical and Aerospace Engineering, Nanyang Technology University, Singapore; NA","2017 International Conference on Advanced Computing and Applications (ACOMP)","25 Jun 2018","2017","","","71","76","Phase assignment is usually a part of periodic time-series data processing which needs some manual labeling or a heuristic method for each specific type of signals. Our work uses an unsupervised learning method to make the phase identification process fully-automated and more universal. This method also allows flexibility of input data in the term of position variation and phase progression variation. Four synthetic periodic two-dimensional signals with different shapes are used to explore our method's learning capabilities and some limitations. The proposed method is also tested with an actual periodic movement sequence captured from a Kinect sensor. This method can learn the periodic pattern automatically from a noisy signal and assign correct phases.","","978-1-5386-0607-0","10.1109/ACOMP.2017.15","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8392581","","Noise reduction;Training data;Data models;Data mining;Cost function;Convergence;Feature extraction","image coding;signal denoising;time series;unsupervised learning","dual autoencoder;phase assignment;periodic time-series data processing;manual labeling;heuristic method;unsupervised learning method;phase identification process;input data;position variation;phase progression variation;two-dimensional signals;learning capabilities;actual periodic movement sequence;periodic pattern;noisy signal;unsupervised phase extraction","","1","1","10","","25 Jun 2018","","","IEEE","IEEE Conferences"
"Image Inpainting Using AutoEncoder and Guided Selection of Predicted Pixels","M. H. Givkashi; M. Hadipour; A. PariZanganeh; Z. Nabizadeh; N. Karimi; S. Samavi","Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran; Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran; Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran; Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran; Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran; Department of Electrical and Computer Engineering, McMaster University, Canada","2022 30th International Conference on Electrical Engineering (ICEE)","20 Jul 2022","2022","","","700","704","Image inpainting is one of the most important ways to enhance corrupted digital images or pictures with missing pixels. For this purpose, different methods have been proposed. Some methods use the information of neighboring pixels to reconstruct the image. However, recent advances in deep learning have shown that receiving reasonable structural and semantic details from images can solve this problem. In this paper, we propose a network for image inpainting. This network, similar to U-Net, extracts various features from images, leading to better results. We improve the final results by replacing the damaged pixels with the recovered pixels of the output images. Our experimental results show that this method produces high-quality results compare to the traditional methods.","2642-9527","978-1-6654-8087-1","10.1109/ICEE55646.2022.9827427","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9827427","image inpainting;mask;missing pixels;U-Net","Learning systems;Image quality;Electrical engineering;Deep learning;Interpolation;Digital images;Video sequences","feature extraction;image coding;image denoising;image reconstruction;image restoration;learning (artificial intelligence)","image inpainting;corrupted digital images;missing pixels;damaged pixels;recovered pixels;AutoEncoder;predicted pixels;image reconstruction;feature extraction;U","","","","25","IEEE","20 Jul 2022","","","IEEE","IEEE Conferences"
"Noise Modeling and Data Augmentation Using Conditional Adversarial Autoencoder","Y. Jiang; Y. Zhu; Y. Liu; C. Xu","School of Automation, China University of Geosciences, Wuhan, China; School of Automation, China University of Geosciences, Wuhan, China; CRRC Zhuzhou Locomotive Co., Ltd.; School of Automation, China University of Geosciences, Wuhan, China","2020 39th Chinese Control Conference (CCC)","9 Sep 2020","2020","","","7390","7395","Noising image recognition is an important but challenging task. The images collected by the camera are often accompanied by a variety of noise, which will cause the loss of image information to make recognition difficult. With powerful feature extraction, neural network models can be used to process these complex noising images. However, when the noise model to be learned is complex and the number of learning samples is limited, this may lead to overfitting of the network model. In order to increase the diversity of noising images in limited learning samples and improve the generalization ability of the recognition model, we propose a noise modeling method based on CVAE-GAN. First, the encoder maps a real noising image to hidden layer vectors, which contains noise distribution, image category, and pose information. Then the decoder receives these hidden layer vectors to generate an synthetic image of the specified category and noise level. Finally, during the training process, we combine adversarial loss and smoothl1 loss to make the generated noising image more realistic. Experiments show that compared with other current generative models, our method can more effectively learn the distribution rules of complex noise in real images and generate synthetic images more similar to real noise. These synthetic images generated by our method can can alleviate the overfitting problem caused by insufficient data volume and enhance the generalization ability of image recognition models. By this way, we obtain the state-of-the-art recognition performance on the challenging noising image dataset.","1934-1768","978-9-8815-6390-3","10.23919/CCC50068.2020.9188989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9188989","Noising Image;Data Augmentation;Recognition;Noise Modeling;Weak Supervision","Data models;Training;Image recognition;Gallium nitride;Feature extraction;Machine learning;Inspection","feature extraction;image denoising;image recognition;neural nets","conditional adversarial autoencoder;image information;neural network models;complex noising images;noise model;learning samples;network model;generalization ability;recognition model;noise modeling method;hidden layer vectors;noise distribution;image category;synthetic image;adversarial loss;generated noising image;current generative models;complex noise;image recognition models;state-of-the-art recognition performance;challenging noising image dataset","","","","18","","9 Sep 2020","","","IEEE","IEEE Conferences"
"Helicopter Track Identification with Autoencoder","L. Wang; P. Lucic; K. Campbell; C. Wanke","The MITRE Corporation, McLean, VA, United States; The MITRE Corporation, McLean, VA, United States; The MITRE Corporation, McLean, VA, United States; The MITRE Corporation, McLean, VA, United States","2021 Integrated Communications Navigation and Surveillance Conference (ICNS)","2 Jun 2021","2021","","","1","8","Computing power, big data, and advancement of algorithms have led to a renewed interest in artificial intelligence (AI), especially in deep learning (DL). The success of DL largely lies on data representation because different representations can indicate to a degree the different explanatory factors of variation behind the data. In the last few year, the most successful story in DL is supervised learning. However, to apply supervised learning, one challenge is that data labels are expensive to get, noisy, or only partially available. With consideration that we human beings learn in an unsupervised way; self-supervised learning methods have garnered a lot of attention recently. A dominant force in self-supervised learning is the autoencoder, which has multiple uses (e.g., data representation, anomaly detection, denoise). This research explored the application of an autoencoder to learn effective data representation of helicopter flight track data, and then to support helicopter track identification. Our testing results are promising. For example, at Phoenix Deer Valley (DVT) airport, where 70% of recorded flight tracks have missing aircraft types, the autoencoder can help to identify twenty-two times more helicopters than otherwise detectable using rule-based methods; for Grand Canyon West Airport (1G4) airport, the autoencoder can identify thirteen times more helicopters than a current rule-based approach. Our approach can also identify mislabeled aircraft types in the flight track data and find true types for records with pseudo aircraft type labels such as HELO. With improved labelling, studies using these data sets can produce more reliable results.","2155-4951","978-1-6654-3584-0","10.1109/ICNS52807.2021.9441606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9441606","","Atmospheric modeling;Surveillance;Helicopters;Supervised learning;Airports;Aircraft navigation;Reliability","aerospace computing;airports;Big Data;data structures;deep learning (artificial intelligence);helicopters;knowledge based systems;object tracking;supervised learning","HELO;1G4 airport;DVT airport;anomaly detection;helicopter flight track data;data representation;self-supervised learning method;data labels;deep learning;artificial intelligence;big data;pseudoaircraft type labels;Grand Canyon West Airport airport;rule-based methods;autoencoder;recorded flight tracks;Phoenix Deer Valley airport;helicopter track identification","","","","12","","2 Jun 2021","","","IEEE","IEEE Conferences"
"Examing and Evaluating Dimension Reduction Algorithms for Classifying Alzheimer’s Diseases using Gene Expression Data","S. Li; P. Yang; V. Lanfranchi","Department of Computer Science, University of Sheffield, Sheffield, UK; Department of Computer Science, University of Sheffield, Sheffield, UK; Department of Computer Science, University of Sheffield, Sheffield, UK","2021 17th International Conference on Mobility, Sensing and Networking (MSN)","13 Apr 2022","2021","","","687","693","Alzheimer’s disease (AD) is a neurodegenerative disease. Its condition is irreversible and ultimately fatal. Researchers have been studying approaches to support early diagnosis of Alzheimer disease and further delay the patient’s condition and improve AD patient’s quality of life. Gene expression data is a mature technology. It has many advantages such as high throughput, less-invasiveness, and affordability. It has great potential to help people diagnose Alzheimer’s disease in early stage. However, because the amount of information is too large compared to the number of samples in the Alzheimer’s database, researchers are facing “curse of dimensionality” when using gene expression data. In this work we are interested in the task of dimensionality reduction of gene expression data in Alzheimer’s Disease Neuroimaging Initiative (ADNI) database. We investigated six dimensionality reduction algorithms: Principal component analysis, Kernel principal component analysis, Isometric feature mapping, Local linear embedding, Stacked denoising autoencoder, and Stacked sparse autoencoder. An SVM classifier is used to classify the samples in the ADNI dataset using the features obtained by dimensionality reduction. We first optimized the appropriate number of hidden layers for the two stacked autoencoders. Then we performed different degrees of dimensionality reduction with the other four algorithms and compared the classification performance of the features obtained by different algorithms with the SVM classifier. Our experimental results show that the features obtained by kernel principal component analysis and local linear embedding, Stacked denoising autoencoder, and Stacked sparse autoencoder dimensionality reduction have good AD classification performance.","","978-1-6654-0668-0","10.1109/MSN53354.2021.00106","National Institute on Aging; National Institute of Biomedical Imaging and Bioengineering; AbbVie; BioClinica; Biogen; Eisai; Elan; Genentech; IXICO; Merck; Meso Scale Diagnostics; Nova; Servier; National Institutes of Health; Northern California Institute for Research and Education; University of Southern California; University of Southern California; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9751471","Gene Expression;Dimensionality Reduction;Alzheimer’s Disease","Dimensionality reduction;Support vector machines;Noise reduction;Classification algorithms;Gene expression;Alzheimer's disease;Task analysis","diseases;feature extraction;image classification;learning (artificial intelligence);medical image processing;neurophysiology;patient diagnosis;pattern classification;principal component analysis;support vector machines","gene expression data;neurodegenerative disease;further delay;Alzheimer's database;dimensionality reduction algorithms;kernel principal component analysis;Stacked denoising autoencoder;SVM classifier;Stacked sparse autoencoder dimensionality reduction","","","","22","IEEE","13 Apr 2022","","","IEEE","IEEE Conferences"
"Multilabel Image classification using optimized ensemble deep learning","H. Dhole; V. S. Devi; R. Aparna; R. Raj","Dept. of ISE, SIT, Tumakuru, India; Dept. of CSA, Indian Institute of Science, Bengaluru, India; Dept. of ISE, SIT, Tumakuru, India; Dept. of CSA, Indian Institute of Science, Bengaluru, India","2022 IEEE World Conference on Applied Intelligence and Computing (AIC)","18 Aug 2022","2022","","","732","738","Deep learning is presently giving very good performance for many applications like Image identification, Speech recognition, Natural language processing, Recommendation systems etc. Ensemble learning is giving very good performance when applied in deep learning. In this paper, we use deep learning as well as ensemble learning for the classification of multi-label dataset. The novelty of the model is that we combine three different models. In the first model we use AutoEncoder+CNN by using only the encoder part to reduce the dimension. The second model is created by adding the noise to the input data and then using AutoEncoder to denoise the noisy data so that the model can work even for noisy dataset in real-time applications. The third model uses the vision Transformer. The proposed ensemble deep learning model combines these different models to predict the final result. The ensemble model outperforms each individual model and the state-of-the-art models.","","978-1-6654-7988-2","10.1109/AIC55036.2022.9848954","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9848954","classification;stacked ensemble;transformer;autoencoder","Deep learning;Computational modeling;Speech recognition;Predictive models;Transformers;Data models;Real-time systems","convolutional neural nets;deep learning (artificial intelligence);image classification;image denoising","vision transformer;AutoEncoder+CNN;individual model;ensemble model;deep learning model;Image identification;optimized ensemble deep learning;multilabel Image classification","","","","16","IEEE","18 Aug 2022","","","IEEE","IEEE Conferences"
"Transformer Fault Diagnosis Using Self-Powered RFID Sensor and Deep Learning Approach","T. Wang; Y. He; B. Li; T. Shi","School of Electrical Engineering and Automation, Hefei University of Technology, Hefei, China; School of Electrical Engineering, Wuhan University, Wuhan, China; School of Electrical Engineering and Automation, Hefei University of Technology, Hefei, China; School of Electrical Engineering and Automation, Hefei University of Technology, Hefei, China","IEEE Sensors Journal","11 Jul 2018","2018","18","15","6399","6411","This paper introduces a novel fault diagnosis approach for transformer based on self-powered radio-frequency identification (RFID) sensor and deep learning technique. The exploited RFID sensor tag with functionalities of signal collection, data storage, and wireless transmission employs surrounding electromagnetic field as power source. A customized power management circuit, including ac–dc converter, supercapacitor, and its corresponding charging circuit, is presented to guarantee constant dc power for the sensor tag. The measured vibration signal contains miscellaneous noises and is characterized as nonlinearity and nonstationarity, so it is difficult to extract robust and useful features by using traditional feature extraction approaches. As one of the deep learning techniques, stacked denoising autoencoder (SDA) shows satisfactory performance in learning robust features from complex signal. Hence, in this paper, SDA approach is employed to learn robust and discriminative features from measured signals. The experimental results show that the presented power supply can generate 2.5-V dc voltage, which is the rated operating voltage for the rest of the sensor tag. The developed sensor tag can achieve a reliable communication distance of 17.3 m in the test environment. Furthermore, the SDA approach shows satisfactory performance in learning robust and discriminative features. Experimental results indicate that the presented approach is effective and time-saving in terms of fault diagnosis for transformer winding and core.","1558-1748","","10.1109/JSEN.2018.2844799","National Natural Science Foundation of China(grant numbers:51577046); State Key Program of National Natural Science Foundation of China(grant numbers:51637004); National Key Research and Development Plan—Important Scientific Instruments and Equipment Development(grant numbers:2016YFF0102200); Equipment Research Project in Advance(grant numbers:41402040301); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374948","Transformer;fault diagnosis;self-powered RFID sensor tag;stacked denoising autoencoder","Radiofrequency identification;Feature extraction;Fault diagnosis;Supercapacitors;Vibrations;Power transformers","AC-DC power convertors;fault diagnosis;feature extraction;learning (artificial intelligence);power engineering computing;radiofrequency identification;signal denoising;supercapacitors;transformer windings;vibrational signal processing","transformer fault diagnosis;self-powered RFID sensor;deep learning approach;fault diagnosis approach;deep learning technique;customized power management circuit;ac-dc converter;constant dc power;deep learning techniques;complex signal;SDA approach;transformer winding;vibration signal;charging circuit;RFID sensor tag","","26","","52","IEEE","7 Jun 2018","","","IEEE","IEEE Journals"
"A Comparative Study of Object Tracking using CNN and SDAE","W. Yang; W. Wang; Y. Gao; Z. Jin","Department of Electrical and Computer Engineering, Binghamton University, SUNY, Binghamton, New York, USA; Department of Computer Science and Engineering, University at Buffalo, SUNY, Buffalo, New York, USA; Department of Computer Science and Engineering, University at Buffalo, SUNY, Buffalo, New York, USA; Department of Computer Science and Engineering, University at Buffalo, SUNY, Buffalo, New York, USA","2018 International Joint Conference on Neural Networks (IJCNN)","14 Oct 2018","2018","","","1","6","Object tracking which refers to automatic estimation of the trajectory is a challenging problem. To track the object robustly and efficiently, we explored an autonomous object tracking methodological framework that adopts the deep learning architectures, specifically the convolutional neural network (CNN) and the stacked denoising autoencoder (SDAE), as opposed to the most frequently used tracking algorithms that only learn the appearance of the tracked object. Moreover, we conduct a comparative study of both approaches in terms of tracking accuracy and efficiency. The results show that the features learned by both CNN and SDAE are very supportive in object tracking problem and the detailed comparisons are demonstrated in this work.","2161-4407","978-1-5090-6014-6","10.1109/IJCNN.2018.8489742","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489742","object tracking;convolutional neural network;stacked denoising autoencoder;particle filter","Target tracking;Object tracking;Neural networks;Convolution;Feature extraction;Trajectory;Machine learning","image denoising;learning (artificial intelligence);object detection;object tracking;recurrent neural nets","comparative study;CNN;SDAE;automatic estimation;autonomous object;deep learning architectures;convolutional neural network;frequently used tracking algorithms;tracked object;object tracking problem","","1","","13","","14 Oct 2018","","","IEEE","IEEE Conferences"
"Deep Learning-based Symbolic Indoor Positioning using the Serving eNodeB","F. Alhomayani; M. Mahoor","Department of Electrical and Computer Engineering, University of Denver, USA; Department of Electrical and Computer Engineering, University of Denver, USA","2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA)","23 Feb 2021","2020","","","489","494","This paper presents a novel indoor positioning method designed for residential apartments. The proposed method makes use of cellular signals emitting from a serving eNodeB which eliminates the need for specialized positioning infrastructure. Additionally, it utilizes Denoising Autoencoders to mitigate the effects of cellular signal loss. We evaluated the pro-posed method using real-world data collected from two different smartphones inside a representative apartment of eight symbolic spaces. Experimental results verify that the proposed method outperforms conventional symbolic indoor positioning techniques in various performance metrics. To promote reproducibility and foster new research efforts, we made all the data and codes associated with this work publicly available.","","978-1-7281-8470-8","10.1109/ICMLA51294.2020.00083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9356376","Cellular Networks;Dataset;Deep Learning;Denoising Autoencoder;eNodeB;Symbolic Indoor Positioning","Measurement;Deep learning;Conferences;Noise reduction;Coherence;Smart phones","cellular radio;deep learning (artificial intelligence);indoor navigation;indoor radio;signal denoising;telecommunication computing","serving eNodeB;indoor positioning method;residential apartments;cellular signals;positioning infrastructure;cellular signal loss;smartphones;representative apartment;symbolic spaces;conventional symbolic indoor positioning techniques;deep learning-based symbolic indoor positioning","","1","","22","","23 Feb 2021","","","IEEE","IEEE Conferences"
"Multi-Task Self-Supervised Learning for Vehicle Classification Based on Carrier-Free UWB Radars","Y. Zhu; S. Chen; X. Li; S. Zhang; L. Zhu","School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Transactions on Instrumentation and Measurement","15 Aug 2022","2022","71","","1","12","Recently, target recognition based on the carrier-free ultrawideband (UWB) radar has attracted increasing attention, as compared with narrowband radars and other traditional UWB radars, short duration and extreme bandwidth guarantee that carrier-free UWB echoes carry richer knowledge concerning the target of interest. However, its widespread application to target recognition faces a challenge; that is, the target-aspect sensitivity issue. The target-aspect sensitivity refers to the phenomenon that carrier-free UWB echoes significantly vary as target-aspect changes, decreasing recognition accuracy. To address this problem, this article presents a novel multitask self-supervised learning model that can capture abundant semantic information relying on data itself instead of identity annotations. First, the model is formulated as a target-aspect-invariant task, which maximizes the mutual information between original data and transformed ones to learn insensitive representations. Then, given the impact of noise on recognition performance, a stacked convolutional denoising autoencoder (SCDAE) is combined with the proposed self-supervised learning framework to extract noise-robust and target-aspect-invariant features synchronously. Extensive experiments on the measured and synthetic data demonstrate that the proposed model can achieve excellent classification performance.","1557-9662","","10.1109/TIM.2022.3196085","Natural Science Foundation of Jiangsu Province(grant numbers:BK20200075,BK20220941); National Natural Science Foundation of China (NSFC)(grant numbers:61971226); Fundamental Research Funds for the Central Universities(grant numbers:30917011315); Jiangsu Funding Program for Excellent Postdoctoral Talent(grant numbers:2022ZB257); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9849047","Carrier-free ultrawideband~(UWB) radar;data augmentation;denoising autoencoder (DAE);multitask self-supervised learning mechanism;vehicle recognition","Ultra wideband radar;Target recognition;Feature extraction;Data models;Task analysis;Multitasking;Sensitivity","feature extraction;image classification;image denoising;image representation;radar imaging;radar target recognition;road vehicles;supervised learning;traffic engineering computing;ultra wideband radar","self-supervised learning framework;narrowband radars;traditional UWB radars;carrier-free UWB echoes;novel multitask self-supervised learning model;recognition performance;target aspect invariant task;target aspect sensitivity issue;carrier free ultrawideband radar;carrier free UWB radars;target aspect invariant features","","","","41","IEEE","3 Aug 2022","","","IEEE","IEEE Journals"
"Deep Learning for Accurate Indoor Human Tracking with a mm-Wave Radar","J. Pegoraro; D. Solimini; F. Matteo; E. Bashirov; F. Meneghello; M. Rossi","Department of Information Engineering, University of Padova; Department of Mathematics, University of Padova; Department of Mathematics, University of Padova; Department of Information Engineering, University of Padova; Department of Information Engineering, University of Padova; Department of Information Engineering, University of Padova","2020 IEEE Radar Conference (RadarConf20)","4 Dec 2020","2020","","","1","6","We address the use of backscattered mm-wave radio signals to track humans as they move within indoor environments. The common approach in the literature leverages the extended Kalman filter (EKF) method, which however undergoes a severe performance degradation when the system evolution model is highly non-linear or presents long-term time dependencies among the system states. In this work, we propose an original model-free tracking procedure based on denoising autoencoders and sequence-to-sequence neural networks, showing its superior performance with respect to state-of-the-art methods. Our architecture can be trained in either a supervised or unsupervised manner, trading tracking accuracy for flexibility. The proposed system is tested on our own measurements, obtained with a 77 GHz radar on single and multiple subjects simultaneously moving in an indoor space. The results are compared against the ground truth trajectories from a motion tracking system, obtaining average tracking errors as low as 12 cm.","2375-5318","978-1-7281-8942-0","10.1109/RadarConf2043947.2020.9266400","MIUR (Italian Ministry of Education, University and Research)(grant numbers:232/2016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9266400","mm-wave radar;indoor sensing;human tracking;denoising autoencoders;sequence-to-sequence autoencoders","Target tracking;Spaceborne radar;Noise reduction;Neural networks;Radar tracking;Extraterrestrial measurements;Trajectory","Kalman filters;learning (artificial intelligence);millimetre wave radar;neural nets;nonlinear filters;object tracking;radar computing;radar signal processing","deep learning;accurate indoor human tracking;mm-wave radar;mm-wave radio signals;indoor environments;extended Kalman filter method;EKF;system evolution model;system states;original model-free tracking procedure;sequence-to-sequence neural networks;supervised manner;unsupervised manner;tracking accuracy;indoor space;long-term time dependencies;average tracking errors;motion tracking system;frequency 77.0 GHz","","","","18","","4 Dec 2020","","","IEEE","IEEE Conferences"
"Dynamic MRI using deep manifold self-learning","A. H. Ahmed; H. Aggarwal; P. Nagpal; M. Jacob","Department of Electrical and Computer Engineering, University of IOWA; Department of Electrical and Computer Engineering, University of IOWA; Department of Electrical and Computer Engineering, University of IOWA; Department of Electrical and Computer Engineering, University of IOWA","2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)","22 May 2020","2020","","","1052","1055","We propose a deep self-learning algorithm to learn the manifold structure of free-breathing and ungated cardiac data and to recover the cardiac CINE MRI from highly under-sampled measurements. Our method learns the manifold structure in the dynamic data from navigators using autoencoder network. The trained autoencoder is then used as a prior in the image reconstruction framework. We have tested the proposed method on free-breathing and ungated cardiac CINE data, which is acquired using a navigated golden-angle gradient-echo radial sequence. Results show the ability of our method to better capture the manifold structure, thus providing us reduced spatial and temporal blurring as compared to the SToRM reconstruction.","1945-8452","978-1-5386-9330-8","10.1109/ISBI45749.2020.9098382","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9098382","Cardiac MRI;denoising auto-enocoder;deep learning;image reconstruction","Magnetic resonance imaging;Storms;Image reconstruction;Navigation;Manifolds;Noise reduction;Data models","biomedical MRI;cardiology;image reconstruction;image sequences;learning (artificial intelligence);medical image processing","dynamic MRI;deep manifold self-learning;deep self-learning algorithm;ungated cardiac data;cardiac CINE MRI;under-sampled measurements;autoencoder network;trained autoencoder;image reconstruction framework;ungated cardiac CINE data;image reconstruction;golden-angle gradient-echo radial sequence","","5","","8","","22 May 2020","","","IEEE","IEEE Conferences"
"No-reference image quality assessment based on deep learning method","R. Yang; J. Su; W. Yu","Beijing Institute of Tracking and Telecommunication Technology, Beijing, China; Beijing Institute of Tracking and Telecommunication Technology, Beijing, China; Beijing Institute of Tracking and Telecommunication Technology, Beijing, China","2017 IEEE 3rd Information Technology and Mechatronics Engineering Conference (ITOEC)","30 Nov 2017","2017","","","476","479","In this work, we adopt the use of deep learning method for no-reference image quality assessment. With the development of deep neural networks technology, foundational and deep features of images could be captured without much prior knowledge. So a sparse autoencoder (SAE) was trained to express a 32 × 32 pixels image into a feature vector. Then the original images were cut into serial sub-images with the size of 32 × 32 pixels which can fix the input size of SAE. After that, the features vector of each sub-image was extracted separately and the information was fused with two strategies for the image quality assessment task. The best strategy in this work is that each sub-score is calculated by a Support Vector Regression (SVR) machine with the input of sub-image feature vector and estimate the image quality by averaging the scores to get the final score for the original image. Moreover, the effectiveness of our proposed method was confirmed by the experimental results in the TID2013 image quality assessment database.","","978-1-5090-5363-6","10.1109/ITOEC.2017.8122340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8122340","Deep learning;sparse autoencoder;no-reference image quality assessment (NF-IQA)","Image quality;Databases;Feature extraction;Distortion;Training;Machine learning;Neural networks","correlation methods;feature extraction;image denoising;learning (artificial intelligence);neural nets;regression analysis;support vector machines;visual databases","no-reference image quality assessment;deep learning method;deep neural networks technology;serial sub-images;image quality assessment task;sub-image feature vector;TID2013 image quality assessment database;support vector regression machine;SVR machine","","1","","13","","30 Nov 2017","","","IEEE","IEEE Conferences"
"Asymmetric Training of Generative Adversarial Network for High Fidelity SAR Image Generation","Y. Huang; W. Mei; S. Liu; T. Li","School of Software Engineering Chongqing University of Posts and Telecommunications, Chongqing, China; School of Software Engineering Chongqing University of Posts and Telecommunications, Chongqing, China; School of Software Engineering Chongqing University of Posts and Telecommunications, Chongqing, China; School of Software Engineering Chongqing University of Posts and Telecommunications, Chongqing, China","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","1576","1579","In practical application, the research of synthetic aperture radar (SAR) target recognition has fallen into a bottle-neck due to the lack of samples. Data argumentation methods based on generative adversarial networks (GAN) have received widespread attention in solving this type of few-shot sample problem. However, the generated images suffer from various shortcomings, such as lack of diversity, low signal-to-noise ratio, blur, etc. In this article, the VAE-WGANGP is proposed, which combines GAN and variational autoencoder (VAE) to alleviate these shortcomings. The innovations of this paper are as follows: firstly, the generator of GAN is replaced with VAE, which constructs an asymmetric network ensuring the stability of GAN training; secondly, the asymmetric loss function is composed of four parts, including reconstruction loss, divergence loss, adversarial loss, and gradient penalty. In this way, the problem of gradient explosion or gradient disappearance is alleviated. The experimental results with the MSTAR dataset show that the images generated by the proposed model outperform the advanced technology with many similar deep features and achieve significant improvement in the target recognition accuracy rate.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884284","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884284","Generative adversarial network (GAN);variational autoencoder (VAE);synthetic aperture radar (SAR);data augmentation;automatic target recognition (ATR)","Training;Technological innovation;Target recognition;Azimuth;Generative adversarial networks;Radar polarimetry;Stability analysis","image denoising;radar imaging;radar resolution;synthetic aperture radar","low signal-to-noise ratio;VAE-WGANGP;asymmetric network;GAN training;asymmetric loss function;adversarial loss;target recognition accuracy rate;asymmetric training;generative adversarial network;high fidelity SAR image generation;synthetic aperture radar target recognition;bottle-neck;data argumentation methods;few-shot sample problem","","","","8","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Seismic Noise Attenuation Using Unsupervised Sparse Feature Learning","M. Zhang; Y. Liu; M. Bai; Y. Chen","State Key Laboratory of Petroleum Resources and Prospecting, China University of Petroleum–Beijing, Beijing, China; School of Petroleum, China University of Petroleum–Beijing, Karamay, China; School of Earth Sciences, Zhejiang University, Hangzhou, China; School of Earth Sciences, Zhejiang University, Hangzhou, China","IEEE Transactions on Geoscience and Remote Sensing","22 Nov 2019","2019","57","12","9709","9723","Noise attenuation plays an important role in seismic data processing. We propose a novel denoising method for seismic data based on unsupervised sparse feature learning. Our goal is to obtain the identifiable feature of the noisy seismic data and then to represent the effective signals. By preprocessing the raw data and training the autoencoder neural network with sparse constraint, the sparse feature of the seismic data can be learned and stored in the neural network. We use the adaptive moment estimation as a backpropagation algorithm to minimize the cost function with a sparse penalty term and combine the dropout technique in the training process to improve the feature extraction and generalization capability of the neural network. Then, the test data set can be reconstructed by the most important sparse features. The final denoising result can be obtained by rearranging the output test data set. Compared with three commonly used state-of-the-art denoising methods, the proposed method performs well in applications to denoising for synthetic and real seismic data.","1558-0644","","10.1109/TGRS.2019.2928715","Important National Science & Technology Specific Project of China(grant numbers:2016ZX05047-002); Research Foundation of China University of Petroleum–Beijing at Karamay(grant numbers:RCYJ2018A-01-001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8789699","Noise attenuation;seismic data;sparse constraint;unsupervised feature learning","Neural networks;Attenuation;Noise reduction;Feature extraction;Transforms;Signal processing algorithms;Neurons","backpropagation;feature extraction;geophysical signal processing;geophysical techniques;learning (artificial intelligence);neural nets;seismology;signal denoising;unsupervised learning","seismic noise attenuation;unsupervised sparse feature learning;seismic data processing;identifiable feature;noisy seismic data;raw data;autoencoder neural network;sparse constraint;sparse penalty term;feature extraction;generalization capability;test data set;important sparse features;output test data;commonly used state-of-the-art denoising methods","","26","","87","IEEE","6 Aug 2019","","","IEEE","IEEE Journals"
"Learning structure in gene expression data using deep architectures, with an application to gene clustering","A. Gupta; H. Wang; M. Ganapathiraju","Language Technologies Institute School of Computer Science, Carnegie Mellon University, Pittsburgh, USA; Language Technologies Institute School of Computer Science, Carnegie Mellon University, Pittsburgh, USA; Department of Biomedical Informatics, University of Pittsburgh, Pittsburgh, USA","2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","17 Dec 2015","2015","","","1328","1335","Genes play a central role in all biological processes. DNA microarray technology has made it possible to study the expression behavior of thousands of genes in one go. Often, gene expression data is used to generate features for supervised and unsupervised learning tasks. At the same time, advances in the field of deep learning have made available a plethora of architectures. In this paper, we use deep architectures pre-trained in an unsupervised manner using denoising autoencoders as a preprocessing step for a popular unsupervised learning task. Denoising autoencoders (DA) can be used to learn a compact representation of input, and have been used to generate features for further supervised learning tasks. We propose that our deep architectures can be treated as empirical versions of Deep Belief Networks (DBNs). We use our deep architectures to regenerate gene expression time series data for two different data sets. We test our hypothesis on two popular datasets for the unsupervised learning task of clustering and find promising improvements in performance.","","978-1-4673-6799-8","10.1109/BIBM.2015.7359871","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7359871","gene expression;autoencoders;deep learning;gene clustering","Noise reduction","genetics;learning (artificial intelligence);neural nets;pattern clustering","learning structure;deep architectures;gene clustering;biological processes;DNA microarray technology;deep learning;denoising autoencoders;learning tasks;Deep Belief Networks;gene expression time series data","","34","","20","","17 Dec 2015","","","IEEE","IEEE Conferences"
"Pan-Sharpening Based on Multilevel Coupled Deep Network","W. Cai; Y. Xu; Z. Wu; H. Liu; L. Qian; Z. Wei","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Science, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","7046","7049","Pan-sharpening is a common image-fusion method. To improve the quality of fused images, a multilevel deep learning Pan-sharpening method is proposed in this paper. In the training phase, we introduce Coupled Sparse Denoising Autoencorder (CSDA) to reconstruct high-Resolution (HR) multispectral (MS) image from low-Resolution (LR) MS image and HR Panchromatic (Pan) image. CSDA has four networks including LM-HP network, HR-MS network, feature mapping network and fine-tuning network. The hidden features in LM-HP network and HR-MS network as well as the mapping function between the two features are learned through joint optimization. In LM-HP and HR-MS networks, the hidden features of image patch pairs are extracted by the sparse autoencoder. A sparse denoising autoencoder is used to build the nonlinear mapping between the extracted features. In the testing phase, the LR-MS and HR-Pan images patches are fed to the CSDA network to reconstruct the fused HR-MS image. The experimental results show that the proposed method is better than the traditional pans-sharpening methods.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518121","Pan-sharpening;deep learning;sparse autoencoder;multilevel coupled networks","Feature extraction;Image reconstruction;Training;Neural networks;Noise reduction;Testing","feature extraction;image fusion;image representation;image resolution;learning (artificial intelligence);neural nets","LM-HP network;HR-MS network;feature mapping network;fine-tuning network;CSDA network;HR panchromatic image;multilevel coupled deep network;image-fusion method;multilevel deep learning pan-sharpening method;coupled sparse denoising autoencoder;high-resolution multispectral image;low-resolution multispectral image;HR-pan images patches;HR-MS image reconstruction;LR-MS image reconstruction;image quality;feature extraction","","4","","9","","4 Nov 2018","","","IEEE","IEEE Conferences"
"Automated blood vessel segmentation based on de-noising auto-encoder and neural network","Z. Fan; J. -J. Mo","Department of Electronic Engineering, Shantou University, Shantou, China; Department of Electronic Engineering, Shantou University, Shantou, China","2016 International Conference on Machine Learning and Cybernetics (ICMLC)","9 Mar 2017","2016","2","","849","856","Retinal vessel segmentation has been widely used for screening, diagnosis and treatment of cardiovascular and ophthalmologic diseases. In this paper, we propose an automated approach for vessel segmentation in digital retinal images based on de-noising auto-encoders layer-wise initialized neural networks. The proposed method utilized a deep neural network, which is layer-wise initialized by de-noising auto-encoders and fine-tuned by BP algorithm, to segment vessel structures in retinal images. The proposed method is very competitive with the state-of-the-art methods. It achieves an average accuracy of 0.9612, 0.9614, 0.6761, sensitivity of 0.7814, 0.7234, 0.9702, and specificity of 0.9788, 0.9799, 0.9702 on 3 public databases DRIVE, STARE, and CHASE_DB1 respectively. The proposed method is promising for automated blood vessel segmentation.","2160-1348","978-1-5090-0390-7","10.1109/ICMLC.2016.7872998","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7872998","Vessel segmentation;Retinal images;Neural networks;Denoising auto-encoders","Retina;Image segmentation;Biological neural networks;Training;Databases;Neurons;Feature extraction","backpropagation;cardiovascular system;diseases;image denoising;medical image processing;neural nets","automated blood vessel segmentation;autoencoder denoising;retinal vessel segmentation;cardiovascular;ophthalmologic diseases;digital retinal images;deep neural networks;BP algorithm;public databases DRIVE;STARE","","6","1","18","","9 Mar 2017","","","IEEE","IEEE Conferences"
"Cyber Attack Detection Process in Sensor of DC Micro-Grids Under Electric Vehicle Based on Hilbert–Huang Transform and Deep Learning","H. Cui; X. Dong; H. Deng; M. Dehghani; K. Alsubhi; H. M. A. Aljahdali","College of Computer Science and Technology, China University of Petroleum, Qingdao, China; Department of Information Technology, Shengli College, China University of Petroleum, Dongying, China; Dongying District Power Supply Company, State Grid Corporation of China, Dongying, China; Software Energy Company, LLC, Detroit, MI, USA; Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia; Faculty of Computing and Information Technology in Rabigh, King Abdulaziz University, Jeddah, Saudi Arabia","IEEE Sensors Journal","15 Jul 2021","2021","21","14","15885","15894","In this article, a new procedure is proposed on the basis of Hilbert-Huang Transform and deep learning for cyber-attacks detection in direct current (DC) micro-grids (MGs) as well as detection of the attacks in distributed generation (DG) units and its sensors. An advanced elective group deep learning method with Krill Herd Optimization (KHO) algorithm is proposed. At first, Hilbert-Huang Transform is used with the aim of extracting the signals feature and next these features are applied as the multiple deep input basis models are made with the aim of capturing automatically sentient traits from raw fluctuation signals. At third, to make sure the variety of the basis patterns, linear decoder, denoising autoencoder and sparse autoencoder are applied to make various deep autoencoders, respectively. Further, Bootstrap is applied with the aim of designing separate educational data subsets for any base model. Fourth, for implementing selective ensemble learning, a combination strategy of enhanced weighted voting (EWV) with class-particular thresholds is studied. Eventually, KHO algorithm is applied with the aim of adaptive selecting the optimal class-specific thresholds. In the offered tactic, firstly, a DC micro-grid is functioned and controlled with the lack of any false data injection attacks (FDIAs) to collect adequate information within the usual operation needed for the educating of deep learning networks. It is noteworthy that, in the procedure of datum production, load variable is also determined with the aim of having distinctive datasets for cyber-attack scenarios and load variables. Also, to provide more realistic method, the smart plug-in electric vehicle is also considered in the model. Outcomes of Simulation in various scenarios are applied with the aim of verifying the benefit of the offered procedure. The outcomes propose that the offered procedure is able to more accurate and robust know various type of false data injection attack over than 93.76% accuracy detection of true rate.","1558-1748","","10.1109/JSEN.2020.3027778","National Natural Science Foundation of China(grant numbers:61262047); Dongying Key Laboratory of Intelligent Information Processing; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9208759","False data injection attack;Hilbert-Huang transform;dc micro-grid;deep learning;krill herd optimization;electric vehicle","Transforms;Machine learning;Sensors;Feature extraction;Electronic mail;Optimization;Voltage control","battery powered vehicles;deep learning (artificial intelligence);distributed power generation;Hilbert transforms;optimisation;power engineering computing;security of data","cyber attack detection process;DC microgrid;electric vehicle;Hilbert-Huang transform;cyber-attacks detection;direct current microgrids;distributed generation units;advanced elective group deep learning;Krill Herd Optimization algorithm;multiple deep input basis models;raw fluctuation signals;sparse autoencoder;deep autoencoders;ensemble learning;KHO algorithm;optimal class-specific thresholds;false data injection attack;deep learning networks;educational data subsets;denoising autoencoder;enhanced weighted voting;false data injection attacks","","10","","23","IEEE","29 Sep 2020","","","IEEE","IEEE Journals"
"Research on strategies to improve model accuracy based on incomplete time series data","W. Wang; L. Bi","School of Information engineering, Ningxia University, Yinchuan, China; School of Information engineering, Ningxia University, Yinchuan, China","2021 5th Asian Conference on Artificial Intelligence Technology (ACAIT)","14 Mar 2022","2021","","","45","52","Aiming at the problem of inaccurate model prediction caused by incomplete time series data, an improved denoising autoencoder was proposed to supplement missing data. Firstly, the convolutional neural network is added into the encoding and decoding of the denoising autoencoder for sequence analysis. The missing values are completed by making full use of the spatial correlation in the time series and used to build models. Secondly, real photovoltaic data are used to train and test the model. In the training process, instances with random missing values are used as the verification set, and the model with the best generalization ability is selected. Then, the performance of the training strategy against instances with missing values of different granularity is tested, which proves the generalization and robustness of the algorithm. Finally, under the unified standard, the model accuracy of this method is improved by 32.64% based on the original model, which verifies that the algorithm improves the model accuracy after data filling, and verifies the feasibility and efficiency of the proposed missing value filling algorithm. The data filling algorithm in this paper greatly improves the problem that the performance of the prediction model deteriorates due to data loss caused by various reasons in photovoltaic power stations.","","978-1-6654-2630-5","10.1109/ACAIT53529.2021.9731336","Ningxia University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9731336","Incomplete;Serial data;Improved denoising auto encoder;Policy padding;Model accuracy","Photovoltaic systems;Training;Analytical models;Machine learning algorithms;Time series analysis;Noise reduction;Predictive models","data analysis;learning (artificial intelligence);neural nets;photovoltaic power systems;time series","inaccurate model prediction;incomplete time series data;improved denoising autoencoder;missing data;convolutional neural network;photovoltaic data;training process;random missing values;training strategy;model accuracy;data filling;missing value filling algorithm;prediction model deteriorates;data loss","","","","30","IEEE","14 Mar 2022","","","IEEE","IEEE Conferences"
"Auto-Encoder with Neural Networks for Wind Speed Forecasting","H. Mezaache; H. Bouzgou","Dept. of Electronics, University of M’sila Lab. G.E. University of M’sila, M’sila, Algeria; Dept. of Industrial Engineering, University of Batna 2, Batna, Algeria","2018 International Conference on Communications and Electrical Engineering (ICCEE)","7 Feb 2019","2018","","","1","5","The use of wind energy is progressively utilized to produce electrical energy. Wind energy is related to the variation of some atmospheric variables such as wind direction, wind speed, air density and atmospheric pressure. Recently, numerous methods base on Artificial Intelligence techniques to forecast wind speed have been proposed in the literature. In this paper a new artificial intelligence approach for wind speed time series forecasting is proposed, it is composed from two blocs: The first one is based on the use of a deep architecture. The Autoencoder which is a type of deep neural networks, utilized generally for Denoising, is employed to reduce the wind speed input dimensionality. In the second bloc of the proposed methodology, the Elman neural network is employed to forecast future values of wind series, it is a kind of recurrent neural networks that are very sensitive to historical variations. To evaluate our approach we used the following error indicators: Root Mean Square Error (RMSE),Mean Absolute Bias Error (MABE), Mean Absolute Percentage Error (MAPE)and the coefficient of determination (R2). The obtained results are compared with those of the Extreme Learning Machine method.","","978-1-7281-0112-5","10.1109/CCEE.2018.8634551","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8634551","Deep neural networks;Autoencoder;Recurrent Neural Networks;Elman Neural Network;Extreme Learning Machine;Wind Speed;Time series","Wind speed;Time series analysis;Wind forecasting;Forecasting;Recurrent neural networks;Artificial neural networks","artificial intelligence;forecasting theory;learning (artificial intelligence);load forecasting;mean square error methods;power engineering computing;recurrent neural nets;time series;wind power plants","artificial intelligence approach;wind speed time series forecasting;Autoencoder;deep neural networks;wind speed input dimensionality;Elman neural network;wind series;recurrent neural networks;auto-encoder;wind energy;electrical energy;atmospheric variables;wind direction;atmospheric pressure;artificial intelligence techniques","","7","","15","","7 Feb 2019","","","IEEE","IEEE Conferences"
"Aeroengine Fault Diagnosis Method Based on Stack Denoising Auto-Encoders Network","X. Kong; G. Peng; X. Li; Z. Wang; X. Na","China Flight Test Establishment, Testing Technology Institute, Xi'an, China; China Flight Test Establishment, Testing Technology Institute, Xi'an, China; China Flight Test Establishment, Testing Technology Institute, Xi'an, China; China Flight Test Establishment, Testing Technology Institute, Xi'an, China; Power Machinery Institute, AVIC Xi'an Aircraft Industry Company LTD, Xi'an, China","2018 11th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","3 Feb 2019","2018","","","1","9","In the fault diagnosis domain for aero-engine, the data collected has the properties of high-dimension and nonlinear. Traditional pattern recognition method is difficult to learn the essential information of such data, which leads to the low fault diagnosis rate. Therefore, mining the feature reflecting aero-engine's condition from high-dimensional data is of great practical significance. To this end, a fault diagnosis algorithm using Stacked Denoising Auto-encoders(SDAE) for aero-engine is proposed in this paper. This method firstly map the high-dimensional data into low-dimensional features to extract feature by constructing SDAE from raw vibration signals of different conditions; Then a softmax regression model is used to verify the discriminability of the features. Finally, the validity of the method is verified by the experiments which show that the approach proposed is effective for aero-engine fault diagnosis.","","978-1-5386-7604-2","10.1109/CISP-BMEI.2018.8633128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8633128","fault diagnosis;neural network;stack auto-encoders;aero-engine","Feature extraction;Noise reduction;Fault diagnosis;Training;Encoding;Data models;Biological neural networks","aerospace engines;data mining;fault diagnosis;feature extraction;learning (artificial intelligence);neural nets;regression analysis;vibrational signal processing","aeroengine fault diagnosis;pattern recognition;stacked denoising autoencoders;feature mining;aeroengine condition;data mining;feature extraction;vibration signals;softmax regression model;fault diagnosis algorithm","","2","","15","","3 Feb 2019","","","IEEE","IEEE Conferences"
"Enhanced Denoising Auto-Encoder for Robust Speech Recognition in Unseen Noise Conditions","S. Joshi; A. Panda; B. Das","TCS Innovation Lab-Mumbai, Yantra Park, Thane, Maharashtra, India; TCS Innovation Lab-Mumbai, Yantra Park, Thane, Maharashtra, India; TCS Innovation Lab-Mumbai, Yantra Park, Thane, Maharashtra, India","2018 11th International Symposium on Chinese Spoken Language Processing (ISCSLP)","6 May 2019","2018","","","359","363","We present a robust front-end processing method for speech recognition in unseen noise conditions. Towards this end, we have investigated the efficacy of a Time Delay Neural Network based Denoising Auto-Encoder (TDNN-DAE) in seen and unseen noise conditions. We show that while the TDNN-DAE succeeds in improving the performance of the speech recognition by a large margin in seen noise conditions (noise encountered during decoding was used in the training of the TDNN-DAE), it fails to improve the performance in unseen noise conditions (noise encountered during decoding was not used in the training of the TDNN-DAE). To address this, we propose to pre-process the training input to the TDNN-DAE using an enhancement technique. In essence, the TDNN-DAE is being trained to address the residual noise left behind by the enhancement technique. For this task, we compare the performance of two enhancement techniques, namely Vector Taylor Series with Acoustic Masking (VTS-AM) and Spectral Subtraction (SS). We show that both these enhancement techniques improve the efficacy of the TDNN-DAE significantly in unseen noise conditions and that the VTS-AM enhanced TDNN-DAE outperforms the SS enhanced TDNN-DAE.","","978-1-5386-5627-3","10.1109/ISCSLP.2018.8706697","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8706697","speech recognition;noise robustness;front-end processing","Noise measurement;Signal to noise ratio;Training;Speech recognition;Feature extraction;Computer architecture;Acoustics","learning (artificial intelligence);neural nets;series (mathematics);speech coding;speech enhancement;speech recognition;vectors","unseen noise conditions;VTS-AM enhanced TDNN-DAE;robust speech recognition;robust front-end processing method;time delay neural network based denoising autoencoder enhancement technique;decoding;vector taylor series with acoustic masking;spectral subtraction;SS","","1","","27","","6 May 2019","","","IEEE","IEEE Conferences"
"Stock Selection via Expand-excite Conv Attention Autoencoder and Layer Sparse Attention Transformer: A Classification Approach Inspire Time Series Sequence Recognition","W. Fu; J. Sun; Y. Jiang","Tsinghua-Berkeley Shenzhen Institute Tsinghua University, Shenzhen, China; Tsinghua-Berkeley Shenzhen Institute Tsinghua University, Shenzhen, China; Tsinghua-Berkeley Shenzhen Institute Tsinghua University, Shenzhen, China","2022 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2022","2022","","","1","7","It is a very complicated task to quantify stock fluctuations and use them to generate profits. Despite the rapid progress in Deep Learning, the effect in predicting stock markets with high randomness and high noise is still not good. Therefore, how to filter out the noise in the stock market is very important for stock price prediction. In the past, we usually used feature engineering to denoise the original stock data. However, with the advent of Deep Learning, neural networks can now automatically perform feature engineering. The question of how to design a reasonable neural network for highly noisy data and perform effective signal extraction is therefore the problem we discuss in this paper. The main novelty of our work is that we transform the stock prediction problem into a classification problem in a time period. Through the layer-by-layer transformation, the model pays attention to different levels of detail each time to achieve automatic construction of different levels. The purpose of the feature is that the model can recognize more valuable information. On this basis, this article proposes the model TS-ECLST. TS-ECLST is the abbreviation of Time Series Expand-excite Conv Attention Autoencoder Layer Sparse Attention Transformer. Using experiments on two markets with six years of data, we show that the TS-ECLST model is better than the current mainstream model and even better than the latest graph neural model in terms of profitability. We also investigate the importance of the layer-transformer structure by ablation. The results show that this hierarchical attention structure is indeed better than the non-hierarchical structure and it is also better than various models based on LSTM or transformer.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9891876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9891876","time-series;classification;autoencoder;convolutional;transformer;sparse attention","Deep learning;Profitability;Neural networks;Time series analysis;Transforms;Transformers;Data models","","","","","","41","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"CellStory: Extendable Cellular Signals-Based Floor Estimator Using Deep Learning","A. Saeed; A. Wasfey; H. Rizk; H. Yamaguchi","Faculty of Engineering, Tanta University, Egypt; Faculty of Engineering, Tanta University, Egypt; Graduate School of Information Science and Technology, Osaka University, Japan; Graduate School of Information Science and Technology, Osaka University, Japan","2022 18th International Conference on Intelligent Environments (IE)","15 Jul 2022","2022","","","1","4","As the demand for location-based services increases, several research efforts have aimed for robust and accurate indoor localization, especially 3D localization. Due to the widespread availability of cellular networks and their support by commodity cellphones, cellular-based systems have recently been proposed as a means of achieving this. However, because of the inherent noise and instability of wireless signals, localization accuracy typically degrades and is not robust to the dynamic heterogeneity of mobile devices.In this paper, we present a CellStory, a deep learning-based floor estimation system that achieves a fine-grained and robust accuracy in the presence of noise. CellStory combines stacked denoising autoencoder learning models, and a probabilistic framework to handle noise in the received signal and capture the complex relationship between the signals detected by the mobile phone and its location. Evaluation using different Android phones in a real testbed shows that CellStory can accurately estimate the user’s floor 98.7% of the time and within one floor error 100% of the time. This accuracy demonstrates CellStory’s superiority over state-of-the-art systems as well as its robustness to heterogeneous devices.","2472-7571","978-1-6654-6934-0","10.1109/IE54923.2022.9826773","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9826773","Cellular localization;2.5D localization;indoor localization;deep learning;fingerprinting","Location awareness;Deep learning;Wireless communication;Three-dimensional displays;Buildings;Noise reduction;Probabilistic logic","cellular radio;image denoising;indoor communication;indoor radio;learning (artificial intelligence);mobile computing;signal denoising;smart phones","user;floor error;CellStory's superiority;extendable cellular signals-based floor estimator;location-based services increases;robust indoor localization;accurate indoor localization;widespread availability;cellular networks;commodity cellphones;cellular-based systems;inherent noise;wireless signals;localization accuracy;mobile devices;deep learning-based floor estimation system;fine-grained accuracy;robust accuracy;autoencoder learning models;received signal;mobile phone","","","","20","IEEE","15 Jul 2022","","","IEEE","IEEE Conferences"
"FUS-Net: U-Net-Based FUS Interference Filtering","S. A. Lee; E. E. Konofagou","Department of Biomedical Engineering, Columbia University, New York, NY, USA; Department of Biomedical Engineering, Columbia University, New York, NY, USA","IEEE Transactions on Medical Imaging","1 Apr 2022","2022","41","4","915","924","Imaging applications tailored towards ultrasound-based treatment, such as high intensity focused ultrasound (FUS), where higher power ultrasound generates a radiation force for ultrasound elasticity imaging or therapeutics/theranostics, are affected by interference from FUS. The artifact becomes more pronounced with intensity and power. To overcome this limitation, we propose FUS-net, a method that incorporates a CNN-based U-net autoencoder trained end-to-end on ’clean’ and ’corrupted’ RF data in Tensorflow 2.3 for FUS artifact removal. The network learns the representation of RF data and FUS artifacts in latent space so that the output of corrupted RF input is clean RF data. We find that FUS-net perform 15% better than stacked autoencoders (SAE) on evaluated test datasets. B-mode images beamformed from FUS-net RF shows superior speckle quality and better contrast-to-noise (CNR) than both notch-filtered and adaptive least means squares filtered RF data. Furthermore, FUS-net filtered images had lower errors and higher similarity to clean images collected from unseen scans at all pressure levels. Lastly, FUS-net RF can be used with existing cross-correlation speckle-tracking algorithms to generate displacement maps. FUS-net currently outperforms conventional filtering and SAEs for removing high pressure FUS interference from RF data, and hence may be applicable to all FUS-based imaging and therapeutic methods.","1558-254X","","10.1109/TMI.2021.3128641","National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health(grant numbers:R01EB027576); Defense Advanced Research Projects Agency (DARPA) Biological Technologies Office (BTO) Electrical Prescriptions (ElectRx)(grant numbers:HR0011-15-2-0054); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9617613","Autoencoder;CNN;deep learning;elastography;filtering;FUS;HIFU artifact;theranostics;therapeutics;U-Net","Radio frequency;Interference;Imaging;Ultrasonic imaging;Transducers;Power harmonic filters;Image reconstruction","biomedical ultrasonics;elasticity;filtering theory;image denoising;learning (artificial intelligence);medical image processing;speckle;ultrasonic imaging","ultrasound-based treatment;ultrasound elasticity imaging;CNN-based U-net autoencoder;RF data;FUS artifact removal;FUS artifacts;FUS-net RF;FUS-based imaging;high-pressure FUS interference","Algorithms;Artifacts;Ultrasonography","","","22","IEEE","16 Nov 2021","","","IEEE","IEEE Journals"
"AutLoc: Deep Autoencoder for Indoor Localization with RSS Fingerprinting","J. Liu; N. Liu; Z. Pan; X. You","National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China","2018 10th International Conference on Wireless Communications and Signal Processing (WCSP)","2 Dec 2018","2018","","","1","6","Wi-Fi based indoor localization has attracted great interest due to its ubiquitous access in many indoor environments. However, the accuracy is deteriorated by the complex indoor propagation environments, which result in variable received signal strength (RSS). In this paper, we propose to utilize an autoencoder to improve the accuracy of indoor localization by preprocessing the noisy RSS. The AutLoc system includes an offline training phase and an online localization phase. In the offline training phase, we train the deep autoencoder to denoise the measured data and then build the RSS fingerprints according to the trained weights. In the online localization phase, we adopt three machine learning algorithms, which are random forest regression, multi-player perceptron classification and multi-player perceptron regression, to estimate the location. Averaging over the results of three algorithms, we then obtain the final estimated location. Simulation results justify superiority of the proposed AutLoc system over previous indoor location schemes in vast scenarios.","2472-7628","978-1-5386-6119-2","10.1109/WCSP.2018.8555665","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8555665","WLAN;indoor localization;fingerprinting;auto-encoder;RSS;noise reduction","Training;Noise measurement;Decoding;Prediction algorithms;Forestry;Estimation;Machine learning algorithms","encoding;indoor radio;learning (artificial intelligence);mobile radio;radiowave propagation;regression analysis;RSSI;wireless LAN","deep autoencoder;RSS fingerprinting;complex indoor propagation environments;noisy RSS;AutLoc system;offline training phase;online localization phase;RSS fingerprints;Wi-Fi based indoor localization;received signal strength;indoor location schemes;machine learning algorithms;random forest regression;multiplayer perceptron classification;multiplayer perceptron regression","","5","","21","","2 Dec 2018","","","IEEE","IEEE Conferences"
"Improving Generative Modelling in VAEs Using Multimodal Prior","V. Abrol; P. Sharma; A. Patra","Mathematical Institute, University of Oxford, Oxford, U.K.; Department of Engineering Science, University of Oxford, Oxford, U.K.; Department of Engineering Science, University of Oxford, Oxford, U.K.","IEEE Transactions on Multimedia","25 Jun 2021","2021","23","","2153","2161","In this paper we propose a conditional generative modelling (CGM) approach for unsupervised disentangled representation learning using variational autoencoder (VAE). CGM employs a multimodal/categorical conditional prior distribution in the latent space to learn global uncertainty in data by modelling the variations at local level. Thus, the proposed framework enforces the model to independently estimate the inherent patterns within each category, which improves the interpretability of the latent representations learned by the VAE model. The evidence lower bound objective for training the generative model is maximized using a mutual information criterion between the global latent categorical variable and the encoded inputs. Further, the approach has a built-in mechanism for bounding the information flow between the encoder and the decoder which addresses the problems of posterior collapse in conventional VAE models. Experiments on a variety of datasets demonstrate that our objective can learn disentangled representations and the proposed approach achieves competitive results on various task such as generative modelling, image classification and image denoising.","1941-0077","","10.1109/TMM.2020.3008053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9136917","Generative modelling;autoencoders;matching network;representation learning","Object oriented modeling;Training;Mutual information;Decoding;Kernel;Data models;Uncertainty","data handling;image classification;image denoising;image representation;learning (artificial intelligence);neural net architecture;unsupervised learning","CGM;unsupervised disentangled representation;variational autoencoder;conditional prior distribution;latent space;latent representations;conventional VAE models;conditional generative modelling","","2","","56","IEEE","8 Jul 2020","","","IEEE","IEEE Journals"
"Consensus Subspace Clustering","N. Thom; H. Nguyen; E. M. Hand","Computer Science and Engineering, University of Nevada, Reno, Reno, USA; Computer Science and Engineering, University of Nevada, Reno, Reno, USA; Computer Science and Engineering, University of Nevada, Reno, Reno, USA","2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)","21 Dec 2021","2021","","","391","395","One significant challenge in the field of supervised deep learning is the lack of large-scale labeled datasets for many problems. In this paper, we propose Consensus Spectral Clustering (CSC), which leverages the strengths of convolutional autoencoders and spectral clustering to provide pseudo labels for image data. This data can be used as weakly-labeled data for training and evaluating classifiers which require supervision. The primary weaknesses of previous works lies in their inability to isolate the object of interest in an image and cluster similar images together. We address these issues by denoising input images to remove pixels which do not contain data pertinent to the target. Additionally, we introduce a voting method for label selection to improve the clustering results. Our extensive experimentation on several benchmark datasets demonstrates that the proposed CSC method achieves competitive performance with state-of-the-art methods.","2375-0197","978-1-6654-0898-1","10.1109/ICTAI52525.2021.00064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9643334","Cluster;Image;Autoencoder;Pseudo label","Training;Deep learning;Conferences;Clustering methods;Noise reduction;Area measurement;Data visualization","image classification;image denoising;learning (artificial intelligence);pattern classification;pattern clustering;video signal processing","Consensus subspace;supervised deep learning;large-scale labeled datasets;Consensus Spectral Clustering;convolutional autoencoders;pseudolabels;image data;weakly-labeled data;evaluating classifiers;primary weaknesses;previous works lies;cluster similar images;input images;label selection;benchmark datasets;CSC method","","","","29","IEEE","21 Dec 2021","","","IEEE","IEEE Conferences"
"DCCR: Deep Collaborative Conjunctive Recommender for Rating Prediction","Q. Wang; B. Peng; X. Shi; T. Shang; M. Shang","School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; Chongqing Key Laboratory of Big Data and Intelligent Computing, Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences, Chongqing, China; Chongqing Key Laboratory of Big Data and Intelligent Computing, Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences, Chongqing, China; College of Computer Science, Sichuan University, Chengdu, China; Chongqing Key Laboratory of Big Data and Intelligent Computing, Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences, Chongqing, China","IEEE Access","17 May 2019","2019","7","","60186","60198","Recently, collaborative filtering combined with various kinds of deep learning models is appealing to recommender systems, which have shown a strong positive effect in an accuracy improvement. However, many studies related to deep learning model rely heavily on abundant information to improve prediction accuracy, which has stringent data requirements in addition to raw rating data. Furthermore, most of them ignore the interaction effect between users and items when building the recommendation model. To address these issues, we propose DCCR, a deep collaborative conjunctive recommender, for rating prediction tasks that are solely based on the raw ratings. A DCCR is a hybrid architecture that consists of two different kinds of neural network models (i.e., an autoencoder and a multilayered perceptron). The main function of the autoencoder is to extract the latent features from the perspectives of users and items in parallel, while the multilayered perceptron is used to represent the interaction between users and items based on fusing the user and item latent features. To further improve the performance of DCCR, an advanced activation function is proposed, which can be specified with input vectors. The extensive experiments conducted with two well-known real-world datasets and performances of the DCCR with varying settings are analyzed. The results demonstrate that our DCCR model outperforms other state-of-art methods. We also discuss the performance of the DCCR with additional layers to show the extensibility of our model.","2169-3536","","10.1109/ACCESS.2019.2915531","National Natural Science Foundation of China(grant numbers:61872065,91646114,61602434); Chongqing Science Technology Bureau(grant numbers:cstc2017zdcy-zdyfX0076,cstc2018jszx-cyztzxX0025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8709799","Recommender systems;collaborative filtering;rating prediction;denoising autoencoders;multi layered perceptron","Feature extraction;Neural networks;Task analysis;Deep learning;Predictive models;Collaboration;Recommender systems","collaborative filtering;feature extraction;learning (artificial intelligence);multilayer perceptrons;recommender systems;transfer functions","deep collaborative conjunctive recommender;collaborative filtering;deep learning model;stringent data requirements;raw rating data;rating prediction tasks;neural network models;multilayered perceptron;item latent features;DCCR model;user latent features;autoencoder;activation function","","16","","35","OAPA","8 May 2019","","","IEEE","IEEE Journals"
"MIMO Radar Aided mmWave Time-Varying Channel Estimation in MU-MIMO V2X Communications","S. Huang; M. Zhang; Y. Gao; Z. Feng","Key Laboratory of Universal Wireless Communications, Ministry of Education, Wireless Technology Innovation Institute (WTI), Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Department of Computing, Imperial College London, London, U.K.; Key Laboratory of Universal Wireless Communications, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Transactions on Wireless Communications","10 Nov 2021","2021","20","11","7581","7594","Robust channel estimation in time-varying channels is used to guarantee the quality of communication services, especially for Vehicle-to-Everything (V2X) scenarios. To improve the channel estimation accuracy and reduce the pilot overhead, multi-input multi-output (MIMO) radar is deployed to assist millimeter wave (mmWave) channel estimation. In this paper, we propose a MIMO radar aided channel estimation scheme using deep learning (DL) for the uplink mmWave multiuser (MU)-MIMO communications. To allocate pilot resources reasonably, we design a transmission frame structure of joint radar module and communication module, which divides the estimation scheme into two stages, i.e., the arrival/departure (AoA/AoDs) estimation stage and the gain estimation stage. In view of the imperfections of array elements in practice, we propose an AoA/AoDs estimation algorithm based on subspace reconstruction in the AoA/AoDs estimation stage named two-step angle estimation (TSAE) algorithm. In the gain estimation stage, a DL based channel gain estimator is designed. An autoencoder combined with residual structure named residual denoising autoencoder (RDAE) is proposed to eliminate the noise on wireless signals, which is passed into the least square (LS) estimation module to obtain gains. Simulation results demonstrate that the MIMO radar aided and DL-based channel estimator provides the efficient estimation performance of the high-mobility mmWave channel with fewer training resources.","1558-2248","","10.1109/TWC.2021.3085823","National Natural Science Foundation of China(grant numbers:61941102); National Key Research and Development Program of China(grant numbers:2020YFB1807602,2019YFB1804404); Beijing Natural Science Foundation(grant numbers:19L2022,4202046); Industrial Internet Innovation and Development Project of Ministry of Industry and Information Technology(grant numbers:TC200H031); Key Laboratory of Universal Wireless Communications (Beijing University of Posts and Telecommunications), Ministry of Education, China(grant numbers:KFKT-2020105); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9449980","Deep learning (DL);millimeter wave (mmWave) communications;multiuser multi-input multi-output (MU-MIMO);MIMO radar;vehicle-to-everything (V2X)","Estimation;Channel estimation;MIMO radar;Wireless communication;Training;Radio frequency;Radar antennas","channel estimation;deep learning (artificial intelligence);direction-of-arrival estimation;estimation theory;least squares approximations;millimetre wave communication;millimetre wave radar;MIMO communication;MIMO radar;multiuser channels;signal denoising;telecommunication computing;time-varying channels;vehicular ad hoc networks","time-varying channel estimation;MU-MIMO V2X Communications;robust channel estimation;time-varying channels;communication services;Vehicle-to-Everything scenarios;channel estimation accuracy;multiinput multioutput radar;MIMO radar aided channel estimation scheme;deep learning;joint radar module;communication module;gain estimation stage;two-step angle estimation algorithm;DL based channel gain estimator;square estimation module;high-mobility mmWave channel;uplink mmWave multiuser-MIMO communications;subspace reconstruction;TSAE;residual structure;residual denoising autoencoder;RDAE;wireless signals;least square estimation module;MIMO radar aided channel estimator","","","","50","CCBY","9 Jun 2021","","","IEEE","IEEE Journals"
"Algorithm to Estimate Scalloping & Banding in Scansar Images and Deep Learning Based Descalloping Technique","N. Saxena; M. Gupta; J. T. Patel","Information Technology department, L.D. College of Engineering, Ahmedabad, Gujarat, India; Space Applications Centre, ISRO, Ahmedabad, Gujarat, India; Information Technology department, L.D. College of Engineering, Ahmedabad, Gujarat, India","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","393","396","An algorithm is designed and implemented to estimate the scalloping or banding effects in wide swath ScanSAR images and an Autoencoder based deep learning method is attempted to remove the scalloping from the images which is an independent method and do not use SAR imaging parameters. Various SAR images are analysed to demonstrate the effectiveness of the proposed method. We have used both simulations and the Radar Imaging Satellite (RISAT-1) SAR image for computing the depth of scalloping. The estimation is based using periodic variation (inherent pattern of ScanSAR because of scan mechanism and SAR processing) of Scalloping/Banding noise present in ScanSAR images. The estimated depth of scalloping from the simulated dataset is observed around 4.50 dB & 7.11 dB whereas in RISAT-1 SAR data (uncorrected) acquired over the Amazon Rainforest in HH and HV image is 7.29 dB & 8.42 dB respectively. The deep learning-based technique is proposed to remove scalloping and interscan banding noise from an image, especially SAR images. For developing deep learning-based image denoising solution, large-scale training dataset is required, here we propose scalloping dataset. We had simulated 19,125 images with different scalloping noises for training and testing of our Autoencoder neural network model. We have used many images to evaluate the performance of our neural network model. These include some simulated images and original RISAT-1 image. Experiments on RISAT-1 and simulated images shows good performance of our proposed method which can further be improved utilizing realistic datasets.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9883518","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9883518","ScanSAR;deep learning;neural networks;scalloping;inter-scan banding;noise","Training;Deep learning;Satellites;Neural networks;Estimation;Training data;Radar imaging","deep learning (artificial intelligence);image denoising;radar computing;radar imaging;synthetic aperture radar","original RISAT-1 image;banding effects;wide swath ScanSAR images;independent method;SAR imaging parameters;Radar Imaging Satellite SAR image;SAR processing;simulated dataset;RISAT-1 SAR data;deep learning-based technique;interscan banding noise;deep learning-based image denoising solution;scalloping dataset;scalloping noises;Autoencoder based deep learning method","","","","9","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Marginalized Multiview Ensemble Clustering","Z. Tao; H. Liu; S. Li; Z. Ding; Y. Fu","Department of Electrical and Computer Engineering, Northeastern University, Boston, USA; Michtom School of Computer Science, Brandeis University, Waltham, USA; Department of Computer Science, University of Georgia, Athens, USA; Department of Computer, Information and Technology, Indiana University-Purdue University Indianapolis, Indianapolis, USA; Khoury College of Computer and Information Sciences, Northeastern University, Boston, USA","IEEE Transactions on Neural Networks and Learning Systems","6 Feb 2020","2020","31","2","600","611","Multiview clustering (MVC), which aims to explore the underlying cluster structure shared by multiview data, has drawn more research efforts in recent years. To exploit the complementary information among multiple views, existing methods mainly learn a common latent subspace or develop a certain loss across different views, while ignoring the higher level information such as basic partitions (BPs) generated by the single-view clustering algorithm. In light of this, we propose a novel marginalized multiview ensemble clustering (M2VEC) method in this paper. Specifically, we solve MVC in an EC way, which generates BPs for each view individually and seeks for a consensus one. By this means, we naturally leverage the complementary information of multiview data upon the same partition space. In order to boost the robustness of our approach, the marginalized denoising process is adopted to mimic the data corruptions and noises, which provides robust partition-level representations for each view by training a single-layer autoencoder. A low-rank and sparse decomposition is seamlessly incorporated into the denoising process to explicitly capture the consistency information and meanwhile compensate the distinctness between heterogeneous features. Spectral consensus graph partitioning is also involved by our model to make M2VEC as a unified optimization framework. Moreover, a multilayer M2VEC is eventually delivered in a stacked fashion to encapsulate nonlinearity into partition-level representations for handling complex data. Experimental results on eight real-world data sets show the efficacy of our approach compared with several state-of-the-art multiview and EC methods. We also showcase our method performs well with partial multiview data.","2162-2388","","10.1109/TNNLS.2019.2906867","Office of the Director(grant numbers:1651902); Army Research Office(grant numbers:W911NF-17-1-0367); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691702","Multiview clustering;ensemble clustering;low-rank representation;auto-encoders","Noise reduction;Nonhomogeneous media;Task analysis;Optimization;Sparse matrices;Clustering algorithms;Transforms","feature extraction;graph theory;image denoising;image representation;learning (artificial intelligence);neural nets;optimisation;pattern clustering","BPs;marginalized denoising process;data corruptions;robust partition-level representations;spectral consensus graph partitioning;partial multiview data;marginalized multiview ensemble clustering;MVC;basic partitions;single-view clustering algorithm;M2VEC method;single-layer autoencoder;unified optimization framework","","18","","66","IEEE","14 Apr 2019","","","IEEE","IEEE Journals"
"Exploiting the Reactive Power in Deep Neural Models for Non-Intrusive Load Monitoring","M. Valenti; R. Bonfigli; E. Principi; a. S. Squartini","Department of Information Engineering, Universitá Politecnica delle Marche Via Brecce Bianche, Ancona, Italy; Department of Information Engineering, Universitá Politecnica delle Marche Via Brecce Bianche, Ancona, Italy; Department of Information Engineering, Universitá Politecnica delle Marche Via Brecce Bianche, Ancona, Italy; Department of Information Engineering, Universitá Politecnica delle Marche Via Brecce Bianche, Ancona, Italy","2018 International Joint Conference on Neural Networks (IJCNN)","14 Oct 2018","2018","","","1","8","Non-intrusive load monitoring (NILM) is defined as the task of retrieving the active power consumption of two or more appliances from information gathered at a single metering point. In this work, the use of the reactive aggregate power as an additional feature to the commonly used active power for deep neural models is proposed. The NILM problem is formulated as a denoising problem, and denoising autoencoder (dAE) neural architectures are used to estimate the appliances individual active power consumption. The proposed approach is evaluated on two public datasets: the Almanac of Minutely Power dataset (AMPds) and the UK Domestic Appliance-Level Electricity (UK-DALE) dataset. In order to better evaluate the generalization capabilities of the algorithm, different testing conditions are considered for the UK-DALE dataset, namely a seen and an unseen scenario. The results show that introducing the reactive power can indeed bring and overall performance increase in all scenarios, ranging from +4.9% to +8.4% of the energy-based F1 score.","2161-4407","978-1-5090-6014-6","10.1109/IJCNN.2018.8489271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489271","Non-intrusive load monitoring;convolutional autoencoder;load disaggregation;reactive power","Reactive power;Training;Aggregates;Noise reduction;Hidden Markov models;Convolution;Microsoft Windows","domestic appliances;load management;neural net architecture;power consumption;power engineering computing;reactive power","deep neural models;NILM problem;UK Domestic Appliance-Level Electricity dataset;UK-DALE dataset;reactive power;nonintrusive load monitoring;reactive aggregate power;individual active power consumption;Almanac of Minutely Power dataset;metering point;denoising autoencoder neural architectures","","11","","41","","14 Oct 2018","","","IEEE","IEEE Conferences"
"An introduction to deep learning","F. Q. Lauzon","Ecole de Technologie Supérieure, Laboratoire de vision et d'intelligence artificielle","2012 11th International Conference on Information Science, Signal Processing and their Applications (ISSPA)","24 Sep 2012","2012","","","1438","1439","Deep learning allows automatically learning multiple levels of representations of the underlying distribution of the data to be modeled. In this work, a specific implementation called stacked denoising autoencoders is explored. We contribute by demonstrating that this kind of representation coupled to a SVM improves classification error on MNIST over the usual deep learning approach where a logistic regression layer is added to the stack of denoising autoencoders.","","978-1-4673-0382-8","10.1109/ISSPA.2012.6310529","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6310529","","Training;Support vector machines;Logistics;Machine learning;Noise reduction;Decoding;Classification algorithms","learning (artificial intelligence);regression analysis;support vector machines","data distribution;stacked denoising autoencoders;SVM;classification error;MNIST;deep learning approach;logistic regression layer","","36","","4","","24 Sep 2012","","","IEEE","IEEE Conferences"
"Hybrid Neural Network mixed with Random Forests and Perlin noise","Mengfei Wang; Fengqin Zhang; Hua Guan; Xiaoqing Li; Guirong Chen; Tengyao Li; Xi Xi","Information and Navigation College, Air Force Engineering University, Xi'an, China; Information and Navigation College, Air Force Engineering University, Xi'an, China; Information and Navigation College, Air Force Engineering University, Xi'an, China; Information and Navigation College, Air Force Engineering University, Xi'an, China; Information and Navigation College, Air Force Engineering University, Xi'an, China; Information and Navigation College, Air Force Engineering University, Xi'an, China; Information and Navigation College, Air Force Engineering University, Xi'an, China","2016 2nd IEEE International Conference on Computer and Communications (ICCC)","11 May 2017","2016","","","1937","1941","Data mixed up with discrete and continuous features makes negative affect to the classification for existing models which discretizes the continuous features or even without any treatment is not able to deal with it. The noise which is not subject to Gaussian distribution also severely affected the result of classification. In this paper, a deep neural network mixed with random forests, Stacked Denoising Autoencoder and Multilayer Perception is proposed to improve the classification effect of mixed features input. Furthermore, to improve pre-training effect of the Stacked Denoising Autoencoder, Perlin noise is added to the Gaussian Noise in noise layer. A certain promotion of this method has been proved through the experiments with the crime data between 2003 and 2015 in San Francisco, and comparisons by 10-fold cross-validation with other common methods of classification shows that this method has advantages on data mixed up with discrete and continuous features.","","978-1-4673-9026-2","10.1109/CompComm.2016.7925039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7925039","hybrid neural network;perlin noise;SDA;deep learning","Noise reduction;Gold;Neural networks;Optimization","feature extraction;Gaussian distribution;Gaussian noise;multilayer perceptrons;pattern classification","hybrid neural network;random forests;Perlin noise;continuous features;discrete features;Gaussian distribution;deep neural network;stacked denoising autoencoder;multilayer perception;Gaussian noise;San Francisco;10-fold cross-validation","","","","9","","11 May 2017","","","IEEE","IEEE Conferences"
"Generating feature sets for fault diagnosis using denoising stacked auto-encoder","R. Thirukovalluru; S. Dixit; R. K. Sevakula; N. K. Verma; A. Salour","Department of Electrical Engineering, IIT Kanpur, India; Department of Electrical Engineering, IIT Kanpur, India; Department of Electrical Engineering, IIT Kanpur, India; Department of Electrical Engineering, IIT Kanpur, India; Department of Electrical Engineering, IIT Kanpur, India","2016 IEEE International Conference on Prognostics and Health Management (ICPHM)","15 Aug 2016","2016","","","1","7","Recent advancements in sensor technologies and data driven model based techniques have made intelligent diagnostic systems prominent in machine maintenance frameworks of industries. The performance of such systems immensely relies upon the quality of features extracted and the classifier model learned. Traditionally features were handcrafted, where engineers would manually design them with statistical parameters and signal transforms based energy distribution analysis. Recently, deep learning techniques have shown new ways of obtaining useful feature representation that provide state of the art results in image and speech processing applications. This paper first presents a brief survey of traditional handcrafted features and later presents a short analysis of handcrafted features v/s features learned by deep neural networks (DNN), for doing fault diagnosis. The DNN based features in this paper were generated in 3 phases: 1) extracted handcrafted features using traditional techniques 2) initialized the weights of DNN by learning de-noising sparse auto-encoders with the handcrafted features in unsupervised fashion and 3) applied two generic fine tuning heuristics that tailor DNN's weights to give good classification performance. The experimentation and analysis were performed on 5 datasets: one each on Air compressor monitoring, Drill bit monitoring and Steel plate monitoring, and two on bearing fault monitoring data. The results clearly show the prospects of DNN obtaining good feature representations and good classification performance. Further, it also finds that Fast Fourier Transform based features with DNN are more suited for Support Vector Machine as classifier than Random Forest.","","978-1-5090-0382-2","10.1109/ICPHM.2016.7542865","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7542865","deep learning;stacked auto-encoders;fault diagnosis;features analysis","Feature extraction;Fault diagnosis;Monitoring;Time-frequency analysis;Training;Transforms;Vibrations","compressors;condition monitoring;drilling machines;fast Fourier transforms;fault diagnosis;feature extraction;machine bearings;mechanical engineering computing;neural nets;pattern classification;plates (structures);set theory;support vector machines;unsupervised learning","fault diagnosis;denoising stacked autoencoder;feature sets;sensor technologies;data driven model based techniques;intelligent diagnostic systems;machine maintenance;classifier model;deep learning techniques;image processing applications;speech processing applications;deep neural networks;DNN based features;handcrafted feature extraction;unsupervised techniques;air compressor monitoring;drill bit monitoring;steel plate monitoring;bearing fault monitoring data;feature representations;fast Fourier transform based features;support vector machine","","51","","62","","15 Aug 2016","","","IEEE","IEEE Conferences"
"Learnable Evolutionary Search Across Heterogeneous Problems via Kernelized Autoencoding","L. Zhou; L. Feng; A. Gupta; Y. -S. Ong","School of Computer Science and Engineering, Nanyang Technological University, Singapore; College of Computer Science, Chongqing University, Chongqing, China; A*STAR, Singapore Institute of Manufacturing Technology, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Evolutionary Computation","27 May 2021","2021","25","3","567","581","The design of the evolutionary algorithm with learning capability from past search experiences has attracted growing research interests in recent years. It has been demonstrated that the knowledge embedded in the past search experience can greatly speed up the evolutionary process if properly harnessed. Autoencoding evolutionary search (AEES) is a recently proposed search paradigm, which employs a single-layer denoising autoencoder to build the mapping between two problems by configuring the solutions of each problem as the input and output for the autoencoder, respectively. The learned mapping makes it possible to perform knowledge transfer across heterogeneous problem domains with diverse properties. It has shown a promising performance of learning and transferring the knowledge from past search experiences to facilitate the evolutionary search on a variety of optimization problems. However, despite the success enjoyed by AEES, the linear autoencoding model cannot capture the nonlinear relationship between the solution sets used in the mapping construction. Taking this cue, in this article, we devise a kernelized autoencoder to construct the mapping in a reproducing kernel Hilbert space (RKHS), where the nonlinearity among problem solutions can be captured easily. Importantly, the proposed kernelized autoencoding method also holds a closed-form solution which will not bring much computational burden in the evolutionary search. Furthermore, a kernelized autoencoding evolutionary-search (KAES) paradigm is proposed that adaptively selects the linear and kernelized autoencoding along the search process in pursuit of effective knowledge transfer across problem domains. To validate the efficacy of the proposed KAES, comprehensive empirical studies on both benchmark multiobjective optimization problems as well as real-world vehicle crashworthiness design problem are presented.","1941-0026","","10.1109/TEVC.2021.3056514","National Natural Science Foundation of China (NSFC)(grant numbers:61876025); Venture and Innovation Support Program for Chongqing Overseas Returnees(grant numbers:cx2018044,cx2019020); A*STAR Cyber-Physical Production System (CPPS)—Towards Contextual and Intelligent Response Research Program, through the RIE2020 IAF-PP(grant numbers:A19C1a0018); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9344841","Evolutionary optimization;kernelization;knowledge transfer;nonlinear","Optimization;Search problems;Noise reduction;Sociology;Knowledge transfer;Kernel;Genetic algorithms","evolutionary computation;Hilbert spaces;optimisation;search problems","learnable evolutionary search;heterogeneous problem;evolutionary algorithm;learning capability;autoencoding evolutionary search;AEES;single-layer denoising autoencoder;linear autoencoding model;kernelized autoencoder;kernel Hilbert space;knowledge transfer;multiobjective optimization;real-world vehicle crashworthiness design problem","","4","","54","IEEE","2 Feb 2021","","","IEEE","IEEE Journals"
"Automated Recognition of Wafer Backside Image Based on a Hierarchical Model","J. Zhuang; Z. Wang; M. Guo; G. Mao; Y. Wang; X. Chen; Y. Wang; Z. Wei","Shanghai Huali Microelectronics Corporation, Shanghai, China; Shanghai Huali Integrated Circuit Corporation, Shanghai, China; Shanghai Huali Integrated Circuit Corporation, Shanghai, China; Shanghai Huali Microelectronics Corporation, Shanghai, China; Shanghai Huali Microelectronics Corporation, Shanghai, China; Shanghai Huali Microelectronics Corporation, Shanghai, China; Shanghai Huali Integrated Circuit Corporation, Shanghai, China; Shanghai Huali Integrated Circuit Corporation, Shanghai, China","2021 China Semiconductor Technology International Conference (CSTIC)","29 Jun 2021","2021","","","1","4","As design rule shrinkage, the defect size control gets tighter, especially different wafer backside defects start to impact the front side pattern defined and cause yield loss. A hierarchical model has been proposed for recognizing abnormal images of wafer backside automatically, based on a neural-network model, which consists of two modules. The first module, called as Preprocessing Module (PM), will filter the noise and enhance the abnormal defect patterns in the images. Then, the images treated at the first module will be classified by the second Retrieval Module (RM) with an unsupervised autoencoder and K-Nearest Neighbor. In terms of the higher accuracy and efficiency, the results of this practical study with real world data showed the viability compared to the time-consuming and subjective eyeball analysis of backside images.","","978-1-6654-4945-8","10.1109/CSTIC52283.2021.9461519","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9461519","wafer backside image;defect pattern;neural network;retrieval module;classification module","Semiconductor device modeling;Image recognition;Image coding;Tools;Feature extraction;Manufacturing;Size control","feature extraction;flaw detection;image classification;image denoising;image filtering;nearest neighbour methods;neural nets;production engineering computing;semiconductor device manufacture;shrinkage;unsupervised learning","image classification;unsupervised autoencoder;k-nearest neighbor;semiconductor manufacturing;noise filtering;automated recognition;wafer backside defects;retrieval module;abnormal defect patterns;preprocessing module;neural network model;defect size control;design rule shrinkage;wafer backside image","","","","8","","29 Jun 2021","","","IEEE","IEEE Conferences"
"Auto-Embedding Generative Adversarial Networks For High Resolution Image Synthesis","Y. Guo; Q. Chen; J. Chen; Q. Wu; Q. Shi; M. Tan","School of Software Engineering, South China University of Technology, Guangzhou, China; School of Software Engineering, South China University of Technology, Guangzhou, China; School of Software Engineering, South China University of Technology, Guangzhou, China; School of Software Engineering, South China University of Technology, Guangzhou, China; School of Software Engineering, South China University of Technology, Guangzhou, China; School of Software Engineering, South China University of Technology, Guangzhou, China","IEEE Transactions on Multimedia","24 Oct 2019","2019","21","11","2726","2737","Generating images via a generative adversarial network (GAN) has attracted much attention recently. However, most of the existing GAN-based methods can only produce lowresolution images of limited quality. Directly generating highresolution images using GANs is nontrivial, and often produces problematic images with incomplete objects. To address this issue, we develop a novel GAN called auto-embedding generative adversarial network, which simultaneously encodes the global structure features and captures the fine-grained details. In our network, we use an autoencoder to learn the intrinsic high-level structure of real images and design a novel denoiser network to provide photo-realistic details for the generated images. In the experiments, we are able to produce 512 × 512 images of promising quality directly from the input noise. The resultant images exhibit better perceptual photo-realism, that is, with sharper structure and richer details, than other baselines on several datasets, including Oxford-102 Flowers, Caltech-UCSD Birds (CUB), High-Quality Large-scale CelebFaces Attributes (CelebAHQ), Large-scale Scene Understanding (LSUN), and ImageNet.","1941-0077","","10.1109/TMM.2019.2908352","National Natural Science Foundation of China(grant numbers:61602185,61876208,61502177); Recruitment Program for Young Professionals; Guangdong Provincial Scientific and Technological Fund(grant numbers:2017B090901008,2017A010101011,2017B090910005); Pearl River S and T Nova Program of Guangzhou(grant numbers:201806010081); CCF-Tencent Open Research Fund(grant numbers:RAGR20170105); Program for Guangdong Introducing Innovative and Enterpreneurial Teams(grant numbers:2017ZT07X183); Scientific and Technological Planning on Provincial Key Research and Development(grant numbers:2018B01010700); Guangdong Special Branch Plans Young Talent; Scientific and Technological Innovation(grant numbers:2016TQ03X445); Guangzhou Science and Technology Planning Project(grant numbers:2019-03-01-06-3002-0003); Guangzhou Tianhe District Science and Technology Planning(grant numbers:201702YH112); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8676365","Generative models;adversarial learning;low-dimensional embedding;autoencoder","Image resolution;Generative adversarial networks;Gallium nitride;Training;Data mining;Feature extraction;Generators","image coding;image denoising;image resolution","intrinsic high-level structure;GAN-based methods;autoembedding generative adversarial network;high resolution image synthesis;low resolution image synthesis;denoiser network;autoencoder;Oxford-102 Flowers;Caltech-UCSD Birds;CUB;high-quality large-scale celebfaces attributes;CelebAHQ;large-scale scene understanding;LSUN;ImageNet","","34","","61","IEEE","29 Mar 2019","","","IEEE","IEEE Journals"
"Synthetic Hyperspectral Images With Controllable Spectral Variability and Ground Truth","B. Palsson; M. O. Ulfarsson; J. R. Sveinsson","Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland","IEEE Geoscience and Remote Sensing Letters","1 Mar 2022","2022","19","","1","5","Spectral variability in hyperspectral images (HSIs) has received lot of attention over the last years, especially in the field of hyperspectral unmixing (HU) where it is a major issue. In this letter, we propose a method utilizing a variational autoencoder (VAE) for creating synthetic HSIs having controllable degree of spectral variability from existing HSIs with established ground-truth abundance maps and endmembers. Such synthetic datasets can be useful for developing HU methods that can handle spectral variability in HSIs. We investigate how the variability in the synthetic images differs from the original images and perform blind unmixing experiments using generated datasets to illustrate the effect of increasing variability. Code for method is available at https://github.com/burknipalsson/vae_synthetic_hsi.","1558-0571","","10.1109/LGRS.2022.3150245","Icelandic Research Fund(grant numbers:174075-05,207233-051); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9707767","Deep learning;hyperspectral unmixing (HU);neural network;synthetic hyperspectral images (HSIs);variational autoencoder (VAE)","Codes;Hyperspectral imaging;Decoding;Image reconstruction;Training;Sensors;Data models","geophysical image processing;hyperspectral imaging;image denoising;neural nets;remote sensing","synthetic hyperspectral images;controllable spectral variability;ground truth;hyperspectral unmixing;synthetic HSIs;controllable degree;synthetic datasets;HU methods;ground-truth abundance maps;variational autoencoder","","","","20","IEEE","8 Feb 2022","","","IEEE","IEEE Journals"
"Nonlinear system modeling with deep neural networks and autoencoders algorithm","E. De la Rosa; W. Yu; X. Li","Departamento de Control Automatico CINVESTAV-IPN Mexico City, Mexico; Departamento de Control Automatico CINVESTAV-IPN Mexico City, Mexico; Departamento de Computacion CINVESTAV-IPN, Mexico City, Mexico","2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","9 Feb 2017","2016","","","002157","002162","Deep learning techniques have been successfully used for pattern classification. These advantage methods are still not applied in nonlinear systems identification. In this paper, the neural model has deep architecture which is obtained by a random search method. The initial weights of this deep neural model is obtained from the denoising autoencoders model. We propose special unsupervised learning methods for this deep learning model with input data. The normal supervised learning is used to train the weights with the output data. The deep learning identification algorithms are validated with three benchmark examples.","","978-1-5090-1897-0","10.1109/SMC.2016.7844558","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7844558","","Machine learning;Nonlinear systems;Computational modeling;Neural networks;Training;Noise reduction;Data models","modelling;neural nets;nonlinear systems;pattern classification;search problems;unsupervised learning","nonlinear system modeling;deep neural networks;autoencoders algorithm;pattern classification;nonlinear system identification;deep architecture;unsupervised learning;normal supervised learning;deep learning identification algorithms;random search method","","8","","23","","9 Feb 2017","","","IEEE","IEEE Conferences"
"Gate-Layer Autoencoders with Application to Incomplete EEG Signal Recovery","H. El-Fiqi; K. Kasmarik; A. Bezerianos; K. C. Tan; H. A. Abbass","UNSW-Canberra, Canberra, Australia; UNSW-Canberra, Canberra, Australia; National University of Singapore, Singapore; City University of Hong Kong, Kowloon, Hong Kong; UNSW-Canberra, Canberra, Australia","2019 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2019","2019","","","1","8","Autoencoders (AE) have been used successfully as unsupervised learners for inferring latent information, learning hidden features and reducing the dimensionality of the data. In this paper, we propose a new AE architecture: Gate-Layer AE (GLAE). The novelty of GLAE lies in its ability to encourage learning of the relationships among different input variables, which affords it with an inherent ability to recover missing variables from the available ones and to act as a concurrent multi-function approximator.GLAE uses a network architecture that associates each input with a binary gate acting as a switch that turns on or off the flow to each input unit, while synchronising its action with data flow to the network. We test GLAE with different coding sizes and compare its performance against the Classic AE, Denoising AE and Variational AE. The evaluation uses Electroencephalograph (EEG) data with an aim to reconstruct the EEG signal when some data are missing. The results demonstrate GLAE's superior performance in reconstructing EEG signals with up to 25% missing data in an input stream.","2161-4407","978-1-7281-1985-4","10.1109/IJCNN.2019.8852101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852101","","Logic gates;Switches;Electroencephalography;Noise reduction;Encoding;Neural networks","electroencephalography;function approximation;medical signal processing;signal reconstruction;unsupervised learning","EEG signal recovery;hidden features;coding sizes;concurrent multifunction approximator;Electroencephalograph data;data flow;input unit;binary gate;network architecture;Gate-Layer AE;AE architecture;unsupervised learners;Gate-Layer autoencoders","","3","","41","","30 Sep 2019","","","IEEE","IEEE Conferences"
"Using autoencoder network to implement non-intrusive load monitoring of small and medium business customer","C. -W. Tsai; C. -W. Yang; W. -J. Ho; Z. -X. Yin; K. -C. Chiang","Southern Taiwan University of Science and Technology, Tainan City, Taiwan; China Medical University, Taiwan; Institude for Information Industry, Taipei, Taiwan; Southern Taiwan University of Science and Technology, Tainan City, Taiwan; Institude for Information Industry, Taipei, Taiwan","2018 IEEE International Conference on Applied System Invention (ICASI)","25 Jun 2018","2018","","","433","436","Recently, issues such as the greenhouse gas emission, depletion of fossil fuels, and safe use of nuclear energy led many countries and governments to focus on problems of energy economy. Improving energy efficiency of small- and medium-(S&M) business customers has become a challenge. To monitor the energy usage of appliances used by S&M business customers given the advanced metering infrastructure (AMI) meter's data and to establish a cost-effiective energy system, this study employs a deep learning network, the denoise autoencoder, to propose a nonintrusive load montoring system for data granularity of 1 sample/min. By implementing the system and analyzing actual data acquired from 12 test sites, the feasibility of the proposed system is demonstrated, and future research venues are discussed.","","978-1-5386-4342-6","10.1109/ICASI.2018.8394277","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8394277","","Power demand;Business;Machine learning;Data models;Testing;Monitoring;Lighting","building management systems;domestic appliances;energy conservation;fossil fuels;learning (artificial intelligence);load management;metering;power consumption;power engineering computing;power system measurement;small-to-medium enterprises","nonintrusive load montoring system;data granularity;autoencoder network;greenhouse gas emission;fossil fuels;nuclear energy;governments;energy economy;energy efficiency;S&M business customers;advanced metering infrastructure meter;cost-effiective energy system;deep learning network;data analysis;small and medium business customers","","1","","13","","25 Jun 2018","","","IEEE","IEEE Conferences"
"Unsupervised Classification of Covid-19 using Chest X-rays with Convolutional Autoencoder","S. Serte; S. M. Akila; K. Almezhghwi","Electrical and Electronic Engineering, Near East University, Nicosia, Turkey; Biomedical Engineering, Near East University, Nicosia, Turkey; Electrical and Electronic Engineering, College of Electronic Technology Tripoli, Tripoli, Libya","2022 International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA)","27 Jun 2022","2022","","","1","5","One of the crucial step in reducing mortality rate due to covid-19 infection is early diagnosis based on examining chest x-rays by trained experts. Particularly, the diagnosis results can only be effective if test results are considerably accurate. Considering the wide spread of covid-19, it can be challenging for certain testing centers to cope with manual examination of x-rays. Moreover, diagnosis errors due to human fatigue can quickly increase and thus put many lives at risk. In this regard, machine learning (ML) has been explored as an alternative to manual evaluation. However, this generally requires the collection of labeled datasets, which can be infeasible due to cost, time or unavailable human resources. As such, to address the aforementioned problem, this paper proposes unsupervised classification of covid-19 from chest x-rays using convolutional autoencoder (CAE), which is further regularized using denoising or dropout training criterion. Our model is light weight, fast and does not require labeled dataset for training the classification model. As such, it is competitively cheaper to deploy in practice. Using a publicly available dataset, several experiments are performed to show the effectiveness of our proposed solution in comparison to other state-of-the-art approaches. Different evaluation metrics such as accuracy, recall, precision and F1-score that are reported show that the proposed model outperforms several state-of-the-art approaches that are more complicated, slower and importantly rely on labeled dataset for training.","","978-1-6654-6835-0","10.1109/HORA55278.2022.9799880","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9799880","covid-19;chest x-ray;classification;diagnosis;convolution auto encoder","COVID-19;Training;Noise reduction;Manuals;Machine learning;X-rays;X-ray imaging","diagnostic radiography;image classification;medical diagnostic computing;medical image processing;pattern classification;unsupervised learning","unsupervised classification;chest x-rays;convolutional autoencoder;mortality rate;covid-19 infection;early diagnosis;trained experts;testing centers;manual examination;diagnosis errors;human fatigue;manual evaluation;labeled dataset;unavailable human resources;training criterion;classification model;publicly available dataset","","","","31","IEEE","27 Jun 2022","","","IEEE","IEEE Conferences"
"Optimized Structure of the Traffic Flow Forecasting Model With a Deep Learning Approach","H. -F. Yang; T. S. Dillon; Y. -P. P. Chen","Department of Computer Science and Information Technology, La Trobe University, Melbourne, VIC, Australia; Department of Computer Science and Information Technology, La Trobe University, Melbourne, VIC, Australia; Department of Computer Science and Information Technology, La Trobe University, Melbourne, VIC, Australia","IEEE Transactions on Neural Networks and Learning Systems","15 Sep 2017","2017","28","10","2371","2381","Forecasting accuracy is an important issue for successful intelligent traffic management, especially in the domain of traffic efficiency and congestion reduction. The dawning of the big data era brings opportunities to greatly improve prediction accuracy. In this paper, we propose a novel model, stacked autoencoder Levenberg-Marquardt model, which is a type of deep architecture of neural network approach aiming to improve forecasting accuracy. The proposed model is designed using the Taguchi method to develop an optimized structure and to learn traffic flow features through layer-by-layer feature granulation with a greedy layerwise unsupervised learning algorithm. It is applied to real-world data collected from the M6 freeway in the U.K. and is compared with three existing traffic predictors. To the best of our knowledge, this is the first time that an optimized structure of the traffic flow forecasting model with a deep learning approach is presented. The evaluation results demonstrate that the proposed model with an optimized structure has superior performance in traffic flow forecasting.","2162-2388","","10.1109/TNNLS.2016.2574840","Australia Research Linkage Grants Scheme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7517319","Deep learning;forecasting;neural network (NN) applications;stacked denoising autoencoders","Forecasting;Predictive models;Artificial neural networks;Machine learning;Prediction algorithms;Data models;Computational modeling","Big Data;learning (artificial intelligence);neural nets;road traffic;traffic engineering computing","traffic flow forecasting model;optimized structure;deep learning approach;intelligent traffic management;traffic efficiency;stacked autoencoder Levenberg-Marquardt model;neural network approach;Taguchi method;layer-by-layer feature granulation;greedy layerwise unsupervised learning algorithm","","139","","40","IEEE","20 Jul 2016","","","IEEE","IEEE Journals"
"Unsupervised Sequential Outlier Detection With Deep Architectures","W. Lu; Y. Cheng; C. Xiao; S. Chang; S. Huang; B. Liang; T. Huang","Department of Automation, Tsinghua University, Beijing, China; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; Department of Industrial and Systems Engineering, University of Washington, Seattle, WA, USA; Department of Automation, Tsinghua University, Beijing, China; Beckman Institute, University of Illinois at Urbana–Champaign, IL, USA","IEEE Transactions on Image Processing","4 Jul 2017","2017","26","9","4321","4330","Unsupervised outlier detection is a vital task and has high impact on a wide variety of applications domains, such as image analysis and video surveillance. It also gains long-standing attentions and has been extensively studied in multiple research areas. Detecting and taking action on outliers as quickly as possible are imperative in order to protect network and related stakeholders or to maintain the reliability of critical systems. However, outlier detection is difficult due to the one class nature and challenges in feature construction. Sequential anomaly detection is even harder with more challenges from temporal correlation in data, as well as the presence of noise and high dimensionality. In this paper, we introduce a novel deep structured framework to solve the challenging sequential outlier detection problem. We use autoencoder models to capture the intrinsic difference between outliers and normal instances and integrate the models to recurrent neural networks that allow the learning to make use of previous context as well as make the learners more robust to warp along the time axis. Furthermore, we propose to use a layerwise training procedure, which significantly simplifies the training procedure and hence helps achieve efficient and scalable training. In addition, we investigate a fine-tuning step to update all parameters set by incorporating the temporal correlation in the sequence. We further apply our proposed models to conduct systematic experiments on five real-world benchmark data sets. Experimental results demonstrate the effectiveness of our model, compared with other state-of-the-art approaches.","1941-0042","","10.1109/TIP.2017.2713048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7942034","Sequential anomaly detection;deep learning;denoising autoencoder;recurrent neural networks","Training;Data models;Feature extraction;Context modeling;Context;Principal component analysis;Correlation","correlation methods;object detection;recurrent neural nets","unsupervised sequential outlier detection;deep architectures;image analysis;video surveillance;feature construction;sequential anomaly detection;temporal correlation;deep structured framework;recurrent neural networks;time axis;layerwise training procedure;fine-tuning step;real-world benchmark data sets;autoencoder models;critical systems;applications domains","","33","","50","IEEE","7 Jun 2017","","","IEEE","IEEE Journals"
"Deep feature learning for pulmonary nodule classification in a lung CT","B. -C. Kim; Y. S. Sung; H. -I. Suk","Department of Brain and Cognitive Engineering, Korea University, Republic of Korea; Biomedical Imaging Infrastructure, Asan Medical Center, Republic of Korea; Department of Brain and Cognitive Engineering, Korea University, Republic of Korea","2016 4th International Winter Conference on Brain-Computer Interface (BCI)","21 Apr 2016","2016","","","1","3","In this paper, we propose a novel method of identifying pulmonary nodules in a lung CT. Specifically, we devise a deep neural network by which we extract abstract information inherent in raw hand-crafted imaging features. We then combine the deep learned representations with the original raw imaging features into a long feature vector. By taking the combined feature vectors, we train a classifier, preceded by a feature selection via t-test. To validate the effectiveness of the proposed method, we performed experiments on our in-house dataset of 20 subjects; 3,598 pulmonary nodules (malignant: 178, benign: 3,420), which were manually segmented by a radiologist. In our experiments, we achieved the maximal accuracy of 95.5%, sensitivity of 94.4%, and AUC of 0.987, outperforming the competing method.","","978-1-4673-7842-0","10.1109/IWW-BCI.2016.7457462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7457462","Pulmonary nodule classification;Lung cancer;Deep learning;Stacked denoising autoencoder","Cancer;Computed tomography;Training;Lungs;Feature extraction;Noise reduction","computerised tomography;feature extraction;feature selection;image classification;learning (artificial intelligence);lung;medical image processing;neural nets","deep feature learning;pulmonary nodule classification;lung CT;pulmonary nodule identification;deep neural network;abstract information extraction;hand-crafted imaging features;deep learned representations;raw imaging features;feature vector;classifier training;feature selection;t-test","","29","","13","","21 Apr 2016","","","IEEE","IEEE Conferences"
"An Evolutionary Deep Learning Anomaly Detection Framework for In-Vehicle Networks - CAN Bus","Y. Lin; C. Chen; F. Xiao; O. Avatefipour; K. Alsubhi; A. Yunianta","Project review, State Grid Fujian Electric Power Company Economic Technology Research Institute, 561748 Fuzhou China 350012 (e-mail: 18606932711@163.com); China Electric Power Research Institute, 467400 Beijing China 100192 (e-mail: dongminyu1980@outlook.com); Development Planning, State Grid Fujian Electric Power Company, 561722 Fuzhou China 350003 (e-mail: 12911429@qq.com); Electrical and Computer Engineering Department, University of Michigan Dearborn, 14711 Dearborn, Michigan United States 48128 (e-mail: oavatefi@umich.edu); Faculty of Computing and Information Technology, King Abdulaziz University, 37848 Jeddah Saudi Arabia (e-mail: kalsubhi@kau.edu.sa); Faculty of Computing and Information Technology, King Abdulaziz University, 37848 Jeddah Saudi Arabia (e-mail: ayunianta@kau.edu.sa)","IEEE Transactions on Industry Applications","","2020","PP","99","1","1","Modern vehicles are no longer considered as mere mechanical-based device, instead, they have been hugely replaced by sophisticated electric devices known as Electronic Control Unit (ECU). These ECUs are communicating with each other by publishing/receiving messages that complies with well-known protocol called Control Area Network (CAN). CAN bus is responsible to ensure all critical parts in vehicle e.g. engine, braking, airbag deployment, steering wheel, acceleration, etc. are functioning properly. This indicates that CAN bus is considered as the back-bone network protocol in modern vehicles. Unfortunately, the CAN bus protocol is vulnerable to various cyberattacks due to the lack of security mechanism in the protocol which has introduced several attack surfaces and allows attackers to have legitimate access to the bus and launch malicious activities. This paper proposes a new effective security solution that can detect three different types of message injected attacks namely Denial of Service (DoS), fuzzy, and impersonation attacks in the CAN traffic based on deep learning model. Moreover, the proposed method makes the use of evolutionary optimization algorithm to avoid premature convergence and manual selection of deep learning network architecture. To assess the practicality and effectiveness of the proposed method, CAN traffic is logged using unmodified license vehicle. Furthermore, the proposed method is evaluated using two other different CAN traffic dataset that proves the proposed method can be applied for different car make and models.","1939-9367","","10.1109/TIA.2020.3009906","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9143513","Controller Area Network (CAN Bus);Anomaly Detection;Deep Learning;Deep Denoising Autoencoder;Optimization Algorithm","Protocols;Anomaly detection;Security;Machine learning;Electronic mail;Industries;Machine learning algorithms","","","","5","","","IEEE","17 Jul 2020","","","IEEE","IEEE Early Access Articles"
"Hearing aids APP design based on deep learning technology","J. Y. Han; W. Z. Zheng; R. J. Huang; Y. Tsao; Y. H. Lai","Deprartment of Biomedical Engineering, National Yang-Ming University, Taipei, Taiwan; Deprartment of Biomedical Engineering, National Yang-Ming University, Taipei, Taiwan; Deprartment of Biomedical Engineering, National Yang-Ming University, Taipei, Taiwan; Research Center for Information Technology Innovation (CITI), Academia Sinica, Taipei, Taiwan; Deprartment of Biomedical Engineering, National Yang-Ming University, Taipei, Taiwan","2018 11th International Symposium on Chinese Spoken Language Processing (ISCSLP)","6 May 2019","2018","","","495","496","Hearing loss is a common health issue in an aging society. When the seniors are suffering from hearing losses, it will affect their quality of life drastically. According to the World Health Organization in 2018, the population with hearing loss has reached 466 million and it is estimated that the number of hearing-impaired population will reach 900 million by 2050. Therefore, it is stated clearly that the hearing loss study deserves more attention and effort. For a hearing loss individual, the hearing aid is the most common assistive device to help users to improve the audibility capability. The previous studies indicated that the hearing aids can provide suitable gain in the quiet environment; however, there is still room for improvement in the environment with noise. Due to this issue, this study proposed a real-time speech enhancement system for hearing loss individual improve listening benefits in noisy conditions, based on deep neural network (DNN) technology. More specifically, we embedded the DNN-based SE approach in a smartphone to achieve real-time speech enhancement processing. The preliminary results showed that the proposed system provides benefits for users under noisy listening conditions.","","978-1-5386-5627-3","10.1109/ISCSLP.2018.8706593","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8706593","speech enhancement;deep neural network;APP;hearing aids;deep denoising autoencoder (DDAE)","Auditory system;Speech enhancement;Noise measurement;Hearing aids;Real-time systems;Indexes;Noise reduction","handicapped aids;hearing;hearing aids;learning (artificial intelligence);medical signal processing;neural nets;smart phones;speech enhancement","deep learning technology;World Health Organization;hearing-impaired population;hearing loss study;hearing loss individual;hearing aids APP design;health issue;deep neural network;DNN;speech enhancement processing;smartphone","","2","","5","","6 May 2019","","","IEEE","IEEE Conferences"
"Unsupervised Detection of Anomalous Behavior in Wireless Devices based on Auto-Encoders","A. Albasir; Q. Hu; M. Al-tekreeti; K. Naik; N. Naik; A. J. Kozlowski; N. Goel","University of Waterloo, Waterloo; University of Waterloo, Waterloo; University of Waterloo, Waterloo; University of Waterloo, Waterloo; Ministry of Defence, Defence School of CIS, UK; Cistech Limited, Ottawa; Cistech Limited, Ottawa","NOMS 2020 - 2020 IEEE/IFIP Network Operations and Management Symposium","8 Jun 2020","2020","","","1","7","A major problem of wireless devices is the detection of security threats in an efficient manner. Several recent incidents show that malicious applications (apps) can find their ways to online markets (e.g., Google Play Store) and be available for download and installation. Such malicious apps can collect sensitive data from millions of users and send them to a third-party servers. In this paper, we propose a methodology that leverages the power consumption of wireless devices to build a model that makes them more robust to the presence of malicious apps. The method consists of two stages: (i) Feature Extraction where stacked Restricted Boltzmann Machine (RBM) AutoEncoders (AE) and Principal Component Analysis (PCA) are used to extract features vector based on AE’s reconstruction errors. (ii) Classifier where One-Class Support Vector Machine is trained to perform the classification task. The validation of the methodology is performed on a real measurements dataset. The obtained results show a good potential and prove that AEs’ reconstruction error can be used as a good discriminating feature. The obtained detection accuracy surpasses previously reported techniques, where it reaches up to ~ 98% in some scenarios.","2374-9709","978-1-7281-4973-8","10.1109/NOMS47738.2020.9110433","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9110433","Malware Detection;Power Consumption Information;Denoising AutoEncoder;Wireless Devices","Wireless communication;Support vector machines;Wireless sensor networks;Power demand;Feature extraction;Malware;Communication system security","Android (operating system);Boltzmann machines;feature extraction;Internet;invasive software;mobile computing;pattern classification;principal component analysis;support vector machines","wireless devices;auto-encoders;security threats;malicious applications;online markets;Google Play Store;feature extraction;anomalous behavior unsupervised detection;restricted Boltzmann machine autoencoders;principal component analysis;one-class support vector machine;classification task","","","","32","","8 Jun 2020","","","IEEE","IEEE Conferences"
"A Robust to Noise Adversarial Recurrent Model for Non-Intrusive Load Monitoring","M. Kaselimi; A. Voulodimos; N. Doulamis; A. Doulamis; E. Protopapadakis","National Technical University of Athens, Athens, Greece; National Technical University of Athens, Athens, Greece; National Technical University of Athens, Athens, Greece; National Technical University of Athens, Athens, Greece; National Technical University of Athens, Athens, Greece","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","3335","3339","The problem of separating the household aggregated power signal into its additive sub-components, called energy (power) disaggregation or Non-Intrusive Load Monitoring (NILM) can play an instrumental role as a driver towards consumer energy consumption awareness and behavioral change. In this paper, we propose EnerGAN++, an adversarially trained model for robust energy disaggregation. We propose a unified autoencoder (AE) and GAN architecture, in which the AE achieves a non-linear power signal source separation. The discriminator performs sequence classification, using a recurrent CNN to handle the temporal dynamics of an appliance energy consumption time series. Experimental results indicate the proposed method’s superiority compared to the state of the art.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9413663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9413663","Non-intrusive load monitoring;energy disaggregation;generative adversarial networks;denoising autoencoders;robustness to noise","Home appliances;Energy consumption;Source separation;Power demand;Time series analysis;Generative adversarial networks;Robustness","domestic appliances;energy consumption;load monitoring;neural net architecture;power engineering computing;recurrent neural nets;source separation;time series","noise adversarial recurrent model;nonintrusive load monitoring;energy disaggregation;consumer energy consumption awareness;nonlinear power signal source separation;recurrent CNN;appliance energy consumption time series;GAN architecture;autoencoder","","","","20","","13 May 2021","","","IEEE","IEEE Conferences"
"Fully convolutional network (FCN) model to extract clear speech signals on non-stationary noises of human conversations for cochlear implants","T. Yi-Ting; L. L. Diana","Department of Computer Science, The University of Hong Kong, Hong Kong, China; Department of Mathematics, University of California, California, USA","2017 IEEE MIT Undergraduate Research Technology Conference (URTC)","8 Feb 2018","2017","","","1","4","Cochlear implant (CI) electronically stimulates the nerve to help those with severe hearing lost. However, under noisy backgrounds, speech perception tasks have remained difficult for CI users. Therefore, speech enhancement (SE) is a critical component to improve speech perception examining through different noise scenarios. In this study, we developed the fully convolutional network (FCN) model to extract clear speech signals on non-stationary noises of human conversations in the background, and further compare the model's performance with previously developed log power spectrum (LPS) based Deep neural network (DNN) model's performance by conducting hearing test of enhanced speech which simulated in CI.","","978-1-5386-2534-7","10.1109/URTC.2017.8284181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8284181","speech enhancement;convolutional neural network;cochlear implant;denoising autoencoder","Speech;Auditory system;Noise measurement;Speech enhancement;Mathematical model;Vocoders;Data models","cochlear implants;hearing;neural nets;speech enhancement","noisy backgrounds;speech perception tasks;speech enhancement;fully convolutional network model;FCN;nonstationary noises;human conversations;Deep neural network model;cochlear implant;clear speech signal extraction;log power spectrum","","","","11","","8 Feb 2018","","","IEEE","IEEE Conferences"
"Two-Stage Deep Learning Approach for Speech Enhancement and Reconstruction in The Frequency and Time Domains","S. A. Nossier; J. Wall; M. Moniri; C. Glackin; N. Cannings","Dept. of Engineering and Computing, University of East London, London, UK; Dept. of Engineering and Computing, University of East London, London, UK; Dept. of Engineering and Computing, University of East London, London, UK; Intelligent Voice Ltd, London, UK; Intelligent Voice Ltd, London, UK","2022 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2022","2022","","","1","10","Deep learning has recently shown promising improvement in the speech enhancement field, due to its effectiveness in eliminating noise. However, a drawback of the denoising process is the introduction of speech distortion, which negatively affects speech quality and intelligibility. In this work, we propose a deep convolutional denoising autoencoder-based speech enhancement network that is designed to have an encoder deeper than the decoder, to improve performance and decrease complexity. Furthermore, we present a two-stage learning approach, in which denoising is performed in the first frequency domain stage using magnitude spectrum as a training target; while, in the second stage, further denoising and speech reconstruction are performed in the time domain. Results show that our architecture achieves 0.22 improvement in the overall predicted mean opinion score (Covl) over state of the art speech enhancement architectures, using the Valentini dataset benchmark. Moreover, the architecture was trained using a larger dataset and tested using a mismatched test corpus, to achieve 0.7 and 6.35% improvement in Perceptual Evaluation of Speech Quality (PESQ) and Short Time Objective Intelligibility (STOI) scores, respectively, compared to the noisy speech.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9892355","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9892355","Deep learning;denoising autoencoders;speech enhancement;speech features;speech reconstruction","Deep learning;Training;Time-frequency analysis;Noise reduction;Neural networks;Speech enhancement;Distortion","","","","","","55","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"No-Reference Video Quality Assessment With 3D Shearlet Transform and Convolutional Neural Networks","Y. Li; L. -M. Po; C. -H. Cheung; X. Xu; L. Feng; F. Yuan; K. -W. Cheung","Department of Electronic Engineering, City University of Hong Kong, Hong Kong; Department of Electronic Engineering, City University of Hong Kong, Hong Kong; Department of Information Systems, City University of Hong Kong, Hong Kong; Department of Electronic Engineering, City University of Hong Kong, Hong Kong; Department of Electronic Engineering, City University of Hong Kong, Hong Kong; Department of Electronic Engineering, City University of Hong Kong, Hong Kong; Department of Computer Science, Chu Hai College of Higher Education, Hong Kong","IEEE Transactions on Circuits and Systems for Video Technology","2 Jun 2016","2016","26","6","1044","1057","In this paper, we propose an efficient general-purpose no-reference (NR) video quality assessment (VQA) framework that is based on 3D shearlet transform and convolutional neural network (CNN). Taking video blocks as input, simple and efficient primary spatiotemporal features are extracted by 3D shearlet transform, which are capable of capturing natural scene statistics properties. Then, CNN and logistic regression are concatenated to exaggerate the discriminative parts of the primary features and predict a perceptual quality score. The resulting algorithm, which we name shearlet- and CNN-based NR VQA (SACONVA), is tested on well-known VQA databases of Laboratory for Image & Video Engineering, Image & Video Processing Laboratory, and CSIQ. The testing results have demonstrated that SACONVA performs well in predicting video quality and is competitive with current state-of-the-art full-reference VQA methods and general-purpose NR-VQA algorithms. Besides, SACONVA is extended to classify different video distortion types in these three databases and achieves excellent classification accuracy. In addition, we also demonstrate that SACONVA can be directly applied in real applications such as blind video denoising.","1558-2205","","10.1109/TCSVT.2015.2430711","City University of Hong Kong, Hong Kong(grant numbers:7004058); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7103036","Auto-encoder;convolutional auto-encoder;convolutional neural network;distortion identification;no-reference video quality assessment;3D shearlet transform;3D shearlet transform;autoencoder (AE);convolutional AE (CAE);convolutional neural network (CNN);distortion identification;no-reference (NR) video quality assessment (VQA)","Video recording;Quality assessment;Three-dimensional displays;Databases;Transforms;Feature extraction;Convolution","feature extraction;feedforward neural nets;image classification;image denoising;regression analysis;transforms;video databases;video signal processing","3D shearlet transform;convolutional neural networks;general-purpose no-reference video quality assessment framework;video blocks;primary spatiotemporal feature extraction;natural scene statistics properties;logistic regression;perceptual quality score prediction;shearlet-based NR VQA;CNN-based NR VQA;SACONVA;VQA databases;Image & Video Engineering Laboratory;Image & Video Processing Laboratory;CSIQ;video quality prediction;video distortion type classification;blind video denoising","","80","","42","IEEE","6 May 2015","","","IEEE","IEEE Journals"
"Deep Non-Cooperative Spectrum Sensing Over Rayleigh Fading Channel","Z. Su; K. C. Teh; S. G. Razul; A. C. Kot","School of Electrical and Electronic Engineering, NTU, Singapore; School of Electrical and Electronic Engineering, NTU, Singapore; Temasek Laboratories, NTU, Singapore; School of Electrical and Electronic Engineering, NTU, Singapore","IEEE Transactions on Vehicular Technology","2 May 2022","2022","71","4","4460","4464","In this paper, we propose a robust non-cooperative spectrum sensing algorithm based on deep learning over Rayleigh fading channel. We conduct noise cancellation on the received sensing data using the stacked convolutional auto-encoder (SCAE) as a pre-processing step. The series of the denoised signal in the time domain is then fed into the proposed Hybrid CNN-SA-GRU (H-CSG) network. The proposed network combines convolutional neural network (CNN), self-attention (SA) modules and gate recurrent unit (GRU). It can extract input features from spatial and temporal domains. The proposed algorithm has been shown to be effective and robust in detecting weak signals at the low signal-to-noise ratio (SNR) level.","1939-9359","","10.1109/TVT.2021.3138593","Temasek Laboratories; Nanyang Technological University; Rapid-Rich Object Search; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9664354","Deep learning;spectrum sensing;signal detection;autoencoder","Sensors;Feature extraction;Signal to noise ratio;Convolution;Training;Convolutional neural networks;OFDM","convolutional neural nets;deep learning (artificial intelligence);feature extraction;radio spectrum management;Rayleigh channels;recurrent neural nets;signal denoising","spatial domains;temporal domains;low signal-to-noise ratio;deep noncooperative spectrum sensing;Rayleigh fading channel;deep learning;noise cancellation;received sensing data;stacked convolutional auto-encoder;denoised signal;time domain;Hybrid CNN-SA-GRU;gate recurrent unit","","1","","19","IEEE","28 Dec 2021","","","IEEE","IEEE Journals"
"A New Pan-Sharpening Method With Deep Neural Networks","W. Huang; L. Xiao; Z. Wei; H. Liu; S. Tang","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Science, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Geoscience and Remote Sensing Letters","19 May 2017","2015","12","5","1037","1041","A deep neural network (DNN)-based new pansharpening method for the remote sensing image fusion problem is proposed in this letter. Research on representation learning suggests that the DNN can effectively model complex relationships between variables via the composition of several levels of nonlinearity. Inspired by this observation, a modified sparse denoising autoencoder (MSDA) algorithm is proposed to train the relationship between high-resolution (HR) and low-resolution (LR) image patches, which can be represented by the DNN. The HR/LR image patches only sample from the HR/LR panchromatic (PAN) images at hand, respectively, without requiring other training images. By connecting a series of MSDAs, we obtain a stacked MSDA (S-MSDA), which can effectively pretrain the DNN. Moreover, in order to better train the DNN, the entire DNN is again trained by a back-propagation algorithm after pretraining. Finally, assuming that the relationship between HR/LR multispectral (MS) image patches is the same as that between HR/LR PAN image patches, the HR MS image will be reconstructed from the observed LR MS image using the trained DNN. Comparative experimental results with several quality assessment indexes show that the proposed method outperforms other pan-sharpening methods in terms of visual perception and numerical measures.","1558-0571","","10.1109/LGRS.2014.2376034","National Natural Science Foundation of China(grant numbers:11431015,61301215,61101194,61171165); National Scientific Equipment Developing Project of China(grant numbers:2012YQ050250); Jiangsu Provincial Postdoctoral Research Funding plan of China(grant numbers:1301025C); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7018004","Deep neural networks (DNNs);multispectral (MS) image;panchromatic (PAN) image;pan-sharpening;Deep neural networks (DNNs);multispectral (MS) image;panchromatic (PAN) image;pan-sharpening","Image reconstruction;Remote sensing;Training;Spatial resolution;Image fusion;Neural networks","geophysical image processing;geophysical techniques;image coding;image denoising;image fusion;image reconstruction;image representation;image resolution;neural nets;numerical analysis;remote sensing","pan-sharpening method;deep neural network;remote sensing image fusion problem;DNN;representation learning;model complex relationships;nonlinearity;modified sparse denoising autoencoder algorithm;high-resolution image patches;low-resolution image patches;low-resolution panchromatic images;high-resolution panchromatic images;MSDA series;high-resolution multispectral image patches;low-resolution multispectral image patches;HR MS image reconstruction;quality assessment indexes;visual perception;numerical measures;back-propagation algorithm","","218","","17","IEEE","22 Jan 2015","","","IEEE","IEEE Journals"
"A deep learning approach to structured signal recovery","A. Mousavi; A. B. Patel; R. G. Baraniuk","Department of Electrical and Computer Engineering, Rice University, Houston, TX; Department of Electrical and Computer Engineering, Rice University, Houston, TX; Department of Electrical and Computer Engineering, Rice University, Houston, TX","2015 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton)","7 Apr 2016","2015","","","1336","1343","In this paper, we develop a new framework for sensing and recovering structured signals. In contrast to compressive sensing (CS) systems that employ linear measurements, sparse representations, and computationally complex convex/greedy algorithms, we introduce a deep learning framework that supports both linear and mildly nonlinear measurements, that learns a structured representation from training data, and that efficiently computes a signal estimate. In particular, we apply a stacked denoising autoencoder (SDA), as an unsupervised feature learner. SDA enables us to capture statistical dependencies between the different elements of certain signals and improve signal recovery performance as compared to the CS approach.","","978-1-5090-1824-6","10.1109/ALLERTON.2015.7447163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7447163","","Machine learning;Sparse matrices;Neural networks;Training;Atmospheric measurements;Particle measurements;Wavelet domain","compressed sensing;computational complexity;convex programming;greedy algorithms;signal denoising;signal representation;statistical analysis;unsupervised learning","structured signal recovery performance improvement;deep learning approach;compressive sensing system;CS system;linear measurement;sparse representation;computationally complex convex algorithm;computationally complex greedy algorithm;mildly nonlinear measurement;stacked denoising autoencoder;SDA;unsupervised feature learner;statistical dependency capture","","206","1","36","","7 Apr 2016","","","IEEE","IEEE Conferences"
"Context-Aware Deep Feature Compression for High-Speed Visual Tracking","J. Choi; H. J. Chang; T. Fischer; S. Yun; K. Lee; J. Jeong; Y. Demiris; J. Y. Choi","ASRI, Seoul National University; EEE., Imperial College London; EEE., Imperial College London; ASRI, Seoul National University; ASRI, Seoul National University; ASRI, Seoul National University; EEE., Imperial College London; ASRI, Seoul National University","2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition","16 Dec 2018","2018","","","479","488","We propose a new context-aware correlation filter based tracking framework to achieve both high computational speed and state-of-the-art performance among real-time trackers. The major contribution to the high computational speed lies in the proposed deep feature compression that is achieved by a context-aware scheme utilizing multiple expert auto-encoders; a context in our framework refers to the coarse category of the tracking target according to appearance patterns. In the pre-training phase, one expert auto-encoder is trained per category. In the tracking phase, the best expert auto-encoder is selected for a given target, and only this auto-encoder is used. To achieve high tracking performance with the compressed feature map, we introduce extrinsic denoising processes and a new orthogonality loss term for pre-training and fine-tuning of the expert autoencoders. We validate the proposed context-aware framework through a number of experiments, where our method achieves a comparable performance to state-of-the-art trackers which cannot run in real-time, while running at a significantly fast speed of over 100 fps.","2575-7075","978-1-5386-6420-9","10.1109/CVPR.2018.00057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8578155","","Target tracking;Correlation;Real-time systems;Convolutional codes;Training;Noise reduction","computer vision;data compression;feature extraction;image coding;image denoising;image filtering;image motion analysis;image representation;object tracking;target tracking;ubiquitous computing","context-aware deep feature compression;high-speed visual tracking;context-aware correlation filter;coarse category;tracking target;expert autoencoders;context-aware framework;feature map;pretraining phase;extrinsic denoising processes","","112","","43","","16 Dec 2018","","","IEEE","IEEE Conferences"
"A Two-Stage Approach for the Remaining Useful Life Prediction of Bearings Using Deep Neural Networks","M. Xia; T. Li; T. Shu; J. Wan; C. W. de Silva; Z. Wang","Department of Mechanical Engineering, University of British Columbia, Vancouver, BC, Canada; Department of Mechanical Engineering, University of British Columbia, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; Department of Mechanical Engineering, University of British Columbia, Vancouver, BC, Canada; School of Mechanical Engineering, Hubei University of Arts and Science, Xiangyang, China","IEEE Transactions on Industrial Informatics","13 Jun 2019","2019","15","6","3703","3711","The degradation of bearings plays a key role in the failures of industrial machinery. Prognosis of bearings is critical in adopting an optimal maintenance strategy to reduce the overall cost and to avoid unwanted downtime or even casualties by estimating the remaining useful life (RUL) of the bearings. Traditional data-driven approaches of RUL prediction rely heavily on manual feature extraction and selection using human expertise. This paper presents an innovative two-stage automated approach to estimate the RUL of bearings using deep neural networks (DNNs). A denoising autoencoder-based DNN is used to classify the acquired signals of the monitored bearings into different degradation stages. Representative features are extracted directly from the raw signal by training the DNN. Then, regression models based on shallow neural networks are constructed for each health stage. The final RUL result is obtained by smoothing the regression results from different models. The proposed approach has achieved satisfactory prediction performance for a real bearing degradation dataset with different working conditions.","1941-0050","","10.1109/TII.2018.2868687","Natural Sciences and Engineering Research Council of Canada; Canada Foundation for Innovation; British Columbia Knowledge Development Fund; National Key Research and Development Program of China(grant numbers:2017YFE0101000); Science and Technology Program of Guangzhou, China(grant numbers:201802030005); Key Program of Natural Science Foundation of Guangdong Province(grant numbers:2017B030311008); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8454498","Bearings;deep neural networks (DNNs);prognosis;remaining useful life (RUL) prediction","Feature extraction;Degradation;Neural networks;Training;Hidden Markov models;Prognostics and health management;Noise reduction","condition monitoring;cost reduction;failure analysis;feature extraction;feature selection;learning (artificial intelligence);machine bearings;machinery;maintenance engineering;neural nets;regression analysis;remaining life assessment;signal classification;signal denoising;vibrational signal processing","remaining useful life prediction;deep neural networks;optimal maintenance strategy;two-stage automated approach;denoising autoencoder-based DNN;data-driven approach;feature extraction;industrial machinery failure;cost reduction;human expertise;regression model;faeture selection;signal classification;vibrational signal processing","","95","","25","IEEE","4 Sep 2018","","","IEEE","IEEE Journals"
"WiDeep: WiFi-based Accurate and Robust Indoor Localization System using Deep Learning","M. Abbas; M. Elhamshary; H. Rizk; M. Torki; M. Youssef","Dept. of Comp. and Sys. Eng., Alexandria University, Alexandria, Egypt; Dept. of Comp. and Cont. Eng., Tanta University, Tanta, Egypt; Dept. of Comp. Sci. and Eng., EJUST, Alexandria, Egypt; Dept. of Comp. and Sys. Eng., Alexandria University, Alexandria, Egypt; Dept. of Comp. and Sys. Eng., Alexandria University, Alexandria, Egypt","2019 IEEE International Conference on Pervasive Computing and Communications (PerCom","22 Jul 2019","2019","","","1","10","Robust and accurate indoor localization has been the goal of several research efforts over the past decade. Due to the ubiquitous availability of WiFi indoors, many indoor localization systems have been proposed relying on WiFi fingerprinting. However, due to the inherent noise and instability of the wireless signals, the localization accuracy usually degrades and is not robust to dynamic changes in the environment.We present WiDeep, a deep learning-based indoor localization system that achieves a fine-grained and robust accuracy in the presence of noise. Specifically, WiDeep combines a stacked denoising autoencoders deep learning model and a probabilistic framework to handle the noise in the received WiFi signal and capture the complex relationship between the WiFi APs signals heard by the mobile phone and its location. WiDeep also introduces a number of modules to address practical challenges such as avoiding over-training and handling heterogeneous devices.We evaluate WiDeep in two testbeds of different sizes and densities of access points. The results show that it can achieve a mean localization accuracy of 2.64m and 1.21m for the larger and the smaller testbeds, respectively. This accuracy outperforms the state-of-the-art techniques in all test scenarios and is robust to heterogeneous devices.","2474-249X","978-1-5386-9148-9","10.1109/PERCOM.2019.8767421","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8767421","WiFi;Deep learning;indoor;localization;fingerprinting","Wireless fidelity;Noise reduction;Probabilistic logic;Noise measurement;Training;Deep learning;Data models","indoor radio;signal denoising;wireless LAN","WiDeep;robust indoor localization system;accurate indoor localization;WiFi indoors;indoor localization systems;WiFi fingerprinting;inherent noise;wireless signals;deep learning-based indoor localization system;stacked denoising autoencoders deep learning model;received WiFi signal;WiFi APs signals;mean localization accuracy;size 1.21 m;size 2.64 m","","85","","44","","22 Jul 2019","","","IEEE","IEEE Conferences"
"MDLFace: Memorability augmented deep learning for video face recognition","G. Goswami; R. Bhardwaj; R. Singh; M. Vatsa","IIIT-Delhi, India; IIIT-Delhi, India; IIIT-Delhi, India; IIIT-Delhi, India","IEEE International Joint Conference on Biometrics","29 Dec 2014","2014","","","1","7","Videos have ample amount of information in the form of frames that can be utilized for feature extraction and matching. However, face images in not all of the frames are “memorable” and useful. Therefore, utilizing all the frames available in a video for recognition does not necessarily improve the performance but significantly increases the computation time. In this research, we present a memorability based frame selection algorithm that enables automatic selection of memorable frames for facial feature extraction and matching. A deep learning algorithm is then proposed that utilizes a stack of denoising autoencoders and deep Boltzmann machines to perform face recognition using the most memorable frames. The proposed algorithm, termed as MDLFace, is evaluated on two publicly available video face databases, Youtube Faces and Point and Shoot Challenge. The results show that the proposed algorithm achieves state-of-the-art performance at low false accept rates.","","978-1-4799-3584-0","10.1109/BTAS.2014.6996299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6996299","","Face;Face recognition;Databases;Feature extraction;Accuracy;Training;YouTube","Boltzmann machines;face recognition;feature extraction;image denoising;image matching;learning (artificial intelligence);video signal processing;visual databases","MDLFace;memorability augmented deep learning;video face recognition;facial feature extraction;facial feature matching;memorability based frame selection algorithm;denoising autoencoders;deep Boltzmann machines;video face databases;Youtube Faces;Point and Shoot Challenge","","34","","34","","29 Dec 2014","","","IEEE","IEEE Conferences"
"Unsupervised Identification of Disease Marker Candidates in Retinal OCT Imaging Data","P. Seeböck; S. M. Waldstein; S. Klimscha; H. Bogunovic; T. Schlegl; B. S. Gerendas; R. Donner; U. Schmidt-Erfurth; G. Langs","Christian Doppler Laboratory for Ophthalmic Image Analysis, Vienna Reading Center, Medical University Vienna, Vienna, Austria; Christian Doppler Laboratory for Ophthalmic Image Analysis, Vienna Reading Center, Medical University Vienna, Vienna, Austria; Christian Doppler Laboratory for Ophthalmic Image Analysis, Vienna Reading Center, Medical University Vienna, Vienna, Austria; Christian Doppler Laboratory for Ophthalmic Image Analysis, Vienna Reading Center, Medical University Vienna, Vienna, Austria; Computational Imaging Research Laboratory, Medical University Vienna, Vienna, Austria; Christian Doppler Laboratory for Ophthalmic Image Analysis, Vienna Reading Center, Medical University Vienna, Vienna, Austria; Computational Imaging Research Laboratory, Medical University Vienna, Vienna, Austria; Christian Doppler Laboratory for Ophthalmic Image Analysis, Vienna Reading Center, Medical University Vienna, Vienna, Austria; Christian Doppler Laboratory for Ophthalmic Image Analysis, Vienna Reading Center, Medical University Vienna, Vienna, Austria","IEEE Transactions on Medical Imaging","2 Apr 2019","2019","38","4","1037","1047","The identification and quantification of markers in medical images is critical for diagnosis, prognosis, and disease management. Supervised machine learning enables the detection and exploitation of findings that are known a priori after annotation of training examples by experts. However, supervision does not scale well, due to the amount of necessary training examples, and the limitation of the marker vocabulary to known entities. In this proof-of-concept study, we propose unsupervised identification of anomalies as candidates for markers in retinal optical coherence tomography (OCT) imaging data without a constraint to a priori definitions. We identify and categorize marker candidates occurring frequently in the data and demonstrate that these markers show a predictive value in the task of detecting disease. A careful qualitative analysis of the identified data driven markers reveals how their quantifiable occurrence aligns with our current understanding of disease course, in early- and late age-related macular degeneration (AMD) patients. A multi-scale deep denoising autoencoder is trained on healthy images, and a one-class support vector machine identifies anomalies in new data. Clustering in the anomalies identifies stable categories. Using these markers to classify healthy-, early AMD- and late AMD cases yields an accuracy of 81.40%. In a second binary classification experiment on a publicly available data set (healthy versus intermediate AMD), the model achieves an area under the ROC curve of 0.944.","1558-254X","","10.1109/TMI.2018.2877080","Christian Doppler Forschungsgesellschaft; Austrian Federal Ministry for Digital and Economic Affairs; Austrian Science Fund(grant numbers:FWF I2714-B31); IBM (2016–2017 IBM Ph.D. Fellowship Award and Faculty Award); Nvidia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502086","Unsupervised deep learning;anomaly detection;biomarker identification;optical coherence tomography","Diseases;Retina;Biomedical imaging;Training;Anomaly detection;Task analysis","biomedical optical imaging;diseases;eye;geriatrics;image classification;image denoising;medical image processing;neural nets;optical tomography;support vector machines;unsupervised learning","disease course;retinal OCT imaging data;medical images;disease management;supervised machine learning;retinal optical coherence tomography;late age-related macular degeneration patients;unsupervised identification;disease marker candidates;multiscale deep denoising autoencoder;support vector machine;binary classification","Algorithms;Biomarkers;Humans;Image Interpretation, Computer-Assisted;Macular Degeneration;ROC Curve;Retina;Tomography, Optical Coherence;Unsupervised Machine Learning","33","","34","IEEE","21 Oct 2018","","","IEEE","IEEE Journals"
"An ensemble of deep neural networks for object tracking","X. Zhou; L. Xie; P. Zhang; Y. Zhang","Shaanxi Provincial Key Laboratory of Speech & Image Information Processing (SAIIP), Northwestern Poly technical University, Xian, P. R. China; Shaanxi Provincial Key Laboratory of Speech & Image Information Processing (SAIIP), Northwestern Poly technical University, Xian, P. R. China; Shaanxi Provincial Key Laboratory of Speech & Image Information Processing (SAIIP), Northwestern Poly technical University, Xian, P. R. China; Shaanxi Provincial Key Laboratory of Speech & Image Information Processing (SAIIP), Northwestern Poly technical University, Xian, P. R. China","2014 IEEE International Conference on Image Processing (ICIP)","29 Jan 2015","2014","","","843","847","Object tracking in complex backgrounds with dramatic appearance variations is a challenging problem in computer vision. We tackle this problem by a novel approach that incorporates a deep learning architecture with an on-line AdaBoost framework. Inspired by its multi-level feature learning ability, a stacked denoising autoencoder (SDAE) is used to learn multi-level feature descriptors from a set of auxiliary images. Each layer of the SDAE, representing a different feature space, is subsequently transformed to a discriminative object/background deep neural network (DNN) classifier by adding a classification layer. By an on-line AdaBoost feature selection framework, the ensemble of the DNN classifiers is then updated on-line to robustly distinguish the target from the background. Experiments on an open tracking benchmark show promising results of the proposed tracker as compared with several state-of-the-art approaches.","2381-8549","978-1-4799-5751-4","10.1109/ICIP.2014.7025169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7025169","Boosting;deep learning;visual tracking;deep neural network;AdaBoost","Boosting;Robustness;Target tracking;Neural networks;Object tracking;Noise reduction","computer vision;image classification;image coding;image denoising;image representation;learning (artificial intelligence);neural net architecture;object tracking","object tracking;deep-neural network ensemble;complex backgrounds;appearance variations;computer vision;deep-learning architecture;stacked denoising autoencoder;multilevel feature descriptor learning ability;auxiliary images;SDAE;feature space representation;object deep-neural network classifier;classification layer;online AdaBoost feature selection framework;DNN classifier ensemble;open tracking benchmark;background deep-neural network classifier","","31","","31","IEEE","29 Jan 2015","","","IEEE","IEEE Conferences"
"Reversible Recursive Instance-Level Object Segmentation","X. Liang; Y. Wei; X. Shen; Z. Jie; J. Feng; L. Lin; S. Yan",National University of Singapore; National University of Singapore; Adobe Research; National University of Singapore; National University of Singapore; Sun Yat-sen University; National University of Singapore,"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","12 Dec 2016","2016","","","633","641","In this work, we propose a novel Reversible Recursive Instance-level Object Segmentation (R2-IOS) framework to address the challenging instance-level object segmentation task. R2-IOS consists of a reversible proposal refinement sub-network that predicts bounding box offsets for refining the object proposal locations, and an instance-level segmentation sub-network that generates the foreground mask of the dominant object instance in each proposal. By being recursive, R2-IOS iteratively optimizes the two subnetworks during joint training, in which the refined object proposals and improved segmentation predictions are alternately fed into each other to progressively increase the network capabilities. By being reversible, the proposal refinement sub-network adaptively determines an optimal number of refinement iterations required for each proposal during both training and testing. Furthermore, to handle multiple overlapped instances within a proposal, an instance-aware denoising autoencoder is introduced into the segmentation sub-network to distinguish the dominant object from other distracting instances. Extensive experiments on the challenging PASCAL VOC 2012 benchmark well demonstrate the superiority of R2-IOS over other state-of-the-art methods. In particular, the APr over 20 classes at 0:5 IoU achieves 66:7%, which significantly outperforms the results of 58:7% by PFN [17] and 46:3% by [22].","1063-6919","978-1-4673-8851-1","10.1109/CVPR.2016.75","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7780444","","Proposals;Object segmentation;Training;Noise reduction;Semantics;Image segmentation;Testing","image coding;image denoising;image segmentation;visual databases","reversible recursive instance-level object segmentation;R2-IOS framework;reversible proposal refinement subnetwork;bounding box offset prediction;object proposal location refining;instance-level segmentation subnetwork;foreground masking;object instance;segmentation prediction improvement;network capabilities;refinement subnetwork;refinement iterations;instance-aware denoising autoencoder;PASCAL VOC 2012 benchmark;IoU;PFN","","29","1","38","","12 Dec 2016","","","IEEE","IEEE Conferences"
"Robust greedy deep dictionary learning for ECG arrhythmia classification","A. Majumdar; R. Ward","IIIT Delhi, New Delhi, India; University of British Columbia, Vancouver, Canada","2017 International Joint Conference on Neural Networks (IJCNN)","3 Jul 2017","2017","","","4400","4407","This work proposes a new deep learning method which we call robust deep dictionary learning RDDL. RDDL is suitable for learning representations from signals corrupted with sparse but large outliers such as artifacts and noise that are more heavy tailed than Gaussian distributions. Such outliers are common in biomedical signals e.g. EEG and ECG. RDDL learns multiple levels of non-linear dictionaries for representing the data. Instead of the standard Euclidean cost function that is usually employed in dictionary learning, we propose a robust l1-norm cost function. In order to achieve sparse representation, an l1-norm is imposed on the learned representation. The `depth' arises from the fact that multiple levels of dictionaries are learnt. The full formulation is solved in a greedy fashion, one layer at a time. To study the extent of usefulness of RDDL, we first benchmark it with two wellknown deep learning tools - the stacked denoising autoencoder and the deep belief network methods; experiments are carried out on benchmark deep learning datasets - MNIST, CIFAR-10 and SVHN. In all cases, our method yields the best results. Then the proposed method is used for learning representations of ECG data (containing arficacts) and for their classification using the MIT-BIH arrhythmia classification database. We compare it with traditional techniques as well as on deep learning tools. Our method yields the best results.","2161-4407","978-1-5090-6182-2","10.1109/IJCNN.2017.7966413","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966413","deep learning;dictionary learning;robust estimation;ECG classification","Dictionaries;Robustness;Machine learning;Cost function;Neural networks;Electrocardiography;Decoding","electrocardiography;greedy algorithms;learning (artificial intelligence);medical signal processing;signal classification;signal denoising;signal representation","robust greedy deep dictionary learning;ECG arrhythmia classification;deep learning method;RDDL;learning representations;biomedical signals;EEG;nonlinear dictionaries;data representation;standard Euclidean cost function;robust l1-norm cost function;sparse representation;stacked denoising autoencoder;deep belief network methods;MIT-BIH arrhythmia classification database","","21","","40","","3 Jul 2017","","","IEEE","IEEE Conferences"
"Semi-Supervised Speech Emotion Recognition With Ladder Networks","S. Parthasarathy; C. Busso","Erik Jonsson School of Engineering, and Computer Science, The University of Texas at Dallas, Dallas, TX, USA; Erik Jonsson School of Engineering & Computer Science, The University of Texas at Dallas, Dallas, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","5 Oct 2020","2020","28","","2697","2709","Speech emotion recognition (SER) systems find applications in various fields such as healthcare, education, and security and defense. A major drawback of these systems is their lack of generalization across different conditions. For example, systems that show superior performance on certain databases show poor performance when tested on other corpora. This problem can be solved by training models on large amounts of labeled data from the target domain, which is expensive and time-consuming. Another approach is to increase the generalization of the models. An effective way to achieve this goal is by regularizing the models through multitask learning (MTL), where auxiliary tasks are learned along with the primary task. These methods often require the use of labeled data which is computationally expensive to collect for emotion recognition (gender, speaker identity, age or other emotional descriptors). This study proposes the use of ladder networks for emotion recognition, which utilizes an unsupervised auxiliary task. The primary task is a regression problem to predict emotional attributes. The auxiliary task is the reconstruction of intermediate feature representations using a denoising autoencoder. This auxiliary task does not require labels so it is possible to train the framework in a semi-supervised fashion with abundant unlabeled data from the target domain. This study shows that the proposed approach creates a powerful framework for SER, achieving superior performance than fully supervised single-task learning (STL) and MTL baselines. We implement the approach with sentence-level or frame-level features, demonstrating the flexibility of our approach. Additionally, the generalization of the ladder networks is evaluated in cross-corpus settings using sentence-level features, obtaining important improvements. Compared to the STL baselines, the proposed approach achieves relative gains in concordance correlation coefficient (CCC) between 3.0% and 3.5% for within corpus evaluations, and between 16.1% and 74.1% for cross corpus evaluations, highlighting the power of the architecture.","2329-9304","","10.1109/TASLP.2020.3023632","National Science Foundation(grant numbers:CNS-1823166,IIS-1453781); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195799","Ladder networks;semi-supervised emotion recognition;speech emotion recognition","Task analysis;Emotion recognition;Training;Speech processing;Speech recognition;Databases;Computational modeling","emotion recognition;learning (artificial intelligence);regression analysis;signal denoising;speech recognition","concordance correlation coefficient;cross-corpus settings;denoising autoencoder;sentence-level features;frame-level features;single-task learning;abundant unlabeled data;semisupervised fashion;intermediate feature representations;emotional attributes;regression problem;unsupervised auxiliary task;emotional descriptors;MTL;multitask learning;target domain;training models;security;SER;ladder networks;semisupervised speech emotion recognition","","21","","58","IEEE","14 Sep 2020","","","IEEE","IEEE Journals"
"Construction of a Hierarchical Feature Enhancement Network and Its Application in Fault Recognition","Z. Chen; H. Lu; S. Tian; J. Qiu; T. Kamiya; S. Serikawa; L. Xu","Computer and Information College, Hohai University, Nanjing, China; Kyushu Institute of Technology, Kitakyushu, Japan; Computer and Information College, Hohai University, Nanjing, China; Computer and Information College, Hohai University, Nanjing, China; Kyushu Institute of Technology, Kitakyushu, Japan; Kyushu Institute of Technology, Kitakyushu, Japan; Computer and Information College, Hohai University, Nanjing, China","IEEE Transactions on Industrial Informatics","5 Apr 2021","2021","17","7","4827","4836","Industrial Internet of Things (IIoT) provide significant support for observing and controlling industrial machinery. In this article, a novel hierarchical feature enhancement network (HFEN) is proposed by combining signal processing and representation learning. The signal processing block extracts features with definite physical significance. Then, the representability of the physical features is improved by connecting stacked denoising autoencoders and squeeze-and-excitation networks. A novel two-stream architecture is designed for HFEN to fuse two types of features. Consequently, HFEN can extract features that can be analyzed for physical significance and that are also representative in terms of recognizable patterns. The experimental results prove that the performance of HFEN is satisfactory in terms of accuracy and efficiency when compared to other methods. Finally, this article also aims to demonstrate the potential of a new pairing that fuses the model- and data-driven strategies for IIoT.","1941-0050","","10.1109/TII.2020.3021688","National Key Research and Development Program of China Stem Cell and Translational Research(grant numbers:2018YFC1508603); National Natural Science Foundation of China(grant numbers:51979085,61671201); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186823","Deep learning;fault recognition;industrial Internet of Things;hierarchical feature enhancement network","Feature extraction;Vibrations;Machine learning;Signal processing;Wavelet transforms;Time-frequency analysis;Informatics","fault diagnosis;feature extraction;Internet of Things;learning (artificial intelligence);machinery;mechanical engineering computing;neural nets;sensor fusion;signal denoising","fault recognition;IIoT;industrial machinery;novel hierarchical feature enhancement network;HFEN;representation learning;signal processing block;squeeze-and-excitation networks;industrial Internet of Things;stacked denoising autoencoders","","21","","30","IEEE","4 Sep 2020","","","IEEE","IEEE Journals"
"Improved Techniques for Adversarial Discriminative Domain Adaptation","A. Chadha; Y. Andreopoulos","Electronic and Electrical Engineering Department, University College London, London, U.K.; Electronic and Electrical Engineering Department, University College London, London, U.K.","IEEE Transactions on Image Processing","23 Jan 2020","2020","29","","2622","2637","Adversarial discriminative domain adaptation (ADDA) is an efficient framework for unsupervised domain adaptation in image classification, where the source and target domains are assumed to have the same classes, but no labels are available for the target domain. While ADDA has already achieved better training efficiency and competitive accuracy on image classification in comparison to other adversarial based methods, we investigate whether we can improve its performance with a new framework and new loss formulations. Following the framework of semi-supervised GANs, we first extend the discriminator output over the source classes, in order to model the joint distribution over domain and task. We thus leverage on the distribution over the source encoder posteriors (which is fixed during adversarial training) and propose maximum mean discrepancy (MMD) and reconstruction-based loss functions for aligning the target encoder distribution to the source domain. We compare and provide a comprehensive analysis of how our framework and loss formulations extend over simple multi-class extensions of ADDA and other discriminative variants of semi-supervised GANs. In addition, we introduce various forms of regularization for stabilizing training, including treating the discriminator as a denoising autoencoder and regularizing the target encoder with source examples to reduce overfitting under a contraction mapping (i.e., when the target per-class distributions are contracting during alignment with the source). Finally, we validate our framework on standard datasets like MNIST, USPS, SVHN, MNIST-M and Office-31. We additionally examine how the proposed framework benefits recognition problems based on sensing modalities that lack training data. This is realized by introducing and evaluating on a neuromorphic vision sensing (NVS) sign language recognition dataset, where the source domain constitutes emulated neuromorphic spike events converted from conventional pixel-based video and the target domain is experimental (real) spike events from an NVS camera. Our results on all datasets show that our proposal is both simple and efficient, as it competes or outperforms the state-of-the-art in unsupervised domain adaptation, such as DIFA and MCDDA, whilst offering lower complexity than other recent adversarial methods.","1941-0042","","10.1109/TIP.2019.2950768","Engineering and Physical Sciences Research Council(grant numbers:EP/R025290/1,EP/P02243X/1,EP/R035342/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8892738","Adversarial methods;domain adaptation;neuromorphic vision sensing","Task analysis;Training;Gallium nitride;Sensors;Proposals;Cameras;Neuromorphics","image classification;image denoising;image reconstruction;neural nets;performance evaluation;sign language recognition;unsupervised learning;video signal processing","emulated neuromorphic spike events;conventional pixel-based video;NVS camera;NVS sign language recognition dataset;neuromorphic vision sensing;denoising autoencoder;maximum mean discrepancy;performance improvement;recognition problems;target per-class distributions;discriminative variants;multiclass extensions;source domain;target encoder distribution;reconstruction-based loss functions;adversarial training;source encoder posteriors;source classes;discriminator output;semisupervised GAN;loss formulations;adversarial based methods;target domain;image classification;unsupervised domain adaptation;ADDA;adversarial discriminative domain adaptation","","20","","48","IEEE","6 Nov 2019","","","IEEE","IEEE Journals"
"A novel wavelet-based model for EEG epileptic seizure detection using multi-context learning","Y. Yuan; G. Xun; K. Jia; A. Zhang","Beijing Laboratory of Advanced Information Networks, Beijing, China; Department of Computer Science and Engineering, State University of New York at Buffalo, NY, USA; Beijing Laboratory of Advanced Information Networks, Beijing, China; Department of Computer Science and Engineering, State University of New York at Buffalo, NY, USA","2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","18 Dec 2017","2017","","","694","699","Epileptic seizure detection has gained increasing attention in clinical therapy. Scalp electroencephalogram (EEG) analysis is a common way to capture brain abnormality for seizure onset detection. This paper presents a novel context-learning based approach using multi-feature fusion to compensate for incomplete description of single feature in epileptic EEG signals. First, EEG scalogram sequence is generated using wavelet transform to represent the time-frequency information. Second, three sets of EEG context features are unsupervisedly learned in parallel by using global principal component analysis (GPCA), stacked denoising autoencoders (SDAEs) and EEG embeddings, respectively. Finally, the multi-features are concatenated into a fixed-length feature vector for seizure classification. The experimental results conducted on two real EEG datasets demonstrate that the proposed cross-patient learning model is able to extract meaningful context features from different perspectives, and hence can detect the onset of epileptic seizure effectively.","","978-1-5090-3050-7","10.1109/BIBM.2017.8217737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8217737","","Electroencephalography;Feature extraction;Brain modeling;Training;Time-frequency analysis;Machine learning;Wavelet transforms","brain;electroencephalography;feature extraction;learning (artificial intelligence);medical signal detection;medical signal processing;principal component analysis;sensor fusion;signal classification;signal denoising;unsupervised learning;wavelet transforms","wavelet-based model;multifeature fusion;wavelet transform;stacked denoising autoencoders;EEG embeddings;real EEG datasets;epileptic seizure;EEG epileptic seizure detection;meaningful context features;cross-patient learning model;seizure classification;fixed-length feature vector;global principal component analysis;EEG context features;time-frequency information;EEG scalogram sequence;epileptic EEG signals;single feature;context-learning based approach;seizure onset detection;brain abnormality;scalp electroencephalogram analysis;clinical therapy;multicontext learning","","17","","25","","18 Dec 2017","","","IEEE","IEEE Conferences"
"A deep learning approach to fetal-ECG signal reconstruction","P. R. Muduli; R. R. Gunukula; A. Mukherjee","Department of Electrical Engineering, Indian Institute of Technology, Kharagpur, WB, India; Department of Electrical Engineering, Indian Institute of Technology, Kharagpur, WB, India; Department of Electrical Engineering, Indian Institute of Technology, Kharagpur, WB, India","2016 Twenty Second National Conference on Communication (NCC)","8 Sep 2016","2016","","","1","6","Fetal electrocardiogram (FECG) monitoring has become essential due to the current increase in the relative number of cardiac patients worldwide. This paper proposes to use a deep learning approach to compress/recover FECG signals, improving the computation speed in a telemonitoring system. The problem is analogous to the reconstruction of a non-sparse signal in compressive sensing (CS) framework. The architecture incorporates a non-linear mapping using a stacked denoising autoencoder (SDAE). The compression of the raw non-sparse FECG data takes place at the transmitter side using a deep neural network. After pre-training, the whole deep SDAE can be further fine tuned by the mini-batch gradient descent-based back-propagation algorithm. Although the training for SDAE is usually time-consuming, it does not affect the performance due to the one-time off-line training process. The real-time FECG reconstruction is faster due to a few matrix-vector multiplications at the receiver end. The simulations performed by employing standard non-invasive FECG databases shows promising results in terms of the reconstruction quality.","","978-1-5090-2361-5","10.1109/NCC.2016.7561206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7561206","","Training;Machine learning;Noise reduction;Computer architecture;Databases;Transforms;Sensors","compressed sensing;electrocardiography;encoding;learning (artificial intelligence);medical signal processing;signal denoising;signal reconstruction;signal restoration","deep learning approach;fetal-ECG signal reconstruction;FECG monitoring;cardiac patients;FECG signal compression;FECG signal recovery;telemonitoring system;nonsparse signal reconstruction;compressive sensing framework;CS framework;nonlinear mapping;stacked denoising autoencoder;SDAE;nonsparse FECG data;deep neural network;mini-batch gradient descent-based back-propagation algorithm;one-time off-line training process;real-time FECG reconstruction;matrix-vector multiplication;standard noninvasive FECG databases;reconstruction quality","","14","","24","","8 Sep 2016","","","IEEE","IEEE Conferences"
"Self-Powered Wireless Sensor for Fault Diagnosis of Wind Turbine Planetary Gearbox","L. Lu; Y. He; T. Wang; T. Shi; B. Li","School of Electrical and Automatic Engineering, Hefei University of Technology, Hefei, China; School of Electrical Engineering, Wuhan University, Wuhan, China; School of Electrical and Automatic Engineering, Hefei University of Technology, Hefei, China; School of Electrical and Automatic Engineering, Hefei University of Technology, Hefei, China; School of Electrical and Automatic Engineering, Hefei University of Technology, Hefei, China","IEEE Access","15 Jul 2019","2019","7","","87382","87395","This paper proposes a wind turbine planetary gearbox (PGB) fault diagnosis method based on a self-powered wireless sensor. The proposed wireless sensor, which consists of a piezoelectric energy harvester, a power management circuit, a microcontroller unit (MCU), a radio-frequency (RF) module, and an accelerometer, can acquire the vibration signals of wind turbine PGB by the accelerometer. The piezoelectric energy harvester utilizing vibration environment is optimized as a power supply for the proposed wireless sensor, including the MCU, RF module, and accelerometer. An ac–dc converter combined with a low-dropout voltage regulator is developed to provide stable dc voltage for the proposed wireless sensor. Stacked denoising autoencoder (SDAE) shows excellent performance in learning robust features from the noised signal. Thus, in this paper, the SDAE method is adopted to learn robust and distinguishable features from measured signals. Then, the least squares support vector machine (LSSVM) is employed to classify features extracted by the SDAE. Both the SDAE and LSSVM are optimized by quantum particle swarm optimization (QPSO). The experimental results show that the presented power supply can generate 3.3-V dc voltage, which ensures regular operation of the rest of the wireless sensor. The proposed wireless sensor can achieve a reliable communication distance of 40.8 m in the test environment. Furthermore, the SDAE approach and LSSVM show excellent performance in feature extraction and fault diagnosis, respectively. The experimental results indicate that the proposed method is effective in terms of fault diagnosis for the wind turbine PGB.","2169-3536","","10.1109/ACCESS.2019.2925426","National Natural Science Foundation of China(grant numbers:51577046); State Key Program of the National Natural Science Foundation of China(grant numbers:51637004); National Key Research and Development Plan—Important Scientific Instruments and Equipment Development—(grant numbers:2016YFF0102200); Equipment Research Project in Advance(grant numbers:41402040301); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8747487","Wind turbine;PGB;fault diagnosis;self-powered wireless sensor;SDAE;LSSVM;QPSO","Wireless sensor networks;Wireless communication;Vibrations;Fault diagnosis;Feature extraction;Wind turbines;Accelerometers","AC-DC power convertors;energy harvesting;fault diagnosis;feature extraction;gears;least squares approximations;microcontrollers;particle swarm optimisation;piezoelectric transducers;power engineering computing;signal denoising;support vector machines;vibrations;voltage regulators;wind turbines;wireless sensor networks","SDAE method;power supply;microcontroller unit;MCU;RF module;quantum particle swarm optimization;vibration signals measurement;QPSO;ac-dc converter;low-dropout voltage regulator;stacked denoising autoencoder;least squares support vector machine;LSSVM;reliable communication distance;feature extraction;stable dc voltage;wind turbine PGB;accelerometer;radio-frequency module;power management circuit;piezoelectric energy harvester;wind turbine planetary gearbox fault diagnosis method;self-powered wireless sensor;size 40.8 m","","12","","51","CCBY","27 Jun 2019","","","IEEE","IEEE Journals"
"Fault diagnosis for centrifugal pumps using deep learning and softmax regression","W. Zhao; Z. Wang; C. Lu; J. Ma; L. Li","School of Reliability and Systems Engineering, China and the Science & Technology on Reliability and Environmental Engineering Laboratory, Beijing, China; School of Reliability and Systems Engineering, China and the Science & Technology on Reliability and Environmental Engineering Laboratory, Beijing, China; School of Reliability and Systems Engineering, China and the Science & Technology on Reliability and Environmental Engineering Laboratory, Beijing, China; School of Reliability and Systems Engineering, China and the Science & Technology on Reliability and Environmental Engineering Laboratory, Beijing, China; School of Reliability and Systems Engineering, Beihang University, China","2016 12th World Congress on Intelligent Control and Automation (WCICA)","29 Sep 2016","2016","","","165","169","Fault diagnosis of centrifugal pumps is critical to lower its operating and maintenance costs. Due to the non-stationary and non-linear characteristics of vibration signals of centrifugal pumps, a large number of approaches for feature extraction and fault classification have been developed. However, these traditional methods spend too much time extracting features, reducing feature dimension and fusing different features. To resolve the issue, this paper presents an effective unsupervised self-learning method to achieve the fault diagnosis of centrifugal pumps, which uses deep learning method to adaptively extract fault features from non-stationary vibration signals and softmax regression model is used to identify possible failure modes automatically. In particular, the stacked denoising autoencoder (SDA) of deep learning models is selected to learn effective feature representations and we improved fault pattern classification robustness by corrupting the input data. The effectiveness and feasibility of the proposed method are validated by experiments in this paper.","","978-1-4673-8414-8","10.1109/WCICA.2016.7578673","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7578673","","Feature extraction;Pumps;Fault diagnosis;Noise reduction;Machine learning;Reliability engineering","costing;encoding;fault diagnosis;feature extraction;pattern classification;pumps;regression analysis;signal denoising;unsupervised learning;vibrational signal processing","fault diagnosis;centrifugal pumps;deep learning;softmax regression;operation cost;maintenance cost;nonstationary characteristic;nonlinear characteristic;vibration signals;feature extraction;fault classification;feature dimension reduction;unsupervised self-learning;stacked denoising autoencoder;SDA;fault pattern classification","","8","","13","","29 Sep 2016","","","IEEE","IEEE Conferences"
"Automatic Premature Ventricular Contractions Detection for Multi-Lead Electrocardiogram Signal","M. M. A. Rahhal; N. A. Ajlan; Y. Bazi; H. A. Hichri; T. Rabczuk","College of applied science, King Saud University; College of Computer and Information Sciences, King Saud University; College of Computer and Information Sciences, King Saud University; College of Computer and Information Sciences, King Saud University; College of Computer and Information Sciences, King Saud University","2018 IEEE International Conference on Electro/Information Technology (EIT)","21 Oct 2018","2018","","","0169","0173","In this paper, we propose an electrocardiogram (ECG) technique for the automatic detection of Premature Ventricular Contractions (PVC) based on multi-lead signals and on a deep learning architecture which is built using Stacked Denoising Autoencoders (SDAEs) networks. The proposed method consists of two main stages; feature learning and classification. In the first stage, we learn a new feature representation from data using SDAEs. Regarding the classification, we add a softmax regression layer on the top of the resulting hidden representation layer yielding a deep neural network (DNN). The proposed method fuses the results of several ECG leads (up to 12) in order to increase the detection accuracy. In the experiments, we use INCART database to test the proposed DNN multi-lead method. The obtained results are 98.6%, 91.4%, and 97.7% respectively for overall accuracy (OA), average sensitivity (Se), and average positive productivity (Pp).","2154-0373","978-1-5386-5398-2","10.1109/EIT.2018.8500197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8500197","","Electrocardiography;Heart rate variability;Databases;Heart beat;Electrodes;Training;Neural networks","electrocardiography;encoding;feature extraction;learning (artificial intelligence);medical signal detection;medical signal processing;neural nets;signal classification;signal denoising;signal representation","multilead electrocardiogram signal;electrocardiogram technique;deep learning architecture;SDAEs;feature learning;feature representation;softmax regression layer;deep neural network;ECG leads;DNN multilead method;automatic premature ventricular contractions detection;stacked denoising autoencoders networks;PVC;feature classification;hidden representation layer;INCART database;overall accuracy;average sensitivity;average positive productivity","","6","","30","","21 Oct 2018","","","IEEE","IEEE Conferences"
"Handwritten digit recognition using sparse deep architectures","R. Walid; A. Lasfar",LASTIMI EST Sale; LASTIMI EST Sale,"2014 9th International Conference on Intelligent Systems: Theories and Applications (SITA-14)","8 Jul 2014","2014","","","1","6","A lot of research has been lately focusing on deep neural networks as an alternative to shallow ones. The added advantage among many, is the automated feature extraction of pattern from data. These models have been applied successfully to many tasks, including handwritten digit recognition, where they lead the state of the art performance. In this paper we apply a sparse deep belief network and a denoising autoencoder to a new dataset proposed in the ICDAR 2013 handwritten digit competition, which is a challenging alternative in multiple aspects to many popular digit datasets. Additionally we raise some difficulties met during modelling. We finally put the spot on some elements that could improve the performance for subsequent attempts in improving models' accuracy.","","978-1-4799-3567-3","10.1109/SITA.2014.6847284","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6847284","","Training;Noise reduction;Vectors;Training data;Feature extraction;Computational modeling;Image coding","belief networks;feature extraction;handwritten character recognition;image coding;image denoising;learning (artificial intelligence);neural nets;object recognition","handwritten digit recognition;sparse deep architectures;deep neural networks;sparse deep belief network;denoising autoencoder;ICDAR 2013 handwritten digit competition;intelligent pattern recognition;machine learning;automated feature extraction","","6","","31","","8 Jul 2014","","","IEEE","IEEE Conferences"
"Robust Feature Extraction and Ensemble Classification Against Cyber-Physical Attacks in the Smart Grid","C. Hu; J. Yan; C. Wang","Concordia Institute for Information Systems Engineering (CIISE), Concordia University Montréal, Québec, Canada; Concordia Institute for Information Systems Engineering (CIISE), Concordia University Montréal, Québec, Canada; Concordia Institute for Information Systems Engineering (CIISE), Concordia University Montréal, Québec, Canada","2019 IEEE Electrical Power and Energy Conference (EPEC)","23 Apr 2020","2019","","","1","6","Intrusion detection systems (IDS) are crucial in threats monitoring for the cyber-physical security of electrical power and energy systems in the smart grid with increasing machine-to-machine communication. However, the multi-sourced, voluminous, correlated, and often noise-contained data, which record various concurring cyber and physical events, are posing significant challenges to the accurate distinction by IDS among events of inadvertent and malignant natures. To tackle such challenges, this paper proposes a robust end-to-end framework based on Stacked Denoising Autoencoder (SDAE) and Ensemble Machine Learning to extract new noise and attack-informed feature sets from cyber-physical system data and incorporate different sources of information for reliable event classification. The proposed framework first leverages SDAE to create lower-dimensional features that allow reconstruction of a noise-free input from noise-corrupted perturbations. By combining attack and noisy inputs, we extracted new, automatically-engineered features that can preserve and present information on normal, fault, and attack events against different synthetic but realistic noises for better classification. Considering the heterogeneous nature of the inputs, which are composed of PMU measurements, system logs, and IDS alerts, we further introduced ensemble learning-based multi-classifier classification with the Extreme Gradient Boosting (XGBoost) technique to classify the samples based on the SDAE-extracted features. Normalization and oversampling were also both performed to improve the uniformity and balance of the data. On a realistic dataset of 37 sub-types of normal, fault, and attack collected from co-simulations on a hardware-in-the-loop (HIL) testbed security testbed, the results have shown that the proposed SDAE+XGBoost solution achieves over 90% classification accuracy with the SDAE features and ensemble classifiers, an effective 8% increase over the state-of-the-art.","2381-2842","978-1-7281-3406-2","10.1109/EPEC47565.2019.9074827","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9074827","","Feature extraction;Training;Smart grids;Robustness;Linear programming;Security;Noise reduction","feature extraction;learning (artificial intelligence);pattern classification;power engineering computing;security of data;signal denoising;smart power grids","lower-dimensional features;noise-free input;noise-corrupted perturbations;automatically-engineered features;system logs;IDS;ensemble learning-based multiclassifier classification;extreme gradient boosting technique;SDAE-extracted features;SDAE+XGBoost solution achieves;SDAE features;ensemble classifiers;robust feature extraction;cyber-physical attacks;smart grid;intrusion detection systems;cyber-physical security;electrical power;machine-to-machine communication;noise-contained data;inadvertent natures;malignant natures;stacked denoising autoencoder;ensemble machine learning;attack-informed feature sets;cyber-physical system data;ensemble classification","","4","","27","","23 Apr 2020","","","IEEE","IEEE Conferences"
"MEED: An Unsupervised Multi-Environment Event Detector for Non-Intrusive Load Monitoring","D. Jorde; M. Kahl; H. -A. Jacobsen","Chair for Application and Middleware Systems, Technische Universität München, Germany; Chair for Application and Middleware Systems, Technische Universität München, Germany; Chair for Application and Middleware Systems, Technische Universität München, Germany","2019 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm)","25 Nov 2019","2019","","","1","6","The accurate detection of transitions between appliance states in electrical signals is the fundamental step that numerous energy conserving applications, such as Non-Intrusive Load Monitoring, rely on. So far, domain experts define rules and patterns to detect changes of appliance states and to extract detailed consumption information of individual appliances subsequently. Such event detectors are specifically designed for certain environments and need to be tediously adapted for new ones, as they require in-depth expert knowledge of the environment. To overcome this limitation, we propose a new unsupervised, multi-environment event detector, called MEED, that is based on a bidirectional recurrent denoising autoencoder. The performance of MEED is evaluated by comparing it to two state-of-the-art algorithms on two publicly available datasets from different environments. The results show that MEED improves the current state of the art and outperforms the reference algorithms on a residential (BLUED) and an office environment (BLOND) dataset while being trained and used fully unsupervised in the heterogeneous environments.","","978-1-5386-8099-5","10.1109/SmartGridComm.2019.8909729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8909729","","Event detection;Detectors;Measurement;Microsoft Windows;Clustering algorithms;Smart grids;Approximation algorithms","acoustic signal processing;domestic appliances;energy conservation;power engineering computing;power system measurement;recurrent neural nets;signal denoising;signal detection;unsupervised learning","appliance states;electrical signals;energy conservation;nonintrusive load monitoring;MEED;bidirectional recurrent denoising autoencoder;office environment dataset;heterogeneous environments;unsupervised multienvironment event detector;BLOND dataset;BLUE dataset","","4","","31","","25 Nov 2019","","","IEEE","IEEE Conferences"
"Improving the Intelligibility of Speech for Simulated Electric and Acoustic Stimulation Using Fully Convolutional Neural Networks","N. Y. -H. Wang; H. -L. S. Wang; T. -W. Wang; S. -W. Fu; X. Lu; H. -M. Wang; Y. Tsao","Department of Audiology and Speech-Language Pathology, Asia University, Taichung, Taiwan; Department of Special Education, National Taiwan Normal University, Taipei, Taiwan; Research Centre for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Research Centre for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; National Institute of Information and Communications Technology, Tokyo, Japan; Academia Sinica, Institute of Information Science, Taipei, Taiwan; Research Centre for Information Technology Innovation, Academia Sinica, Taipei, Taiwan","IEEE Transactions on Neural Systems and Rehabilitation Engineering","26 Feb 2021","2021","29","","184","195","Combined electric and acoustic stimulation (EAS) has demonstrated better speech recognition than conventional cochlear implant (CI) and yielded satisfactory performance under quiet conditions. However, when noise signals are involved, both the electric signal and the acoustic signal may be distorted, thereby resulting in poor recognition performance. To suppress noise effects, speech enhancement (SE) is a necessary unit in EAS devices. Recently, a time-domain speech enhancement algorithm based on the fully convolutional neural networks (FCN) with a short-time objective intelligibility (STOI)-based objective function (termed FCN(S) in short) has received increasing attention due to its simple structure and effectiveness of restoring clean speech signals from noisy counterparts. With evidence showing the benefits of FCN(S) for normal speech, this study sets out to assess its ability to improve the intelligibility of EAS simulated speech. Objective evaluations and listening tests were conducted to examine the performance of FCN(S) in improving the speech intelligibility of normal and vocoded speech in noisy environments. The experimental results show that, compared with the traditional minimum-mean square-error SE method and the deep denoising autoencoder SE method, FCN(S) can obtain better gain in the speech intelligibility for normal as well as vocoded speech. This study, being the first to evaluate deep learning SE approaches for EAS, confirms that FCN(S) is an effective SE approach that may potentially be integrated into an EAS processor to benefit users in noisy environments.","1558-0210","","10.1109/TNSRE.2020.3042655","Ministry of Science and Technology (MOST), Taiwan(grant numbers:108-2628-E-001-002-MY3,109-2221-E-001-022,109-2410-H-468-019-MY2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9281097","Electric and acoustic stimulation (EAS);cochlear implant;fully convolutional neural network;speech enhancement","Noise measurement;Speech enhancement;Speech recognition;Acoustics;Noise reduction;Linear programming;Convolutional neural networks","convolutional neural nets;learning (artificial intelligence);least mean squares methods;signal denoising;speech coding;speech enhancement;speech intelligibility;speech recognition;vocoders","noisy environments;minimum-mean square-error SE method;deep denoising autoencoder SE method;speech intelligibility;normal as well as vocoded speech;effective SE approach;EAS processor;simulated electric;acoustic stimulation;speech recognition;conventional cochlear implant;noise signals;electric signal;acoustic signal;poor recognition performance;noise effects;EAS devices;time-domain speech enhancement algorithm;fully convolutional neural networks with a short-time objective intelligibility-based objective function;clean speech signals;normal speech;objective evaluations","Acoustic Stimulation;Cochlear Implants;Electric Stimulation;Humans;Neural Networks, Computer;Speech Intelligibility;Speech Perception","4","","97","CCBY","4 Dec 2020","","","IEEE","IEEE Journals"
"Gradient-guided filtering of depth maps using deep neural networks","C. A. Ochotorena; C. N. Ochotorena; E. Dadios",Western University; Western University; NA,"2015 International Conference on Humanoid, Nanotechnology, Information Technology,Communication and Control, Environment and Management (HNICEM)","28 Jan 2016","2015","","","1","8","Image filtering has long been an area of interest in computer vision applications. It may be used in applications where noise is prominent or when certain features need to be enhanced. While single-image filtering techniques are well-established in literature, the introduction of additional information can further improve the quality of filtering. Guided filtering allows for the use of additional signals to enhance the filtering process. However, many of these techniques operate on natural images and are not suited for certain classes of images such as depth maps. In this work, we propose a filter that is specifically tuned to operate on noisy depth maps. To guide the filtering process, known image gradients are inputted into the system. Given the complex nature of this input, a five-layer neural network built using stacked denoising autoencoders was used to implement a black-box filter. Testing with the proposed system shows the benefits of using the deep network for depth map filtering.","","978-1-5090-0360-0","10.1109/HNICEM.2015.7393265","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7393265","neural network;deep network;filtering;depth map","Cameras;Estimation;Apertures;Noise measurement;Image color analysis;Conferences","computer vision;image coding;image denoising;image filtering;neural nets","gradient-guided filtering;deep-neural networks;computer vision application;single-image filtering techniques;filtering quality improvement;filtering process enhancement;natural images;noisy depth maps;image gradients;five-layer neural network;stacked denoising autoencoders;black-box filter;depth map filtering","","4","","38","","28 Jan 2016","","","IEEE","IEEE Conferences"
"Using Latent Representations of Muscle Activation Patterns to Mitigate Myoelectric Interface Noise","Y. Teh; L. J. Hargrove","Department of Biomedical Engineering, Regenstein Center for Bionic Medicine at the Shirley Ryan AbilityLab, Northwestern University, Chicago, IL, USA; Department of Physical Medicine and Rehabilitation and Biomedical Engineering, Regenstein Center for Bionic Medicine, Shirley Ryan AbilityLab, Northwestern University, Chicago, IL, USA","2021 10th International IEEE/EMBS Conference on Neural Engineering (NER)","2 Jun 2021","2021","","","1148","1151","Myoelectric controllers for upper limb prostheses are susceptible to signal disturbances across practical conditions. In particular, electrode liftoff or wire breakage introduce interface noise that, even if only present in a single channel, is detrimental to controller performance. We trained a supervised denoising variational autoencoder to learn a low-dimensional subspace underlying muscle activation patterns that was robust to noise in single EMG channels. Two latent space classifiers, which used the deep learning model, and two conventional LDA-based classifiers were used to classify wrist and hand gestures from clean and synthetically corrupted EMG signals. The baseline LDA classifier, trained on clean data only, suffered a marked increase in errors when evaluated on the corrupted data. The second LDA classifier, trained on clean and corrupted data, improved robustness to noise. Regardless, both latent space methods significantly outperformed both LDA methods in classifying clean and corrupted data. These results highlight that interface noise has adverse effects on current pattern recognition controllers but that deep learning inspired latent space classifiers can mitigate these effects and achieve highly accurate movement classification.","1948-3554","978-1-7281-4337-8","10.1109/NER49283.2021.9441396","National Institutes of Health NIH(grant numbers:R01HD094861); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9441396","prosthesis;myoelectric control;pattern recognition;neural networks;latent representation","Wrist;Deep learning;Noise reduction;Wires;Aerospace electronics;Muscles;Electromyography","biomechanics;electromyography;feature extraction;image denoising;learning (artificial intelligence);medical control systems;medical signal processing;muscle;pattern classification;pattern recognition;prosthetics","latent representations;mitigate myoelectric interface noise;myoelectric controllers;upper limb prostheses;practical conditions;electrode liftoff;single channel;controller performance;supervised denoising variational autoencoder;low-dimensional subspace underlying muscle activation patterns;single EMG channels;latent space classifiers;deep learning model;conventional LDA-based classifiers;wrist;hand gestures;clean corrupted EMG signals;synthetically corrupted EMG signals;baseline LDA classifier;clean data;corrupted data;improved robustness;latent space methods;current pattern recognition controllers","","3","","18","","2 Jun 2021","","","IEEE","IEEE Conferences"
"Maximum Contrastive Networks for multi-channel SSVEP detection","S. S. Embrandiri; M. Ramasubba Reddy","Bio-Medical Engineering Group, Indian Institute of Technology, Madras, India; Bio-Medical Engineering Group, Indian Institute of Technology, Madras, India","2015 7th International IEEE/EMBS Conference on Neural Engineering (NER)","2 Jul 2015","2015","","","992","995","The performance of steady-state visual-evoked potential (SSVEP)-based Brain-Computer Interfaces (BCIs) have shown great improvement with multi-channel classification techniques. These methods fundamentally involve developing spatial filters that linearly combine the Electroencephalography (EEG) channels so as to improve SSVEP strength and suppress noise. This paper proposes a nonlinear spatial filter using Maximum Contrastive Networks (MCNs). Essentially, MCNs are deep networks trained to maximize the contrast between signal and noise components in EEG. In other words, the network attempts to enhance the signal-to-noise ratio (SNR) of the SSVEPs in EEG. Networks of varying configurations and sigmoid functions are experimented on the EEG recordings. After random initialization, the network is pre-trained using a denoising autoencoder. Then the network is trained by back-propagation to maximize contrast/SNR. The results obtained from the MCNs are compared with the classifiers based on Minimum Energy Combination (MEC) and Canonical Correlation Analysis (CCA). In this initial study, results show that MCNs significantly improve performance over the MEC and CCA based classifiers across all sessions for the trained subject. The cube-root sigmoid MCNs proved to be more accurate compared to the hyperbolic tangent MCNs. Since significantly higher accuracies were attained for lower EEG time segments, subject-specific trained MCNs with optimal configuration likely possess a large potential for online SSVEP detection.","1948-3554","978-1-4673-6389-1","10.1109/NER.2015.7146793","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7146793","","Electroencephalography;Signal to noise ratio;Accuracy;Electrodes;Training;Steady-state","backpropagation;electroencephalography;medical signal processing;nonlinear filters;signal classification;signal denoising;spatial filters;visual evoked potentials","multichannel SSVEP detection;steady-state visual-evoked potential-based brain-computer interfaces;multichannel classification techniques;nonlinear spatial filter;electroencephalography channels;noise suppression;signal-to-noise ratio;EEG recordings;sigmoid functions;denoising autoencoder;back-propagation;cube-root sigmoid maximum contrastive networks;subject-specific trained maximum contrastive networks","","3","","10","","2 Jul 2015","","","IEEE","IEEE Conferences"
"Transfer learning for brain decoding using deep architectures","B. Velioglu; F. T. Y. Vural; F. T. Yarman Vural","Computer Engineering, Middle East Technical University, Ankara, Turkey; Computer Engineering, Middle East Technical University, Ankara, Turkey; Computer Engineering, Middle East Technical University, Ankara, Turkey","2017 IEEE 16th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC)","16 Nov 2017","2017","","","65","70","Is there a general representation of the information content of human brain, which can be extracted from the functional magnetic resonance imaging (fMRI) data? Is it possible to learn this representation automatically from big data sets by unsupervised learning methods? Is it possible to transfer this representation to learn and decode a set of cognitive states in other fMRI data sets? This study addresses partial answers to the above questions by using transfer learning in deep architectures. First, a hierarchical representation for fMRI data is learned from a large data set in Human Connectome Project (HCP) by a 3-layered stacked denoising autoencoder (SDAE). Then, the learned representations are used to train and recognize the cognitive states recorded by a relatively small data set of one-back repetition detection experiment. Results show that, it is possible to learn a general representation and transfer the learned representation of an fMRI data set to another dataset for brain decoding problem. The learned representation has a better discriminative power compared to the Pearson correlation features. Results also show us that deep neural networks transfer representations better than factor models commonly used in pattern recognition and neuroscience literature.","","978-1-5386-0771-8","10.1109/ICCI-CC.2017.8109731","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8109731","Deep Neural Network;Transfer Learning;Feature Learning;Brain Decoding","Correlation;Feature extraction;Decoding;Noise reduction;Indexes","biomedical MRI;brain;cognition;feature extraction;image denoising;learning (artificial intelligence);medical image processing;neural nets;neurophysiology;pattern recognition;unsupervised learning","Human Connectome Project;stacked denoising autoencoder;one-back repetition detection experiment;Pearson correlation features;deep neural network transfer representations;pattern recognition;neuroscience literature;unsupervised learning methods;big data sets;functional magnetic resonance imaging data;brain decoding problem;fMRI data set;cognitive states;deep architectures;transfer learning","","2","","15","","16 Nov 2017","","","IEEE","IEEE Conferences"
"Improving the performance of hearing aids in noisy environments based on deep learning technology","Y. -H. Lai; W. -Z. Zheng; S. -T. Tang; S. -H. Fang; W. -H. Liao; Y. Tsao","National Yang-Ming University, Taipei, TW; Yuan Ze University, Chung-Li, Taoyuan, TW; Ming Chuan University, Taipei, TW; Yuan Ze University, Chung-Li, Taoyuan, TW; National Yang-Ming University, Taipei, TW; Academia Sinica, Taipei, Taipei, TW","2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","28 Oct 2018","2018","","","404","408","The performance of a deep-learning-based speech enhancement (SE) technology for hearing aid users, called a deep denoising autoencoder (DDAE), was investigated. The hearing-aid speech perception index (HASPI) and the hearing- aid sound quality index (HASQI), which are two well-known evaluation metrics for speech intelligibility and quality, were used to evaluate the performance of the DDAE SE approach in two typical high-frequency hearing loss (HFHL) audiograms. Our experimental results show that the DDAE SE approach yields higher intelligibility and quality scores than two classical SE approaches. These results suggest that a deep-learning-based SE method could be used to improve speech intelligibility and quality for hearing aid users in noisy environments.","1558-4615","978-1-5386-3646-6","10.1109/EMBC.2018.8512277","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8512277","","Noise measurement;Speech enhancement;Hearing aids;Signal to noise ratio;Auditory system;Training","hearing;hearing aids;learning (artificial intelligence);signal denoising;speech coding;speech enhancement;speech intelligibility","speech intelligibility;speech enhancement technology;speech quality;DDAE SE approach;high-frequency hearing loss audiograms;hearing- aid sound quality index;hearing-aid speech perception index;deep denoising autoencoder;deep learning technology;noisy environments;hearing aid users","Auditory Perception;Deep Learning;Hearing Aids;Hearing Loss, Sensorineural;Hearing Tests;Humans;Sound;Speech Intelligibility;Speech Perception","2","","40","","28 Oct 2018","","","IEEE","IEEE Conferences"
"Subjective Feedback-based Neural Network Pruning for Speech Enhancement","F. Ye; Y. Tsao; F. Chen","Department of Electrical and Electronic Engineering, Southern University of Science and Technology; Research Center for Information Technology Innovation, Academic Sinica; Department of Electrical and Electronic Engineering, Southern University of Science and Technology","2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","5 Mar 2020","2019","","","673","677","Speech enhancement based on neural networks provides performance superior to that of conventional algorithms. However, the network may suffer owing to redundant parameters, which demands large unnecessary computation and power consumption. This work aimed to prune the large network by removing extra neurons and connections while maintaining speech enhancement performance. Iterative network pruning combined with network retraining was employed to compress the network based on the weight magnitude of neurons and connections. This pruning method was evaluated using a deep denoising autoencoder neural network, which was trained to enhance speech perception under nonstationary noise interference. Word correct rate was utilized as the subjective intelligibility feedback to evaluate the understanding of noisy speech enhanced by the sparse network. Results showed that the iterative pruning method combined with retraining could reduce 50% of the parameters without significantly affecting the speech enhancement performance, which was superior to the two baseline conditions of direct network pruning with network retraining and iterative network pruning without network retraining. Finally, an optimized network pruning method was proposed to implement the iterative network pruning and retraining in a greedy repetition manner, yielding a maximum pruning ratio of 80%.","2640-0103","978-1-7281-3248-8","10.1109/APSIPAASC47483.2019.9023330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9023330","","Speech enhancement;Iterative methods;Noise measurement;Speech recognition;Biological neural networks;Indexes","feedback;neural nets;signal denoising;speech enhancement","speech enhancement performance;direct network pruning;network retraining;iterative network pruning;optimized network pruning method;maximum pruning ratio;subjective feedback-based neural network pruning;neural networks;deep denoising autoencoder neural network;speech perception;noisy speech;sparse network;iterative pruning method","","2","","24","","5 Mar 2020","","","IEEE","IEEE Conferences"
"SDA-based neural network approach to digit classification","T. Williams; R. Li","Department of Electrical & Computer Engineering, North Carolina A&T State University, Greensboro, NC, USA; Department of Electrical & Computer Engineering, North Carolina A&T State University, Greensboro, NC, USA","SoutheastCon 2016","9 Jul 2016","2016","","","1","6","Image classification and object recognition are important issues in machine learning. With the increased usage of the internet and smart-based applications, image classification has become more important in various social, financial, and domestic spheres. Deep learning algorithms have proven useful and powerful, having successfully classified many types of images, objects, etc. This paper uses a type of deep neural network, stacked denoising autoencoders (SDA), to classify the handwritten digits in the MNIST database. The method proposed transforms the images into the wavelet domain, for faster, more efficient processing, as compared to the spatial domain. Furthermore, the low frequency and high frequency components separately provide pertinent feature details learned by the SDA to correctly classify each digit. The fusion of the learned low and high frequency features, and processing the combined feature mapping results in an increased detection accuracy. Compared to traditional (spatial) SDA and other classification algorithms, experimental results of this method show an increase in speed, efficiency, and accuracy in image classification and object recognition.","1558-058X","978-1-5090-2246-5","10.1109/SECON.2016.7506768","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7506768","SDA;Neural Network;Deep Learning;Wavelet;Classification;Fusion;Machine Learning;Object Recognition;Digits","Machine learning;Noise reduction;Training;Classification algorithms;Wavelet domain;Neural networks;Image classification","feature extraction;handwritten character recognition;image classification;image denoising;image fusion;learning (artificial intelligence);neural nets;object recognition","SDA-based neural network approach;stacked denoising autoencoders;handwritten digit classification;image classification;object recognition;machine learning;deep neural network;MNIST database;spatial domain;feature fusion;feature mapping","","2","1","15","","9 Jul 2016","","","IEEE","IEEE Conferences"
"Toward Generating Synthetic CT Volumes using a 3D-Conditional Generative Adversarial Network","J. Mangalagiri; D. Chapman; A. Gangopadhyay; Y. Yesha; J. Galita; S. Menon; Y. Yesha; B. Saboury; M. Morris; P. Nguyen","Baltimore County, University of Maryland, Baltimore, MD, USA; Baltimore County, University of Maryland, Baltimore, MD, USA; Baltimore County, University of Maryland, Baltimore, MD, USA; Baltimore County, University of Maryland, Baltimore, MD, USA; Baltimore County, University of Maryland, Baltimore, MD, USA; Baltimore County, University of Maryland, Baltimore, MD, USA; Baltimore County, University of Maryland, Baltimore, MD, USA; National Institutes of Health Clinical Center, Bethesda, MD, USA; Networking Health, Glen Burnie, MD, USA; OpenKneck Inc, Halethorpe, MD, USA","2020 International Conference on Computational Science and Computational Intelligence (CSCI)","23 Jun 2021","2020","","","858","862","Network (cGAN) architecture that is capable of generating 3D Computed Tomography scans in voxels from noisy and/or pixelated approximations and with the potential to generate full synthetic 3D scan volumes. We believe conditional cGAN to be a tractable approach to generate 3D CT volumes, even though the problem of generating full resolution deep fakes is presently impractical due to GPU memory limitations. We present results for autoencoder, denoising, and depixelating tasks which are trained and tested on two novel COVID19 CT datasets. Our evaluation metrics, Peak Signal to Noise ratio (PSNR) range from 12.53 - 46.46 dB, and range from 0.89 to 1.","","978-1-7281-7624-6","10.1109/CSCI51800.2020.00160","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9458065","networks (GANs);synthesizing 3D CT volumes","Image quality;COVID-19;Solid modeling;Three-dimensional displays;PSNR;Computed tomography;Computer architecture","computerised tomography;image denoising;image resolution;medical image processing;neural nets","depixelating tasks;autoencoder tasks;denoising tasks;GPU memory;synthetic 3D CT scan volumes;COVID19 CT datasets;3D computed tomography scans;3D-conditional generative adversarial network","","1","","21","","23 Jun 2021","","","IEEE","IEEE Conferences"
"Linear Approximation of Deep Neural Networks for Efficient Inference on Video Data","B. Rueckauer; S. -C. Liu","Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland","2019 27th European Signal Processing Conference (EUSIPCO)","18 Nov 2019","2019","","","1","5","Sequential data such as video are characterized by spatio-temporal correlations. As of yet, few deep learning algorithms exploit them to decrease the often massive cost during inference. This work leverages correlations in video data to linearize part of a deep neural network and thus reduce its size and computational cost. Drawing upon the simplicity of the typically used rectifier activation function, we replace the ReLU function by dynamically updating masks. The resulting layer stack is a simple chain of matrix multiplications and bias additions, that can be contracted into a single weight matrix and bias vector. Inference then reduces to an affine transformation of the input sequence with these contracted parameters. We show that the method is akin to approximating the neural network with a first-order Taylor expansion around a dynamically updating reference point. The proposed algorithm is evaluated on a denoising convolutional autoencoder.","2076-1465","978-9-0827-9703-9","10.23919/EUSIPCO.2019.8902997","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902997","Deep neural networks;video;sequential data;linearization;compression","Neurons;Biological neural networks;Taylor series;Convolution;Noise reduction;Task analysis;Correlation","approximation theory;image denoising;inference mechanisms;learning (artificial intelligence);matrix multiplication;neural nets;transfer functions;vectors;video signal processing","sequential data;spatio-temporal correlations;deep learning algorithms;video data;deep neural network;rectifier activation function;ReLU function;single weight matrix;bias vector;dynamically updating reference point;linear approximation;matrix multiplications;first-order Taylor expansion;denoising convolutional autoencoder","","1","","15","","18 Nov 2019","","","IEEE","IEEE Conferences"
"Connecting deep neural networks with symbolic knowledge","A. Kumar; T. Oates","Department of Computer Science and Electrical Engineering, University of Maryland Baltimore County, Baltimore, Maryland; Department of Computer Science and Electrical Engineering, University of Maryland Baltimore County, Baltimore, Maryland","2017 International Joint Conference on Neural Networks (IJCNN)","3 Jul 2017","2017","","","3601","3608","Neural networks have attracted significant interest in recent years due to their exceptional performance in various domains ranging from natural language processing to image identification and classification. Modern deep neural networks demonstrate state-of-the-art results in complex tasks such as epileptic seizure detection [1] and time series classification [2]. The internal architecture of these networks, in terms of learned representations, still remains opaque. This research addresses the first step towards the long term goal of constructing a bidirectional connection between raw input data and symbolic representations. In this research, we examined whether a denoising autoencoder can internally find correlated principal features from input images and their symbolic representations that can be used to generate one from the other. Our results indicate that using symbolic representations along with the raw inputs generates better reconstructions. Our network was able to construct the symbolic representations from the input as well as input instances from their symbolic representations.","2161-4407","978-1-5090-6182-2","10.1109/IJCNN.2017.7966309","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966309","","Neural networks;Loss measurement;Image reconstruction;Training;Entropy;Noise reduction;Image color analysis","image classification;image denoising;image representation;neural nets;time series","deep neural networks;symbolic knowledge;natural language processing;image identification;image classification;epileptic seizure detection;time series classification;denoising autoencoder;symbolic representations","","1","","17","","3 Jul 2017","","","IEEE","IEEE Conferences"
"Ball Screw Health Indicator Construction with Limited Monitoring Data and Health Assessment Based on Global Context Network","P. Xia; Y. Huang; D. Xiao; C. Liu; L. Shi","State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, PR China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, PR China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, PR China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, PR China; Shanghai SmartState Technology Co., Ltd, Shanghai, PR China","2021 IEEE International Conference on Sensing, Diagnostics, Prognostics, and Control (SDPC)","19 Oct 2021","2021","","","168","173","Ball screw is one of the most important transmission mechanisms in manufacturing. Constructing effective health indicator to represent the health condition of ball screw and assessing health state are of great significance to reducing unnecessary cost. However, researches on ball screw health indicator and health assessment are limited. Most health indicator construction methods for rotating machine require manual feature extraction process and feature selection or reduction process using monitoring data at different health states, which are difficult to obtain for ball screw in real applications. In this paper, a deep learning-based ball screw health indicator construction method with limited monitoring data and a health assessment method are proposed. The health indicator construction model is trained using partially monitored sensor data based on denoising convolutional autoencoder (DCAE) and maximum mean discrepancy (MMD). DCAE is used to extract feature representations from monitoring signals. Then feature distribution discrepancy measured by MMD is mapped to HI. An end-to-end health state assessment method based on global context network (GCNet) is also proposed. Experiments show the proposed method achieved better assessment accuracy.","","978-1-6654-4976-2","10.1109/SDPC52933.2021.9563363","National Natural Science Foundation of China(grant numbers:51975356); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9563363","ball screw;health indicator;health assessment;deep learning","Costs;Rotating machines;Noise reduction;Manuals;Feature extraction;Data models;Mechanical products","ball screws;condition monitoring;convolutional neural nets;deep learning (artificial intelligence);electric machines;feature extraction;feature selection;mechanical engineering computing;signal denoising;signal representation","health condition;feature selection;feature representation extraction;deep learning;limited monitoring data;partially monitored sensor data;global context network;assessment accuracy;end-to-end health state assessment;ball screw health indicator construction;transmission mechanisms;manufacturing;rotating machine;denoising convolutional autoencoder;DCAE;maximum mean discrepancy;MMD;feature distribution discrepancy;GCNet","","1","","21","IEEE","19 Oct 2021","","","IEEE","IEEE Conferences"
"Visual Terrain Classification Methods for Mobile Robots Using Hybrid Coding Architecture","H. Wu; W. Zhang; B. Li; Y. Sun; D. Duan; P. Chen","Institute of Medical Support Technology, Academy of Military Sciences of Chinese PLA, Tianjin, China; Institute of Medical Support Technology, Academy of Military Sciences of Chinese PLA, Tianjin, China; National Innovation Institute of Defense Technology, Academy of Military Sciences of Chinese PLA, Beijing, China; Zhonghuan Information College, Tianjin University of technology, Tianjin, China; Institute of Medical Support Technology, Academy of Military Sciences of Chinese PLA, Tianjin, China; Institute of Medical Support Technology, Academy of Military Sciences of Chinese PLA, Tianjin, China","2019 IEEE 4th International Conference on Image, Vision and Computing (ICIVC)","6 Feb 2020","2019","","","17","22","Visual terrain classification can provide crucial and important information for motion control and autonomous navigation for mobile robots in complex terrain environment, becoming an important but challenging task. This paper uses a novel hybrid coding architecture, Deep Filter Banks (DFB), combining stacked denoising sparse autoencoder (SDSAE) and Fisher Vector (FV) for visual terrain classification. Then, we propose a terrain dataset, termed ""Terrain8"", which is the first publicly available benchmark for visual terrain classification. This dataset contains 2400 terrain images, covering 8 terrain classes with 300 images in each class. Our method achieves superior performance on the Terrain8 dataset. Moreover, we design the framework to deal with terrain videos and carry out the field experiments in arc-legged mobile robot. The field experimental results also indicate the effectiveness of our proposed methods.","","978-1-7281-2325-7","10.1109/ICIVC47709.2019.8981092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8981092","visual terrain classification;terrain dataset;deep filter banks;fisher vector;arc-legged mobile robot","","data visualisation;feature extraction;image classification;image denoising;image filtering;image texture;mobile robots;motion control;neural nets;terrain mapping;video signal processing","terrain videos;arc-legged mobile robot;complex terrain environment;hybrid coding architecture;terrain images;visual terrain classification methods;motion control;autonomous navigation;deep filter banks;stacked denoising sparse autoencoder;Fisher vector","","1","","27","","6 Feb 2020","","","IEEE","IEEE Conferences"
"Proxy Individual Positioning via IEEE 802.11 Monitor Mode and Fine-Tuned Analytics","M. You; S. Park; S. -H. Lee; T. Yang","Dept. of Computer Engineering, Chungbuk National University, Cheongju, Republic of Korea; Dept. of Computer Engineering, Chungbuk National University, Cheongju, Republic of Korea; Dept. of Management Information Systems, Chungbuk National University, Cheongju, Republic of Korea; Dept. of Computer Engineering, Chungnam National University, Daejeon, Republic of Korea","2019 IEEE 90th Vehicular Technology Conference (VTC2019-Fall)","7 Nov 2019","2019","","","1","5","Indoor positioning of individuals is one of the most important technologies in smart home applications for user-customized support. The indoor positioning is typically fulfilled through radio signal strength indicators (RSSIs) of referred devices with specific media such as Wi-Fi access points (APs) and Wi-Fi station devices (STAs). So, the capability of typical positioning schemes is highly close to the signal acquisition environments of such media. In other words, since STAs frequently fall into a sleep mode to save the battery power and some data acquisition technologies are based on advertising intervals, the amount of RSSIs of referring devices could not be gathered enough to detect correct positions of individuals. In this paper, a novel individual positioning mechanism, called PIPing (Proxy Individual Positioning), is come up with. The PIPing mechanism carries out proxy signal acquisition via IEEE 802.11 monitor mode devices to overcome such restrictions. In addition, PIPing includes machine learning based signal data analytics to provide high reliable results for positioning. Based on the proof-of-concept prototype, PIPing can acquire much higher amount of RSSI data than existing manners, about 330% increment; the reliability of positioning for a home with seven rooms shows 96.4% via the support vector machine (SVM) and 96.5% by the multilayer perceptron (MLP) with autoencoder denoising to tune up signals.","2577-2465","978-1-7281-1220-6","10.1109/VTCFall.2019.8891177","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891177","","Monitoring;IEEE 802.11 Standard;Support vector machines;Wireless fidelity;Mobile handsets;Servers;Probes","data acquisition;indoor navigation;indoor radio;learning (artificial intelligence);multilayer perceptrons;RSSI;signal denoising;signal detection;support vector machines;telecommunication network reliability;telecommunication power management;wireless LAN","data acquisition technologies;Proxy Individual Positioning;PIPing mechanism;proxy signal acquisition;IEEE 802.11 monitor mode devices;signal data analytics;indoor positioning;smart home applications;radio signal strength indicators;Wi-Fi access points;signal acquisition;individual positioning mechanism;RSSI;support vector machine;SVM;multilayer perceptron;MLP;autoencoder denoising","","1","","14","IEEE","7 Nov 2019","","","IEEE","IEEE Conferences"
"A locally linear embbeding based postfiltering approach for speech enhancement","Y. -C. Wu; H. -T. Hwang; S. -S. Wang; C. -C. Hsu; Y. -H. Lai; Y. Tsao; H. -M. Wang","Institute of Information Science, Taipei, Taiwan; Institute of Information Science, Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Institute of Information Science, Taipei, Taiwan; Department of Electrical Engineering, Yuan Ze University, Taoyuan, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Institute of Information Science, Taipei, Taiwan","2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","19 Jun 2017","2017","","","5555","5559","This paper presents a novel postfiltering approach based on the locally linear embedding (LLE) algorithm for speech enchantment (SE). The aim of the proposed LLE-based postfiltering approach is to further remove the residual noise components from the SE-processed speech signals through a spectral conversion process, thereby increasing the signal-to-noise ratio (SNR) and speech quality. The proposed postfiltering approach consists of two phases. In the offline phase, paired SE-processed and clean speech exemplars are prepared for dictionary construction. In the online phase, the LLE algorithm is adopted to convert the SE-processed speech signals to the clean ones. The present study integrates the LLE-based postfiltering approach with a deep denoising autoencoder (DDAE) SE method, which has been confirmed to provide outstanding capability for noise reduction. Experimental results show that the proposed postfiltering approach can notably enhance the DDAE-based SE processed speech signals in different noise types and SNR levels.","2379-190X","978-1-5090-4117-6","10.1109/ICASSP.2017.7953219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7953219","Speech enhancement;deep neural network;locally linear embedding;postfiltering","Speech;Dictionaries;Speech enhancement;Noise measurement;Signal to noise ratio;Noise reduction;Automobiles","filtering theory;signal denoising;spectral analysis;speech enhancement","noise reduction;DDAE SE method;deep denoising autoencoder;dictionary construction;clean speech exemplars;paired SE-processed speech exemplars;speech quality;SNR;signal-to-noise ratio;spectral conversion process;SE-processed speech signals;residual noise components removal;LLE-based postfiltering approach;locally linear embedding algorithm;speech enhancement","","","","20","","19 Jun 2017","","","IEEE","IEEE Conferences"
"Learning Long-Term Invariant Features for Vision-Based Localization","N. C. Mithun; C. Simons; R. Casey; S. Hilligardt; A. Roy-Chowdhury","University of California, Riverside, CA; University of California, Riverside, CA; VWGoA Electronics Research Lab, Belmont, CA; VWGoA Electronics Research Lab, Belmont, CA; University of California, Riverside, CA","2018 IEEE Winter Conference on Applications of Computer Vision (WACV)","7 May 2018","2018","","","2038","2047","Constructing a feature representation invariant to certain types of geometric and photometric transformations is of significant importance in many computer vision applications. In spite of significant effort, developing invariant feature representations remains a challenging problem. Most of the existing representations often fail to satisfy the longterm repeatability requirements of specific applications like vision-based localization, applications whose domain includes significant, non-uniform illumination and environmental changes. To these ends, we explore the use of natural image pairs (i.e. images captured of the same location but at different times) as an additional source of supervision to generate an improved feature representation for the task of vision-based localization. Specifically, we resort to training deep denoising autoencoder, with CNN feature representation of one image in the pair being treated as a noisy version of the other. The resulting system thereby learns localization features which are both discriminative and invariant to illumination and environmental changes. In experiments tailored towards vision-based localization, features generated using the proposed method produced higher matching rates than state-of-the-art image features.","","978-1-5386-4886-5","10.1109/WACV.2018.00225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354329","","Feature extraction;Task analysis;Training;Visualization;Lighting;Noise reduction;Databases","computer vision;feature extraction;feedforward neural nets;image classification;image denoising;image matching;image representation;learning (artificial intelligence)","long-term invariant features;vision-based localization;geometric transformations;photometric transformations;computer vision applications;invariant feature representations;nonuniform illumination;environmental changes;natural image pairs;improved feature representation;deep denoising autoencoder;CNN feature representation;localization features;long-term repeatability requirements","","","","55","","7 May 2018","","","IEEE","IEEE Conferences"
"Deep-Learning-Based Signal Enhancement of Low-Resolution Accelerometer for Fall Detection Systems","K. -C. Liu; K. -H. Hung; C. -Y. Hsieh; H. -Y. Huang; C. -T. Chan; Y. Tsao","Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Bachelor’s Program in Medical Informatics and Innovative Applications, Fu Jen Catholic University, New Taipei City, Taiwan; Department of Biomedical Engineering, National Yang Ming Chiao Tung University, Taipei, Taiwan; Department of Biomedical Engineering, National Yang Ming Chiao Tung University, Taipei, Taiwan; Department of Electrical Engineering, Chung Yuan Christian University, Taoyuan, Taiwan","IEEE Transactions on Cognitive and Developmental Systems","8 Sep 2022","2022","14","3","1270","1281","In the last two decades, fall detection (FD) systems have been developed as a popular assistive technology. To support long-term FD services, various power-saving strategies have been implemented. Among them, a reduced sampling rate is a common approach for an energy-efficient system in the real world. However, the performance of FD systems is diminished owing to low-resolution (LR) accelerometer signals. To improve the detection accuracy with LR accelerometer signals, several technical challenges must be considered, including mismatch of effective features and the degradation effects. In this work, a deep-learning-based accelerometer signal enhancement (ASE) model is proposed as a front-end processor to help typical LR-FD systems achieve better detection performance. The proposed ASE model based on a deep denoising convolutional autoencoder architecture reconstructs high-resolution (HR) signals from the LR signals by learning the relationship between the LR and HR signals. The results show that the FD system using support vector machine (SVM) and the proposed ASE model at an extremely low sampling rate (sampling rate < 2 Hz) achieved 97.34% and 90.52% accuracies in the SisFall and FallAllD data sets, respectively, while those without ASE models only achieved 95.92% and 87.47% accuracies in the SisFall and FallAllD data sets, respectively. The results also demonstrate that the proposed ASE mode can be suitably combined with deep-learning-based FD systems.","2379-8939","","10.1109/TCDS.2021.3116228","Ministry of Science and Technology, Taiwan(grant numbers:MOST 109-2221-E-001-022,108-2628-E-001-002-MY3,109-2634-F-008-006); Academia Sinica(grant numbers:AS-CDA-106-M04,AS-GC-109-05); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9552232","Accelerometer signal enhancement (ASE);deep learning (DL) approach;low-resolution fall detection (LR-FD);wearable sensors","Accelerometers;Power demand;Fall detection;Batteries;Signal resolution;Feature extraction;Degradation","accelerometers;assisted living;convolutional neural nets;deep learning (artificial intelligence);fall detection;signal denoising;signal reconstruction;signal sampling;support vector machines","FD services;FD system;LR accelerometer signals;ASE;support vector machine;fall detection systems;assistive technology;accelerometer signal enhancement;deep denoising convolutional autoencoder architecture;signal reconstruction;deepl earning;frequency 2.0 Hz","","","","47","CCBY","29 Sep 2021","","","IEEE","IEEE Journals"
"Bolstering Adversarial Robustness with Latent Disparity Regularization","D. Schwartz; G. Ditzler","Department of Electrical and Computer Engineering, University of Arizona, Tucson, United States of America; Department of Electrical and Computer Engineering, University of Arizona, Tucson, United States of America","2021 International Joint Conference on Neural Networks (IJCNN)","20 Sep 2021","2021","","","1","8","Recent research has revealed that neural networks and other machine learning models are vulnerable to adversarial attacks that aim to subvert their predictions' integrity or privacy by adding a small calculated perturbation to inputs. Further, the adversary can significantly degrade the performance of the model. The number and severity of attacks continues to grow. However, a dearth of techniques robustly defends machine learning models in a computationally inexpensive way. Against this background, we propose an adversarially robust training procedure and objective function for arbitrary neural network architectures. Robustness of neural networks against adversarial attacks on integrity is achieved by augmentation of a novel regularization term. This regularizer penalizes the discrepancy between the representations induced in hidden layers by benign and adversarial data. We benchmark our regularization approach on the Fashion-Mnist and Cifar-10 datasets. Our model is benchmarked against three state-of-the-art defense methods, namely: (i) regularization to the largest eigenvalue in the Fisher information matrix of the activity of the terminal layer, (ii) a higher-level representation guided denoising autoencoder (trained with adversarial examples), and (iii) training an otherwise undefended model on data distorted by additive white Gaussian noise. Our experiments show that the proposed regularizer provides significant improvements in adversarial robustness over both an undefended baseline model as well as the same model defended with other techniques. This result is observed over several adversarial budgets with only a small (but seemingly unavoidable) decline in benign test accuracy.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9533815","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9533815","Adversarial Defenses;Fast Gradient Sign Method;Regularization","Training;Privacy;Computational modeling;Perturbation methods;Neural networks;Machine learning;Benchmark testing","AWGN;data privacy;eigenvalues and eigenfunctions;image denoising;image representation;learning (artificial intelligence);neural nets","additive white Gaussian noise;terminal layer;Fisher information matrix;eigenvalue;Cifar-10 dataset;Fashion-Mnist dataset;privacy;higher-level representation guided denoising autoencoder;adversarial data;benign data;regularization term;arbitrary neural network architectures;adversarially robust training procedure;machine learning models;adversarial attacks;latent disparity regularization;undefended baseline model;adversarial robustness","","","","34","","20 Sep 2021","","","IEEE","IEEE Conferences"
"A Novel Two-stage Prediction Model to Classify Functional Connectivity for Brain Disease Diagnosis","G. Xu; Y. Liang","Faculty of Information Technology College of Computer Science and Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology College of Computer Science and Technology, Beijing University of Technology, Beijing, China","2021 IEEE 4th International Conference on Computer and Communication Engineering Technology (CCET)","30 Sep 2021","2021","","","63","68","Neuroscience studies have demonstrated that inherent interactions in human brain are associated with various brain diseases. The functional connectivity (FC) analysis in the resting-state functional magnetic resonance imaging (rs-fMRI) has attracted increasing attention. Recently, the application of deep learning algorithms has shown great potential in exploring the diagnosis biomarker for brain disease. However, the high dimensionality and small sample size properties of the FC patterns usually restrict the training of deep learning models and limit the model generalization performance. To solve this problem, this paper proposed a novel prediction model with a two-stage design to extract and classify FC features for the brain diseases diagnosis. Our model employed a flexible configuration that contained a deep learning-based FC feature extraction stage followed by a separate classification stage. In the first stage, stacked sparse denoising autoencoders were employed to extract and learn the abstract feature representations of the initial FC patterns with both unsupervised and supervised learning steps. In the second stage, the learnt features were used to train a separate simple classifier for brain disease classification. We conducted experiments on a large-scale fMRI dataset to construct FC patterns and distinguish autism patients from healthy controls. Results showed that our two-stage model outperformed the competing classification methods and showed robust generality for different brain nodes parcellation. Our study indicated that this flexible two-stage model design can further improve the classification performance and provide a promising approach for the computer-aided diagnosis of brain disorders.","","978-1-6654-3890-2","10.1109/CCET52649.2021.9544424","Beijing Natural Science Foundation(grant numbers:4204089); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9544424","brain diseases diagnosis;resting-state functional magnetic resonance imaging;functional connectivity;two-stage classification mode;machine learning","Training;Deep learning;Computational modeling;Biological system modeling;Predictive models;Functional magnetic resonance imaging;Brain modeling","biomedical MRI;brain;deep learning (artificial intelligence);diseases;feature extraction;image classification;image denoising;image representation;medical disorders;medical image processing;neurophysiology;unsupervised learning","autism patients;stacked sparse denoising autoencoders;rs-fMRI;neuroscience;brain nodes parcellation;brain disease diagnosis;brain disorders;computer-aided diagnosis;brain disease classification;unsupervised learning;deep learning-based FC feature extraction stage;resting-state functional magnetic resonance imaging;functional connectivity;human brain","","","","20","","30 Sep 2021","","","IEEE","IEEE Conferences"
"DeepSign: Deep learning for automatic malware signature generation and classification","O. E. David; N. S. Netanyahu","Dept. of Computer Science, Bar-Ilan University, Ramat-Gan, Israel; Dept. of Computer Science, Bar-Ilan University, Ramat-Gan, Israel","2015 International Joint Conference on Neural Networks (IJCNN)","1 Oct 2015","2015","","","1","8","This paper presents a novel deep learning based method for automatic malware signature generation and classification. The method uses a deep belief network (DBN), implemented with a deep stack of denoising autoencoders, generating an invariant compact representation of the malware behavior. While conventional signature and token based methods for malware detection do not detect a majority of new variants for existing malware, the results presented in this paper show that signatures generated by the DBN allow for an accurate classification of new malware variants. Using a dataset containing hundreds of variants for several major malware families, our method achieves 98.6% classification accuracy using the signatures generated by the DBN. The presented method is completely agnostic to the type of malware behavior that is logged (e.g., API calls and their parameters, registry entries, websites and ports accessed, etc.), and can use any raw input from a sandbox to successfully train the deep neural network which is used to generate malware signatures.","2161-4407","978-1-4799-1960-4","10.1109/IJCNN.2015.7280815","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280815","Deep Learning;Deep Belief Network;Autoencoders;Malware;Automatic Signature Generation","Training;Malware","belief networks;invasive software;learning (artificial intelligence);neural nets;pattern classification","automatic malware signature generation;automatic malware signature classification;deep learning;deep belief network;deep stack denoising autoencoders;malware behavior invariant compact representation;DBN;malware families;deep neural network;deep unsupervised neural network;DeepSign","","103","4","30","","1 Oct 2015","","","IEEE","IEEE Conferences"
"VIGAN: Missing view imputation with generative adversarial networks","C. Shang; A. Palmer; J. Sun; K. -S. Chen; J. Lu; J. Bi","Department of Computer Science and Engineering, University of Connecticut, Storrs, CT, USA; Department of Computer Science and Engineering, University of Connecticut, Storrs, CT, USA; Department of Computer Science and Engineering, University of Connecticut, Storrs, CT, USA; Department of Computer Science and Engineering, University of Connecticut, Storrs, CT, USA; Department of Computer Science and Engineering, University of Connecticut, Storrs, CT, USA; Department of Computer Science and Engineering, University of Connecticut, Storrs, CT, USA","2017 IEEE International Conference on Big Data (Big Data)","15 Jan 2018","2017","","","766","775","In an era when big data are becoming the norm, there is less concern with the quantity but more with the quality and completeness of the data. In many disciplines, data are collected from heterogeneous sources, resulting in multi-view or multi-modal datasets. The missing data problem has been challenging to address in multi-view data analysis. Especially, when certain samples miss an entire view of data, it creates the missing view problem. Classic multiple imputations or matrix completion methods are hardly effective here when no information can be based on in the specific view to impute data for such samples. The commonly-used simple method of removing samples with a missing view can dramatically reduce sample size, thus diminishing the statistical power of a subsequent analysis. In this paper, we propose a novel approach for view imputation via generative adversarial networks (GANs), which we name by VIGAN. This approach first treats each view as a separate domain and identifies domain-to-domain mappings via a GAN using randomly-sampled data from each view, and then employs a multi-modal denoising autoencoder (DAE) to reconstruct the missing view from the GAN outputs based on paired data across the views. Then, by optimizing the GAN and DAE jointly, our model enables the knowledge integration for domain mappings and view correspondences to effectively recover the missing view. Empirical results on benchmark datasets validate the VIGAN approach by comparing against the state of the art. The evaluation of VIGAN in a genetic study of substance use disorders further proves the effectiveness and usability of this approach in life science.","","978-1-5386-2715-0","10.1109/BigData.2017.8257992","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8257992","missing data;missing view;generative adversarial networks;autoencoder;domain mapping;cycle-consistent","Gallium nitride;Data models;Generators;Noise reduction;Image reconstruction;Training;Matrix decomposition","Big Data;data analysis;learning (artificial intelligence);neural nets","multiview data analysis;missing view problem;matrix completion methods;generative adversarial networks;GAN;VIGAN;multimodal denoising autoencoder;paired data;big data;multimodal datasets;missing data problem;missing view imputation;heterogeneous sources;multiview datasets;classic multiple imputations;sample size reduction;subsequent analysis;domain-to-domain mappings;knowledge integration;benchmark datasets","","30","","41","","15 Jan 2018","","","IEEE","IEEE Conferences"
"Deep Matrix Factorization for Trust-Aware Recommendation in Social Networks","L. Wan; F. Xia; X. Kong; C. -H. Hsu; R. Huang; J. Ma","Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, School of Software, Dalian University of Technology, Dalian, China; School of Engineering, IT and Physical Sciences, Federation University Australia, Ballarat, VIC, Australia; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; Department of Medical Research, China Medical University Hospital, China Medical University, Taichung, Taiwan; Faculty of Computer and Information Sciences, Hosei University, Tokyo, Japan; Faculty of Computer and Information Sciences, Hosei University, Tokyo, Japan","IEEE Transactions on Network Science and Engineering","17 Mar 2021","2021","8","1","511","528","Recent years have witnessed remarkable information overload in online social networks, and social network based approaches for recommender systems have been widely studied. The trust information in social networks among users is an important factor for improving recommendation performance. Many successful recommendation tasks are treated as the matrix factorization problems. However, the prediction performance of matrix factorization based methods largely depends on the matrixes initialization of users and items. To address this challenge, we develop a novel trust-aware approach based on deep learning to alleviate the initialization dependence. First, we propose two deep matrix factorization (DMF) techniques, i.e., linear DMF and non-linear DMF to extract features from the user-item rating matrix for improving the initialization accuracy. The trust relationship is integrated into the DMF model according to the preference similarity and the derivations of users on items. Second, we exploit deep marginalized Denoising Autoencoder (Deep-MDAE) to extract the latent representation in the hidden layer from the trust relationship matrix to approximate the user factor matrix factorized from the user-item rating matrix. The community regularization is integrated in the joint optimization function to take neighbours’ effects into consideration. The results of DMF are applied to initialize the updating variables of Deep-MDAE in order to further improve the recommendation performance. Finally, we validate that the proposed approach outperforms state-of-the-art baselines for recommendation, especially for the cold-start users.","2327-4697","","10.1109/TNSE.2020.3044035","National Natural Science Foundation of China(grant numbers:61 801 076,61 872 054,62 072 409); Fundamental Research Funds for the Central Universities(grant numbers:DUT20JC29); Natural Science Foundation of Zhejiang Province(grant numbers:LR21F020003); Fundamental Research Funds for the Provincial Universities of Zhejiang(grant numbers:RF-B2020001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9291430","Autoencoder;deep learning;matrix factorization;social networks;trust relationship.","Collaboration;Recommender systems;Deep learning;Social networking (online);Sparse matrices;Predictive models;Probabilistic logic","learning (artificial intelligence);matrix decomposition;recommender systems;social networking (online)","trust-aware recommendation;social network;remarkable information overload;online social networks;recommender systems;trust information;successful recommendation tasks;matrix factorization problems;prediction performance;matrixes initialization;trust-aware approach;deep learning;initialization dependence;deep matrix factorization techniques;user-item rating matrix;initialization accuracy;DMF model;deep marginalized Denoising Autoencoder;Deep-MDAE;trust relationship matrix;approximate the user factor matrix;cold-start users","","8","","74","CCBY","11 Dec 2020","","","IEEE","IEEE Journals"
"A Novel CT-Based Descriptors for Precise Diagnosis of Pulmonary Nodules","A. Shaffie; A. Soliman; H. A. Khalifeh; F. Taher; M. Ghazal; N. Dunlap; A. Elmaghraby; R. Keynton; A. El-Baz","Bioengineering Department, University of Louisville, Louisville, KY, USA; Bioengineering Department, University of Louisville, Louisville, KY, USA; Chemical Engineering Department, Abu Dhabi University, Abu Dhabi, United Arab Emirates; College of Technological Innovation, Zayed University, Dubai, United Arab Emirates; Department of Electrical and Computer Engineering, Abu Dhabi University, Abu Dhabi, United Arab Emirates; Department of Radiation Oncology, University of Louisville, Louisville, KY, USA; Computer Engineering and Computer Science Department, University of Louisville, Louisville, KY, USA; Bioengineering Department, University of Louisville, Louisville, KY, USA; Bioengineering Department, University of Louisville, Louisville, KY, USA","2019 IEEE International Conference on Image Processing (ICIP)","26 Aug 2019","2019","","","1400","1404","Early diagnosis of pulmonary nodules is critical for lung cancer clinical management. In this paper, a novel framework for pulmonary nodule diagnosis, using descriptors extracted from single computed tomography (CT) scan, is introduced. This framework combines appearance and shape descriptors to give an indication of the nodule prior growth rate, which is the key point for diagnosis of lung nodules. Resolved Ambiguity Local Binary Pattern and 7th Order Markov Gibbs Random Field are developed to describe the nodule appearance without neglecting spatial information. Spherical harmonics expansion and some primitive geometric features are utilized to describe how the nodule shape is complicated. Ultimately, all descriptors are combined using denoising autoencoder to classify the nodule, whether malignant or benign. Training, testing, and parameter tuning of all framework modules are done using a set of 727 nodules extracted from the Lung Image Database Consortium (LIDC) dataset. The proposed system diagnosis accuracy, sensitivity, and specificity were 94.95%, 94.62%, 95.20% respectively, all of which show that our system has promise to reach the accepted clinical accuracy threshold.","2381-8549","978-1-5386-6249-6","10.1109/ICIP.2019.8803036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8803036","Computer Aided Diagnosis;RALBP;MGRF;Computer Tomography;Spherical Harmonics;Autoencoder","Lung;Cancer;Shape;Three-dimensional displays;Computed tomography;Classification algorithms;Solids","cancer;computerised tomography;feature extraction;image classification;lung;Markov processes;medical image processing","LIDC dataset;autoencoder denoising;primitive geometric features;resolved ambiguity local binary pattern;novel CT-based descriptors;7th order Markov Gibbs random field;lung image database consortium dataset;lung nodule diagnosis;nodule prior growth rate;single computed tomography scan;pulmonary nodule diagnosis;lung cancer clinical management","","2","","21","","26 Aug 2019","","","IEEE","IEEE Conferences"
"Height Prediction and Refinement From Aerial Images With Semantic and Geometric Guidance","M. Elhousni; Z. Zhang; X. Huang","Department of Electrical and Computer Engineering, Worcester Polytechnic Institute (WPI), Worcester, MA, USA; Department of Electrical and Computer Engineering, Worcester Polytechnic Institute (WPI), Worcester, MA, USA; Department of Electrical and Computer Engineering, Worcester Polytechnic Institute (WPI), Worcester, MA, USA","IEEE Access","1 Nov 2021","2021","9","","145638","145647","Deep learning provides a powerful new approach to many computer vision tasks. Height prediction from aerial images is one of those tasks which benefited greatly from the deployment of deep learning, thus replacing traditional multi-view geometry techniques. This manuscript proposes a two-stage approach to solve this task, where the first stage is a multi-task neural network whose main branch is used to predict the height map resulting from a single RGB aerial input image, while being augmented with semantic and geometric information from two additional branches. The second stage is a refinement step, where a denoising autoencoder is used to correct some errors in the first stage prediction results, producing a more accurate height map. Experiments on two publicly available datasets show that the proposed method is able to outperform state-of-the-art computer vision based and deep learning-based height prediction methods. Code is publicly available at: https://github.com/melhousni/DSMNet.","2169-3536","","10.1109/ACCESS.2021.3122894","U.S. NSF(grant numbers:CCF-2006738); The MathWorks Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585603","UAV;height;DSM;CNN;autoencoders;multi-task","Semantics;Task analysis;Noise reduction;Deep learning;Three-dimensional displays;Pipelines;Image reconstruction","computer vision;deep learning (artificial intelligence);geometry;geophysical image processing;image colour analysis","geometric guidance;computer vision tasks;multiview geometry techniques;two-stage approach;multitask neural network;single RGB aerial input image;geometric information;refinement step;accurate height map;deep learning-based height prediction methods;denoising autoencoder","","","","47","CCBY","26 Oct 2021","","","IEEE","IEEE Journals"
"Self-Supervised Learning and Multi-Task Pre-Training Based Single-Channel Acoustic Denoising","Y. Li; Y. Sun; S. M. Naqvi","Intelligent Sensing and Communications Group, School of Engineering, Newcastle University, Newcastle Upon Tyne, U.K.; Big Data Institute, University of Oxford, Oxford, U.K.; Intelligent Sensing and Communications Group, School of Engineering, Newcastle University, Newcastle Upon Tyne, U.K.","2022 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)","13 Oct 2022","2022","","","1","5","In self-supervised learning-based single-channel speech denoising problem, it is challenging to reduce the gap between the denoising performance on the estimated and target speech signals with existed pre-tasks. In this paper, we propose a multi-task pre-training method to improve the speech denoising performance within self-supervised learning. In the proposed pre-training autoencoder (PAE), only a very limited set of unpaired and unseen clean speech signals are required to learn speech latent representations. Meanwhile, to solve the limitation of existing single pre-task, the proposed masking module exploits the dereverberated mask and estimated ratio mask to denoise the mixture as the new pre-task. The downstream task autoencoder (DAE) utilizes unlabeled and unseen reverberant mixtures to generate the estimated mixtures. The DAE is trained to share a latent representation with the clean examples from the learned representation in the PAE. Experimental results on a benchmark dataset demonstrate that the proposed method outperforms the state-of-the-art approaches.","","978-1-6654-6026-2","10.1109/MFI55806.2022.9913855","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9913855","","Noise reduction;Self-supervised learning;Benchmark testing;Multitasking;Acoustics;Task analysis;Intelligent systems","","","","","","23","IEEE","13 Oct 2022","","","IEEE","IEEE Conferences"
"DLTSR: A Deep Learning Framework for Recommendations of Long-Tail Web Services","B. Bai; Y. Fan; W. Tan; J. Zhang","Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; IBM Thomas J. Watson Research Center, New York; Department of Electrical and Computer Engineering, Carnegie Mellon University, Moffett Field","IEEE Transactions on Services Computing","6 Feb 2020","2020","13","1","73","85","With the growing popularity of web services, more and more developers are composing multiple services into mashups. Developers show an increasing interest in non-popular services (i.e., long-tail ones), however, there are very scarce studies trying to address the long-tail web service recommendation problem. The major challenges for recommending long-tail services accurately include severe sparsity of historical usage data and unsatisfactory quality of description content. In this paper, we propose to build a deep learning framework to address these challenges and perform accurate long-tail recommendations. To tackle the problem of unsatisfactory quality of description content, we use stacked denoising autoencoders (SDAE) to perform feature extraction. Additionally, we impose the usage records in hot services as a regularization of the encoding output of SDAE, to provide feedback to content extraction. To address the sparsity of historical usage data, we learn the patterns of developers' preference instead of modeling individual services. Our experimental results on a real-world dataset demonstrate that, with such joint autoencoder based feature representation and content-usage learning framework, the proposed algorithm outperforms the state-of-the-art baselines significantly.","1939-1374","","10.1109/TSC.2017.2681666","National Natural Science Foundation of China(grant numbers:61673230); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7876831","Deep learning;mashup creation;service recommendation;long-tail","Mashups;Machine learning;Noise reduction;Ecosystems;Neural networks;Data mining","feature extraction;learning (artificial intelligence);query processing;recommender systems;service-oriented architecture;Web services","deep learning;long-tail Web service recommendation problem;content-usage learning;autoencoder based feature representation;description content quality;stacked denoising autoencoders;feature extraction;content extraction;service-oriented computing;Internet of Service;IoS;mashup query","","37","","37","IEEE","13 Mar 2017","","","IEEE","IEEE Journals"
"Linked Source and Target Domain Subspace Feature Transfer Learning -- Exemplified by Speech Emotion Recognition","J. Deng; Z. Zhang; B. Schuller","Machine Intelligence & Signal Processing Group, Technische Universitat, München, Germany; Machine Intelligence & Signal Processing Group, Technische Universitat, München, Germany; Machine Intelligence & Signal Processing Group, Technische Universitat, München, Germany","2014 22nd International Conference on Pattern Recognition","6 Dec 2014","2014","","","761","766","The typical inherent mismatch between the test and training corpora and by that between 'target' and 'source' sets usually leads to significant performance downgrades. To cope with this, this study presents a feature transfer learning method using Denoising Auto encoders (DAEs) to build high order subspaces of the source and target corpora, where features in the source domain are transferred to the target domain by an additional neural network. To exemplify effectiveness of our approach, we select the INTERSPEECH Emotion Challenge's FAU Aibo Emotion Corpus as target corpus and further two publicly available databases as source corpora for extensive and reproducible evaluation. The experimental results show that our method significantly improves over the baseline performance and outperforms today's state-of-the-art domain adaptation methods.","1051-4651","978-1-4799-5209-0","10.1109/ICPR.2014.141","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976851","feature transfer learning;denoising autoencoders;cross-corpus;domain adaptation;speech emotion recognition","Training;Speech;Databases;Artificial neural networks;Emotion recognition;Noise reduction","emotion recognition;neural nets;speech processing","target domain subspace feature transfer learning;linked source;speech emotion recognition;denoising auto encoders;DAE;target corpora;source corpora;neural network;INTERSPEECH emotion challenge FAU Aibo emotion corpus","","17","1","25","","6 Dec 2014","","","IEEE","IEEE Conferences"
"Learning discriminative low-rank representation for image classification","J. Li; H. Chang; J. Yang","School of Computer Science and Technology, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Technology, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Technology, Nanjing University of Science and Technology, Nanjing, China","2014 International Joint Conference on Neural Networks (IJCNN)","4 Sep 2014","2014","","","313","318","Low-rank representation (LRR) efficiently performs the subspace segmentation and feature extraction from corrupted data. However, there are three disadvantages in existing LRR techniques. First, the inference algorithm of LRR (as a generative model) is computationally expensive. Second, LRR ignores the discriminative information for image classification. Third, although the robust representation is implemented by recovering the low-rank components and the sparse noises, it has been limited due to the constrained assumption that noises is sparse. To solve these problems, and inspired by Denoising Autoencoders (DAE) and Contractive Autoencoders (CAE), this paper proposes a discriminative low-rank representations framework (DLRR) for image classification. We directly learn a discriminative projection dictionary that results in fast inference. Simultaneously, DLRR can obtain a robust representation from any corrupted input. Our implementation of DLRR achieves state-of-the-art results on artificial dataset and dataset of Olivetti Face Patches.","2161-4407","978-1-4799-1484-5","10.1109/IJCNN.2014.6889401","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6889401","","Dictionaries;Robustness;Face;Training;Sparse matrices;Jacobian matrices;Principal component analysis","feature extraction;image classification;image representation;image segmentation;learning (artificial intelligence)","discriminative low-rank representation learning;image classification;subspace segmentation;feature extraction;LRR technique;generative model;denoising autoencoders;DAE;contractive autoencoders;CAE;discriminative projection dictionary;Olivetti face patches","","8","","28","","4 Sep 2014","","","IEEE","IEEE Conferences"
"Combining End-to-End and Adversarial Training for Low-Resource Speech Recognition","J. Drexler; J. Glass","Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA","2018 IEEE Spoken Language Technology Workshop (SLT)","14 Feb 2019","2018","","","361","368","In this paper, we develop an end-to-end automatic speech recognition (ASR) model designed for a common low-resource scenario: no pronunciation dictionary or phonemic transcripts, very limited transcribed speech, and much larger non-parallel text and speech corpora. Our semi-supervised model is built on top of an encoder-decoder model with attention and takes advantage of non-parallel speech and text corpora in several ways: a denoising text autoencoder that shares parameters with the ASR decoder, a speech autoencoder that shares parameters with the ASR encoder, and adversarial training that encourages the speech and text encoders to use the same embedding space. We show that a model with this architecture significantly outperforms the baseline in this low-resource condition. We additionally perform an ablation evaluation, demonstrating that all of our added components contribute substantially to the overall performance of our model. We propose several avenues for further work, noting in particular that a model with this architecture could potentially enable fully unsupervised speech recognition.","","978-1-5386-4334-1","10.1109/SLT.2018.8639541","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8639541","speech recognition;low-resource;end-to-end;semi-supervised learning","Speech recognition;Training;Hidden Markov models;Decoding;Data models;Speech coding;Speech processing","learning (artificial intelligence);speech recognition","ASR encoder;low-resource condition;low-resource speech recognition;end-to-end automatic speech recognition model;speech corpora;semisupervised model;encoder-decoder model;text corpora;denoising text autoencoder;ASR decoder;speech autoencoder;speech recognition","","6","","32","","14 Feb 2019","","","IEEE","IEEE Conferences"
"Stochastic least squares learning for deep architectures","G. Kumar; J. M. Sim; E. Y. Cheu; X. Li","NUS High School of Mathematics and Science, Singapore; A*STAR (Agency for Science, Technology and Research), Exploit Technologies Pte Ltd., Singapore; Rolls Royce Singapore Pte Ltd.; A*STAR, Institute for Infocomm Research, Singapore","2015 International Joint Conference on Neural Networks (IJCNN)","1 Oct 2015","2015","","","1","7","In this paper, we present a novel way of pre-training deep architectures by using the stochastic least squares autoencoder (SLSA). The SLSA is based on the combination of stochastic least squares estimation and logistic sampling. The usefulness of the stochastic least squares approach coupled with the numerical trick of constraining the logistic sampling process is highlighted in this paper. This approach was tested and benchmarked against other methods including Neural Nets (NN), Deep Belief Nets (DBN), and Stacked Denoising Autoencoder (SDAE) using the MNIST dataset. In addition, the SLSA architecture was also tested against established methods such as the Support Vector Machine (SVM), and the Naive Bayes Classifier (NB) on the Reuters-21578 and MNIST datasets. The experiments show the promise of SLSA as a pre-training step, in which stacked of SLSA yielded the lowest classification error and the highest F-measure scores on the MNIST and Reuters-21578 datasets respectively. Hence, this paper establishes the value of pre-training deep neural network, by using the SLSA.","2161-4407","978-1-4799-1960-4","10.1109/IJCNN.2015.7280502","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280502","","","learning (artificial intelligence);least squares approximations;neural net architecture;sampling methods;stochastic processes","stochastic least squares learning;pretraining deep-architectures;stochastic least squares autoencoder;stochastic least squares estimation;logistic sampling process;neural nets;deep belief nets;stacked denoising autoencoder;NN;DBN;SDAE;MNIST dataset;support vector machine;SVM;naive Bayes classifier;NB;Reuters-21578 dataset;classification error;F-measure score;SLSA architecture","","","","29","","1 Oct 2015","","","IEEE","IEEE Conferences"
"Deep Learning for a Fair Distance-based SCMA Detector","M. Rebhi; K. Hassan; K. Raoof; P. Chargé","Le Mans University, Le Mans, France; Le Mans University, Le Mans, France; Le Mans University, Le Mans, France; IETR, Ecole polytechnique Université de Nantes, Nantes, France","2022 IEEE Wireless Communications and Networking Conference (WCNC)","16 May 2022","2022","","","650","655","As a scheme of non-orthogonal multiple access in the code-domain, sparse code multiple access (SCMA) is one of the promoting candidate for the upcoming generations of wireless communication systems, and it has been actively investigated in recent years with several challenges in designing low complexity and high accuracy decoding algorithms. Deep learning technologies are of significant potential in solving several problems of communication systems. Motivated by this, we explore new approaches to improve SCMA detection performance using deep learning methods. In this paper, we propose to jointly design and train a denoising auto-encoder (DAE) and deep neural network (DNN) to decode SCMA signals over an additive white Gaussian noise channel. Simulation results show that our proposed DAE-DNN detector outperforms existing deep learning ones. However, the performance of the above-mentioned method is slightly worse than that of the traditional message passing algorithm (MPA). Nevertheless, this comparison is not fair, since the DAE-DNN detector, contrary to MPA, assumes that the SCMA codebook is unknown at the receiver. That is why, we propose a new distance-based DNN detector under the assumption that the codebook is known. The proposed detector can be fairly compared to MPA, and simulations confirmed that its performance is better than that of MPA.","1558-2612","978-1-6654-4266-4","10.1109/WCNC51071.2022.9771635","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9771635","SCMA detector;deep learning;denoising autoencoder;fairness","Deep learning;Wireless communication;NOMA;Simulation;Noise reduction;Neural networks;Detectors","AWGN channels;code division multiple access;deep learning (artificial intelligence);next generation networks;nonorthogonal multiple access;radio receivers;wireless channels","message passing algorithm;DAE-DNN detector;SCMA codebook;distance-based DNN detector;fair distance-based SCMA detector;nonorthogonal multiple access;code-domain;sparse code multiple access;wireless communication systems;high accuracy decoding algorithms;deep learning technologies;SCMA detection performance;deep learning methods;denoising auto-encoder;deep neural network;decode SCMA signals;additive white Gaussian noise channel","","","","26","EU","16 May 2022","","","IEEE","IEEE Conferences"
"An Effective Deep Learning Based Scheme for Network Intrusion Detection","H. Zhang; C. Q. Wu; S. Gao; Z. Wang; Y. Xu; Y. Liu","State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China; Department of Computer Science, New Jersey Institute of Technology, Newark, USA; Cooperative Innovation Center of Internet Healthcare, Zhengzhou University, Zhengzhou, China; Cooperative Innovation Center of Internet Healthcare, Zhengzhou University, Zhengzhou, China; Department of Research and Development, Hangzhou DPtech Technologies Co., Ltd., Hangzhou, China; Cooperative Innovation Center of Internet Healthcare, Zhengzhou University, Zhengzhou, China","2018 24th International Conference on Pattern Recognition (ICPR)","29 Nov 2018","2018","","","682","687","Intrusion detection systems (IDS) play an important role in the protection of network operations and services. In this paper, we propose an effective network intrusion detection scheme based on deep learning techniques. The proposed scheme employs a denoising autoencoder (DAE) with a weighted loss function for feature selection, which determines a limited number of important features for intrusion detection to reduce feature dimensionality. The selected data is then classified by a compact multilayer perceptron (MLP) for intrusion identification. Extensive experiments are conducted on the UNSW-NB dataset to demonstrate the effectiveness of the proposed scheme. With a small feature selection ratio of 5.9%, the proposed scheme is still able to achieve a superior performance in terms of different evaluation criteria. The strategic selection of a reduced set of features yields satisfactory detection performance with low memory and computing power requirements, making the proposed scheme a promising solution to intrusion detection in high-speed networks.","1051-4651","978-1-5386-3788-3","10.1109/ICPR.2018.8546162","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8546162","Intrusion detection system;denoising autoen-coder;feature selection;deep learning","Feature extraction;Intrusion detection;Engines;Training;Noise reduction;Hidden Markov models","feature extraction;learning (artificial intelligence);multilayer perceptrons;neural nets;pattern classification;power aware computing;security of data","intrusion detection systems;weighted loss function;intrusion identification;strategic selection;network intrusion detection;deep learning;feature selection;multilayer perceptron;IDS;denoising autoencoder;DAE","","18","","31","","29 Nov 2018","","","IEEE","IEEE Conferences"
"A Hybrid Cloud Intrusion Detection Method Based on SDAE and SVM","W. Wang; X. Du; D. Shan; N. Wang","PLA Strategic Support Force Information Engineering University, Zhengzhou, China; PLA Strategic Support Force Information Engineering University, Zhengzhou, China; PLA Strategic Support Force Information Engineering University, Zhengzhou, China; PLA Strategic Support Force Information Engineering University, Zhengzhou, China","2019 12th International Conference on Intelligent Computation Technology and Automation (ICICTA)","2 Mar 2020","2019","","","271","274","Network intrusion detection is one of the effective methods to prevent the cloud environment from malicious attacks. In this paper, we propose a cloud intrusion detection method based on stacked denoising autoencoders (SDAE) and support vector machine (SVM). Utilizing the unsupervised deep learning algorithm SDAE for dimensionality reduction, and using the supervised shallow learning algorithm SVM for building classifier to detect malicious attacks. The detection performance of the proposed SDAE+SVM model has been evaluated using the well-known intrusion detection evaluation datasets namely the NSL-KDD.","","978-1-7281-4284-5","10.1109/ICICTA49267.2019.00064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9017139","Cloud Computing;Feature Extraction;Denoising Auto-encoder;Support Vector Machine","Feature extraction;Support vector machines;Cloud computing;Intrusion detection;Classification algorithms;Noise reduction;Machine learning","cloud computing;pattern classification;security of data;support vector machines","support vector machine;unsupervised deep learning algorithm;SDAE-SVM model;stacked denoising autoencoders;malicious attacks;cloud environment;network intrusion detection;hybrid cloud intrusion detection method","","3","","10","IEEE","2 Mar 2020","","","IEEE","IEEE Conferences"
"CBR-Based Decision Support System for Maintenance Text Using NLP for an Aviation Case Study","S. M. R. Naqvi; M. Ghufran; S. Meraghni; C. Varnier; J. -M. Nicod; N. Zerhouni","Fives CortX, Lyon, France; Fives CortX, Lyon, France; FEMTO-ST Institute, Université de Bourgogne Franche-Comté / CNRS / ENSMM, Besançon, France; FEMTO-ST Institute, Université de Bourgogne Franche-Comté / CNRS / ENSMM, Besançon, France; FEMTO-ST Institute, Université de Bourgogne Franche-Comté / CNRS / ENSMM, Besançon, France; FEMTO-ST Institute, Université de Bourgogne Franche-Comté / CNRS / ENSMM, Besançon, France","2022 Prognostics and Health Management Conference (PHM-2022 London)","1 Jul 2022","2022","","","344","349","Recently, Prognostics and Health Management (PHM) has emerged to promote predictive maintenance as a methodological key to overcome the limitations of traditional reliability analysis. The Natural Language Processing (NLP) methods allow the maintenance log usage for maintenance diagnostics and decision making. The Maintenance Work Orders (MWOs) contain vital health indicators and decades of experience related to various maintenance actions. However, due to the unstructured nature of maintenance text, it is not common to develop a tool using these textual maintenance entries. This paper proposes a textual Case-Based Reasoning (CBR) approach combined with Technical Language Processing (TLP) to find solutions for new problems based on previous experiences. The Bidirectional Encoder Representations from Transformers (BERT) model is adopted for maintenance data using unsupervised finetuning technique Transformer-based Sequential Denoising AutoEncoder (TSDAE) for aviation case study. Results show that the pre-trained BERT model can adopt domain-specific data and produce semantic matches with only a small amount (1000 samples) of domain specific data.","2166-5656","978-1-6654-7954-7","10.1109/PHM2022-London52454.2022.00067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9808428","Prognostics and Health Management (PHM);Case-Based Reasoning;Natural Language Processing;Technical Language Processing;BERT;Sequential Denoising Auto-Encoder","Noise reduction;Bit error rate;Semantics;Maintenance engineering;Transformers;Natural language processing;Data models","case-based reasoning;decision making;decision support systems;natural language processing;neural nets;software maintenance;text analysis;unsupervised learning","prognostics and health management;predictive maintenance;reliability analysis;natural language processing methods;NLP;maintenance log usage;maintenance diagnostics;decision making;maintenance work orders;health indicators;maintenance actions;unstructured nature;maintenance text;textual maintenance entries;technical language processing;maintenance data;CBR-based decision support system;textual case-based reasoning approach;bidirectional encoder representations;unsupervised finetuning technique;transformer-based sequential denoising autoencoder","","","","28","IEEE","1 Jul 2022","","","IEEE","IEEE Conferences"
"Bayesian Deep Neural Network to Compensate for Current Transformer Saturation","S. Key; S. -H. Kang; N. -H. Lee; S. -R. Nam","Department of Electrical Engineering, Myongji University, Yongin, South Korea; Department of Electrical Engineering, Myongji University, Yongin, South Korea; Korea Electric Power Research Institute, Daejeon, South Korea; Department of Electrical Engineering, Myongji University, Yongin, South Korea","IEEE Access","24 Nov 2021","2021","9","","154731","154739","Current transformer saturation has a negative effect on the operation of IEDs, resulting in their malfunction. Here, we present a technique to compensate for saturated waveforms using Bayesian Deep Neural Network (BDNN) comprising Deep Neural Network (DNN) and Bayesian optimization (BO). DNN, that utilizes stacked denoising autoencoder (SDAE) and Backpropagation (BP), is employed to optimize deep learning structure. Unlike the conventional neural network, which is a shallow network or random-initialize weights, the SDAE calculates optimal weights for each hidden layer and BP uses them to fine-tune which yields results with high performance for CT saturation compensation. To improve the empirical search of training hyperparameters, Bayesian optimization is adopted to decide training-related vectors such as batch size, learning rate, and number of neurons. Finally, the performance of the proposed approach was evaluated on an overhead transmission line which is imported from PSCAD/EMTDC with the different scenarios of fault inception angle, remnant flux, and voltage system. Therefore, numerical cases of saturation were comprehensively evaluated to demonstrate the performance of the proposed algorithm. A comparative analysis was shown to demonstrate that the proposed BDNN is superior to artificial neural network (ANN), and least square error (LES) technique.","2169-3536","","10.1109/ACCESS.2021.3127542","Korea Electric Power Corporation (KEPCO)(grant numbers:R17XA05-2); Korea Research Foundation funding from the Government (Ministry of Education), in 2019(grant numbers:NRF-2019R1F1A1059619); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9612180","Current transformer;saturation;deep learning;stacked denoising auto-encoders;Bayesian","Circuit faults;Fault currents;Training;Current transformers;Saturation magnetization;Magnetic flux;Harmonic analysis","backpropagation;current transformers;deep learning (artificial intelligence);power engineering computing;power overhead lines;power system CAD","Bayesian optimization;BDNN;deep learning structure;conventional neural network;shallow network;optimal weights;CT saturation compensation;artificial neural network;Bayesian deep neural network;current transformer saturation;saturated waveforms;PSCAD;EMTDC;LES;ANN;SDAE;stacked denoising autoencoder;BO","","","","31","CCBY","11 Nov 2021","","","IEEE","IEEE Journals"
"Robust Classification of Largely Corrupted Electronic Nose Data Using Deep Neural Networks","Y. Yoo; H. -I. Kim; S. -I. Choi","Independent Researcher; Department of Computer Science and Engineering, Dankook University, Yongin, South Korea; Department of Computer Engineering, Dankook University, Yongin, South Korea","IEEE Sensors Journal","18 Jan 2021","2021","21","4","5052","5059","Data loss for electronic noses may occur because of the sensor’s installation environment or from electrical disturbances. As a result, electronic noses may experience difficulties when identifying gases. This paper proposes two deep neural network-based functions for identifying gases. First, a denoising auto-encoder based on the corruption reconstruction method is proposed for electronic nose data to solve this problem. Second, a convolutional neural network-based gas-classifying model is proposed. Although the electronic nose data are highly discriminative, they are sensitive to the corruption of information; hence, they require an efficient restoration method for practical use. From the experiments we demonstrate that the proposed denoising auto-encoder provides a strong restoration capability, and the convolutional neural network-based classifier successfully discriminates the gas data samples with a classification rate over 95% even when the data loss is 50%.","1558-1748","","10.1109/JSEN.2020.3034145","Dankook University(grant numbers:2019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240952","Electronic nose;data corruption;data reconstruction;denoising auto-encoder;deep neural network;convolutional neural network;classification","Gas detectors;Feature extraction;Image reconstruction;Sensor phenomena and characterization;Electronic noses;Sensor arrays","chemical variables measurement;computerised instrumentation;convolutional neural nets;deep learning (artificial intelligence);electronic noses","gas data samples;robust classification;electronic noses;deep neural network-based functions;denoising autoencoder;corruption reconstruction method;convolutional neural network-based gas-classifying model;corrupted electronic nose data","","3","","45","IEEE","27 Oct 2020","","","IEEE","IEEE Journals"
"Transformer Network for Remaining Useful Life Prediction of Lithium-Ion Batteries","D. Chen; W. Hong; X. Zhou","School of Intelligent Transportation, Zhejiang Institute of Mechanical and Electrical Engineering, Hangzhou, China; Shuye Technology Company Ltd., Hangzhou, China; Shuye Technology Company Ltd., Hangzhou, China","IEEE Access","25 Feb 2022","2022","10","","19621","19628","Accurately predicting the Remaining Useful Life (RUL) of a Li-ion battery plays an important role in managing the health and estimating the state of a battery. With the rapid development of electric vehicles, there is an increasing need to develop and improve the techniques for predicting RUL. To predict RUL, we designed a Transformer-based neural network. First, battery capacity data is always full of noise, especially during battery charge/discharge regeneration. To alleviate this problem, we applied a Denoising Auto-Encoder (DAE) to process raw data. Then, to capture temporal information and learn useful features, a reconstructed sequence was fed into a Transformer network. Finally, to bridge denoising and prediction tasks, we combined these two tasks into a unified framework. Results of extensive experiments conducted on two data sets and a comparison with some existing methods show that our proposed method performs better in predicting RUL. Our projects are all open source and are available at https://github.com/XiuzeZhou/RUL.","2169-3536","","10.1109/ACCESS.2022.3151975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9714323","Li-ion battery;remaining useful life;transformer;denoising auto-encoder;neural network","Transformers;Noise reduction;Task analysis;Predictive models;Data models;Degradation;Lithium-ion batteries","battery management systems;lithium compounds;neural nets;power engineering computing;remaining life assessment;secondary cells","lithium-ion batteries;remaining useful life prediction;electric vehicles;transformer-based neural network;battery capacity data;denoising autoencoder;raw data;prediction tasks;data sets;RUL prediction;DAE;temporal information;reconstructed sequence;Li+","","1","","66","CCBY","15 Feb 2022","","","IEEE","IEEE Journals"
"Analytical determination of interwell connectivity based on interwell influence","J. Yuan; X. Zeng; H. Wu; W. Zhang; J. Zhou; B. Chen","Research Institute of Petroleum Exploration and Development, Beijing, China; College of Computer Science and Technology, China University of Petroleum, Qingdao, China; College of Computer Science and Technology, China University of Petroleum, Qingdao, China; College of Computer Science and Technology, China University of Petroleum, Qingdao, China; Department of Computer and Electronic Engineering, University of Oulu, Oulu, Finland; College of Computer Science and Technology, China University of Petroleum, Qingdao, China","Tsinghua Science and Technology","9 Jun 2021","2021","26","6","813","820","Interwell connectivity, an important element in reservoir characterization, especially for water flooding, is used to make decisions for better oil production. The existing methods in literature directly use related data of wells to infer interwell connectivity, but they ignore the influence between different wells. The connection of one well to more than two wells (as is often true in the oil field well pattern) will impact the accuracy of the connectivity analysis. To address this challenge, this paper proposes the Particle Swarm Optimization-based CatBoost for Interwell Connectivity (PSOC4IC) based on relative features to analyze interwell connectivity with the combination of joint mutual information maximization-based denoising sparse autoencoder for inter-feature construction and extraction and PSO-based CatBoost (PSO-CatBoost) for connectivity prediction with high-dimensional noise data. The experimental results show that the PSOC4IC improves analysis accuracy.","1007-0214","","10.26599/TST.2020.9010039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9449326","interwell connectivity;interwell influence;Particle Swarm Optimization (PSO);CatBoost","Feature extraction;Oils;Production;Reservoirs;Data models;Mutual information;Mathematical model","feature extraction;floods;gradient methods;hydrocarbon reservoirs;neural nets;particle swarm optimisation;public domain software;well logging","interwell connectivity;interwell influence;connectivity analysis;connectivity prediction;reservoir characterization;water flooding;oil production;particle swarm optimization;PSOC4IC;joint mutual information maximization;denoising sparse autoencoder;inter-feature construction;inter-feature extraction;PSO-CatBoost","","","","","","9 Jun 2021","","","TUP","TUP Journals"
"Using models of cortical development based on sparse coding to discriminate between real and synthetically-generated faces","N. T. T. Nguyen; J. S. Moore; G. T. Kenyon","Los Alamos National Laboratory, Los Alamos, NM, USA; Los Alamos National Laboratory, Los Alamos, NM, USA; Los Alamos National Laboratory, Los Alamos, NM, USA","2020 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)","10 May 2021","2020","","","1","7","We compare the robustness of image classifiers based on state-of-the-art Deep Neural Networks (DNNs) with classifiers based on a model of cortical development using a single layer of sparse coding. The comparison is based on the ability of the two distinct types of classifiers to distinguish between faces of celebrities from the CelebA dataset and synthetic faces created by the ProGAN multi-scale GAN, trained on the same CelebA images. We examine the robustness of DNNs compared to classifiers based on sparse coding after the addition of universal adversarial perturbations (UAPs), which fool most or all of the DNN classifiers we examined. Our results show that simple classifiers based on sparse coding are robust to UAPs that substantially degrade performance across a wide range of DNN architectures. We hypothesize that sparse latent representations, which correspond to fixed points of a dynamical attractor—or Hopfield network—are naturally denoising and remove small adversarial perturbations. We observe that analogous but reduced robustness is conferred by deep denoising autoencoders. Our results suggest that DNN-based classifiers may be designed to rely on more robust features, and thus may be less susceptible to adversarial attacks, if preceded by a denoising pre-processing layer.","2332-5615","978-1-7281-8243-8","10.1109/AIPR50011.2020.9425143","Los Alamos National Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9425143","sparse coding;deep convolutional neural network;adversarial examples;robustness;denoising;deepfakes","Image coding;Perturbation methods;Noise reduction;Neural networks;Hopfield neural networks;Generative adversarial networks;Robustness","face recognition;feature extraction;image classification;image coding;image denoising;learning (artificial intelligence);neural nets","cortical development;sparse coding;image classifiers;DNNs;synthetic faces;ProGAN multiscale GAN;CelebA images;DNN classifiers;simple classifiers;sparse latent representations;analogous but reduced robustness;DNN-based classifiers","","","","40","IEEE","10 May 2021","","","IEEE","IEEE Conferences"
"Comparing SVD and SDAE for Analysis of Islamist Forum Postings","N. Alsadhan; D. B. Skillicorn","School of Computing, Queen's University; School of Computing, Queen's University","2015 IEEE International Conference on Data Mining Workshop (ICDMW)","4 Feb 2016","2015","","","948","953","We analyze postings in the Turn to Islam forum using techniques based on singular value decomposition (SVD) and the deep learning technique of stacked denoising autoencoders (SDAE). Models based on frequent words and jihadist language intensity are used, and the results compared. Our main conclusion is that SDAE approaches, while clearly discovering structure in document-word matrices, do not yet provide a natural interpretation strategy, limiting their practical usefulness. In contrast, SVD approaches provide interpretable models, primarily because of the coupling between document and word variation patterns.","2375-9259","978-1-4673-8493-3","10.1109/ICDMW.2015.108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7395769","s22211","Noise reduction;Training;Singular value decomposition;Conferences;Machine learning;Matrix decomposition;Encoding","document handling;humanities;natural language processing;singular value decomposition;Web sites","SVD;SDAE;Islamist forum postings analysis;singular value decomposition;deep learning technique;stacked denoising autoencoders;frequent words;jihadist language intensity;document-word matrices;natural interpretation strategy;interpretable models;word variation patterns;document patterns","","","","13","","4 Feb 2016","","","IEEE","IEEE Conferences"
"Cornet: Composite-Regularized Neural Network For Convolutional Sparse Coding","D. Jawali; P. K. Pokala; C. S. Seelamantula","Department of Electrical Engineering, Indian Institute of Science, Bangalore, India; Department of Electrical Engineering, Indian Institute of Science, Bangalore, India; Department of Electrical Engineering, Indian Institute of Science, Bangalore, India","2020 IEEE International Conference on Image Processing (ICIP)","30 Sep 2020","2020","","","818","822","Sparse recovery via composite regularization is an interesting approach proposed recently in the literature. One could design nonconvex regularizers through a convex combination of sparsity-promoting penalties with known proximal operators. We develop a new algorithm, namely, convolutional proximal-averaged thresholding algorithm (C-PATA) for composite-regularized convolutional sparse coding (CR-CSC) based on the recently proposed idea of proximal averaging. We develop an autoencoder structure based on the deep-unfolding of C-PATA iterations into neural network layers, which results in the composite-regularized neural network (CoRNet) architecture. The convolutional learned iterative soft-thresholding algorithm becomes a special case of CoRNet. We demonstrate the efficacy of CoRNet considering applications to image denoising and inpainting, and compare the performance with state-of-the-art techniques such as BM3D, convolutional LISTA, and fast and flexible convolutional sparse coding (FFCSC).","2381-8549","978-1-7281-6395-6","10.1109/ICIP40778.2020.9190923","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190923","Convolutional sparse coding;convolutional LISTA;composite regularization;deep unfolding;CoRNet","Convolutional codes;Convolution;Image denoising;Neural networks;Image coding;Noise reduction;Minimization","concave programming;convex programming;image coding;image denoising;image reconstruction;image representation;iterative methods;learning (artificial intelligence);neural nets","CoRNet;sparse recovery;composite regularization;nonconvex regularizers;convex combination;sparsity-promoting penalties;known proximal operators;composite-regularized convolutional sparse coding;proximal averaging;C-PATA iterations;neural network layers;composite-regularized neural network architecture;convolutional learned iterative soft-thresholding algorithm;flexible convolutional sparse coding","","","","35","","30 Sep 2020","","","IEEE","IEEE Conferences"
"Enhanced Seq2Seq Autoencoder via Contrastive Learning for Abstractive Text Summarization","C. Zheng; K. Zhang; H. J. Wang; L. Fan; Z. Wang","University of Delaware; University of Maryland, College Park; University of Delaware; Tezign.com; Tezign.com","2021 IEEE International Conference on Big Data (Big Data)","13 Jan 2022","2021","","","1764","1771","In this paper, we present a denoising sequence-to-sequence (seq2seq) autoencoder via contrastive learning for abstractive text summarization. Our model adopts a standard Transformer-based architecture with a multi-layer bi-directional encoder and an auto-regressive decoder. To enhance its denoising ability, we incorporate self-supervised contrastive learning along with various sentence-level document augmentation. These two components, seq2seq autoencoder and contrastive learning, are jointly trained through fine-tuning, w hich i mproves the performance of text summarization with regard to ROUGE scores and human evaluation. We conduct experiments on two datasets and demonstrate that our model outperforms many existing benchmarks and even achieves comparable performance to the state-of-the-art abstractive systems trained with more complex architecture and extensive computation resources.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671819","University of Delaware; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671819","Abstractive Text Summarization;Contrastive Learning;Data Augmentation;Seq2seq","Computational modeling;Conferences;Noise reduction;Computer architecture;Big Data;Benchmark testing;Transformers","","","","","","50","","13 Jan 2022","","","IEEE","IEEE Conferences"
"Cloud-Aware Generative Network: Removing Cloud From Optical Remote Sensing Images","L. Sun; Y. Zhang; X. Chang; Y. Wang; J. Xu","College of Materials Sciences and Opto-Electronic Technology, University of Chinese Academy of Sciences, Beijing, China; AI Lab, Changchun Spirits AI Technology Co., Ltd., Changchun, China; AI Lab, Changchun Spirits AI Technology Co., Ltd., Changchun, China; Image Processing Department, Key Laboratory of Airborne Optical Imaging and Measurement, Chinese Academy of Sciences, Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Sciences, Changchun, China; AI Lab, Changchun Spirits AI Technology Co., Ltd., Changchun, China","IEEE Geoscience and Remote Sensing Letters","25 Mar 2020","2020","17","4","691","695","In the optical remote sensing and earth observation fields, clouds severely obscure the land’s visibility and degrade the image. In recent years, there have been many excellent efforts to mitigate the effects of cloud cover. However, it has been found that there will be some blurs in the area if a single degraded image is restored by autoencoder-based methods. This letter focuses on removing clouds from single optical remote sensing images by autoencoder-based methods without multitemporal information while at the same time mitigating blurs caused by missing information. Therefore, we propose a novel cloud removal method that combines image inpainting and image denoising, called the Cloud-Aware Generative Network (CAGN). The CAGN consists of two stages: the first stage is a recurrent convolution network for potential cloud region detection and the second is an autoencoder for cloud removal. The method uses a side-guided method that adds attention mechanisms in the first stage to assist in predicting the mask. Furthermore, to update the mask adaptively for restoring degraded image areas greedily, the method embeds partial convolution in the autoencoder to condition the convolution calculation of pixels in the regions of thick clouds at different layers. Extensive experiments demonstrate clearly that CAGN can easily achieve a considerable increase in the peak signal-to-noise ratio (PSNR) and the structural similarity index (SSIM) compared with a competitive baseline model.","1558-0571","","10.1109/LGRS.2019.2928840","Chinese Academy of Sciences(grant numbers:2016201); National Defense Science and Technology Innovation Zone(grant numbers:18-H863-00-TS-002-018-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8884095","Attention mechanism;cloud detection;cloud removal;generative network;remote sensing","Convolution;Remote sensing;Optical imaging;Optical sensors;Image reconstruction;Training","image coding;image denoising;image restoration;recurrent neural nets;remote sensing","attention mechanisms;SSIM;structural similarity index;PSNR;peak signal-to-noise ratio;earth observation fields;partial convolution;potential cloud region detection;recurrent convolution network;CAGN;Cloud-Aware Generative Network;image inpainting;cloud removal method;single optical remote sensing images;autoencoder-based methods;single degraded image;cloud cover","","6","","20","IEEE","28 Oct 2019","","","IEEE","IEEE Journals"
"Robust feature learning by improved auto-encoder from non-Gaussian noised images","D. Zhao; B. Guo; J. Wu; W. Ning; Y. Yan","School of Aerospace Science and Technology, Xidian University, Xi'an, Shaanxi, China; School of Aerospace Science and Technology, Xidian University, Xi'an, Shaanxi, China; School of Aerospace Science and Technology, Xidian University, Xi'an, Shaanxi, China; School of Aerospace Science and Technology, Xidian University, Xi'an, Shaanxi, China; School of Aerospace Science and Technology, Xidian University, Xi'an, Shaanxi, China","2015 IEEE International Conference on Imaging Systems and Techniques (IST)","8 Oct 2015","2015","","","1","5","Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Net-works(DBN) and stacks of auto-encoder variants, with impressive results obtained in several areas, mostly on vision and languages datasets. These learning algorithms aim to find good representations for data, which can be used for classification, reconstruction, visualization and so on. Despite the progress, most existing algorithms would be fragile to non-Gaussian noises and outliers due to the criterion of mean square error(MSE) and cross entropy(CE). In this paper, we propose a robust auto-encoder called correntropy-based contractive auto-encoder(C-CAE) to learn robust features from data with non-Gaussian noises and outliers. The maximum correntropy criterion(MCC) is adopted as reconstruction cost function and a well chosen penalty term is added to the reconstruction cost function. By replacing cross entropy with MCC, the proposed method can learn robust features from the data containing non-Gaussian noises and outliers. The penalty term corresponds to the Frobenius norm of the Jacobian matrix of the encoder activations with respect to the input. By adding the penalty term, the antinoise ability of the proposed method is improved. The proposed method is evaluated using the MNIST benchmark dataset. Experimental results show that, compared with the traditional auto-encoders, the proposed method learns robust features, improves classification accuracy and reduces the reconstruction error, which demonstrates that the proposed method is capable of learning robust features on noisy data.","1558-2809","978-1-4799-8633-0","10.1109/IST.2015.7294537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7294537","feature learning;stacked autoencoder;correntropy","Noise;Robustness;Image reconstruction;Cost function;Feature extraction;Noise reduction;Entropy","data structures;feature extraction;Gaussian noise;image classification;image denoising;image reconstruction;Jacobian matrices;learning (artificial intelligence);maximum entropy methods;mean square error methods","robust feature learning algorithms;improved autoencoder;nonGaussian noised images;deep belief networks;DBN;language datasets;vision datasets;data representations;mean square error;MSE;cross entropy;correntropy-based contractive auto-encoder;maximum correntropy criterion;MCC;reconstruction cost function;Frobenius norm;Jacobian matrix;antinoise ability;MNIST benchmark dataset;reconstruction error;robust feature learning","","2","","26","","8 Oct 2015","","","IEEE","IEEE Conferences"
"Age Invariant Face Recogntion Using Stacked Autoencoder Deep Neural Network","R. Arora; P. Kaur; E. D. Kaur","CSE Department, SUS College of Engineering and Technology, SAS Nagar, Mohali, India; CSE Department, SUS College of Engineering and Technology, SAS Nagar, Mohali, India; Head of CSE Department, SUS College of Engineering and Technology, SAS Nagar, Mohali, India","2020 International Conference on Intelligent Engineering and Management (ICIEM)","6 Aug 2020","2020","","","358","363","When it comes to computer vision, the most challenging and crucial field is Face recognition with latest technology system. There are plenty of research articles available, and had done lot of research in this domain to achieve the stability, but due to the timely Changes new challenges has been occurred with time and the research started towards to resolve the problem. As we have analyzed due to the certain changes of time and structure of face has reshaped with the effect of aging. So, various authors has discussed the face recognition without aging affect in plenty of articles, but all have some problems and low accuracy to identify the face. This research also describes face recognition with different face features like structure, shape, texture, size and many more. In this paper, we mainly considers two domains, face recognition and Age Invariant. The aim of this research is to include the face recognition work which does not achieved by previous researchers that does not discussed the significant methods, such as: Feature based, Appearance based and soft computing based method. To evaluate our technique, we used a large dataset known as Cross-Age Celebrity Dataset (CACD). This dataset contains more than 2000 Celebrities having 160,000 Images with age ranging from 16 to 62. We have used 1000 Images as input dataset for training and model evaluation. We proposed the Auto-encoder denoising deep neural Network, which extracts the 1000 features from image, and achieved 99.8% Accuracy.","","978-1-7281-4097-1","10.1109/ICIEM48762.2020.9160113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9160113","Face Recognition;feature based;soft computing based;appearance based;Age Estimation;Aging;Age Invariant Introduction","Face;Face recognition;Feature extraction;Aging;Training;Biological neural networks;Computational modeling","computer vision;face recognition;feature extraction;neural nets","soft computing;cross-age celebrity dataset;age invariant face recognition;stacked autoencoder deep neural Network;computer vision;CACD","","","","34","IEEE","6 Aug 2020","","","IEEE","IEEE Conferences"
"Deep learning for robust outdoor vehicle visual tracking","J. -n. Xin; X. Du; J. Zhang","Shaanxi Key Laboratory of Complex System Control and Intelligent Information Processing, Xi'an University of Technology, Xi'an, P.R.China; Shaanxi Key Laboratory of Complex System Control and Intelligent Information Processing, Xi'an University of Technology, Xi'an, P.R.China; Faculty of Engineering and Information Technology, University of Technology (UTS), Sydney, Australia","2017 IEEE International Conference on Multimedia and Expo (ICME)","31 Aug 2017","2017","","","613","618","Robust visual tracking for outdoor vehicle is still a challenging problem due to large appearance variations caused by illumination variation, occlusion and scale variation, etc. In this paper, a deep-learning-based approach for robust outdoor vehicle tracking is proposed. Firstly, a stacked denoising auto-encoder is pre-trained to learn the feature representation way of images. Then, a k-sparse constraint is added to the stacked denoising auto-encoder and the encoder of k-sparse stacked denoising auto-encoder (kSSDAE) is connected with a classification layer to construct a classification neural network. After fine-tuning, the classification neural network is applied to online tracking under particle filter framework. Extensive tracking experiments are conducted on a challenging single object online tracking evaluation platform benchmark to verify the effectiveness of our tracker. Experiments show that our tracker outperforms most state-of-the-art trackers.","1945-788X","978-1-5090-6067-2","10.1109/ICME.2017.8019329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019329","Visual tracking;deep k-sparse auto-encoder;classification neural network;particle filter","Robustness;Object tracking;Machine learning;Feature extraction;Biological neural networks;Visualization","image classification;learning (artificial intelligence);neural nets;object tracking;particle filtering (numerical methods)","deep learning;robust outdoor vehicle visual tracking;appearance variation;stacked denoising auto-encoder;k-sparse constraint;k-sparse stacked denoising autoencoder;classification neural network;particle filter framework;online tracking evaluation platform","","7","","24","","31 Aug 2017","","","IEEE","IEEE Conferences"
"Adversarial 3D Convolutional Auto-Encoder for Abnormal Event Detection in Videos","C. Sun; Y. Jia; H. Song; Y. Wu","Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, China; Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, China; Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, China; Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, China","IEEE Transactions on Multimedia","24 Sep 2021","2021","23","","3292","3305","Abnormal event detection aims to identify the events that deviate from expected normal patterns. Existing methods usually extract normal spatio-temporal patterns of appearance and motion in a separate manner, which ignores low-level correlations between appearance and motion patterns and may fall short of capturing fine-grained spatio-temporal patterns. In this paper, we propose to simultaneously learn appearance and motion to obtain fine-grained spatio-temporal patterns. To this end, we present an adversarial 3D convolutional auto-encoder to learn the normal spatio-temporal patterns and then identify abnormal events by diverging them from the learned normal patterns in videos. The encoder captures the low-level correlations between spatial and temporal dimensions of videos, and generates distinctive features representing visual spatio-temporal information. The decoder reconstrucccts the original video from the encoded features representing by 3D de-convolutions and learns the normal spatio-temporal patterns in an unsupervised manner. We introduce the denoising reconstruction error and adversarial learning strategy to train the 3D convolutional auto-encoder to implicitly learn accurate data distributions that are considered normal patterns, which benefits enhancing the reconstruction ability of the auto-encoder to discriminate abnormal events. Both the theoretical analysis and the extensive experiments on four publicly available datasets demonstrate the effectiveness of our method.","1941-0077","","10.1109/TMM.2020.3023303","National Natural Science Foundation of China(grant numbers:61702037,61773062); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9194323","Adversarial 3D convolutional auto-encoder;normal patterns;adversarial learning;abnormal event detection","Three-dimensional displays;Videos;Event detection;Noise reduction;Correlation;Decoding;Generators","convolutional neural nets;feature extraction;image denoising;image motion analysis;image reconstruction;object detection;unsupervised learning;video signal processing","adversarial 3D convolutional autoencoder;unsupervised learning;3D deconvolutions;decoder;video reconstruction;normal spatio-temporal pattern extraction;adversarial learning strategy;denoising reconstruction error;visual spatio-temporal information;temporal dimensions;spatial dimensions;fine-grained spatio-temporal patterns;motion patterns;low-level correlations;expected normal patterns;abnormal event detection","","1","","61","IEEE","10 Sep 2020","","","IEEE","IEEE Journals"
"High-speed High-performance Visual Tracker via Correlation Filter with Compressed Deep Feature","J. Choi; K. Lee; J. Jeong; J. Y. Choi","Department of Electrical and Computer Engineering, ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering, ASRI, Seoul National University, Seoul, Korea","2018 18th International Conference on Control, Automation and Systems (ICCAS)","13 Dec 2018","2018","","","158","163","This paper introduces a context-aware correlation filter based tracker to achieve both high speed and high performance. We achieve high speed via deep feature compression based on a context-aware scheme utilizing multiple expert auto-encoders. To achieve high performance with the compressed feature map, we introduce extrinsic denoising processes and a new orthogonality loss term for pre-training and fine-tuning of the expert auto-encoders. In experiments, the proposed tracker is verified to achieve a comparable performance to state-of-the-art with running at over 100 fps.","","978-89-93215-16-8","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8571776","deep feature compression;context-aware scheme;expert auto-encoders;correlation filter tracker","Target tracking;Correlation;Training;Noise reduction;Feature extraction;Encoding;Visualization","data compression;feature extraction;image coding;image denoising;image filtering;object tracking;optical tracking;target tracking;tracking filters","extrinsic denoising processes;multiple expert autoencoders;compressed feature map;deep feature compression;context-aware correlation filter;high-speed high-performance visual tracker","","","1","30","","13 Dec 2018","","","IEEE","IEEE Conferences"
"TCAD-Augmented Machine Learning With and Without Domain Expertise","H. Dhillon; K. Mehta; M. Xiao; B. Wang; Y. Zhang; H. Y. Wong","Department of Electrical Engineering, San Jose State University, San Jose, CA, USA; Department of Electrical Engineering, San Jose State University, San Jose, CA, USA; The Bradley Department of Electrical and Computer Engineering, Center for Power Electronics Systems, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA; The Bradley Department of Electrical and Computer Engineering, Center for Power Electronics Systems, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA; The Bradley Department of Electrical and Computer Engineering, Center for Power Electronics Systems, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA; Department of Electrical Engineering, San Jose State University, San Jose, CA, USA","IEEE Transactions on Electron Devices","21 Oct 2021","2021","68","11","5498","5503","In this article, using experimental data, we demonstrate that the technology computer-aided design (TCAD) is a very cost-effective tool to generate the data to build machine learning (ML) models for semiconductor device and process characterization. Characterization of the emerging ultra wide bandgap gallium oxide (Ga2O3) Schottky barrier diode (SBD) is used as an example. Machines are trained by using only TCAD  ${I}$ – ${V}$ ’s and then used to deduce the effective Schottky metal work function (WF) and ambient temperature ( ${T}$ ) of an experimental SBD based on its  ${I}$ – ${V}$ . Besides noise, the experimental device also suffers from relatively large variations in drift layer thickness and doping concentrations. Both ML models with domain expertise (WDE) and without domain expertise (WoDE) are studied and compared. The ML model WDE requires the use of device knowledge to extract relevant features (e.g., subthreshold slope and turn-on voltage) for ML. The ML model WoDE obviates such a requirement and can be extended to cases where domain expertise is difficult to apply. Denois- ing autoencoder is used in the WoDE case. We showed that with only 500 TCAD  ${I}$ – ${V}$ ’s, we can train machines WDE and WoDE that can deduce the experimental device WF and  ${T}$  reasonably well. In particular, the ML model WoDE has an acceptable prediction accuracy despite the noise and additional variations in the experimental device.","1557-9646","","10.1109/TED.2021.3073378","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419673","Autoencoder (AE);gallium oxide;machine learning (ML);simulation;technology computer-aided design (TCAD);ultra wide bandgap","Feature extraction;Data models;Temperature measurement;Predictive models;Physics;Computational modeling;Performance evaluation","gallium compounds;learning (artificial intelligence);Schottky barriers;Schottky diodes;technology CAD (electronics);work function","domain expertise;technology computer-aided design;cost-effective tool;machine learning models;semiconductor device;process characterization;ambient temperature;experimental SBD;drift layer thickness;doping concentrations;device knowledge;ML model WoDE;ultra wide bandgap gallium oxide;TCAD-augmented machine learning;Schottky barrier diode;Schottky metal work function;subthreshold slope;turn-on voltage;denoising autoencoder;WoDE case;acceptable prediction accuracy;Ga2O3","","11","","22","USGov","29 Apr 2021","","","IEEE","IEEE Journals"
"Unsupervised Learning Approach to Feature Analysis for Automatic Speech Emotion Recognition","S. E. Eskimez; Z. Duan; W. Heinzelman","Electrical and Computer Engineering, University of Rochester, Rochester, NY, USA; Electrical and Computer Engineering, University of Rochester, Rochester, NY, USA; Electrical and Computer Engineering, University of Rochester, Rochester, NY, USA","2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 Sep 2018","2018","","","5099","5103","The scarcity of emotional speech data is a bottleneck of developing automatic speech emotion recognition (ASER) systems. One way to alleviate this issue is to use unsupervised feature learning techniques to learn features from the widely available general speech and use these features to train emotion classifiers. These unsupervised methods, such as denoising autoencoder (DAE), variational autoencoder (VAE), adversarial autoencoder (AAE) and adversarial variational Bayes (AVB), can capture the intrinsic structure of the data distribution in the learned feature representation. In this work, we systematically investigate four kinds of unsupervised feature learning methods for improving speaker-independent ASER. We show that all methods improve the performance regarding unweighted accuracy rating (UAR) and Fl-score over methods that use hand-crafted features or that do not perform feature learning on external datasets. We also show that VAE, AAE and AVB methods, which control the distribution of the latent representation, outperform DAE that does not control such distribution. This suggests the benefits of using variational inference methods to learn features from general speech for the speech tasks such as ASER that has very limited labeled data.","2379-190X","978-1-5386-4658-8","10.1109/ICASSP.2018.8462685","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8462685","Automatic speech emotion classification;unsupervised feature learning;autoencoders;variational inference","Decoding;Task analysis;Speech recognition;Emotion recognition;Unsupervised learning;Noise reduction;Training","Bayes methods;emotion recognition;feature extraction;pattern classification;speech recognition;unsupervised learning","feature representation;general speech;speech tasks;variational inference methods;AVB methods;hand-crafted features;speaker-independent ASER;data distribution;adversarial variational Bayes;adversarial autoencoder;unsupervised methods;emotion classifiers;unsupervised feature;automatic speech emotion recognition systems;emotional speech data;feature analysis;unsupervised learning approach","","17","","28","","13 Sep 2018","","","IEEE","IEEE Conferences"
"A Generative Adversarial Network Model for Disease Gene Prediction With RNA-seq Data","X. Jiang; J. Zhao; W. Qian; W. Song; G. N. Lin","School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; Shanghai Key Laboratory of Psychotic Disorders, Shanghai Mental Health Center, Shanghai Jiao Tong University School of Medicine, Shanghai, China","IEEE Access","28 Feb 2020","2020","8","","37352","37360","Deep learning models often need large amounts of training samples (thousands of training samples) to effectively extract hidden patterns in the data, thus achieving better results. However, in the field of brain-related disease, the omics data obtained by using advanced sequencing technology typically have much fewer patient samples (tens to hundreds of samples). Due to the small sample problem, statistical methods and intelligent machine learning methods have been unable to obtain a convergent gene set when prioritizing biomarkers. Furthermore, mathematical models designed for prioritizing biomarkers perform differently on different datasets. However, the architecture of the generative adversarial network (GAN) can address this bottleneck problem. Through the game between the generator and the discriminator, samples with similar distributions to that of samples in the training set can be generated by the generator, and the prediction accuracy and robustness of the discriminator could be significantly improved. Therefore, in this study, we designed a new generative adversarial network model with a denoising auto-encoder (DAE) as the generator and a multilayer perceptron (MLP) as the discriminator. The prediction residual error was backpropagated to the decoder part of the DAE, modifying the captured probability distribution. Based on this model, we further designed a framework to predict disease genes with RNA-seq data. The deep learning model improves the identification accuracy of disease genes over the-state-of-the-art approaches. An analysis of the experimental results has uncovered new disease-related genes and disease-associated pathways in the brain, which in turn have provided insight into the molecular mechanisms underlying disease phenotypes.","2169-3536","","10.1109/ACCESS.2020.2975585","National Basic Research Program of China (973 Program)(grant numbers:2017YFC0909200); National Natural Science Foundation of China(grant numbers:81671328,81971292); Program for Professor of Special Appointment (Eastern Scholar) at Shanghai Institutions of Higher Learning(grant numbers:1610000043); Shanghai Municipal Education Commission(grant numbers:ZXWF082101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9006830","Denoising auto-encoder;multilayer perceptron;generative adversarial network;RNA-seq data","Generative adversarial networks;Generators;Diseases;Data models;Training;Gallium nitride;Hidden Markov models","backpropagation;bioinformatics;brain;data analysis;diseases;genetics;genomics;medical computing;multilayer perceptrons;probability;RNA;statistical analysis","generative adversarial network model;disease gene prediction;RNA-seq data;deep learning model;brain-related disease;omics data;intelligent machine learning;prediction residual error;disease-related genes;disease phenotypes;statistical methods;denoising autoencoder;multilayer perceptron;backpropagation;bioinformatics;probability distribution","","10","","40","CCBY","21 Feb 2020","","","IEEE","IEEE Journals"
"Video Anomaly Detection by Estimating Likelihood of Representations","Y. Ouyang; V. Sanchez","Department of Computer Science, University of Warwick, Coventry, UK; Department of Computer Science, University of Warwick, Coventry, UK","2020 25th International Conference on Pattern Recognition (ICPR)","5 May 2021","2021","","","8984","8991","Video anomaly detection is a challenging task not only because it involves solving many sub-tasks such as motion representation, object localization and action recognition, but also because it is commonly considered as an unsupervised learning problem that involves detecting outliers. Traditionally, solutions to this task have focused on the mapping between video frames and their low-dimensional features, while ignoring the spatial connections of those features. Recent solutions focus on analyzing these spatial connections by using hard clustering techniques, such as K-Means, or applying neural networks to map latent features to a general understanding, such as action attributes. In order to solve video anomaly in the latent feature space, we propose a deep probabilistic model to transfer this task into a density estimation problem where latent manifolds are generated by a deep denoising autoencoder and clustered by expectation maximization. Evaluations on several benchmarks datasets show the strengths of our model, achieving outstanding performance on challenging datasets.","1051-4651","978-1-7281-8808-9","10.1109/ICPR48806.2021.9412694","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9412694","Video Anomaly Detection;Autoencoder;Expectation Maximization;Gaussian Mixture Model","Noise reduction;Neural networks;Estimation;Detectors;Probabilistic logic;Performance analysis;Pattern recognition","feature extraction;image denoising;image representation;neural nets;pattern clustering;unsupervised learning;video signal processing","spatial connections;hard clustering techniques;map latent features;latent feature space;density estimation problem;video anomaly detection;motion representation;object localization;unsupervised learning problem;video frames;low-dimensional features","","1","","45","","5 May 2021","","","IEEE","IEEE Conferences"
"Textile Defect Detection Algorithm Based on Unsupervised Learning","D. Wang; W. Yu; P. Lian; M. Zhang","Software Engineering Institute of Guangzhou, Guangzhou, China; Software Engineering Institute of Guangzhou, Guangzhou, China; Software Engineering Institute of Guangzhou, Guangzhou, China; Software Engineering Institute of Guangzhou, Guangzhou, China","2022 7th International Conference on Image, Vision and Computing (ICIVC)","19 Sep 2022","2022","","","81","86","In order to solve the problem of lack of sample data and high cost of dataset due to the large number of abnormal samples and high-precision marking data required by current deep learning algorithms in textile defect detection, a pixel-level real-time defect detection scheme based on autoencoder and morphology was proposed in this paper. Algorithm is innovation in that can carry on the network training by unsupervised learning, as opposed to supervised learning needs a large number of high-precision marking abnormal samples, the algorithm relies on the dataset is only normal sample data, and no need to tag samples. In addition to reducing the production cost of large dataset, textile defects of various sizes can be detected in real-time at the pixel level. The algorithm steps are described as follows: First, the normal textile image is input into the network for encoding and decoding, and the underlying feature information of textile image is learned and reconstructed into a new image. Secondly, the encoding and decoding stages were combined horizontally to obtain better fitting effect. By subtracting the input image from the reconstructed image, the difference matrix of the input image and the reconstructed image was obtained to obtain the range of the defect area. Finally, Dilate, Median Filtering and Edge Detection are used to amplify and denoise the features of the defect region to obtain the final accurate defect region. The experimental results show that the scheme can effectively detect textile defects in real-time at pixel-level only when normal samples are used as dataset. Compared with supervised learning based algorithms such as RCNN and YOLO, this scheme only needs normal samples as dataset to carry out network training, which greatly reduces the cost of making dataset. Besides, Accuracy and F1-score can both reach over 0.95 in 4 different textile datasets, and its FPS is 36.2. Meet the requirements of real-time detection. The code and models will be made publicly available at https://github.com/hanknewbird/anomaly-detection.","","978-1-6654-6734-6","10.1109/ICIVC55077.2022.9887216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9887216","anomaly detection;autoencoders;industrial inspection;defect detection;unsupervised learning","Training;Technological innovation;Costs;Supervised learning;Production;Real-time systems;Decoding","automatic optical inspection;edge detection;feature extraction;image denoising;image reconstruction;image texture;learning (artificial intelligence);neural nets;object detection;production engineering computing;unsupervised learning","textile defect detection algorithm;unsupervised learning;abnormal samples;high-precision marking data;current deep learning algorithms;pixel-level;real-time defect detection scheme;network training;supervised learning;normal sample data;production cost;textile defects;pixel level;algorithm steps;normal textile image;underlying feature information;input image;reconstructed image;defect area;Edge Detection;final accurate defect region;normal samples;4 different textile datasets;real-time detection;size 0.95 inch","","","","22","IEEE","19 Sep 2022","","","IEEE","IEEE Conferences"
"Establishing A Hybrid Pieceswise Linear Model for Air Quality Prediction Based Missingness Challenges","H. Zhu; Y. Ren; J. Hu","Graduate School of Information, Production and Systems, Waseda University, Kitakyushu, Japan; Graduate School of Information, Production and Systems, Waseda University, Kitakyushu, Japan; Graduate School of Information, Production and Systems, Waseda University, Kitakyushu, Japan","2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","6 Jan 2022","2021","","","1705","1710","Air pollution has threatened people’s health. It is urgent for the government to strengthen and improve the ability of air pollution monitoring. This paper proposes a winner-take-all (WTA) autoencoder-based piecewise linear model for imputing air quality prediction under the missing data scenario. The main idea consists of two parts. Firstly, overcomplete WTA stacked denoising autoencoders (SDAEs) are proposed to handle missing data, which play two roles: 1) devise the multiple imputation strategy to fill in missing values; 2) generate a set of binary gate control sequences to construct the sophisticated partitioning. Besides, renewed teacher signals are updated based on clustering information in the trained SDAEs to improve the accuracy of filling in missing samples. Secondly, the piecewise linear model is then proposed by the generated set of gate signals using the information from the feature layers of SDAEs. By using a quasi-linear kernel based on the trained gating mechanism, our piecewise air quality predictor is finally identified in the exact same way as support vector regression. The proposed modeling method is applied to real air quality datasets to show that it has led to greater performance than traditional models.","2577-1655","978-1-6654-4207-7","10.1109/SMC52423.2021.9658931","China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9658931","","Support vector machines;Atmospheric modeling;Noise reduction;Predictive models;Logic gates;Air pollution;Data models","air pollution;environmental science computing;image coding;image denoising;learning (artificial intelligence);neural nets;regression analysis;support vector machines","missing samples;generated set;gate signals;quasilinear kernel;trained gating mechanism;piecewise air quality predictor;air quality datasets;hybrid pieceswise linear model;air quality prediction;missingness challenges;air pollution monitoring;winner-take-all autoencoder-based piecewise linear model;missing data scenario;overcomplete WTA;multiple imputation strategy;binary gate control sequences;renewed teacher signals;trained SDAE;support vector regression","","","","17","IEEE","6 Jan 2022","","","IEEE","IEEE Conferences"
"EnerGAN++: A Generative Adversarial Gated Recurrent Network for Robust Energy Disaggregation","M. Kaselimi; N. Doulamis; A. Voulodimos; A. Doulamis; E. Protopapadakis","Department of Electrical and Computer Engineering, National Technical University of Athens, Zografou, Greece; Department of Electrical and Computer Engineering, National Technical University of Athens, Zografou, Greece; Department of Informatics and Computer Engineering, University of West Attica, Athens, Greece; Department of Electrical and Computer Engineering, National Technical University of Athens, Zografou, Greece; Department of Electrical and Computer Engineering, National Technical University of Athens, Zografou, Greece","IEEE Open Journal of Signal Processing","26 Jan 2021","2021","2","","1","16","Energy disaggregation, namely the separation of the aggregated household energy consumption signal into its additive sub-components, bears resemblance to the signal (source) separation problem and poses several challenges, not only as an ill-posed problem, but also, due to unsteady appliance signatures, abnormal behaviour that is usually detected in appliances operation and the existence of noise in the aggregated signal. In this paper, we propose EnerGAN++, a model based on Generative Adversarial Networks (GAN) for robust energy disaggregation. We attempt to unify the autoencoder (AE) and GAN architectures into a single framework, in which the autoencoder achieves a non-linear power signal source separation. EnerGAN++ is trained adversarially using a novel discriminator, to enhance robustness to noise. The discriminator performs sequence classification, using a recurrent convolutional neural network to handle the temporal dynamics of an appliance energy consumption time series. In particular, the proposed architecture of the discriminator leverages the ability of Convolutional Neural Networks (CNN) in rapid processing and optimal feature extraction, among with the need to infer the data temporal character and time dependence. Experimental results indicate the proposed method’s superiority compared to the current state of the art.","2644-1322","","10.1109/OJSP.2020.3045829","EU H2020 project BENEFFICE(grant numbers:768774); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9298835","Convolutional neural networks;denoising autoencoders;energy disaggregation;generative adversarial networks;non-intrusive load monitoring;recurrent neural networks;robustness to noise;sequence-to-sequence learning","Generative adversarial networks;Energy consumption;Hidden Markov models;Data models;Aggregates;Gallium nitride;Deep learning","domestic appliances;energy consumption;feature extraction;power consumption;power engineering computing;recurrent neural nets;source separation;time series","generative adversarial gated recurrent network;aggregated household energy consumption signal;additive sub-components;signal separation problem;appliance signatures;EnerGAN;generative adversarial networks;GAN;robust energy disaggregation;nonlinear power signal source separation;recurrent convolutional neural network;appliance energy consumption time series;EnerGAN++;feature extraction","","4","","51","CCBY","18 Dec 2020","","","IEEE","IEEE Journals"
"Robust unsupervised discriminative dependency parsing","Y. Jiang; J. Cai; K. Tu","School of Information Science and Technology, ShanghaiTech University, Shanghai 201210, China; Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai 200050; University of Chinese Academy of Sciences, Beijing 100049, China; School of Information Science and Technology, ShanghaiTech University, Shanghai 201210, China; School of Information Science and Technology, ShanghaiTech University, Shanghai 201210, China","Tsinghua Science and Technology","2 Sep 2019","2020","25","2","192","202","Discriminative approaches have shown their effectiveness in unsupervised dependency parsing. However, due to their strong representational power, discriminative approaches tend to quickly converge to poor local optima during unsupervised training. In this paper, we tackle this problem by drawing inspiration from robust deep learning techniques. Specifically, we propose robust unsupervised discriminative dependency parsing, a framework that integrates the concepts of denoising autoencoders and conditional random field autoencoders. Within this framework, we propose two types of sentence corruption mechanisms as well as a posterior regularization method for robust training. We tested our methods on eight languages and the results show that our methods lead to significant improvements over previous work.","1007-0214","","10.26599/TST.2018.9010145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8821513","unsupervised learning;dependency parsing;autoencoders","Training;Noise reduction;Unsupervised learning;Task analysis;Decoding;Support vector machines;Deep learning","grammars;unsupervised learning","robust unsupervised discriminative dependency parsing;deep learning techniques;random field autoencoders","","","","","","2 Sep 2019","","","TUP","TUP Journals"
"An Automatic Cardiac Arrhythmia Classification System With Wearable Electrocardiogram","Y. Xia; H. Zhang; L. Xu; Z. Gao; H. Zhang; H. Liu; S. Li","Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, Shenzhen, China; School of Information Engineering, Guangdong Medical University, Dongguan, China; Department of Cardiology, General Hospital of Guangzhou Military Command of PLA, Guangzhou, China; Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, Shenzhen, China; Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, Shenzhen, China; State Key Laboratory of Modern Optical Instrumentation, Zhejiang University, Hangzhou, China; Western University, London, ON, Canada","IEEE Access","3 May 2018","2018","6","","16529","16538","This paper presents an automatic wearable electrocardiogram (ECG) classification and monitoring system with stacked denoising autoencoder (SDAE). We use a wearable device with wireless sensors to obtain the ECG data, and send these ECG data to a computer with Bluetooth 4.2. Then, these ECG data are classified by the automatic cardiac arrhythmia classification system. First, the ECG feature representation is learned by the SDAE with sparsity constraint. Then, the softmax regression is used to classify the ECG beats. In the fine-tuning phase, an active learning is added to improve the performance. In the active learning phase, we use the method that relies on the deep neural networks posterior probabilities to associate confidence measures to select the most informative samples. Breaking-ties and modified breaking-ties methods are used to select the most informative samples. We validate the proposed method on the well-known MIT-BIH arrhythmia database and ECG data obtained from the wearable device. We follow the recommendations of the Association for the Advancement of Medical Instrumentation for class labeling and results presentation. The results show that the classification performance of our proposed approach outperforms the most of the state-of-the-art methods.","2169-3536","","10.1109/ACCESS.2018.2807700","National Key Research and Development Program of China(grant numbers:2016YFC1301700,2017YFE0104000); Shenzhen Dual Chain Funding(grant numbers:20170502171625936); National Natural Science Foundation of China(grant numbers:61771464,61427807); Science and Technology Planning Project of Guangdong Province(grant numbers:2014A020212257,2013A022100036); Guangzhou Science and Technology Planning Project(grant numbers:201704020079); Shenzhen Innovation Funding(grant numbers:JCYJ20151030151431727,JCYJ20150401145529007,SGLH20161212104605195); China Postdoctoral Science Foundation(grant numbers:2017M620394); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8300311","Stacked denoising autoencoder;wearable device;active learning;breaking-ties;modified breaking-ties","Electrocardiography;Biomedical monitoring;Feature extraction;Databases;Support vector machines;Noise reduction;Neural networks","electrocardiography;learning (artificial intelligence);medical signal processing;neural nets;signal classification","modified breaking-ties methods;breaking-ties method;class labeling;Association for the Advancement of Medical Instrumentation;monitoring system;wearable electrocardiogram;classification performance;active learning phase;ECG beats;SDAE;ECG feature representation;automatic cardiac arrhythmia classification system;ECG data;wearable device","","58","","38","OAPA","21 Feb 2018","","","IEEE","IEEE Journals"
"Deep Learning Modeling for Top-N Recommendation With Interests Exploring","W. Zhou; J. Li; M. Zhang; Y. Wang; F. Shah","School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Optoelectronic Information, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Access","5 Oct 2018","2018","6","","51440","51455","Recommender systems (RS) currently play a crucial role in information filtering and retrieval, and have been ubiquitously applied in many domains, although suffering from such data sparsity and cold start problems. There are plenty of studies that try to make efforts to improve the performance of RS through different aspects, such as traditional matrix factorization technique and deep learning methods in recent years, however, it's still a challenging issue under research. In this paper, motivated by this, a two-stage deep learning-based model for top-N recommendation with interests exploring (DLMR) is proposed: 1) DLMR explores latent interests for each user, captures factors from reviews and contextual information via convolutional neural network, and performs convolutional matrix factorization to generate the candidates list; 2) In order to enhance the recommendation performance, DLMR further conducts candidates ranking through a three-layer denoising autoencoder, with taking account of heterogeneous side information. The DLMR provides a flexible scheme to leverage the available resources for recommendation, which is able to explore user's latent interests, capture the intricate interactions between users and items, and provide accurate and personalized recommendations. Experimental analysis over real world data sets demonstrates that DLMR could provide high performance top-N recommendation in sparse settings and outperform state-of-the-art recommender approaches significantly.","2169-3536","","10.1109/ACCESS.2018.2869924","National Natural Science Foundation of China(grant numbers:61370073); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8463482","Sparse latent Dirichlet allocation;interest exploring;convolutional neural network;denoising autoencoder;top-N recommendation","Machine learning;Recommender systems;Convolutional neural networks;Noise reduction;Probabilistic logic;Resource management;Tools","convolution;feedforward neural nets;information filtering;learning (artificial intelligence);matrix decomposition;recommender systems","recommender systems;information filtering;DLMR;contextual information;convolutional neural network;heterogeneous side information;personalized recommendations;deep learning-based model for top-N recommendation;convolutional matrix factorization;user latent interests;information retrieval","","16","","47","OAPA","12 Sep 2018","","","IEEE","IEEE Journals"
"An Attention Guided Semi-Supervised Learning Mechanism to Detect Electricity Frauds in the Distribution Systems","Z. Aslam; F. Ahmed; A. Almogren; M. Shafiq; M. Zuair; N. Javaid","Department of Computer Science, COMSATS University Islamabad, Islamabad Campus, Islamabad, Pakistan; Department of Computer Science, COMSATS University Islamabad, Islamabad Campus, Islamabad, Pakistan; Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Department of Information and Communication Engineering, Yeungnam University, Gyeongsan, South Korea; Computer Engineering Department, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Department of Computer Science, COMSATS University Islamabad, Islamabad Campus, Islamabad, Pakistan","IEEE Access","17 Dec 2020","2020","8","","221767","221782","Electricity theft is one of the main causes of non-technical losses and its detection is important for power distribution companies to avoid revenue loss. The advancement of traditional grids to smart grids allows a two-way flow of information and energy that enables real-time energy management, billing and load surveillance. This infrastructure enables power distribution companies to automate electricity theft detection (ETD) by constructing new innovative data-driven solutions. Whereas, the traditional ETD approaches do not provide acceptable theft detection performance due to high-dimensional imbalanced data, loss of data relationships during feature extraction and the requirement of experts' involvement. Hence, this paper presents a new semi-supervised solution for ETD, which consists of relational denoising autoencoder (RDAE) and attention guided (AG) TripleGAN, named as RDAE-AG-TripleGAN. In this system, RDAE is implemented to derive features and their associations while AG performs feature weighting and dynamically supervises the AG-TripleGAN. As a result, this procedure significantly boosts the ETD. Furthermore, to demonstrate the acceptability of the proposed methodology over conventional approaches, we conducted extensive simulations using the real power consumption data of smart meters. The proposed solution is validated over the most useful and suitable performance indicators: area under the curve, precision, recall, Matthews correlation coefficient, F1-score and precision-recall area under the curve. The simulation results prove that the proposed method efficiently improves the detection of electricity frauds against conventional ETD schemes such as extreme gradient boosting machine and transductive support vector machine. The proposed solution achieves the detection rate of 0.956, which makes it more acceptable for electric utilities than the existing approaches.","2169-3536","","10.1109/ACCESS.2020.3042636","Deanship of Scientific Research at King Saud University(grant numbers:RG-1437-035); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9281043","Electricity theft detection;smart grids;relational denoising autoencoder;electricity consumption;TripleGAN","Feature extraction;Smart grids;Support vector machines;Noise reduction;Boosting;Reliability;Radio frequency","feature extraction;fraud;learning (artificial intelligence);power consumption;power distribution;power engineering computing;public utilities;security of data;smart power grids;support vector machines","transductive support vector machine;attention guided semisupervised learning;smart meters;power consumption data;RDAE-AG-TripleGAN;semisupervised solution;feature extraction;data relationships;high-dimensional imbalanced data;electricity theft detection;load surveillance;smart grids;traditional grids;revenue loss;power distribution companies;distribution systems;electricity fraud detection;electric utilities;detection rate;conventional ETD schemes","","16","","50","CCBY","4 Dec 2020","","","IEEE","IEEE Journals"
"On-Device Reliability Assessment and Prediction of Missing Photoplethysmographic Data Using Deep Neural Networks","M. Singha Roy; B. Roy; R. Gupta; K. Das Sharma","Electrical Engineering Section, Department of Applied Physics, University of Calcutta, Kolkata, India; Electronics & Communication Engineering Department, NITMAS, West Bengal, India; Electrical Engineering Section, Department of Applied Physics, University of Calcutta, Kolkata, India; Electrical Engineering Section, Department of Applied Physics, University of Calcutta, Kolkata, India","IEEE Transactions on Biomedical Circuits and Systems","31 Dec 2020","2020","14","6","1323","1332","Photoplethysmographic (PPG) measurements from ambulatory subjects may suffer from unreliability due to body movements and missing data segments due to loosening of sensor. This paper describes an on-device reliability assessment from PPG measurements using a stack denoising autoencoder (SDAE) and multilayer perceptron neural network (MLPNN). The missing segments were predicted by a personalized convolutional neural network (CNN) and long-short term memory (LSTM) model using a short history of the same channel data. Forty sets of volunteers' data, consisting of equal share of healthy and cardiovascular subjects were used for validation and testing. The PPG reliability assessment model (PRAM) achieved over 95% accuracy for correctly identifying acceptable PPG beats out of total 5000 using expert annotated data. Disagreement with experts' annotation was nearly 3.5%. The missing segment prediction model (MSPM) achieved a root mean square error (RMSE) of 0.22, and mean absolute error (MAE) of 0.11 for 40 missing beats prediction using only four beat history from the same channel PPG. The two models were integrated in a standalone device based on quad-core ARM Cortex-A53, 1.2 GHz, with 1 GB RAM, with 130 MB memory requirement and latency ~0.35 s per beat prediction with a 30 s frame. The present method also provides improved performance with published works on PPG quality assessment and missing data prediction using two public datasets, CinC and MIMIC-II under PhysioNet.","1940-9990","","10.1109/TBCAS.2020.3028935","University Grants Commission, India(grant numbers:029/17-18/1702); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9216529","Convolutional neural network;photoplethysmogram (PPG);on-device measurement;prediction of missing data;reliability assessment;stack denoising autoencoder","Predictive models;Reliability;Photoplethsymography;Long short term memory;Convolutional neural networks","cardiovascular system;electrocardiography;learning (artificial intelligence);mean square error methods;medical signal detection;medical signal processing;multilayer perceptrons;neural nets;patient monitoring;photoplethysmography","healthy subjects;cardiovascular subjects;PPG reliability assessment model;acceptable PPG;expert annotated data;missing segment prediction model;root mean square error;beats prediction;beat history;channel PPG;standalone device;beat prediction;PPG quality assessment;missing data prediction;on-device reliability assessment;missing photoplethysmographic data;deep neural networks;photoplethysmographic measurements;ambulatory subjects;body movements;missing data segments;PPG measurements;multilayer perceptron neural network;missing segments;personalized convolutional neural network;long-short term;short history;channel data;volunteers;time 30.0 s;frequency 1.2 GHz;memory size 1.0 GByte;memory size 130.0 MByte;time 0.35 s","Adult;Aged;Aged, 80 and over;Humans;Middle Aged;Neural Networks, Computer;Photoplethysmography;Reproducibility of Results;Signal Processing, Computer-Assisted;Young Adult","7","","43","IEEE","7 Oct 2020","","","IEEE","IEEE Journals"
"Day-Ahead Wind Power Forecasting Based on Single Point Clustering","S. Jiakang; P. Yonggang; X. Yanghong","College of electrical Engineering, Zhejiang University, Hangzhou; College of electrical Engineering, Zhejiang University, Hangzhou; College of electrical Engineering, Zhejiang University, Hangzhou","2018 37th Chinese Control Conference (CCC)","7 Oct 2018","2018","","","2479","2484","Wind power forecasting is significant for the security and economy of the power system. For the better robustness and accuracy, various clustering-based forecasting methods have been proposed. However, most of them utilize clustering on a daily sample basis usually called day clustering, which mainly exploits daily features of numerical weather prediction (NWP) and meets some limitations. In this paper, a single point clustering method is proposed to enhance the performance of day-ahead forecasting, which is conducted on a point sample basis through K-means algorithm. First, the extraction of clustering features is optimized. Being different from the commonly used clustering features, the high-order features extracted from NWP is used for the proposed method based on stacked denoising autoencoder (SDAE). Then, both the compactness within the single group and the separation among the multiple groups are enhanced, which is realized through choosing the number of clusters to maximize silhouette. In the case study, the proposed method is compared to the conventional day clustering method with two types of features and the single point clustering with the commonly used clustering features of NWP. Through the results, it is shown that the proposed method performs better than the other comparative methods.","1934-1768","978-988-15639-5-8","10.23919/ChiCC.2018.8482674","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8482674","Day-ahead forecasting;single point clustering;stacked denoising autoencoder;silhouette;K-means","Feature extraction;Forecasting;Wind power generation;Predictive models;Clustering algorithms;Noise reduction;Wind speed","load forecasting;pattern clustering;power engineering computing;weather forecasting;wind power;wind power plants","day-ahead wind power forecasting;power system;clustering-based forecasting methods;single point clustering method;day-ahead forecasting;point sample basis","","1","","18","","7 Oct 2018","","","IEEE","IEEE Conferences"
"A Hybrid CMOS-Memristive Approach to Designing Deep Generative Models","V. Parmar; M. Suri","Department of Electrical Engineering, IIT Delhi, New Delhi, India; Department of Electrical Engineering, IIT Delhi, New Delhi, India","IEEE Transactions on Neural Networks and Learning Systems","2 Jun 2021","2021","32","6","2790","2796","Deep learning and its applications have gained tremendous interest recently in both academia and industry. Restricted Boltzmann machines (RBMs) offer a key methodology to implement deep learning paradigms. This brief presents a novel approach for realizing hybrid CMOS-memristive-based deep generative models (DGMs). In our proposed DGM architecture, HfOx-based (filamentary-type switching) memristive devices are extensively used for realizing both computational as well as storage functions, such as: 1) synapses (weights); 2) internal neuron-state storage; 3) stochastic neuron activation; and 4) programmable signal normalization. To validate the proposed scheme, we have simulated two different architectures: 1) deep belief network (DBN) for classification and 2) stacked denoising autoencoder for the reconstruction of handwritten digits from the MNIST data set. The maximum test accuracy achieved by pretraining of the proposed DBN was 92.6%, whereas the best case mean squared error (mse) achieved by pretraining of the proposed SDA network was 0.046. When the proposed model-based weights are used for weight initialization, they offer a significant advantage in terms of learning performance in comparison with randomized initialization.","2162-2388","","10.1109/TNNLS.2020.3008154","Department of Science and Technology (DST) Science and Engineering Research Board (SERB) Core(grant numbers:CRG/2018/001901); Indian Institute of Technology Delhi (IITD) Multi-Institutional Faculty Interdisciplinary Research Project (MFIRP); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9146605","Deep belief network (DBN);deep generative models (DGMs);deep learning;memristors;restricted Boltzmann machine (RBM);resistive random access memory (RRAM);stacked denoising autoencoder (SDA)","Neurons;Computer architecture;Noise reduction;Switches;Architecture;Logic gates;Memristors","belief networks;Boltzmann machines;CMOS integrated circuits;deep learning (artificial intelligence);mean square error methods;memristors;pattern classification","handwritten digits;filamentary-type switching;deep generative models;model-based weights;internal neuron-state storage;storage functions;memristive devices;DGM architecture;hybrid CMOS-memristive-based deep generative models;deep learning;restricted Boltzmann machines;hybrid CMOS-memristive approach;learning performance","","1","","38","IEEE","23 Jul 2020","","","IEEE","IEEE Journals"
"A Multimodal Approach for Identifying Autism Spectrum Disorders in Children","J. Han; G. Jiang; G. Ouyang; X. Li","Beijing Key Laboratory of Learning and Cognition, School of Psychology, Capital Normal University, Beijing, China; School of Electrical Engineering, Yanshan University, Qinhuangdao, China; State Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal University, Beijing, China; State Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal University, Beijing, China","IEEE Transactions on Neural Systems and Rehabilitation Engineering","22 Jul 2022","2022","30","","2003","2011","Identification of autism spectrum disorder (ASD) in children is challenging due to the complexity and heterogeneity of ASD. Currently, most existing methods mainly rely on a single modality with limited information and often cannot achieve satisfactory performance. To address this issue, this paper investigates from internal neurophysiological and external behavior perspectives simultaneously and proposes a new multimodal diagnosis framework for identifying ASD in children with fusion of electroencephalogram (EEG) and eye-tracking (ET) data. Specifically, we designed a two-step multimodal feature learning and fusion model based on a typical deep learning algorithm, stacked denoising autoencoder (SDAE). In the first step, two SDAE models are designed for feature learning for EEG and ET modality, respectively. Then, a third SDAE model in the second step is designed to perform multimodal fusion with learned EEG and ET features in a concatenated way. Our designed multimodal identification model can automatically capture correlations and complementarity from behavior modality and neurophysiological modality in a latent feature space, and generate informative feature representations with better discriminability and generalization for enhanced identification performance. We collected a multimodal dataset containing 40 ASD children and 50 typically developing (TD) children to evaluate our proposed method. Experimental results showed that our proposed method achieved superior performance compared with two unimodal methods and a simple feature-level fusion method, which has promising potential to provide an objective and accurate diagnosis to assist clinicians.","1558-0210","","10.1109/TNSRE.2022.3192431","National Natural Science Foundation of China(grant numbers:62003228,61761166003); Science and Technology Development Project of Beijing Municipal Education Commission of China(grant numbers:KM202010028019); National Key Research and Development Program of China(grant numbers:2017YFC0820205); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9832930","Autism spectrum disorders (ASD);multimodal fusion;electroencephalogram (EEG);eye-tracking (ET);stacked denoising autoencoders;classification","Electroencephalography;Feature extraction;Behavioral sciences;Brain modeling;Variable speed drives;Pediatrics;Neuroimaging","electroencephalography;feature extraction;image fusion;image representation;learning (artificial intelligence);medical signal processing;neurophysiology;signal classification","unimodal methods;simple feature-level fusion method;multimodal approach;identifying autism spectrum disorders;autism spectrum disorder;single modality;internal neurophysiological behavior perspectives;external behavior perspectives;multimodal diagnosis framework;eye-tracking;two-step multimodal feature learning;fusion model;typical deep learning algorithm;SDAE model;multimodal fusion;designed multimodal identification model;behavior modality;neurophysiological modality;latent feature space;informative feature representations;enhanced identification performance;multimodal dataset;40 ASD children","Algorithms;Autism Spectrum Disorder;Child;Electroencephalography;Humans","","","37","CCBY","19 Jul 2022","","","IEEE","IEEE Journals"
"An Agreement Based Dynamic Routing Method for Fault Diagnosis in Power Network with Enhanced Noise Immunity","S. R. Fahim; S. M. Muyeen; Y. Sarker; S. K. Sarker; S. K. Das","American International University-Bangladesh, Dhaka, Bangladesh; Qatar University, Doha, Qatar; Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh; Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh; Rajshahi University of Engineering & Technology, Rajshahi, Bangladesh","2021 31st Australasian Universities Power Engineering Conference (AUPEC)","16 Nov 2021","2021","","","1","5","The stable operation of a power system often depends on inscribing the faults that may arise when transmitting and distributing electrical power. Characterizing these faults is necessary to analyze the post-fault oscillography of the power lines. The power lines are prone to be affected by noises. The noises are responsible to introduce uncertainty in operating conditions. The variation in operating conditions leads to an unbalanced system. The diagnosis of faults is essential to ensure the secured operation of a power network. This paper introduces a unified unsupervised learning framework for short circuit fault analysis of a power transmission line. The proposed approach works with a small number of data set and reduces the computational cost. It uses a capsule network that investigates the low-level fault-oriented features. To guarantee the robustness of the proposed framework against noises a stacked denoising-autoencoder is integrated and modeled. The performance of the proposed model is measured and compared with some of the techniques available in the literature in terms of noise. The test with field data for three types of fault classification results in an accuracy of 9 ms for fault triggering.","2474-1507","978-1-6654-3451-5","10.1109/AUPEC52110.2021.9597762","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9597762","Faults;transmission line;Capsule network;time series imaging;vector;denoising autoencoder","Fault diagnosis;Adaptation models;Power transmission lines;Uncertainty;Computational modeling;Noise reduction;Transmission line measurements","fault diagnosis;power engineering computing;power system stability;power transmission faults;power transmission lines;short-circuit currents;unsupervised learning","post-fault oscillography;power lines;operating conditions;unbalanced system;secured operation;power network;unified unsupervised learning framework;short circuit fault analysis;power transmission line;capsule network;low-level fault-oriented features;fault classification results;fault triggering;dynamic routing method;fault diagnosis;enhanced noise immunity;power system stable operation;electrical power distribution;agreement based dynamic routing method;time 9.0 ms","","","","16","IEEE","16 Nov 2021","","","IEEE","IEEE Conferences"
"SVDD-based Network Traffic Anomaly Detection Method with High Robustness","S. Dong; B. Zhang","PLA SSF IEU, Henan Key Laboratory of Information Security, Zhengzhou, China; PLA SSF IEU, Henan Key Laboratory of Information Security, Zhengzhou, China","2019 IEEE 5th International Conference on Computer and Communications (ICCC)","13 Apr 2020","2019","","","1522","1526","Due to attacks' strong concealment and rarity, it is still a big challenge to discriminate anomaly in network traffic, especially in big data era where the amount of traffic and the feature dimensionality of each flow are high. In this paper, we proposed a network traffic anomaly detection method based on stacked denoising autoencoders (SDA) and support vector data description (SVDD). The method used SDA to extract deep traffic features with high robustness and reduce the dimensionality of each flow's original features, and trained SVDD with the deep features of normal network flows to construct a one-class classifier so that it can detect any network anomaly accurately. The experimental results using the NSLKDD dataset show that the proposed method has a higher detection performance and a lower time-consuming of training the classifier compared with single SVDD.","","978-1-7281-4743-7","10.1109/ICCC47050.2019.9064205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9064205","anomaly detection;feature extraction;deep learning;stacked denoising autoencoders;support vector data description","Feature extraction;Anomaly detection;Training;Telecommunication traffic;Support vector machines;Robustness","computer network security;feature extraction;learning (artificial intelligence);pattern classification;support vector machines;telecommunication traffic","support vector data description;SDA;deep traffic features;SVDD;SVDD-based network traffic anomaly detection method;Big Data era;feature dimensionality;NSLKDD dataset;one-class classifier","","","","13","","13 Apr 2020","","","IEEE","IEEE Conferences"
"Intelligent Compensation Method of Infrared Temperature Measurement for Multiple Interference Factors","D. Pan; Z. Jiang; Y. Li; H. Yu; W. Gui","School of Automation, Central South University, Changsha, China; Peng Cheng Laboratory, Shenzhen, China; School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China","IEEE Sensors Journal","30 Sep 2022","2022","22","19","18550","18559","Infrared thermography is a widely used noncontact temperature measurement method. However, the infrared temperature measurement result is susceptible to interference factors. To overcome the infrared temperature measurement errors caused by the simultaneous influence of multiple interference factors, this article takes the measuring distance and dust as specific interference factors and proposes an intelligent compensation method for the infrared temperature measurement errors caused by the measuring distance and dust. First, the influence of the measuring distance and dust is analyzed from the perspective of the infrared temperature measurement principle. Second, a weighted ensemble stacked denoising autoencoder (WE-SDAE) is proposed and used to construct an intelligent compensation model. Then, the measuring distance, dust transmittance, and measured temperature are used as the input of the compensation model to estimate the errors caused by the measuring distance and dust. Finally, the estimated error is used to compensate for the original infrared temperature measurement results under multifactor interference. Experimental results in two cases show that the proposed method is effective in compensating for the infrared temperature measurement errors caused by the measuring distance and dust, which is beneficial to ensure the accuracy of the infrared thermal imager in complex temperature measurement scenarios.","1558-1748","","10.1109/JSEN.2022.3199264","National Major Scientific Research Equipment of China(grant numbers:61927803); Natural Science Foundation of Hunan Province, China(grant numbers:2022JJ40634); Changsha Natural Science Foundation Project(grant numbers:kq2202075); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9866650","Error analysis;infrared thermography;multifactor interference;stacked denoising autoencoder (DAE);temperature compensation","Temperature measurement;Measurement uncertainty;Interference;Atmospheric measurements;Temperature;Optical variables measurement;Optical imaging","","","","","","29","IEEE","24 Aug 2022","","","IEEE","IEEE Journals"
"Online Anomaly Detection with Streaming Data based on Fine-grained Feature Forecasting","K. Liu; W. Mao; H. Shi; C. Wu; J. Chen","School of Computer and Information Engineering Henan Normal University, Xinxiang, Henan, China; Engineering Lab of Intelligence Business & Internet of Things of Henan Province, Xinxiang, Henan, China; School of Computer and Information Engineering Henan Normal University, Xinxiang, Henan, China; School of Computer and Information Engineering Henan Normal University, Xinxiang, Henan, China; School of Computer and Information Engineering Henan Normal University, Xinxiang, Henan, China","2021 33rd Chinese Control and Decision Conference (CCDC)","30 Nov 2021","2021","","","454","459","In the industrial applications like fault diagnosis and health management, monitoring data generally reaches sequentially in a streaming form. To recognize fault occurrence in real time without system halt, it is necessary to improve the accuracy and stability of anomaly detection with streaming data. To solve this problem, a new online anomaly detection method with streaming data is proposed based on fine-grained feature forecasting. First, to conduct fine-grained decomposition of features, a denoising autoencoder network is run to extract multiple-dimensional deep features of online data in the initial period of normal state. Second, a forecasting model with tensor Tucker decomposition and ARIMA is conducted to predict the fluctuation trend of all feature sequences. Finally, the deviation degree between the prediction values and sequentially-arrived data is calculated, and an alarm threshold is built according to the 95% confidence interval of the maximum deviation. Then the anomalous state data can be detected in real time. This paper adopts the problem of bearing early fault online detection as an example, and run comparative experiments on the IEEE PHM Challenge 2012 bearing dataset. The results show that the proposed method has good detection accuracy and is with no false alarm, while the model training does not rely on any offline data. Then the proposed method is applicable to the problem of online anomaly detection","1948-9447","978-1-6654-4089-9","10.1109/CCDC52312.2021.9602609","National Key R&D Program of China(grant numbers:2018YFB1701400); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9602609","Streaming data;Denoising autoencoder;Anomaly detection;Alarm threshold;ARIMA model","Training;Tensors;Feature extraction;Real-time systems;Data models;Stability analysis;Robustness","condition monitoring;data handling;fault diagnosis;learning (artificial intelligence);machine bearings;mechanical engineering computing;statistical analysis;tensors","tensor Tucker decomposition;feature sequences;anomalous state data;good detection accuracy;offline data;fine-grained feature forecasting;fault diagnosis;health management;streaming form;fault occurrence;online anomaly detection method;multiple-dimensional deep features;online data;forecasting model","","","","14","IEEE","30 Nov 2021","","","IEEE","IEEE Conferences"
"Prediction of Defects Occurrence Time for Capacitive Device","J. Peng; F. -r. Zhou; H. -r. Xiang; Y. Ma; Z. -z. Zheng; S. -b. Jiang; J. Li","Electric Power Research Institute, Yunnan Power Grid Co., Ltd., Kunming, China; Electric Power Research Institute, Yunnan Power Grid Co., Ltd., Kunming, China; Electric Power Research Institute, Yunnan Power Grid Co., Ltd., Kunming, China; Electric Power Research Institute, Yunnan Power Grid Co., Ltd., Kunming, China; School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China; School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China; School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, China","2019 16th International Computer Conference on Wavelet Active Media Technology and Information Processing","16 Apr 2020","2019","","","226","229","In this paper, we propose an analysis method for defect data of capacitive devices and a method for predicting the occurrence time of defects based on the analysis method. This method is not sensitive to noise in data and has strong robustness. We analyze various features that may affect the occurrence time of capacitive device defects, and use sparse auto encoder (SAE) for dimensionality reduction and denoising. This unsupervised method learns the low-dimensional sparse features of nonlinear manifolds from the data features, which improves the generalization performance of the classifiers to a certain extent. Based on K-nearest regression (KNR), support vector regression (SVR), random forest (RF), gradient boosting decision tree (GBDT) and deep learning (DL) models, we predict the occurrence time of capacitive equipment defects respectively. The root means square error (RMSE) between prediction time and labels is only 243.80 days. Compared with the simple baseline model, the error is reduced by 1773.50 days, and the predicted result is state-of-the-art.","2576-8964","978-1-7281-4242-5","10.1109/ICCWAMTIP47768.2019.9067704","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9067704","Prediction of defects occurrence time;Capacitive devices;Sparse auto encoder;Gradient boosting decision tree","Predictive models;Radio frequency;Training;Feature extraction;Dimensionality reduction;Noise reduction;Regression tree analysis","capacitors;data analysis;decision trees;electronic engineering computing;feature extraction;generalisation (artificial intelligence);gradient methods;inspection;nearest neighbour methods;neural nets;pattern classification;random forests;regression analysis;support vector machines;unsupervised learning","capacitive device defects;dimensionality reduction;denoising;unsupervised method;low-dimensional sparse features;data features;capacitive equipment defects;sparse autoencoder;defect occurrence time prediction;defect data analysis method;nonlinear manifolds;generalization performance improvement;classifiers;K-nearest regression;support vector regression;random forest;gradient boosting decision tree;deep learning models;SVR;DL models","","","","7","","16 Apr 2020","","","IEEE","IEEE Conferences"
"Fault diagnosis method study in roller bearing based on wavelet transform and stacked auto-encoder","T. Junbo; L. Weining; A. Juneng; W. Xueqian","Center of Intelligent Control and Telescience, Tsinghua University, Beijing; Center of Intelligent Control and Telescience, Tsinghua University, Beijing; State Key Laboratory of Acoustics, Chinese Academy of Sciences, Beijing, 100190; Center of Intelligent Control and Telescience, Tsinghua University, Beijing","The 27th Chinese Control and Decision Conference (2015 CCDC)","20 Jul 2015","2015","","","4608","4613","Considering the nonlinear and non-stationary characteristics of fault vibration signal in the roller bearing system, an intelligent fault diagnosis model based on wavelet transform and stacked auto-encoder is proposed. This paper firstly uses the combination of digital wavelet frame (DWF) and nonlinear soft threshold method to de-noise fault vibration signal. Then stacked auto-encoder is taken to extract the fault signal feature, which is regarded as the input of BP network classifier. The output results of BP network classifier represent fault categories. In addition, neural network ensemble method is also adopted to greatly improve the recognition rate of fault diagnosis.","1948-9447","978-1-4799-7017-9","10.1109/CCDC.2015.7162738","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7162738","wavelet transform;stacked auto-encoder;roller bearing;fault diagnosis;deep learning","Feature extraction;Vibrations;Fault diagnosis;Wavelet transforms;Neural networks;Noise reduction","backpropagation;fault diagnosis;feature extraction;neural nets;rolling bearings;signal classification;signal denoising;vibrational signal processing;wavelet transforms","nonlinear characteristics;nonstationary characteristics;fault vibration signal;roller bearing system;intelligent fault diagnosis model;wavelet transform;stacked autoencoder;digital wavelet frame;nonlinear soft threshold method;fault vibration signal denoising;fault signal feature extraction;BP network classifier;fault categories;neural network ensemble method;fault diagnosis recognition rate;roller bearing","","34","7","10","","20 Jul 2015","","","IEEE","IEEE Conferences"
"Intelligent Process Monitoring of Laser-Induced Graphene Production With Deep Transfer Learning","M. Xia; H. Shao; Z. Huang; Z. Zhao; F. Jiang; Y. Hu","Department of Engineering, Lancaster University, Lancaster, U.K; College of Mechanical and Vehicle Engineering, Hunan University, Changsha, China; Institute of Technological Sciences, Wuhan University, Wuhan, China; Institute of Technological Sciences, Wuhan University, Wuhan, China; Institute of Technological Sciences, Wuhan University, Wuhan, China; Institute of Technological Sciences, Wuhan University, Wuhan, China","IEEE Transactions on Instrumentation and Measurement","8 Jul 2022","2022","71","","1","9","Three-dimensional graphene has been increasingly used in many applications due to its superior properties. The laser-induced graphene (LIG) technique is an effective way to produce 3-D graphene by combining graphene preparation and patterning into a single step using direct laser writing. However, the variation in process parameters and environment could largely affect the formation and crystallization quality of 3-D graphene. This article develops a vision and deep transfer learning-based processing monitoring system for LIG production. To solve the problem of limited labeled data, novel convolutional de-noising auto-encoder (CDAE)-based unsupervised learning is developed to utilize the available unlabeled images. The learned weights from CDAE are then transferred to a Gaussian convolutional deep belief network (GCDBN) model for further fine-tuning with a very small amount of labeled images. The experimental results show that the proposed method can achieve the state-of-art performance of precise and robust monitoring for the quality of the LIG formation.","1557-9662","","10.1109/TIM.2022.3186688","National Natural Science Foundation of China(grant numbers:51901162,51905160); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9808183","Deep transfer learning;laser-induced graphene (LIG);process monitoring;semi-supervised learning","Graphene;Three-dimensional displays;Manufacturing;Production;Process monitoring;Laser modes;Cameras","belief networks;computer vision;convolutional neural nets;deep learning (artificial intelligence);feature extraction;graphene;image denoising;laser materials processing;process monitoring;production engineering computing;unsupervised learning","convolutional denoising autoencoder-based unsupervised learning;three-dimensional graphene;laser-induced graphene production;intelligent process monitoring;LIG formation;robust monitoring;precise monitoring;Gaussian convolutional deep belief network model;learned weights;CDAE;LIG production;monitoring system;deep transfer learning;crystallization quality;process parameters;direct laser writing;patterning;graphene preparation;3D graphene","","","","25","IEEE","27 Jun 2022","","","IEEE","IEEE Journals"
"Competent Ultra Data Compression By Enhanced Features Excerption Using Deep Learning Techniques","P. Nagaraj; J. S. Rao; V. Muneeswaran; A. Sudheer Kumar; K. Muthamil sudar","Dept. of CSE, Kalasalingam Academy of Research and Education, Tamilnadu, India; Dept. of CSE, Kalasalingam Academy of Research and Education, Tamilnadu, India; Dept. of ECE, Kalasalingam Academy of Research and Education, Tamilnadu, India; Dept. of CSE, Kalasalingam Academy of Research and Education, Tamilnadu, India; Dept. of CSE, Kalasalingam Academy of Research and Education, Tamilnadu, India","2020 4th International Conference on Intelligent Computing and Control Systems (ICICCS)","19 Jun 2020","2020","","","1061","1066","The objective of data compression is to extract the main features of the data and to restore the decompressed data from latent space i.e., compressed data without any quality or noise. In this paper, a Convolutional LSTM model is proposed to reduce the redundancy data and unnecessary information in the data set. The proposed methodology normalizes the picture to reduce blur and noises, with a compression ratio of 50%. The Convolutional LSTM model is compared with other models such as autoencoder, denoising autoencoder, convolutional neural network and our present work shows better RMSE compared to the other models. Datasets like MNIST and other datasets are used for testing and training the images.","","978-1-7281-4876-2","10.1109/ICICCS48265.2020.9121126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121126","Data compression;Feature Extraction;latent space;CNN (Convolutional Neural Networks)","","convolutional neural nets;data compression;image denoising;image restoration;learning (artificial intelligence);mean square error methods;recurrent neural nets","deep learning;redundancy data;convolutional neural network;ultra data compression;features excerption;latent space;convolutional LSTM","","20","","24","","19 Jun 2020","","","IEEE","IEEE Conferences"
"Encoding Multi-Resolution Brain Networks Using Unsupervised Deep Learning","A. Rahnama; A. Alchihabi; V. Gupta; P. J. Antsaklis; F. T. Yarman Vural","Department of Electrical Engineering, University of Notre Dame, Notre Dame, USA; Department of Computer Engineering, Middle East Technical University, Ankara, Turkey; Department of Electrical Engineering, University of Notre Dame, Notre Dame, USA; Department of Electrical Engineering, University of Notre Dame, Notre Dame, USA; Orta Dogu Teknik Universitesi, Ankara, Ankara, TR","2017 IEEE 17th International Conference on Bioinformatics and Bioengineering (BIBE)","11 Jan 2018","2017","","","75","80","The main goal of this study is to extract a set of brain networks in multiple time-resolutions to analyze the connectivity patterns among the anatomic regions for a given cognitive task. We suggest a deep architecture which learns the natural groupings of the connectivity patterns of human brain in multiple time-resolutions. The suggested architecture is tested on task data set of Human Connectome Project (HCP) where we extract multi-resolution networks, each of which corresponds to a cognitive task. At the first level of this architecture, we decompose the fMRI signal into multiple sub-bands using wavelet decompositions. At the second level, for each sub-band, we estimate a brain network extracted from short time windows of the fMRI signal. At the third level, we feed the adjacency matrices of each mesh network at each time-resolution into an unsupervised deep learning algorithm, namely, a Stacked De- noising Auto-Encoder (SDAE). The outputs of the SDAE provide a compact connectivity representation for each time window at each sub-band of the fMRI signal. We concatenate the learned representations of all sub-bands at each window and cluster them by a hierarchical algorithm to find the natural groupings among the windows. We observe that each cluster represents a cognitive task with a performance of 93% Rand Index and 71% Adjusted Rand Index. We visualize the mean values and the precisions of the networks at each component of the cluster mixture. The mean brain networks at cluster centers show the variations among cognitive tasks and the precision of each cluster shows the within cluster variability of networks, across the subjects.","2471-7819","978-1-5386-1324-5","10.1109/BIBE.2017.00-75","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8251269","Deep Learning;Stacked Autoencoders;Brain Decoding;Mesh Networks;Connectivity Patterns;Clustering","Mesh networks;Machine learning;Clustering algorithms;Decoding;Indexes","biomedical MRI;brain;cognition;feature extraction;neurophysiology;pattern clustering;signal representation;signal resolution;unsupervised learning","multiresolution brain networks;connectivity patterns;deep architecture;natural groupings;human brain;task data set;Human Connectome Project;multiresolution networks;fMRI signal;multiple sub-bands;short time windows;mesh network;unsupervised deep learning algorithm;compact connectivity representation;learned representations;mean brain networks;cognitive task;stacked denoising autoencoder","","","","15","","11 Jan 2018","","","IEEE","IEEE Conferences"
"Enhancing Robustness Against Adversarial Examples in Network Intrusion Detection Systems","M. J. Hashemi; E. Keller","Department of Computer Science, University of Colorado Boulder, Boulder, CO, USA; Department of Electrical Computer and Energy Engineering, University of Colorado Boulder, Boulder, CO, USA","2020 IEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN)","24 Dec 2020","2020","","","37","43","The increase of cyber attacks in both the numbers and varieties in recent years demands to build a more sophisticated network intrusion detection system (NIDS). These NIDS perform better when they can monitor all the traffic traversing through the network like when being deployed on a Software-Defined Network (SDN). Because of the inability to detect zero-day attacks, signature-based NIDS which were traditionally used for detecting malicious traffic are beginning to get replaced by anomaly-based NIDS built on neural networks. However, recently it has been shown that such NIDS have their own drawback namely being vulnerable to the adversarial example attack. Moreover, they were mostly evaluated on the old datasets which don't represent the variety of attacks network systems might face these days. In this paper, we present Reconstruction from Partial Observation (RePO) as a new mechanism to build an NIDS with the help of denoising autoencoders capable of detecting different types of network attacks in a low false alert setting with an enhanced robustness against adversarial example attack. Our evaluation conducted on a dataset with a variety of network attacks shows denoising autoencoders can improve detection of malicious traffic by up to 29% in a normal setting and by up to 45% in an adversarial setting compared to other recently proposed anomaly detectors.","","978-1-7281-8159-2","10.1109/NFV-SDN50289.2020.9289869","NSF(grant numbers:1700527); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9289869","Intrusion Detection Systems;Neural Networks;Anomaly Detection;Adversarial Example","Noise reduction;Neural networks;Network intrusion detection;Robustness;Network function virtualization;Software defined networking;Monitoring","computer network security;security of data;software defined networking;telecommunication traffic","denoising autoencoders;reconstruction from partial observation;software-defined network;adversarial setting;network attacks;attacks network systems;adversarial example attack;neural networks;anomaly-based NIDS;malicious traffic;signature-based NIDS;zero-day attacks;traffic traversing;network intrusion detection system;cyber attacks","","7","","25","","24 Dec 2020","","","IEEE","IEEE Conferences"
"Machine Learning Applied to the Underwater Radar-Encoded Laser System","D. W. Illig; K. X. Kocan; L. J. Mullen","NAWCAD,Electro-Optics and Special Mission Sensors Division,Patuxent River,MD,USA; NAWCAD,Electro-Optics and Special Mission Sensors Division,Patuxent River,MD,USA; NAWCAD,Electro-Optics and Special Mission Sensors Division,Patuxent River,MD,USA","Global Oceans 2020: Singapore – U.S. Gulf Coast","9 Apr 2021","2020","","","1","6","In this work we demonstrate the use of machine learning to enhance imagery collected by the underwater radar-encoded laser imaging system. Laser-based sensors offer the potential for high-resolution, three-dimensional imaging in the underwater environment. However, these capabilities become degraded in turbid water environments due to scattering. This work presents experimental results applying a denoising autoencoder to imagery collected in our lab test tank. We experiment with both shallow and deep network architectures at a variety of water conditions. The use of machine learning allows us to suppress both backscatter and forward scatter. In particular, by applying the denoising autoencoder we are able to acquire imagery at 6.9 attenuation lengths, representing a 25% improvement over our baseline processing scheme.","0197-7385","978-1-7281-5446-6","10.1109/IEEECONF38699.2020.9389092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9389092","imaging;lasers;lidar;machine learning;scattering","Laser radar;Oceans;Noise reduction;Scattering;Machine learning;Radar imaging;Sensors","image sensors;learning (artificial intelligence);turbidity;underwater optics","underwater radar-encoded laser system;machine learning;imagery;underwater radar-encoded laser imaging system;laser-based sensors;three-dimensional imaging;underwater environment;turbid water environments;denoising autoencoder;lab test tank;shallow network architectures;deep network architectures;water conditions","","1","","19","","9 Apr 2021","","","IEEE","IEEE Conferences"
"Encoding Broad Learning System : An Effective Shallow Model For Anti-fraud","R. Zhong; Z. Zhang; R. Lin; H. Zou","Science and Technology on Communication Networks Laboratory; National Computer Network Emergency Response Technical Team/Coordination Center of China; Science and Technology on Communication Networks Laboratory; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China","2020 IEEE International Conference on Big Data (Big Data)","19 Mar 2021","2020","","","5496","5504","The criminal behavior of telecom fraud is increasing rapidly with the development of the communication industry, causing huge losses every year. The commonly used traditional fraud detection methods are less flexible. Currently, a more accurate and timely method is needed to deal with the evolving fraud. However, with the development of deep learning, more and more complex structures and a large number of parameters lead to the more time-consuming training process and poor interpretability which are unacceptable in the field of anti-fraud. Therefore, this paper proposes a shallow model called Encoding Broad Learning by incorporating the denoising autoencoder into the Broad Learning System (BLS). We use the first 15 seconds of the call content to process the text data of the fraudulent call by constructing TF-IDF, adding Gaussian noise to it, and combining with the denoising autoencoder to learn more general and robust features in the data. Then it is transformed into a neural network based on BLS, and fraudulent calls are identified on this model. This method is extremely suitable for fraud identification systems with few data features and high real-time training requirements. At the same time, in order to further improve the training efficiency and solve the potential memory explosion problem, we propose an integrated learning algorithm for parallel training of EBLS. Experiments and detailed analysis of the above methods are carried out. The results show that compared with the existing classic network algorithms, this method has a faster training speed, can ensure the accuracy and timeliness of online fraud identification, and help quickly identify fraudulent calls. The paper visualized the training results of these algorithms after processing the relevant parameters of EBLS training. These algorithms have strong interpretability and better meet the high security requirements in the field of anti-fraud.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9378330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378330","anti-fraud;broad learning;encoder;ensemble learning;parallel","Training;Learning systems;Noise reduction;Big Data;Encoding;Telecommunications;Security","deep learning (artificial intelligence);feature extraction;fraud;Gaussian noise;telecommunication computing;telecommunication industry;telecommunication security;text analysis","fraud identification systems;data features;real-time training requirements;integrated learning algorithm;training speed;online fraud identification;EBLS training;Encoding Broad Learning System;telecom fraud;deep learning;time-consuming training process;denoising autoencoder;text data;antifraud model;fraud detection;criminal behavior;communication industry;call content;TF-IDF;Gaussian noise;robust feature learning;memory explosion problem;EBLS;fraudulent call identification;security requirements;time 15.0 s","","","","27","","19 Mar 2021","","","IEEE","IEEE Conferences"
"Large-Scale and High-Dimensional Cell Outage Detection in 5G Self-Organizing Networks","P. -C. Lin","Department of Electrical Engineering, Yuan Ze University, Taoyuan, Taiwan","2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","5 Mar 2020","2019","","","8","12","In this paper, we investigate the cell outage detection in Self-Organizing Networks. The purpose of cell outage detection is to automatically detect whether there exist some failures or degradation in the base stations, such that users could not obtain mobile services, or the obtained mobile services do not fulfill their requirements. The cell outage detection in 5G is with great challenge. The deployment of future 5G mobile communication networks would be heterogeneous and ultra-dense. The mobile communication environments are very complicated. They include the multipath transmission, fading, shadowing, interference, and so on. Users' mobility and usage pattern also vary. In such environments, the mobile data would be large-scale and high-dimensional. Traditional small-scale and low-dimensional anomaly detection methods would be unsuitable. Moreover, operational mobile communication networks should be normal almost all the time. Cell outage would be seldom. Therefore, the normal data and anomaly data would be imbalanced. In this paper, we formulate the cell outage detection problem as an anomaly detection problem. We propose an cell outage detection method using the autoencoder, which is a neural network that is trained by unsupervised learning. The network could be trained in advance even when the cell outage data is still not available. Moreover, the autoencoder is also useful for denoising. This proposed method could thus automatically detect the cell outage in complicated and time-varying mobile wireless communication environments. Comprehensive system-level simulations validate the performance of the pronosed method.","2640-0103","978-1-7281-3248-8","10.1109/APSIPAASC47483.2019.9023348","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9023348","5G;Self-Organizing Network;Cell Outage Detection;Autoencoder","Base stations;5G mobile communication;Anomaly detection;Training;Testing;Hidden Markov models","5G mobile communication;cellular radio;mobile communication;mobile radio;self-organising feature maps;telecommunication computing;unsupervised learning;wireless channels","high-dimensional cell outage detection;5G self-organizing networks;mobile services;5G mobile communication networks;mobile communication environments;mobile data;mobile communication networks;anomaly detection problem;large-scale cell outage detection;unsupervised learning","","7","","12","","5 Mar 2020","","","IEEE","IEEE Conferences"
"Evolutionary Multitasking via Artificial Neural Networks","X. Chen; Y. Huang; W. Zhou; L. Feng","college of Computer Science, Chongqing University, Chongqing, China; college of Computer Science, Chongqing University, Chongqing, China; college of Computer Science, Chongqing University, Chongqing, China; college of Computer Science, Chongqing University, Chongqing, China","2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","6 Jan 2022","2021","","","1545","1552","Evolutionary Multi-Tasking (EMT), which solves multiple optimization tasks simultaneously, is a burgeoning topic in the area of evolutionary computation. As the EMT transfers useful knowledge across tasks to guide the search while the optimization process progresses online, superior search performance has been obtained in many recent attempts. Autoencoding evolutionary multitasking is a recently proposed EMT algorithm, which employs a single-layer denoising auto-encoder for knowledge transfer. However, since the autoencoding evolutionary multitasking (AEEMT) algorithm learns the relationships between tasks through a linear auto-encoder, it may lead to negative transfer in cases that the linear variable relationship does not hold across tasks. Taking this cue, we propose an evolutionary multitasking algorithm with artificial neural networks for transferring knowledge across tasks in this paper, which possesses higher modeling capability of variable relationships. To test and verify the efficiency and effectiveness of the proposed model, we conducted comprehensive empirical studies on the well-known single-objectives multi-task optimization benchmarks. The experimental results have shown that the proposed method has a remarkable effect on the evolutionary search in terms of both search speed and solution quality and comparing to the autoencoding evolutionary multitasking algorithms and the single-task evolutionary counterpart.","2577-1655","978-1-6654-4207-7","10.1109/SMC52423.2021.9659031","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9659031","Evolutionary Multi-tasking;Knowledge Transfer;Neural Network;Multi-task Optimization","Knowledge engineering;Uncertainty;Heuristic algorithms;Noise reduction;Artificial neural networks;Benchmark testing;Multitasking","evolutionary computation;learning (artificial intelligence);neural nets;search problems","evolutionary computation;EMT;optimization process;superior search performance;knowledge transfer;linear autoencoder;negative transfer;linear variable relationship;evolutionary multitasking algorithm;artificial neural networks;evolutionary search;search speed;autoencoding evolutionary multitasking algorithms;multiple optimization tasks;single task evolutionary counterpart;single objectives multitask optimization benchmarks;single layer denoising autoencoder","","","","30","IEEE","6 Jan 2022","","","IEEE","IEEE Conferences"
"Unsupervised Feature Learning Based on Deep Models for Environmental Audio Tagging","Y. Xu; Q. Huang; W. Wang; P. Foster; S. Sigtia; P. J. B. Jackson; M. D. Plumbley","Centre for Vision, University of Surrey, Guildford, U.K.; Centre for Vision, University of Surrey, Guildford, U.K.; Centre for Vision, University of Surrey, Guildford, U.K.; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.; Centre for Vision, University of Surrey, Guildford, U.K.; Centre for Vision, University of Surrey, Guildford, U.K.","IEEE/ACM Transactions on Audio, Speech, and Language Processing","23 May 2017","2017","25","6","1230","1241","Environmental audio tagging aims to predict only the presence or absence of certain acoustic events in the interested acoustic scene. In this paper, we make contributions to audio tagging in two parts, respectively, acoustic modeling and feature learning. We propose to use a shrinking deep neural network (DNN) framework incorporating unsupervised feature learning to handle the multilabel classification task. For the acoustic modeling, a large set of contextual frames of the chunk are fed into the DNN to perform a multilabel classification for the expected tags, considering that only chunk (or utterance) level rather than frame-level labels are available. Dropout and background noise aware training are also adopted to improve the generalization capability of the DNNs. For the unsupervised feature learning, we propose to use a symmetric or asymmetric deep denoising auto-encoder (syDAE or asyDAE) to generate new data-driven features from the logarithmic Mel-filter banks features. The new features, which are smoothed against background noise and more compact with contextual information, can further improve the performance of the DNN baseline. Compared with the standard Gaussian mixture model baseline of the DCASE 2016 audio tagging challenge, our proposed method obtains a significant equal error rate (EER) reduction from 0.21 to 0.13 on the development set. The proposed asyDAE system can get a relative 6.7% EER reduction compared with the strong DNN baseline on the development set. Finally, the results also show that our approach obtains the state-of-the-art performance with 0.15 EER on the evaluation set of the DCASE 2016 audio tagging task while EER of the first prize of this challenge is 0.17.","2329-9304","","10.1109/TASLP.2017.2690563","Engineering and Physical Sciences Research Council (EPSRC)(grant numbers:EP/N014111/1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7933054","DCASE 2016;deep neural networks;deep de-noising auto-encoder;environmental audio tagging;unsupervised feature learning","Tagging;Noise measurement;Acoustics;Training;Machine learning;Speech;Audio recording","audio signals;Gaussian processes;mixture models;neural nets","unsupervised feature learning;deep model;environmental audio tagging;acoustic events;acoustic scene;acoustic modeling;shrinking deep neural network;DNN framework;multilabel classification task;frame-level label;background noise-aware training;dropout aware training;asymmetric deep denoising autoencoder;symmetric deep denoising auto-encoder;standard Gaussian mixture model baseline;DCASE 2016 audio tagging challenge;equal error rate reduction","","41","","49","CCBY","23 May 2017","","","IEEE","IEEE Journals"
"Modulation Filter Learning Using Deep Variational Networks for Robust Speech Recognition","P. Agrawal; S. Ganapathy","Learning and Extraction of Acoustic Patterns Lab, Department of Electrical Engineering, Indian Institute of Science, Bangalore, India; Learning and Extraction of Acoustic Patterns Lab, Department of Electrical Engineering, Indian Institute of Science, Bangalore, India","IEEE Journal of Selected Topics in Signal Processing","17 May 2019","2019","13","2","244","253","The performance of a typical speech recognition system is degraded in the presence of extrinsic sources like noise and due to the recording artifacts like reverberation. The principle of modulation filtering attempts to remove the spectro-temporal modulations of the speech signal that are more susceptible to noise while preserving the key modulations for speech recognition. While traditional approaches use modulation filters that are hand-crafted, we propose a novel method for modulation filter learning using deep variational models in this paper. Specifically, we pose the filter learning problem in a deep unsupervised generative modeling framework where the convolutional filters in the variational autoencoder capture the important speech modulations. The two-dimensional modulation filters, learned using the deep variational networks in the joint spectro-temporal domain, are used to process the spectrogram features for speech recognition task. Several speech recognition experiments are performed on a set of tasks consisting of additive noise with channel artifacts (Aurora-4), reverberation (REVERB Challenge), and additive noise with reverberation (CHiME-3). In these experiments, the proposed modulation filter learning framework shows significant improvements over the baseline features as well as various other noise robust front-ends (average relative improvements of 7.5% and 20% over the baseline features on the Aurora-4 and CHiME-3 databases respectively). Furthermore, the proposed method is also shown to be of considerable benefit for semi-supervised automatic speech recognition applications. For example, on Aurora-4 database we observe an average relative improvement of 25% over the baseline system using 30% labeled training data.","1941-0484","","10.1109/JSTSP.2019.2913965","Department of Science and Technology; Department of Atomic Energy, Government of India; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8703845","Unsupervised filter learning;deep variational autoencoder;modulation filtering;noise robust speech recognition","Modulation;Speech recognition;Decoding;Spectrogram;Reverberation;Convolution;Training","filtering theory;modulation;neural nets;signal denoising;speech recognition;unsupervised learning","deep variational networks;spectro-temporal modulations;speech signal;deep variational models;filter learning problem;deep unsupervised generative modeling framework;convolutional filters;two-dimensional modulation filters;speech recognition task;additive noise;semisupervised automatic speech recognition applications;speech recognition system;speech modulations","","19","","48","IEEE","1 May 2019","","","IEEE","IEEE Journals"
"Problem-based band selection for hyperspectral images","M. Habermann; V. Fremont; E. H. Shiguemori","Brazilian Air Force, Institute for Advanced Studies, Brazil; Sorbonne Universités, Heudiasyc UMR 7253, Compiègne cedex, France; Brazilian Air Force, Institute for Advanced Studies, Brazil","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","1800","1803","This paper addresses the band selection of a hyperspectral image. Considering a binary classification, we devise a method to choose the more discriminating bands for the separation of the two classes involved, by using a simple algorithm: single-layer neural network. After that, the most discriminative bands are selected, and the resulting reduced data set is used in a more powerful classifier, namely, stacked denoising autoencoder. Besides its simplicity, the advantage of this method is that the selection of features is made by an algorithm similar to the classifier to be used, and not focused only on the separability measures of the data set. Results indicate the decrease of overfitting for the reduced data set, when compared to the full data architecture.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8127325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8127325","Band Selection;Deep Learning;Artificial Neural Networks;Feature Selection;Binary Classification","Feature extraction;Training;Neural networks;Error analysis;Training data;Hyperspectral imaging","feature extraction;geophysical image processing;image denoising;learning (artificial intelligence);neural nets","powerful classifier;band selection;hyperspectral image;binary classification;discriminating bands;single-layer neural network;discriminative bands;resulting reduced data set","","2","","7","","4 Dec 2017","","","IEEE","IEEE Conferences"
"Speech Enhancement via Attention Masking Network (SEAMNET): An End-to-End System for Joint Suppression of Noise and Reverberation","B. J. Borgström; M. S. Brandstein","Massachusetts Institute of Technology Lincoln Laboratory, Lexington, Massachusetts, USA; Massachusetts Institute of Technology Lincoln Laboratory, Lexington, Massachusetts, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","7 Jan 2021","2021","29","","515","526","This paper proposes the Speech Enhancement via Attention Masking Network (SEAMNET), a neural network-based end-to-end single-channel speech enhancement system designed for joint suppression of noise and reverberation. It formalizes an end-to-end network architecture, referred to as b-Net, which accomplishes noise suppression through attention masking in a learned embedding space. A key contribution of SEAMNET is that the b-Net architecture contains both an enhancement and an autoencoder path. This paper proposes a novel loss function which simultaneously trains both the enhancement and the autoencoder paths, so that disabling the masking mechanism during inference causes SEAMNET to reconstruct the input speech signal. This allows dynamic control of the level of suppression applied by SEAMNET via a minimum gain level, which is not possible in other state-of-the-art approaches to end-to-end speech enhancement. This paper also proposes a perceptually-motivated waveform distance measure. In addition to the b-Net architecture, this paper proposes a novel method for designing target waveforms for network training, so that joint suppression of additive noise and reverberation can be performed by an end-to-end enhancement system, which has not been previously possible. Experimental results show the SEAMNET system to outperform a variety of state-of-the-art baselines systems, both in terms of objective speech quality measures and subjective listening tests. Finally, this paper draws parallels between SEAMNET and conventional statistical model-based enhancement approaches, offering interpretability of many network components.","2329-9304","","10.1109/TASLP.2020.3043655","Department of Defense under Air Force(grant numbers:FA8702-15-D-0001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288904","Convolutional neural network;end-to-end neural network;noise suppression;reverberation suppression;speech enhancement","Speech enhancement;Reverberation;Estimation;Noise reduction;Noise measurement;Training;Task analysis","learning (artificial intelligence);neural nets;signal denoising;speech enhancement","Attention Masking Network;end-to-end system;reverberation;neural network-based end-to-end single-channel speech enhancement system;end-to-end network architecture;noise suppression;b-Net architecture;autoencoder path;masking mechanism;input speech signal;end-to-end speech enhancement;network training;additive noise;end-to-end enhancement system;SEAMNET system;state-of-the-art baselines systems;objective speech quality measures;conventional statistical model-based enhancement approaches;network components","","5","","73","IEEE","9 Dec 2020","","","IEEE","IEEE Journals"
"Remote Photoplethysmography Enhancement with Machine Leaning Methods","B. -F. Wu; P. -W. Huang; D. -H. He; C. -H. Lin; K. -H. Chen","Institute of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Institute of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Institute of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Institute of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Institute of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan","2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)","28 Nov 2019","2019","","","2466","2471","Driver's physiological state is highly correlated to the traffic safety. An affordable and convenient way to monitor driver's physiological state is remote Photoplethysmography (rPPG). Earlier algorithms achieved high accuracy on measuring rPPG signals in stationary case. But in real cases, such as driving, rPPG signals might be corrupted with interference. To obtain higher Signal-to-Noise-Ratio (SNR) rPPG signals, three algorithms are proposed. The PCA spectral subtraction (PCA-SS) considers the spectrum of the environmental noise and utilizes the energy subtraction to reduce the noise. The machine learning methods, convolution autoencoder (CAE) and multi-channel convolution autoencoder (Multi-CAE), are adopted in order to enhance the rPPG signal. The test data we used are 187 videos recorded in stationary case, passenger case, and real driving situation. In driving situation, the Multi-CAE method, in comparison with the original method provided by W. Wang et al. [1] and G. De Haan et al. [2], achieves 33% & 35% reduction in MAE, RMSE respectively, and 11% improvement in success rate [3].","2577-1655","978-1-7281-4569-3","10.1109/SMC.2019.8914554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8914554","","Databases;Convolution;Spectrogram;Time-frequency analysis;Heart rate;Motion artifacts;Vehicles","learning (artificial intelligence);mean square error methods;photoplethysmography;principal component analysis;signal denoising;video recording","remote photoplethysmography enhancement;driver;earlier algorithms achieved high accuracy;rPPG signal;stationary case;higher Signal-to-Noise-Ratio rPPG signals;PCA spectral subtraction;environmental noise;multichannel convolution autoencoder;passenger case;driving situation;MultiCAE method","","1","","19","","28 Nov 2019","","","IEEE","IEEE Conferences"
"Towards speech enhancement using a variational U-Net architecture","E. J. Nustede; J. Anemüller","Dept. med. Physics & Acoustics and Cluster of Excellence Hearing4all, Carl von Ossietzky University Oldenburg, Computational Audition Group, Oldenburg, Germany; Dept. med. Physics & Acoustics and Cluster of Excellence Hearing4all, Carl von Ossietzky University Oldenburg, Computational Audition Group, Oldenburg, Germany","2021 29th European Signal Processing Conference (EUSIPCO)","8 Dec 2021","2021","","","481","485","We investigate the viability of a variational U-Net architecture for denoising of single-channel audio data. Deep network speech enhancement systems commonly aim to estimate filter masks, or opt to work on the waveform signal, potentially neglecting relationships across higher dimensional spectro-temporal features. We study the adoption of a probabilistic (variational) bottleneck into the classic U-Net architecture for direct spectral reconstruction. Evaluation of several ablation network variants is carried out using signal-to-distortion ratio and perceptual measures, on audio data that includes known and unknown noise types as well as reverberation. Our experiments show that the residual (skip) connections in the proposed system are a prerequisite for successful spectral reconstruction, i.e., without filter mask estimation. Results show, on average, an advantage of the proposed variational U-Net architecture over its classic, non-variational version in signal enhancement performance under reverberant conditions of 0.31 and 6.98 in PESQ and STOI scores, respectively. Anecdotal evidence points to improved suppression of impulsive noise sources with the variational U-Net compared to the recurrent mask estimation network baseline.","2076-1465","978-9-0827-9706-0","10.23919/EUSIPCO54536.2021.9616114","Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)(grant numbers:352015383,SFB 1330/B3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616114","Speech enhancement;U-Net architecture;variational autoencoder;deep learning;audio source separation","Training;Source separation;Estimation;Speech enhancement;Probabilistic logic;Data models;Reverberation","filtering theory;probability;signal denoising;signal reconstruction;speech enhancement","single-channel audio data;deep network speech enhancement systems;waveform signal;higher dimensional spectro-temporal features;probabilistic bottleneck;direct spectral reconstruction;ablation network variants;signal-to-distortion ratio;spectral reconstruction;filter mask estimation;signal enhancement performance;recurrent mask estimation network baseline;PESQ;STOI;variational U-Net architecture","","","","22","","8 Dec 2021","","","IEEE","IEEE Conferences"
"Mapping and Masking Targets Comparison using Different Deep Learning based Speech Enhancement Architectures","S. A. Nossier; J. Wall; M. Moniri; C. Glackin; N. Cannings","Dept. of Engineering and Computing, University of East London, London, UK; Dept. of Engineering and Computing, University of East London, London, UK; Dept. of Engineering and Computing, University of East London, London, UK; Intelligent Voice Ltd, London, UK; Intelligent Voice Ltd, London, UK","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","8","Mapping and Masking targets are both widely used in recent Deep Neural Network (DNN) based supervised speech enhancement. Masking targets are proved to have a positive impact on the intelligibility of the output speech, while mapping targets are found, in other studies, to generate speech with better quality. However, most of the studies are based on comparing the two approaches using the Multilayer Perceptron (MLP) architecture only. With the emergence of new architectures that outperform the MLP, a more generalized comparison is needed between mapping and masking approaches. In this paper, a complete comparison will be conducted between mapping and masking targets using four different DNN based speech enhancement architectures, to work out how the performance of the networks changes with the chosen training target. The results show that there is no perfect training target with respect to all the different speech quality evaluation metrics, and that there is a tradeoff between the denoising process and the intelligibility of the output speech. Furthermore, the generalization ability of the networks was evaluated, and it is concluded that the design of the architecture restricts the choice of the training target, because masking targets result in significant performance degradation for deep convolutional autoencoder architecture.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9206623","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206623","Deep Learning;Speech Enhancement;Training Targets;Time-Frequency Mapping;Time-Frequency Masking","Speech enhancement;Training;Noise measurement;Spectrogram;Feature extraction;Time-frequency analysis","convolutional neural nets;learning (artificial intelligence);multilayer perceptrons;signal denoising;speech enhancement","masking targets;deep neural network;supervised speech enhancement;output speech;mapping targets;multilayer perceptron architecture;masking approaches;perfect training target;deep convolutional autoencoder architecture;DNN based speech enhancement architectures;deep learning based speech enhancement architectures;speech quality evaluation metrics;MLP","","2","","54","","28 Sep 2020","","","IEEE","IEEE Conferences"
"Bio-inspired neuromorphic visual processing with neural networks for cyclist detection in vehicle's blind spot and segmentation in medical CT images","W. -S. Han; I. S. Han","ODIGA, London, U.K.; ODIGA, London, U.K.","2017 Computing Conference","11 Jan 2018","2017","","","744","750","Neuromorphic visual processing inspired by the biological vision system of brain offers an alternative process into applying machine vision in everyday environment. With the growing demand for an effective detection method of moving objects on the road for the purpose of transportation safety enhancement, the proposed neuromorphic visual processing was tested on the vehicle's blind spot cyclist detection. The effectiveness of proposed convolutional-recurrent mixed networks of neuromorphic visual processing is evaluated for the cyclist detection without optimized complex template matching or denoising layers of neural network. The new feature extraction by integrating both hand-cut convolution filters and autoencoder is designed for processing the noisy image including the 3-dimensional tooth segmentation in the gum region. The proposed mixed feature extraction by the hand-cut filter and auto-encoder demonstrates the cyclist detection rate of 98% for vehicles on the road or the successful segmentation for medical CT images of dental X-ray 3D CT including the gum region or brain CT in BRATS data sets.","","978-1-5090-5443-5","10.1109/SAI.2017.8252179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8252179","Neuromorphic Visual Processing;Neural Network;Blind Spot Cyclist Detection;Segmentation;Dental CT images;Brain CT images","Visualization;Neuromorphics;Feature extraction;Image segmentation;Computed tomography;Dentistry;Biological neural networks","brain;computer vision;computerised tomography;feature extraction;feedforward neural nets;image coding;image denoising;image segmentation;image sensors;learning (artificial intelligence);medical image processing;object detection;recurrent neural nets","bio-inspired neuromorphic visual processing;neural network;alternative process;cyclist detection rate;moving object detection method;vehicle blind spot;medical CT image segmentation;biological vision system;machine vision;transportation safety enhancement;convolutional-recurrent mixed networks;hand-cut convolution filters;autoencoder;noisy image processing;3-dimensional tooth segmentation;gum region;mixed feature extraction;BRATS data set","","1","","8","","11 Jan 2018","","","IEEE","IEEE Conferences"
"Global Context with Discrete Diffusion in Vector Quantised Modelling for Image Generation","M. Hu; Y. Wang; T. -J. Cham; J. Yang; P. N. Suganthan",Nanyang Technological University; Sensetime Research; Nanyang Technological University; Nanyang Technological University; Nanyang Technological University,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","11492","11501","The integration of Vector Quantised Variational AutoEncoder (VQ-VAE) with autoregressive models as generation part has yielded high-quality results on image generation. However, the autoregressive models will strictly follow the progressive scanning order during the sampling phase. This leads the existing VQ series models to hardly escape the trap of lacking global information. Denoising Diffusion Probabilistic Models (DDPM) in the continuous domain have shown a capability to capture the global context, while generating high-quality images. In the discrete state space, some works have demonstrated the potential to perform text generation and low resolution image generation. We show that with the help of a content-rich discrete visual codebook from VQ-VAE, the discrete diffusion model can also generate high fidelity images with global context, which compensates for the deficiency of the classical autoregressive model along pixel space. Meanwhile, the integration of the discrete VAE with the diffusion model resolves the drawback of conventional autoregressive models being oversized, and the diffusion model which demands excessive time in the sampling process when generating images. It is found that the quality of the generated images is heavily dependent on the discrete visual codebook. Extensive experiments demonstrate that the proposed Vector Quantised Discrete Diffusion Model (VQ-DDM) is able to achieve comparable performance to top-tier methods with low complexity. It also demonstrates outstanding advantages over other vectors quantised with autoregressive models in terms of image inpainting tasks without additional training.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879884","Image and video synthesis and generation","Training;Visualization;Image resolution;Image synthesis;Pipelines;Noise reduction;Probabilistic logic","autoregressive processes;feature extraction;filtering theory;image coding;image denoising;image resolution;image restoration;learning (artificial intelligence);vector quantisation","Vector Quantised modelling;Vector Quantised Variational AutoEncoder;VQ-VAE;generation part;high-quality results;existing VQ series models;global information;Diffusion Probabilistic Models;high-quality images;discrete state space;text generation;low resolution image generation;content-rich discrete visual codebook;high fidelity images;classical autoregressive model;discrete VAE;conventional autoregressive models;generating images;Vector Quantised Discrete Diffusion Model;image inpainting tasks","","","","41","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Machine Learning Approach for Tensegrity Form Finding: Feature Extraction Problem","E. Zalyaev; S. Savin; L. Vorochaeva","Laboratory of Mechatronics, Control and Prototyping, Innopolis University, Innopolis, Russia; Laboratory of Mechatronics, Control and Prototyping, Innopolis University, Innopolis, Russia; Department of mechanics, mechatronics and robotics, Southwest State University, Kursk, Russia","2020 4th Scientific School on Dynamics of Complex Networks and their Application in Intellectual Robotics (DCNAIR)","8 Oct 2020","2020","","","265","268","In this paper, the problem of form finding for a tensegrity structure with the use of a machine learning pipeline, including feature extraction and regression, is studied. Tensegrity robots present a range of new opportunities in a number of areas in robotics, however the lack of efficient and scalable tools for controlling their motion slows down their deployment. This study aims to add a new tool for solving one of the basic problems encountered in tensegrity robot control: finding a stable equilibrium state (and its inverse task). Using machine learning approach makes the solution scalable and potentially faster than iterative optimization-based methods. The paper provides a view into the issue of feature extraction, and provides implementation of a number of feature extraction methods: Principle Component Analysis (PCA), Kernel PCA, undercomplete, denoising and sparse autoencoders.","","978-1-7281-7286-6","10.1109/DCNAIR50402.2020.9216799","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9216799","tensegrity;form finding;feature extraction;machine learning;PCA;autoencoders","Robots;Feature extraction;Principal component analysis;Noise reduction;Kernel;Machine learning;Training","control engineering computing;feature extraction;learning (artificial intelligence);principal component analysis;robots","tensegrity form finding;feature extraction problem;tensegrity structure;machine learning;tensegrity robot control;feature extraction methods;equilibrium state;principle component analysis","","4","","16","","8 Oct 2020","","","IEEE","IEEE Conferences"
"Deep Diffusion Processes for Active Learning of Hyperspectral Images","A. Tasissa; D. Nguyen; J. M. Murphy","Department of Mathematics, Tufts University, USA; Department of Mathematics, University of Maryland, College Park, USA; Department of Mathematics, Tufts University, USA","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","3665","3668","A method for active learning of hyperspectral images (HSI) is proposed, which combines deep learning with diffusion processes on graphs. A deep variational autoencoder extracts smoothed, denoised features from a high-dimensional HSI, which are then used to make labeling queries based on graph diffusion processes. The proposed method combines the robust representations of deep learning with the mathematical tractability of diffusion geometry, and leads to strong performance on real HSI.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553196","hyperspectral images;variational autoencoders;deep clustering;active learning;semi-supervised learning;diffusion geometry","Geometry;Deep learning;Diffusion processes;Geoscience and remote sensing;Feature extraction;Labeling;Hyperspectral imaging","","","","4","","24","","12 Oct 2021","","","IEEE","IEEE Conferences"
"Application of WE-AE-BP Method to Electric Shock Faults Identification in the Low-voltage Distribution Network","S. Wu; S. -Y. Lin; M. -F. Guo","College of Electrical Engineering and Automation, Fuzhou University, Fuzhou, China; College of Electrical Engineering and Automation, Fuzhou University, Fuzhou, China; College of Electrical Engineering and Automation, Fuzhou University, Fuzhou, China","2020 IEEE 1st China International Youth Conference on Electrical Engineering (CIYCEE)","1 Feb 2021","2020","","","1","6","In the low-voltage distribution network, the tripping criterion of the residual current devices is usually a fixed threshold. The incorrect detection of leakage current signal may lead to tripping delay or mis-trip of the devices in electric shock accidents, which may be caused by the equipment vibration, harmonics, transient disturbances, etc. Hence, this study proposes an artificial intelligence method for quickly identifying electric shock faults to improve the function of the device. Firstly, wavelet entropy removes noise from the electric shock signal. Then, the autoencoder is applied to extract the total leakage current waveform as the feature information. Finally, the back-propagation neural network classifies the electric shock types. The simulation and experiment platforms are established to obtain experimental samples and validate the reliability of the proposed method. Compared to other alternative methods, the proposed method shows outstanding identification ability, which demonstrates its applicability in reality.","","978-1-7281-9659-6","10.1109/CIYCEE49808.2020.9332673","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9332673","Autoencoder;back-propagation;electric shock faults identification;low-voltage distribution network;wavelet entropy denoising","Fault diagnosis;Electric shock;Feature extraction;Entropy;Leakage currents;Data mining;Object recognition","backpropagation;distribution networks;electric shocks;fault diagnosis;leakage currents;neural nets;power engineering computing;residual current devices;wavelet transforms","WE-AE-BP method;electric shock faults identification;low-voltage distribution network;tripping criterion;residual current devices;leakage current signal;tripping delay;electric shock accidents;artificial intelligence method;electric shock signal;total leakage current waveform;backpropagation neural network;electric shock types","","1","","15","","1 Feb 2021","","","IEEE","IEEE Conferences"
"BePCon: A Photoplethysmography-based Quality-aware Continuous Beat-to-Beat Blood Pressure Measurement Technique Using Deep Learning","M. S. Roy; R. Gupta; K. D. Sharma","Department of Applied Physics, Electrical Engineering Section, University of Calcutta, India; Department of Applied Physics, Electrical Engineering Section, University of Calcutta, India; Department of Applied Physics, Electrical Engineering Section, University of Calcutta, India","IEEE Transactions on Instrumentation and Measurement","","2022","PP","99","1","1","Research on noninvasive blood pressure (NIBP) measurement using electrocardiogram (ECG)/ photoplethysmogram (PPG) and their combinations have been most popular in ambulatory health monitoring. The real challenge is motion artifact (MA) corruption in the PPG, which makes the BP measurement unreliable. This paper presents BePCon, a deep learning-based model for beat-to-beat (BtB) BP measurement using a temporal convolutional network (TCN). Initially, the signal quality assessment (SQA) of PPG is done by a self-organizing map (SOM). Next, the time-domain, statistical, wavelet and stacked autoencoder features from current and previous good quality PPG cycles are extracted. A recursive feature elimination (RFE) selects optimum set of 20 features from each cycle before being fed to the TCN to predict the systolic (SBP) and diastolic blood pressure (DBP) of current beat. While evaluated over 150 data records from PhysioNet MIMIC-II/III waveform database, BePCon achieves standard deviation (SD), and mean absolute error (MAE) of 3.24 mmHg and 2.38 mmHg respectively for SBP, and 1.73 mmHg, and 1.23 mmHg respectively for the DBP respectively. An improvement of accuracy by a factor of 19.56% for SBP and 24.61% for DBP is obtained over without SQA. BePCon also complies with AAMI and BHS Grade A standard and improvement over published works on BtB BP measurement using MIMIC-II/III waveform database. A standalone implementation with a single core 1-GHz ARM v6 controller supported by 512 MB RAM shows low latency (~2.5 s per beat) and low memory requirement (~32.22 KB per beat). This establishes that BePCon has the potential for real-time ambulatory BtB BP measurement.","1557-9662","","10.1109/TIM.2022.3212750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9913482","Blood Pressure;Photoplethysmogram (PPG);Recursive Feature Elimination;Stack denoising autoencoder;Temporal Convolutional Neural Network;Unsupervised Learning","Feature extraction;Time measurement;Biomedical monitoring;Pressure measurement;Monitoring;MIMICs;Current measurement","","","","","","","IEEE","6 Oct 2022","","","IEEE","IEEE Early Access Articles"
"LDICDL: LncRNA-Disease Association Identification Based on Collaborative Deep Learning","W. Lan; D. Lai; Q. Chen; X. Wu; B. Chen; J. Liu; J. Wang; Y. -P. P. Chen","School of Computer, Electronic and Information and Guangxi Key Laboratory of Multimedia Communications and Network Technology, Guangxi University, Nanning, Guangxi, China; School of Computer, Electronic and Information, Guangxi University, Nanning, Guangxi, China; State Key Laboratory for Conservation and Utilization of Subtropical Agro-bioresources, School of Computer, Electronic and Information, Guangxi University, Nanning, Guangxi, China; School of Computer, Electronic and Information, Guangxi University, Nanning, Guangxi, China; State Key Laboratory for Conservation and Utilization of Subtropical Agro-bioresources, Guangxi University, Nanning, Guangxi, China; Hunan Provincial Key Lab on Bioinformatics, School of Computer Science and Engineering, Central South University, Changsha, Hunan, China; Hunan Provincial Key Lab on Bioinformatics, School of Computer Science and Engineering, Central South University, Changsha, Hunan, China; Department of Computer Science and Information Technology, La Trobe University, Melbourne, VIC, Australia","IEEE/ACM Transactions on Computational Biology and Bioinformatics","3 Jun 2022","2022","19","3","1715","1723","It has been proved that long noncoding RNA (lncRNA) plays critical roles in many human diseases. Therefore, inferring associations between lncRNAs and diseases can contribute to disease diagnosis, prognosis and treatment. To overcome the limitation of traditional experimental methods such as expensive and time-consuming, several computational methods have been proposed to predict lncRNA-disease associations by fusing different biological data. However, the prediction performance of lncRNA-disease associations identification needs to be improved. In this study, we propose a computational model (named LDICDL) to identify lncRNA-disease associations based on collaborative deep learning. It uses an automatic encoder to denoise multiple lncRNA feature information and multiple disease feature information, respectively. Then, the matrix decomposition algorithm is employed to predict the potential lncRNA-disease associations. In addition, to overcome the limitation of matrix decomposition, the hybrid model is developed to predict associations between new lncRNA (or disease) and diseases (or lncRNA). The ten-fold cross validation and de novo test are applied to evaluate the performance of method. The experimental results show LDICDL outperforms than other state-of-the-art methods in prediction performance.","1557-9964","","10.1109/TCBB.2020.3034910","National Natural Science Foundation of China(grant numbers:61702122,62072124,61963004,61972185); Natural Science Foundation of Guangxi Province(grant numbers:2017GXNSFDA198033,2018GXNSFBA281193); Key Research and Development Plan of Guangxi(grant numbers:AB17195055); Science and Technology Base and talent special project of Guangxi(grant numbers:AD20159044); foundation of Guangxi University(grant numbers:20190240,XBZ180476); Innovation Project of Guangxi Graduate Education(grant numbers:YCSW2020020); Natural Science Foundation of Yunnan Province(grant numbers:2019FA024); Hunan Provincial Science and Technology Department(grant numbers:2019CB1007); scientific Research Foundation of Hunan Provincial Education Department(grant numbers:18B469); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9246263","lncRNA-disease associations;matrix factorization;stacked denoising autoencoder","Diseases;Matrix decomposition;RNA;Prediction algorithms;Noise reduction;Biological system modeling;Computational modeling","bioinformatics;biology computing;data mining;diseases;genetics;learning (artificial intelligence);matrix decomposition;medical computing;molecular biophysics;network theory (graphs);patient diagnosis;pattern clustering;RNA","collaborative deep learning;long noncoding RNA;human diseases;disease diagnosis;prediction performance;lncRNA-disease associations identification;multiple lncRNA;multiple disease feature information;potential lncRNA-disease associations;or disease;or lncRNA;LncRNA-disease association identification","Algorithms;Computational Biology;Deep Learning;Humans;Neoplasms;RNA, Long Noncoding","3","","56","IEEE","30 Oct 2020","","","IEEE","IEEE Journals"
"Deep Learning Based Encryption Policy Intrusion Detection Using Commodity WiFi","Y. Liu; Q. Liao; J. Zhao; Z. Han","Beijing Laboratory of Advanced Information Networks, School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Laboratory of Advanced Information Networks, School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Laboratory of Advanced Information Networks, School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Laboratory of Advanced Information Networks, School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China","2019 IEEE 5th International Conference on Computer and Communications (ICCC)","13 Apr 2020","2019","","","2129","2135","WiFi-based intrusion detection plays a significant role in indoor safety applications, setting human free from wearable devices and causing no privacy concerns, compared to sensor-based or vision-based solutions. WiFi-based systems have achieved high accuracy, but with limitations in dataset collection consumptions and feature extractions. In this paper, we propose EPID, a scheme for Encryption Policy Intrusion Detection leveraging Channel State Information (CSI). EPID applies Butterworth low-pass filter for signal denoising, and conjugate calibration to remove CSI random phase offsets. Generative Adversarial Networks (GAN) based data augmentation approach is proposed to augment dataset. Besides, sparse autoencoder (SAE) is adopted for feature extraction to reduce computational complexity and mistaken detection risks caused by redundant statistics. Based on the features, one-class Support Vector Machine (SVM) is conducted for general intrusion detection. Extensive empirical evidence shows that EPID yields mean 96.6% detection accuracy with practical feasibility.","","978-1-7281-4743-7","10.1109/ICCC47050.2019.9064215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9064215","Intrusion detection;CSI;Data augmentation;Feature extraction","Intrusion detection;Feature extraction;Wireless fidelity;Gallium nitride;Antennas;Encryption;Neurons","Butterworth filters;computational complexity;cryptography;feature extraction;learning (artificial intelligence);low-pass filters;recurrent neural nets;signal denoising;statistical analysis;support vector machines","redundant statistics;feature extractions;signal denoising;butterworth low-pass filter;generative adversarial networks based data augmentation approach;deep learning based encryption policy intrusion detection;CSI random phase offsets;channel state information;EPID;feature extraction;dataset collection consumptions;WiFi-based systems;privacy concerns;indoor safety applications;WiFi-based intrusion detection;commodity WiFi","","1","","15","","13 Apr 2020","","","IEEE","IEEE Conferences"
"Collaborating Ray Tracing and AI Model for AUV-Assisted 3-D Underwater Sound-Speed Inversion","W. Huang; M. Liu; D. Li; F. Yin; H. Chen; J. Zhou; H. Xu","Collaborative Innovation Center of Geospatial Technology, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China; Collaborative Innovation Center of Geospatial Technology, Wuhan, China; The Chinese University of Hong Kong, Shenzhen, China; Electronic Information School, Wuhan University, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China","IEEE Journal of Oceanic Engineering","12 Oct 2021","2021","46","4","1372","1390","Three-dimensional sound-speed distribution is essential for large-scale underwater acoustic applications due to its influence on the signal propagation trajectory. However, it is labor, energy, and time consuming to measure sound speed by traditional methods because of the weak system maneuverability. In this article, an autonomous-underwater-vehicle-assisted underwater sound-speed inversion framework that collaborates ray tracing and artificial intelligence model is proposed to quickly obtain 3-D sound-speed distribution through multicoordinate inversions. An autoencoding-translation neural network is proposed to establish the nonlinear relationship from signal propagation time to the sound-speed profile (SSP), and the inversion time can be shortened with once forward propagation through the model. Robustness could be improved by inverting error-resistant implicit features into the SSP through the proposed translating neural network, whereas the implicit features are extracted from the autoencoder by denoising reconstruction of the input time information. To solve the overfitting problem and extend the training data set, virtual SSPs based on sparse feature points of real SSPs are generated. Simulation results show that our approach can provide a reliable and instantaneous monitoring of 3-D sound-speed distribution.","1558-1691","","10.1109/JOE.2021.3066780","China Postdoctoral Science Foundation(grant numbers:2020M672412); National Key Research and Development Program of China Stem Cell and Translational Research(grant numbers:2018YFB1800800); Guangdong Zhujiang Project(grant numbers:2017ZT07X152); 13th ACM International Conference on Underwater Networks, and Systems, ACM, Shenzhen, China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9433716","Autoencoding-translation neural network (AETNN);autonomous underwater vehicle (AUV);sound-speed profile (SSP);sparse feature points (SFPs);3-D sound-speed inversion","Neural networks;Autonomous underwater vehicles;Ray tracing;Underwater acoustics;Feature extraction;Artificial intelligence","acoustic signal processing;autonomous underwater vehicles;encoding;feature extraction;learning (artificial intelligence);neural nets;radar computing;ray tracing;signal denoising;signal reconstruction;underwater acoustic propagation;underwater sound","instantaneous monitoring;denoising reconstruction;SSP;AUV-assisted 3D underwater sound-speed inversion;underwater sound-speed inversion framework;input time information;translating neural network;inversion time;sound-speed profile;signal propagation time;autoencoding-translation neural network;multicoordinate inversions;artificial intelligence model;autonomous underwater vehicle;weak system maneuverability;signal propagation trajectory;large-scale underwater acoustic applications;three-dimensional sound-speed distribution;AI model;ray tracing","","","","56","IEEE","18 May 2021","","","IEEE","IEEE Journals"
"Vector Quantized Diffusion Model for Text-to-Image Synthesis","S. Gu; D. Chen; J. Bao; F. Wen; B. Zhang; D. Chen; L. Yuan; B. Guo",University of Science and Technology of China; Microsoft Research; Microsoft Research; Microsoft Research; Microsoft Research; Microsoft Cloud+AI; Microsoft Cloud+AI; Microsoft Research,"2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","27 Sep 2022","2022","","","10686","10696","We present the vector quantized diffusion (VQ-Diffusion) model for text-to-image generation. This method is based on a vector quantized variational autoencoder (VQ-VAE) whose latent space is modeled by a conditional variant of the recently developed Denoising Diffusion Probabilistic Model (DDPM). We find that this latent-space method is well-suited for text-to-image generation tasks because it not only eliminates the unidirectional bias with existing methods but also allows us to incorporate a mask-and-replace diffusion strategy to avoid the accumulation of errors, which is a serious problem with existing methods. Our experiments show that the VQ-Diffusion produces significantly better text-to-image generation results when compared with conventional autoregressive (AR) models with similar numbers of parameters. Compared with previous GAN-based text-to-image methods, our VQ-Diffusion can handle more complex scenes and improve the synthesized image quality by a large margin. Finally, we show that the image generation computation in our method can be made highly efficient by reparameterization. With traditional AR methods, the text-to-image generation time increases linearly with the output image resolution and hence is quite time consuming even for normal size images. The VQ-Diffusion allows us to achieve a better trade-off between quality and speed. Our experiments indicate that the VQ-Diffusion model with the reparameterization is fifteen times faster than traditional AR methods while achieving a better image quality. The code and models are available at https://github.com/cientgu/VQ-Diffusion.","2575-7075","978-1-6654-6946-3","10.1109/CVPR52688.2022.01043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9879180","Image and video synthesis and generation; Vision + language","Image quality;Computer vision;Image resolution;Image synthesis;Computational modeling;Noise reduction;Computer architecture","approximation theory;gallium compounds;Gaussian processes;image denoising;image representation;image resolution;image sampling;image texture;medical image processing;rendering (computer graphics);vector quantisation","vector quantized Diffusion Model;text-to-image synthesis;VQ-VAE;recently developed Denoising Diffusion Probabilistic Model;latent-space method;text-to-image generation tasks;-replace diffusion strategy;text-to-image generation results;conventional autoregressive models;previous GAN-based text-to-image methods;synthesized image quality;image generation computation;traditional AR methods;text-to-image generation time;output image resolution;normal size images;VQ-Diffusion model","","","","73","IEEE","27 Sep 2022","","","IEEE","IEEE Conferences"
"Noisy deep dictionary learning: Application to Alzheimer's Disease classification","A. Majumdar; V. Singhal","IIIT Delhi, New Delhi, India; IIIT Delhi, New Delhi, India","2017 International Joint Conference on Neural Networks (IJCNN)","3 Jul 2017","2017","","","2679","2683","A recent work introduced the concept of deep dictionary learning. In deep dictionary learning, the first level proceeds like standard dictionary learning; in sub-sequent layers the (scaled) output coefficients from the previous layer are used as inputs for dictionary learning. This is an unsupervised deep learning approach. The features from the final / deepest layer are employed for subsequent analysis and classification. The seminal paper of stacked denoising autoencoders have shown that robust deep models can be learnt when noisy data is used for training stacked autoencoders instead of clean data. We adopt this idea into the deep dictionary learning framework; instead of using only clean data we augment the training dataset by adding noise; this improves robustness. Experimental evaluation on benchmark deep learning datasets and real world problem of AD classification show that our proposal yields considerable improvement.","2161-4407","978-1-5090-6182-2","10.1109/IJCNN.2017.7966184","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966184","dictionary learning;deep learning;AD classification","Dictionaries;Training;Machine learning;Noise measurement;Robustness;Benchmark testing;Noise reduction","diseases;medical computing;pattern classification;unsupervised learning","noisy deep dictionary learning;Alzheimers disease classification;unsupervised deep learning approach;stacked denoising autoencoders;robust deep models;clean data;deep dictionary learning framework;benchmark deep learning datasets;AD classification","","9","","20","","3 Jul 2017","","","IEEE","IEEE Conferences"
"End-to-End Learning of Secure Wireless Communications: Confidential Transmission and Authentication","Z. Sun; H. Wu; C. Zhao; G. Yue","Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China","IEEE Wireless Communications","28 Oct 2020","2020","27","5","88","95","Aiming to provide more efficient and robust physical layer security strategies for wireless communications, this article investigates the endogenous security of end-to-end learning of communication by addressing two main security issues of communication: confidential transmission and user authentication. For confidential transmission, we have redesigned the loss function of the autoencoder-based deep learning communication model to combat illegal eavesdropping over wireless broadcast channels. While assuming that the eavesdropper has three different ways of decoding prior information, the probability of successful eavesdropping attack is evaluated using the bit error rate criterion. In terms of user authentication, an authentication scheme using ""symbol-level fingerprints"" is designed for a single user, which takes advantage of the high complexity of parameters of the deep learning model and its natural sensitivity to training conditions. In addition, by leveraging a denoising autoencoder, we extend the authentication to adapt to the multi-user access situation. Experiments have shown that the proposed authentication scheme could guarantee reliability under dynamic channel and resistance to wireless attacks. The results inspire us to rebuild an efficient physical layer secure framework for wireless communication through a new deep learning method.","1558-0687","","10.1109/MWC.001.2000005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9241890","","Decoding;Receivers;Wireless communication;Authentication;Training;Privacy;Network security","broadcast channels;cryptography;encoding;error statistics;learning (artificial intelligence);probability;telecommunication computing;telecommunication security;wireless channels","multiuser access situation;authentication scheme;wireless attacks;secure wireless communications;confidential transmission;robust physical layer security strategies;endogenous security;end-to-end learning;user authentication;illegal eavesdropping;wireless broadcast channels;eavesdropping attack;bit error rate criterion;deep learning model;symbol-level fingerprints;denoising autoencoder;deep learning communication model","","2","","15","","28 Oct 2020","","","IEEE","IEEE Magazines"
"Characterizing Sub-Cohorts via Data Normalization and Representation Learning","E. Rush; O. Ozmen; K. Knight; B. Park; C. Baker; M. Jones; M. Ward; J. Nebeker","Oak Ridge National Laboratory, Oak Ridge, TN, USA; Oak Ridge National Laboratory, Oak Ridge, USA; Oak Ridge National Laboratory, Oak Ridge, USA; Oak Ridge National Laboratory, Oak Ridge, TN, USA; US Department of Veterans Affairs, Washington, DC, USA; US Department of Veterans Affairs, Washington, DC, USA; US Department of Veterans Affairs, Washington, DC, USA; US Department of Veterans Affairs, Washington, DC, USA","2020 IEEE 33rd International Symposium on Computer-Based Medical Systems (CBMS)","1 Sep 2020","2020","","","173","176","The process of identifying a cohort of interest is a very challenging task. It requires manually inspecting many patient records of complex structure that might include medical coding errors and missing data. This paper presents a computational pipeline for refining the process of cohort selection based on medical concepts recorded in the electronic health records (EHRs). The pipeline extracts EHR data for a given cohort and normalizes this data using standard vocabularies. Then a stacked denoising autoencoder is used to embed the normalized patient vectors in a low dimensional space, where the patients are subsequently clustered into sub-cohorts. The goal is to represent the cohort in a standard format and abstract variants of sub-populations. As a use-case, we applied the pipeline to 1.8 million Veterans diagnosed with major depressive disorder (MDD), and identified four meaningful sub-cohorts using the features learned by the autoencoder. Then, each sub-cohort was explored using a set of keywords for interpretation.","2372-9198","978-1-7281-9429-5","10.1109/CBMS49503.2020.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9183159","electronic health records, data normalization, UMLS, cohort selection, representation learning, clustering","Medical diagnostic imaging;Pipelines;Unified modeling language;Sparse matrices;Data mining;Noise reduction;Vocabulary","electronic health records;health care;learning (artificial intelligence);medical disorders;medical image processing","computational pipeline;cohort selection;medical concepts;electronic health records;standard vocabularies;stacked denoising autoencoder;normalized patient vectors;low dimensional space;standard format;data normalization;representation learning;patient records;complex structure;medical coding errors;missing data;subcohorts;EHR","","","","9","","1 Sep 2020","","","IEEE","IEEE Conferences"
"Device-Free Multiple Presence Detection Using CSI with Machine Learning Methods","Y. -M. Huang; A. -H. Hsiao; C. -J. Chiu; K. -T. Feng; P. -H. Tseng","Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Electronic Engineering, National Taipei University of Technology, Taipei, Taiwan","2019 IEEE 90th Vehicular Technology Conference (VTC2019-Fall)","7 Nov 2019","2019","","","1","5","Present detection can remotely detect whether a person appears in specific scene. Channel state information (CSI) can provide high precision environment detection by its characteristic, and this technology can often be adopted for indoor localization or presence detection nowadays. We propose a device-free multiple presence detection system by using particular preprocessing method for our system, and a two-stage learning system combining convolutional denoising autoencoder (CDAE) and neural network (NN) to classify different cases of presence detection. The first stage contains several one-dimensional convolutional hidden layers which can denoise and reduce the dimension of data. The second stage classifies the cases for the purpose of presence detection. The proposed system can detect the presence of multiple persons at hotspots with high estimation accuracy.","2577-2465","978-1-7281-1220-6","10.1109/VTCFall.2019.8891200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891200","","Artificial neural networks;Antennas;Indexes;Indoor environment;Data models;Training","feature extraction;learning (artificial intelligence);location based services;neural nets;support vector machines","indoor localization;support vector machine;one-dimensional convolutional hidden layers;convolutional denoising autoencoder;neural network;two-stage learning system;device-free multiple presence detection system;high precision environment detection;channel state information;machine learning methods;CSI","","3","","12","","7 Nov 2019","","","IEEE","IEEE Conferences"
"Semi-Supervised Multichannel Speech Enhancement With a Deep Speech Prior","K. Sekiguchi; Y. Bando; A. A. Nugraha; K. Yoshii; T. Kawahara","Center for Advanced Intelligence Project (AIP), RIKEN, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology (AIST), Tokyo, Japan; Center for Advanced Intelligence Project (AIP), RIKEN, Tokyo, Japan; Center for Advanced Intelligence Project (AIP), RIKEN, Tokyo, Japan; Graduate School of Informatics, Kyoto University, Kyoto","IEEE/ACM Transactions on Audio, Speech, and Language Processing","27 Nov 2019","2019","27","12","2197","2212","This paper describes a semi-supervised multichannel speech enhancement method that uses clean speech data for prior training. Although multichannel nonnegative matrix factorization (MNMF) and its constrained variant called independent low-rank matrix analysis (ILRMA) have successfully been used for unsupervised speech enhancement, the low-rank assumption on the power spectral densities (PSDs) of all sources (speech and noise) does not hold in reality. To solve this problem, we replace a low-rank speech model with a deep generative speech model, i.e., formulate a probabilistic model of noisy speech by integrating a deep speech model, a low-rank noise model, and a full-rank or rank-1 model of spatial characteristics of speech and noise. The deep speech model is trained from clean speech data in an unsupervised auto-encoding variational Bayesian manner. Given multichannel noisy speech spectra, the full-rank or rank-1 spatial covariance matrices and PSDs of speech and noise are estimated in an unsupervised maximum-likelihood manner. Experimental results showed that the full-rank version of the proposed method was significantly better than MNMF, ILRMA, and the rank-1 version. We confirmed that the initialization-sensitivity and local-optimum problems of MNMF with many spatial parameters can be solved by incorporating the precise speech model.","2329-9304","","10.1109/TASLP.2019.2944348","JST(grant numbers:JPMJER1401); JSPS KAKENHI(grant numbers:19H04137); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861142","Multichannel speech enhancement;deep learning;variational autoencoder;nonnegative matrix factorization","Speech enhancement;Noise measurement;Data models;Probabilistic logic;Maximum likelihood estimation;Time-frequency analysis","blind source separation;covariance matrices;matrix algebra;matrix decomposition;maximum likelihood estimation;neural nets;signal denoising;speech enhancement;supervised learning;unsupervised learning","semisupervised multichannel speech enhancement method;clean speech data;multichannel nonnegative matrix factorization;low-rank matrix analysis;unsupervised speech enhancement;low-rank speech model;deep generative speech model;probabilistic model;deep speech model;low-rank noise model;rank-1 model;unsupervised auto-encoding variational Bayesian manner;multichannel noisy speech spectra","","14","","46","CCBY","7 Oct 2019","","","IEEE","IEEE Journals"
"Deep learning models for bone suppression in chest radiographs","M. Gusarev; R. Kuleev; A. Khan; A. Ramirez Rivera; A. M. Khattak","Department of Computer Science, Innopolis University, Innopolis, Russia; Department of Computer Science, Innopolis University, Innopolis, Russia; Department of Computer Science, Innopolis University, Innopolis, Russia; Institute of Computing, University of Campinas, Campinas, Brazil; College of Technological Innovation, Zayed University, Abu Dhabi, UAE","2017 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)","5 Oct 2017","2017","","","1","7","Bone suppression in lung radiographs is an important task, as it improves the results on other related tasks, such as nodule detection or pathologies classification. In this paper, we propose two architectures that suppress bones in radiographs by treating them as noise. In the proposed methods, we create end-to-end learning frameworks that minimize noise in the images while maintaining sharpness and detail in them. Our results show that our proposed noise-cancellation scheme is robust and does not introduce artifacts into the images.","","978-1-4673-8988-4","10.1109/CIBCB.2017.8058543","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8058543","lung cancer;bone suppression;autoencoder;convolution neural network;deep learning","Bones;Noise reduction;Radiography;Ribs;Lungs;Image segmentation;Image reconstruction","bone;diagnostic radiography;image denoising;learning (artificial intelligence);lung;medical image processing","image artifact;noise-cancellation scheme;end-to-end learning frameworks;nodule detection;lung radiographs;chest radiographs;bone suppression;deep learning models","","14","","26","","5 Oct 2017","","","IEEE","IEEE Conferences"
"Fully Unsupervised Salient Object Detection","N. Fatemi; H. Sajedi; M. E. Shiri Ahmadabadi","Department of Mathematics, Amirkabir University, Tehran, Iran; Department of Mathematics, University of Tehran, Tehran, Iran; Department of Mathematics, Amirkabir University, Tehran, Iran","2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA)","5 Aug 2019","2019","","","32","38","Object detection is one of the most important components of machine vision. Today, object detection is used in a variety of areas, including guidance, driving, industry, and other key areas. For this reason, many algorithms have been proposed in this regard, with the aim of increasing the quality of detecting objects in an image. Since the correct representation of the object in the image is considered an essential requirement, in this article, a five-step algorithm is proposed for object detection. Experiments are performed on a given database in comparison with other methods in this area. In this algorithm, a color space is used to extract the feature and from self-encoder to remove the noise in the property matrix. Then, by scoring the clusters created based on the features, using the mean shift algorithm, the maximum pixels of the object are detected and separated from the background. The results of the experiments show performance of the proposed method in dealing with photos that involve challenges from multiple objects to changes the image.","2049-3630","978-1-7281-1621-1","10.1109/PRIA.2019.8785974","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8785974","Salient object detection;Autoencoder;Mean Shift Algorithm;segmentation","Feature extraction;Image color analysis;Object detection;Clustering algorithms;Image segmentation;Kernel;Computer science","computer vision;image colour analysis;image denoising;image segmentation;object detection","fully unsupervised salient object detection;machine vision;image representation;noise removal;mean shift algorithm;object pixel;property matrix","","2","","19","","5 Aug 2019","","","IEEE","IEEE Conferences"
"Comparison of Semi-supervised Deep Neural Networks for Anomaly Detection in Industrial Processes","G. S. Chadha; A. Rabbani; A. Schwung","Department of Automation Technology, South Westphalia University of Applied Sciences, Soest, Germany; Department of Automation Technology, South Westphalia University of Applied Sciences, Soest, Germany; Department of Automation Technology, South Westphalia University of Applied Sciences, Soest, Germany","2019 IEEE 17th International Conference on Industrial Informatics (INDIN)","30 Jan 2020","2019","1","","214","219","Anomaly detection methods are used for fast and reliable detection of abnormal events in industrial processes. The early detection of anomalies can avoid critical process breakdowns and hence can increase the overall productivity of the system. The availability of labelled datasets for all the possible faulty scenarios is generally not possible, as most of the industrial systems operate in a non-faulty condition. Deep learning architectures that can be trained in an unsupervised setting such as deep autoencoders, denoising autoencoder and variational autoencoder provide an appropriate solution to this problem of unlabelled data for industrial anomaly detection. We investigate and compare the applicability of these architectures on the benchmark Tennessee Eastman fault detection study. The deep architectures are trained to model only the normal operating condition with its threshold set by kernel density estimation. A detailed comparison from the experimental results shows superior anomaly detection capabilities of the variational autoencoder as compared to the other methods.","2378-363X","978-1-7281-2927-3","10.1109/INDIN41052.2019.8972172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8972172","Semi-supervised learning;Anomaly detection;autoencoders;deep learning","","chemical industry;fault diagnosis;learning (artificial intelligence);neural nets;production engineering computing","semisupervised deep neural networks;industrial processes;deep learning architectures;unsupervised setting;industrial anomaly detection;Tennessee Eastman fault detection","","9","","29","","30 Jan 2020","","","IEEE","IEEE Conferences"
"Through Wall Human Detection Under Small Samples Based on Deep Learning Algorithm","Y. Li; W. Wang; Y. Jiang","College of Electronics and Communication Engineering, Tianjin Normal University, Tianjin, China; College of Electronics and Communication Engineering, Tianjin Normal University, Tianjin, China; College of Electronics and Communication Engineering, Tianjin Normal University, Tianjin, China","IEEE Access","27 Nov 2018","2018","6","","65837","65844","Through-wall human detection has vital and widely used applications for anti-terrorism, anti-explosion, and post-disaster relief. The through-wall human-target recognition using ultra-wideband radar-based technology was established in recent research. With the recent development of deep learning algorithms, classification algorithms have demonstrated a dynamic aptitude to learn important characteristics of the dataset by utilizing only a few sample sets. This paper focuses on studying the detection of a human target’s status behind wall in small sample conditions. In the deep learning network model, the autoencoder algorithm is chosen here to classify and identify human targets behind walls. Through automatic acquiring of the knowledge of inherent characteristics in the data, the autoencoder algorithm can extract the concise data-feature representations. Based on the autoencoder network, we add the denoising encoder and sparsity constraints to extract more efficient feature representations, thereby improving the classification and identification rates. In this paper, we classify and identify the behind-wall human-target states separately under single and multiple sensors under a small-sample condition, and then compare the results with those of other classification algorithms. The results illustrate that the use of multiple sensors is more effective than the use of a single sensor and that the adopted autoencoder algorithm enables more effective detection of human targets behind walls than other algorithms.","2169-3536","","10.1109/ACCESS.2018.2877730","National Natural Science Foundation of China(grant numbers:61501326,61401310); National Natural Science Foundation of China(grant numbers:61731006); National Natural Science Foundation of China(grant numbers:61271411); Tianjin Research Program of Application Foundation and Advanced Technology(grant numbers:15JCZDJC31500); Tianjin Science Foundation(grant numbers:16JCYBJC16500); Tianjin Higher Education Creative Team Funds Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502787","Autoencoder;deep learning;small sample;target identification;ultra-wideband radar","Classification algorithms;Feature extraction;Training;Support vector machines;Mathematical model;Kernel","","","","8","","24","OAPA","23 Oct 2018","","","IEEE","IEEE Journals"
"Low-Dose CT With a Residual Encoder-Decoder Convolutional Neural Network","H. Chen; Y. Zhang; M. K. Kalra; F. Lin; Y. Chen; P. Liao; J. Zhou; G. Wang","College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; Department of Radiology, Massachusetts General Hospital, Boston, MA, USA; College of Computer Science, Sichuan University, Chengdu, China; Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, Nanjing, China; Department of Scientific Research and Education, The Sixth People’s Hospital of Chengdu, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA","IEEE Transactions on Medical Imaging","29 Nov 2017","2017","36","12","2524","2535","Given the potential risk of X-ray radiation to the patient, low-dose CT has attracted a considerable interest in the medical imaging field. Currently, the main stream low-dose CT methods include vendor-specific sinogram domain filtration and iterative reconstruction algorithms, but they need to access raw data, whose formats are not transparent to most users. Due to the difficulty of modeling the statistical characteristics in the image domain, the existing methods for directly processing reconstructed images cannot eliminate image noise very well while keeping structural details. Inspired by the idea of deep learning, here we combine the autoencoder, deconvolution network, and shortcut connections into the residual encoder-decoder convolutional neural network (RED-CNN) for low-dose CT imaging. After patch-based training, the proposed RED-CNN achieves a competitive performance relative to the-state-of-art methods in both simulated and clinical cases. Especially, our method has been favorably evaluated in terms of noise suppression, structural preservation, and lesion detection.","1558-254X","","10.1109/TMI.2017.2715284","National Natural Science Foundation of China(grant numbers:61671312,61302028,61202160,81370040,81530060); National Institute of Biomedical Imaging and Bioengineering/National Institutes of Health(grant numbers:R01 EB016977,U01 EB017140); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7947200","Low-dose CT;deep learning;auto-encoder;convolutional;deconvolutional;residual neural network","Image reconstruction;Computed tomography;Convolution;Feature extraction;Decoding;X-ray imaging","computerised tomography;deconvolution;image denoising;image reconstruction;iterative methods;learning (artificial intelligence);medical image processing;neural nets;statistical analysis","residual encoder-decoder convolutional neural network;X-ray radiation;medical imaging field;main stream low-dose CT methods;vendor-specific sinogram domain filtration;iterative reconstruction algorithms;raw data;statistical characteristics;image domain;image noise;deep learning;autoencoder;deconvolution network;residual encoder-decoder convolutional neural network;RED-CNN;low-dose CT imaging;patch-based training;noise suppression;structural preservation;lesion detection","Abdomen;Algorithms;Computer Simulation;Humans;Image Processing, Computer-Assisted;Liver Neoplasms;Neural Networks (Computer);Tomography, X-Ray Computed","563","","51","IEEE","13 Jun 2017","","","IEEE","IEEE Journals"
"Discriminative Robust Deep Dictionary Learning for Hyperspectral Image Classification","V. Singhal; H. K. Aggarwal; S. Tariyal; A. Majumdar","Indraprastha Institute of Information Technology at Delhi, New Delhi, India; Indraprastha Institute of Information Technology at Delhi, New Delhi, India; Indraprastha Institute of Information Technology at Delhi, New Delhi, India; Indraprastha Institute of Information Technology at Delhi, New Delhi, India","IEEE Transactions on Geoscience and Remote Sensing","25 Aug 2017","2017","55","9","5274","5283","This paper proposes a new framework for deep learning that has been particularly tailored for hyperspectral image classification. We learn multiple levels of dictionaries in a robust fashion. The last layer is discriminative that learns a linear classifier. The training proceeds greedily; at a time, a single level of dictionary is learned and the coefficients used to train the next level. The coefficients from the final level are used for classification. Robustness is incorporated by minimizing the absolute deviations instead of the more popular Euclidean norm. The inbuilt robustness helps combat mixed noise (Gaussian and sparse) present in hyperspectral images. Results show that our proposed techniques outperform all other deep learning methods-deep belief network, stacked autoencoder, and convolutional neural network. The experiments have been carried out on both benchmark deep learning data sets (MNIST, CIFAR-10, and Street View House Numbers) as well as on real hyperspectral imaging data sets.","1558-0644","","10.1109/TGRS.2017.2704590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7948751","Deep learning;dictionary learning;robust estimation","Dictionaries;Machine learning;Artificial neural networks;Hyperspectral imaging;Robustness;Tools","belief networks;Gaussian noise;hyperspectral imaging;image classification;image denoising;learning (artificial intelligence);neural nets","discriminative robust deep dictionary learning;hyperspectral image classification;linear classifier;Gaussian noise;sparse noise;Euclidean norm;deep belief network;stacked autoencoder;convolutional neural network","","42","","50","IEEE","14 Jun 2017","","","IEEE","IEEE Journals"
"Experimental Study on Extreme Learning Machine Applications for Speech Enhancement","T. Hussain; S. M. Siniscalchi; C. -C. Lee; S. -S. Wang; Y. Tsao; W. -H. Liao","Department of Computer Science, National Chengchi University, Taipei, Taiwan; Department of Computer Engineering, Kore University of Enna, Enna, Italy; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Department of Computer Science, National Chengchi University, Taipei, Taiwan","IEEE Access","7 Dec 2017","2017","5","","25542","25554","In wireless telephony and audio data mining applications, it is desirable that noise suppression can be made robust against changing noise conditions and operates in real time (or faster). The learning effectiveness and speed of artificial neural networks are therefore critical factors in applications for speech enhancement tasks. To address these issues, we present an extreme learning machine (ELM) framework, aimed at the effective and fast removal of background noise from a single-channel speech signal, based on a set of randomly chosen hidden units and analytically determined output weights. Because feature learning with shallow ELM may not be effective for natural signals, such as speech, even with a large number of hidden nodes, hierarchical ELM (H-ELM) architectures are deployed by leveraging sparse autoencoders. In this manner, we not only keep all the advantages of deep models in approximating complicated functions and maintaining strong regression capabilities, but we also overcome the cumbersome and time-consuming features of both greedy layer-wise pre-training and back-propagation (BP)-based fine tuning schemes, which are typically adopted for training deep neural architectures. The proposed ELM framework was evaluated on the Aurora-4 speech database. The Aurora-4 task provides relatively limited training data, and test speech data corrupted with both additive noise and convolutive distortions for matched and mismatched channels and signal-to-noise ratio (SNR) conditions. In addition, the task includes a subset of testing data involving noise types and SNR levels that are not seen in the training data. The experimental results indicate that when the amount of training data is limited, both ELMand H-ELM-based speech enhancement techniques consistently outperform the conventional BP-based shallow and deep learning algorithms, in terms of standardized objective evaluations, under various testing conditions.","2169-3536","","10.1109/ACCESS.2017.2766675","National Science Council(grant numbers:MOST104-2221-E-001-026-MY2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8085130","Speech enhancement;artificial neural networks;extreme learning machine;hierarchical extreme learning machines","Speech enhancement;Speech;Noise measurement;Training data;Signal to noise ratio;Noise reduction","backpropagation;data mining;feedforward neural nets;learning (artificial intelligence);regression analysis;signal denoising;speech enhancement","extreme learning machine applications;wireless telephony;audio data mining applications;noise suppression;noise conditions;learning effectiveness;artificial neural networks;critical factors;speech enhancement tasks;background noise;single-channel speech signal;randomly chosen hidden units;output weights;shallow ELM;natural signals;hidden nodes;hierarchical ELM architectures;sparse autoencoders;deep models;complicated functions;greedy layer-wise pre-training;fine tuning schemes;deep neural architectures;ELM framework;Aurora-4 speech database;training data;test speech data;additive noise;mismatched channels;testing data;noise types;ELMand H-ELM;deep learning algorithms;testing conditions;regression capabilities","","33","","69","OAPA","26 Oct 2017","","","IEEE","IEEE Journals"
"Bringing Old Photos Back to Life","Z. Wan; B. Zhang; D. Chen; P. Zhang; D. Chen; J. Liao; F. Wen",City University of Hong Kong; Microsoft Research Asia; Microsoft Cloud + AI; University of Science and Technology of China; Microsoft Research Asia; City University of Hong Kong; Microsoft Research Asia,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","2744","2754","We propose to restore old photos that suffer from severe degradation through a deep learning approach. Unlike conventional restoration tasks that can be solved through supervised learning, the degradation in real photos is complex and the domain gap between synthetic images and real old photos makes the network fail to generalize. Therefore, we propose a novel triplet domain translation network by leveraging real photos along with massive synthetic image pairs. Specifically, we train two variational autoencoders (VAEs) to respectively transform old photos and clean photos into two latent spaces. And the translation between these two latent spaces is learned with synthetic paired data. This translation generalizes well to real photos because the domain gap is closed in the compact latent space. Besides, to address multiple degradations mixed in one old photo, we design a global branch with a partial nonlocal block targeting to the structured defects, such as scratches and dust spots, and a local branch targeting to the unstructured defects, such as noises and blurriness. Two branches are fused in the latent space, leading to improved capability to restore old photos from multiple defects. The proposed method outperforms state-of-the-art methods in terms of visual quality for old photos restoration.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156748","","Image restoration;Degradation;Zirconium;Image color analysis;Fading channels;Task analysis;Image resolution","image coding;image denoising;image restoration;image texture;learning (artificial intelligence)","local branch;VAE;variational autoencoders;deep learning approach;old photo restoration;latent space;clean photos;massive synthetic image pairs;triplet domain translation network;domain gap","","25","","59","IEEE","5 Aug 2020","","","IEEE","IEEE Conferences"
"A Novel Multivariate-Multiscale Approach for Computing EEG Spectral and Temporal Complexity for Human Emotion Recognition","A. Bhattacharyya; R. K. Tripathy; L. Garg; R. B. Pachori","Department of Electronics and Communication Engineering, National Institute of Technology Hamirpur, Hamirpur, India; Department of Electrical and Electronics Engineering, Birla Institute of Technology and Science Pilani (BITS Pilani) at Hyderabad Campus, Hyderabad, India; Department of Information and Communication Technology, University of Malta, Msida, Malta; Discipline of Electrical Engineering, Indian Institute of Technology Indore, Indore, India","IEEE Sensors Journal","6 Jan 2021","2021","21","3","3579","3591","This work proposes a novel multivariate-multiscale approach for computing the spectral and temporal entropies from the multichannel electroencephalogram (EEG) signal. This facilitates the recognition of three human emotions: positive, neutral, and negative. The proposed approach is based on the application of the Fourier-Bessel series expansion based empirical wavelet transform (FBSE-EWT). We have extended the existing FBSE-EWT method for multichannel signals and derived FBSE-EWT based multivariate Hilbert marginal spectrum (MHMS) for computing spectral Shannon and K-nearest neighbor (K-NN) entropies. The multivariate FBSE-EWT decomposes the multichannel EEG signals into narrow band subband signals. The multiscaling operation adapted in the spectral domain is based on the selection of successive joint instantaneous amplitude and frequency functions of the subband signals. On the other hand, the time domain multiscale K-NN entropy is computed from the cumulatively added multidimensional subband signals. The extracted spectral and temporal entropy features are smoothed and fed to the sparse autoencoder based random forest (ARF) classifier architecture for emotion classification. The proposed approach is tested using multichannel EEG signals available in a public database (SJTU emotion EEG dataset (SEED)). The bivariate EEG signals from different channel pairs with distinct spatial locations over the scalp are considered as input to our proposed system. The obtained overall classification accuracy of 94.4% reveals that the proposed approach is useful in classifying human emotions. The method is also validated using DREAMER emotion EEG public database. The method outperforms the existing state-of-the-art methods evaluated in these databases.","1558-1748","","10.1109/JSEN.2020.3027181","University of Malta’s Research Innovation and Development Trust (RIDT) under Research Grant(grant numbers:E18LO77-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207950","Multivariate-multiscale;emotion recognition;spectral entropy;temporal entropy;ARF classifier","Electroencephalography;Entropy;Emotion recognition;Time-frequency analysis;Transforms;Feature extraction;Support vector machines","electroencephalography;emotion recognition;entropy;feature extraction;filtering theory;Hilbert transforms;medical signal processing;signal denoising;wavelet transforms","Fourier-Bessel series expansion;empirical wavelet;multichannel signals;FBSE-EWT based multivariate Hilbert marginal spectrum;multivariate FBSE-EWT;narrow band subband signals;spectral domain;successive joint instantaneous amplitude;frequency functions;time domain multiscale K-NN entropy;multidimensional subband signals;spectral entropy features;temporal entropy features;random forest classifier architecture;emotion classification;multichannel EEG signals;bivariate EEG signals;DREAMER emotion EEG public database;temporal complexity;human emotion recognition;spectral entropies;temporal entropies;multichannel electroencephalogram signal;multivariate-multiscale approach;ARF classifier architecture;sparse autoencoder based random forest;Shannon entropy;K-nearest neighbor entropy","","21","","57","IEEE","28 Sep 2020","","","IEEE","IEEE Journals"
"Representation Learning for Single-Channel Source Separation and Bandwidth Extension","M. Zöhrer; R. Peharz; F. Pernkopf","Intelligent Systems Group, Graz University of Technology, Graz, Austria; iDN–Institute of Physiology, Medical University of Graz, Graz, Austria; Intelligent Systems Group, Graz University of Technology, Graz, Austria","IEEE/ACM Transactions on Audio, Speech, and Language Processing","20 May 2017","2015","23","12","2398","2409","In this paper, we use deep representation learning for model-based single-channel source separation (SCSS) and artificial bandwidth extension (ABE). Both tasks are ill-posed and source-specific prior knowledge is required. In addition to well-known generative models such as restricted Boltzmann machines and higher order contractive autoencoders two recently introduced deep models, namely generative stochastic networks (GSNs) and sum-product networks (SPNs), are used for learning spectrogram representations. For SCSS we evaluate the deep architectures on data of the 2 nd CHiME speech separation challenge and provide results for a speaker dependent, a speaker independent, a matched noise condition and an unmatched noise condition task. GSNs obtain the best PESQ and overall perceptual score on average in all four tasks. Similarly, frame-wise GSNs are able to reconstruct the missing frequency bands in ABE best, measured in frequency-domain segmental SNR. They outperform SPNs embedded in hidden Markov models and the other representation models significantly.","2329-9304","","10.1109/TASLP.2015.2470560","Austrian Science Fund(grant numbers:P25244-N15,P27803-N15); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7210172","Bandwidth extension;deep neural networks (DNNs);generative stochastic networks;representation learning;single-channel source separation (SCSS);sum-product networks","Hidden Markov models;Spectrogram;Learning systems;Speech processing;Data models;Adaptation models;Bandwidth;Neural networks;Stochastic processes","Boltzmann machines;hidden Markov models;learning (artificial intelligence);signal denoising;source separation;speaker recognition","deep representation learning;model-based single-channel source separation;SCSS;artificial bandwidth extension;ABE;ill-posed prior knowledge;source-specific prior knowledge;generative models;restricted Boltzmann machines;higher order contractive autoencoders;generative stochastic networks;GSN;sumproduct networks;SPN;2nd CHiME speech separation challenge;speaker dependent;speaker independent;matched noise condition;unmatched noise condition task;PESQ;overall perceptual score;frame-wise GSN;missing frequency band reconstruction;frequency-domain segmental SNR;hidden Markov models","","14","","78","IEEE","19 Aug 2015","","","IEEE","IEEE Journals"
"Memory-Oriented Unpaired Learning for Single Remote Sensing Image Dehazing","X. Chen; Y. Huang","College of Electronic and Information Engineering, Shenyang Aerospace University, Shenyang, China; College of Electronic and Information Engineering, Shenyang Aerospace University, Shenyang, China","IEEE Geoscience and Remote Sensing Letters","28 Apr 2022","2022","19","","1","5","Remote sensing image dehazing (RSID) is an extremely challenging problem due to the irregular and nonuniform distribution of haze. The existing RSID methods achieve excellent performance using deep learning; however, relying on paired synthetic data is limited to their generality in various haze distribution. In this letter, we present a memory-oriented generative adversarial network (MO-GAN), which tries to capture the desired hazy features in an unpaired learning manner toward single RSID. For better extracting the haze-relevant features, a novel multistage attentive-recurrent memory module is designed to guide an autoencoder neural network, which can record the various appearances of haze distribution at different stages. To well differentiate fake images from real ones, a dual region discriminator is constructed to handle spatially varying haze densities in global and local regions. Extensive experiments demonstrate that our designed MO-GAN outperforms the recent comparing approaches on the various frequently used datasets, especially in real world nonuniform haze conditions. The source code is released in https://github.com/cxtalk/MO-GAN.","1558-0571","","10.1109/LGRS.2022.3167476","Liaoning Education Department of Science and Technology research project(grant numbers:JYT2020030); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757219","Attention mechanism;generative adversarial networks (GANs);haze removal;memory network;remote sensing (RS) image;unpaired learning","Feature extraction;Generative adversarial networks;Training;Memory modules;Sensors;Image reconstruction;Task analysis","feature extraction;geophysical image processing;image classification;image denoising;learning (artificial intelligence);neural nets;remote sensing","global regions;local regions;MO-GAN;world nonuniform haze conditions;memory-oriented unpaired learning;single remote sensing image dehazing;extremely challenging problem;existing RSID methods;deep learning;paired synthetic data;haze distribution;memory-oriented generative adversarial network;desired hazy features;unpaired learning manner;single RSID;haze-relevant features;novel multistage attentive-recurrent memory module;autoencoder neural network;differentiate fake images;dual region discriminator;haze densities","","1","","27","IEEE","14 Apr 2022","","","IEEE","IEEE Journals"
"Image-based Sea/Land Map Generation from Radar Data","F. J. Riera; R. Engholm; L. W. Jochumsen; T. B. Moeslund","Aalborg University, Aalborg, Denmark; Terma A/S, Lystrup, Denmark; Terma A/S, Lystrup, Denmark; Aalborg University, Aalborg, Denmark","2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)","14 Feb 2019","2018","","","1","6","2D radars are efficient sensors used for e.g. coastal or shipborne surveillance. However, the recorded data contains echoes from all its surroundings, without any discrimination of land, sea or occluded terrain, which degrades the performance of target detectors and trackers. We assume that a complete 360° radar scan can be used as an image and thereby exploit its spatial information with a multi-scale feature-connected convolutional autoencoder to perform image-based radar segmentation. Our method is compared against the reimplementation of a temporal-based classifier when using unfiltered radar data. The conducted experiments display that our framework can overcome the noise problems inherit in 2D radar data and discriminate the different surfaces by outperforming the temporal-based implementation with a 20% increase in mean pixel-wise accuracy, with a mAP of 67%, and a mean IoU of 58.67%. This is a promising approach towards the application of deep learning for segmentation of radar-based images.","","978-1-5386-9294-3","10.1109/AVSS.2018.8639357","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8639357","","Feature extraction;Clutter;Radar imaging;Image segmentation;Radar clutter;Decoding","cartography;convolutional neural nets;feature extraction;geophysical image processing;image denoising;image segmentation;marine radar;object detection;radar imaging;remote sensing by radar;target tracking","shipborne surveillance;recorded data;target detectors;complete 360° radar scan;multiscale feature-connected convolutional autoencoder;image-based radar segmentation;unfiltered radar data;temporal-based implementation;radar-based images;target trackers;image-based sea map generation;image-based land map generation;2D radars;coastal surveillance","","1","","20","","14 Feb 2019","","","IEEE","IEEE Conferences"
"Combined Holistic and Local Patches for Recovering 6D Object Pose","Q. Cao; H. Zhang","Shanghai Jiao Tong University, Shanghai, P.R. China; Shanghai Jiao Tong University, Shanghai, P.R. China","2017 IEEE International Conference on Computer Vision Workshops (ICCVW)","22 Jan 2018","2017","","","2219","2227","We present a novel method for recovering 6D object pose in RGB-D images. By contrast with recent holistic or local patch-based method, we combine holistic patches and local patches together to fulfil this task. Our method has three stages, including holistic patch classification, local patch regression and fine 6D pose estimation. In the first stage, we apply a simple Convolutional Neural Network (CNN) to classify all the sampled holistic patches from the scene image. After that, the candidate region of target object can be segmented. In the second stage, as proposed in Doumanoglou et al. [16] and Kehl et al. [17], a Convolutional Autoencoder (CAE) is employed to extract condensed local patch feature, and coarse 6D object pose can be estimated by the regression of feature voting. Finally, we apply Particle Swarm Optimization (PSO) to refine 6D object pose. Our method is evaluated on the LINEMOD dataset [5] and the Occlusion dataset [10, 5], and compared with the state-of-the-art on the same sequences. Experimental results show that our method has high precision and good performance under foreground occlusion and background clutter conditions.","2473-9944","978-1-5386-1034-3","10.1109/ICCVW.2017.259","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8265469","","Feature extraction;Conferences;Computer vision;Pose estimation;Image segmentation","feature extraction;feedforward neural nets;image classification;image colour analysis;image denoising;image segmentation;object detection;particle swarm optimisation;pose estimation;regression analysis","sampled holistic patches;target object;local patch feature;coarse 6D object;holistic patch classification;simple convolutional neural network;local-patch regression;fine 6D-object pose estimation;convolutional autoencoder;CAE;particle swarm optimization;PSO;LINEMOD dataset","","1","","37","","22 Jan 2018","","","IEEE","IEEE Conferences"
"Noise image segmentation method based on offset field estimation","Z. Ling; S. Fangxing; L. Jianchao; L. Gang; Z. Juming; Z. Yueqin","University of Technology,College of Software of Taiyuan,Taiyuan,China; University of Technology,College of Information and Computer of Taiyuan,Taiyuan,China; University of Technology,College of Software of Taiyuan,Taiyuan,China; University of Technology,College of Software of Taiyuan,Taiyuan,China; University of Technology,College of Information and Computer of Taiyuan,Taiyuan,China; Tizones Technology Co.,Ltd.,Information Technology,Department of Shanxi,Taiyuan,China","2020 Eighth International Conference on Advanced Cloud and Big Data (CBD)","21 Apr 2021","2020","","","189","194","The model of level set based on the local offset field solves the problem that the traditional local model cannot deal with the uneven grayscale images. But the performance of the model on noisy images is still not excellent. In response to this problem, this paper introduces a convolutional autoencoder to design an unsupervised noise separation mechanism to model the noise field based on the local model, so that the additive noise field can be separated from the image and avoid its interference to the image segmentation process. The results show that the proposed method can separate the additive image noise effectively and improve the segmentation accuracy in a noisy environment, which is superior to traditional noise robust models and offset field models.","","978-1-6654-2313-7","10.1109/CBD51900.2020.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9406899","Image Segmentation;Offset Field;Noisy Image;Automatic Encoder","Image segmentation;Adaptation models;Level set;Fitting;Manuals;Interference;Gray-scale","image denoising;image segmentation","offset field models;noisy environment;segmentation accuracy;additive image noise;image segmentation process;additive noise field;unsupervised noise separation mechanism;convolutional autoencoder;noisy images;uneven grayscale images;local offset field;offset field estimation;noise image segmentation method","","","","7","","21 Apr 2021","","","IEEE","IEEE Conferences"
"Defect Detection of Rubber Gloves Based on Normal Samples","N. Yu; H. Wang; Q. Xu; J. Lin","Faculty of Information Technology, Ministry of Education, Beijing University of Technology, Beijing Key Laboratory of Computing Intelligence and Intelligent System, Engineering Research Center of Digital Community, Beijing, China; Faculty of Information Technology, Ministry of Education, Beijing University of Technology, Beijing Key Laboratory of Computing Intelligence and Intelligent System, Engineering Research Center of Digital Community, Beijing, China; Faculty of Information Technology, Ministry of Education, Beijing University of Technology, Beijing Key Laboratory of Computing Intelligence and Intelligent System, Engineering Research Center of Digital Community, Beijing, China; Faculty of Information Technology, Ministry of Education, Beijing University of Technology, Beijing Key Laboratory of Computing Intelligence and Intelligent System, Engineering Research Center of Digital Community, Beijing, China","2021 IEEE 6th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA)","2 Jun 2021","2021","","","612","618","Rubber gloves are widely favored in various industries, and the defect detection link in production is very important. This paper proposes a method for detecting defects in rubber gloves based on normal samples (no defects). First, random noise is added to the collected rubber glove images, and the size is standardized and unified. Secondly, establish an improved GANomaly network model. According to the small and difficult defect to distinguish characteristics of black spots and oil defects of rubber gloves, a noise-reducing convolutional autoencoder is built in the network model as a generation network, and the least square loss is introduced for the model of confrontation training. The model only uses normal sample input for training, learning the characteristic distribution of the normal sample and performs image reconstruction, and judges whether it has defects according to the reconstruction effect score of the input sample during testing. The experiment is based on the rubber glove image data set, and the results show that the method can accurately identify whether there are defects on the rubber glove.","","978-1-6654-2311-3","10.1109/ICCCBDA51879.2021.9442497","Beijing Municipal Education Commission; Beijing Municipal Natural Science Foundation of China(grant numbers:KZ202010005004); National Natural Science Foundation of China(grant numbers:62076014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442497","defect detection;normal Samples;generative confrontation network;GANomaly","Training;Industries;Cloud computing;Oils;Conferences;Production;Generative adversarial networks","automatic optical inspection;convolutional neural nets;deep learning (artificial intelligence);flaw detection;image denoising;image reconstruction;image sampling;least squares approximations;production engineering computing;protective clothing;random noise;rubber products","defect detection;improved GANomaly network model;oil defects;image reconstruction;rubber glove image data;random noise;black spots;noise-reducing convolutional autoencoder;network model;generation network;least square loss;confrontation training;deep learning","","","","18","","2 Jun 2021","","","IEEE","IEEE Conferences"
"Triple-Regularized Latent Subspace Discriminative Regression for Hyperspectral Image Classification","W. Wang; Z. Yang; P. Huang; F. Zhang; W. Tang","School of Information and Engineering, Nanjing Audit University, Nanjing, China; School of Information and Engineering, Nanjing Audit University, Nanjing, China; School of Information and Engineering, Nanjing Audit University, Nanjing, China; School of Information and Engineering, Nanjing Audit University, Nanjing, China; School of Information and Engineering, Nanjing Audit University, Nanjing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","3 Aug 2021","2021","14","","7310","7323","There are various types and distributions of noise in hyperspectral images. However, the existing classification models are vulnerable to noise in the data. To improve the robustness of the classification models, a novel hyperspectral image classification model is proposed, named triple-regularized latent subspace discriminative regression (TRLSDR). The core idea of TRLSDR is to add a latent subspace to the standard discriminative least squares regression model to extract high-order features from the visual space by undercomplete autoencoder, and then use clean data for classification. Three regularizers are introduced in this process: Tikhonov regularizer is used to avoid overfitting; Laplacian regularizer is used to capture the neighborhood relationship; and low-rank regularizer is used to alleviate the error of Laplacian matrix construction caused by noise in original samples. We designed experiments on five hyperspectral image datasets and the results show that the proposed model is superior to the existing regression models.","2151-1535","","10.1109/JSTARS.2021.3094816","National Natural Science Foundation of China(grant numbers:U1831127); Jiangsu Science and Technology Department(grant numbers:BY2020033); Nanjing Audit University(grant numbers:A111010004/012); Six Peak Talent and Qinglan Project of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9476983","Graph regularization;hyperspectral image classification;low rank;manifold learning;noise reduction","Data models;Visualization;Hyperspectral imaging;Manifolds;Optimization;Noise reduction;Laplace equations","feature extraction;geophysical image processing;geophysics computing;hyperspectral imaging;image classification;image denoising;least squares approximations;matrix algebra;regression analysis","hyperspectral image classification;TRLSDR;Tikhonov regularizer;Laplacian regularizer;triple regularized latent subspace discriminative regression;discriminative least squares regression model;autoencoder;Laplacian matrix;Indian Pines","","","","45","CCBY","7 Jul 2021","","","IEEE","IEEE Journals"
"Noise RETF Estimation and Removal for Low SNR Speech Enhancement","L. Birnie; P. Samarasinghe; T. Abhayapala; D. Grixti-Cheng","Audio & Acoustic Signal Processing Group, The Australian National University, Canberra, Australia; Audio & Acoustic Signal Processing Group, The Australian National University, Canberra, Australia; Audio & Acoustic Signal Processing Group, The Australian National University, Canberra, Australia; Audio & Acoustic Signal Processing Group, The Australian National University, Canberra, Australia","2021 IEEE 31st International Workshop on Machine Learning for Signal Processing (MLSP)","15 Nov 2021","2021","","","1","6","A method for offline two-microphone speech enhancement in highly adverse noisy environments with signal-to-noise (SNR) ratios of −10 to −20 dB is proposed. While the topic of speech enhancement is well researched, there are very few methods developed to address such significant noise conditions. Specifically, we are interested in removing noise from unintelligible recordings such that the resulting denoised speech content is understandable to human listeners. We propose exploiting the Relative Transfer Function (ReTF), a spatial feature of the noise source in a speech enhancement algorithm. We model the noise source ReTF with a time-domain machine learning structure to estimate and subtract the noise signal from the mixture. Both a linear filtering and an autoen-coder based structure are proposed. For a single interfering noise source, speech intelligibility is improved to within 9% below the Short-Time Objective Intelligibility (STOI) score of the benchmark oracle Ideal Binary Mask (IBM).","1551-2541","978-1-7281-6338-3","10.1109/MLSP52302.2021.9596209","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9596209","Relative transfer function;noise removal;speech enhancement;two-microphone;time-domain;CNN","Maximum likelihood detection;Machine learning algorithms;Convolution;Signal processing algorithms;Transfer functions;Machine learning;Speech enhancement","filtering theory;learning (artificial intelligence);neural nets;noise;signal denoising;speech enhancement;speech intelligibility","noise RETF estimation;low SNR speech enhancement;offline two-microphone speech enhancement;highly adverse noisy environments;signal-to-noise ratios;unintelligible recordings;relative transfer function;noise source ReTF;speech intelligibility;time-domain machine learning structure;linear filtering;autoencoder based structure;noise figure -20.0 dB to -10.0 dB","","","","39","IEEE","15 Nov 2021","","","IEEE","IEEE Conferences"
"A Deep Convolutional Coupling Network for Change Detection Based on Heterogeneous Optical and Radar Images","J. Liu; M. Gong; K. Qin; P. Zhang","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi’an, China; School of Computer Science and Information Technology, RMIT University, Melbourne, VIC, Australia; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi’an, China","IEEE Transactions on Neural Networks and Learning Systems","23 Feb 2018","2018","29","3","545","559","We propose an unsupervised deep convolutional coupling network for change detection based on two heterogeneous images acquired by optical sensors and radars on different dates. Most existing change detection methods are based on homogeneous images. Due to the complementary properties of optical and radar sensors, there is an increasing interest in change detection based on heterogeneous images. The proposed network is symmetric with each side consisting of one convolutional layer and several coupling layers. The two input images connected with the two sides of the network, respectively, are transformed into a feature space where their feature representations become more consistent. In this feature space, the different map is calculated, which then leads to the ultimate detection map by applying a thresholding algorithm. The network parameters are learned by optimizing a coupling function. The learning process is unsupervised, which is different from most existing change detection methods based on heterogeneous images. Experimental results on both homogenous and heterogeneous images demonstrate the promising performance of the proposed network compared with several existing approaches.","2162-2388","","10.1109/TNNLS.2016.2636227","National Natural Science Foundation of China(grant numbers:61422209); National Program for Support of Top-Notch Young Professionals of China; Specialized Research Fund for the Doctoral Program of Higher Education(grant numbers:20130203110011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7795259","Change detection;deep neural network;denoising autoencoder optical images;synthetic aperture radar images","Optical sensors;Optical imaging;Feature extraction;Neural networks;Couplings;Laser radar","feature extraction;image representation;object detection;optical images;radar imaging;unsupervised learning","unsupervised deep convolutional coupling network;optical sensors;homogeneous images;convolutional layer;coupling layers;feature space;ultimate detection map;network parameters;coupling function;change detection methods;heterogeneous optical and radar images;thresholding algorithm;learning process","","181","","57","IEEE","22 Dec 2016","","","IEEE","IEEE Journals"
"Loop closure detection for visual SLAM systems using deep neural networks","X. Gao; T. Zhang","Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China","2015 34th Chinese Control Conference (CCC)","14 Sep 2015","2015","","","5851","5856","The detection of loop closure is of essential importance in visual simultaneous localization and mapping systems. It can reduce the accumulating drift of localization algorithms if the loops are checked correctly. Traditional loop closure detection approaches take advantage of Bag-of-Words model, which clusters the feature descriptors as words and measures the similarity between the observations in the word space. However, the features are usually designed artificially and may not be suitable for data from new-coming sensors. In this paper a novel loop closure detection approach is proposed that learns features from raw data using deep neural networks instead of common visual features. We discuss the details of the method of training neural networks. Experiments on an open dataset are also demonstrated to evaluate the performance of the proposed method. It can be seen that the neural network is feasible to solve this problem.","1934-1768","978-9-8815-6389-7","10.1109/ChiCC.2015.7260555","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7260555","Simultaneous Localization and Mapping;Loop Closure Detection;Deep Neural Networks;Denoising Autoencoder","Training;Simultaneous localization and mapping;Neural networks;Visualization;Feature extraction;Machine learning;Sparse matrices","neurocontrollers;robot vision;SLAM (robots)","loop closure detection;visual SLAM systems;deep neural networks;visual simultaneous localization and mapping systems;bag-of-words","","28","","20","","14 Sep 2015","","","IEEE","IEEE Conferences"
"A recurrent encoder-decoder approach with skip-filtering connections for monaural singing voice separation","S. I. Mimilakis; K. Drossos; T. Virtanen; G. Schuller","Fraunhofer IDMT, Ilmenau, Germany; Tampere University of Technology, Tampere, Finland; Tampere University of Technology, Tampere, Finland; Technical University of Ilmenau, Ilmenau, Germany","2017 IEEE 27th International Workshop on Machine Learning for Signal Processing (MLSP)","7 Dec 2017","2017","","","1","6","The objective of deep learning methods based on encoder-decoder architectures for music source separation is to approximate either ideal time-frequency masks or spectral representations of the target music source(s). The spectral representations are then used to derive time-frequency masks. In this work we introduce a method to directly learn time-frequency masks from an observed mixture magnitude spectrum. We employ recurrent neural networks and train them using prior knowledge only for the magnitude spectrum of the target source. To assess the performance of the proposed method, we focus on the task of singing voice separation. The results from an objective evaluation show that our proposed method provides comparable results to deep learning based methods which operate over complicated signal representations. Compared to previous methods that approximate time-frequency masks, our method has increased performance of signal to distortion ratio by an average of 3.8 dB.","","978-1-5090-6341-3","10.1109/MLSP.2017.8168117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8168117","Music source separation;deep learning;denoising autoencoders","Time-frequency analysis;Spectrogram;Decoding;Road transportation;Source separation;Estimation;Machine learning","acoustic signal processing;approximation theory;audio signal processing;decoding;encoding;learning (artificial intelligence);music;recurrent neural nets;signal representation;source separation;speech processing;time-frequency analysis","recurrent encoder-decoder approach;skip-filtering connections;monaural singing voice separation;deep learning methods;encoder-decoder architectures;music source separation;spectral representations;target music source;target source;deep learning based methods;signal representations;time-frequency masks;mixture magnitude spectrum","","20","3","29","","7 Dec 2017","","","IEEE","IEEE Conferences"
"A Robust Approach for Securing Audio Classification Against Adversarial Attacks","M. Esmaeilpour; P. Cardinal; A. Lameiras Koerich","Department of Software and IT Engineering, École de Technologie Supérieure, University of Quebec, Montreal, Canada; Department of Software and IT Engineering, École de Technologie Supérieure, University of Quebec, Montreal, Canada; Department of Software and IT Engineering, École de Technologie Supérieure, University of Quebec, Montreal, Canada","IEEE Transactions on Information Forensics and Security","4 Feb 2020","2020","15","","2147","2159","Adversarial audio attacks can be considered as a small perturbation unperceptive to human ears that is intentionally added to an audio signal and causes a machine learning model to make mistakes. This poses a security concern about the safety of machine learning models since the adversarial attacks can fool such models toward the wrong predictions. In this paper we first review some strong adversarial attacks that may affect both audio signals and their 2D representations and evaluate the resiliency of deep learning models and support vector machines (SVM) trained on 2D audio representations such as short time Fourier transform, discrete wavelet transform (DWT) and cross recurrent plot against several state-of-the-art adversarial attacks. Next, we propose a novel approach based on pre-processed DWT representation of audio signals and SVM to secure audio systems against adversarial attacks. The proposed architecture has several preprocessing modules for generating and enhancing spectrograms including dimension reduction and smoothing. We extract features from small patches of the spectrograms using the speeded up robust feature (SURF) algorithm which are further used to transform into cluster distance distribution using the K-Means++ algorithm. Finally, SURF-generated vectors are encoded by this codebook and the resulting codewords are used for training a SVM. All these steps yield to a novel approach for audio classification that provides a good tradeoff between accuracy and resilience. Experimental results on three environmental sound datasets show the competitive performance of the proposed approach compared to the deep neural networks both in terms of accuracy and robustness against strong adversarial attacks.","1556-6021","","10.1109/TIFS.2019.2956591","Natural Sciences and Engineering Research Council of Canada(grant numbers:RGPIN 2016-04855,RGPIN 2016-06628); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8922608","Spectrograms;environmental sound classification;adversarial attack;K-means++;support vector machines (SVM);convolutional denoising autoencoder","Support vector machines;Machine learning;Robustness;Perturbation methods;Predictive models;Optimization;Two dimensional displays","audio signal processing;discrete wavelet transforms;feature extraction;Fourier transforms;learning (artificial intelligence);neural nets;security of data;signal classification;support vector machines","discrete wavelet transform;K-Means++ algorithm;SURF algorithm;pre-processed DWT representation;short time Fourier transform;2D audio representations;support vector machines;deep learning models;security concern;machine learning model;audio signal;adversarial audio attacks;audio classification;SVM;speeded up robust feature algorithm","","20","","47","IEEE","4 Dec 2019","","","IEEE","IEEE Journals"
"Pointfilter: Point Cloud Filtering via Encoder-Decoder Modeling","D. Zhang; X. Lu; H. Qin; Y. He","State Key Laboratory of Virtual Reality Technology and Systems, Beihang Unviersity, Beijing, China; School of Information Technology, Deakin University, Geelong, Australia; Department of Computer Science, Stony Brook University, Stony Brook, NY, USA; School of Computer Science and Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Visualization and Computer Graphics","29 Jan 2021","2021","27","3","2015","2027","Point cloud filtering is a fundamental problem in geometry modeling and processing. Despite of significant advancement in recent years, the existing methods still suffer from two issues: 1) they are either designed without preserving sharp features or less robust in feature preservation; and 2) they usually have many parameters and require tedious parameter tuning. In this article, we propose a novel deep learning approach that automatically and robustly filters point clouds by removing noise and preserving their sharp features. Our point-wise learning architecture consists of an encoder and a decoder. The encoder directly takes points (a point and its neighbors) as input, and learns a latent representation vector which goes through the decoder to relate the ground-truth position with a displacement vector. The trained neural network can automatically generate a set of clean points from a noisy input. Extensive experiments show that our approach outperforms the state-of-the-art deep learning techniques in terms of both visual quality and quantitative error metrics. The source code and dataset can be found at https://github.com/dongbo-BUAA-VR/Pointfilter.","1941-0506","","10.1109/TVCG.2020.3027069","National Key R&D Program of China(grant numbers:2017YFF0106407); Deakin University(grant numbers:CY01-251301-F003-PJ03906-PG00447); industry Grant(grant numbers:PJ06625); Australian Cancer Research Foundation(grant numbers:20/20); National Natural Science Foundation of China(grant numbers:61532002); National Science Foundation(grant numbers:IIS-0949467,IIS-1047715,IIS-1812606,IIS-1715985,IIS-1049448); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207844","Automatic point cloud filtering;deep learning;autoencoder;feature-preserving denoising","Three-dimensional displays;Noise measurement;Machine learning;Robustness;Tuning;Network architecture;Filtering","codecs;deep learning (artificial intelligence);image coding;image filtering;neural nets;vectors","geometry modeling;feature preservation;parameter tuning;point-wise learning architecture;clean points;deep learning techniques;point cloud filtering;encoder-decoder modeling;trained neural network;latent representation vector;visual quality;quantitative error metrics;displacement vector","","11","","45","IEEE","28 Sep 2020","","","IEEE","IEEE Journals"
"Predicting the Noise Covariance With a Multitask Learning Model for Kalman Filter-Based GNSS/INS Integrated Navigation","F. Wu; H. Luo; H. Jia; F. Zhao; Y. Xiao; X. Gao","School of Software Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Research Center for Ubiquitous Computing Systems, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; School of Software Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Software Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Software Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Research Center for Ubiquitous Computing Systems, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Instrumentation and Measurement","4 Dec 2020","2021","70","","1","13","In the recent years, the availability of accurate vehicle position becomes more urgent. The global navigation satellite systems/inertial navigation system (GNSS/INS) is the most used integrated navigation scheme for land vehicles, which utilizes the Kalman filter (KF) to optimally fuse GNSS measurement and INS prediction for accurate and robust localization. However, the uncertainty of the process noise covariance and the measurement noise covariance has a significant impact on Kalman filtering performance. Traditional KF-based integrated navigation methods configure the process noise covariance and measurement noise covariance with predefined constants, which cannot adaptively characterize the various and dynamic environments, and obtain accurate and continuous positioning results under complex environments. To obtain accurate and robust localization results under various complex and dynamic environments, in this article, we propose a novel noise covariance estimation algorithm for the GNSS/INS-integrated navigation using multitask learning model, which can simultaneously estimate the process noise covariance and measurement noise covariance for the KF. The predicted multiplication factors are used to dynamically scale process noise covariance matrix and measurement noise covariance matrix respectively according to the inputs of raw inertial measurement. Extensive experiments are conducted on our collected practical road data set under three typical complex urban scenarios, such as, avenues, viaducts, and tunnels. Experimental results demonstrate that compared with the traditional KF-based integrated navigation algorithm with predefined fixed settings, our proposed method reduces 77.13% positioning error.","1557-9662","","10.1109/TIM.2020.3024357","National Key Research and Development Program of China(grant numbers:2018YFB0505200); Fundamental Research Funds for the Central Universities(grant numbers:2019XDA06); Special Project for Youth Research and Innovation, Beijing University of Posts and Telecommunications; Fundamental Research Funds for the Central Universities(grant numbers:2019PTB-011); National Natural Science Foundation of China(grant numbers:61872046,61761038); Joint Research Fund for the Beijing Natural Science Foundation and Haidian Original Innovation(grant numbers:L192004); Key Research and Development Project from Hebei Province(grant numbers:19210404D,20313701D); Science and Technology Plan Project of Inner Mongolia Autonomous Region(grant numbers:2019GG328); Open Project of the Beijing Key Laboratory of Mobile Computing and Pervasive Device; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9198927","Adaptive integrated navigation;deep learning;denoising autoencoder (DAE);Kalman filter (KF);measurement noise;process noise","Noise measurement;Kalman filters;Covariance matrices;Navigation;Estimation;Prediction algorithms;Machine learning","covariance matrices;Global Positioning System;inertial navigation;Kalman filters;learning (artificial intelligence)","multitask learning model;accurate vehicle position;integrated navigation scheme;measurement noise covariance;Kalman filtering performance;accurate positioning results;continuous positioning results;accurate localization results;robust localization results;noise covariance estimation algorithm;process noise covariance matrix;KF-based integrated navigation algorithm;GNSS-INS integrated navigation;global navigation satellite systems;inertial navigation system;land vehicles;multiplication factors;inertial measurement","","8","","37","IEEE","16 Sep 2020","","","IEEE","IEEE Journals"
"Unsupervised feature extraction for multimedia event detection and ranking using audio content","E. Amid; A. Mesaros; K. J. Palomäki; J. Laaksonen; M. Kurimo","Department of Information and Computer Science, Aalto University, Espoo, Finland; Department of Signal Processing and Acoustics, Aalto University, Espoo, Finland; Department of Signal Processing and Acoustics, Aalto University, Espoo, Finland; Department of Information and Computer Science, Aalto University, Espoo, Finland; Department of Signal Processing and Acoustics, Aalto University, Espoo, Finland","2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","14 Jul 2014","2014","","","5939","5943","In this paper, we propose a new approach to classify and rank multimedia events based purely on audio content using video data from TRECVID-2013 multimedia event detection (MED) challenge. We perform several layers of nonlinear mappings to extract a set of unsupervised features from an initial set of temporal and spectral features to obtain a superior presentation of the atomic audio units. Additionally, we propose a novel weighted divergence measure for kernel based classifiers. The extensive set of experiments confirms that augmentation of the proposed steps results in an improved accuracy for most of the event classes.","2379-190X","978-1-4799-2893-4","10.1109/ICASSP.2014.6854743","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6854743","Multimedia Event Detection;Unsupervised Feature Extraction;Stacked Denoising Autoencoders;Bag of Words;Term Weighting;Weighted Jensen-Shannon Divergence","Feature extraction;Vectors;Multimedia communication;Histograms;Speech;Noise reduction;Event detection","audio signal processing;audio streaming;feature extraction;multimedia systems;signal classification;spectral analysis;unsupervised learning","atomic audio units;weighted divergence measure;kernel based classifier;temporal features;spectral features;nonlinear mapping;TRECVID-2013;video data;multimedia event classification;audio content;multimedia event ranking;multimedia event detection;unsupervised feature extraction","","7","","23","","14 Jul 2014","","","IEEE","IEEE Conferences"
"Speech Dereverberation Based on Integrated Deep and Ensemble Learning Algorithm","W. -J. Lee; S. -S. Wang; F. Chen; X. Lu; S. -Y. Chien; Y. Tsao","Research Center for Information Technology Innovation, Academia Sinica, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taiwan; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, China; National Institute of Information and Communications Technology, Japan; Department of Electrical Engineering, National Taiwan University, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taiwan","2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 Sep 2018","2018","","","5454","5458","Reverberation, which is generally caused by sound reflections from walls, ceilings, and floors, can result in severe performance degradation of acoustic applications. Due to a complicated combination of attenuation and time-delay effects, the reverberation property is difficult to characterize, and it remains a challenging task to effectively retrieve the anechoic speech signals from reverberation ones. In the present study, we proposed a novel integrated deep and ensemble learning algorithm (IDEA) for speech dereverberation. The IDEA consists of offline and online phases. In the offline phase, we train multiple dereverberation models, each aiming to precisely dereverb speech signals in a particular acoustic environment; then a unified fusion function is estimated that aims to integrate the information of multiple dereverberation models. In the online phase, an input utterance is first processed by each of the dereverberation models. The outputs of all models are integrated accordingly to generate the final anechoic signal. We evaluated the IDEA on designed acoustic environments, including both matched and mismatched conditions of the training and testing data. Experimental results confirm that the proposed IDEA outperforms single deep-neural-network-based dereverberation model with the same model architecture and training data.","2379-190X","978-1-5386-4658-8","10.1109/ICASSP.2018.8462662","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8462662","Deep neural networks;Speech dereverberation;Ensemble learning;Convolutional neural networks;Deep denoising autoencoder","Training;Testing;Reverberation;Task analysis;Speech enhancement;Convolution","delays;learning (artificial intelligence);neural nets;reverberation;speech processing","sound reflections;time-delay effects;reverberation property;anechoic speech signals;IDEA;online phase;offline phase;deep-neural-network-based dereverberation model;fusion function;integrated deep learning ensemble learning algorithm","","6","","34","","13 Sep 2018","","","IEEE","IEEE Conferences"
"A robust diarization system for measuring dominance in Peer-Led Team Learning groups","H. Dubey; A. Sangwan; J. H. L. Hansen","Center for Robust Speech Systems, The University of Texas at Dallas, Richardson, TX, USA; Center for Robust Speech Systems, The University of Texas at Dallas, Richardson, TX, USA; University of Texas at Dallas, Richardson, TX, US","2016 IEEE Spoken Language Technology Workshop (SLT)","9 Feb 2017","2016","","","319","323","Peer-Led Team Learning (PLTL) is a structured learning model where a team leader is appointed to facilitate collaborative problem solving among students for Science, Technology, Engineering and Mathematics (STEM) courses. This paper presents an informed HMM-based speaker diarization system. The minimum duration of short conversational-turns and number of participating students were fed as side information to the HMM system. A modified form of Bayesian Information Criterion (BIC) was used for iterative merging and re-segmentation. Finally, we used the diarization output to compute a novel dominance score based on unsupervised acoustic analysis.","","978-1-5090-4903-5","10.1109/SLT.2016.7846283","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7846283","Bottleneck features;Denoising Autoencoders;Dominance Score;Peer-Led Team Learning;Robust Speaker Diarization","Hidden Markov models;Speech;Merging;Feature extraction;Mel frequency cepstral coefficient;Noise reduction;Splicing","Bayes methods;educational courses;hidden Markov models;speaker recognition;STEM","robust diarization system;dominance measurement;peer-led team learning groups;PLTL;structured learning model;team leader;collaborative problem solving;science-technology-engineering-and-mathematics courses;STEM courses;HMM-based speaker diarization system;minimum duration short-conversational-turns;Bayesian information criterion;BIC;iterative merging;re-segmentation;dominance score;unsupervised acoustic analysis","","5","","21","","9 Feb 2017","","","IEEE","IEEE Conferences"
"Separation matrix optimization using associative memory model for blind source separation","M. Omachi; T. Ogawa; T. Kobayashi; M. Fujieda; K. Katagiri","Department of the computer science, Waseda University, Japan; Department of the computer science, Waseda University, Japan; Department of the computer science, Waseda University, Japan; Oki Electric Industry Co., Ltd., Japan; Oki Electric Industry Co., Ltd., Japan","2015 23rd European Signal Processing Conference (EUSIPCO)","28 Dec 2015","2015","","","1098","1102","A source signal is estimated using an associative memory model (AMM) and used for separation matrix optimization in linear blind source separation (BSS) to yield high quality and less distorted speech. Linear-filtering-based BSS, such as independent vector analysis (IVA), has been shown to be effective in sound source separation while avoiding non-linear signal distortion. This technique, however, requires several assumptions of sound sources being independent and generated from non-Gaussian distribution. We propose a method for estimating a linear separation matrix without any assumptions about the sources by repeating the following two steps: estimating non-distorted reference signals by using an AMM and optimizing the separation matrix to minimize an error between the estimated signal and reference signal. Experimental comparisons carried out in simultaneous speech separation suggest that the proposed method can reduce the residual distortion caused by IVA.","2076-1465","978-0-9928-6263-3","10.1109/EUSIPCO.2015.7362553","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7362553","convolutional neural network;denoising autoencoder associative memory model linear filtering blind","Distortion;Speech;Optimization;Yttrium;Convolution;Training;Blind source separation","blind source separation;filtering theory;matrix algebra;optimisation;speech processing;vectors","linear blind source separation;separation matrix optimization;associative memory model;source signal;high quality speech;less distorted speech;linear-filtering-based BSS;independent vector analysis;IVA;sound source separation;nonGaussian distribution;linear separation matrix;nondistorted reference signals;estimated signal","","1","","14","","28 Dec 2015","","","IEEE","IEEE Conferences"
"Analysis of Deep Neural Network Architectures and Similarity Metrics for Low-Dose CT Reconstruction","J. Brusokas; L. Petkevičius","Institute of Computer Science, Vilnius University, Vilnius, Lithuania; Institute of Computer Science, Vilnius University, Vilnius, Lithuania","2020 IEEE Open Conference of Electrical, Electronic and Information Sciences (eStream)","5 Jun 2020","2020","","","1","6","Computed tomography (CT) is a widely used imaging technique in the medical field. During CT procedures patients are exposed to high amounts of radiation, posing a tangible threat to their health. Developed low-dose procedures lower exposure but produce noise and artifacts in images. To improve diagnostic accuracy, deep learning techniques are proposed to remove noises and artifacts from low-dose images. In this paper, the performance of several neural network architectures and similarity metrics as loss functions for low-dose CT image reconstruction are analyzed. Experimental results showed that selection of loss function can have significant impact on model performance, with the GSSIM metric outperforming other contemporary metrics SSIM, MSSSIM and MSE. Experiments were conducted using open-access and local cancer research institution data.","","978-1-7281-9779-1","10.1109/eStream50540.2020.9108883","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9108883","Low-dose CT reconstruction;Medical image reconstruction;U-Net;U-Net++;Denoising;Deep learning;Autoencoders","Measurement;Deep learning;Computed tomography;Conferences;Neural networks;Computer architecture;Image reconstruction","cancer;computerised tomography;image reconstruction;learning (artificial intelligence);medical image processing;neural nets","loss function;low-dose CT image reconstruction;deep neural network architectures;similarity metrics;low-dose CT reconstruction;computed tomography;imaging technique;medical field;CT procedures patients;low-dose procedures lower exposure;deep learning techniques;low-dose images","","1","","43","","5 Jun 2020","","","IEEE","IEEE Conferences"
"Prediction of Multiple Molten Iron Quality Indices in the Blast Furnace Ironmaking Process Based on Attention-Wise Deep Transfer Network","K. Jiang; Z. Jiang; Y. Xie; D. Pan; W. Gui","School of Automation, Central South University, Changsha, China; Peng Cheng Laboratory, Shenzhen, China; School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China","IEEE Transactions on Instrumentation and Measurement","4 Jul 2022","2022","71","","1","14","Molten iron quality (MIQ) indices prediction based on data-driven models is an important way to monitor product quality and smelting status in the blast furnace ironmaking process. However, some challenges still place in the MIQ prediction: 1) limited nonlinear and dynamic description capabilities and interpretability of data-driven models; 2) high demand on the number of the labeled samples; and 3) insufficient exploration of the underlying relationship between MIQ indices. In this case, we propose a novel data-driven deep model for the online prediction of MIQ indices. First, we design an attention-wise module to self-learn the nonlinear and dynamic relationship between process variables and prediction targets and enhance interpretability. Then, the minute-level molten iron temperature (MIT) data detected by our previously developed equipment is used to pretrain the attention-wise deep network to obtain the improved weights and reduce dependence on labeled samples. Finally, the pretrained model is extended to a structure with a weight-shared attention-wise module and task-separated prediction networks to explore the relationship between multiple prediction tasks. The effectiveness of the proposed attention-wise deep network is verified in an industrial ironmaking plant, which shows a significant improvement in performance, i.e., high accuracy and interpretability.","1557-9662","","10.1109/TIM.2022.3185325","National Major Scientific Research Equipment of China(grant numbers:61927803); National Science Foundation for Distinguished Young Scholars of China(grant numbers:61725306); Science and Technology Innovation Program of Hunan Province(grant numbers:2021RC4054); Fundamental Research Funds for the Central Universities of Central South University(grant numbers:2021zzts0183); Hunan Provincial Innovation Foundation for Postgraduate(grant numbers:CX20210242); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9803273","Attention-wise deep network;blast furnace (BF);denoising autoencoder (DAE);molten iron quality (MIQ);multitask transfer learning;prediction","Predictive models;Silicon;Iron;Task analysis;Smelting;Heuristic algorithms;Computational modeling","blast furnaces;industrial plants;iron;learning (artificial intelligence);metallurgical industries;smelting;steel industry","multiple molten iron quality indices;blast furnace ironmaking process;attention-wise deep transfer network;molten iron quality indices prediction;data-driven models;product quality;smelting status;MIQ prediction;dynamic description capabilities;labeled samples;underlying relationship;MIQ indices;novel data-driven deep model;online prediction;dynamic relationship;process variables;prediction targets;minute-level molten iron temperature data;attention-wise deep network;pretrained model;weight-shared attention-wise module;task-separated prediction networks;multiple prediction tasks;industrial ironmaking plant","","","","40","IEEE","22 Jun 2022","","","IEEE","IEEE Journals"
"A Sample-Efficient OPF Learning Method Based on Annealing Knowledge Distillation","Z. Dong; K. Hou; Z. Liu; X. Yu; H. Jia; C. Zhang","Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Extra-High Voltage Branch Company, Nanjing, China","IEEE Access","27 Sep 2022","2022","10","","99724","99733","To quickly respond to variations in the state of network load demand, a solution using data-driven techniques to predict optimal power flow (OPF) has emerged in recent years. However, most of the existing methods are highly dependent on large data volumes. This limits their application on the newly established or expanded systems. In this regard, this work proposes a sample-efficient OPF learning method to maximize the utilization of limited samples. By decomposing the OPF task before knowledge distillation, deep learning complexity is reduced. Thereafter, knowledge distillation is used to integrate decoupled tasks and improve accuracy in low-data setups. Unsupervised pre-training is introduced to alleviate the demand for labeled data. Additionally, the focal loss function and teacher annealing strategy are adopted to achieve higher accuracy without extra samples. Numerical tests on different systems corroborate the advanced accuracy and training speed over other training methods, especially on fewer-sample occasions.","2169-3536","","10.1109/ACCESS.2022.3207146","National Natural Science Foundation of China(grant numbers:52077150/U2066213); Natural Science Foundation of Tianjin City, China(grant numbers:19JCYBJC19200); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9893817","Optimal power flow;sample efficiency;annealing knowledge distillation;focal loss function;stacked denoising autoencoder;deep learning","Encoding;Knowledge engineering;Load modeling;Deep learning;Data models;Power generation;Annealing;Noise reduction;Optimal control;Annealing","computational complexity;data handling;deep learning (artificial intelligence);knowledge based systems;load flow;power engineering computing","sample-efficient OPF;annealing knowledge distillation;network load demand;data-driven techniques;optimal power flow;data volumes;newly established expanded systems;OPF task;low-data setups;focal loss function;teacher annealing strategy;training methods;fewer-sample occasions","","","","30","CCBY","16 Sep 2022","","","IEEE","IEEE Journals"
"An Improved Content Based Image Retrieval System using Unsupervised Deep Neural Network and Locality Sensitive Hashing","P. Balasundaram; S. Muralidharan; S. Bijoy","Department of CSE, SSN College of Engineering, Chennai, INDIA; Department of CSE, SSN College of Engineering, Chennai, INDIA; Department of CSE, SSN College of Engineering, Chennai, INDIA","2021 5th International Conference on Computer, Communication and Signal Processing (ICCCSP)","29 Jun 2021","2021","","","1","7","Nowadays, many types of digital devices generate data in the form of text, image and video. Hence, it is essential to have a data archival system that maintains and accesses the data. In this context, Content Based Image Retrieval (CBIR) is the problem of searching for images in a large database of images. The CBIR involves feature extraction and identification of similar images. Existing works have utilized supervised deep neural networks to learn the features and used exhaustive searching technique to identify the similar images. However, since real datasets of images are unlabelled and large in size, the usage of supervised deep neural networks and exhaustive searching technique will be a time-consuming process. Thus, this paper proposes an Improved CBIR system that first utilizes an unsupervised deep learning approach to extract the features. Further, it utilizes Locality Sensitive Hashing (LSH) to reduce search space and K Nearest Neighbor (KNN) algorithm on the reduced search space to find the required number of similar images.","","978-1-6654-3277-1","10.1109/ICCCSP52374.2021.9465496","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9465496","Content based image retrieval;Denoising Autoencoder;Locality sensitive hashing;KNN algorithm","Measurement;Deep learning;Neural networks;Image retrieval;Noise reduction;Signal processing algorithms;Signal processing","content-based retrieval;deep learning (artificial intelligence);feature extraction;file organisation;image representation;image retrieval;information retrieval systems;neural nets;unsupervised learning;visual databases","unsupervised deep neural network;locality sensitive hashing;data archival system;feature extraction;supervised deep neural networks;exhaustive searching technique;unsupervised deep learning approach;improved content based image retrieval system;digital devices;improved CBIR system;image searching;image database;image identification;feature learning;LSH;search space reduction;k nearest neighbor algorithm;KNN algorithm","","","","15","","29 Jun 2021","","","IEEE","IEEE Conferences"
"A Biochemical Fault Detection Method Based on Stack Noise Reduction Sparse Automatic Encoder","P. Wang; Z. Chu; L. Sun","Academy of Information Science and Technology, Zhengzhou normal university, Henan; Academy of Information Science and Technology, Zhengzhou normal university, Henan; Academy of Information Science and Technology, Zhengzhou normal university, Henan","2020 Chinese Control And Decision Conference (CCDC)","11 Aug 2020","2020","","","5344","5349","A method based on stack noise reduction sparse automatic coder is proposed for biochemical process fault detection. Based on SDSA, softmax classifier is introduced to build a deep neural network model, and particle swarm optimization algorithm is used to optimize the parameters of the model to improve the sensitivity of the model in fault detection. The effectiveness of the proposed method is verified by the simulation of Eastman process in Tennessee.","1948-9447","978-1-7281-5855-6","10.1109/CCDC49329.2020.9164763","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9164763","Deep Neural Network;Stacked Denoising Sparse Autoencoder;Fault Detection","Fault detection;Training;Noise reduction;Biological system modeling;Support vector machines;Encoding;Classification algorithms","biochemistry;chemical industry;fault diagnosis;neural nets;particle swarm optimisation;pattern classification;production engineering computing","biochemical fault detection method;stack noise reduction sparse automatic encoder;stack noise reduction sparse automatic coder;biochemical process fault detection;softmax classifier;deep neural network model;particle swarm optimization algorithm;Eastman process","","","","11","","11 Aug 2020","","","IEEE","IEEE Conferences"
"A Lightweight sequence-based Unsupervised Loop Closure Detection","F. Xiong; Y. Ding; M. Yu; W. Zhao; N. Zheng; P. Ren","College of Artificial Intelligence, Xi'an Jiaotong University, Xi'an, China; College of Artificial Intelligence, Xi'an Jiaotong University, Xi'an, China; College of Artificial Intelligence, Xi'an Jiaotong University, Xi'an, China; College of Artificial Intelligence, Xi'an Jiaotong University, Xi'an, China; College of Artificial Intelligence, Xi'an Jiaotong University, Xi'an, China; College of Artificial Intelligence, Xi'an Jiaotong University, Xi'an, China","2021 International Joint Conference on Neural Networks (IJCNN)","22 Sep 2021","2021","","","1","8","Stable, effective and lightweight loop closure detection is an always pursued goal in real-time SLAM systems, that can be ported on embedded processors and deployed on autonomous robotics. Deep learning methods have extended the expressive ability and adaptability of the descriptor, and sequence-based methods can greatly improve the matching accuracy. However, the increased computation complexity and storage bandwidth requirements of matching calculations for high-dimensional descriptor make it infeasible for real-time deployment, especially for robots that navigate in relatively big maps. To address this challenge, we propose a lightweight sequence-based unsupervised loop closure detection scheme. To be specific, Principal Component Analysis (PCA) is applied to squeeze the descriptor dimensions while maintaining sufficient expressive ability. Additionally, with the consideration of the image sequence and combining linear query with fast approximate nearest neighbor search to further reduce the execution time and improve the efficiency of sequence matching. We implement our method on CALC, a state-of-the-art unsupervised solution, and conduct experiments on NVIDIA TX2, results demonstrate that the accuracy has been improved by 5%, while the execution speed is 2× faster. Source code is available at https://github.com/Mingrui-Yu/Seq-CALC.","2161-4407","978-1-6654-3900-8","10.1109/IJCNN52387.2021.9534180","Key-Area Research and Development Program of Guangdong Province(grant numbers:2019B010153003); National Natural Science Foundation of China(grant numbers:61773307); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9534180","Simultaneous Localization and Mapping;Loop Closure Detection;PCA;Images Sequence;Denoising Autoencoder","Deep learning;Visualization;Simultaneous localization and mapping;Runtime;Program processors;Real-time systems;Liquid crystal displays","computational complexity;deep learning (artificial intelligence);embedded systems;image matching;image sequences;microprocessor chips;nearest neighbour methods;principal component analysis;search problems;SLAM (robots)","sequence matching;lightweight loop closure detection;real-time SLAM systems;embedded processors;autonomous robotics;sequence-based methods;matching accuracy;computation complexity;storage bandwidth requirements;high-dimensional descriptor;real-time deployment;lightweight sequence-based unsupervised loop closure detection scheme;image sequence;execution time","","","","39","","22 Sep 2021","","","IEEE","IEEE Conferences"
"A Deep-Learning-Based Optimal Energy Flow Method for Reliability Assessment of Integrated Energy Systems","Z. Dong; K. Hou; Z. Liu; X. Yu; H. Jia; Q. Xiao","Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China","IEEE Access","5 Sep 2022","2022","10","","91092","91102","The energy interactions and uncertain factors of integrated energy systems (IES) have brought risks to the reliable energy supply. A large number of states need to be analyzed to obtain a stable reliability value. However, different operating characteristics complicate the optimal energy flow (OEF) model, which brings tremendous computational cost. To address that, a deep-learning-based approach is proposed as an alternative way to solve the OEF problems. This approach constructs the mapping between system state and energy allocation to directly obtain the optimal load curtailment. Thereafter, the deep-learning-based reliability assessment framework for IES is proposed to improve efficiency. Additionally, the Gaussian noise and data-processing strategies are involved to achieve higher accuracy. Compared to the model-based approach, the proposed method increases the reliability assessment efficiency by 6 orders of time. With an accuracy of over 95%, it outperforms other autoencoder and random forest methods. Method accuracy has remained above 90% in various scenarios.","2169-3536","","10.1109/ACCESS.2022.3202197","National Natural Science Foundation of China(grant numbers:52077150/U2066213); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9868354","Integrated energy system;deep learning;optimal energy flow;stacked denoising auto-encoder (SDAE);reliability assessment","Reliability;Noise reduction;Decoding;Deep learning;Uncertainty;Load modeling;Encoding;Energy consumption","deep learning (artificial intelligence);demand side management;Gaussian noise;optimisation;power engineering computing;power generation reliability;random forests","optimal energy flow method;integrated energy systems;energy interactions;IES;deep-learning-based approach;energy allocation;optimal load curtailment;reliability assessment framework;model-based approach;OEF;computational cost;Gaussian noise;data-processing strategies;random forest methods;autoencoder","","","","27","CCBY","26 Aug 2022","","","IEEE","IEEE Journals"
"A Sparsity-Aware Hybrid Collaborative Recommendation Method with Multi-Source Data","H. Leng; W. Lin; Z. Pan","Hangzhou Normal University, Hangzhou, China; Hangzhou Normal University, Hangzhou, China; Hangzhou Normal University, Hangzhou, China","2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)","15 Mar 2022","2021","","","708","715","Collaborative filtering (CF) is an effective method, which is widely applied in a great deal of recommendation systems. It can extract latent user preferences and item features from user-item rating matrix, by making use of Matrix Factorization (MF)'s technique to generate recommended items. However, the traditional MF based recommendation methods are faced with sparsity problems caused by unavailable and incomplete user-item rating datasets, which greatly degrades the accuracy of recommendation results. To address the sparsity problem caused by unavailable and incomplete datasets, we propose a sparsity-aware hybrid collaborative recommendation approach with multi-source and heterogeneous data in this paper. Firstly, we adopt more abundant and accessible implicit feedback data rather than explicit user-item rating data to overcome the data unavailability issue. Moreover, to address the “Missing not at random” (MSAR) problem with implicit feedback data, we adopt auxiliary data from user profile or item content to generate more accurate user preference and item features; which will be fused into the MF model to generate accurate recommendation results. More specifically, Principal Component Analysis (PCA) and Stacked Denoising Auto Encoder (SDAE) are used as feature extractor, thereby generating user preferences and item features. Finally, we did a lot of experiments on several datasets to assess the proposed recommendation approach. The results indicate that, compared with pure matrix factorization, the hybrid collaborative recommendation model combining extra latent user/item representation can enhance the recommended results' accuracy; while the time consumption is almost the same.","","978-1-6654-2174-4","10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00118","Natural Science Foundation of Zhejiang Province(grant numbers:LQ21F020021); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9730402","Recommender systems;Collaborative Filtering;Deep learning;Autoencoder","Computational modeling;Collaborative filtering;Noise reduction;Collaboration;Big Data;Feature extraction;Data models","collaborative filtering;matrix decomposition;principal component analysis;recommender systems","multisource data;collaborative filtering;recommendation systems;latent user preferences;item features;user-item rating matrix;matrix factorization technique;recommended items;traditional MF;recommendation methods;sparsity problem;unavailable user-item rating datasets;incomplete user-item rating datasets;unavailable datasets;incomplete datasets;sparsity-aware hybrid collaborative recommendation approach;heterogeneous data;abundant feedback data;accessible implicit feedback data;user-item rating data;data unavailability issue;random problem;auxiliary data;user profile;accurate user preference;MF model;accurate recommendation results;pure matrix factorization;hybrid collaborative recommendation model;recommended results;sparsity-aware hybrid collaborative recommendation method;MSAR;missing not at random;stacked denoising auto encoder;SDAE;PCA;principal component analysis","","","","32","IEEE","15 Mar 2022","","","IEEE","IEEE Conferences"
"Automatic Scoring of Multiple Semantic Attributes With Multi-Task Feature Leverage: A Study on Pulmonary Nodules in CT Images","S. Chen; J. Qin; X. Ji; B. Lei; T. Wang; D. Ni; J. -Z. Cheng","National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Medicine, Shenzhen University, Shenzhen, China; Smart Health, School of Nursing, The Hong Kong Polytechnic University, Hung Hom, Hong Kong; National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Medicine, Shenzhen University, Shenzhen, China; National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Medicine, Shenzhen University, Shenzhen, China; National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Medicine, Shenzhen University, Shenzhen, China; National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Medicine, Shenzhen University, Shenzhen, China; National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Medicine, Shenzhen University, Shenzhen, China","IEEE Transactions on Medical Imaging","1 Mar 2017","2017","36","3","802","814","The gap between the computational and semantic features is the one of major factors that bottlenecks the computer-aided diagnosis (CAD) performance from clinical usage. To bridge this gap, we exploit three multi-task learning (MTL) schemes to leverage heterogeneous computational features derived from deep learning models of stacked denoising autoencoder (SDAE) and convolutional neural network (CNN), as well as hand-crafted Haar-like and HoG features, for the description of 9 semantic features for lung nodules in CT images. We regard that there may exist relations among the semantic features of “spiculation”, “texture”, “margin”, etc., that can be explored with the MTL. The Lung Image Database Consortium (LIDC) data is adopted in this study for the rich annotation resources. The LIDC nodules were quantitatively scored w.r.t. 9 semantic features from 12 radiologists of several institutes in U.S.A. By treating each semantic feature as an individual task, the MTL schemes select and map the heterogeneous computational features toward the radiologists' ratings with cross validation evaluation schemes on the randomly selected 2400 nodules from the LIDC dataset. The experimental results suggest that the predicted semantic scores from the three MTL schemes are closer to the radiologists' ratings than the scores from single-task LASSO and elastic net regression methods. The proposed semantic attribute scoring scheme may provide richer quantitative assessments of nodules for better support of diagnostic decision and management. Meanwhile, the capability of the automatic association of medical image contents with the clinical semantic terms by our method may also assist the development of medical search engine.","1558-254X","","10.1109/TMI.2016.2629462","National Natural Science Foundation of China(grant numbers:61402296,61571304,81571758,61501305,61427806); Shenzhen Key Basic Research Project(grant numbers:JCYJ20150525092940986,JCYJ20150525092940982,JCYJ20130329105033277,JCYJ20140509172 609164); (Key) Project of Department of Education of Guangdong Province(grant numbers:2014GKXM052); Natural Science Foundation of SZU(grant numbers:2016089); Shenzhen-Hong Kong Innovation Circle Funding Program(grant numbers:JSE201109150013A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745891","Computer-aided diagnosis (CAD);lung nodule;computed tomography (CT);multi-task learning;deep learning;feature learning","Semantics;Computed tomography;Medical diagnostic imaging;Computational modeling;Machine learning;Lungs","computerised tomography;feature extraction;lung;medical image processing;pneumodynamics;regression analysis","computer-aided diagnosis performance;multitask learning schemes;deep learning models;stacked denoising autoencoder;convolutional neural network;HoG features;lung nodules;CT images;semantic features;Lung Image Database Consortium data;heterogeneous computational features;single-task LASSO;elastic net regression methods;medical image;clinical semantic terms;medical search engine;pulmonary nodules","Algorithms;Humans;Lung Neoplasms;Machine Learning;Neural Networks (Computer);Radiographic Image Interpretation, Computer-Assisted;Solitary Pulmonary Nodule;Tomography, X-Ray Computed","94","","48","IEEE","16 Nov 2016","","","IEEE","IEEE Journals"
"Predicting Remaining Useful Life of Rolling Bearings Based on Deep Feature Representation and Transfer Learning","W. Mao; J. He; M. J. Zuo","School of Computer and Information Engineering, Henan Normal University, Xinxiang, China; School of Computer and Information Engineering, Henan Normal University, Xinxiang, China; Department of Mechanical Engineering, University of Alberta, Edmonton, Canada","IEEE Transactions on Instrumentation and Measurement","10 Mar 2020","2020","69","4","1594","1608","For the data-driven remaining useful life (RUL) prediction for rolling bearings, the traditional machine learning-based methods generally provide insufficient feature representation and adaptive extraction. Although deep learning-based RUL prediction methods can solve these problems to some extent, they still do not yield satisfactory predictive results due to less degradation data and inconsistent data distribution among different bearings. To solve these problems, a new RUL prediction method based on deep feature representation and transfer learning is proposed in this paper. This method includes an off-line stage and an online stage. In the off-line stage, the Hilbert-Huang transform marginal spectra of the raw vibration signal of auxiliary bearings are first calculated as the input, and then contractive denoising autoencoder is introduced to extract deep features with good and stable fault representation. Second, by using the obtained deep features and Pearson's correlation coefficient, a new health condition assessment method is proposed to divide the whole life of each bearing into a normal state and a fast-degradation state. Finally, using the extracted deep features and their RUL values, an RUL prediction model for the fast-degradation state is trained by means of a least-square support vector machine. In the online stage, a kind of transfer learning algorithm, i.e., transfer component analysis, is introduced to sequentially adjust the features of target bearing from auxiliary bearings, and then the corresponding RUL is predicted using the corrected features. Results using the PHM Challenging 2012 data set show a significant performance improvement when using the proposed method in terms of predictive accuracy and numerical stability.","1557-9662","","10.1109/TIM.2019.2917735","National Natural Science Foundation of China(grant numbers:U1704158); China Postdoctoral Science Foundation(grant numbers:2016T90944); Natural Sciences and Engineering Research Council of Canada(grant numbers:PGPIN-2015-04897); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8718405","Correlation coefficient;deep learning (DL);remaining useful life (RUL) prediction;transfer component analysis (TCA);transfer learning","Feature extraction;Degradation;Predictive models;Prognostics and health management;Deep learning;Support vector machines;Prediction algorithms","condition monitoring;fault diagnosis;feature extraction;Hilbert transforms;learning (artificial intelligence);least squares approximations;remaining life assessment;rolling bearings;support vector machines;vibrational signal processing;vibrations","rolling bearings;useful life prediction;machine learning-based methods;adaptive extraction;inconsistent data distribution;stable fault representation;health condition assessment method;transfer learning algorithm;deep learning-based remaining useful life prediction;Hilbert-Huang transform marginal spectra;auxiliary bearings vibration signal;contractive denoising autoencoder;Pearson's correlation coefficient;least-square support vector machine;numerical stability","","89","","50","IEEE","20 May 2019","","","IEEE","IEEE Journals"
"Forecasting the High Penetration of Wind Power on Multiple Scales Using Multi-to-Multi Mapping","J. Yan; H. Zhang; Y. Liu; S. Han; L. Li; Z. Lu","State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, School of Renewable Energy, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, School of Renewable Energy, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, School of Renewable Energy, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, School of Renewable Energy, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, School of Renewable Energy, North China Electric Power University, Beijing, China; Department of Electrical Engineering, Tsinghua University, Beijing, China","IEEE Transactions on Power Systems","17 Apr 2018","2018","33","3","3276","3284","Highly wind penetrated future power system will couple to the variabilities and nonlinear correlations of wind. Reliable wind power forecasting (WPF) for a region is critical to the security and economics of the power system operation. Therefore, this paper proposes a multiscale WPF method by establishing a multi-to-multi (m2m) mapping network and the use of stacked denoising autoencoder (SDAE). The concerned forecast time horizon is 24-72 hours. First, multi-NWPs in a region are corrected based on SDAE to generate better inputs for the following regional WPF. Second, a number of SDAEs with diverse model parameters and input features are integrated into ensemble SDAE for predicting the wind power generated from various wind farms in a region. Two sets of data are utilized in this case study to validate the proposed method. The results show that the proposed m2m mapping and SDAE are able to capture the real correlations of wind at multiple sites, and outperform the other counterparts in terms of multi-NWPs correction as well as the WPF for both the region and individual concerned wind farm. Moreover, the ensemble SDAE performs better than any other individual regional WPF model.","1558-0679","","10.1109/TPWRS.2017.2787667","National Key Research and Development Program of China: Fundamental Theory of Planning and Operation for Power Systems with High Share of Renewable Energy Generations(grant numbers:2016YFB0900100); State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources(grant numbers:LAPS17014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240639","Multi-scale forecasting;regional forecasting;wind power forecasting;high penetration;deep learning;multiple NWP","Wind farms;Correlation;Wind speed;Wind forecasting;Forecasting;Wind power generation","load forecasting;neural nets;power engineering computing;power generation reliability;wind power;wind power plants","stacked denoising autoencoder;concerned forecast time horizon;ensemble SDAE;wind farms;individual concerned wind farm;individual regional WPF model;future power system;reliable wind power forecasting;power system operation;multiscale WPF method;multi-to-multimapping network;wind penetrated future power system;regional WPF;multiNWP correction","","75","","26","IEEE","27 Dec 2017","","","IEEE","IEEE Journals"
"Tactile object recognition using deep learning and dropout","A. Schmitz; Y. Bansho; K. Noda; H. Iwata; T. Ogata; S. Sugano","Sugano Lab, Waseda University, Tokyo, Japan; Sugano Lab, Waseda University, Tokyo, Japan; Graduate School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Department of Modern Mechanical Engineering, Waseda University; Graduate School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Department of Modern Mechanical Engineering, Waseda University, Tokyo, Japan","2014 IEEE-RAS International Conference on Humanoid Robots","16 Feb 2015","2014","","","1044","1050","Recognizing grasped objects with tactile sensors is beneficial in many situations, as other sensor information like vision is not always reliable. In this paper, we aim for multimodal object recognition by power grasping of objects with an unknown orientation and position relation to the hand. Few robots have the necessary tactile sensors to reliably recognize objects: in this study the multifingered hand of TWENDY-ONE is used, which has distributed skin sensors covering most of the hand, 6 axis F/T sensors in each fingertip, and provides information about the joint angles. Moreover, the hand is compliant. When using tactile sensors, it is not clear what kinds of features are useful for object recognition. Recently, deep learning has shown promising results. Nevertheless, deep learning has rarely been used in robotics and to our best knowledge never for tactile sensing, probably because it is difficult to gather many samples with tactile sensors. Our results show a clear improvement when using a denoising autoencoder with dropout compared to traditional neural networks. Nevertheless, a higher number of layers did not prove to be beneficial.","2164-0580","978-1-4799-7174-9","10.1109/HUMANOIDS.2014.7041493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7041493","","Object recognition;Principal component analysis;Tactile sensors;Training;Skin","control engineering computing;dexterous manipulators;distributed sensors;learning (artificial intelligence);object recognition;tactile sensors","tactile object recognition;dropout;grasped objects recognition;tactile sensors;multimodal object recognition;power grasping;unknown orientation;position relation;multifingered hand;TWENDY-ONE;distributed skin sensors;F/T sensors;joint angles;deep learning;denoising autoencoder","","56","","36","","16 Feb 2015","","","IEEE","IEEE Conferences"
"Autoencoding Evolutionary Search With Learning Across Heterogeneous Problems","L. Feng; Y. -S. Ong; S. Jiang; A. Gupta","College of Computer Science, Chongqing University, Chongqing, China; School of Computer Engineering, Nanyang Technological University, Singapore; Singapore Institute of Manufacturing Technology, Singapore; School of Computer Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Evolutionary Computation","29 Sep 2017","2017","21","5","760","772","To enhance the search performance of evolutionary algorithms, reusing knowledge captured from past optimization experiences along the search process has been proposed in the literature, and demonstrated much promise. In the literature, there are generally three types of approaches for reusing knowledge from past search experiences, namely exact storage and reuse of past solutions, the reuse of model-based information, and the reuse of structured knowledge captured from past optimized solutions. In this paper, we focus on the third type of knowledge reuse for enhancing evolutionary search. In contrast to existing works, here we focus on knowledge transfer across heterogeneous continuous optimization problems with diverse properties, such as problem dimension, number of objectives, etc., that cannot be handled by existing approaches. In particular, we propose a novel autoencoding evolutionary search paradigm with learning capability across heterogeneous problems. The essential ingredient for learning structured knowledge from search experience in our proposed paradigm is a single layer denoising autoencoder (DA), which is able to build the connections between problem domains by treating past optimized solutions as the corrupted version of the solutions for the newly encountered problem. Further, as the derived DA holds a closed-form solution, the corresponding reusing of knowledge from past search experiences will not bring much additional computational burden on the evolutionary search. To evaluate the proposed search paradigm, comprehensive empirical studies on the complex multiobjective optimization problems are presented, along with a real-world case study from the fiber-reinforced polymer composites manufacturing industry.","1941-0026","","10.1109/TEVC.2017.2682274","National Natural Science Foundation of China(grant numbers:61603064); Data Science and Artificial Intelligence Center at the Nanyang Technological University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7879282","Evolutionary optimization;knowledge transfer;learning;memetic computation","Search problems;Optimization;Memetics;Noise reduction;Problem-solving;Routing;Evolutionary computation","evolutionary computation;fibre reinforced plastics;learning (artificial intelligence);optimisation;plastics industry;production engineering computing;search problems","heterogeneous problems;search performance;evolutionary algorithms;search process;search experience;structured knowledge;optimized solutions;knowledge reuse;knowledge transfer;heterogeneous continuous optimization problems;problem dimension;single layer denoising autoencoder;problem domains;newly encountered problem;closed-form solution;complex multiobjective optimization problems;autoencoding evolutionary search paradigm;fiber-reinforced polymer composites manufacturing industry;learning capability;DA","","52","","50","OAPA","15 Mar 2017","","","IEEE","IEEE Journals"
"Sparseness Analysis in the Pretraining of Deep Neural Networks","J. Li; T. Zhang; W. Luo; J. Yang; X. -T. Yuan; J. Zhang","School of Computer Science and Technology, Nanjing University of Science and Technology, Nanjing, China; Department of Statistics, Rutgers University, Piscataway, NJ, USA; College of Mathematics and Informatics, South China Agricultural University, Guangzhou, China; School of Computer Science and Technology, Nanjing University of Science and Technology, Nanjing, China; School of Information and Control, Nanjing University of Information Science and Technology, Nanjing, China; Department of Computer Engineering, Huaihai Institute of Technology, Lianyungang, China","IEEE Transactions on Neural Networks and Learning Systems","20 May 2017","2017","28","6","1425","1438","A major progress in deep multilayer neural networks (DNNs) is the invention of various unsupervised pretraining methods to initialize network parameters which lead to good prediction accuracy. This paper presents the sparseness analysis on the hidden unit in the pretraining process. In particular, we use the  $L_{1}$ -norm to measure sparseness and provide some sufficient conditions for that pretraining leads to sparseness with respect to the popular pretraining models—such as denoising autoencoders (DAEs) and restricted Boltzmann machines (RBMs). Our experimental results demonstrate that when the sufficient conditions are satisfied, the pretraining models lead to sparseness. Our experiments also reveal that when using the sigmoid activation functions, pretraining plays an important sparseness role in DNNs with sigmoid (Dsigm), and when using the rectifier linear unit (ReLU) activation functions, pretraining becomes less effective for DNNs with ReLU (Drelu). Luckily, Drelu can reach a higher recognition accuracy than DNNs with pretraining (DAEs and RBMs), as it can capture the main benefit (such as sparseness-encouraging) of pretraining in Dsigm. However, ReLU is not adapted to the different firing rates in biological neurons, because the firing rate actually changes along with the varying membrane resistances. To address this problem, we further propose a family of rectifier piecewise linear units (RePLUs) to fit the different firing rates. The experimental results show that the performance of RePLU is better than ReLU, and is comparable with those with some pretraining techniques, such as RBMs and DAEs.","2162-2388","","10.1109/TNNLS.2016.2541681","National Science Fund for Distinguished Young Scholars(grant numbers:61125305,91420201,61472187,61233011,6137306,61373063); Program for Changjiang Scholars and Innovative Research Team in University(grant numbers:IRT13072); Key Project of Chinese Ministry of Education(grant numbers:313030); 973 Program(grant numbers:2014CB349303); Fundamental Research Funds for the Central Universities(grant numbers:30920140121005); Natural Science Foundation of Jiangsu Province of China(grant numbers:BK20141003); National Natural Science Foundation of China(grant numbers:61402232,61522308); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7445251","Activation function;deep neural networks;infomax principle;sparseness;unsupervised pretraining","Biological neural networks;Neurons;Training;Biomembranes;Learning systems;Signal processing algorithms","Boltzmann machines;learning (artificial intelligence)","sparseness analysis;deep multilayer neural networks;DNN;unsupervised pretraining methods;pretraining models;denoising autoencoders;DAE;restricted Boltzmann machines;RBM;sigmoid activation functions;sparseness role;rectifier linear unit;ReLU activation functions;Dsigm;firing rates;biological neurons;membrane resistances;rectifier piecewise linear units;RePLU","","43","","52","IEEE","31 Mar 2016","","","IEEE","IEEE Journals"
"Affective states classification using EEG and semi-supervised deep learning approaches","H. Xu; K. N. Plataniotis","The Edward S. Rogers Sr. Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON, CANADA; The Edward S. Rogers Sr. Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON, CANADA","2016 IEEE 18th International Workshop on Multimedia Signal Processing (MMSP)","16 Jan 2017","2016","","","1","6","Affective states of a user provide important information for many applications such as, personalized information (e.g., multimedia content) retrieval/delivery or intelligent human-computer interface design. In recently years, physiological signals, Electroencephalogram (EEG) in particular, have been shown to be very effective in estimating a user's affective states during social interaction or under video or audio stimuli. However, due to the large number of parameters associated with the neural expression of emotion, there is still a lot of unknowns on the specific spatial and spectral correlation of the EEG signal and the affective states expression. To investigate on such correlation, two types of semi-supervised deep learning approaches, stacked denoising autoencoder (SDAE) and deep belief networks (DBN), were applied as application specific feature extractors for the affective states classification problem using EEG signals. To evaluate the efficacy of the proposed semi-supervised approaches, a subject-specific affective states classification experiment were carried out on the DEAP database to classify 2-dimensional affect states. The DBN based model achieved averaged F1 scores of 86.67%, 86.60% and 86.69% for arousal, valence and liking states classification respectively, which has significantly improved the state-of-art classification performance. By examining the weight vectors at each layer, we were also able to gain insights on the spatial or spectral locations of the most discriminating features. Another main advantage of applying the semi-supervised learning methods is that only a small fraction of labeled data, e.g., 1/6 of the training samples, were used in this study.","2473-3628","978-1-5090-3724-7","10.1109/MMSP.2016.7813351","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7813351","","Electroencephalography;Feature extraction;Multimedia communication;Streaming media;Noise reduction;Brain modeling;Training","electroencephalography;emotion recognition;feature extraction;human computer interaction;learning (artificial intelligence);medical signal processing;signal classification;spectral analysis","affective user state classification;semisupervised deep learning;physiological signals;electroencephalogram;social interaction;neural emotion expression;spectral correlation;spatial correlation;stacked denoising autoencoder;SDAE;deep belief networks;application specific feature extractors;state classification;EEG signal;DEAP database;DBN based model","","34","","17","","16 Jan 2017","","","IEEE","IEEE Conferences"
"Asymmetric Adaptation of Deep Features for Cross-Domain Classification in Remote Sensing Imagery","N. Ammour; L. Bashmal; Y. Bazi; M. M. Al Rahhal; M. Zuair","Computer Engineering Department, King Saud University, Riyadh, Saudi Arabia; Computer Engineering Department, King Saud University, Riyadh, Saudi Arabia; Computer Engineering Department, King Saud University, Riyadh, Saudi Arabia; Information Science Department, King Saud University, Riyadh, Saudi Arabia; Computer Engineering Department, King Saud University, Riyadh, Saudi Arabia","IEEE Geoscience and Remote Sensing Letters","23 Mar 2018","2018","15","4","597","601","In this letter, we introduce an asymmetric adaptation neural network (AANN) method for cross-domain classification in remote sensing images. Before the adaptation process, we feed the features obtained from a pretrained convolutional neural network to a denoising autoencoder (DAE) to perform dimensionality reduction. Then the first hidden layer of AANN (placed on the top of DAE) maps the labeled source data to the target space, while the subsequent layers control the separation between the available land-cover classes. To learn its weights, the network minimizes an objective function composed of two losses related to the distance between the source and target data distributions and class separation. The results of experiments conducted on six scenarios built from three benchmark scene remote sensing data sets (i.e., Merced, KSA, and AID data sets) are reported and discussed.","1558-0571","","10.1109/LGRS.2018.2800642","Deanship of Scientific Research at King Saud University through the Local Research Group Program(grant numbers:RG-1435-055); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291513","Asymmetric adaptation neural network (AANN);cross-domain classification;deep features","Feature extraction;Neural networks;Training;Niobium;Feeds;Remote sensing;Linear programming","feedforward neural nets;geophysical image processing;image classification;image coding;learning (artificial intelligence);remote sensing","DAE;dimensionality reduction;hidden layer;AANN;labeled source data;target space;class separation;benchmark scene remote sensing data sets;deep features;cross-domain classification;remote sensing imagery;asymmetric adaptation neural network method;remote sensing images;pretrained convolutional neural network;denoising autoencoder;land-cover classes;objective function;source data distribution;target data distribution;Merced data set;KSA data set;AID data set","","34","","14","IEEE","14 Feb 2018","","","IEEE","IEEE Journals"
"Advanced Image Classification Using Wavelets and Convolutional Neural Networks","T. Williams; R. Li","Department of Electrical & Computer Engineering, North Carolina A&T State University, Greensboro, NC, USA; Department of Electrical & Computer Engineering, North Carolina A&T State University, Greensboro, NC, USA","2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)","2 Feb 2017","2016","","","233","239","Image classification is a vital technology many people in all arenas of human life utilize. It is pervasive in every facet of the social, economic, and corporate spheres of influence, worldwide. This need for more accurate, detail-oriented classification increases the need for modifications, adaptations, and innovations to Deep learning algorithms. This paper uses Convolutional Neural Networks (CNN) to classify handwritten digits in the MNIST database, and scenes in the CIFAR-10 database. Our proposed method preprocesses the data in the wavelet domain to attain greater accuracy and comparable efficiency to the spatial domain processing. By separating the image into different subbands, important feature learning occurs over varying low to high frequencies. The fusion of the learned low and high frequency features, and processing the combined feature mapping results in an increase in the detection accuracy. Comparing the proposed methods to spatial domain CNN and Stacked Denoising Autoencoder (SDA), experimental findings reveal a substantial increase in accuracy.","","978-1-5090-6167-9","10.1109/ICMLA.2016.0046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7838150","CNN;SDA;Neural Network;Deep Learning;Wavelet;Classification;Fusion;Machine Learning;Object Recognition","Neurons;Discrete wavelet transforms;Machine learning;Biological neural networks;Image classification","image classification;learning (artificial intelligence);wavelet neural nets","image classification;wavelets;convolutional neural networks;detail-oriented classification;deep learning algorithms;MNIST database;CIFAR-10 database;wavelet domain;spatial domain processing;high frequency features;spatial domain CNN;stacked denoising autoencoder;SDA","","31","","28","","2 Feb 2017","","","IEEE","IEEE Conferences"
"Regularized Deep Learning for Face Recognition With Weight Variations","S. Nagpal; M. Singh; R. Singh; M. Vatsa","Indraprastha Institute of Information Technology Delhi, New Delhi, India; Indraprastha Institute of Information Technology Delhi, New Delhi, India; Indraprastha Institute of Information Technology Delhi, New Delhi, India; Indraprastha Institute of Information Technology Delhi, New Delhi, India","IEEE Access","20 May 2017","2015","3","","3010","3018","Body weight variations are an integral part of a person's aging process. However, the lack of association between the age and the weight of an individual makes it challenging to model these variations for automatic face recognition. In this paper, we propose a regularizer-based approach to learn weight invariant facial representations using two different deep learning architectures, namely, sparse-stacked denoising autoencoders and deep Boltzmann machines. We incorporate a body-weight aware regularization parameter in the loss function of these architectures to help learn weight-aware features. The experiments performed on the extended WIT database show that the introduction of weight aware regularization improves the identification accuracy of the architectures both with and without dropout.","2169-3536","","10.1109/ACCESS.2015.2510865","Department of Electronics and Information Technology, Government of India; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7361971","Face recognition;biometrics;body-weight variations;facial aging","Machine learning;Face recognition;Deep learning;Training data;Noise reduction","face recognition;feature extraction;learning (artificial intelligence)","regularized deep learning;body weight variations;person aging process;automatic face recognition;regularizer-based approach;learn weight invariant facial representations;deep learning architectures;sparse-stacked denoising autoencoders;deep Boltzmann machines;body-weight aware regularization parameter;weight-aware feature learning;extended WIT database","","23","","22","OAPA","22 Dec 2015","","","IEEE","IEEE Journals"
"Predicting Transportation Carbon Emission with Urban Big Data","X. Lu; K. Ota; M. Dong; C. Yu; H. Jin","Department of Information and Electronic Engineering, Muroran Institute of Technology, Muroran, Hokkaido, Japan; Department of Information and Electronic Engineering, Muroran Institute of Technology, Muroran, Hokkaido, Japan; Department of Information and Electronic Engineering, Muroran Institute of Technology, Muroran, Hokkaido, Japan; Services Computing Technology and System Lab, Huazhong University of Science and Technology, Wuhan, China; Services Computing Technology and System Lab, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Sustainable Computing","8 Dec 2017","2017","2","4","333","344","Transportation carbon emission is a significant contributor to the increase of greenhouse gases, which directly threatens the change of climate and human health. Under the pressure of the environment, it is very important to master the information of transportation carbon emission in real time. In the traditional way, we get the information of the transportation carbon emission by calculating the combustion of fossil fuel in the transportation sector. However, it is very difficult to obtain the real-time and accurate fossil fuel combustion in the transportation field. In this paper, we predict the real-time and fine-grained transportation carbon emission information in the whole city, based on the spatio-temporal datasets we observed in the city, that is taxi GPS data, transportation carbon emission data, road networks, points of interests (POIs), and meteorological data. We propose a three-layer perceptron neural network (3-layerPNN) to learn the characteristics of collected data and infer the transportation carbon emission. We evaluate our method with extensive experiments based on five real data sources obtained in Zhuhai, China. The results show that our method has advantages over the well-known three machine learning methods (Gaussian Naive Bayes, Linear Regression, and Logistic Regression) and two deep learning methods (Stacked Denoising Autoencoder and Deep Belief Networks).","2377-3782","","10.1109/TSUSC.2017.2728805","NSFC(grant numbers:61472149); Fundamental Research Funds; Central Universities(grant numbers:2015QN67); National 863 Hi-Tech Research; JSPS KAKENHI(grant numbers:JP16K00117,JP15K15976); KDDI Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7984819","Transportation carbon emission;urban big data;multilayer perceptron neural network;real-time prediction","Carbon dioxide;Urban areas;Smart cities;Real-time systems;Neural networks;Fuels","air pollution;Bayes methods;belief networks;Big Data;combustion;environmental science computing;fossil fuels;learning (artificial intelligence);multilayer perceptrons;regression analysis;transportation","deep learning methods;stacked denoising autoencoder;deep belief networks;logistic regression;linear regression;Gaussian Naive Bayes;machine learning methods;China;Zhuhai;3-layer PNN;three-layer perceptron neural network;meteorological data;POI;points of interests;road networks;taxi GPS data;spatio-temporal datasets;fossil fuel combustion;human health;climate change;greenhouse gases;Urban Big Data;transportation carbon emission prediction;transportation carbon emission data;fine-grained transportation carbon emission information;transportation field;transportation sector","","22","","29","IEEE","19 Jul 2017","","","IEEE","IEEE Journals"
"RF-based Direction Finding of UAVs Using DNN","S. Abeywickrama; L. Jayasinghe; H. Fu; S. Nissanka; C. Yuen","National University of Singapore, Singapore; Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore","2018 IEEE International Conference on Communication Systems (ICCS)","14 Apr 2019","2018","","","157","161","This paper presents a sparse denoising autoencoder (SDAE)-based deep neural network (DNN) for the direction finding (DF) of small unmanned aerial vehicles (UAVs). It is motivated by the practical challenges associated with classical DF algorithms such as MUSIC and ESPRIT. The proposed DF scheme is practical and low-complex in the sense that a phase synchronization mechanism, an antenna calibration mechanism, and the analytical model of the antenna radiation pattern are not essential. Also, the proposed DF method can be implemented using a single-channel RF receiver. The paper validates the proposed method experimentally as well.","","978-1-5386-7864-0","10.1109/ICCS.2018.8689177","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8689177","Drone surveillance;direction finding;UAV tracking","","antenna radiation patterns;autonomous aerial vehicles;neural nets;radio direction-finding;radio receivers","single-channel RF receiver;RF-based direction finding;DNN;SDAE;unmanned aerial vehicles;phase synchronization mechanism;antenna calibration mechanism;antenna radiation pattern;UAV;sparse denoising autoencoder;deep neural network;MUSIC;ESPRIT","","19","","24","","14 Apr 2019","","","IEEE","IEEE Conferences"
"Hierarchically Learned View-Invariant Representations for Cross-View Action Recognition","Y. Liu; Z. Lu; J. Li; T. Yang","School of Telecommunications Engineering, Xidian University, Xi’an, China; School of Telecommunications Engineering, Xidian University, Xi’an, China; School of Telecommunications Engineering, Xidian University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China","IEEE Transactions on Circuits and Systems for Video Technology","5 Aug 2019","2019","29","8","2416","2430","Recognizing human actions from varied views is challenging due to huge appearance variations in different views. The key to this problem is to learn discriminant view-invariant representations generalizing well across views. In this paper, we address this problem by learning view-invariant representations hierarchically using a novel method, referred to as joint sparse representation and distribution adaptation. To obtain robust and informative feature representations, we first incorporate a sample-affinity matrix into the marginalized Stacked Denoising Autoencoder to obtain shared features that are then combined with the private features. In order to make the feature representations of videos across views transferable, we then learn a transferable dictionary pair simultaneously from pairs of videos taken at different views to encourage each action video across views to have the same sparse representation. However, the distribution difference across views still exists because a unified subspace, where the sparse representations of one action across views are the same, may not exist when the view difference is large. Therefore, we propose a novel unsupervised distribution adaptation method that learns a set of projections that project the source and target views data into respective low-dimensional subspaces, where the marginal and conditional distribution differences are reduced simultaneously. Therefore, the finally learned feature representation is view-invariant and robust for substantial distribution difference across views even though the view difference is large. Experimental results on four multi-view datasets show that our approach outperforms the state-of-the-art approaches.","1558-2205","","10.1109/TCSVT.2018.2868123","National Natural Science Foundation of China(grant numbers:61502364,61672429); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453034","Action recognition;cross-view;dictionary learning;distribution adaptation","Videos;Dictionaries;Robustness;Machine learning;Sparse matrices;Noise reduction;Cameras","feature extraction;image recognition;image representation;learning (artificial intelligence);matrix algebra;video signal processing","substantial distribution difference;videos feature representations;affinity matrix;unsupervised distribution adaptation method;marginalized stacked denoising autoencoder;conditional distribution difference;joint sparse representation;discriminant view-invariant representations;cross-view action recognition;hierarchically learned view-invariant representations;multiview datasets;informative feature representations","","16","","55","IEEE","31 Aug 2018","","","IEEE","IEEE Journals"
"A clustering-based approach for data-driven imputation of missing traffic data","W. C. Ku; G. R. Jagadeesh; A. Prakash; T. Srikanthan","School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore","2016 IEEE Forum on Integrated and Sustainable Transportation Systems (FISTS)","29 Aug 2016","2016","","","1","6","The problem of missing samples in road traffic data undermines the performance of intelligent transportation applications. This paper proposes a data-driven imputation method that exploits the spatial and temporal relationships existing between the traffic flows of multiple road segments that are correlated with each other. The K-means clustering technique is used to group together road segments with similar traffic flow patterns. Next, a deep-learning model based on stacked denoising autoencoders is constructed for each group of road segments to extract their spatial-temporal relationships and use them for imputing the missing data points. Experiments conducted with real traffic data demonstrate that the imputation accuracy of the proposed method is robust under different missing data rates.","","978-1-5090-2930-3","10.1109/FISTS.2016.7552320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552320","Traffic data;imputation;clustering;deep learning;intelligent transportation systems.","Roads;Data models;Training;Noise reduction;Sensors;Decoding;Traffic control","data handling;intelligent transportation systems;pattern clustering;traffic engineering computing","clustering-based approach;road traffic data missing samples;intelligent transportation applications;data-driven imputation method;traffic flows;multiple road segments correlation;K-means clustering technique;road segment grouping;traffic flow patterns;deep-learning model;stacked denoising autoencoders;spatial-temporal relationship extraction;missing data point imputation","","16","","21","","29 Aug 2016","","","IEEE","IEEE Conferences"
"Fast Economic Dispatch in Smart Grids Using Deep Learning: An Active Constraint Screening Approach","Y. Yang; Z. Yang; J. Yu; K. Xie; L. Jin","State Key Laboratory of Power Transmission Equipment and System Security and New Technology, College of Electrical Engineering, Chongqing University, Chongqing, China; State Key Laboratory of Power Transmission Equipment and System Security and New Technology, College of Electrical Engineering, Chongqing University, Chongqing, China; State Key Laboratory of Power Transmission Equipment and System Security and New Technology, College of Electrical Engineering, Chongqing University, Chongqing, China; State Key Laboratory of Power Transmission Equipment and System Security and New Technology, College of Electrical Engineering, Chongqing University, Chongqing, China; Dispatching and Control Center, State Grid Chongqing Electric Power Company, Chongqing, China","IEEE Internet of Things Journal","12 Nov 2020","2020","7","11","11030","11040","In smart grids, the power supply and demand are balanced through the electricity market to promote the maximization of social welfare. An important procedure in electricity market clearing is to sequentially solve the security-constrained economic dispatch (SCED) problem. However, the scale of the SCED problem with all N-1 constraints is huge. Directly optimizing such a problem is inefficient and not robust. With the development of smart grids, the frequency of market clearing is increasing, which presents new requirements for fast calculation of SCED. To solve this problem, we propose an intelligent prescreening method to identify the active constraints of SCED based on deep learning. We utilize stacked denoising autoencoders (SDAEs) to extract the nonlinear relationship between the system operating condition and the active constraint set of SCED. Especially, the input/output feature vectors and learning strategy are designed to improve the training efficiency and guarantee the learning accuracy of the deep neural network (DNN). Besides, a fast tuning strategy of neural network parameters based on transfer learning is proposed to handle new scenarios such as topology change. The computational efficiency of the SCED problem is significantly improved while the accuracy is not influenced. The IEEE 30-bus, IEEE 118-bus, and practical utility 661-bus systems are used to demonstrate the effectiveness of the proposed method.","2327-4662","","10.1109/JIOT.2020.2993567","National Natural Science Foundation of China(grant numbers:51807014); State Grid Corporation of China (The Key Technology and Application of Active and Reactive Power Scheduling Based on Nonlinear Projection); Fundamental Research Funds for the Central Universities(grant numbers:2019CDXYDQ0010); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9091585","Active constraint set;constraint screening;deep neural network (DNN);security-constrained economic dispatch (SCED)","Feature extraction;Neural networks;Economics;Computational modeling;Optimization;Smart grids;Training","feature extraction;learning (artificial intelligence);neural nets;optimisation;power engineering computing;power markets;power system economics;power system security;smart power grids","deep learning;active constraint screening approach;smart grids;power supply;social welfare;electricity market clearing;security-constrained economic dispatch problem;SCED problem;intelligent prescreening method;learning strategy;learning accuracy;deep neural network;fast tuning strategy;transfer learning;fast economic dispatch;DNN;IEEE 118-bus;IEEE 30-bus system;practical utility 661-bus systems;stacked denoising autoencoders;SDAE;computational efficiency;input-output feature vectors;neural network parameters","","13","","44","IEEE","13 May 2020","","","IEEE","IEEE Journals"
"Domain Adaptation for Test Report Classification in Crowdsourced Testing","J. Wang; Q. Cui; S. Wang; Q. Wang","University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Electrical and Computer Engineering, University of Waterloo, Canada; University of Chinese Academy of Sciences, Beijing, China","2017 IEEE/ACM 39th International Conference on Software Engineering: Software Engineering in Practice Track (ICSE-SEIP)","3 Jul 2017","2017","","","83","92","In crowdsourced testing, it is beneficial to automatically classify the test reports that actually reveal a fault - a true fault, from the large number of test reports submitted by crowd workers. Most of the existing approaches toward this task simply leverage historical data to train a machine learning classifier and classify the new incoming reports. However, our observation on real industrial data reveals that projects under crowdsourced testing come from various domains, and the submitted reports usually contain different technical terms to describe the software behavior for each domain. The different data distribution across domains could significantly degrade the performance of classification models when utilized for cross-domain report classification. To build an effective cross-domain classification model, we leverage deep learning to discover the intermediate representation that is shared across domains, through the co-occurrence between domain-specific terms and domain-unaware terms. Specifically, we use the Stacked Denoising Autoencoders to automatically learn the high-level features from raw textual terms, and utilize these features for classification. Our evaluation on 58 commercial projects of 10 domains from one of the Chinese largest crowdsourced testing platforms shows that our approach can generate promising results, compared to three commonly-used and state-of-the-art baselines. Moreover, we also evaluate its usefulness using real-world case studies. The feedback from real-world testers demonstrates its practical value.","","978-1-5386-2717-4","10.1109/ICSE-SEIP.2017.8","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7965432","Crowdsourced testing;test report classification;domain adaptation;deep learning","Testing;Feature extraction;Noise reduction;Training;Software;Data models;Machine learning","learning (artificial intelligence);pattern classification;program testing","test report classification;crowdsourced testing;machine learning classifier;stacked denoising autoencoders;data distribution;cross-domain report classification;deep learning","","13","","31","","3 Jul 2017","","","IEEE","IEEE Conferences"
"Recursive Sparse, Spatiotemporal Coding","T. Dean; R. Washington; G. Corrado","Google, Inc., Mountain View, CA, USA; Google, Inc., Mountain View, CA, USA; University of Stanford, Stanford, CA, USA","2009 11th IEEE International Symposium on Multimedia","28 Dec 2009","2009","","","645","650","We present a new approach to learning sparse, spatiotemporal codes in which the number of basis vectors, their orientations, velocities and the size of their receptive fields change over the duration of unsupervised training. The algorithm starts with a relatively small, initial basis with minimal temporal extent. This initial basis is obtained through conventional sparse coding techniques and is expanded over time by recursively constructing a new basis consisting of basis vectors with larger temporal extent that proportionally conserve regions of previously trained weights. These proportionally conserved weights are combined with the result of adjusting newly added weights to represent a greater range of primitive motion features. The size of the current basis is determined probabilistically by sampling from existing basis vectors according to their activation on the training set. The resulting algorithm produces bases consisting of filters that are bandpass, spatially oriented and temporally diverse in terms of their transformations and velocities. The basic methodology borrows inspiration from the layer-by-layer learning of multiple-layer restricted Boltzmann machines developed by Geoff Hinton and his students. Indeed, we can learn multiple-layer sparse codes by training a stack of denoising autoencoders, but we have had greater success using L1 regularized regression in a variation on Olshausen and Field's original SPARSENET. To accelerate learning and focus attention, we apply a space-time interest-point operator that selects for periodic motion. This attentional mechanism enables us to efficiently compute and compactly represent a broad range of interesting motion. We demonstrate the utility of our approach by using it to recognize human activity in video. Our algorithm meets or exceeds the performance of state-of-the-art activity-recognition methods.","","978-1-4244-5231-6","10.1109/ISM.2009.28","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5365771","sparse coding;human-activity recognition","Spatiotemporal phenomena;Humans;USA Councils;Acceleration;Sampling methods;Band pass filters;Machine learning;Noise reduction;Statistics;Motion pictures","image motion analysis;image recognition;unsupervised learning;video coding","sparse coding;spatiotemporal codes;unsupervised training;primitive motion features;basis vectors;training set;Boltzmann machines;denoising autoencoders;SPARSENET;space-time interest-point operator;activity recognition","","11","","17","","28 Dec 2009","","","IEEE","IEEE Conferences"
"Analysis of Road-User Interaction by Extraction of Driver Behavior Features Using Deep Learning","A. Bichicchi; R. Belaroussi; A. Simone; V. Vignali; C. Lantieri; X. Li","Department of Civil, Chemical, Environmental and Materials Engineering, School of Engineering and Architecture, University of Bologna, Bologna, Italy; COSYS-GRETTIA, French Institute of Science and Technology for Transport, Development and Networks, Gustave Eiffel University, Marne-la-Vallée, France; Department of Civil, Chemical, Environmental and Materials Engineering, School of Engineering and Architecture, University of Bologna, Bologna, Italy; Department of Civil, Chemical, Environmental and Materials Engineering, School of Engineering and Architecture, University of Bologna, Bologna, Italy; Department of Civil, Chemical, Environmental and Materials Engineering, School of Engineering and Architecture, University of Bologna, Bologna, Italy; School of Instrument Science and Engineering, Southeast University, Nanjing, China","IEEE Access","30 Jan 2020","2020","8","","19638","19645","In this study, an improved deep learning model is proposed to explore the complex interactions between the road environment and driver's behaviour throughout the generation of a graphical representation. The proposed model consists of an unsupervised Denoising Stacked Autoencoder (SDAE) able to provide output layers in RGB colors. The dataset comes from an experimental driving test where kinematic measures were tracked with an in-vehicle GPS device. The graphical outcomes reveal the method ability to efficiently detect patterns of simple driving behaviors, as well as the road environment complexity and some events encountered along the path.","2169-3536","","10.1109/ACCESS.2020.2965940","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8957135","Deep learning;driver behavior;event detection;road safety;workload","Feature extraction;Vehicles;Roads;Image color analysis;Principal component analysis;Data models;Data mining","behavioural sciences computing;Global Positioning System;learning (artificial intelligence);neural nets;traffic engineering computing","pattern detection;driver behavior feature extraction;unsupervised denoising stacked autoencoder;road environment complexity;driving behaviors;graphical outcomes;in-vehicle GPS device;kinematic measures;experimental driving test;RGB colors;output layers;graphical representation;complex interactions;improved deep learning model;road-user interaction","","10","","18","CCBY","13 Jan 2020","","","IEEE","IEEE Journals"
"Greedy deep transform learning","J. Maggu; A. Majumdar",IIIT-Delhi; IIIT-Delhi,"2017 IEEE International Conference on Image Processing (ICIP)","22 Feb 2018","2017","","","1822","1826","We introduce deep transform learning - a new tool for deep learning. Deeper representation is learnt by stacking one transform after another. The learning proceeds in a greedy way. The first layer learns the transform and features from the input training samples. Subsequent layers use the features (after activation) from the previous layers as training input. Experiments have been carried out with other deep representation learning tools - deep dictionary learning, stacked denoising autoencoder, deep belief network and PCANet (a version of convolutional neural network). Results show that our proposed technique is better than all the said techniques, at least on the benchmark datasets (MNIST, CIFAR-10 and SVHN) compared on.","2381-8549","978-1-5090-2175-8","10.1109/ICIP.2017.8296596","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8296596","deep learning;greedy learning;transform learning","Transforms;Machine learning;Neural networks;Training;Tools;Dictionaries;Inverse problems","learning (artificial intelligence)","deeper representation;deep belief network;deep representation learning tools;deep dictionary learning;Greedy deep transform learning;stacked denoising autoencoder;PCANet;convolutional neural network","","10","","37","","22 Feb 2018","","","IEEE","IEEE Conferences"
"DLGraph: Malware Detection Using Deep Learning and Graph Embedding","H. Jiang; T. Turki; J. T. L. Wang","Computer Science Department, New Jersey Institute of Technology, Newark, NJ, USA; Computer Science Department, King Abdulaziz: University, Jeddah, Saudi Arabia; New Jersey Institute of Technology, Newark, NJ, US","2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)","17 Jan 2019","2018","","","1029","1033","In this paper we present a new approach, named DLGraph, for malware detection using deep learning and graph embedding. DLGraph employs two stacked denoising autoencoders (SDAs) for representation learning, taking into consideration computer programs' function-call graphs and Windows application programming interface (API) calls. Given a program, we first use a graph embedding technique that maps the program's function-call graph to a vector in a low-dimensional feature space. One SDA in our deep learning model is used to learn a latent representation of the embedded vector of the function-call graph. The other SDA in our model is used to learn a latent representation of the given program's Windows API calls. The two learned latent representations are then merged to form a combined feature vector. Finally, we use softmax regression to classify the combined feature vector for predicting whether the given program is malware or not. Experimental results based on different datasets demonstrate the effectiveness of the proposed approach and its superiority over a related method.","","978-1-5386-6805-4","10.1109/ICMLA.2018.00168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8614193","malware detection, function-call graphs, Windows API calls","Deep learning;Microsoft Windows;Trojan horses;Noise reduction;Static analysis;Feature extraction","application program interfaces;embedded systems;feature extraction;graph theory;invasive software;learning (artificial intelligence);neural nets;pattern classification","function-call graph;SDA;embedded vector;malware detection;stacked denoising autoencoders;representation learning;graph embedding;deep learning;DLGraph;Windows API calls;Windows application programming interface calls;softmax regression;combined feature vector classification","","9","","26","","17 Jan 2019","","","IEEE","IEEE Conferences"
"A Session-Based Customer Preference Learning Method by Using the Gated Recurrent Units With Attention Function","J. Chen; A. Abdul","Center for Artificial Intelligence in Medicine, Chang Gung Memorial Hospital, Taoyuan, Taiwan; Division of Computer Science and Information Engineering, Chang Gung University, Taoyuan, Taiwan","IEEE Access","14 Feb 2019","2019","7","","17750","17759","In this paper, we investigate an attention function combined with the gated recurrent units (GRUs), named GRUA, to raise the accuracy of the customer preference prediction. The attention function extracts the important product features by using the time-bias parameter and the term frequency-inverse document frequency parameter for recommending products to a customer in the ongoing session. We show that the attention function with the GRUs can learn the customer's intention in the ongoing session more precisely than the existing session-based recommendation (SBR) methods. The experimental results show that the GRUA outperforms two SBR methods: the stacked denoising autoencoders with collaborative filtering (SDAE/CF) and the GRUs with collaborative filtering (GRU/CF) based on the precision and recall evaluation metrics. The data from three publicly available datasets, the Amazon Product Review dataset, the Xing dataset, and the Yoo-Choose Click dataset, are used to evaluate the performance of the GRUA with the SDAE/CF and the GRU/CF. This paper shows that adopting the attention function into the GRUs can dramatically increase the accuracy of the product recommendation in the SBR.","2169-3536","","10.1109/ACCESS.2019.2895647","Ministry of Science and Technology, Taiwan(grant numbers:MOST107-2221-E-182-072); Chang Gung Memorial Hospital(grant numbers:CMRPD2I0051); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8628957","Attention function;collaborative filtering;gated recurrent units;prediction;recommendation","Feature extraction;Databases;Logic gates;History;Collaboration;Online services;Metadata","collaborative filtering;data mining;learning (artificial intelligence);pattern classification;recommender systems;recurrent neural nets;retail data processing;text analysis","attention function;term frequency-inverse document frequency parameter;ongoing session;GRUs;session-based customer preference learning method;gated recurrent units;customer preference prediction;session-based recommendation methods;time-bias parameter;stacked denoising autoencoders;collaborative filtering;precision evaluation metrics;recall evaluation metrics;Amazon product review dataset;Xing dataset;Yoo-Choose Click dataset;product recommendation","","9","","31","OAPA","29 Jan 2019","","","IEEE","IEEE Journals"
"Deep Physiological Arousal Detection in a Driving Simulator Using Wearable Sensors","A. Saeed; S. Trajanovski; M. Van Keulen; J. Van Erp","University of Twente, Enschede, Netherlands; Philips Research, Eindhoven, Netherlands; Universiteit Twente, Enschede, Netherlands; Universiteit Twente, Enschede, Overijssel, Netherlands","2017 IEEE International Conference on Data Mining Workshops (ICDMW)","18 Dec 2017","2017","","","486","493","Driving is an activity that requires considerable alertness. Insufficient attention, imperfect perception, inadequate information processing, and sub-optimal arousal are possible causes of poor human performance. Understanding of these causes and the implementation of effective remedies is of key importance to increase traffic safety and improve driver's well-being. For this purpose, we used deep learning algorithms to detect arousal level, namely, under-aroused, normal and over-aroused for professional truck drivers in a simulated environment. The physiological signals are collected from 11 participants by wrist wearable devices. We presented a cost effective ground-truth generation scheme for arousal based on a subjective measure of sleepiness and score of stress stimuli. On this dataset, we evaluated a range of deep neural network models for representation learning as an alternative to handcrafted feature extraction. Our results show that a 7-layers convolutional neural network trained on raw physiological signals (such as heart rate, skin conductance and skin temperature) outperforms a baseline neural network and denoising autoencoder models with weighted F-score of 0.82 vs. 0.75 and Kappa of 0.64 vs. 0.53, respectively. The proposed convolutional model not only improves the overall results but also enhances the detection rate for every driver in the dataset as determined by leave-one-subject-out cross-validation.","2375-9259","978-1-5386-3800-2","10.1109/ICDMW.2017.69","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8215701","Arousal Detection;Deep Learning;Driving Simulator;Convolutional Neural Network;Wearable Sensors","Physiology;Heart rate;Sleep;Stress;Feature extraction;Skin","driver information systems;feature extraction;learning (artificial intelligence);neural nets;physiology;road safety","inadequate information processing;poor human performance;traffic safety;deep learning algorithms;arousal level;professional truck drivers;simulated environment;wrist wearable devices;cost effective ground-truth generation scheme;sleepiness;score;deep neural network models;representation learning;handcrafted feature extraction;7-layers convolutional neural network;raw physiological signals;skin conductance;skin temperature;baseline neural network;denoising autoencoder models;convolutional model;detection rate;deep physiological arousal detection;driving simulator;wearable sensors;considerable alertness;imperfect perception","","9","","40","","18 Dec 2017","","","IEEE","IEEE Conferences"
"Multimodal Mild Depression Recognition Based on EEG-EM Synchronization Acquisition Network","J. Zhu; Y. Wang; R. La; J. Zhan; J. Niu; S. Zeng; X. Hu","Gansu Provincial Key Laboratory of Wearable Computing, School of Information Science and Engineering, Lanzhou University, Lanzhou, China; Gansu Provincial Key Laboratory of Wearable Computing, School of Information Science and Engineering, Lanzhou University, Lanzhou, China; Gansu Provincial Key Laboratory of Wearable Computing, School of Information Science and Engineering, Lanzhou University, Lanzhou, China; Gansu Provincial Key Laboratory of Wearable Computing, School of Information Science and Engineering, Lanzhou University, Lanzhou, China; Gansu Provincial Key Laboratory of Wearable Computing, School of Information Science and Engineering, Lanzhou University, Lanzhou, China; Gansu Provincial Key Laboratory of Wearable Computing, School of Information Science and Engineering, Lanzhou University, Lanzhou, China; Gansu Provincial Key Laboratory of Wearable Computing, School of Information Science and Engineering, Lanzhou University, Lanzhou, China","IEEE Access","15 Mar 2019","2019","7","","28196","28210","In this paper, we used electroencephalography (EEG)-eye movement (EM) synchronization acquisition network to simultaneously record both EEG and EM physiological signals of the mild depression and normal controls during free viewing. Then, we consider a multimodal feature fusion method that can best discriminate between mild depression and normal control subjects as a step toward achieving our long-term aim of developing an objective and effective multimodal system that assists doctors during diagnosis and monitoring of mild depression. Based on the multimodal denoising autoencoder, we use two feature fusion strategies (feature fusion and hidden layer fusion) for fusion of the EEG and EM signals to improve the recognition performance of classifiers for mild depression. Our experimental results indicate that the EEG-EM synchronization acquisition network ensures that the recorded EM and EEG data require that both the data streams are synchronized with millisecond precision, and both fusion methods can improve the mild depression recognition accuracy, thus demonstrating the complementary nature of the modalities. Compared with the unimodal classification approach that uses only EEG or EM, the feature fusion method slightly improved the recognition accuracy by 1.88%, while the hidden layer fusion method significantly improved the classification rate by up to 7.36%. In particular, the highest classification accuracy achieved in this paper was 83.42%. These results indicate that the multimodal deep learning approaches with input data using a combination of EEG and EM signals are promising in achieving real-time monitoring and identification of mild depression.","2169-3536","","10.1109/ACCESS.2019.2901950","National Natural Science Foundation of China(grant numbers:61632014,61210010,61402211); National Basic Research Program of China (973 Program)(grant numbers:2014CB744600); Fundamental Research Funds for the Central Universities(grant numbers:lzujbky-2017-it74,lzujbky-2017-it75); International Cooperation Project of Ministry of Science and Technology(grant numbers:2013DFA11140); Beijing Municipal Science and Technology Commission(grant numbers:Z171100000117005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8653893","EEG;eye movement;mild depression;network;classification;multimodal deep learning","Electroencephalography;Feature extraction;Synchronization;Deep learning;Noise reduction;Classification algorithms;Electrodes","electroencephalography;medical signal processing;pattern classification","multimodal mild depression recognition;EEG-EM synchronization acquisition network;electroencephalography-eye movement synchronization acquisition network;multimodal feature fusion method;effective multimodal system;multimodal denoising autoencoder;fusion strategies;fusion methods;mild depression recognition accuracy;hidden layer fusion method","","7","","75","OAPA","27 Feb 2019","","","IEEE","IEEE Journals"
"A General Multi-Task Learning Framework to Leverage Text Data for Speech to Text Tasks","Y. Tang; J. Pino; C. Wang; X. Ma; D. Genzel","Facebook AI, USA; Facebook AI, USA; Facebook AI, USA; Johns Hopkins University, USA; Facebook AI, USA","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","6209","6213","Attention-based sequence-to-sequence modeling provides a powerful and elegant solution for applications that need to map one sequence to a different sequence. Its success heavily relies on the availability of large amounts of training data. This presents a challenge for speech applications where labelled speech data is very expensive to obtain, such as automatic speech recognition (ASR) and speech translation (ST). In this study, we propose a general multi-task learning framework to leverage text data for ASR and ST tasks. Two auxiliary tasks, a denoising autoencoder task and machine translation task, are proposed to be co-trained with ASR and ST tasks respectively. We demonstrate that representing text input as phoneme sequences can reduce the difference between speech and text inputs, and enhance the knowledge transfer from text corpora to the speech to text tasks. Our experiments show that the proposed method achieves a relative 10~15% word error rate reduction on the English LIBRISPEECH task compared with our baseline, and improves the speech translation quality on the MUST-C tasks by 3.6~9.2 BLEU.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9415058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9415058","Multi-task learning;speech recognition;speech translation","Error analysis;Conferences;Noise reduction;Training data;Speech enhancement;Signal processing;Machine translation","language translation;learning (artificial intelligence);natural language processing;speech recognition","training data;speech applications;labelled speech data;automatic speech recognition;ASR;ST;general multitask learning framework;leverage text data;auxiliary tasks;denoising autoencoder task;machine translation task;text input;phoneme sequences;text corpora;text tasks;English LIBRISPEECH task;speech translation quality;MUST-C tasks;sequence-to-sequence modeling;powerful solution;elegant solution;map one sequence;different sequence","","6","","30","IEEE","13 May 2021","","","IEEE","IEEE Conferences"
"Multimodal Deep Learning Framework for Mental Disorder Recognition","Z. Zhang; W. Lin; M. Liu; M. Mahmoud","Tencent Jarvis Lab, Shenzhen, China; Department of Engineering, University of Cambridge, Cambridge, United Kingdom; Department of Physics, University of Oxford, Oxford, United Kingdom; Department of Computer Science and Technology, University of Cambridge, Cambridge, United Kingdom","2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)","18 Jan 2021","2020","","","344","350","Current methods for mental disorder recognition mostly depend on clinical interviews and self-reported scores that can be highly subjective. Building an automatic recognition system can help in early detection of symptoms and providing insights into the biological markers for diagnosis. It is, however, a challenging task as it requires taking into account indicators from different modalities, such as facial expressions, gestures, acoustic features and verbal content. To address this issue, we propose a general-purpose multimodal deep learning framework, in which multiple modalities - including acoustic, visual and textual features - are processed individually with the cross-modality correlation considered. Specifically, a Multimodal Deep Denoising Autoencoder (multi- DDAE) is designed to obtain multimodal representations of audio-visual features followed by the Fisher Vector encoding which produces session-level descriptors. For textual modality, a Paragraph Vector (PV) is proposed to embed the transcripts of interview sessions into document representations capturing cues related to mental disorders. Following an early fusion strategy, both audio-visual and textual features are then fused prior to feeding them to a Multitask Deep Neural Network (DNN) as the final classifier. Our framework is evaluated on the automatic detection of two mental disorders: bipolar disorder (BD) and depression, using two datasets: Bipolar Disorder Corpus (BDC) and the Extended Distress Analysis Interview Corpus (E-DAIC), respectively. Our experimental evaluation results showed comparable performance to the state-of-the-art in BD and depression detection, thus demonstrating the effective multimodal representation learning and the capability to generalise across different mental disorders.","","978-1-7281-3079-8","10.1109/FG47880.2020.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9320154","mental disorder;deep learning;fisher vector;multimodal","Mental disorders;Feature extraction;Interviews;Visualization;Noise reduction;Encoding;Acoustics","acoustic signal processing;audio signal processing;emotion recognition;face recognition;feature extraction;learning (artificial intelligence);medical disorders;medical image processing;natural language processing;neural nets;vectors","mental disorder recognition;clinical interviews;self-reported scores;automatic recognition system;providing insights;acoustic features;general-purpose multimodal deep learning framework;multiple modalities;textual features;cross-modality correlation;Multimodal Deep Denoising Autoencoder;multimodal representations;audio-visual features;Fisher Vector encoding;session-level descriptors;textual modality;interview sessions;early fusion strategy;Multitask Deep Neural Network;automatic detection;Bipolar Disorder Corpus;Extended Distress Analysis Interview Corpus;depression detection;effective multimodal representation learning;different mental disorders","","6","","28","","18 Jan 2021","","","IEEE","IEEE Conferences"
"Robust Voice Activity Detector by combining sequentially trained Deep Neural Networks","S. M. R. Nahar; A. Kai","Graduate School of Integrated Science and Technology, Shizuoka University, Shizuoka, JP; Graduate School of Integrated Science and Technology, Shizuoka University, Hamamatsu, Japan","2016 International Conference On Advanced Informatics: Concepts, Theory And Application (ICAICTA)","2 Jan 2017","2016","","","1","5","Deep Neural Network (DNN) has been hot topic in the field of information processing recently. As a vast field of information processing, speech processing has also been aided by Deep Neural Network. After Deep Neural Network is introduced to speech processing, its performance has outperformed its older methods. But still there is room for improvement and researchers are working on to find new ways to make the fullest use of DNN. In the same direction, we have been carrying out our research to find improved results. Our work is about combining two DNNs to perform voice activity detection where one DNN has the role of Denoising Autoencoder (DAE) and the second one acts as Voice Activity Detector (VAD) and to train them sequentially to develop a robust voice activity detection system for noisy and reverberant speech through distant microphone in the real environment scenario like meeting room or so.","","978-1-5090-1636-5","10.1109/ICAICTA.2016.7803133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7803133","Speech Processing;Deep Neural Network;Voice activity Detection;sequentially trained Deep Neural Networks","Cepstral analysis;Artificial neural networks","learning (artificial intelligence);voice activity detection","robust voice activity detector;sequentially trained deep neural networks;DNN;information processing;speech processing;denoising autoencoder;DAE;VAD;robust voice activity detection system;noisy speech;reverberant speech;distant microphone","","6","","22","","2 Jan 2017","","","IEEE","IEEE Conferences"
"Classify autism and control based on deep learning and community structure on resting-state fMRI","D. Liao; H. Lu","Department of Electromechanical Engineering, ChangZhou Textile Garment Institute, Changzhou, China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China","2018 Tenth International Conference on Advanced Computational Intelligence (ICACI)","11 Jun 2018","2018","","","289","294","It is unsatisfied to diagnose brain disorders based on subjective judgment. In this paper, we proposed a novel method to classify autism disorders and normal subjects objectively and automatically. The method firstly detects community structure in network of every subject. The NMI statistic matrix, which can effectively represent the features of all subject in a certain dataset, was developed and then was imported into denoising autoencoder to classify. We tested our method on three datasets. The results show that the accuracy of our method is higher than that of traditional one. Additionally, our method is more efficient than import Pearson correlation matrix into classifier. Our method is effective to help doctors diagnose autism objectively.","","978-1-5386-4362-4","10.1109/ICACI.2018.8377471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8377471","deep learning;fMRI;autism;community detection","Functional magnetic resonance imaging;Autism;Noise reduction;Symmetric matrices;Correlation;Support vector machines;Machine learning","biomedical MRI;brain;image classification;learning (artificial intelligence);medical disorders;medical image processing;neurophysiology","community structure;NMI statistic matrix;denoising autoencoder;Pearson correlation matrix;deep learning;resting-state fMRI;brain disorders;autism disorders;autism classification","","5","","17","","11 Jun 2018","","","IEEE","IEEE Conferences"
"Deep Tensor Factorization for Multi-Criteria Recommender Systems","Z. Chen; S. Gai; D. Wang","School of Engineering, Westlake University, Hangzhou, China; School of Engineering, Westlake University, Hangzhou, China; School of Engineering, Westlake University, Hangzhou, China","2019 IEEE International Conference on Big Data (Big Data)","24 Feb 2020","2019","","","1046","1051","Matrix factorization is one of the most successful methods for single-criterion recommender systems but not for multi-criteria recommender systems that contain multiple criterion-specific ratings. Tensor factorization methods have been developed to learn predictive models in multi-criteria recommender systems by dealing with the three-dimensional (3D) user-item-criterion ratings. However, they suffer from the data sparsity issues in real applications. In order to alleviate this problem, we propose deep tensor factorization (DTF) in this paper by integrating deep representation learning and tensor factorization, where the side information is embedded to provide an effective compensation for tensor sparsity. We exhibit two DTF instantiations by combining stacked denoising autoencoder (SDAE) and CANDECOMP/PARAFAC (CP) tensor factorization. Experimental results demonstrate that our DTF schemes outperform state-of-the-art methods in terms of multi-criteria recommendations.","","978-1-7281-0858-2","10.1109/BigData47090.2019.9005677","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9005677","Multi-criteria recommender systems;tensor factorization;deep learning;side information","Tensile stress;Recommender systems;Predictive models;Data models;Machine learning;Optimization;Big Data","learning (artificial intelligence);matrix decomposition;neural nets;recommender systems;tensors","tensor factorization methods;multicriteria recommender systems;three-dimensional user-item-criterion ratings;deep tensor factorization;deep representation learning;tensor sparsity;multicriteria recommendations;matrix factorization;single-criterion recommender systems;stacked denoising autoencoder;CANDECOMP/PARAFAC tensor factorization","","4","","28","","24 Feb 2020","","","IEEE","IEEE Conferences"
"Assessing Wireless Sensing Potential With Large Intelligent Surfaces","C. J. Vaca-Rubio; P. Ramirez-Espinosa; K. Kansanen; Z. -H. Tan; E. De Carvalho; P. Popovski","Department of Electronic Systems, Aalborg University, Aalborg, Denmark; Department of Electronic Systems, Aalborg University, Aalborg, Denmark; Norwegian University of Science and Technology, Trondheim, Norway; Department of Electronic Systems, Aalborg University, Aalborg, Denmark; Department of Electronic Systems, Aalborg University, Aalborg, Denmark; Department of Electronic Systems, Aalborg University, Aalborg, Denmark","IEEE Open Journal of the Communications Society","20 Apr 2021","2021","2","","934","947","Sensing capability is one of the most highlighted new feature of future 6G wireless networks. This paper addresses the sensing potential of Large Intelligent Surfaces (LIS) in an exemplary Industry 4.0 scenario. Besides the attention received by LIS in terms of communication aspects, it can offer a high-resolution rendering of the propagation environment. This is because, in an indoor setting, it can be placed in proximity to the sensed phenomena, while the high resolution is offered by densely spaced tiny antennas deployed over a large area. By treating an LIS as a radio image of the environment relying on the received signal power, we develop techniques to sense the environment, by leveraging the tools of image processing and machine learning. Once a radio image is obtained, a Denoising Autoencoder (DAE) network can be used for constructing a super-resolution image leading to sensing advantages not available in traditional sensing systems. Also, we derive a statistical test based on the Generalized Likelihood Ratio (GLRT) as a benchmark for the machine learning solution. We test these methods for a scenario where we need to detect whether an industrial robot deviates from a predefined route. The results show that the LIS-based sensing offers high precision and has a high application potential in indoor industrial environments.","2644-125X","","10.1109/OJCOMS.2021.3073467","European Unions Horizon 2020 Research and Innovation Programme through the Marie Skłodowska-Curie(grant numbers:813999); EU H2020 RISE-6G project; Danish Council for Independent Research(grant numbers:DFF-701700271); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9405304","Computer vision;industry 4.0;large intelligent surfaces;machine learning;sensing","Wireless sensor networks;Wireless networks;Noise reduction;Superresolution;Machine learning;Tools;Robot sensing systems","human computer interaction;image resolution;industrial robots;learning (artificial intelligence);MIMO communication;rendering (computer graphics);statistical testing;wireless sensor networks","wireless sensing potential;Large Intelligent Surfaces;sensing capability;future 6G wireless networks;Industry 4.0;communication aspects;high-resolution rendering;propagation environment;densely spaced tiny antennas;radio image;received signal power;image processing;Denoising Autoencoder network;super-resolution image;sensing advantages;traditional sensing systems;machine learning solution;industrial robot deviates;LIS-based sensing;indoor industrial environments","","2","","52","CCBY","15 Apr 2021","","","IEEE","IEEE Journals"
"A Multi-phase Intersection Traffic Signal Control Strategy with Deep Reinforcement Learning","C. Li; Y. Li; G. Liu","School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; Operation No.4 Company Chongqing, Railway Transportation Group co., Ltd, Chongqing, China","2018 Chinese Automation Congress (CAC)","24 Jan 2019","2018","","","959","964","In this paper, a deep reinforcement learning (DNQ) algorithm for multi-phase intersection traffic control is proposed for improves the capacity of the urban road intersections. Here, deep learning is applied for extracting the features of traffic flow to learn the Q-function of reinforcement learning. The denoising stacked autoencoders are considered to reduce the effects of abnormal data generated during system operation. Considering the connection between the signal timing scheme and the phase sequence, the DNQ algorithm is used to adjust the sequence of the signal phase according to the dynamic traffic characteristics of the intersection while realtime self-adaptive adjustment of the signal timing. Simulations in platform consisting of VISSIM and Python are applied to test the algorithm. The performance of the proposed method is comprehensively compared with a traditional algorithm with fixed or free phase sequence under different traffic demand. Simulation results suggest that the proposed method signify-cantly reduces the delay in the intersection when compared to the alternative methods.","","978-1-7281-1312-8","10.1109/CAC.2018.8623383","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8623383","intersection;deep reinforcement learning;signal timing;styling;phase sequence","Reinforcement learning;Information science;Companies;Rail transportation;Timing","control engineering computing;learning (artificial intelligence);road traffic control;traffic engineering computing","multiphase intersection traffic signal control strategy;deep reinforcement learning algorithm;multiphase intersection traffic control;urban road intersections;deep learning;traffic flow;denoising stacked autoencoders;DNQ algorithm;signal phase;dynamic traffic characteristics;signal timing;fixed phase sequence;free phase sequence;traffic demand;VISSIM;Python;feature extraction","","2","","14","","24 Jan 2019","","","IEEE","IEEE Conferences"
"Layered Representation of Bengali Texts in Reduced Dimension Using Deep Feedforward Neural Network for Categorization","B. Purkaystha; T. Datta; M. S. Islam; Marium-E-Jannat","Computer Science and Engineering, Shahjalal University of Science and Technology, Sylhet, Bangladesh; Computer Science and Engineering, Shahjalal University of Science and Technology, Sylhet, Bangladesh; Computer Science and Engineering, Shahjalal University of Science and Technology, Sylhet, Bangladesh; Computer Science and Engineering, Shahjalal University of Science and Technology, Sylhet, Bangladesh","2018 21st International Conference of Computer and Information Technology (ICCIT)","3 Feb 2019","2018","","","1","5","Automatic text categorization is a primary step in information retrieval where it is necessary to find the most relevant documents in an enormous volume. It is also useful in a wide range of web domains, such as from portal sites to news indexing, or from spam filtering to genre tagging. A significant amount of research works has been carried out in this field, and they are mostly dominated by Support Vector Machines (SVMs) models. Although these models have been very successful, but they require careful feature engineering to achieve optimum results. In this paper, we propose a model for Bengali text categorization that doesn't require feature engineering and is able to capture nonlinearity in data. We had first found a lower dimensional representation for the tf-idf vectors of each document using denoising autoencoders, and then we fed this transformed domain data vector into a deep feedforward network to find its most plausible category. We also show empirically that our model achieves 94.05 % accuracy for 12 categories that surmounts the best existing models on Bengali text categorization.","","978-1-5386-9242-4","10.1109/ICCITECHN.2018.8631935","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8631935","auto encoders;tt-idt;deep learning;SVM;text categorization","Biological system modeling;Noise reduction;Analytical models;Mathematical model;Text categorization;Support vector machines;Feature extraction","feedforward neural nets;Internet;support vector machines;text analysis;vectors","transformed domain data vector;Bengali text categorization;layered representation;Bengali texts;deep feedforward neural network;automatic text categorization;web domains;Support Vector Machines models;tf-idf vectors;denoising autoencoders","","2","","20","IEEE","3 Feb 2019","","","IEEE","IEEE Conferences"
"Autonomous Deep Learning: Incremental Learning of Deep Neural Networks for Evolving Data Streams","A. Ashfahani","School of Computer Science and Engineering, Nanyang Technological University, Singapore","2019 International Conference on Data Mining Workshops (ICDMW)","13 Jan 2020","2019","","","83","90","It was recently demonstrated that network evolution strategies can be used to handle evolving data streams. However, most of these strategies are applied on shallow network structure making it unable to benefit from the power of depth. The application of deep neural networks (DNNs) for evolving data streams is hindered by its static nature which cannot adapt to rapidly changing environments. In this paper, we demonstrate that recently proposed DNN approaches, Autonomous Deep Learning (ADL) and Deep Evolving Denoising Autoencoder (DEVDAN), are able to address evolving data stream problems by adopting a flexible network structure DNN. In other words, these approaches manage to incrementally construct its network structure from scratch in respect to the variation of data. Furthermore, these methods work with the absence of a user-defined threshold and fully operate in the single-pass learning fashion. The multiple hidden nodes growing and adaptive synapses pruning are proposed to boost the predictive performance. When tested on popular datasets, the modified version of ADL and DEVDAN outperformed its original version and existing strategies while maintaining the space and computational complexity to an acceptable level. Also, data streams related research directions to deal with semi-supervised learning are discussed.","2375-9259","978-1-7281-4896-0","10.1109/ICDMW.2019.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8955598","Deep Neural Networks, Data Streams, Online Learning, Adaptive Synapses Pruning","Task analysis;Neural networks;Data models;Noise reduction;Computational complexity;Labeling;Reactive power","data handling;neural nets;supervised learning","Autonomous Deep Learning;incremental Learning;deep neural networks;evolving data streams;network evolution strategies;shallow network structure;Deep Evolving Denoising Autoencoder;flexible network structure DNN;ADL;DEVDAN;single-pass learning;semisupervised learning","","2","","38","","13 Jan 2020","","","IEEE","IEEE Conferences"
"A New Point Anomaly Detection Method About Aero Engine Based on Deep Learning","X. FU; H. Chen; G. Zhang; T. Tao","School of Naval Architecture and Ocean Engineering, Harbin Institute of Technology at Weihai, Weihai, Shandong, China; School of Naval Architecture and Ocean Engineering, Harbin Institute of Technology at Weihai, Weihai, Shandong, China; School of Naval Architecture and Ocean Engineering, Harbin Institute of Technology at Weihai, Weihai, Shandong, China; Maintenance & Engineering Department, Sichuan Airlines, Chengdu, Sichuan, China","2018 International Conference on Sensing,Diagnostics, Prognostics, and Control (SDPC)","14 Mar 2019","2018","","","176","181","Aero engine is one of the most important parts of the aircraft, so timely and efficient discovery of aero engine anomalies is essential for aircraft flight safety and airline economy. Aero engine anomaly detection method based on data driven can effectively improve the accuracy and economy of aero engine fault diagnosis. Based on data difference abnormalities can be divided into two categories: point anomaly and collective anomaly. This paper presents a method of aero engine point anomaly detection based on deep learning, and the method is composed of two main parts: the feature extraction and the anomaly detection. Feature extraction is primarily based on the construction of stacked denoising autoencoder to extract the features of the original input data, and anomaly detection is to build a single gaussian model to detect anomalies. The experimental results are analyzed to verify that the method proposed in this paper has obvious effect on point anomaly detection in the aero engine.","","978-1-5386-6057-7","10.1109/SDPC.2018.8664977","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8664977","Anomaly Detection;Aero Engine;Deep Learning;SDAE;SGM","Feature extraction;Engines;Anomaly detection;Mathematical model;Deep learning;Training;Aircraft","aerospace computing;aerospace engines;aerospace safety;aircraft;fault diagnosis;feature extraction;Gaussian distribution;learning (artificial intelligence);neural nets","deep learning;aircraft flight safety;airline economy;aero engine anomaly detection method;aero engine fault diagnosis;feature extraction;stacked denoising autoencoder;gaussian model","","2","","13","","14 Mar 2019","","","IEEE","IEEE Conferences"
"Deep Learning for Predicting the Operation of Under-Frequency Load Shedding Systems","Y. Xiao; R. Zhao; Y. Wen","Yunnan Power Grid Planning and Construction Research Center, Kunming, China; School of Electrical Engineering, Chongqing University, Chongqing, China; School of Electrical and Information Engineering, Hunan University, Changsha, China","2019 IEEE Innovative Smart Grid Technologies - Asia (ISGT Asia)","24 Oct 2019","2019","","","4142","4147","The frequency nadir and the potential stages to be triggered by the under-frequency load shedding (UFLS) systems are two most important metrics for evaluating the severity of a sudden active power imbalance event. However, the excessive computational time required to apply conventional methods for those calculations does not allow the real-time application. To tackle this issue, this paper describes how the post-fault frequency nadir and the triggering stages of the UFLS could be rapidly and accurately predicted using a deep learning tool based on the stacked denoising autoencoder (SDAE). This data-driven method employs the actual feature data as the inputs and establishes a nonlinear mapping between the input and output data through a deep network architecture. The parameters of the SDAE are optimized by a two-stage training strategy, i.e., the pre-training and the fine-tuning incorporated with the dropout technique. Case studies on a modified New England 39-bus system show that the proposed approach has extremely high computation speed compared to the time-domain simulation method, and achieves higher prediction accuracy in comparison with other shallow neural networks.","2378-8542","978-1-7281-3520-5","10.1109/ISGT-Asia.2019.8881643","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8881643","deep learning;frequency nadir;UFLS;SDAE;frequency stability","Deep learning;Security;Training;Power system stability;Power system dynamics;Time-frequency analysis","learning (artificial intelligence);load shedding;neural nets;power generation control;power system management","post-fault frequency nadir;deep learning tool;stacked denoising autoencoder;SDAE;data-driven method;feature data;output data;deep network architecture;two-stage training strategy;modified New England 39-bus system show;time-domain simulation method;under-frequency load shedding systems;sudden active power imbalance event;UFLS systems","","2","","20","","24 Oct 2019","","","IEEE","IEEE Conferences"
"HDNN-CF: A hybrid deep neural networks collaborative filtering architecture for event recommendation","L. Zou; Y. Gu; J. Song; W. Liu; Y. Yao","Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China","2017 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computed, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)","28 Jun 2018","2017","","","1","8","Along with the rise of Event-Based Social Networks (EBSNs), event recommendation has become an increasing important problem. However, unlike recommending usual items, such as movies or music, event recommendation suffers from severe cold-start problem, because most events in EBSNs are typically short-lived and registered by only a few users. Additionally, the available feedbacks for events are implicit feedbacks. In this work, we propose a Hybrid Deep Neural Networks Collaborative Filtering Architecture (HDNN-CF) that collaboratively makes use of the events' semantic information and users' implicit feedbacks for event recommendation. Specifically, we extend state-of-the-art method AutoRec to model implicit feedbacks by proposing Probabilistic AutoRec (PAutoRec). We collaboratively train a Stacked Denoise AutoEncoder (SDAE) to learn the deep representation of the semantic information and a PAutoRec to collaborative filter based on implicit feedbacks. Extensive experiments on a real large scale dataset Meetup show that HDNN-CF significantly outperforms state-of-the-art methods by 10% on recall of top 30 recommendations.","","978-1-5386-0435-9","10.1109/UIC-ATC.2017.8397524","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8397524","","Semantics;Collaboration;Mathematical model;Predictive models;Neural networks;Filtering;Adaptation models","collaborative filtering;learning (artificial intelligence);neural nets;recommender systems;social networking (online)","HDNN-CF;hybrid deep neural networks collaborative filtering architecture;event recommendation;EBSNs;cold-start problem;available feedbacks;implicit feedbacks;events;users;Event-Based Social Networks;Probabilistic AutoRec;Stacked Denoise AutoEncoder;SDAE","","1","","27","","28 Jun 2018","","","IEEE","IEEE Conferences"
"Patient-specific detection of ventricular tachycardia in remote continuous health devices","A. Juneja; M. Marefat","Electrical and Computer Engineering Department, University of Arizona, Tucson, Arizona, United States; Electrical and Computer Engineering Department, University of Arizona, Tucson, Arizona, United States","2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","18 Oct 2016","2016","","","529","532","Ventricular Tachycardia (VT) is a dangerous arrhythmic event which can lead to sudden cardiac death if not detected and taken care of in time. This work uses non-linear features derived from Recurrence Quantification Analysis (RQA) along with Kolmogorov complexity, by analyzing the ECG signals, to train a classifier which can predict VT prior to their onset in remote continuous health devices. Compressed ECG signal along with amplitude ranges extracted from the ECG signal are used as features to strengthen the classifier. Stacked Denoising Autoencoders (SDAE) are used for the purpose of feature extraction and compression of signals, and their performance is compared with other works that detect VT for different window sizes. Softmax Regression is used as the classifier in this work. The proposed method is tested against MIT-BIH Arrhythmia database, MIT-BIH Malignant Ventricular Arrhythmia Database (VFDB) and Creighton University Ventricular Tachyarrhythmia Database (CUDB). A total of 96.52% accuracy with 96.18% sensitivity is obtained after testing the proposed method on all test records.","1558-4615","978-1-4577-0220-4","10.1109/EMBC.2016.7590756","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590756","","Feature extraction;Electrocardiography;Training;Databases;Complexity theory;Testing;Heart beat","compressed sensing;diseases;electrocardiography;feature extraction;medical disorders;medical signal processing;regression analysis;signal classification","patient-specific detection;ventricular tachycardia;remote continuous health devices;dangerous arrhythmic event;cardiac death;nonlinear features;recurrence quantification analysis;Kolmogorov complexity;classifier;compressed ECG signal;amplitude range extraction;stacked denoising autoencoders;feature extraction;window sizes;Softmax regression;MIT-BIH malignant ventricular arrhythmia database;Creighton University ventricular tachyarrhythmia database","Algorithms;Arrhythmias, Cardiac;Electrocardiography;Humans;Tachycardia, Ventricular;Ventricular Fibrillation","1","","13","","18 Oct 2016","","","IEEE","IEEE Conferences"
"Fast Estimation of Total Transfer Capability Considering both Load and Source Uncertainties","W. Liu; Y. Liu; L. Zhang; H. Wu; Q. Zhang; M. Yang","Key Laboratory of Power System, Shandong University, Jinan, China; Key Laboratory of Power System, Shandong University, Jinan, China; Jiangsu Electric Power Dispatching and Control Center, State Grid Jiangsu Electric Power Company, Nanjing, China; Jiangsu Electric Power Dispatching and Control Center, State Grid Jiangsu Electric Power Company, Nanjing, China; Jiangsu Electric Power Dispatching and Control Center, State Grid Jiangsu Electric Power Company, Nanjing, China; Jiangsu Electric Power Dispatching and Control Center, State Grid Jiangsu Electric Power Company, Nanjing, China","2019 IEEE Sustainable Power and Energy Conference (iSPEC)","30 Jan 2020","2019","","","1291","1296","With the development of smart grid and new energy technologies, both load and source uncertainties need be considered in the calculation of total transfer capability (TTC) of power system transmission. Based on deep learning technology and the improved multi-point estimation method, a fast TTC estimation method considering uncertainties of load power, demand response and wind power generation is proposed. The uncertainties are represented by probability distribution of prediction error and Nataf transformation is introduced to deal with the non-normal probability distributions and their correlations. The stacked denoising autoencoder is employed to estimate TTCs of operating scenarios generated by Nataf transform and the improved multi-point estimation method is used to obtain their probability. Simulation results demonstrate that the fast estimation method is able to consider both load and source uncertainties effectively and calculate TTC fast and accurately.","","978-1-7281-4930-1","10.1109/iSPEC48194.2019.8975281","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8975281","Total transfer capability;deep learning;multi-point estimation;Nataf transformation;power system","","demand side management;estimation theory;probability;transmission networks;wind power","power system transmission;deep learning technology;fast TTC estimation method;load power;demand response;wind power generation;Nataf transformation;fast estimation;total transfer capability;multipoint estimation method;probability distribution;prediction error;stacked denoising autoencoder","","1","","13","","30 Jan 2020","","","IEEE","IEEE Conferences"
"Representation Learning for Improved Generalization of Adversarial Domain Adaptation with Text Classification","A. Khaddaj; H. Hajj","American University of Beirut, Lebanon; American University of Beirut, Lebanon","2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT)","11 May 2020","2020","","","525","531","Domain Adaptation techniques remain limited in accuracy and robustness due to data sparsity. In this paper, we present a new approach called Domain Adversarial network with Representation Learning (DARL), to improve domain adaptation by introducing an encoding layer as part of DARL model learning. We integrate a Stacked Denoising Autoencoder and Adversarial learning for the domain adaptation process. The advantage of the proposed method is that it can extract descriptive features under noisy conditions while still learning task discriminative features. The encoding under noisy reconstruction ensures both higher accuracy and increased robustness in the learning process. We evaluate DARL using Amazon review data set and the results showed superior accuracy and robustness compared to Domain Adversarial Neural Networks (DANN).","","978-1-7281-4821-2","10.1109/ICIoT48696.2020.9089430","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9089430","","Feature extraction;Training;Task analysis;Support vector machines;Noise reduction;Predictive models;DVD","convolutional neural nets;feature extraction;learning (artificial intelligence);pattern classification;text analysis","adversarial domain adaptation;text classification;domain adaptation techniques;data sparsity;domain adversarial network;encoding layer;DARL model learning;stacked denoising autoencoder;domain adaptation process;descriptive features;task discriminative features;learning process;Amazon review data;adversarial neural networks;adversarial learning","","1","","19","","11 May 2020","","","IEEE","IEEE Conferences"
"A Regional Traffic Signal Control Strategy with Deep Reinforcement Learning","C. Li; F. Yan; Y. Zhou; J. Wu; X. Wang","School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China","2018 37th Chinese Control Conference (CCC)","7 Oct 2018","2018","","","7690","7695","In this paper, a deep reinforcement learning algorithm for regional intersection traffic control is proposed for improves the capacity of the road network. This method interacts with the traffic environment to learn the optimal signal control strategy by reinforcement learning. And it using deep learning to reduce the dimension of the huge traffic flow data generated by the road network. The denoising stacked autoencoders are adopted to handle the abnormal dynamic traffic data. Simulations in platform consisting of VISSIM and Python are applied to test the algorithm. The performance of the proposed method is comprehensively compared with a traditional algorithms and a fixed signal timing method with green time difference for regional traffic signal control under different traffic demand. Simulation results suggest that the proposed method significantly reduces the average delay in the traffic network when traffic conditions changed rapidly.","1934-1768","978-988-15639-5-8","10.23919/ChiCC.2018.8483361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8483361","Deep Reinforcement Learning;Traffic Control;Traffic Network","Machine learning;Roads;Noise reduction;Learning (artificial intelligence);Traffic control;Timing","learning (artificial intelligence);optimal control;road traffic control;traffic engineering computing","traffic environment;optimal signal control strategy;deep learning;road network;denoising stacked autoencoders;abnormal dynamic traffic data;fixed signal timing method;traffic network;traffic conditions;regional traffic signal control strategy;deep reinforcement learning algorithm;regional intersection traffic control;traffic flow data;traffic demand;VISSIM;Python","","1","","27","","7 Oct 2018","","","IEEE","IEEE Conferences"
"Coupled Analysis Dictionary Learning to inductively learn inversion: Application to real-time reconstruction of Biomedical signals","K. Gupta; B. Bhowmick; A. Majumdar","Embedded Systems and Robotics, TCS Research and Innovation, India; Embedded Systems and Robotics, TCS Research and Innovation, India; Indraprastha Institute of Information Technology Delhi, India","2018 International Joint Conference on Neural Networks (IJCNN)","14 Oct 2018","2018","","","1","8","This work addresses the problem of reconstructing biomedical signals from their lower dimensional projections. Traditionally Compressed Sensing (CS) based techniques have been employed for this task. These are transductive inversion processes; the problem with these approaches is that the inversion is time-consuming and hence not suitable for real-time applications. With the recent advent of deep learning, Stacked Sparse Denoising Autoencoder (SSDAE) has been used for learning inversion in an inductive setup. The training period for inductive learning is large but is very fast during application - capable of real-time speed. This work proposes a new approach for inductive learning of the inversion process. It is based on Coupled Analysis Dictionary Learning. Results on Biomedical signal reconstruction show that our proposed approach is very fast and yields result far better than CS and SSDAE.","2161-4407","978-1-5090-6014-6","10.1109/IJCNN.2018.8489148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489148","inverse problem;reconstruction;inductive learning;transfer learning;dictionary learning","","compressed sensing;electrocardiography;feature extraction;learning (artificial intelligence);medical signal processing;photoplethysmography;signal reconstruction;signal representation","Traditionally Compressed Sensing;biomedical signal reconstruction;real-time speed;inductive learning;inductive setup;learning inversion;Stacked Sparse Denoising Autoencoder;deep learning;transductive inversion processes;real-time reconstruction;Coupled Analysis Dictionary Learning","","1","","26","","14 Oct 2018","","","IEEE","IEEE Conferences"
"SysEvoRecomd: Network Reconstruction by Graph Evolution and Change Learning","A. Chaturvedi; A. Tiwari; S. Chaturvedi","Department of Informatics, King's College London, London, U.K.; Indian Institute of Technology Indore, Indore, India; Design and Manufacturing, Indian Institute of Information Technology, Jabalpur, India","IEEE Systems Journal","2 Sep 2020","2020","14","3","4007","4014","We introduce a System Evolution Recommender (SysEvoRecomd) algorithm that uses a novel algorithm Graph Evolution and Change Learning (GECL) to do system network reconstruction. Internally, GECL uses Deep Evolution Learner (DEL) to learn about evolution and changes happened over a system state series. The DEL is an extension of the deep learning algorithm, which uses an Evolving Connection Matrix (ECM) representing temporal patterns of the evolving entity-connections for training incremental states. The DEL generates a Deep System Neural Network (Deep SysNN) to do network (graph) reconstruction. The SysEvoRecomd extracts the evolving characteristic of graph with deep neural network techniques. It aims to learn the evolution and changes of the system state series to reconstruct the system network. Our key idea is to design three variants of GECL based on three remodeled deep learning techniques: Restricted Boltzmann Machine (RBM), Deep Belief Network (DBN), and denoising Autoencoder (dA). Based on proposed SysEvoRecomd algorithm, we developed a SysEvoRecomd-Tool, which is applied on different evolving systems: software, natural language, multisport event, retail market, and IMDb movie genre. We demonstrated the usefulness of intelligent recommendations using three variants of GECL based on RBM, DBN, and dA.","1937-9234","","10.1109/JSYST.2020.2988037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9154729","Graph theory;machine learning;network reconstruction;systems engineering and theory","Electronic countermeasures;Matrix converters;Machine learning;Buffer storage;Silicon;Training;Neural networks","belief networks;Boltzmann machines;learning (artificial intelligence);matrix algebra;network theory (graphs)","GECL;system network reconstruction;DEL;system state series;deep learning algorithm;evolving entity-connections;training incremental states;remodeled deep learning techniques;deep belief network;SysEvoRecomd-Tool;graph evolution and change learning;deep evolution learner;evolving connection matrix;deep system neural network;deep SysNN;SysEvoRecomd algorithm;system evolution recommender algorithm;restricted Boltzmann machine;DBN;RBM;denoising autoencoder;dA","","1","","36","IEEE","3 Aug 2020","","","IEEE","IEEE Journals"
"Cross-domain sentiment classification using deep learning approach","Miao Sun; Qi Tan; Runwei Ding; Hong Liu","South China Normal University, Guangzhou, China; South China Normal University, Guangzhou, China; Peking University, Shenzhen Graduate School, Shenzhen, China; Peking University, Beijing, China","2014 IEEE 3rd International Conference on Cloud Computing and Intelligence Systems","6 Aug 2015","2014","","","60","64","Deep learning, as a new unsupervised leaning algorithm, has strong capabilities to learn data representations. Previous work has shown that new features learned by deep learning algorithm help to improve the accuracy of cross-domain classification. In this paper, we firstly propose a modified version of marginalized stacked denoising autoencoders (mSDA). We call it mSDA++ algorithm, which can learn excellent and low-dimensional features for training classifier. In addition, we combine mSDA with EASYADAPT algorithm to further improve the accuracy of cross-domain classification. Then we use SVM, mSDA, mSDA++, and EA+mSDA algorithms to do the cross-domain sentiment classification experiments on Amazon benchmark dataset. The results show that EA+mSDA algorithm attains the best accuracy. Besides, the mSDA++ algorithm can accelerate the subsequent calculation and reduce the data storage space.","2376-595X","978-1-4799-4719-5","10.1109/CCIS.2014.7175703","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7175703","Text sentiment classification;Deep learning;Cross-domain;dimension reduction;feature augment","Noise reduction;Classification algorithms;Training;ISO standards","data structures;pattern classification;storage management;support vector machines;unsupervised learning","cross-domain sentiment classification;deep learning approach;unsupervised leaning algorithm;data representations;marginalized stacked denoising autoencoders;mSDA++ algorithm;EASYADAPT algorithm;SVM;EA+mSDA;Amazon benchmark dataset;data storage space","","1","","13","","6 Aug 2015","","","IEEE","IEEE Conferences"
"Label-free Optimization for Passive Beamforming in IRS-assisted MISO Systems","L. Chu; H. He; L. Pei; W. Yu; R. C. Qiu","Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","2020 IEEE 20th International Conference on Communication Technology (ICCT)","24 Dec 2020","2020","","","157","162","The intelligent reflecting surface (IRS) has been recently brought up and foreseen to be one of the revolutionary technologies for future communication systems. A significant number of low-cost passive elements (PAs) can effectively reflect incident signals and collaboratively achieve beamforming by controlling phase shifts at PAs. In this paper, we study the passive beamforming problem (PBP) in the IRS-assisted multiple-input single-output (MISO) wireless system with imperfect channel station information (CSI). Considering the effect of imperfect CSI, we propose to jointly solve the non-convex beamforming problem and the CSI denoising problem with specially-designed autoencoder based deep neural networks (DNN). Moreover, instead of purely applying the DNN, we elaborate designs of the activation function, the loss function, and the feature selection. The experimental results demonstrate the advantages of the proposed method: 1) It can provide comparable performance with state-of-art approach while consuming significantly less computational time; 2) It can achieve robust beamforming over different kinds of channel estimation errors; 3) It requires no prior knowledge of the labeled targets (phase shifts), which demonstrates its potential application with CSI obtained from real environments.","2576-7828","978-1-7281-8141-7","10.1109/ICCT50939.2020.9295770","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9295770","Intelligent Reflecting Surface;MISO;label-free learning;passive beamforming;imperfect CSI","Array signal processing;Task analysis;Optimization;Wireless communication;Noise reduction;MISO communication;Feature extraction","array signal processing;channel estimation;concave programming;deep learning (artificial intelligence);intelligent materials;MISO communication;neural nets;telecommunication computing","label-free optimization;IRS-assisted MISO systems;intelligent reflecting surface;revolutionary technologies;communication systems;low-cost passive elements;incident signals;phase shifts;passive beamforming problem;multiple-input single-output wireless system;imperfect channel station information;imperfect CSI;nonconvex beamforming problem;CSI denoising problem;deep neural networks;DNN;activation function;loss function;robust beamforming;channel estimation errors;autoencoder","","1","","28","","24 Dec 2020","","","IEEE","IEEE Conferences"
"Neural networks based channel compensation for i-vector speaker verification","W. Rao; X. Xiao; C. Xu; H. Xu; K. Lee; E. S. Chng; H. Li","Temasek Laboratories, Nanyang Technological University, Singapore; Temasek Laboratories, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; Temasek Laboratories, Nanyang Technological University, Singapore; Human Language Technology Department, A*STAR, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore","2016 10th International Symposium on Chinese Spoken Language Processing (ISCSLP)","4 May 2017","2016","","","1","5","Linear discriminant analysis (LDA) and Gaussian probabilistic LDA (PLDA) have been shown to effectively suppress channel- and session-variability of i-vectors. But they suffer the following limitations: 1) In LDA, a single linear transformation may not be adequate to describe the nonlinear relationship of features and 2) Gaussian-PLDA assumes the speaker and channel factors follow a Gaussian distribution, but they are actually non-Gaussians. We consider neural networks (NN) as a way to overcome the limitations, that captures the nonlinear relationship of features and does not require prior assumptions. This paper investigates three NN based channel compensation methods: deep metric learning, NN classifier, and deep denoising autoencoder and compares their performance with LDA and PLDA. Experiments conducted on NIST 2010 speaker recognition evaluation suggest that NN-based channel compensation methods are superior to LDA and that the performance of NN classifier is better than that of PLDA under most of common evaluation conditions. Additionally, this paper also helps us understand the relationships among LDA, PLDA, and NN based methods.","","978-1-5090-4294-4","10.1109/ISCSLP.2016.7918436","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7918436","neural networks;LDA;PLDA;i-vector;speaker recognition","Artificial neural networks;Measurement;Training;Transforms;Noise reduction;Feature extraction","Gaussian distribution;learning (artificial intelligence);neural nets;signal classification;speaker recognition","neural networks;channel compensation;i-vector speaker verification;linear discriminant analysis;Gaussian probabilistic LDA;PLDA;linear transformation;Gaussian distribution;NN;channel compensation methods;deep metric learning;NN classifier;deep denoising autoencoder","","","","24","","4 May 2017","","","IEEE","IEEE Conferences"
"Nonlinear Cross-Domain Feature Representation Learning Method Based on Dual Constraints","H. Ding; Y. Zhang; S. Yang; Y. Lin","Key Laboratory of Knowledge Engineering with Big Data, (Hefei University of Technology), Ministry of Education School of Computer Science and Information Engineering Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, (Hefei University of Technology), Ministry of Education School of Computer Science and Information Engineering Hefei University of Technology, Hefei, China; Key Laboratory of Knowledge Engineering with Big Data, (Hefei University of Technology), Ministry of Education School of Computer Science and Information Engineering Hefei University of Technology, Hefei, China; Key Laboratory of Data Science and Intelligence Application, Fujian Province University, Zhangzhou, China","2019 IEEE International Conference on Big Knowledge (ICBK)","30 Dec 2019","2019","","","66","72","Feature representation learning is a research focus in domain adaptation. Recently, due to the fast training speed, the marginalized Denoising Autoencoder (mDA) as a standing deep learning model has been widely utilized for feature representation learning. However, the training of mDA suffers from the lack of nonlinear relationship and does not explicitly consider the distribution discrepancy between domains. To address these problems, this paper proposes a novel method for feature representation learning, namely Nonlinear cross-domain Feature learning based Dual Constraints (NFDC), which consists of kernelization and dual constraints. Firstly, we introduce kernelization to effectively extract nonlinear relationship in feature representation learning. Secondly, we design dual constraints including Maximum Mean Discrepancy (MMD) and Manifold Regularization (MR) in order to minimize distribution discrepancy during the training process. Experimental results show that our approach is superior to several state-of-the-art methods in domain adaptation tasks.","","978-1-7281-4607-2","10.1109/ICBK.2019.00017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944645","Domain Adaptation;Feature Representation Learning;Kernelization;Maximum Mean Discrepancy;Manifold Regularization","Noise reduction;Manifolds;Training;Adaptation models;Kernel;Deep learning;Feature extraction","feature extraction;learning (artificial intelligence)","domain adaptation tasks;training process;manifold regularization;maximum mean discrepancy;kernelization;distribution discrepancy;marginalized denoising autoencoder;nonlinear relationship;standing deep learning model;dual constraints;Nonlinear cross-domain Feature representation learning method","","","","30","IEEE","30 Dec 2019","","","IEEE","IEEE Conferences"
"Deep Learning Features for Modeling Perceptual Similarity in Microcalcification Lesion Retrieval","J. Wang; L. Lei; Y. Yang","Department of Electrical and Computer Engineering, Illinois Institute of Technology, Chicago, IL, USA; School of Intelligent Tech. and Engineering, Chongqing University of Science and Technology, Chongqing, China; Department of Electrical and Computer Engineering, Illinois Institute of Technology, Chicago, IL, USA","2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)","22 May 2020","2020","","","1486","1489","Retrieving cases with similar image features has been found to be effective for improving the diagnostic accuracy of microcalcification (MC) lesions in mammograms. However, a major challenge in such an image-retrieval approach is how to determine a retrieved lesion image has diagnostically similar features to that of a query case. We investigate the feasibility of modeling perceptually similar MC lesions by using deep learning features extracted from two types of deep neural networks, of which one is a supervised-learning network developed for the task of MC detection and the other is a denoising autoencoder network. In the experiments, the deep learning features were compared against the perceptual similarity scores collected from a reader study on 1,000 MC lesion image pairs. The results indicate that the deep learning features can potentially be more effective for modelling the notion of perceptual similarity of MC lesions than traditional handcrafted texture features.","1945-8452","978-1-5386-9330-8","10.1109/ISBI45749.2020.9098521","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9098521","Clustered microcalcifications;content-based image retrieval;deep learning features","Lesions;Feature extraction;Machine learning;Mammography;Detectors;Training","feature extraction;image classification;image retrieval;image texture;learning (artificial intelligence);mammography;medical image processing;neural nets","deep learning features;modeling perceptual similarity;microcalcification lesion retrieval;similar image features;microcalcification lesions;image-retrieval approach;retrieved lesion image;deep neural networks;supervised-learning network;perceptual similarity scores;traditional handcrafted texture features;MC lesion image pairs;mammograms;denoising autoencoder network","","","","14","","22 May 2020","","","IEEE","IEEE Conferences"
"Exploring a Deeper Convolutional Neural Network Architecture with high dropout for Motor Imagery BCI Decoding","R. Alami; A. Partovi; F. Goodarzy","Monash University,Faculty of Information Technology,Melbourne,Australia; The University of Melbourne,Department of Biomedical Engineering,Melbourne,Australia; The University of Melbourne,Department of Medicine,Melbourne,Australia","2021 9th International Winter Conference on Brain-Computer Interface (BCI)","5 Apr 2021","2021","","","1","5","In recent years, brain-computer interfaces (BCI) have gained lots of popularity as an assistive method for individuals with disabilities to regain their communication or mobility and interact with the world more naturally. The utility of such systems rely on their accuracy in decoding user intentions. In this research, we build on previous BCI research that explored CNN models for decoding motor imagery tasks. Inspired by denoising autoencoders, we introduce a deeper CNN model with very high drop out rates that performs better at motor imagery tasks by reducing the effects of EEG data artefacts on the decoder. We tested the model on a hand squeeze data-set where our model has outperformed the previous best classifiers. Additionally, given the deeper nature of this model, we have explored its limitations by comparing its performance as both the individual sample size and the number of training data change.","2572-7672","978-1-7281-8485-2","10.1109/BCI51272.2021.9385323","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9385323","EEG decoding;motor imagery;Deep learning;CCN;BCI;BMI","Training;Brain modeling;Electroencephalography;Data models;Brain-computer interfaces;Decoding;Task analysis","brain-computer interfaces;electroencephalography;learning (artificial intelligence);medical signal processing;neural nets;signal classification","deeper convolutional neural network architecture;high dropout;motor imagery BCI decoding;brain-computer interfaces;assistive method;user intentions;previous BCI research;CNN models;motor imagery tasks;denoising autoencoders;deeper CNN model;high drop;EEG data artefacts;decoder;hand squeeze data-set;previous best classifiers;deeper nature;individual sample size","","","","13","","5 Apr 2021","","","IEEE","IEEE Conferences"
"Deep Transfer Collaborative Filtering with Geometric Structure Preservation for Cross-Domain Recommendation","Y. Kang; S. Gai; F. Zhao; D. Wang; A. Tang","Westlake Institute for Advanced Study, Hangzhou, China; Westlake Institute for Advanced Study, Hangzhou, China; Westlake Institute for Advanced Study, Hangzhou, China; Westlake Institute for Advanced Study, Hangzhou, China; WeCar (Shenzhen) Technology Co., Ltd., Shenzhen, China","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","8","Collaborative filtering (CF) is one of the most effective approaches for recommender systems by exploiting user-item behavior interactions. However, in real applications, the rating matrix is usually sparse, causing a poor performance. Numerous CF methods tend to incorporate the side information for the enrichment of priors. Cross-domain recommendation is an alternative to alleviate these two problems by referring to the knowledge of relevant domains. Due to the sparsity of the ratings and side information, the resulting latent factors might not be effective as expected. In this paper, we incorporate both the side information and deep knowledge transfer in CF models. A general architecture of deep transfer collaborative filtering with geometry preservation (DTCFGP) is proposed by integrating cross-domain collective matrix factorization, deep feature learning and the graph modeling. We exhibit a instantiations of our architecture by employing non-negative matrix tri-factorization and stacked denoising autoencoder (SDAE) in both source and target domains, where the common latent factors are taken as a bridge between domains due to its across-domain stability and data geometric structure is evaluated by using a nearest neighbor graph modeling. Extensive experiments on various real-world datasets demonstrate the effectiveness of our proposed approach in comparison to state-of-the-art approaches.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9207009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207009","recommendation;collaborative filtering;deep learning;transfer learning;non-negative matrix tri-factorization","Matrix decomposition;Collaboration;Machine learning;Sparse matrices;Knowledge transfer;Bridges;Bayes methods","collaborative filtering;graph theory;matrix decomposition;nearest neighbour methods;recommender systems","target domains;common latent factors;across-domain stability;data geometric structure;deep transfer collaborative filtering;geometric structure preservation;cross-domain recommendation;recommender systems;user-item behavior interactions;rating matrix;latent factors;deep knowledge transfer;CF models;geometry preservation;cross-domain collective matrix factorization;deep feature learning;nonnegative matrix tri-factorization;stacked denoising autoencoder;nearest neighbor graph modeling","","","","46","","28 Sep 2020","","","IEEE","IEEE Conferences"
"Fast Probabilistic TTC Assessment Based on Copula Theory and Deep Ensemble Learning","S. Zhang; J. Yan; X. Li; D. Yang; H. Ma; C. Li","Key Laboratory of Power System Intelligent Dispatch and Control, Ministry of Education, Shandong University, Jinan, Shandong, China; Key Laboratory of Power System Intelligent Dispatch and Control, Ministry of Education, Shandong University, Jinan, Shandong, China; State Grid Shandong Electric Power Company, Jinan, Shandong, China; State Grid Shandong Electric Power Company, Electric Power Research Institute, Jinan, Shandong, China; State Grid Shandong Electric Power Company, Electric Power Research Institute, Jinan, Shandong, China; Key Laboratory of Power System Intelligent Dispatch and Control, Ministry of Education, Shandong University, Jinan, Shandong, China","2022 7th Asia Conference on Power and Electrical Engineering (ACPEE)","1 Jun 2022","2022","","","2096","2100","Wind power integration makes the uncertainty of power system increasing dramatically, which brings new challenges to the calculation of Total Transfer Capability (TTC). A fast assessment method for probabilistic TTC based on Copula and deep ensemble learning is proposed. Considering wind power output uncertainties and correlation of wind speed in geographical close wind farms, Copula function is adopted to generate scenarios. Stacked Denoising Autoencoder (SDAE) is used to extract features directly from source data. Support Vector Regression (SVR) is selected as regressor and bagging ensemble strategy is applied to further improve the accuracy of the TTC estimation. The case study in simplified Shandong grid validates the effectiveness of the proposed method.","","978-1-6654-1819-5","10.1109/ACPEE53904.2022.9783751","National Science Foundation; Shandong University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9783751","total transfer capability;wind power farm;Copula theory;correlation;deep learning;ensemble learning","Support vector machines;Correlation;Uncertainty;Wind speed;Simulation;Wind power generation;Wind farms","deep learning (artificial intelligence);power engineering computing;power grids;probability;regression analysis;support vector machines;wind power plants","Copula theory;deep ensemble learning;wind power integration;power system;total transfer capability;wind power output uncertainties;wind speed;geographical close wind farms;stacked denoising autoencoder;bagging ensemble strategy;probabilistic TTC assessment;SDAE;support vector regression;SVR;Shandong grid","","","","12","IEEE","1 Jun 2022","","","IEEE","IEEE Conferences"
"Short-term Voltage Stability Assessment of AC/DC Power Grid based on SDAE and ADAM Algorithms","L. Li; Q. Lin; H. Qu; B. Liu; Y. Zhu; C. Li; Y. Lui","State Grid Jinan Power Supply Company, Jinan, China; State Grid Jinan Power Supply Company, Jinan, China; State Grid Jinan Power Supply Company, Jinan, China; State Grid Jinan Power Supply Company, Jinan, China; Key Laboratory of Power System Intelligent Dispatch and Control of Ministry of Education, Shandong University, Jinan, China; Key Laboratory of Power System Intelligent Dispatch and Control of Ministry of Education, Shandong University, Jinan, China; Key Laboratory of Power System Intelligent Dispatch and Control of Ministry of Education, Shandong University, Jinan, China","2020 IEEE/IAS Industrial and Commercial Power System Asia (I&CPS Asia)","29 Sep 2020","2020","","","774","778","With the development of HVDC transmission and changes of load composition and characteristics, the short-term voltage problem seriously threatens the safety and stable operation of power systems. A short-term voltage stability assessment method based on deep learning neural network for AC/DC receiving-end power grid is proposed in this paper. The stacked denoising autoencoder (SDAE) and adaptive moment estimation (ADAM) algorithms are used to build a rapid evaluation model, and the training sample set is used to train the transient voltage stability rapid evaluation model. The steady-state power flow features are used as inputs and an index of quantifying short-term voltage stability of commutation bus is utilized as the output. Simulation results of real multi-infeed AC/DC power grid demonstrate the effectiveness of the proposed method.","","978-1-7281-4303-3","10.1109/ICPSAsia48933.2020.9208541","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9208541","AC/DC power grid;SDAE;short-term voltage stability;deep learning;deep learning neural network","Power system stability;Power grids;Transient analysis;Stability criteria;Training","AC-DC power convertors;learning (artificial intelligence);load flow;neural nets;power engineering computing;power grids;power system transient stability;power transmission faults","power systems;short-term voltage stability assessment;deep learning neural network;SDAE algorithms;training sample set;transient voltage stability;steady-state power flow;ADAM algorithms;load composition;short-term voltage problem;rapid evaluation model;HVDC transmission;AC-DC receiving-end power grid;stacked denoising autoencoder;adaptive moment estimation algorithms;commutation bus;real multiinfeed AC-DC power grid","","","","11","","29 Sep 2020","","","IEEE","IEEE Conferences"
"Path Asymmetry Reconstruction via Deep Learning","N. Alhashmi; N. Almoosa; G. Gianini","EBTIC, Khalifa University, Abu Dhabi, UAE; EBTIC, Khalifa University, Abu Dhabi, UAE; EBTIC/Khalifa University, Abu Dhabi Università degli Studi di Milano, Milano, Italy","2022 IEEE 21st Mediterranean Electrotechnical Conference (MELECON)","3 Aug 2022","2022","","","1171","1176","This paper proposes a novel scheme to enhance the accuracy of packet-switched network synchronization systems by estimating path asymmetry (PA) using convolutional denoising autoencoders (CDAEs). Network synchronization is a key enabler of several emerging applications, with increasingly tight accuracy requirements especially for 5G. Path asymmetry, which arises due to physical and stochastic network conditions, severely degrades synchronization accuracy. In this paper, we propose a novel technique based on the IEEE Precision Time Protocol (PTP), which accurately reconstructs PA information from PTP packets. The proposed PA estimator can be integrated with existing synchronization systems as a pre-processing method to enhance the overall performance. Simulation results using industry-standard traffic profiles demonstrate significant improvements in PA estimation accuracy compared to the state of the art.","2158-8481","978-1-6654-4280-0","10.1109/MELECON53508.2022.9842892","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842892","Time Synchronization;IEEE 1588 Precision Time Protocol;PTP;Path Asymmetry;Machine Learning;Deep Learning","Deep learning;Industries;Protocols;Convolution;Simulation;Noise reduction;Estimation","deep learning (artificial intelligence);packet switching;protocols;switching networks;synchronisation;telecommunication computing;telecommunication traffic","Path asymmetry reconstruction;deep learning;packet-switched network synchronization systems;convolutional denoising autoencoders;physical network conditions;stochastic network conditions;synchronization accuracy;IEEE Precision Time Protocol;PA information;PTP packets;PA estimation accuracy;CDAEs;5G;pre-processing method;industry-standard traffic profiles","","","","36","IEEE","3 Aug 2022","","","IEEE","IEEE Conferences"
"A Nonintrusive Load Monitoring Based on Multi-Target Regression Approach","B. Buddhahai; S. Makonin","Walailak University International College, Walailak University, Tha Sala, Nakhon Si Thammarat, Thailand; School of Engineering Science, Simon Fraser University, Burnaby, BC, Canada","IEEE Access","17 Dec 2021","2021","9","","163033","163042","This paper proposes an experimental design process for the application of energy disaggregation using multi-target regression, a new data learning approach in this application area. The approach shows to be a suitable model for dealing with energy disaggregation problems in which the task is to predict multiple appliances usage from the aggregate data. The experiments were conducted by analyzing AMPds2 and ECO public data sets for verifying the effectiveness of the approach. The data were analyzed through the machine learning process to select the optimal set of electrical features, learning algorithm, and model parameter so that the system resulting from the process could deliver the optimal performance for loads inference. Results of the data learning showed that the electrical features set of current ( $I$ ), real power ( $P$ ), reactive power ( $Q$ ), and power factor (PF) for the aggregate data and Random Forest as the base regressor for multi-target regression model could provide the best disaggregation performance. The overall predictive performance of disaggregation accuracy and F-score outperformed the benchmarking Super State Hidden Markov Model (SSHMM) and Denoising Autoencoder (DAE) network approaches.","2169-3536","","10.1109/ACCESS.2021.3133292","Research Grants from the Walailak University Research Fund(grant numbers:WU64203); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9638625","Home energy monitoring;machine learning process;multi-target regression;nonintrusive load monitoring","Hidden Markov models;Data models;Home appliances;Data aggregation;Predictive models;Load modeling;Task analysis","hidden Markov models;load monitoring;neural nets;power factor;random forests;reactive power;regression analysis","reactive power;power factor;nonintrusive load monitoring;multitarget regression approach;energy disaggregation problems;ECO public data sets;machine learning process;data learning approach;analyzing AMPds2;learning algorithm;real power;random forest;benchmarking super state hidden markov model;denoising autoencoder network approaches","","","","43","CCBY","6 Dec 2021","","","IEEE","IEEE Journals"
"Network Traffic Classification Based on Domain Adaptive Migration for Multimedia Services in Smart City Networks","B. Gao; Y. Yang; Z. Gao; L. Zhao; Z. Wang; D. Cui","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; China Xiong'an Group Digital City Technology Co., Ltd, Xiong'an, China; China Xiong'an Group Digital City Technology Co., Ltd, Xiong'an, China; China Xiong'an Group Digital City Technology Co., Ltd, Xiong'an, China","2022 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)","25 Jul 2022","2022","","","1","6","Network traffic classification is a key technology for multimedia service management in smart city networks, which is of great significance to broadcast applications to smart cities. According to the characteristics of different network traffic to ensure the full utilization of broadband resources and improve the quality of network service. Due to the wide application of dynamic port number and stream encryption technology, the traditional network traffic classification method based on port number and deep packet inspection is no longer effective. In recent years, machine learning methods can be used to accurately identify categories of network traffic applications by labeled data. However, collecting enough labeled network traffic data is a time-consuming and difficult task, and the distribution of traffic data collected in various networks is different. In order to solve the problem of insufficient labeled samples and domain distribution differences, a network traffic classification method based on domain adaptive migration is proposed in this paper. This paper designs a new domain adaptive method, which reduces distribution differences between domains, makes the distribution of samples under the same category more compact and different application categories more separated. Then migrate the feature extraction module to the target domain. And the unlabeled data and few labeled samples are utilized to jointly classify network traffic applications using a siamese sparse denoising stacked autoencoder. Experimental results show that compared with other algorithms, the network traffic classification algorithm proposed in this paper achieves the best result.","2155-5052","978-1-6654-6901-2","10.1109/BMSB55706.2022.9828638","National Key R&D Program of China(grant numbers:2019YFB2103202); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9828638","network traffic classification;domain adaptation;AI for advanced multimedia service management;broadcast applications to smart cities","Digital multimedia broadcasting;Adaptive systems;Smart cities;Noise reduction;Supervised learning;Telecommunication traffic;Classification algorithms","computer network management;cryptography;feature extraction;learning (artificial intelligence);multimedia systems;neural nets;pattern classification;service-oriented architecture;smart cities","domain adaptive migration;smart city networks;multimedia service management;network service quality;dynamic port number;labeled network traffic data;domain distribution differences;network traffic classification algorithm;broadband resource utilization;stream encryption technology;deep packet inspection;machine learning;feature extraction module;siamese sparse denoising stacked autoencoder","","","","10","IEEE","25 Jul 2022","","","IEEE","IEEE Conferences"
"The Text Captcha Solver: A Convolutional Recurrent Neural Network-Based Approach","Z. Dou","University of New South Wales, UNSW, Sydney","2021 International Conference on Big Data Analysis and Computer Science (BDACS)","23 Aug 2021","2021","","","273","283","Although several different attacks or modern security mechanisms have been proposed, the captchas created by the numbers and the letters are still used by some websites or applications to protect their information security. The reason is that the labels of the captcha data are difficult to collect for the attacker, and protector can easily control the various parameters of the captchas: like the noise, the font type, the font size, and the background color, then make this security mechanism update with the increased attack methods. It can against attacks in different situations very effectively. This paper presents a method to recognize the different text-based captchas based on a system constituted by the denoising autoencoder and the Convolutional Recurrent Neural Network (CRNN) model with the Connectionist Temporal Classification (CTC) structure. We show that our approach has a better performance for recognizing, and it solves the identification problem of indefinite character length captchas efficiently.","","978-1-6654-2561-2","10.1109/BDACS53596.2021.00067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9516530","Deep learning;CAPTCHA;Convolutional Recurrent neural network;Connectionist Temporal Classification","Recurrent neural networks;Image color analysis;Noise reduction;Information security;Internet;Character recognition;Optical character recognition software","convolutional neural nets;human computer interaction;image classification;recurrent neural nets;security of data;text detection","text captcha solver;modern security mechanisms;information security;captcha data;font type;font size;background color;security mechanism update;increased attack methods;text-based captchas;convolutional recurrent neural network model;indefinite character length captchas;connectionist temporal classification structure;convolutional recurrent neural network-based approach;denoising autoencoder;CTC structure;identification problem","","","","28","","23 Aug 2021","","","IEEE","IEEE Conferences"
"Automatic change detection based on conditional random field in high resolution remote sensing images","G. Cao; X. Li; Y. Shang","The School of Computer Science and Technology, Nanjing University of Science and Technology, Nanjing, China; The School of Computer Science and Technology, Nanjing University of Science and Technology, Nanjing, China; The third research institute of ministry of public security, Shanghai, China","2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","3 Nov 2016","2016","","","2403","2406","An automatic change detection method based on conditional random field (CRF) is presented for high resolution remote sensing images in this paper. Marginalized denoising autoencoder is used to generate the difference image. The clustering results of Fuzzy C-means are applied to initialize the unary potentials of CRF. A scaled squared Euclidean distance between neighboring pixels in the observed images is introduced to define the pairwise potentials of CRF, which avoid training parameters and help improve the accuracy and the degree of automation. The experimental results obtained on different remote sensing images demonstrated the accuracy and efficiency of our proposed method.","2153-7003","978-1-5090-3332-4","10.1109/IGARSS.2016.7729620","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7729620","Change detection;conditional random field;fuzzy C-means (FCM);remote sensing image","Remote sensing;Change detection algorithms;Training;Classification algorithms;Labeling;Image resolution;Kernel","fuzzy reasoning;geophysical image processing;remote sensing","automatic change detection;conditional random field;high resolution remote sensing images;marginalized denoising autoencoder;Fuzzy C-means;scaled squared Euclidean distance","","","","10","","3 Nov 2016","","","IEEE","IEEE Conferences"
"Speech Gesture Generation from Acoustic and Textual Information using LSTMs","A. Thangthai; K. Thangthai; A. Namsanit; S. Thatphithakkul; S. Saychum","Speech and Text Understanding Research Team, National Electronics and Computer Technology Center (NECTEC), Thailand; Speech and Text Understanding Research Team, National Electronics and Computer Technology Center (NECTEC), Thailand; Speech and Text Understanding Research Team, National Electronics and Computer Technology Center (NECTEC), Thailand; Speech and Text Understanding Research Team, National Electronics and Computer Technology Center (NECTEC), Thailand; Speech and Text Understanding Research Team, National Electronics and Computer Technology Center (NECTEC), Thailand","2021 18th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)","18 Jun 2021","2021","","","718","723","This paper presents a gesture generation system developed for the generation and evaluation of non-verbal behaviour for embodied agents (GENEA) challenge 2020. The GENEA challenge provides approximately 4 hours of speech corpus, and 3D full-body human motions called the Trinity speech gesture dataset The gesture generation system's input varies from acoustic speech only, text only, acoustic and text, while the expected output is a video of the corresponding 3D motions.The proposed system consists of 2 steps: pre-processing the data and gesture modeling. In the first step, we pre-process the audio and text and stack them together as an input vector. We then pre-process the output of the 3D motion using a representation learning method. We select only 15 joints in the upper part of the body and represent them with a vector learned from the Denoising Autoencoder Networks (DAEs) model. In the second step, we build the gesture model using the encoder-decoder bidirectional LSTM architecture. This model transforms the acoustic speech and textual information into the DAEs output representation. We then decode the DAE representation to generate the 3D motion output video.The system has been evaluated using the held-out dataset and has been compared among nine systems: five participants, two baseline systems, two natural motions (real video). Two subjective evaluation methods, which are human-likeness and appropriateness, have been measured via a crowdsourced system. Our proposed system gets a fair rating score on both subjective evaluation methods.","","978-1-6654-0382-5","10.1109/ECTI-CON51831.2021.9454931","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9454931","gesture motion;gesture generation;encoder-decoder LSTM","Solid modeling;Three-dimensional displays;Noise reduction;Computer architecture;Transforms;Phonetics;Particle measurements","gesture recognition;image motion analysis;learning (artificial intelligence);recurrent neural nets;speech recognition;text analysis;video signal processing","Trinity speech gesture dataset;gesture generation system;acoustic speech;gesture modeling;input vector;representation learning method;encoder-decoder bidirectional LSTM architecture;textual information;DAEs output representation;3D motion output video;baseline systems;natural motions;subjective evaluation methods;crowdsourced system;speech gesture generation;nonverbal behaviour;embodied agents challenge 2020;GENEA challenge;speech corpus;denoising autoencoder network model;3D full-body human motions","","","","17","","18 Jun 2021","","","IEEE","IEEE Conferences"
"Identification and Correction of False Data Injection Attacks against AC State Estimation using Deep Learning","F. ALmutairy; R. Shadid; S. Wshah","Vermont Complex Systems Center, University of Vermont; Applied Science Private University; Vermont Complex Systems Center, University of Vermont","2020 IEEE Power & Energy Society General Meeting (PESGM)","16 Dec 2020","2020","","","1","5","New advances in technology have greatly improved the monitoring and controlling of power networks, but these advances leave the system open to cyber attacks. One common attack is known as a False Data Injection Attacks (FDIAs), which poses serious threats to the operation and control of power grids. Hence, recent literature has proposed various detection and identification methods for FDIAs, but few studies have focused on a solution that would prevent such attacks from occurring. However, great strides have been made using deep learning to detect attacks. Inspired by these advancements, we have developed a new methodology for not only identifying AC FDIAs but, more importantly, for correction as well. Our methodology utilizes a Long-Short Term Memory Denoising Autoencoder (LSTM-DAE) to correct attacked-estimated states based on the attacked measurements. The method was evaluated using the IEEE 30 system, and the experiments demonstrated that the proposed method was successfully able to identify the corrupted states and correct them with high accuracy.","1944-9933","978-1-7281-5508-1","10.1109/PESGM41954.2020.9282037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9282037","","Deep learning;Noise reduction;Power grids;Data models;State estimation;Monitoring;Load modeling","learning (artificial intelligence);power grids;power system security;power system state estimation;recurrent neural nets;security of data","deep learning;power networks;common attack;False Data Injection Attacks;power grids;AC FDIAs;attacked-estimated states;attacked measurements;AC state estimation;cyber attacks;Long-Short Term Memory Denoising Autoencoder","","","","23","","16 Dec 2020","","","IEEE","IEEE Conferences"
"Estimating Evaluation of Cosmetics Reviews with Machine Learning Methods","Q. Ma; M. Tsukagoshi; M. Murata","Dept. Applied Mathematics and Informatics, Ryukoku University, Otsu, Japan; Dept. Applied Mathematics and Informatics, Ryukoku University, Otsu, Japan; Dept. Information and Electronics, Tottori University, Tottori, Japan","2020 International Conference on Asian Language Processing (IALP)","7 Jan 2021","2020","","","259","263","This paper presents methods for estimating evaluation of cosmetics reviews, i.e., for assigning scores to cosmetics reviews, by using three kinds of machine learning methods: support vector machine (SVM), stacked denoising autoencoder (SdA), and convolutional neural network (CNN). The experimental results show that (1) using words with various parts of speech (POSs), not only nouns, as features in vectorizing review text is effective, (2) selecting features on the basis of dependency analysis is effective, (3) the three machine learning methods have almost the same estimation precision and are much higher than a rule-based baseline method, and (4) the training cost of SVM is extremely lower than the other two methods, and SVM therefore performs the best among the three methods.","","978-1-7281-7689-5","10.1109/IALP51396.2020.9310471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9310471","cosmetics review;evaluation;machine learning;dependency analysis","Skin;Support vector machines;Machine learning;Feature extraction;Training;Transforms;Proposals","convolutional neural nets;cosmetics;learning (artificial intelligence);review sites;support vector machines;text analysis","cosmetics reviews;machine learning methods;support vector machine;SVM;convolutional neural network;review text;estimation precision;rule-based baseline method;stacked denoising autoencoder;SdA;CNN;parts of speech;POSs;dependency analysis","","","","12","","7 Jan 2021","","","IEEE","IEEE Conferences"
"QoS Prediction for Service Recommendation With Features Learning in Mobile Edge Computing Environment","Y. Yin; Z. Cao; Y. Xu; H. Gao; R. Li; Z. Mai","Key Laboratory of Complex Systems Modeling and Simulation of Ministry of Education, Hangzhou, China; School of Computer, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science and Technology, Xidian University, Xi’an, China; School of Computer Engineering and Science, Shanghai University, Shanghai, China; School of Computer Science and Technology, Xidian University, Xi’an, China; Xanten Guangdong Development Company Ltd., Foshan, China","IEEE Transactions on Cognitive Communications and Networking","8 Dec 2020","2020","6","4","1136","1145","In recent years, deep neural networks have achieved exciting results in a variety of tasks, and many fields try to introduce neural network techniques. In mobile edge computing, there are not many attempts that build neural network models in service recommendation or QoS (quality-of-service) prediction. The method proposed in this article is an attempt to employ neural network technique for QoS prediction. Compared to the pure use of QoS records, the exploration for context information in QoS prediction also still needs a lot of efforts. But an increasing number of features are highly likely to result in overfitting problem, especially in the case that the data size is small. To solve those problems, in this article, we propose several new techniques, including denoising auto-encoder with fuzzy clustering (DAFC) and recombination embedding network, focusing on how to use context information and how to alleviate overfitting problem. DAFC uses the denoising auto-encoder, which helps the fuzzy clustering algorithm overcome the defect that the performance is easy to be impacted by the number of clusters. Extensive experiments under different data densities show that these two network structures indeed improve the performance and reduce the overfitting problem.","2332-7731","","10.1109/TCCN.2020.3027681","Natural Science Foundation of China(grant numbers:61902236,61702391,61502374); Natural Science Foundation of Shaanxi Province(grant numbers:2018JQ6050); Fundamental Research Funds for the Provincial Universities of Zhejiang(grant numbers:GK199900299012-025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9209192","Service recommendation;QoS prediction;fuzzy clustering;features learning;mobile edge computing","Quality of service;Neural networks;Computational modeling;Noise reduction;Collaboration;Clustering algorithms;Edge computing","collaborative filtering;fuzzy set theory;learning (artificial intelligence);mobile computing;neural nets;pattern clustering;quality of service;recommender systems","network structures;overfitting problem;QoS prediction;service recommendation;features learning;mobile edge computing environment;deep neural networks;neural network technique;neural network models;quality-of-service;QoS records;context information;recombination embedding network;DAFC;denoising autoencoder with fuzzy clustering;performance improvement","","41","","29","IEEE","29 Sep 2020","","","IEEE","IEEE Journals"
"A predictive model of gene expression using a deep learning framework","Rui Xie; A. Quitadamo; J. Cheng; Xinghua Shi","Department of Computer Science, University of Missouri at Columbia, Columbia, MO, USA; Department of Bioinformatics and Genomics, University of North Carolina at Charlotte, Charlotte, NC, USA; Department of Computer Science, University of Missouri at Columbia, Columbia, MO, USA; Department of Bioinformatics and Genomics, University of North Carolina at Charlotte, Charlotte, NC, USA","2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","19 Jan 2017","2016","","","676","681","With an unprecedented amount of data available, it is important to explore new methods for developing predictive models to mine this data for scientific discoveries. In this study, we propose a deep learning regression model based on MultiLayer Perceptron and Stacked Denoising Auto-encoder (MLP-SAE) to predict gene expression from genotypes of genetic variation. Specifically, we use a stacked denoising auto-encoder to train our regression model in order to extract useful features, and utilize the multilayer perceptron for backpropagation. We further improve our model by adding a dropout technique to prevent overfitting. Our results on a real genomic dataset show that our MLP-SAE model with dropout outperform Lasso, Random Forests, and MLP-SAE without dropout. Our study provides a new application of deep learning in mining genomics data, and demonstrates that deep learning has great potentials in building predictive models to help understand biological systems.","","978-1-5090-1611-2","10.1109/BIBM.2016.7822599","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822599","","Predictive models;Mathematical model;Gene expression;Training;Machine learning;Data models","backpropagation;biology computing;data mining;feature extraction;genetics;genomics;multilayer perceptrons;regression analysis","gene expression;deep learning regression model;multilayer perceptron;stacked denoising autoencoder;genetic variation genotypes;feature extraction;backpropagation;genomic dataset;MLP-SAE model;dropout technique;genomics data mining;biological systems","","3","","54","","19 Jan 2017","","","IEEE","IEEE Conferences"
"High Dynamic Range Imaging Using Deep Image Priors","G. Jagatap; C. Hegde",Iowa State University; Iowa State University,"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","9289","9293","Traditionally, dynamic range enhancement for images has involved a combination of contrast improvement (via gamma correction or histogram equalization) and a denoising operation to reduce the effects of photon noise. More recently, modulo-imaging methods have been introduced for high dynamic range photography to significantly expand dynamic range at the sensing stage itself. The transformation function for both of these problems is highly non-linear, and the image reconstruction procedure is typically non-convex and ill-posed. A popular recent approach is to regularize the above inverse problem via a neural network prior (such as a trained autoencoder), but this requires extensive training over a dataset with thousands of paired regular/HDR image data samples.In this paper, we introduce a new approach for HDR image reconstruction using neural priors that require no training data. Specifically, we employ deep image priors, which have been successfully used for imaging problems such as denoising, super-resolution, inpainting and compressive sensing with promising performance gains over conventional regularization techniques. In this paper, we consider two different approaches to high dynamic range (HDR) imaging - gamma encoding and modulo encoding - and propose a combination of deep image prior and total variation (TV) regularization for reconstructing low-light images. We demonstrate the significant improvement achieved by both of these approaches as compared to traditional dynamic range enhancement techniques.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9054218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054218","Deep image prior;untrained neural networks;convolutional networks;low-light enhancement;HDR imaging;inverse imaging;modulo camera","Training;Image coding;Noise reduction;Neural networks;Training data;Dynamic range;Image reconstruction","image coding;image denoising;image enhancement;image reconstruction;image resolution;image sampling;inverse problems;learning (artificial intelligence);neural nets;photography","dynamic range enhancement techniques;low-light images;modulo encoding;gamma encoding;compressive sensing;imaging problems;training data;neural priors;HDR image reconstruction;inverse problem;ill-posed problem;image reconstruction procedure;high dynamic range photography;modulo-imaging methods;gamma correction;deep image priors;high dynamic range imaging","","","","38","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Abnormal Driving Detection With Normalized Driving Behavior Data: A Deep Learning Approach","J. Hu; X. Zhang; S. Maybank","College of Computer Science and Artificial Intelligence, Institute of Big Data and Information Technology, Wenzhou University, Wenzhou, China; College of Computer Science and Artificial Intelligence, Institute of Big Data and Information Technology, Wenzhou University, Wenzhou, China; School of Computer Science and Information Systems, Birkbeck College, London, U.K.","IEEE Transactions on Vehicular Technology","15 Jul 2020","2020","69","7","6943","6951","Abnormal driving may cause serious danger to both the driver and the public. Existing detectors of abnormal driving behavior are mainly based on shallow models, which require large quantities of labeled data. The acquisition and labelling of abnormal driving data are, however, difficult, labor-intensive and time-consuming. This situation inspires us to rethink the abnormal driving detection problem and to apply deep architecture models. In this study, we establish a novel deep-learning-based model for abnormal driving detection. A stacked sparse autoencoders model is used to learn generic driving behavior features. The model is trained in a greedy layer-wise fashion. As far as the authors know, this is the first time that a deep learning approach is applied using autoencoders as building blocks to represent driving features for abnormal driving detection. In addition, a method for denoising is added to the algorithm to increase the robustness of feature expression. The dropout technology is introduced into the entire training process to avoid overfitting. Experiments carried out on our self-created driving behavior dataset demonstrate that the proposed scheme achieves a superior performance for abnormal driving detection compared to the state-of-the-art.","1939-9359","","10.1109/TVT.2020.2993247","National Natural Science Foundation of China(grant numbers:61922064); Natural Science Foundation of Zhejiang Province(grant numbers:LR17F030001,LQ18F030010,LQ19F020005); Project of Science and Technology Plans of Wenzhou City(grant numbers:C20170008,G20150017,ZG2017016,G20170010); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9090320","Abnormal driving detection;deep learning;stacked autoencoder","Vehicles;Machine learning;Feature extraction;Data models;Adaptation models;Biological system modeling;Acceleration","behavioural sciences computing;feature extraction;learning (artificial intelligence);traffic engineering computing","deep learning approach;driving features;normalized driving behavior data;abnormal driving behavior;abnormal driving data;abnormal driving detection problem;deep architecture models;deep-learning-based model;generic driving behavior features;self-created driving behavior dataset","","17","","36","IEEE","8 May 2020","","","IEEE","IEEE Journals"
"Low Dose Abdominal CT Image Reconstruction: An Unsupervised Learning Based Approach","S. Kuanar; V. Athitsos; D. Mahapatra; K. R. Rao; Z. Akhtar; D. Dasgupta","Department of Electrical, University of Texas, Arlington, TX, USA; Department of Computer Science Engineering, University of Texas, Arlington, TX, USA; IBM Research, Melbourne, VIC, Australia; Department of Electrical, University of Texas, Arlington, TX, USA; Department of Computer Science, University of Memphis, Memphis, TN, USA; Department of Computer Science, University of Memphis, Memphis, TN, USA","2019 IEEE International Conference on Image Processing (ICIP)","26 Aug 2019","2019","","","1351","1355","In medical practice, the X-ray Computed tomography-based scans expose a high radiation dose and lead to the risk of prostate or abdomen cancers. On the other hand, the low-dose CT scan can reduce radiation exposure to the patient. But the reduced radiation dose degrades image quality for human perception, and adversely affects the radiologist's diagnosis and prognosis. In this paper, we introduce a GAN based auto-encoder network to de-noise the CT images. Our network first maps CT images to low dimensional manifolds and then restore the images from its corresponding manifold representations. Our reconstruction algorithm separately calculates perceptual similarity, learns the latent feature maps, and achieves more accurate and visually pleasing reconstructions. We also showed the effectiveness of our model on a number of patient abdomen CT images, and compare our results with existing deep learning and iterative reconstruction methods. Experimental results demonstrate that our model outperforms other state-of-the-art methods in terms of PSNR, SSIM, and statistical properties of the image regions. https://github.com/ShibaPrasad/CT-Image-Reconstruction.","2381-8549","978-1-5386-6249-6","10.1109/ICIP.2019.8803037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8803037","Auto-encoder;Low dose CT Image;De-noise;Manifold;and GAN","Computed tomography;Image reconstruction;Manifolds;Feature extraction;Generators;Convolution;X-ray imaging","cancer;computerised tomography;image denoising;image reconstruction;iterative methods;medical image processing;statistical analysis;unsupervised learning","statistical properties;X-ray computed tomography-based scans;GAN based autoencoder network;abdomen cancers;unsupervised learning;low dose abdominal CT image reconstruction;image regions;iterative reconstruction methods;deep learning;patient abdomen CT images;network first maps CT images;reduced radiation dose;radiation exposure;low-dose CT scan;prostate cancers;high radiation dose","","28","","24","","26 Aug 2019","","","IEEE","IEEE Conferences"
"A deep learning-based segmentation method for brain tumor in MR images","Zhe Xiao; Ruohan Huang; Yi Ding; Tian Lan; RongFeng Dong; Zhiguang Qin; Xinjie Zhang; Wei Wang","School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Information and Software Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; Department of Neurosurgery, Sichuan University, Chengdu, Sichuan, China; Department of Neurosurgery, Sichuan University, Chengdu, Sichuan, China","2016 IEEE 6th International Conference on Computational Advances in Bio and Medical Sciences (ICCABS)","2 Jan 2017","2016","","","1","6","Accurate tumor segmentation is an essential and crucial step for computer-aided brain tumor diagnosis and surgical planning. Subjective segmentations are widely adopted in clinical diagnosis and treating, but they are neither accurate nor reliable. An automatical and objective system for brain tumor segmentation is strongly expected. But they are still facing some challenges such as lower segmentation accuracy, demanding a priori knowledge or requiring the human intervention. In this paper, a novel and new coarse-to-fine method is proposed to segment the brain tumor. This hierarchical framework consists of preprocessing, deep learning network based classification and post-processing. The preprocessing is used to extract image patches for each MR image and obtains the gray level sequences of image patches as the input of the deep learning network. The deep learning network based classification is implemented by a stacked auto-encoder network to extract the high level abstract feature from the input, and utilizes the extracted feature to classify image patches. After mapping the classification result to a binary image, the post-processing is implemented by a morphological filter to get the final segmentation result. In order to evaluate the proposed method, the experiment was applied to segment the brain tumor for the real patient dataset. The final performance shows that the proposed brain tumor segmentation method is more accurate and efficient.","2473-4659","978-1-5090-4199-2","10.1109/ICCABS.2016.7802771","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7802771","Brain tumor segmentation;Brain tumor detection;Computer Aided Diagnosis (CAD);Deep Learning;Stacked Denoising Auto-Encoder (SDAE);Stacked Auto-Encoder (SAE)","Image segmentation;Surgery;Image reconstruction","biomedical MRI;brain;image classification;image segmentation;learning (artificial intelligence);medical image processing;tumours","deep learning-based segmentation method;MR images;computer-aided brain tumor diagnosis;surgical planning;clinical diagnosis;brain tumor segmentation;deep learning network based classification;image patches;gray level sequences;stacked autoencoder network;morphological filter","","14","","33","","2 Jan 2017","","","IEEE","IEEE Conferences"
"Gradient-based learning of higher-order image features","R. Memisevic","Department of Computer Science, University of Frankfurt am Main, Germany","2011 International Conference on Computer Vision","12 Jan 2012","2011","","","1591","1598","Recent work on unsupervised feature learning has shown that learning on polynomial expansions of input patches, such as on pair-wise products of pixel intensities, can improve the performance of feature learners and extend their applicability to spatio-temporal problems, such as human action recognition or learning of image transformations. Learning of such higher order features, however, has been much more difficult than standard dictionary learning, because of the high dimensionality and because standard learning criteria are not applicable. Here, we show how one can cast the problem of learning higher-order features as the problem of learning a parametric family of manifolds. This allows us to apply a variant of a de-noising autoencoder network to learn higher-order features using simple gradient based optimization. Our experiments show that the approach can outperform existing higher-order models, while training and inference are exact, fast, and simple.","2380-7504","978-1-4577-1102-2","10.1109/ICCV.2011.6126419","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6126419","","Computational modeling;Manifolds;Training;Noise reduction;Encoding;Vectors;Decoding","feature extraction;learning (artificial intelligence);object recognition","gradient-based learning;higher-order image features;unsupervised feature learning;polynomial expansions;pair-wise products;pixel intensities;feature learners;spatio-temporal problems;human action recognition;image transformations;higher order features;dictionary learning;higher-order feature learning;denoising autoencoder network;higher-order features;gradient based optimization;training;inference","","27","","34","","12 Jan 2012","","","IEEE","IEEE Conferences"
"Unsupervised surgical data alignment with application to automatic activity annotation","Y. Gao; S. S. Vedula; G. I. Lee; M. R. Lee; S. Khudanpur; G. D. Hager","Department of Computer Science, Johns Hopkins University Whiting, Baltimore, MD, USA; Johns Hopkins University, Baltimore, MD, US; Department of Surgery, School of Medicine, Baltimore, MD, USA; Department of Surgery, School of Medicine, Baltimore, MD, USA; Department of Electrical and Computer Engineering, School of Engineering, Baltimore, MD, USA; Department of Computer Science, Johns Hopkins University Whiting, Baltimore, MD, USA","2016 IEEE International Conference on Robotics and Automation (ICRA)","9 Jun 2016","2016","","","4158","4163","Robotic surgery and other minimally-invasive surgical techniques are an integral part of patient care, and readily yield large amounts of data. Surgical tool motion (kinematic data) contains information that is useful for assessment and education. Typically, assessment and education tools that rely upon the kinematic data require substantial manual processing such as activity annotations. The goal of this paper was to develop an automated method to align surgical recordings and assign activity annotations. We developed an approach based on unsupervised alignment to efficient annotate kinematic data for its constituent activity segments. Our method includes extracting non-linear features from the kinematic data using a stacked de-noising autoencoder, and using modified dynamic time warping to align the kinematic data from different trials of the study task. We combined alignment between a test and one or a small set of template trials (with prior manual annotations) with voting based on kernel density estimation to transfer labels from the template to the test trial. Our experiments on performance of this method using two datasets captured in the training laboratory demonstrate an accuracy of 72% to 94% for annotating activity segments within a surgical training task. Our findings are robust to data captured from several surgeons, and to deviations in activity from a canonical activity sequence.","","978-1-4673-8026-3","10.1109/ICRA.2016.7487608","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7487608","","Surgery;Kinematics;Training;Robots;Robustness;Hidden Markov models;Manuals","feature extraction;medical robotics;patient care;robot kinematics;surgery","canonical activity sequence;surgical training task;activity segment annotation;training laboratory;kernel density estimation;dynamic time warping;stacked denoising autoencoder;nonlinear feature extraction;kinematic data annotation;unsupervised alignment;surgical recordings;activity annotations;education tool;assessment tool;surgical tool motion;patient care;minimally-invasive surgical techniques;robotic surgery;automatic activity annotation;unsupervised surgical data alignment","","9","","20","","9 Jun 2016","","","IEEE","IEEE Conferences"
"Forecasting the weather of Nevada: A deep learning approach","M. Hossain; B. Rekabdar; S. J. Louis; S. Dascalu","Dept of Computer Science and Engineering, University of Nevada, Reno Reno, Nevada; Dept of Computer Science and Engineering, University of Nevada, Reno Reno, Nevada; Dept of Computer Science and Engineering, University of Nevada, Reno Reno, Nevada; Dept of Computer Science and Engineering, University of Nevada, Reno Reno, Nevada","2015 International Joint Conference on Neural Networks (IJCNN)","1 Oct 2015","2015","","","1","6","This paper compares two approaches for predicting air temperature from historical pressure, humidity, and temperature data gathered from meteorological sensors in Northwestern Nevada. We describe our data and our representation and compare a standard neural network against a deep learning network. Our empirical results indicate that a deep neural network with Stacked Denoising Auto-Encoders (SDAE) outperforms a standard multilayer feed forward network on this noisy time series prediction task. In addition, predicting air temperature from historical air temperature data alone can be improved by employing related weather variables like barometric pressure, humidity and wind speed data in the training process.","2161-4407","978-1-4799-1960-4","10.1109/IJCNN.2015.7280812","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280812","","Meteorology;Artificial neural networks;Noise reduction;History","atmospheric humidity;atmospheric temperature;feedforward neural nets;time series;weather forecasting;wind","Nevada weather forecasting;air temperature predictiion;pressure data;humidity data;meteorological sensor;Northwestern Nevada;neural network;deep learning network;stacked denoising autoencoder;multilayer feed forward network;time series prediction task;air temperature data;barometric pressure;wind speed data","","51","1","19","","1 Oct 2015","","","IEEE","IEEE Conferences"
"Adversarial Collaborative Auto-encoder for Top-N Recommendation","F. Yuan; L. Yao; B. Benatallah","Dept. of Computer Sci. and Eng., University of New South Wales, Sydney, Australia; Dept. of Computer Sci. and Eng., University of New South Wales, Sydney, Australia; Dept. of Computer Sci. and Eng., University of New South Wales, Sydney, Australia","2019 International Joint Conference on Neural Networks (IJCNN)","30 Sep 2019","2019","","","1","8","Recently, deep learning-based recommendation models have been proved to have state-of-the-art recommendation accuracy. However, most of the existing work assume that user feedbacks are noise-free, on which the neural networks (NN) are trained. Although some methods apply man-made noises on the input data to train the networks more effectively (e.g. the collaborative denoising auto-encoder), the noises are randomly generated. To gain further improvements, we focus on boosting the overall recommendation performance through adversarial noises. We propose a general framework to adversarially train a NN-based item recommendation model. In particular, we select the collaborative auto-encoder model as an example and test our method on three public datasets. We show that our approach enhances both overall robustness and performance which outperforms competitive state-of-the-art item recommendation models.","2161-4407","978-1-7281-1985-4","10.1109/IJCNN.2019.8851902","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8851902","Recommender Systems;Auto Encoders;Adversarial Training","Collaboration;Training;Robustness;Data models;Artificial neural networks;Noise reduction","groupware;learning (artificial intelligence);neural nets;recommender systems","top-n recommendation;user feedbacks;noise-free;neural networks;collaborative denoising auto-encoder;adversarial noises;deep learning;adversarial collaborative autoencoder;item recommendation model","","9","","35","","30 Sep 2019","","","IEEE","IEEE Conferences"
"Robust Semisupervised Deep Generative Model Under Compound Noise","X. Chen","SAS Institute Inc., Cary, NC 27513 USA (e-mail: steven.xu.chen@gmail.com)","IEEE Transactions on Neural Networks and Learning Systems","","2021","PP","99","1","15","Semisupervised learning has been widely applied to deep generative model such as variational autoencoder. However, there are still limited work in noise-robust semisupervised deep generative model where the noise exists in both of the data and the labels simultaneously, which are referred to as outliers and noisy labels or compound noise. In this article, we propose a novel noise-robust semisupervised deep generative model by jointly tackling the noisy labels and outliers in a unified robust semisupervised variational autoencoder randomized generative adversarial network (URSVAE-GAN). Typically, we consider the uncertainty of the information of the input data in order to enhance the robustness of the variational encoder toward the noisy data in our unified robust semisupervised variational autoencoder (URSVAE). Subsequently, in order to alleviate the detrimental effects of noisy labels, a denoising layer is integrated naturally into the semisupervised variational autoencoder so that the variational inference is conditioned on the corrected labels. Moreover, to enhance the robustness of the variational inference in the presence of outliers, the robust β-divergence measure is employed to derive the novel variational lower bound, which already achieves competitive performance. This further motivates the development of URSVAE-GAN that collapses the decoder of URSVAE and the generator of a robust semisupervised generative adversarial network into one unit. By applying the end-to-end denoising scheme in the joint optimization, the experimental results demonstrate the superiority of the proposed framework by the evaluating on image classification and face recognition tasks and comparing with the state-of-the-art approaches.","2162-2388","","10.1109/TNNLS.2021.3105080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9523628","Joint optimization;overfitting;regularization;robust divergence;variational inference.","Noise measurement;Data models;Semisupervised learning;Uncertainty;Generative adversarial networks;Deep learning;Compounds","","","","","","","IEEE","26 Aug 2021","","","IEEE","IEEE Early Access Articles"
"Multiscale Superpixel Segmentation With Deep Features for Change Detection","Y. Lei; X. Liu; J. Shi; C. Lei; J. Wang","Research and Development Institute, Northwestern Polytechnical University in Shenzhen, Shenzhen, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; Research and Development Institute, Northwestern Polytechnical University in Shenzhen, Shenzhen, China; School of Electronic Engineering, Xidian University, Xi’an, China; 4Xidian University Library, Xidian University, Xi’an, China","IEEE Access","31 Mar 2019","2019","7","","36600","36616","In this paper, a novel change detection technique is proposed based on multiscale superpixel segmentation and stacked denoising autoencoders (SDAE). This approach is designed to achieve superpixel-based change detection, in which the basic analysis unit is between pixel-based and object-based ones. Given two original images, the difference image (DI) is obtained by conventional DI generation methods. Then, we propose a multiscale superpixel segmentation which is guided by the changing degrees estimated from the DI. Different from traditional multiscale superpixel, the proposed multiscale superpixel segmentation is employed in a single map. In the proposed method, SDAE is used to learn the difference representation between bi-temporal superpixels. Bi-temporal superpixels are stacked and fed into SDAE for its pre-training, and then SDAE is fine-tuned according to pseudo labels generated by traditional unsupervised methods. After fine-tuned with back propagation, the SDAE can be used to classify all superpixel pairs into changed or unchanged ones. The experimental results on real remote sensing datasets have demonstrated the effectiveness of the proposed approach.","2169-3536","","10.1109/ACCESS.2019.2902613","Shenzhen Research and Development Foundation(grant numbers:JCYJ20170306153943097); National Natural Science Foundation of China(grant numbers:61603299,61602385); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8657751","Change detection;multiscale superpixel segmentation;deep neural networks;difference representation learning","Image segmentation;Change detection algorithms;Neural networks;Clustering algorithms;Task analysis;Deep learning;Feature extraction","feature extraction;geophysical image processing;image classification;image denoising;image segmentation;learning (artificial intelligence);remote sensing","multiscale superpixel segmentation;novel change detection technique;SDAE;superpixel-based change detection;traditional multiscale superpixel;bi-temporal superpixels;superpixel pairs","","29","","56","OAPA","4 Mar 2019","","","IEEE","IEEE Journals"
"Pose Encoding for Robust Skeleton-Based Action Recognition","G. G. Demisse; K. Papadopoulos; D. Aouada; B. Ottersten","Interdisciplinary Center for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Interdisciplinary Center for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Interdisciplinary Center for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Interdisciplinary Center for Security, Reliability and Trust, University of Luxembourg, Luxembourg","2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","16 Dec 2018","2018","","","301","3016","Some of the main challenges in skeleton-based action recognition systems are redundant and noisy pose transformations. Earlier works in skeleton-based action recognition explored different approaches for filtering linear noise transformations, but neglect to address potential nonlinear transformations. In this paper, we present an unsupervised learning approach for estimating nonlinear noise transformations in pose estimates. Our approach starts by decoupling linear and nonlinear noise transformations. While the linear transformations are modelled explicitly the nonlinear transformations are learned from data. Subsequently, we use an autoencoder with L2-norm reconstruction error and show that it indeed does capture nonlinear noise transformations, and recover a denoised pose estimate which in turn improves performance significantly. We validate our approach on a publicly available dataset, NW-UCLA.","2160-7516","978-1-5386-6100-0","10.1109/CVPRW.2018.00056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8575517","","Noise measurement;Data models;Decoding;Cameras;Noise reduction;Training;Unsupervised learning","image coding;image denoising;image filtering;image motion analysis;image recognition;image reconstruction;object recognition;pose estimation;unsupervised learning","unsupervised learning approach;pose estimates;pose encoding;robust skeleton-based action recognition;skeleton-based action recognition systems;pose transformations;nonlinear noise transformations;L2-norm reconstruction error;NW-UCLA","","23","","32","IEEE","16 Dec 2018","","","IEEE","IEEE Conferences"
"Domain Adaptation by Stacked Local Constraint Auto-Encoder Learning","X. Peng; Y. Li; Y. L. Murphey; J. Luo","School of Aeronautics and Astronautics, Shanghai Jiao Tong University, Shanghai, China; School of Aeronautics and Astronautics, Shanghai Jiao Tong University, Shanghai, China; College of Engineering and Computer Science, University of Michigan–Dearborn, Dearborn, MI, USA; School of Aeronautics and Astronautics, Shanghai Jiao Tong University, Shanghai, China","IEEE Access","14 Aug 2019","2019","7","","108248","108260","Domain adaptation (DA), a particular case of transfer learning, is an effective technology for learning a discriminative model in scenarios where the data from the training (source) and the testing (target) domains share common class labels but follow different distributions. The differences between domains, called domain shifts, are caused by variations in the acquisition devices and environmental conditions, such as changing illuminations, pose, and collecting-device noises, that are related to a specific domain, denoted as domain-specific noises in this paper. The research on stacked denoising autoencoder (SDA) has demonstrated that noise-robust features could be learned through training a model to reduce the man-made (simulated) noises. However, little research has been conducted to learn the domain-invariant features through training SDA to reduce the domain-specific noises from the real word. In this paper, we propose a novel variant of SDA for DA, called the stacked local constraint auto-encoder (SLC-AE), which aims to learn domain-invariant features through iteratively optimizing the SDA and the low-dimensional manifold. The core idea behind the SLC-AE is that both the source and target samples are corrupted due to the domain-specific noises, and each corrupted sample could be de-noised by calculating the weighted sum of its neighbor samples defined on the intrinsic manifold. Because the neighbor samples on the intrinsic manifold are semantically similar, their weighted sum preserves the generic information and reduces the domain-specific noises. To properly evaluate the performance of the SLC-AE, we conducted extensive experiments using seven benchmark data sets, i.e., MNIST, USPS, COIL20, SYN SIGNS, GTSRB, MSRC and VOC 2007. Compared to twelve different state-of-the-art methods, the experimental results demonstrated that the proposed SLC-AE model made significant improvement over the performance of SDA and achieved the best average performance on the seven data sets.","2169-3536","","10.1109/ACCESS.2019.2933591","National Natural Science Foundation of China(grant numbers:U1406404); Civil Aviation Special Project of China(grant numbers:MJZ-2016-S-44); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8789382","Computer vision;machine learning;image recognition;feature extraction","Training;Feature extraction;Data models;Manifolds;Adaptation models;Computer architecture;Task analysis","feature extraction;image denoising;iterative methods;learning (artificial intelligence);neural nets;optimisation;pose estimation","domain adaptation;collecting-device noises;domain-specific noises;SDA;noise-robust features;domain-invariant features;testing domain;domain shifts;stacked local constraint auto-encoder learning;transfer learning;discriminative model;training domain;acquisition devices;environmental conditions;SLC-AE","","2","","61","CCBY","6 Aug 2019","","","IEEE","IEEE Journals"
"Generic Image Restoration with Flow Based Priors","L. Helminger; M. Bernasconi; A. Djelouah; M. Gross; C. Schroers","Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland; DisneyResearch|Studios, Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland; DisneyResearch|Studios, Zurich, Switzerland","2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","1 Sep 2021","2021","","","334","343","Image restoration has seen great progress in the last years thanks to the advances in deep neural networks. Most of these existing techniques are trained using full supervision with suitable image pairs to tackle a specific degradation. However, in a generic setting with unknown degradations this is not possible and a good prior remains crucial. Recently, neural network based approaches have been proposed to model such priors by leveraging either denoising autoencoders or the implicit regularization captured by the neural network structure itself. In contrast to this, we propose using normalizing flows to model the distribution of the target content and to use this as a prior in a maximum a posteriori (MAP) formulation. By expressing the MAP optimization process in the latent space through the learned bijective mapping, we are able to obtain solutions through gradient descent. To the best of our knowledge, this is the first work that explores normalizing flows as prior in generic image enhancement problems. Furthermore, we present experimental results for a number of different degradations on data sets varying in complexity and show competitive results when comparing with the deep image prior approach.","2160-7516","978-1-6654-4899-4","10.1109/CVPRW53098.2021.00043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9522836","","Degradation;Training;Noise reduction;Neural networks;Superresolution;Image restoration;Complexity theory","image classification;image denoising;image enhancement;image restoration;neural nets;optimisation","image restoration;flow based priors;deep neural networks;neural network structure;MAP optimization process;learned bijective mapping;generic image enhancement problems;deep image prior approach;maximum a posteriori formulation","","1","","33","IEEE","1 Sep 2021","","","IEEE","IEEE Conferences"
"Graph Clustering with Embedding Propagation","C. Yang; L. Liu; M. Liu; Z. Wang; C. Zhang; J. Han","Emory University, Atlanta, USA; University of Illinois, Urbana Champaign, Urbana, USA; Carnegie Mellon University, Pittsburgh, USA; Google Inc., Mountain View, USA; Georgia Institute of Technology, Atlanta, USA; University of Illinois, Urbana Champaign, Urbana, USA","2020 IEEE International Conference on Big Data (Big Data)","19 Mar 2021","2020","","","858","867","In the past decade, the amount of attributed network data has skyrocketed, and the problem of identifying their underlying group structures has received significant attention. By leveraging both attribute and link information, recent state-of-the-art network clustering methods have achieved significant improvements on relatively clean datasets. However, the noisy nature of real-world attributed networks has long been over-looked, which leads to degraded performance facing missing or inaccurate attributes and links. In this work, we overcome such weaknesses by marrying the strengths of clustering and embedding on attributed networks. Specifically, we propose GRACE (GRAph Clustering with Embedding propagation), to simultaneously learn network representations and identify net-work clusters in an end-to-end manner. It employs deep denoise autoencoders to generate robust network embeddings from node attributes, propagates the embeddings in the network to capture node interactions, and detects clusters based on the stable state of embedding propagation. To provide more insight, we further analyze GRACE in a theoretical manner and find its underlying connections with two canonical approaches for network modeling. Extensive experiments on six real-world attributed networks demonstrate the superiority of GRACE over various baselines from the state-of-the-art. Remarkably, GRACE improves the averaged performance of the strongest baseline from 0.43 to 0.52, yielding a 21% relative improvement. Controlled experiments and case studies further verify our intuitions and demonstrate the ability of GRACE to handle noisy information in real-world attributed networks.","","978-1-7281-6251-5","10.1109/BigData50022.2020.9378031","U.S. Army; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9378031","network clustering;representation learning;influence propagation","Deep learning;Social networking (online);Conferences;Big Data;Market research;Data models;Noise measurement","complex networks;graph theory;image denoising;learning (artificial intelligence);pattern clustering;statistical analysis","real-world attributed networks;GRACE;graph Clustering;embedding propagation;attributed network data;link information;recent state-of-the-art network;inaccurate attributes;GRAph Clustering;network representations;net-work clusters;robust network embeddings;node attributes;detects clusters;network modeling","","","","80","","19 Mar 2021","","","IEEE","IEEE Conferences"
"Fast Beam Training for mmWave UAV Communications Using Machine Learning","Y. GU; W. ZHONG; Q. ZHU; P. LI; X. CHEN","College of Astronautics, Nanjing University of Aeronautics and Astronautics, Nanjing, CHINA; College of Astronautics, Nanjing University of Aeronautics and Astronautics, Nanjing, CHINA; College of Astronautics, Nanjing University of Aeronautics and Astronautics, Nanjing, CHINA; College of Astronautics, Nanjing University of Aeronautics and Astronautics, Nanjing, CHINA; College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, CHINA","2020 International Conference on Wireless Communications and Signal Processing (WCSP)","28 Dec 2020","2020","","","697","701","Establishing and training beams in unmanned aerial vehicle (UAV) assisted millimeter-wave (mmWave) communications is a challenging task. In this paper, a novel beam training method is proposed by employing the machine learning (ML) method. Firstly, we analyze the applicable conditions of ML and preplan an ideal relationship of received signals. The required beam patterns based on this ideal relationship can be obtained by using the Fourier series method (FSM). We then formulate the beam selection issue as a polynomial regression problem based on hand-crafted features. Especially, we utilize the denoising autoencoder (DAE) to modify the error caused by the channel noise. Numerical simulation results demonstrate that our proposed beam training algorithm is able to provide precise beam selection for the mmWave UAV communications.","2472-7628","978-1-7281-7236-1","10.1109/WCSP49889.2020.9299722","Fundamental Research Funds for the Central Universities; Aeronautical Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9299722","unmanned aerial vehicles;mmWave communications;beam training;machine learning","Training;Noise measurement;Data models;Training data;Machine learning;Unmanned aerial vehicles;Slot antennas","aerospace communication;autonomous aerial vehicles;Fourier series;frequency division multiplexing;learning (artificial intelligence);millimetre wave communication;neural nets;regression analysis;signal denoising;telecommunication computing;wireless channels","fast beam training;mmWave UAV communications;unmanned aerial vehicle;millimeter-wave communications;novel beam training method;machine learning method;ideal relationship;received signals;required beam patterns;Fourier series method;beam selection issue;beam training algorithm;precise beam selection","","","","17","","28 Dec 2020","","","IEEE","IEEE Conferences"
"A Machine-Learning-Based Technique for False Data Injection Attacks Detection in Industrial IoT","M. M. N. Aboelwafa; K. G. Seddik; M. H. Eldefrawy; Y. Gadallah; M. Gidlund","Electronics and Communications Engineering Department, American University in Cairo, New Cairo; Electronics and Communications Engineering Department, American University in Cairo, New Cairo; School of Information Technology, Halmstad University, Halmstad, Sweden; Electronics and Communications Engineering Department, American University in Cairo, New Cairo; Department of Information Systems and Technology, Mid Sweden University, Sundsvall, Sweden","IEEE Internet of Things Journal","15 Sep 2020","2020","7","9","8462","8471","The accelerated move toward the adoption of the Industrial Internet-of-Things (IIoT) paradigm has resulted in numerous shortcomings as far as security is concerned. One of the IIoT affecting critical security threats is what is termed as the false data injection (FDI) attack. The FDI attacks aim to mislead the industrial platforms by falsifying their sensor measurements. FDI attacks have successfully overcome the classical threat detection approaches. In this article, we present a novel method of FDI attack detection using autoencoders (AEs). We exploit the sensor data correlation in time and space, which in turn can help identify the falsified data. Moreover, the falsified data are cleaned using the denoising AEs (DAEs). Performance evaluation proves the success of our technique in detecting FDI attacks. It also significantly outperforms a support vector machine (SVM)-based approach used for the same purpose. The DAE data cleaning algorithm is also shown to be very effective in recovering clean data from corrupted (attacked) data.","2327-4662","","10.1109/JIOT.2020.2991693","Swedish Foundation for International Cooperation in Research and Higher Education (STINT)(grant numbers:IB2018-7469); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9084134","Autoencoders (AEs);false data injection (FDI) attacks;Industrial Internet-of-Things (IIoT) security;machine learning (ML);support vector machine (SVM)","Correlation;Support vector machines;Security;Training;Noise reduction;Feature extraction","Internet of Things;learning (artificial intelligence);production engineering computing;security of data;support vector machines","IIoT;critical security threats;FDI attacks;industrial platforms;threat detection;FDI attack detection;sensor data correlation;data falsification;support vector machine;DAE data cleaning algorithm;machine-learning-based technique;false data injection attacks detection;industrial IoT;Industrial Internet-of-Things paradigm","","21","","25","IEEE","1 May 2020","","","IEEE","IEEE Journals"
"Industrial Control System Anomaly Detection and Classification Based on Network Traffic","J. -R. Jiang; Y. -T. Chen","Department of Computer Science and Information Engineering, National Central University, Taoyuan City, Taiwan; Department of Computer Science and Information Engineering, National Central University, Taoyuan City, Taiwan","IEEE Access","25 Apr 2022","2022","10","","41874","41888","This paper proposes an anomaly detection and classification method for industrial control systems (ICSs). The proposed method is based on network traffic data of industrial field protocols like Modbus TCP and S7 Communication. First, the denoising autoencoder (DAE) is utilized to reduce data noise and extract core features from data. Second, the synthetic minority oversampling technique (SMOTE) and the Tomek link (T-Link) mechanism are employed to oversample and undersample data for addressing the data imbalance problem. Finally, extreme gradient boosting (XGBoost) is used to leverage the ensemble learning concept to avoid overfitting for achieving good performance. A real-life railway industry ICS dataset called Electra is used to evaluate the performance of the proposed method, and the evaluation results are compared with those of other related methods. The proposed method is shown to have the highest (100%) precision, recall and F1-score for anomaly detection, and have fairly high performance of anomaly classification. The contribution of this paper is to show that integrating the DAE, SMOTE, T-Link, and XGBoost schemes can achieve the highest or extremely high performance in the aspect of ICS anomaly detection and classification based on network traffic. The computational complexity and convergence analyses of the proposed method are also provided in this paper. Furthermore, the code implementing the proposed method is released for public access through IEEE Code Ocean so that the effectiveness and the applicability of the method can be validated.","2169-3536","","10.1109/ACCESS.2022.3167814","Ministry of Science and Technology (MOST), Taiwan(grant numbers:109-2622-E-008-028); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9758754","Anomaly classification;anomaly detection;autoencoder;data imbalance;industrial control system;modbus;S7 communication;SMOTE;Tomek link;XGBoost","Anomaly detection;Codes;Telecommunication traffic;Generative adversarial networks;Performance evaluation;Integrated circuit modeling;Feature extraction","","","","1","","55","CCBYNCND","18 Apr 2022","","","IEEE","IEEE Journals"
"Hierarchical Learning Framework for UAV Detection and Identification","O. O. Medaiyese; M. Ezuma; A. P. Lauf; A. A. Adeniran","Department of Computer Science and Engineering, University of Louisville, Louisville, KY, USA; Department of Electrical and Computer Engineering, North Carolina State University at Raleigh, Raleigh, NC, USA; Department of Computer Science and Engineering, University of Louisville, Louisville, KY, USA; Department of Mechanical Engineering, University of Louisville, Louisville, KY, USA","IEEE Journal of Radio Frequency Identification","28 Mar 2022","2022","6","","176","188","The ubiquity of unmanned aerial vehicles (UAVs) or drones is posing both security and safety risks to the public as UAVs are now used for cybercrimes. To mitigate these risks, it is important to have a system that can detect or identify the presence of an intruding UAV in a restricted environment. In this work, we propose a radio frequency (RF) based UAV detection and identification system by exploiting signals emanating from both the UAV and its flight controller, respectively. While several RF devices (i.e., Bluetooth and WiFi) operate in the same frequency band as UAVs, the proposed framework utilizes a semi-supervised learning approach for the detection of UAV or UAV’s control signals in the presence of other wireless signals such as Bluetooth and WiFi. The semi-supervised learning approach uses stacked denoising autoencoder and local outlier factor algorithms. After the detection of UAV or UAV’s control signals, the signal is decomposed by using Hilbert-Huang transform and wavelet packet transform to extract features from the time-frequency-energy domain of the signal. The extracted feature sets are used to train a three-level hierarchical classifier for identifying the type of signals (i.e., UAV or UAV control signal), UAV models, and flight mode of UAV.","2469-7281","","10.1109/JRFID.2022.3157653","NASA(grant numbers:NNX17AJ94A); National Science Foundation Aerial Experimentation Research Platform for Advanced Wireless (AERPAW) Project(grant numbers:CNS-1939334); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9729891","Autoencoder;Hilbert Huang transform;RF fingerprinting;unmanned aerial system;wavelet packet transform","Autonomous aerial vehicles;Feature extraction;Wireless fidelity;Radio frequency;Bluetooth;Sensors;Signal to noise ratio","autonomous aerial vehicles;feature extraction;Hilbert transforms;learning (artificial intelligence);remotely operated vehicles;wavelet transforms","UAV models;UAV detection;intruding UAV;semisupervised learning approach;UAV's control signals;UAV control signal","","1","","36","IEEE","8 Mar 2022","","","IEEE","IEEE Journals"
"A Fault Diagnosis Framework for Autonomous Vehicles Based on Hybrid Data Analysis Methods Combined with Fuzzy PID Control","Y. Fang; C. Cheng; Z. Dong; H. Min; X. Zhao","School of Information Engineering, Chang’an University, Xi’an, China; School of Information Engineering, Chang’an University, Xi’an, China; Department of Transportation Information Engineering, Henan College of Transportation, Zhengzhou, China; School of Information Engineering, Chang’an University, Xi’an, China; School of Information Engineering, Chang’an University, Xi’an, China","2020 3rd International Conference on Unmanned Systems (ICUS)","7 Dec 2020","2020","","","281","286","This paper presents a fault diagnosis framework for autonomous vehicles on the basis of several hybrid data analysis approaches and fuzzy Proportional Integral Derivative (PID) control method. The framework consists of sensor monitor cluster, novel anomaly detector and actuator fault testing cluster. The Discrete Wavelet Transform (DWT) are used for denoising and feature extracting when constructing the sensor monitor. The extreme learning machine based autoencoder (ELM_AE) are applied for novel anomaly detection. Further, system approximation using neural networks and actuator fault testing via fuzzy PID control are presented. Contributions are as follow: 1) An algorithm using DWT with slide window is proposed for fatal sensor fault detection, which considers the sequential arrival characteristic of the sensor data; 2) Combining the neural network and fuzzy PID control for actuator fault testing, which solves the problem of fault location from the perspective of control. Experiments on the real autonomous vehicle platform `Xinda' and related simulations validate the effectiveness of the proposed approaches in this fault diagnosis framework.","","978-1-7281-8025-0","10.1109/ICUS50048.2020.9274856","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9274856","fault diagnosis;autonomous vehicles;discrete wavelet transform;extreme learning machine based autoencoder;system approximation;fuzzy PID control","Germanium;Transportation;Transforms;Testing;Discrete wavelet transforms;Actuators;PI control","data analysis;discrete wavelet transforms;fault diagnosis;fault location;feature extraction;fuzzy control;learning (artificial intelligence);mobile robots;neurocontrollers;sensors;three-term control","fault diagnosis framework;autonomous vehicles;hybrid data analysis methods combined;fuzzy PID control;hybrid data analysis approaches;fuzzy Proportional Integral Derivative control method;sensor monitor cluster;actuator fault testing;neural networks;fatal sensor fault detection;sensor data;fault location;related simulations","","","","15","","7 Dec 2020","","","IEEE","IEEE Conferences"
"Anomaly Detection and Classification of Household Electricity Data: A Time Window and Multilayer Hierarchical Network Approach","Q. Zhao; Z. Chang; G. Min","Department of Software Engineering, Shanxi University, Taiyuan, China; Faculty of Information Technology, University of Jyväskylä, Jyväskylä, Finland; Department of Computer Science, College of Engineering, Mathematics, and Physical Sciences, University of Exeter, Exeter, U.K.","IEEE Internet of Things Journal","21 Feb 2022","2022","9","5","3704","3716","With the increasing popularity of the smart grid, huge volumes of data are gathered from numerous sensors. How to classify, store, and analyze massive data sets to facilitate the development of the smart grid has recently attracted much attention. In particular, with the popularity of household smart meters and electricity monitoring sensors, a large amount of data can be obtained to analyze household electricity usage so as to better diagnose the leakage and theft behaviors, identify man-made tampering and data fraud, and detect powerline loss. In this article, the time window method is first proposed to obtain the features and potential periodicity of household electricity data. Combining the denoising ability of the autoencoder and the induction ability of the feedforward neural network, a multilayer hierarchical network (MLHN) is then established to detect anomalies in single sensor data and classify multiple groups of sensor data, respectively. The experimental results show that the accuracy of detecting abnormal data and data classification is significantly improved compared with the presented scheme.","2327-4662","","10.1109/JIOT.2021.3098735","NSFC(grant numbers:62071105); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9491042","Anomaly detection;autoencoder;classification;feedforward network;household electricity;multilayer hierarchical network (MLHN)","Feature extraction;Smart grids;Time series analysis;Training;Meters;Nonhomogeneous media;Correlation","domestic appliances;feedforward neural nets;learning (artificial intelligence);pattern classification;power engineering computing;security of data;smart meters;smart power grids","smart grid;household smart meters;electricity monitoring sensors;household electricity usage;time window method;household electricity data;feedforward neural network;single sensor data;data classification;anomaly detection;multilayer hierarchical network approach;MLHN;sensor data classification;powerline loss","","","","29","IEEE","20 Jul 2021","","","IEEE","IEEE Journals"
"Speech Enhancement for Demodulated Signals under Multipath Fading Communication Channels","A. Kobayashi","University of Tsukuba Technology, Tsukuba, Japan","2020 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","31 Dec 2020","2020","","","460","464","In analog communication channels, such as radio broadcasting, the superposition of multiple reflected signals causes multipath fading. Multipath fading often results in the fluctuation of the received electric intensity levels of these signals; thus, it causes severe quality degradation in audible sounds. In this paper, we focus on speech enhancement under a fading communication channel with additive Gaussian noise. We attempt to reconstruct the original speech based on the use of denoising autoencoders that employ mean-squared-error and additive perceptual evaluation of speech quality (PESQ)-based loss functions in multi-task learning (MTL). The experimental results indicate that the MTL-based autoencoder improves PESQ scores from 2.00 to 2.75 for demodulated signals under fading communication channels with additive Gaussian noise.","2640-0103","978-988-14768-8-3","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9306366","","Fading channels;Speech enhancement;Communication channels;Noise reduction;Estimation;Additives;Wireless communication","Gaussian noise;Gaussian processes;learning (artificial intelligence);mean square error methods;multipath channels;speech enhancement","speech enhancement;demodulated signals;multipath fading communication channels;analog communication channels;radio broadcasting;multiple reflected signals;received electric intensity levels;severe quality degradation;fading communication channel;additive Gaussian noise;original speech;speech quality-based loss functions;MTL-based autoencoder","","","","26","","31 Dec 2020","","","IEEE","IEEE Conferences"
"Open Set Recognition by Regularising Classifier with Fake Data Generated by Generative Adversarial Networks","I. Jo; J. Kim; H. Kang; Y. -D. Kim; S. Choi","Department of Computer Science and Engineering, POSTECH, Korea; Department of Computer Science and Engineering, POSTECH, Korea; Device Solutions, Software R&D Center, Korea; Device Solutions, Software R&D Center, Korea; Department of Computer Science and Engineering, POSTECH, Korea","2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 Sep 2018","2018","","","2686","2690","We present a new method to generate fake data in unknown classes in generative adversarial networks (GANs) framework. The generator in GANs is trained to generate somewhat similar to data in known classes but the different one by modelling noisy distribution on feature space of a classifier using proposed marginal denoising autoencoder. The generated data are treated as fake instances in unknown classes and given to the classifier to make it be robust to the real unknown classes. Our results show that synthetic data can act as fake unknown classes and keep down the certainty of the classifier on real unknown classes meanwhile the classification capability of known classes is not degenerated, even improved.","2379-190X","978-1-5386-4658-8","10.1109/ICASSP.2018.8461700","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8461700","Generative adversarial networks;Denoising au-toencoder;Open set recognition;Feature matching","Feature extraction;Gallium nitride;Uncertainty;Linear programming;Entropy;Noise reduction;Data models","image classification;neural nets;security of data","fake instances;synthetic data;fake unknown classes;open set recognition;generative adversarial networks framework;GANs;fake data;regularising classifier;classifier feature space","","10","","26","","13 Sep 2018","","","IEEE","IEEE Conferences"
"SNR Enhancement for Multi-TE MRSI Using Joint Low-Dimensional Model and Spatial Constraints","Y. Li; Z. Wang; F. Lam","Department of Bioengineering, University of Illinois Urbana-Champaign, USA; Department of Bioengineering, University of Illinois Urbana-Champaign, USA; Department of Bioengineering and the Beckman Institute for Advanced Science and Technology, University of Illinois Urbana-Champaign, Urbana, IL, USA","IEEE Transactions on Biomedical Engineering","19 Sep 2022","2022","69","10","3087","3097","We present a novel method to enhance the SNR for multi-TE MR spectroscopic imaging (MRSI) data by integrating learned nonlinear low-dimensional model and spatial constraints. A deep complex convolutional autoencoder (DCCAE) was developed to learn a nonlinear low-dimensional representation of the high-dimensional multi-TE $^{1}$H spectroscopy signals. The learned model significantly reduces the data dimension thus serving as an effective constraint for noise reduction. A reconstruction formulation was proposed to integrate the spatiospectral encoding model, the learned model, and a spatial constraint for an SNR-enhancing reconstruction from multi-TE data. The proposed method has been evaluated using both numerical simulations and in vivo brain MRSI experiments. The superior denoising performance of the proposed over alternative methods was demonstrated, both qualitatively and quantitatively. In vivo multi-TE data was used to assess the improved metabolite quantification reproducibility and accuracy achieved by the proposed method. We expect the proposed SNR-enhancing reconstruction to enable faster and/or higher-resolution multi-TE $^{1}$H-MRSI of the brain, potentially useful for various clinical applications.","1558-2531","","10.1109/TBME.2022.3161417","NSF(grant numbers:CBET 1944249); NIH-NIBIB(grant numbers:1R21EB029076); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9740411","Complex convolutional neural network;deep learning;denoising;low-dimensional modeling;multi-TE   $^{1}$  H-MRSI;regularized reconstruction","Data models;Signal to noise ratio;Noise reduction;Image reconstruction;Convolution;Training;Spatial resolution","","","Algorithms;Brain;Magnetic Resonance Imaging;Magnetic Resonance Spectroscopy;Nonlinear Dynamics;Reproducibility of Results","","","59","CCBY","23 Mar 2022","","","IEEE","IEEE Journals"
"Adapted Domain Specific Class Means","G. Csurka; B. Chidlovskii; S. Clinchant","Xerox Research Centre Europe, Meylan, France; Xerox Research Centre Europe, Meylan, France; Xerox Research Centre Europe, Meylan, France","2015 IEEE International Conference on Computer Vision Workshop (ICCVW)","15 Feb 2016","2015","","","80","84","We address the problem of domain adaptation (DA) from one or multiple source domains to a target domain. Most of the existing DA methods assume that source data is largely available. Such an assumption rarely holds in real applications, for both technical and legal reasons. More realistic are situations where source domain observations become quickly unavailable, but only some domain representatives can be retained, either as source instances or as their aggregation. In this paper therefore we focus on the Domain Specific Class Means (DSCM) classifier [5] that can handle such scenario and we combine it with the sMDA framework [4]. We show, on a variety of datasets and tasks, that the method can be applied successfully even when no labeled target is available and also that it can provide performance comparable to the case where dense knowledge (all source data) is available.","","978-1-4673-9711-7","10.1109/ICCVW.2015.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7406369","","Noise reduction;Adaptation models;Noise level;Correlation;Feature extraction;Europe;Law","pattern classification;unsupervised learning","adapted domain specific class means classifier;source data;sMDA framework;DSCM classifier;unsupervised stacked marginalized denoising autoencoders","","2","","19","","15 Feb 2016","","","IEEE","IEEE Conferences"
"Uncertainty Quantification in Deep MRI Reconstruction","V. Edupuganti; M. Mardani; S. Vasanawala; J. Pauly","Department of Electrical Engineering, Stanford University, Stanford, CA, USA; Department of Electrical Engineering, Stanford University, Stanford, CA, USA; Department of Radiology, Stanford University, Stanford, CA, USA; Department of Electrical Engineering, Stanford University, Stanford, CA, USA","IEEE Transactions on Medical Imaging","29 Dec 2020","2021","40","1","239","250","Reliable MRI is crucial for accurate interpretation in therapeutic and diagnostic tasks. However, undersampling during MRI acquisition as well as the overparameterized and non-transparent nature of deep learning (DL) leaves substantial uncertainty about the accuracy of DL reconstruction. With this in mind, this study aims to quantify the uncertainty in image recovery with DL models. To this end, we first leverage variational autoencoders (VAEs) to develop a probabilistic reconstruction scheme that maps out (low-quality) short scans with aliasing artifacts to the diagnostic-quality ones. The VAE encodes the acquisition uncertainty in a latent code and naturally offers a posterior of the image from which one can generate pixel variance maps using Monte-Carlo sampling. Accurately predicting risk requires knowledge of the bias as well, for which we leverage Stein's Unbiased Risk Estimator (SURE) as a proxy for mean-squared-error (MSE). A range of empirical experiments is performed for Knee MRI reconstruction under different training losses (adversarial and pixel-wise) and unrolled recurrent network architectures. Our key observations indicate that: 1) adversarial losses introduce more uncertainty; and 2) recurrent unrolled nets reduce the prediction uncertainty and risk.","1558-254X","","10.1109/TMI.2020.3025065","NIH(grant numbers:R01EB009690,R01EB026136); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201098","Uncertainty quantification;VAE;MRI reconstruction;SURE","Image reconstruction;Uncertainty;Magnetic resonance imaging;Biomedical imaging;Data models;Training;Probabilistic logic","biomedical MRI;image denoising;image reconstruction;learning (artificial intelligence);mean square error methods;medical image processing;Monte Carlo methods","Stein Unbiased Risk Estimator;substantial uncertainty;deep learning;MRI acquisition;deep MRI reconstruction;uncertainty quantification;prediction uncertainty;Knee MRI reconstruction;mean-squared-error;Monte-Carlo sampling;pixel variance maps;acquisition uncertainty;diagnostic-quality ones;probabilistic reconstruction scheme;DL reconstruction","Artifacts;Image Processing, Computer-Assisted;Magnetic Resonance Imaging;Monte Carlo Method;Uncertainty","10","","40","IEEE","21 Sep 2020","","","IEEE","IEEE Journals"
"Rotated Sphere Haar Wavelet and Deep Contractive Auto-Encoder Network With Fuzzy Gaussian SVM for Pilot’s Pupil Center Detection","E. Q. Wu; G. -R. Zhou; L. -M. Zhu; C. -F. Wei; H. Ren; R. S. F. Sheng","Science and Technology on Avionics Integration Laboratory, China National Aeronautical Radio Electronics Research Institute, Shanghai, China; Department of Avionics Systems, COMAC Shanghai Aircraft Design and Research Institute, Shanghai, China; Department of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; Human Space-Flight System Engineering Division, Institute of Manned Space System Engineering, CAST, Beijing, China; Department of Automation, Shanghai Engineering Research Center of Civil Aircraft Health Monitoring, Shanghai, China; Department of Avionics Systems, COMAC Shanghai Aircraft Design and Research Institute, Shanghai, China","IEEE Transactions on Cybernetics","22 Dec 2020","2021","51","1","332","345","How to track the attention of the pilot is a huge challenge. We are able to capture the pupil status of the pilot and analyze their anomalies and judge the attention of the pilot. This paper proposes a new approach to solve this problem through the integration of spherical Haar wavelet transform and deep learning methods. First, considering the application limitations of Haar wavelet and other wavelets in spherical signal decomposition and reconstruction, a feature learning method based on the spherical Haar wavelet is proposed. In order to obtain the salient features of the spherical signal, a rotating spherical Haar wavelet is also proposed, which has a consistent scale in the same direction between the reconstructed image and the original image. Second, in order to find a better characteristic representation of the spherical signal, a higher contractive autoencoder (HCAE) is designed for the potential representation of the spherical Haar wavelet coefficients, which has two penalty items, respectively, from Jacobian and two order items from Taylor expansion of the point ${x}$ for the contract learning of sample space. Third, in order to improve the classification performance, this paper proposes a fuzzy Gaussian support vector machine (FGSVM) as the top classification tool of the deep learning model, which can punish some Gaussian noise from the output of the deep HCAE network (DHCAEN). Finally, a DHCAEN-FGSVM classifier is proposed to identify the location of the pupil center. The experimental results of the public data set and actual data show that our model is an effective method for spherical signal detection.","2168-2275","","10.1109/TCYB.2018.2886012","National Natural Science Foundation of China(grant numbers:61671293); Chinese Military Commission Equipment Development Department(grant numbers:61400030601); Open Project Program of the State Key Laboratory of CAD & CG, Zhejiang University(grant numbers:A1713); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8610016","Auto-encoder (AE);fuzzy Gaussian support vector machine (FGSVM);pupil detection;rotation;sphere Haar wavelets","Wavelet transforms;Fatigue;Support vector machines;Deep learning;Image reconstruction;Aerospace electronics;Monitoring","feature extraction;Gaussian noise;image denoising;image reconstruction;learning (artificial intelligence);support vector machines;wavelet transforms","deep learning model;deep HCAE network;pupil center;spherical signal detection;rotated sphere Haar wavelet;deep contractive auto-encoder network;spherical signal decomposition;rotating spherical Haar wavelet;spherical Haar wavelet coefficients;contract learning;fuzzy Gaussian support vector machine","","9","","63","IEEE","11 Jan 2019","","","IEEE","IEEE Journals"
"A multi-scale noise-resistant feature adaptation approach for image tampering localization over Facebook","Y. Zhang; V. L. L. Thing","Cyber Security Cluster Institute for Infocomm Research, Singapore; Cyber Security Cluster Institute for Infocomm Research, Singapore","2017 IEEE 2nd International Conference on Signal and Image Processing (ICSIP)","30 Nov 2017","2017","","","272","276","This work introduces an approach to localize the tampered region among the images from social media platforms. We propose a joint model to integrate the predictions from a set of features, each of which represents the inherent relation among the pixels within a certain distance to detect the forgery. Within a fixed distance, the feature is adapted from a few basic statistics through a stacked Autoencoder to a proper version in a noise-resistant manner, so that it will be more robust to detect the tampering when the forgery gone through some common social media platform operations. The classifier is trained using a standalone dataset from a benchmarking but is pre-processed properly to simulate its possible imperfections when spreading over the Internet. The approach was tested on images from Facebook, with results showing an encouraging improvement from the prior arts.","","978-1-5386-0969-9","10.1109/SIPROCESS.2017.8124547","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8124547","image tampering detection;forgery detection;image forensics","Discrete cosine transforms;Feature extraction;Facebook;Forgery;Training;Internet","feature extraction;image denoising;image forensics;social networking (online)","multiscale noise-resistant feature adaptation approach;image tampering localization;Facebook;social media platforms;forgery","","2","","13","","30 Nov 2017","","","IEEE","IEEE Conferences"
"Spatial and Multispectral Correlations for Joint Design of Color Filter Arrays and Demosaicing","G. Qi; Z. Du","College of Computer Science and Technology, Nanjing Tech University; College of Computer Science and Technology, Nanjing Tech University","2020 IEEE 5th Information Technology and Mechatronics Engineering Conference (ITOEC)","16 Jul 2020","2020","","","604","608","CFA(Color filter array) is an essential component in the acquisition system, its adoption greatly decreases the acquisition size, however its design directly relates to the imaging quality. In this paper, a novel method of joint design of color filter arrays and demosaicing based on the spatial and multi-spectral correlation is proposed. The isotropic neighborhood is exploited for acquiring the spatial correlation, and the multi-spectral is utilized for the correlation cross channels. A convolutional network autoencoder is presented to design the color filter array patterns and demosaic, which comprehensively employs the spatial and multi-spectral correlation. Experiments shows that the method achieved high-quality image reconstructions, holding higher PSNR than the ones obtained by the state-the-art techniques on standard dataset.","","978-1-7281-4323-1","10.1109/ITOEC49072.2020.9141745","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141745","CFA;Spectral correlation;Spatial correlation;Automatic encoder;De-mosaic algorithm","Image color analysis;Correlation;Image reconstruction;Information filters;Filtering algorithms;Decoding","filtering theory;image colour analysis;image denoising;image reconstruction;image segmentation","correlation cross channels;color filter array patterns;high-quality image reconstructions;spatial correlations;multispectral correlations;color filter arrays;acquisition system;acquisition size;imaging quality;demosaicing","","","","18","","16 Jul 2020","","","IEEE","IEEE Conferences"
"Grip Force Perception Based on dAENN for Minimally Invasive Surgery Robot","Y. Guo; B. Pan; Y. Fu; M. Q. . -H. Meng","State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang, China; Department of Electronic Engineering, Chinese University of Hong Kong, Hong Kong, China","2019 IEEE International Conference on Robotics and Biomimetics (ROBIO)","20 Jan 2020","2019","","","1216","1221","Although robot assisted minimally invasive surgery brings the gospel to patients, force perception is gone. Among all the contact forces during surgery, the instrument grip force plays the most important role. In this paper, a grip force perception method based on denoising AutoEncoder Neural Network (dAENN) is proposed. The method utilizes sensor data including encoder readings and motor current over a time window as the input of dAENN for sufficient information. An Artificial Neural Network (ANN) is then introduced as a machine learning tool to learn the nonlinear mapping between the compact features and grip force labels. Feature extraction is first introduced into grip force perception problem in this paper. Experiment results shows adequate expressive capability of the extracted coding as well as the superior grip force perception performance over several popular data-based methods under the same dataset.","","978-1-7281-6321-5","10.1109/ROBIO49542.2019.8961473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8961473","grip force estimation;dAENN;surgical instrument;minimally invasive surgery","","control engineering computing;feature extraction;learning (artificial intelligence);medical robotics;neural nets;neurocontrollers;surgery","grip force perception problem;data-based methods;dAENN;minimally invasive surgery robot;contact forces;instrument grip force;grip force perception method;autoencoder neural network;sensor data;artificial neural network;grip force labels;machine learning tool","","3","","17","","20 Jan 2020","","","IEEE","IEEE Conferences"
"Novelty Detection and Analysis with a Βeta-DVAE Network","T. Graydon; F. Sahin","Department of Electrical and Microelectronic Engineering, Rochester Institute of Technology, Rochester, NY; Department of Electrical and Microelectronic Engineering, Rochester Institute of Technology, Rochester, NY","2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","17 Jan 2019","2018","","","2687","2691","In this paper we apply generative modeling to Gaussian Mixture Models (GMM) as a solution to high dimensional novel event detection and analysis on radio frequency (RF) power generators. A family of Denoising and β-Disentangling Variational Autoencoders (β-DVAE) is used to encode datasets into lower and more salient dimensions. The reduced feature sets are modeled using GMMs where model parameters are learned using the Expectation Maximization (EM) algorithm. The data is obtained from two different generator models operating under normal as well as known not-normal conditions. This approach is also tested on standard classification sets. Robust testing is reported to achieve a target class accuracy of 98.16% for the target RF generator. Additionally, the GMM parameters are decoded by the generative model to the original data space for calculating per-variable fitness in order to provide an initial novel event analysis for engineers and technicians. This per-variable fitness is very critical for determining each variable's contribution to a novelty so that engineers can perform informed trouble shooting and maintenance of the RF generators.","2577-1655","978-1-5386-6650-0","10.1109/SMC.2018.00459","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8616455","","Generators;Data models;Standards;Training;Analytical models;Radio frequency;Noise reduction","electric generators;expectation-maximisation algorithm;Gaussian processes;learning (artificial intelligence);mixture models;pattern classification;power engineering computing","EM algorithm;disentangling variational autoencoders;event detection;DVAE network;event analysis;expectation maximization algorithm;Gaussian mixture models;generative model;GMM parameters;target RF generator;radio frequency power generators","","","","21","","17 Jan 2019","","","IEEE","IEEE Conferences"
"Environment Knowledge-Aided Massive MIMO Feedback Codebook Enhancement Using Artificial Intelligence","J. Guo; C. -K. Wen; M. Chen; S. Jin","National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; Institute of Communications Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China","IEEE Transactions on Communications","14 Jul 2022","2022","70","7","4527","4542","The autoencoder empowered by artificial intelligence has shown considerable potential in solving channel state information (CSI) feedback problems in frequency-division duplexing systems. However, this method needs to completely change the existing feedback schemes, which is difficult to deploy in the next few years. This paper proposes an environment knowledge-aided codebook-based CSI feedback framework, which retains the existent codebook-based scheme while introducing environment knowledge to feedback process through neural networks (NNs) at the base station. Only an NN-based refining operation is added after the common standardized feedback approach. The NNs learn to automatically extract environment features and utilize the channel statistics through large volumes of recorded data. The NNs also use the partial correlation between bidirectional channels to further improve feedback performance. In addition, to deal with downlink channel estimation errors, we propose two strategies to reduce their effects using an NN-based denoise module. The proposed framework can be easily embedded in most existing codebook-based feedback methods, such as random vector quantization. Two channel datasets generated by QuaDRiGa and measured in practical systems are adopted to evaluate the proposed methods. Results show that the proposed method offers over 100% increase in the throughput compared with the baseline codebook because of more accurate feedback.","1558-0857","","10.1109/TCOMM.2022.3180388","National Natural Science Foundation of China (NSFC)(grant numbers:61941104,61921004); Key Research and Development Program of Shandong Province(grant numbers:2020CXGC010108); OPPO Research Fund; Ministry of Science and Technology of Taiwan(grant numbers:MOST 110-2224-E-110-001); Postgraduate Research&Practice Innovation Program of Jiangsu Province(grant numbers:KYCX21_0104); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9789120","CSI feedback;FDD;artificial intelligence;environment knowledge;codebook","Downlink;Correlation;Channel estimation;Uplink;Artificial intelligence;Massive MIMO;Image reconstruction","artificial intelligence;channel coding;channel estimation;feature extraction;MIMO communication;neural nets;vector quantisation;wireless channels","codebook-based feedback methods;codebook-based scheme;environment knowledge-aided codebook-based CSI feedback framework;feedback schemes;frequency-division duplexing systems;channel state information feedback problems;artificial intelligence;environment knowledge-aided massive MIMO feedback codebook enhancement;accurate feedback;baseline codebook;channel datasets;NN-based denoise module;downlink channel estimation errors;feedback performance;bidirectional channels;channel statistics;environment features;common standardized feedback approach;NN-based refining operation;base station","","1","","45","IEEE","6 Jun 2022","","","IEEE","IEEE Journals"
"Extracting deep bottleneck features using stacked auto-encoders","J. Gehring; Y. Miao; F. Metze; A. Waibel","Interactive Systems Laboratory, Karlsruhe Institute of Technology, Germany; Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Karlsruher Institut fur Technologie, Karlsruhe, Baden-WÃ¼rttemberg, DE","2013 IEEE International Conference on Acoustics, Speech and Signal Processing","21 Oct 2013","2013","","","3377","3381","In this work, a novel training scheme for generating bottleneck features from deep neural networks is proposed. A stack of denoising auto-encoders is first trained in a layer-wise, unsupervised manner. Afterwards, the bottleneck layer and an additional layer are added and the whole network is fine-tuned to predict target phoneme states. We perform experiments on a Cantonese conversational telephone speech corpus and find that increasing the number of auto-encoders in the network produces more useful features, but requires pre-training, especially when little training data is available. Using more unlabeled data for pre-training only yields additional gains. Evaluations on larger datasets and on different system setups demonstrate the general applicability of our approach. In terms of word error rate, relative improvements of 9.2% (Cantonese, ML training), 9.3% (Tagalog, BMMI-SAT training), 12% (Tagalog, confusion network combinations with MFCCs), and 8.7% (Switchboard) are achieved.","2379-190X","978-1-4799-0356-6","10.1109/ICASSP.2013.6638284","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6638284","Bottleneck features;Deep learning;Auto-encoders","Hidden Markov models;Speech;Training;Neural networks;Feature extraction;Acoustics;Vectors","neural nets;speech processing","Switchboard;MFCC;BMMI-SAT training;word error rate;Cantonese conversational telephone speech corpus;phoneme states;deep neural network;training scheme;stacked autoencoder;deep bottleneck feature","","120","","22","","21 Oct 2013","","","IEEE","IEEE Conferences"
"Overview of Deep Learning Architectures for EEG-based Brain Imaging","L. Bozhkov; P. Georgieva","Technical University of Sofia, Bulgaria; Department of Electronics Telecommunications and Informatics /IEETA, University of Aveiro, Portugal","2018 International Joint Conference on Neural Networks (IJCNN)","14 Oct 2018","2018","","","1","7","Despite numerous successful applications of Deep Learning (DL) to large-scale image, video, speech and text data, they remain relatively unexplored in brain imaging field. In this paper, we make an overview of recent DL architectures for recognizing cognitive brain activities from Electroencephalogram (EEG) data with particular emphasis on Brain Computer Interface(BCI) technologies and Affective Neurocomputing. We discuss the use of convolutional, recurrent neural nets, as well as deep belief networks, echo-state networks, reservoir computing, and denoising auto encoder models. A major challenge in modeling brain cognitive activity from EEG data is finding representations that are invariant to inter- and intra-subject differences, as well as the inherent noise in the EEG recordings. The reviewed studies reveal the great potential of DL to decode human intentions in BCI applications and to find the invariant descriptors of human emotions across subjects in Affective Neurocomputing applications. Many of the DL models prove to be more accurate and efficient than traditional machine learning models.","2161-4407","978-1-5090-6014-6","10.1109/IJCNN.2018.8489561","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489561","EEG data;Deep Learning;Brain-Computer Interface;Convolutional Neural Networks;Auto-Encoders;Recurrent Neural Networks;Echo State Networks;Deep Belief Networks;Reservoir Computing;Affective Computing","Electroencephalography;Machine learning;Brain modeling;Feature extraction;Task analysis;Imaging","belief networks;brain-computer interfaces;electroencephalography;learning (artificial intelligence);medical signal processing;recurrent neural nets","electroencephalogram data;Brain Computer Interface;autoencoder models;brain cognitive activity;machine learning models;BCI technologies;reservoir computin;human emotions;Affective Neurocomputing applications;BCI applications;EEG data;reservoir computing;echo-state networks;deep belief networks;recurrent neural nets;convolutional nets;cognitive brain activities;brain imaging field;text data;EEG-based Brain imaging;Deep Learning architectures","","9","","32","","14 Oct 2018","","","IEEE","IEEE Conferences"
"AI-aided Hidden Camera Detection and Localization based on Raw IoT Network Traffic","J. Lee; S. Seo; T. Yang; S. Park","Culture Technology, KAIST, Daejoen, Republic of Korea; Electrical Engineering, Korea University, Seoul, Republic of Korea; Computer Engineering, Chungnam National University, Daejeon, Republic of Korea; Computer Engineering, Chungbuk National University, Cheongju, Republic of Korea","2022 IEEE 47th Conference on Local Computer Networks (LCN)","26 Aug 2022","2022","","","315","318","This paper proposes a novel scheme to detect and localize the spy cameras based on AI algorithm based raw traffic analytics, named AI-aided Hidden Camera Locator (AHCL). In AHCL, the video streaming data are filtered via the SVM (support vector machine) algorithm to quickly monitor whole raw network traffic from a router to the networks first. Then, gathered traffic data are denoised by the Denoising Autoencoder (DAE) technique to improve the data quality of classification for localization, where a camera transmits video streaming. Based on the proof-of-concept implementation, the proposed scheme can achieve 99.5% positioning accuracy of camera detection with the Ensemble Neural Networks (NNs).","0742-1303","978-1-6654-8001-7","10.1109/LCN53696.2022.9843203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9843203","","Support vector machines;Location awareness;Data integrity;Noise reduction;Telecommunication traffic;Streaming media;Filtering algorithms","","","","","","10","IEEE","26 Aug 2022","","","IEEE","IEEE Conferences"
"Machine Learning for Missile Streak Detection and Localization","J. Krucinski; A. Bienkowski; K. R. Pattipati","Department of Electrical and Computer Engineering, University of Connecticut, Storrs, CT, U.S.A.; Department of Electrical and Computer Engineering, University of Connecticut, Storrs, CT, U.S.A.; Department of Electrical and Computer Engineering, University of Connecticut, Storrs, CT, U.S.A.","2021 IEEE Aerospace Conference (50100)","7 Jun 2021","2021","","","1","10","This paper presents a machine learning approach using Neural Networks for the detection and localization of a single streaking target from an optical sensor's Focal Plane Array (FPA). Current state-of-the-art methods utilize model-based probabilistic techniques, such as the maximum likelihood method. The image data for training and the concomitant ground truth for detection and localization is generated via simulation due to lack of sufficient amounts of real-world data. The images were generated assuming that the target's point spread function (PSF) is Gaussian and moves during the FPA's integration time. Also, a noise model for each optical pixel on the FPA is used that is consistent with a Poisson model of the number of non-target originated photons. Our approach divides the problem into two parts: streak detection and localization. To simplify neural network architecture selection and training, we split the large images into smaller sub-images. The noisy sub-images were preprocessed by an autoencoder with Convolutional layers, which preserved the target intensity. Next, we used the denoised sub-images from the autoencoder to detect streaks. For localization, the Neural Network was given the original sub-images to predict the pixel locations of a streak's start and end points. All three processing steps utilized Convolutional layers. The performance of the detection model was evaluated in terms of confusion matrices at different noise intensities, as well as the Receiver Operating Characteristic (ROC) curves at a constant noise intensity. For the localization model, we evaluated the Mean Squared Error (MSE). These results were compared to the Generalized Likelihood Ratio Test (GLRT) for detection and an existing matched filter-based maximum likelihood method for localization. We found that the machine learning models were 340 times faster for detection and approximately 360 times faster for localization on full size 256x256 images. In addition, the detection accuracy of the machine learning model was substantially better than the maximum likelihood method (area under the ROC of 0.94 versus 0.85) and the MSE was significantly lower (0.0261 versus 0.0622 on 32x32 sub-images and 0.0351 versus 0.243 on 256x256 original images). These results are significant for time-critical systems, such as missile defense systems (e.g., C-RAM). Aside from missile defense, the approach presented here can be applied to counter many other weapons that exhibit similar linear streak trajectories, such as torpedoes. In this case, sonar images would be used rather than images from an optical sensor.","1095-323X","978-1-7281-7436-5","10.1109/AERO50100.2021.9438357","U.S. Naval Research Laboratory(grant numbers:N00014-18-1-1238,N000173-16-1-G905); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9438357","","Location awareness;Training;Optical filters;Missiles;Maximum likelihood detection;Neural networks;Machine learning","convolutional neural nets;focal planes;Gaussian processes;image filtering;infrared imaging;learning (artificial intelligence);matched filters;mean square error methods;military computing;missiles;object detection;optical transfer function","mean squared error;receiver operating characteristic;convolutional layers;PSF;target point spread function;FPA;optical sensor focal plane array;neural networks;missile streak localization;machine learning;nontarget originated photons;Poisson model;optical pixel;single streaking target;missile streak detection","","","","9","","7 Jun 2021","","","IEEE","IEEE Conferences"
"Abstractive Summarization of Korean Legal Cases using Pre-trained Language Models","J. Yoon; M. Junaid; S. Ali; J. Lee","Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, Republic of Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, Republic of Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, Republic of Korea; College of Computing and Informatics, Sungkyunkwan University, Suwon, Republic of Korea","2022 16th International Conference on Ubiquitous Information Management and Communication (IMCOM)","28 Feb 2022","2022","","","1","7","AI technology in the legal domain has developed at a rapid pace around the world, but not much research is being conducted in the Korean legal field due to barriers of language and the high level of expertise required. We first attempt abstractive summarization of Korean legal decision text and publicly release our collected dataset. We utilize two pretrained language models, i.e., BERT2BERT and BART, for our task. They are based on the encoder-decoder approach under transformer architecture. While BERT2BERT is pre-trained with BERT on both the encoder and decoder, BART combines BERT and GPT as the encoder and the decoder. We then evaluate the baseline models and show that, despite the difference in language style, the high-quality summary was generated using applied models. We also show that pre-training using both autoencoder and autoregressive method makes better performance than using solely denoising autoencoder.","","978-1-6654-2678-7","10.1109/IMCOM53663.2022.9721808","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9721808","abstractive summarization;legal AI;pre-trained language model;text generation;natural language processing","Law;Bit error rate;Noise reduction;Transformers;Decoding;Information management;Task analysis","decoding;encoding;law administration;learning (artificial intelligence);natural language processing;text analysis","Korean legal cases;pre-trained language models;AI technology;legal domain;Korean legal field;attempt abstractive summarization;Korean legal decision text;pretrained language models;BERT2BERT;BART;encoder-decoder approach;language style;high-quality summary;applied models","","","","25","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"Deep networks for predicting human intent with respect to objects","R. Kelley; K. Browne; L. Wigand; M. Nicolescu; B. Hamilton; M. Nicolescu","Department of Computer Science, University of Nevada,슠Reno, Reno, NV, USA; Department of Computer Science, University of Nevada,슠Reno, Reno, NV, USA; Department of Computer Science, University of Nevada,슠Reno, Reno, NV, USA; Department of Computer Science, University of Nevada,슠Reno, Reno, NV, USA; Department of Computer Science, University of Nevada,슠Reno, Reno, NV, USA; Department of Computer Science, University of Nevada,슠Reno, Reno, NV, USA","2012 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","30 Jul 2012","2012","","","171","172","Effective human-robot interaction requires systems that can accurately infer and predict human intentions. In this paper, we introduce a system that uses stacked denoising autoencoders to perform intent recognition. We introduce the intent recognition problem, provide an overview of deep architectures in machine learning, and outline the components of our system. We also provide preliminary results for our system's performance.","2167-2148","978-1-4503-1063-5","10.1145/2157689.2157740","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249510","human-robot interaction;intention modeling;deep architectures","Hidden Markov models;Humans;Noise reduction;Training;Robot sensing systems;Neural networks","","","","4","","6","","30 Jul 2012","","","IEEE","IEEE Conferences"
"Mutual Information Based Fusion Model (MIBFM): Mild Depression Recognition Using EEG and Pupil Area Signals","J. Zhu; C. Yang; X. Xie; S. Wei; Y. Li; X. Li; B. Hu","School of Information Science and Engineering, Lanzhou University, 12426 Lanzhou, Gansu, China; School of Information Science and Engineering, Lanzhou University, 12426 Lanzhou, Gansu, China; School of Information Science and Engineering, Lanzhou University, 12426 Lanzhou, Gansu, China; School of Information Science and Engineering, Lanzhou University, 12426 Lanzhou, Gansu, China; School of Information Science and Engineering Lanzhou, Lanzhou University, 12426 Lanzhou, Gansu, China; Computer science, School of Information Science and Engineering, Lanzhou, Gansu, China; School of Information Science and Engineering, Lanzhou Uiversity, Lanzhou, Gansu Province, China, 730000","IEEE Transactions on Affective Computing","","2022","PP","99","1","1","The detection of mild depression is conducive to the early intervention and treatment of depression. This study explored the fusion of electroencephalography (EEG) and pupil area signals to build an effective and convenient mild depression recognition model. We proposed Mutual Information Based Fusion Model (MIBFM), which innovatively used pupil area signals to select EEG electrodes based on mutual information. Then we extracted features from EEG and pupil area signals in different bands, and fused bimodal features using the denoising autoencoder. Experimental results showed that MIBFM could obtain the highest accuracy of 87.03%. And MIBFM exhibited better performance than other existing methods. Our findings validate the effectiveness of the use of pupil area as signals, which makes eye movement signals can be easily obtained using high resolution camera, and the EEG electrode selection scheme based on mutual information is also proved to be an applicable solution for data dimension reduction and multimodal complementary information screening. This study casts a new light for mild depression recognition using multimodal data of EEG and pupil area signals, and provides a theoretical basis for the development of portable and universal application systems.","1949-3045","","10.1109/TAFFC.2022.3171782","National Natural Science Foundation of China(grant numbers:Grant No.61627808,Grant No.61632014,Grant No.62102172); National Key Research and Development Program of China(grant numbers:Grant No. 2019YFA0706200); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9767586","Mild depression;multimodal fusion;EEG;pupil area signal;mutual information","Depression;Electroencephalography;Pupils;Feature extraction;Electrodes;Fuses;Brain modeling","","","","","","","IEEE","3 May 2022","","","IEEE","IEEE Early Access Articles"
"Highly Robust Vehicle Lateral Localization Using Multilevel Robust Network","Z. Zheng; X. Li; J. Zhu; J. Yuan; L. Wu","School of Instrument Science and Engineering, Southeast University, Nanjing 210096, China.; School of Instrument Science and Engineering, Southeast University, Nanjing 210096, China (e-mail: lixu.mail@163.com); School of Instrument Science and Engineering, Southeast University, Nanjing 210096, China.; Traffic Management Research Institute, Ministry of Public Security, Wuxi 214151, China.; Zhejiang Dahua Technology Company Ltd., Hangzhou 310053, China.","IEEE Transactions on Neural Networks and Learning Systems","","2021","PP","99","1","11","Vision-based vehicle lateral localization has been extensively studied in the literature. However, it faces great challenges when dealing with occlusion situations where the road is frequently occluded by moving/static objects. To address the occlusion problem, we propose a highly robust lateral localization framework called multilevel robust network (MLRN) in this article. MLRN utilizes three deep neural networks (DNNs) to reduce the impact of occluding objects on localization performance from the object, feature, and decision levels, respectively, which shows strong robustness to varying degrees of road occlusion. At the object level, an attention-guided network (AGNet) is designed to achieve accurate road detection by paying more attention to the interested road area. Then, at the feature level, a lateral-connection fully convolutional denoising autoencoder (LC-FCDAE) is proposed to learn robust location features from the road area. Finally, at the decision level, a long short-term memory (LSTM) network is used to enhance the prediction accuracy of lateral position by establishing the temporal correlations of positioning decisions. Experimental results validate the effectiveness of the proposed framework in improving the reliability and accuracy of vehicle lateral localization.","2162-2388","","10.1109/TNNLS.2021.3116433","National Natural Science Foundation of China(grant numbers:61973079,41904024); Program for Special Talents in Six Major Fields of Jiangsu Province(grant numbers:2017 JXQC-003); Jiangsu Higher Education Institutions of China(grant numbers:18KJB413007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9565154","Multilevel robust network (MLRN);road occlusion;robustness;vehicle lateral localization.","Roads;Feature extraction;Location awareness;Cameras;Reliability;Semantics;Robustness","","","","","","","IEEE","8 Oct 2021","","","IEEE","IEEE Early Access Articles"
"Fully Convolutional Networks for Monocular Retinal Depth Estimation and Optic Disc-Cup Segmentation","S. M. Shankaranarayana; K. Ram; K. Mitra; M. Sivaprakasam","Electrical Engineering, Indian Institute of Technology, Madras, Chennai, India; Centre for Visual Information Technology, International Institute of Information Technology, Hyderabad, India; Electrical Engineering, Indian Institute of Technology, Madras, Chennai, India; Electrical Engineering, Indian Institute of Technology, Madras, Chennai, India","IEEE Journal of Biomedical and Health Informatics","1 Jul 2019","2019","23","4","1417","1426","Glaucoma is a serious ocular disorder for which the screening and diagnosis are carried out by the examination of the optic nerve head (ONH). The color fundus image (CFI) is the most common modality used for ocular screening. In CFI, the central region which is the optic disc and the optic cup region within the disc are examined to determine one of the important cues for glaucoma diagnosis called the optic cup-to-disc ratio (CDR). CDR calculation requires accurate segmentation of optic disc and cup. Another important cue for glaucoma progression is the variation of depth in ONH region. In this paper, we first propose a deep learning framework to estimate depth from a single fundus image. For the case of monocular retinal depth estimation, we are also plagued by the labeled data insufficiency. To overcome this problem we adopt the technique of pretraining the deep network where, instead of using a denoising autoencoder, we propose a new pretraining scheme called pseudo-depth reconstruction, which serves as a proxy task for retinal depth estimation. Empirically, we show pseudo-depth reconstruction to be a better proxy task than denoising. Our results outperform the existing techniques for depth estimation on the INSPIRE dataset. To extend the use of depth map for optic disc and cup segmentation, we propose a novel fully convolutional guided network, where, along with the color fundus image the network uses the depth map as a guide. We propose a convolutional block called multimodal feature extraction block to extract and fuse the features of the color image and the guide image. We extensively evaluate the proposed segmentation scheme on three datasetsORIGA, RIMONEr3, and DRISHTI-GS. The performance of the method is comparable and in many cases, outperforms the most recent state of the art.","2168-2208","","10.1109/JBHI.2019.2899403","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642288","Glaucoma;Fully Convolutional Networks;Semantic Segmentation;Depth Estimation","Optical imaging;Estimation;Image segmentation;Retina;Biomedical optical imaging;Feature extraction;Image color analysis","biomedical optical imaging;diseases;eye;feature extraction;image segmentation;learning (artificial intelligence);medical image processing","color image;depth map;proxy task;pseudodepth reconstruction;deep network;single fundus image;ONH region;glaucoma progression;optic cup-to-disc ratio;glaucoma diagnosis;optic cup region;central region;ocular screening;CFI;color fundus image;optic nerve head;serious ocular disorder;optic disc-cup segmentation;monocular retinal depth estimation;fully convolutional networks","Diagnostic Techniques, Ophthalmological;Glaucoma;Humans;Image Interpretation, Computer-Assisted;Neural Networks, Computer;Optic Disk;ROC Curve;Retina","31","","34","IEEE","14 Feb 2019","","","IEEE","IEEE Journals"
"Unsupervised deep embedding for novel class detection over data stream","A. M. Mustafa; G. Ayoade; K. Al-Naami; L. Khan; K. W. Hamlen; B. Thuraisingham; F. Araujo","Department of Computer Science, The University of Texas at Dallas, Richardson, Texas; Department of Computer Science, The University of Texas at Dallas, Richardson, Texas; Department of Computer Science, The University of Texas at Dallas, Richardson, Texas; Department of Computer Science, The University of Texas at Dallas, Richardson, Texas; Department of Computer Science, The University of Texas at Dallas, Richardson, Texas; Department of Computer Science, The University of Texas at Dallas, Richardson, Texas; IBM Research, Thomas J. Watson Research Center, Yorktown Heights, NY","2017 IEEE International Conference on Big Data (Big Data)","15 Jan 2018","2017","","","1830","1839","Data streams are continuous flows of data points. Novel class detection is an important part of data stream mining. A novel class is a newly emerged class that has not previously been modeled by the classifier over the input stream. This paper proposes deep embedding for novel class detection - a novel approach that combines feature learning using denoising autoencoding with novel class detection. A denoising autoencoder is a neural network with hidden layers aiming to reconstruct the input vector from a corrupted version. A nonparametric multidimensional change point detection approach is also proposed, to detect concept-drift (the change of data feature values over time). Experiments on several real datasets show that the approach significantly improves the performance of novel class detection.","","978-1-5386-2715-0","10.1109/BigData.2017.8258127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8258127","Stream Mining;Novel Class Detection;Concept-drift;Deep Learning","Feature extraction;Data models;Machine learning;Anomaly detection;Noise reduction;Training data","data handling;data mining;learning (artificial intelligence);neural nets;pattern classification;unsupervised learning","nonparametric multidimensional change point detection approach;unsupervised deep embedding;data points;data stream mining;newly emerged class;input stream;class detection","","7","","30","","15 Jan 2018","","","IEEE","IEEE Conferences"
"Industrial Big Data Analytics for Prediction of Remaining Useful Life Based on Deep Learning","H. Yan; J. Wan; C. Zhang; S. Tang; Q. Hua; Z. Wang","School of Electrical Engineering, Guangdong Mechanical and Electrical College, Guangzhou, China; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; School of Mechanical and Electrical Engineering, Qingdao University, Qingdao, China; School of Mechanical Engineering, Hubei University of Arts and Science, Xiangyang, China","IEEE Access","9 Apr 2018","2018","6","","17190","17197","Due to the recent development of cyber-physical systems, big data, cloud computing, and industrial wireless networks, a new era of industrial big data is introduced. Deep learning, which brought a revolutionary change in computer vision, natural language processing, and a variety of other applications, has significant potential for solutions providing in sophisticated industrial applications. In this paper, a concept of device electrocardiogram (DECG) is presented, and an algorithm based on deep denoising autoencoder (DDA) and regression operation is proposed for the prediction of the remaining useful life of industrial equipment. First, the concept of electrocardiogram is explained. Then, a problem statement based on manufacturing scenario is presented. Subsequently, the architecture of the proposed algorithm called integrated DDA and the algorithm workflow are provided. Moreover, DECG is compared with traditional factory information system, and the feasibility and effectiveness of the proposed algorithm are validated experimentally. The proposed concept and algorithm combine typical industrial scenario and advance artificial intelligence, which has great potential to accelerate the implementation of industry 4.0.","2169-3536","","10.1109/ACCESS.2018.2809681","Natural Science Foundation of Guangdong Province, China(grant numbers:2015A030313746,2017B030311008); National Key Research and Development Project(grant numbers:2017YFE0101000); Major Projects for Numerical Control Machine(grant numbers:2015ZX04005001); Natural Science Foundation of Hubei Province, China(grant numbers:2014CFB637); Research Fund Program of Guangdong Provincial Key Laboratory of Computer Integrated Manufacturing(grant numbers:CIMSOF2016004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302913","Cyber-physical systems;deep learning;device electrocardiogram;industrial big data;industry 40","Machine learning;Production;Manufacturing;Maintenance engineering;Big Data;Hidden Markov models;Prediction algorithms","","","","55","","39","OAPA","26 Feb 2018","","","IEEE","IEEE Journals"
"A Deep Neural Networks Approach to Automatic Recognition Systems for Volcano-Seismic Events","M. Titos; A. Bueno; L. García; C. Benítez","Department of Signal Theory, Telematic and Communications, University of Granada, Granada, Spain; Department of Signal Theory, Telematic and Communications, University of Granada, Granada, Spain; Department of Signal Theory, Telematic and Communications, University of Granada, Granada, Spain; Department of Signal Theory, Telematic and Communications, University of Granada, Granada, Spain","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","27 Apr 2018","2018","11","5","1533","1544","Deep neural networks (DNNs) could help to identify the internal sources of volcano-seismic events. However, direct applications of DNNs are challenging, given the multiple seismic sources and the small size of available datasets. In this paper, we propose a novel approach in the field of volcano seismology to classify volcano-seismic events based on fully connected DNNs. Two DNN architectures with different weights scheme initialization are studied: stacked denoising autoencoders and deep belief networks. Using a combined feature vector of linear prediction coefficients and statistical properties, we evaluate classification performance on seven different classes of isolated seismic events. These proposed architectures are compared to multilayer perceptron, support vector machine, and random forest. Experimental results show that DNNs can efficiently capture complex relationships of volcano-seismic data and achieve better classification performance with faster convergence when compared to classical models.","2151-1535","","10.1109/JSTARS.2018.2803198","TEC2015- 68752 (MINECO/FEDER); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307075","Artificial intelligence;feedforward neural networks;geoscience and remote sensing;geophysical signal processing;multilayer neural networks;neural networks;remote monitoring;remote sensing;signal processing;volcanoes;volcanic activity","Volcanoes;Neural networks;Data models;Feature extraction;Computer architecture;Training;Remote sensing","belief networks;feature extraction;geophysical techniques;geophysics computing;learning (artificial intelligence);neural net architecture;pattern classification;seismology;statistical analysis;volcanology","volcano seismology;volcano-seismic events;fully connected DNNs;deep belief networks;isolated seismic events;volcano-seismic data;deep neural networks approach;automatic recognition systems;multiple seismic sources;DNN architectures;combined feature vector;linear prediction coefficients;statistical properties;classification performance","","52","","53","IEEE","6 Mar 2018","","","IEEE","IEEE Journals"
"Deep Robust Reinforcement Learning for Practical Algorithmic Trading","Y. Li; W. Zheng; Z. Zheng","Guangdong Key Laboratory for Big Data Analysis and Simulation of Public Opinion, Sun Yat-sen University, Guangzhou, China; Guangdong Key Laboratory for Big Data Analysis and Simulation of Public Opinion, Sun Yat-sen University, Guangzhou, China; National Engineering Research Center of Digital Life, Sun Yat-sen University, Guangzhou, China","IEEE Access","14 Aug 2019","2019","7","","108014","108022","In algorithmic trading, feature extraction and trading strategy design are two prominent challenges to acquire long-term profits. However, the previously proposed methods rely heavily on domain knowledge to extract handcrafted features and lack an effective way to dynamically adjust the trading strategy. With the recent breakthroughs of deep reinforcement learning (DRL), sequential real-world problems can be modeled and solved with a more human-like approach. In this paper, we propose a novel trading agent, based on deep reinforcement learning, to autonomously make trading decisions and gain profits in the dynamic financial markets. We extend the value-based deep Q-network (DQN) and the asynchronous advantage actor-critic (A3C) for better adapting to the trading market. Specifically, in order to automatically extract robust market representations and resolve the financial time series dependence, we utilize the stacked denoising autoencoders (SDAEs) and the long short-term memory (LSTM) as parts of the function approximator, respectively. Furthermore, we design several elaborate mechanisms to make the trading agent more practical to the real trading environment, such as position-controlled action and n-step reward. The experimental results show that our trading agent outperforms the baselines and achieves stable risk-adjusted returns in both the stock and the futures markets.","2169-3536","","10.1109/ACCESS.2019.2932789","National Basic Research Program of China (973 Program)(grant numbers:2016YFB1000101); National Natural Science Foundation of China(grant numbers:61722214,U1811462); Guangdong Province Universities and Colleges Pearl River Scholar Funded Scheme(grant numbers:2016); Program for Guangdong Introducing Innovative and Entrepreneurial Teams(grant numbers:2016ZT06D211); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8786132","Algorithmic trading;Markov decision process;deep neural network;reinforcement learning","Reinforcement learning;Time series analysis;Autoregressive processes;Heuristic algorithms;Neural networks;Biological system modeling;Markov processes","electronic trading;feature extraction;function approximation;learning (artificial intelligence);neural nets;time series","deep robust reinforcement learning;practical algorithmic trading;feature extraction;long-term profits;handcrafted features;sequential real-world problems;trading agent;deep reinforcement learning;trading decisions;gain profits;dynamic financial markets;value-based deep Q-network;trading market;robust market representations;trading environment;DRL;trading strategy design","","31","","39","CCBY","5 Aug 2019","","","IEEE","IEEE Journals"
"DeepCachNet: A Proactive Caching Framework Based on Deep Learning in Cellular Networks","S. Rathore; J. H. Ryu; P. K. Sharma; J. H. Park",Seoul National University of Science and Technology; Seoul National University of Science and Technology; Seoul National University of Science and Technology; Seoul National University of Science and Technology,"IEEE Network","30 May 2019","2019","33","3","130","138","Content caching at the network edge is considered to be a suitable technique for enhancing the efficacy of content delivery in cellular networks. Caching the strategic content at the SBS is critical due to storage constraints; however, it requires information about popularity dissemination that is not known in advance. Furthermore, the popularity of content is varied due to the fact that every mobile user connected to the SBSs has a different preference for content. Thus, the nature of the content a user prefers depends on the features of both user and content. This article proposes a novel deep learning-based proactive caching framework in cellular networks, called DeepCachNet, in which a vast amount of data is collected from the mobile devices of users connected to SBSs. The deep-learning methods called auto-encoder and stacked denoising autoencoders are applied to the collected data to extract the features of users and content, respectively. The extracted features are then used to estimate the content popularity at the core network. Based on the estimated content popularity, the strategic content is cached at SBSs to obtain higher backhaul offloading and user satisfaction. To validate the effectiveness of the proposed framework, a case study is carried out in which mobile data are gathered from connected mobile devices by using a developed android mobile application, and a simulation of the proposed framework is performed on the collected data. The results of the simulation show that the framework resolves the cold-start and data sparsity problem, and yields significant improvements in terms of backhaul offloading and the user satisfaction ratio. It achieves gains of up to 6.2 percent and 30 percent for backhaul offloading and user satisfaction, respectively.","1558-156X","","10.1109/MNET.2019.1800058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642795","","Feature extraction;Data mining;Mobile handsets;Sensors;Estimation;Distributed databases;Cellular networks","Android (operating system);cache storage;cellular radio;feature extraction;learning (artificial intelligence);mobile computing","content caching;network edge;content delivery;cellular networks;strategic content;popularity dissemination;mobile user;SBSs;collected data;core network;estimated content popularity;mobile data;connected mobile devices;data sparsity problem;user satisfaction ratio;DeepCachNet;android mobile application","","21","","15","","15 Feb 2019","","","IEEE","IEEE Magazines"
"Detecting Unipolar and Bipolar Depressive Disorders from Elicited Speech Responses Using Latent Affective Structure Model","K. -Y. Huang; C. -H. Wu; M. -H. Su; Y. -T. Kuo","Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan","IEEE Transactions on Affective Computing","14 Aug 2020","2020","11","3","393","404","Mood disorders, including unipolar depression (UD) and bipolar disorder (BD) [1] , are reported to be one of the most common mental illnesses in recent years. In diagnostic evaluation on the outpatients with mood disorder, a large portion of BD patients are initially misdiagnosed as having UD [2] . As most previous research focused on long-term monitoring of mood disorders, short-term detection which could be used in early detection and intervention is thus desirable. This work proposes an approach to short-term detection of mood disorder based on the patterns in emotion of elicited speech responses. To the best of our knowledge, there is no database for short-term detection on the discrimination between BD and UD currently. This work collected two databases containing an emotional database (MHMC-EM) collected by the Multimedia Human Machine Communication (MHMC) lab and a mood disorder database (CHI-MEI) collected by the CHI-MEI Medical Center, Taiwan. As the collected CHI-MEI mood disorder database is quite small and emotion annotation is difficult, the MHMC-EM emotional database is selected as a reference database for data adaptation. For the CHI-MEI mood disorder data collection, six eliciting emotional videos are selected and used to elicit the participants' emotions. After watching each of the six eliciting emotional video clips, the participants answer the questions raised by the clinician. The speech responses are then used to construct the CHI-MEI mood disorder database. Hierarchical spectral clustering is used to adapt the collected MHMC-EM emotional database to fit the CHI-MEI mood disorder database for dealing with the data bias problem. The adapted MHMC-EM emotional data are then fed to a denoising autoencoder for bottleneck feature extraction. The bottleneck features are used to construct a long short term memory (LSTM)-based emotion detector for generation of emotion profiles from each speech response. The emotion profiles are then clustered into emotion codewords using the K-means algorithm. Finally, a class-specific latent affective structure model (LASM) is proposed to model the structural relationships among the emotion codewords with respect to six emotional videos for mood disorder detection. Leave-one-group-out cross validation scheme was employed for the evaluation of the proposed class-specific LASM-based approaches. Experimental results show that the proposed class-specific LASM-based method achieved an accuracy of 73.33 percent for mood disorder detection, outperforming the classifiers based on SVM and LSTM.","1949-3045","","10.1109/TAFFC.2018.2803178","Ministry of Science and Technology, Taiwan(grant numbers:104-2221-E-006 -051 -MY3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8288569","Mood disorder;speech emotion recognition;latent affective structure model","Mood;Databases;Speech;Videos;Emotion recognition;Mental disorders;Feature extraction","emotion recognition;feature extraction;medical diagnostic computing;medical disorders;pattern clustering;psychology;speech processing;support vector machines","hierarchical spectral clustering;SVM;LASM;class-specific latent affective structure model;bottleneck feature extraction;multimedia human machine communication lab;CHI-MEI medical center;data adaptation;MHMC-EM emotional database;LSTM-based emotion detector;latent affective structure model;unipolar depressive disorder detection;bipolar depressive disorder detection;emotion codewords;emotion profiles;long short term memory-based emotion detector;eliciting emotional video clips;emotional videos;CHI-MEI mood disorder data collection;emotion annotation;short-term detection;elicited speech responses","","15","","55","IEEE","9 Feb 2018","","","IEEE","IEEE Journals"
"Deep Learning Assessment of Myocardial Infarction From MR Image Sequences","M. Chen; L. Fang; Q. Zhuang; H. Liu","State Key Laboratory of Modern Optical Instrumentation, Zhejiang University, Hangzhou, China; State Key Laboratory of Modern Optical Instrumentation, Zhejiang University, Hangzhou, China; Department of Cardiology, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Modern Optical Instrumentation, Zhejiang University, Hangzhou, China","IEEE Access","16 Jan 2019","2019","7","","5438","5446","The quantitative assessment of the location and size of myocardial infarction has important implications for the diagnosis and treatment of ischemic cardiac diseases. In particular, the tasks of optical flow estimation are of increasing interest in the motion analysis in the field of computer vision. In this paper, we propose a deep learning constrained framework, integrating optical flow features for the classification and localization of myocardial infarction from medical image sequences. The framework is composed of two stages. In the first stage, a stacked denoising autoencoder allows for the extraction of the intensity and motion characteristics from images. Thereafter, a support vector machine model is employed to predict the anomaly scores of each input. Initial experiments are performed with two-dimensional cardiac MRI sequences.","2169-3536","","10.1109/ACCESS.2018.2889744","National Key Technology Research and Development Program of China(grant numbers:2017YFE0104000); National Natural Science Foundation of China(grant numbers:61525106,61427807,U180920013,61701436,81873908); Shenzhen Innovation Fund(grant numbers:JCYJ20170818164343304,JCYJ20170816172431715); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598739","Deep learning;support vector machine;myocardial infarction","Myocardium;Support vector machines;Heart;Deep learning;Magnetic resonance imaging;Optical imaging;Feature extraction","","","","13","","28","OAPA","1 Jan 2019","","","IEEE","IEEE Journals"
"Deep Learning-Enabled Sparse Industrial Crowdsensing and Prediction","E. Wang; M. Zhang; X. Cheng; Y. Yang; W. Liu; H. Yu; L. Wang; J. Zhang","College of Computer Science and Technology, Jilin University, Changchun, China; College of Computer Science and Technology, Jilin University, Changchun, China; Department of Computer Science, Middlesex University, London, U.K.; College of Computer Science and Technology, Jilin University, Changchun, China; College of Computer Science and Technology, Jilin University, Changchun, China; College of Computer Science and Technology, Jilin University, Changchun, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; College of Cyber Science, Nankai University, Tianjin, China","IEEE Transactions on Industrial Informatics","15 Jun 2021","2021","17","9","6170","6181","Mobile Crowdsensing (MCS) is a powerful sensing paradigm, which provides sufficient social data for cognitive analytics in industrial sensing, and industrial manufacturing. Considering the sensing costs, sparse MCS, as a variant, only senses the data in a few subareas, and then infers the data of unsensed subareas by the spatio-temporal relationship of the sensed data. Existing works usually assume that the sensed data are linearly spatiotemporal dependent, which cannot work well in real-world nonlinear systems, and thus, result in low data inference accuracy. Moreover, in many cases, users not only require inferring the current data, but also have an interest in predicting the near future, which can provide more information for users' decision making. Facing these problems, we propose a deep learning-enabled industrial sensing, and prediction scheme based on sparse MCS, which consists of two parts: matrix completion and future prediction. Our goal is to achieve high-precision prediction of future moments under the hypothesis of sparse historical data. To make full use of the sparse data for prediction, we first propose a deep matrix factorization method, which can retain the nonlinear temporal-spatial relationship, and perform high-precision matrix completion. In order to predict the subareas' data in several future sensing cycles, we further propose a nonlinear autoregressive neural network, and a stacked denoising autoencoder to obtain the temporal-spatial correlation between the data from different cycles or subareas. According to the results gained by experiments on four real-world industrial sensing datasets consisting of six typical tasks, it can be seen that the method in this article improves the accuracy of prediction using sparse data.","1941-0050","","10.1109/TII.2020.3028616","National Natural Science Foundation of China(grant numbers:61772230,61972450); National Natural Science Foundation of China; Young Scholars(grant numbers:61702215); Natural Science Foundations of Jilin Province(grant numbers:20190201022JC); National Science Key Lab Fund(grant numbers:61421010418); Innovation Capacity Building Project of Jilin Province Development and Reform Commission(grant numbers:2020C017-2); Changchun Science and Technology Development Project(grant numbers:18DY005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9214506","Data inference;deep matrix completion;mobile crowdsensing (MCS);spatiotemporal series prediction","Sensors;Sparse matrices;Correlation;Manufacturing;Task analysis;Inference algorithms;Data models","autoregressive processes;decision making;learning (artificial intelligence);matrix decomposition;mobile computing;neural nets;spatiotemporal phenomena","sparse industrial Crowdsensing;Mobile Crowdsensing;powerful sensing paradigm;sufficient social data;industrial manufacturing;sensing costs;sparse MCS;senses;unsensed subareas;spatio-temporal relationship;sensed data;real-world nonlinear systems;low data inference accuracy;deep learning-enabled industrial sensing;prediction scheme;high-precision prediction;sparse historical data;sparse data;deep matrix factorization method;temporal-spatial relationship;high-precision matrix completion;future sensing cycles;real-world industrial sensing datasets","","12","","30","IEEE","6 Oct 2020","","","IEEE","IEEE Journals"
"Towards Unsupervised Speech-to-text Translation","Y. -A. Chung; W. -H. Weng; S. Tong; J. Glass","Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","17 Apr 2019","2019","","","7170","7174","We present a framework for building speech-to-text translation (ST) systems using only monolingual speech and text corpora, in other words, speech utterances from a source language and independent text from a target language. As opposed to traditional cascaded systems and end-to-end architectures, our system does not require any labeled data (i.e., transcribed source audio or parallel source and target text corpora) during training, making it especially applicable to language pairs with very few or even zero bilingual resources. The framework initializes the ST system with a cross-modal bilingual dictionary inferred from the monolingual corpora, that maps every source speech segment corresponding to a spoken word to its target text translation. For unseen source speech utterances, the system first performs word-by-word translation on each speech segment in the utterance. The translation is improved by leveraging a language model and a sequence denoising autoencoder to provide prior knowledge about the target language. Experimental results show that our unsupervised system achieves comparable BLEU scores to supervised end-to-end models despite the lack of supervision. We also provide an ablation analysis to examine the utility of each component in our system.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8683550","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8683550","speech-to-text translation;unsupervised speech processing;speech2vec;bilingual lexicon induction","Dictionaries;Training;Semantics;Laplace equations;Measurement;Eigenvalues and eigenfunctions;Buildings","language translation;natural language processing;speech processing;unsupervised learning","monolingual speech;cross-modal bilingual dictionary;target text translation;source speech segment;word-by-word translation;unsupervised speech-to-text translation systems","","12","","26","","17 Apr 2019","","","IEEE","IEEE Conferences"
"Action-Conditioned 3D Human Motion Synthesis with Transformer VAE","M. Petrovich; M. J. Black; G. Varol","LIGM, École des Ponts, Univ Gustave Eiffel, CNRS, France; Max Planck Institute for Intelligent Systems, Tübingen, Germany; LIGM, École des Ponts, Univ Gustave Eiffel, CNRS, France","2021 IEEE/CVF International Conference on Computer Vision (ICCV)","28 Feb 2022","2021","","","10965","10975","We tackle the problem of action-conditioned generation of realistic and diverse human motion sequences. In contrast to methods that complete, or extend, motion sequences, this task does not require an initial pose or sequence. Here we learn an action-aware latent representation for human motions by training a generative variational autoencoder (VAE). By sampling from this latent space and querying a certain duration through a series of positional encodings, we synthesize variable-length motion sequences conditioned on a categorical action. Specifically, we design a Transformer-based architecture, ACTOR, for encoding and decoding a sequence of parametric SMPL human body models estimated from action recognition datasets. We evaluate our approach on the NTU RGB+D, HumanAct12 and UESTC datasets and show improvements over the state of the art. Furthermore, we present two use cases: improving action recognition through adding our synthesized data to training, and motion denoising. Code and models are available on our project page [53].","2380-7504","978-1-6654-2812-5","10.1109/ICCV48922.2021.01080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9711041","Gestures and body pose;Action and behavior recognition;Neural generative models","Training;Solid modeling;Computer vision;Three-dimensional displays;Motion estimation;Noise reduction;Transformers","","","","10","","73","IEEE","28 Feb 2022","","","IEEE","IEEE Conferences"
"An Effective Patient Representation Learning for Time-series Prediction Tasks Based on EHRs","L. Lei; Y. Zhou; J. Zhai; L. Zhang; Z. Fang; P. He; J. Gao","School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; Shanghai Hospital Development Center, Shanghai, China; Shanghai Shuguang Hospital, Shanghai, China","2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","24 Jan 2019","2018","","","885","892","Electronic Health Records (EHRs) provide possibilities to improve patient care and facilitate clinical research. However, there are many challenges faced by the applications of EHRs, such as temporality, high dimensionality, sparseness, noise, random error, and systematic bias. In particular, temporal patient information is difficult to effectively use by traditional machine learning methods while the sequential information of EHRs is very useful. In this paper, we propose a general-purpose patient representation learning approach to summarize sequential EHRs. Specifically, a recurrent neural network based denoising autoencoder is employed to encode in hospital records of each patient into a low dimensional dense vector. Based on EHR data collected from Shanghai Shuguang Hospital, we experimentally evaluate our proposed method on both mortality prediction and comorbidity prediction tasks. Experimental studies show that our proposed method outperforms other reference methods based on raw EHRs data. We also apply the “Deep Feature” represented by our method to track similar patients with t-SNE, which also achieves interesting results.","","978-1-5386-5488-0","10.1109/BIBM.2018.8621542","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8621542","Deep learning;electronic health records;recurrent neural network;representation learning","Task analysis;Heart;Medical diagnostic imaging;Diseases;Hospitals;Predictive models;Machine learning","electronic health records;health care;learning (artificial intelligence);medical computing;medical information systems;patient care;patient treatment;recurrent neural nets;time series;vectors","time-series prediction tasks;patient care;clinical research;temporal patient information;sequential information;sequential EHRs;hospital records;low dimensional dense vector;EHR data;mortality prediction;comorbidity prediction tasks;electronic health records;general-purpose patient representation learning;Shanghai Shuguang Hospital;recurrent neural network","","9","","43","","24 Jan 2019","","","IEEE","IEEE Conferences"
"A deep learning technique for imputing missing healthcare data","S. Phung; A. Kumar; J. Kim","Biomedical and Multimedia Information Technology (BMIT) Research Group, School of Computer Science, The University of Sydney, Australia; Biomedical and Multimedia Information Technology (BMIT) Research Group, School of Computer Science, The University of Sydney, Australia; Biomedical and Multimedia Information Technology (BMIT) Research Group, School of Computer Science, The University of Sydney, Australia","2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","7 Oct 2019","2019","","","6513","6516","Missing data is a frequent occurrence in medical and health datasets. The analysis of datasets with missing data can lead to loss in statistical power or biased results. We address this issue with a novel deep learning technique to impute missing values in health data. Our method extends upon an autoencoder to derive a deep learning architecture that can learn the hidden representations of data even when data is perturbed by missing values (noise). Our model is constructed with overcomplete representation and trained with denoising regularization. This allows the latent/hidden layers of our model to effectively extract the relationships between different variables; these relationships are then used to reconstruct missing values. Our contributions include a new loss function designed to avoid local optima, and this helps the model to learn the real distribution of variables in the dataset. We evaluate our method in comparison with other well-established imputation strategies (mean, median imputation, SVD, KNN, matrix factorization and soft impute) on 48,350 Linked Birth/Infant Death Cohort Data records. Our experiments demonstrate that our method achieved lower imputation mean squared error (MSE=0.00988) compared with other imputation methods (with MSE ranging from 0.02 to 0.08). When assessing the imputation quality using the imputed data for prediction tasks, our experiments show that the data imputed by our method yielded better results (F1=70.37%) compared with other imputation methods (ranging from 66 to 69%).","1558-4615","978-1-5386-1311-5","10.1109/EMBC.2019.8856760","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8856760","","Data models;Deep learning;Noise reduction;Task analysis;Decoding;Support vector machines;Standards","data handling;learning (artificial intelligence);mean square error methods;medical information systems;singular value decomposition","deep learning technique;missing healthcare data;medical health datasets;statistical power;health data;deep learning architecture;hidden representations;well-established imputation strategies;mean imputation;median imputation;soft impute;lower imputation;imputation methods;imputation quality;imputed data","Deep Learning;Research Design","7","","22","","7 Oct 2019","","","IEEE","IEEE Conferences"
"CoDe-DTI: Collaborative Deep Learning-based Drug-Target Interaction Prediction","N. Yasuo; Y. Nakashima; M. Sekijima","Department of Computer Science, Tokyo Institute of Technology, Yokohama, Japan; Department of Computer Science, Tokyo Institute of Technology, Yokohama, Japan; Advanced Computational Drug Discovery Unit, Tokyo Institute of Technology, Yokohama, Japan","2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","24 Jan 2019","2018","","","792","797","Drug-target interaction (DTI) prediction is a problem that identifies novel protein-ligand interactions from previous information. DTI plays an important role in computer-aided drug discovery because it is related to many aspects of drug discovery, such as virtual screening, target prediction, side effect prediction, and drug repositioning. Previous methods can be divided into two types: content-based methods and collaborative filtering. However, both types have problems, namely, a lack of diversity and “cold-start” problems. In this study, we developed a new method named CoDe-DTI (COllaborative DEep learning-based Drug Target Interaction predictor) that combines both methods to avoid these problems. CoDe-DTI is based on collaborative deep learning, which introduces the information of chemical structures into the latent variables by combining probabilistic matrix factorization with a denoising autoencoder. Fivefold cross validation showed that CoDe-DTI significantly outperformed other machine learning-based methods regarding hit rate (top 5%). Comparing between drugwise cross validation and interactionwise cross validation, CoDe-DTI still works even when there is no interaction information of the input ligand exists. The source code for CoDe-DTI is available at: https://github.con/sekijima-lab/CoDe-DTI.","","978-1-5386-5488-0","10.1109/BIBM.2018.8621368","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8621368","Drug-target interaction prediction;Collaborative deep learning;Matrix factorization;Computer-aided drug discovery","Drugs;Collaboration;Diffusion tensor imaging;Probabilistic logic;Noise reduction;Deep learning;Matrix decomposition","bioinformatics;drugs;groupware;learning (artificial intelligence);matrix decomposition;proteins","protein-ligand interactions;computer-aided drug discovery;side effect prediction;drug repositioning;content-based methods;machine learning-based methods;interaction information;collaborative deep learning;CoDe-DTI;drug target interaction predictor","","6","","40","","24 Jan 2019","","","IEEE","IEEE Conferences"
"Energy Disaggregation Based Deep Learning Techniques: A pre-processing Stage to Enhance The Household Load Forecasting","A. F. Ebrahim; O. A. Mohammed","Department of Electrical and Computer Engineering, Florida International University, Miami, FL; Department of Electrical and Computer Engineering, Florida International University, Miami, FL","2018 IEEE Industry Applications Society Annual Meeting (IAS)","29 Nov 2018","2018","","","1","8","The development of the current power system grid is essential to serve the client better. Especially, with the massive expansion in the distribution network and the increase of renewable energy penetration. This development means the grid must be reliable, more flexible, and smarter. Households represent a massive portion of the grid infrastructure. The deployment of smart appliances enables the grid to be smarter through energy/demand side management based appliances control. Therefore, Short-Term Load Forecasting (STLF) is needed to help the energy management for households' systems. The main challenge for STLF at the household's level is the high uncertainty in the load demand. In this paper, a new method for households' STLF is employed. It consists of a Feed Forward artificial neural network (FFANN) and a preprocessing stage of Energy Disaggregation (ED) techniques. Extract the individual load pattern of household's appliances from the total load demand by the ED techniques, enlarge the training data set of the FFANN forecaster to achieve a remarkable improvement for its forecasting performance. Three deep neural network architectures have been used for energy disaggregation. 1) denoising autoencoder (DAE); 2) a unique type of a recurrent neural network (RNN) entitled long short-term memory (LSTM); 3) a network that provides rectangles for the estimated demand by regression the start time, end time and average power demand (nicknamed as RECTANGLES). The proposed method outperforms the state of the art techniques in household load forecasting regarding RMSE, NRMSE and MAE.","2576-702X","978-1-5386-4536-9","10.1109/IAS.2018.8544664","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8544664","Short-Term Load Forecasting (STLF);Feed-Forward Artificial Neural Network (FFANN);Energy Disaggregation (ED);and Household Load demand Forecasting;Deep Learning (DL)","Load forecasting;Home appliances;Recurrent neural networks;Feature extraction;Uncertainty","domestic appliances;feedforward neural nets;learning (artificial intelligence);load forecasting;power engineering computing;recurrent neural nets","STLF;energy management;preprocessing stage;energy disaggregation;individual load pattern;total load demand;ED techniques;FFANN forecaster;forecasting performance;deep neural network architectures;recurrent neural network;short-term memory;estimated demand;average power demand;household load forecasting;deep learning techniques;pre-processing stage;current power system grid;massive expansion;distribution network;renewable energy penetration;massive portion;grid infrastructure;smart appliances;feed forward artificial neural network;short-term load forecasting;energy-demand side management based appliances control","","6","","32","","29 Nov 2018","","","IEEE","IEEE Conferences"
"Robust and Efficient Classification for Underground Metal Target Using Dimensionality Reduction and Machine Learning","Y. Wan; T. Li; P. Wang; S. Duan; C. Zhang; N. Li","School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; Datang Gohigh Data Networks Technology Company Ltd., Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Materials Science and Engineering, University of Science and Technology Beijing, Beijing, China; School of Mathematics and Physics, University of Science and Technology Beijing, Beijing, China","IEEE Access","12 Jan 2021","2021","9","","7384","7401","Underground metal target detection technology has been widely applied in industrial production, resource exploration, and engineering construction, etc. However, due to the influence of non-negligible noise and high dimensionality in collected data, achieving efficient and accurate underground target classification remains a grand challenge for further applications of underground metal target detection on portable devices with limited computing capability and energy supply. This study aimed to seek out robust and efficient data-based strategies to classify the underground metal targets of different shapes and materials based on electromagnetic induction detection. We investigated thirty-three classification strategies based on eleven dimensionality reduction methods, namely, the least absolute shrinkage and selection operator (LASSO), genetic algorithm-support vector machine (GA-SVM), Pearson correlation coefficient (PCC), mutual information (MI), maximal relevance minimal redundancy Pearson correlation (mRMRP), maximal relevance minimal redundancy mutual information (mRMRMI), statistical features (SF), principal component analysis (PCA), kernel principal component analysis (KPCA), locally linear embedding (LLE), and stacked denoising autoencoder (SDAE), and three machine learning models, namely, artificial neural network (ANN), linear support vector machine (L-SVM), and Gaussian Naïve Bayes (GNB). Several parameters, including classification accuracy, the number of features after dimensionality, the feature type importance, and the time consumption were considered to evaluate the data-based classification strategies. Among the classification strategies investigated and considering the above evaluation parameters, the artificial neural network (ANN) classifier assisted with the kernel principal component analysis (KPCA) feature extraction method yielded the best performance in the material-based classification (accuracy:0.99) and the shape-based classification (accuracy:0.99). The locally linear embedding (LLE) improved the robustness of machine learning classifiers and efficiency of the artificial neural network in the material-based classification (improvement of average accuracy:0.17, reduction of classification time cost:14%) and shape-based classification (improvement of average accuracy:0.16, reduction of classification time cost:22%). Our comparative investigation provides a robust and efficient data-based strategy for underground metal target classification, which is significant for applications of underground metal target detection on portable devices with limited computing capability and energy supply. The cross-combination strategy of dimensionality reduction methods and machine learning models provides a way to find the optimal machine learning model for underground target detection.","2169-3536","","10.1109/ACCESS.2021.3049308","The National Key Research and Development Program of China(grant numbers:2017YFB0702300); National Natural Science Foundation of China(grant numbers:61971031); Scientific and Technological Innovation Foundation of Shunde Graduate School, USTB(grant numbers:BK19AF007); China Postdoctoral Science Foundation(grant numbers:2019M650778); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9314126","Dimensionality reduction;machine learning;underground target classification;underground target detection","Feature extraction;Metals;Object detection;Dimensionality reduction;Machine learning;Support vector machines;Principal component analysis","feature extraction;genetic algorithms;image classification;learning (artificial intelligence);neural nets;object detection;principal component analysis;support vector machines","underground metal target detection technology;target classification;accurate underground target classification;portable devices;computing capability;energy supply;electromagnetic induction detection;dimensionality reduction methods;genetic algorithm-support vector machine;kernel principal component analysis;locally linear embedding;machine learning models;linear support vector machine;classification accuracy;data-based classification strategies;artificial neural network classifier;material-based classification;shape-based classification;machine learning classifiers;classification time cost;underground metal target classification;optimal machine learning model;underground target detection","","5","","90","CCBY","5 Jan 2021","","","IEEE","IEEE Journals"
"Deep Neural Networks for In Situ Hybridization Grid Completion and Clustering","Y. Li; H. Huang; H. Chen; T. Liu","Department of Computer Science, University of Georgia, Athens; School of Automation, Northwestern Polytechnical University, Xi'an, China; Department of Computer Science, University of Georgia, Athens; Department of Computer Science, University of Georgia, Athens","IEEE/ACM Transactions on Computational Biology and Bioinformatics","2 Apr 2020","2020","17","2","536","546","Transcriptome in brain plays a crucial role in understanding the cortical organization and the development of brain structure and function. Two challenges, incomplete data and high dimensionality of transcriptome, remain unsolved. Here, we present a novel training scheme that successfully adapts the U-net architecture to the problem of volume recovery. By analogy to denoising autoencoder, we hide a portion of each training sample so that the network can learn to recover missing voxels from context. Then on the completed volumes, we show that Restricted Boltzmann Machines (RBMs) can be used to infer co-occurrences among voxels, providing foundations for dividing the cortex into discrete subregions. As we stack multiple RBMs to form a deep belief network (DBN), we progressively map the high-dimensional raw input into abstract representations and create a hierarchy of transcriptome architecture. A coarse to fine organization emerges from the network layers. This organization incidentally corresponds to the anatomical structures, suggesting a close link between structures and the genetic underpinnings. Thus, we demonstrate a new way of learning transcriptome-based hierarchical organization using RBM and DBN.","1557-9964","","10.1109/TCBB.2018.2864262","National Institutes of Health(grant numbers:R01 DA-033393,R01 AG-042599); National Science Foundation(grant numbers:IIS-1149260,BME-1302089,BCS-1439051,DBI-1564736); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8428473","Deep belief network;fully convolutional neural network;restricted Boltzmann machines;transcriptome architecture","Training;Brain;Neural networks;Organizations;Computer architecture;Measurement;Bioinformatics","","","Animals;Atlases as Topic;Brain;Cluster Analysis;Computational Biology;Gene Expression Profiling;Image Processing, Computer-Assisted;In Situ Hybridization;Mice;Neural Networks, Computer;Transcriptome","3","","47","IEEE","7 Aug 2018","","","IEEE","IEEE Journals"
"G-SimCLR: Self-Supervised Contrastive Learning with Guided Projection via Pseudo Labelling","S. Chakraborty; A. R. Gosthipaty; S. Paul",Walmart Labs; Netaji Subhash Engineering College; PyImageSearch,"2020 International Conference on Data Mining Workshops (ICDMW)","16 Feb 2021","2020","","","912","916","In the realms of computer vision, it is evident that deep neural networks perform better in a supervised setting with a large amount of labeled data. The representations learned with supervision are not only of high quality but also helps the model in enhancing its accuracy. However, the collection and annotation of a large dataset are costly and time-consuming. To avoid the same, there has been a lot of research going on in the field of unsupervised visual representation learning especially in a self-supervised setting. Amongst the recent advancements in self-supervised methods for visual recognition, in SimCLR Chen et al. shows that good quality representations can indeed be learned without explicit supervision. In SimCLR, the authors maximize the similarity of augmentations of the same image and minimize the similarity of augmentations of different images. A linear classifier trained with the representations learned using this approach yields 76.5% top-1 accuracy on the ImageNet ILSVRC-2012 dataset. In this work, we propose that, with the normalized temperature-scaled cross-entropy ($\boldsymbol{NT}-\boldsymbol{Xent}$) loss function (as used in SimCLR), it is beneficial to not have images of the same category in the same batch. In an unsupervised setting, the information of images pertaining to the same category is missing. We use the latent space representation of a denoising autoencoder trained on the unlabeled dataset and cluster them with k-means to obtain pseudo labels. With this apriori information we batch images, where no two images from the same category are to be found. We report comparable performance enhancements on the CIFAR10 dataset and a subset of the ImageNet dataset11https://github.com/thunderInfy/imagenet-5-categories. We refer to our method as $\boldsymbol{G}-\boldsymbol{SimCLR}$ 22Code available at https://github.com/ariG23498/G-SimCLR.","2375-9259","978-1-7281-9012-9","10.1109/ICDMW51313.2020.00131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9346544","Self-supervised Representation Learning;Clustering;Contrastive Learning;Visual Recognition","Training;Visualization;Conferences;Noise reduction;Neural networks;Labeling;Data mining","computer vision;entropy;image classification;image recognition;image representation;learning (artificial intelligence);neural nets;object detection","G-SimCLR;self-supervised contrastive learning;guided projection;pseudolabelling;realms;computer vision;deep neural networks;unsupervised visual representation learning;self-supervised setting;self-supervised methods;visual recognition;SimCLR Chen et al;good quality representations;explicit supervision;linear classifier;ImageNet ILSVRC-2012 dataset;normalized temperature-scaled cross-entropy;unsupervised setting;latent space representation;unlabeled dataset;pseudolabels;batch images;comparable performance enhancements;CIFARIO dataset;ImageNet dataset","","3","","26","IEEE","16 Feb 2021","","","IEEE","IEEE Conferences"
"Video Anomaly Detection using Pre-Trained Deep Convolutional Neural Nets and Context Mining","C. Wu; S. Shao; C. Tunc; S. Hariri","NSF Center for Cloud and Autonomic Computing, The University of Arizona, Tucson, Arizona; NSF Center for Cloud and Autonomic Computing, The University of Arizona, Tucson, Arizona; Department of Computer Science & Engineering, The University of North Texas, Denton, Texas; NSF Center for Cloud and Autonomic Computing, The University of Arizona, Tucson, Arizona","2020 IEEE/ACS 17th International Conference on Computer Systems and Applications (AICCSA)","13 Jan 2021","2020","","","1","8","Anomaly detection is critically important for intelligent surveillance systems to detect in a timely manner any malicious activities. Many video anomaly detection approaches using deep learning methods focus on a single camera video stream with a fixed scenario. These deep learning methods use large-scale training data with large complexity. As a solution, in this paper, we show how to use pre-trained convolutional neural net models to perform feature extraction and context mining, and then use denoising autoencoder with relatively low model complexity to provide efficient and accurate surveillance anomaly detection, which can be useful for the resource-constrained devices such as edge devices of the Internet of Things (IoT). Our anomaly detection model makes decisions based on the high-level features derived from the selected embedded computer vision models such as object classification and object detection. Additionally, we derive contextual properties from the high-level features to further improve the performance of our video anomaly detection method. We use two UCSD datasets to demonstrate that our approach with relatively low model complexity can achieve comparable performance compared to the state-of-the-art approaches.","2161-5330","978-1-7281-8577-4","10.1109/AICCSA50499.2020.9316538","Air Force Office of Scientific Research (AFOSR); National Science Foundation(grant numbers:NSF-1624668,NSF-1849113,DUE-1303362); National Institute of Standards and Technology (NIST)(grant numbers:70NANB18H263); Department of Energy; National Nuclear Security Administration(grant numbers:DE-NA0003946); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9316538","Security;video surveillance;anomaly video analysis;abnormal event detection;deep features;context mining","Feature extraction;Anomaly detection;Computational modeling;Task analysis;Streaming media;Semantics;Cameras","computer vision;convolutional neural nets;data mining;deep learning (artificial intelligence);feature extraction;image classification;image representation;object detection;video signal processing;video streaming;video surveillance","object classification;object detection;video anomaly detection method;deep convolutional neural nets;context mining;intelligent surveillance systems;single camera video stream;large-scale training data;convolutional neural net models;feature extraction;anomaly detection model;surveillance anomaly detection;deep learning methods;embedded computer vision models;UCSD dataset;Internet of Things","","3","","36","","13 Jan 2021","","","IEEE","IEEE Conferences"
"Pixel-Wise Failure Prediction For Semantic Video Segmentation","C. B. Kuhn; M. Hofbauer; Z. Xu; G. Petrovic; E. Steinbach","Automated and Autonomous Driving Division, BMW Group, Munich, Germany; Chair of Media Technology, Technical University of Munich, Munich, Germany; Chair of Media Technology, Technical University of Munich, Munich, Germany; Automated and Autonomous Driving Division, BMW Group, Munich, Germany; Chair of Media Technology, Technical University of Munich, Munich, Germany","2021 IEEE International Conference on Image Processing (ICIP)","23 Aug 2021","2021","","","614","618","We propose a pixel-accurate failure prediction approach for semantic video segmentation. The proposed scheme improves previously proposed failure prediction methods which so far disregarded the temporal information in videos. Our approach consists of two main steps: First, we train an LSTM-based model to detect spatio-temporal patterns that indicate pixel-wise misclassifications in the current video frame. Second, we use sequences of failure predictions to train a denoising autoencoder that both refines the current failure prediction and predicts future misclassifications. Since public data sets for this scenario are limited, we introduce the large-scale densely annotated video driving (DAVID) data set generated using the CARLA simulator. We evaluate our approach on the real-world Cityscapes data set and the simulator-based DAVID data set. Our experimental results show that spatiotemporal failure prediction outperforms single-image failure prediction by up to 8.8%. Refining the prediction using a sequence of previous failure predictions further improves the performance by a significant 15.2% and allows to accurately predict misclassifications for future frames. While we focus our study on driving videos, the proposed approach is general and can be easily used in other scenarios as well.","2381-8549","978-1-6654-4115-5","10.1109/ICIP42928.2021.9506552","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506552","Semantic Segmentation;Failure Prediction;Introspection;Recurrent Neural Network","Training;Image segmentation;Semantics;Noise reduction;Video sequences;Refining;Predictive models","image motion analysis;image segmentation;image sequences;learning (artificial intelligence);recurrent neural nets;spatiotemporal phenomena;video signal processing","current video frame;current failure prediction;future misclassifications;public data sets;real-world Cityscapes data;simulator-based DAVID data;spatiotemporal failure prediction;single-image failure prediction;previous failure predictions;driving videos;pixel-wise failure prediction;semantic video segmentation;pixel-accurate failure prediction approach;failure prediction methods;temporal information;LSTM-based model;spatio-temporal patterns;pixel-wise misclassifications","","3","","20","IEEE","23 Aug 2021","","","IEEE","IEEE Conferences"
"Mood disorder identification using deep bottleneck features of elicited speech","K. -Y. Huang; C. -H. Wu; M. -H. Su; C. -H. Chou","Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan","2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","8 Feb 2018","2017","","","1648","1652","In the diagnosis of mental health disorder, a large portion of the Bipolar Disorder (BD) patients is likely to be misdiagnosed as Unipolar Depression (UD) on initial presentation. As speech is the most natural way to express emotion, this work focuses on tracking emotion profile of elicited speech for short-term mood disorder identification. In this work, the Deep Scattering Spectrum (DSS) and Low Level Descriptors (LLDs) of the elicited speech signals are extracted as the speech features. The hierarchical spectral clustering (HSC) algorithm is employed to adapt the emotion database to the mood disorder database to alleviate the data bias problem. The denoising autoencoder is then used to extract the bottleneck features of DSS and LLDs for better representation. Based on the bottleneck features, a long short term memory (LSTM) is applied to generate the time-varying emotion profile sequence. Finally, given the emotion profile sequence, the HMM-based identification and verification model is used to determine mood disorder. This work collected the elicited emotional speech data from 15 BDs, 15 UDs and 15 healthy controls for system training and evaluation. Five-fold cross validation was employed for evaluation. Experimental results show that the system using the bottleneck feature achieved an identification accuracy of 73.33%, improving by 8.89%, compared to that without bottleneck features. Furthermore, the system with verification mechanism, improving by 4.44%, outperformed that without verification.","","978-1-5386-1542-3","10.1109/APSIPA.2017.8282296","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8282296","","Hidden Markov models;Feature extraction;Emotion recognition;Speech;Mood;Speech recognition;Acoustics","emotion recognition;feature extraction;hidden Markov models;learning (artificial intelligence);neural nets;speech processing;speech recognition","mental health disorder;UD;short-term mood disorder identification;DSS;elicited speech signals;speech features;hierarchical spectral clustering algorithm;emotion database;mood disorder database;long short term memory;time-varying emotion profile sequence;elicited emotional speech data;identification accuracy;bipolar disorder patients;deep scattering spectrum;low level descriptors;LLD","","2","","19","","8 Feb 2018","","","IEEE","IEEE Conferences"
"Fault Diagnosis and Health Assessment of Landing Gear Hydraulic Retraction System Based on Multi-source Information Feature Fusion","K. Liu; Y. Feng; X. Xue","Department of Aircraft Design Engineering, Northwestern Polytechnical University, Xi'an, China; Department of Aircraft Design Engineering, Northwestern Polytechnical University, Xi'an, China; Department of Aircraft Design Engineering, Northwestern Polytechnical University, Xi'an, China","2017 International Conference on Sensing, Diagnostics, Prognostics, and Control (SDPC)","14 Dec 2017","2017","","","321","327","In order to solve the problems that a single signal cannot provide sufficient fault information, while the direct using of multi-sensor signals for fusion diagnosis will lead to a heavy calculation which will reduce the diagnostic efficiency, a multi-source information feature fusion method is proposed in this paper. The stacked denoising autoencoders (SDAE) is used to extract the abstract features of time-domain features of multi-source signals, and then locality preserving projection (LPP) is used to dimension reduction to complete the feature fusion. Finally, the fused low-dimensional features act as inputs to the support vector machine (SVM) to realize the failure detection and fault location of typical fault modes of the landing gear hydraulic retraction system. The inhibitory effect of the closed-loop system on the incipient fault is discussed as well. Moreover, a health assessment method is presented considering the gradual degradation of leakage fault of the actuator. The results show that the proposed method is more accurate and reliable than any single signal result. The model of health assessment can give the internal leakage severity of the actuator. The significance of this paper is to provide a feasible idea of the fault diagnosis and health assessment of the landing gear hydraulic retraction system.","","978-1-5090-4020-9","10.1109/SDPC.2017.68","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8186524","fault diagnosis;health assessment;landing gear;hydraulic retraction system;multi-source;SDAE;LPP;feature fusion;closed-loop","Gears;Fault diagnosis;Feature extraction;Support vector machines;Valves;Actuators","condition monitoring;fault diagnosis;fault location;feature extraction;gears;hydraulic systems;mechanical engineering computing;sensor fusion;support vector machines","fault diagnosis;landing gear hydraulic retraction system;multisource information feature fusion;multisensor signals;fusion diagnosis;time-domain features;multisource signals;low-dimensional features;failure detection;fault location;health assessment method;leakage fault;single signal result;fault information;abstract feature extraction","","2","","22","","14 Dec 2017","","","IEEE","IEEE Conferences"
"SKYNET: an efficient and robust neural network training tool for machine learning in astronomy","P. Graff; F. Feroz; M. P. Hobson; A. Lasenby",NA; NA; NA; NA,"Monthly Notices of the Royal Astronomical Society","19 Jan 2018","2014","441","2","1741","1759","We present the first public release of our generic neural network training algorithm, called SKYNET. This efficient and robust machine learning tool is able to train large and deep feed-forward neural networks, including autoencoders, for use in a wide range of supervised and unsupervised learning applications, such as regression, classification, density estimation, clustering and dimensionality reduction. SKYNET uses a ‘pre-training’ method to obtain a set of network parameters that has empirically been shown to be close to a good solution, followed by further optimization using a regularized variant of Newton's method, where the level of regularization is determined and adjusted automatically; the latter uses second-order derivative information to improve convergence, but without the need to evaluate or store the full Hessian matrix, by using a fast approximate method to calculate Hessian-vector products. This combination of methods allows for the training of complicated networks that are difficult to optimize using standard backpropagation techniques. SKYNET employs convergence criteria that naturally prevent overfitting, and also includes a fast algorithm for estimating the accuracy of network outputs. The utility and flexibility of SKYNET are demonstrated by application to a number of toy problems, and to astronomical problems focusing on the recovery of structure from blurred and noisy images, the identification of gamma-ray bursters, and the compression and denoising of galaxy images. The SKYNET software, which is implemented in standard ANSI C and fully parallelized using MPI, is available at http://www.mrao.cam.ac.uk/software/skynet/.","1365-2966","","10.1093/mnras/stu642","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8180871","methods: data analysis;methods: statistical","","","","","1","1","","","19 Jan 2018","","","OUP","OUP Journals"
"Fault Diagnosis of SF<sub>6</sub>-insulated Equipment by Micro Gas Sensor Array","J. Chu; Q. Wang; Y. Liu; J. Pan; H. Yuan; A. Yang; X. Wang; M. Rong","State Key Laboratory of Electrical Insulation and Power Equipment, School of Electrical Engineering, Xi&#x0027;an Jiaotong University, Xi&#x0027;an, China; State Key Laboratory of Electrical Insulation and Power Equipment, School of Electrical Engineering, Xi&#x0027;an Jiaotong University, Xi&#x0027;an, China; State Key Laboratory of Electrical Insulation and Power Equipment, School of Electrical Engineering, Xi&#x0027;an Jiaotong University, Xi&#x0027;an, China; State Key Laboratory of Electrical Insulation and Power Equipment, School of Electrical Engineering, Xi&#x0027;an Jiaotong University, Xi&#x0027;an, China; State Key Laboratory of Electrical Insulation and Power Equipment, School of Electrical Engineering, Xi&#x0027;an Jiaotong University, Xi&#x0027;an, China; State Key Laboratory of Electrical Insulation and Power Equipment, School of Electrical Engineering, Xi&#x0027;an Jiaotong University, Xi&#x0027;an, China; State Key Laboratory of Electrical Insulation and Power Equipment, School of Electrical Engineering, Xi&#x0027;an Jiaotong University, Xi&#x0027;an, China; State Key Laboratory of Electrical Insulation and Power Equipment, School of Electrical Engineering, Xi&#x0027;an Jiaotong University, Xi&#x0027;an, China","IEEE Transactions on Power Delivery","","2022","PP","99","1","9","SF<sub>6</sub> decomposition products could reflect the running status and inner faults of power equipment, and it's expected to realize a timely warning. In this work, six faults including spark and corona discharge were simulated, and SF<sub>6</sub> decomposition products with various types and contents were obtained as well. Different from previous investigations employing precision instruments, such as gas chromatography and infrared spectroscopy, a micro sensor array loaded with three gas-sensitive nanomaterials was used to discriminate fault characteristic gases, performing obvious advantages in small size, high integration, and rapid detection. Gas chromatography-mass spectrometry (GCMS) indicated that seven analytes had significant differences in types and contents. Meanwhile, the as-prepared micro gas sensor array also outputted significantly various signals for seven analytes, which provided a basis for gas identification. With the assistance of stacked denoising autoencoder (SDAE)-based discrimination algorithms, the recognition model between the response signals of the array and the discharge faults in power equipment could be established. In comparison with KNN (66.67 %), decision tree (70.47 %), and BPNN (73.33 %), SVM has achieved the highest average accuracy of 75.23 %. Totally, this work provides a promising novel method for rapid on-site inspection of SF<sub>6</sub>-insulated power equipment.","1937-4208","","10.1109/TPWRD.2022.3184687","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9801662","Spark discharge;corona discharge;SF<sub xmlns:ali=""http://www.niso.org/schemas/ali/1.0/"" xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"">6</sub> decomposition products;gas sensor array;fault diagnosis;on-site inspection","Discharges (electric);Sensor arrays;Needles;Electrodes;Sparks;Corona;Voltage","","","","","","","IEEE","20 Jun 2022","","","IEEE","IEEE Early Access Articles"
"Research of Quality Prediction Based on Extreme Learning Machine","Y. Yinghua; S. Zeping; L. Xiaozhi","College of Information Science and Engineering, Northeastern University, Shenyang; College of Information Science and Engineering, Northeastern University, Shenyang; College of Information Science and Engineering, Northeastern University, Shenyang","2020 Chinese Control And Decision Conference (CCDC)","11 Aug 2020","2020","","","1943","1947","Aiming at the problems of poor stability and generalization performance in quality prediction based on extreme learning machine (ELM), this paper presents an improved method of ELM. It is named as the DAE-P-ELM algorithm, which integrates denoising autoencoder (DAE) with principal component analysis (PCA). First, in order to reflect the characteristics and intrinsic relationship of the modeling data as much as possible, DAE technology is introduced to reconstruct the input data. Therefore, output weight sufficiently containing the input data information is obtained, which is used as input weight of the ELM. Then, the PCA technology is used to reduce the dimension of the hidden layer output matrix to avoid the multicollinear problem in calculation of output weight matrix, which solves the problem of poor stability of the model due to too many hidden layer nodes. Finally, the method is applied to the Tennessee Eastman (TE) process. The simulation results show that the content of components G and H predicted by this method is basically consistent with the real value, which proves that the proposed method has a good prediction effect.","1948-9447","978-1-7281-5855-6","10.1109/CCDC49329.2020.9164243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9164243","Quality prediction;ELM;DAE;PCA;TE","Principal component analysis;Prediction algorithms;Data models;Decoding;Dimensionality reduction;Noise reduction;Predictive models","feedforward neural nets;learning (artificial intelligence);matrix algebra;principal component analysis;production engineering computing;quality control;regression analysis","quality prediction;extreme learning machine;generalization performance;DAE-P-ELM algorithm;principal component analysis;DAE technology;input data information;PCA technology;hidden layer output matrix;multicollinear problem;output weight matrix;Tennessee Eastman process","","","","10","","11 Aug 2020","","","IEEE","IEEE Conferences"
"Self-supervised Learning for Sonar Image Classification","A. Preciado-Grijalva; B. Wehbe; M. B. Firvida; M. Valdenegro-Toro","Bonn-Rhein-Sieg University of Applied Sciences, Sankt Augustin, Germany; German Research Center for Artificial Intelligence, Bremen, Germany; German Research Center for Artificial Intelligence, Bremen, Germany; Department of AI, University of Groningen, Groningen, The Netherlands","2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","23 Aug 2022","2022","","","1498","1507","Self-supervised learning has proved to be a powerful approach to learn image representations without the need of large labeled datasets. For underwater robotics, it is of great interest to design computer vision algorithms to improve perception capabilities such as sonar image classification. Due to the confidential nature of sonar imaging and the difficulty to interpret sonar images, it is challenging to create public large labeled sonar datasets to train supervised learning algorithms. In this work, we investigate the potential of three self-supervised learning methods (RotNet, Denoising Autoencoders, and Jigsaw) to learn high-quality sonar image representation without the need of human labels. We present pre-training and transfer learning results on real-life sonar image datasets. Our results indicate that self-supervised pre-training yields classification performance comparable to supervised pre-training in a few-shot transfer learning setup across all three methods. Code and self-supervised pre-trained models are be available at agrija9/ssl-sonar-images.","2160-7516","978-1-6654-8739-9","10.1109/CVPRW56347.2022.00156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9857338","","Computer vision;Transfer learning;Supervised learning;Noise reduction;Sonar;Self-supervised learning;Image representation","computer vision;image classification;image representation;sonar imaging;supervised learning","sonar image classification;image representations;labeled datasets;computer vision algorithms;sonar imaging;sonar images;public large labeled sonar datasets;supervised learning algorithms;self-supervised learning methods;high-quality sonar image representation;transfer learning results;real-life sonar image datasets;self-supervised pre-training yields classification performance;self-supervised pre-trained","","","","45","IEEE","23 Aug 2022","","","IEEE","IEEE Conferences"
"SE-Loc: Security-Enhanced Indoor Localization with Semi-Supervised Deep Learning","Q. Ye; X. Fan; H. Bie; D. Puthal; T. Wu; X. Song; G. Fang","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing, China; Department of Electronic Engineering, Tsinghua University, 12442 Beijing, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing, China; Department of Electrical Engineering and Computer Science, Khalifa University, 105955 Abu Dhabi, Abu Dhabi, United Arab Emirates; School of Electronic Engineering, National University of Defense Technology, 58294 Heifei, Anhui, China; University of Technology Sydney, 1994 Sydney, New South Wales, Australia; School of Electrical and Data Engineering, University of Technology Sydney, 1994 Sydney, New South Wales, Australia","IEEE Transactions on Network Science and Engineering","","2022","PP","99","1","1","Wireless indoor localization has become unavoidable for industrial indoor location-based services. Given the ubiquitous deployment of wireless access points (APs), WiFi fingerprinting of Received Signal Strength (RSS) has been widely adopted for indoor localization. Meanwhile, existing RSS fingerprint-based methods lack security-oriented considerations and are vulnerable to malicious attacks. When security vulnerabilities are exploited, mobile users may confront indoor localization mismatches, faults and even localization system failures. In this paper, we propose SE-Loc, a semi-supervised learning-based technique to enhance security and resiliency of fingerprint-based localization. The architecture of SE-Loc consists of two parts: (1) a correlation-based AP selection for processing RSS fingerprints and fingerprint-image generation, and (2) a deep learning model based on a denoising autoencoder and convolutional neural networks for robust feature learning and location matching. Extensive experiments show that under potential AP attacks, SE-Loc demonstrates superior performance on indoor localization over the state-of-the-art methods. With up to 100 malicious attacking APs in the UJIIndoorLoc edge server, SE-Loc can still achieve the lowest error fluctuation of 1.7 m and the highest average localization accuracy of 8.9 m.","2327-4697","","10.1109/TNSE.2022.3174674","National Natural Science Foundation of China(grant numbers:62002377); Hong Kong Scholars Program(grant numbers:No. 2021-101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9780234","Computational Intelligence;Wireless Indoor Localization;Semi-supervised Deep Learning;Internet of Things","Location awareness;Security;Wireless fidelity;Interference;Deep learning;Feature extraction;Internet of Things","","","","","","","IEEE","23 May 2022","","","IEEE","IEEE Early Access Articles"
"Abnormal Traffic Detection: Traffic Feature Extraction and DAE-GAN With Efficient Data Augmentation","Z. Li; S. Chen; H. Dai; D. Xu; C. -K. Chu; B. Xiao","Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Huawei Technologies Company Ltd. Singapore, Singapore; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong","IEEE Transactions on Reliability","","2022","PP","99","1","13","Abnormal traffic detection is the core component of the network intrusion detection system. Although semisupervised methods can detect zero-day attack traffic, previous work suffers from high false alarms because the trained model is simply based on normal traffic. In this article, we propose an accurate abnormal traffic detection method using pseudoanomaly, consisting of an efficient feature extraction framework and a novel denoise autoencoder-generative adversarial network (DAE-GAN) model. The feature extraction framework adopts an innovative packet window scheme to extract spatial and temporal features from traffic flows. The DAE-GAN model has multiple DAEs to achieve efficient data augmentation and generate high-quality pseudoanomalies. The pseudoanomalies are obtained by adding noise on normal traffic and enhanced by adversarial learning in DAE-GAN. Our semisupervised detection method, exploiting both normal data and generated pseudoanomalies, achieves a precision of 98.6% on the NSL-KDD dataset and 98.5% on the UNSW-NB15 dataset. Compared with the state-of-the-art, the detection precision and recall under different user behaviors are significantly improved. The evaluation on four attack datasets shows that our method has a high flow-wise precision of over 99% and a high recall of 60.6%.","1558-1721","","10.1109/TR.2022.3204349","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9893038","Abnormal traffic detection;adversarial training;anomaly detection;deep learning;DNN;generative adversarial networks (GAN);malware","Feature extraction;Data models;Training;Anomaly detection;Generators;Computational modeling;Adversarial machine learning","","","","","","","IEEE","14 Sep 2022","","","IEEE","IEEE Early Access Articles"
"A Semi-Supervised Ladder Network-based Indoor Localization using Channel State Information","Y. -W. He; T. -T. Hsu; P. -H. Tseng","Department of Electronic Engineering, National Taipei University of Technology, Taipei, Taiwan; AsusTek Computer Inc, Taiwan; Department of Electronic Engineering, National Taipei University of Technology, Taipei, Taiwan","IEEE Transactions on Instrumentation and Measurement","","2022","PP","99","1","1","We propose a ladder network-based fingerprinting (LadderNetFi) method, which combines unsupervised learning with supervised learning in the neural network model for channel state information (CSI)-based indoor localization. The unsupervised part of LadderNetFi, which serves as a denoising autoencoder with skip connections from its encoder to the decoder, focuses on detailed features related to supervised learning. By dealing with the measurement uncertainty in the architecture design, a better generalization of fingerprints from the pre-processing of CSI amplitude leads to performance improvement compared to other deep learning-based methods. As semi-supervised learning, we verify that LadderNet trained using only a small portion of labeled measurements with the unlabeled measurements, e.g., 2,000 versus 20,000, and only a part of reference points, e.g., 19 versus 31, provides better performance than state-of-art methods using all labeled measurements. By reducing human labor from labeling, the deployment for LadderNetFi is scalable.","1557-9662","","10.1109/TIM.2022.3210964","Ministry of Science and Technology of Taiwan(grant numbers:110-2221-E-027-039,111-2221-E-027-055-MY2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9906122","Indoor Localization;Fingerprinting;Semi-supervised Learning;Channel State Information;Deep Learning","Location awareness;Fingerprint recognition;Feature extraction;Position measurement;Artificial neural networks;Wireless fidelity;Semisupervised learning","","","","","","","IEEE","30 Sep 2022","","","IEEE","IEEE Early Access Articles"
"Improving deep learning based anomaly detection on multivariate time series through separated anomaly scoring","A. Lundström; M. O’Nils; F. Qureshi; A. Jantsch","SCA, Sundsvall, Sweden; Department of Electronics Design, Mid Sweden University, Sundsvall, Sweden; Faculty of Science, University of Ontario Institute of Technology, Oshawa, ON, Canada; Institute of Computer Technology, TU Wien, Vienna, Austria","IEEE Access","","2022","PP","99","1","1","The importance of anomaly detection in multivariate time series has led to the development of several prominent deep learning solutions. As a part of the anomaly detection method, the scoring method has shown to be of significant importance when separating non-anomalous points from anomalous ones. At this time, most of the solutions utilize an aggregated score which means that relevant information created by the anomaly detection model might be lost. Therefore, this study has set out to examine to what extent anomaly detection in multivariate time series based on deep learning can be improved if all the residuals from each individual channel is considered in the anomaly score. To achieve this, an aggregated and separated scoring method has been applied with a simple denoising convulutional autoencoder (DCAE). In addition, the performance has been compared with other state-of-the-art methods. The result showed that the separated approach has the potential to generate a significantly higher performance than the aggregated one. At the same time, there were some indications suggesting that an aggregated scoring is better at generalizing when no labels to base the anomaly thresholds on, are available. Therefore, the result should serve as an encouragement to use a separated scoring approach together with a small sample of labeled anomalies to optimise the thresholds. Lastly, due to the impact of the anomaly score, the result suggests that future research within this field should consider applying the same anomaly scoring method when comparing the performance of deep learning algorithms.","2169-3536","","10.1109/ACCESS.2022.3213038","The Knowledge Foundation (kks.se) within the Industrial graduate school Smart Industry Sweden.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9913974","Anomaly detection;Anomaly scoring;Deep learning;Multivariate time series (MVTS)","Anomaly detection;Time series analysis;Deep learning;Training data;Optimization;Predictive models;Generative adversarial networks","","","","","","","CCBY","10 Oct 2022","","","IEEE","IEEE Early Access Articles"
"Parallel LSTM Architectures for Non-Intrusive Load Monitoring in Smart Homes","M. Mobasher-Kashani; N. Noman; S. Chalup","School of Electr. Eng. and Computing, The University of Newcastle, Callaghan NSW, Australia; School of Electr. Eng. and Computing, The University of Newcastle, Callaghan NSW, Australia; School of Electr. Eng. and Computing, The University of Newcastle, Callaghan NSW, Australia","2020 IEEE Symposium Series on Computational Intelligence (SSCI)","5 Jan 2021","2020","","","1272","1279","Non-Intrusive Load Monitoring (NILM) is becoming popular as an appliance monitoring technique that can extract detailed power consumption information related to the different appliances used in a household. NILM utilises time series analysis methods to disaggregate signals of operating appliances from a single point in houses. Based on that it can help to provide energy consumption advice for household owners. NILM is known to be a challenging task from a computational aspect. This study proposes deep neural network models with a Parallel Long Short-Term Memory Topology (PLT) and evaluates them on the public REDD dataset. The new models' experimental evaluation results exhibit a significant improvement in four main state-based and energy-based metrics in comparison to previous results obtained using deep denoising autoencoders.","","978-1-7281-2547-3","10.1109/SSCI47803.2020.9308592","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308592","","Hidden Markov models;Measurement;Feature extraction;Deep learning;Convolution;Topology;Computational modeling","building management systems;domestic appliances;learning (artificial intelligence);neural nets;power consumption;recurrent neural nets;time series","different appliances;NILM utilises time series analysis methods;operating appliances;energy consumption advice;household owners;deep neural network models;Parallel Long Short-Term Memory Topology;Parallel LSTM architectures;nonIntrusive Load Monitoring;smart homes;NonIntrusive Load Monitoring;appliance monitoring technique;power consumption information","","","","32","","5 Jan 2021","","","IEEE","IEEE Conferences"
"A combined Feature extraction technique for cancer classification based on deep learning approach","S. Mishra; M. Bhattacharya","Dept. of Information Technology, ABV-Indian Institute of Information Technology and Management, Gwalior, India; Dept. of Information Technology, ABV-Indian Institute of Information Technology and Management, Gwalior, India","2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","14 Jan 2022","2021","","","1","7","Extraction from large no. of features (genes signatures) are the major issues in the prediction of cancer and its specific type identification using microarray datasets. Even though most classifiers predict the class (normal or cancerous) for various cancers, the accuracy of prediction still suffers. This is due to the importance of fewer gene signatures for a particular cancer and classification of samples independent from their originating form. The present paper proposes gene extraction techniques to work in an unsupervised manner. The proposed technique takes the advantage of both linear and non-linear feature extraction methods. Principal component analysis (PCA) is used in a linear manner whereas Denoising Autoencoder (DAE) is used in a nonlinear manner. In the first phase of the work, feature space extracts from both the methods have been combined and new features space has been utilized for cancer classification. Here, Four classifiers: Support vector machine (SVM), Multilayer perceptron (MLP), Naive Bays (NB) and Decision Tree are applied on a no. of gene signatures extracted from four different cancer datasets. It is seen that after feature extraction from this PCA-DAE, classification accuracy either increases or attains its maximum value in comparison with base techniques except NB.","","978-1-6654-0126-5","10.1109/BIBM52615.2021.9669466","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669466","DAE;Feature reduction;Microarray;PCA;Linear and non linear technique;Unsupervised learning","Support vector machines;Dimensionality reduction;Deep learning;Noise reduction;Multilayer perceptrons;Feature extraction;Gene expression","biology computing;cancer;decision trees;feature extraction;genetics;learning (artificial intelligence);multilayer perceptrons;pattern classification;principal component analysis;support vector machines","cancer classification;classifiers;different cancer datasets;classification accuracy;base techniques;combined Feature extraction technique;deep learning approach;genes signatures;specific type identification;microarray datasets;class;fewer gene signatures;particular cancer;gene extraction techniques;unsupervised manner;nonlinear feature extraction methods;principal component analysis;linear manner;nonlinear manner;space extracts;features space","","","","23","IEEE","14 Jan 2022","","","IEEE","IEEE Conferences"
"Heterogeneous Graph Convolutional Network integrates Multi-modal Similarities for Drug-Target Interaction Prediction","L. Jiang; J. Sun; Y. Wang; Q. Ning; N. Luo; M. Yin","Information Science and Technology, Northeast Normal University, Changchun; Information Science and Technology, Northeast Normal University, Changchun; Information Science and Technology, Dalian Maritime University, Dalian; Information Science and Technology, Dalian Maritime University, Dalian; Information Science and Technology, Northeast Normal University, Changchun; Information Science and Technology, Northeast Normal University, Changchun","2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)","14 Jan 2022","2021","","","137","140","Accurate identification of drug-target interactions (DTIs) play a crucial role in drug discovery. Conventional computational methods almost simply view heterogeneous networks which integrate diverse drug-related and target-related dataset instead of fully explored drug and protein similarities. In this paper, we propose a new method, named HGSDTI. Firstly, the low-dimensional features of drugs, proteins, diseases and side-effects are obtained by a denoising autoencoder. Then, we construct a heterogeneous network across drug, protein, disease and side-effect nodes, and a three-layer graph convolutional network (GCN) is applied to learn the neighbor topology information and integrate the low-dimensional features of nodes. Next, we calculate multi-modal drug similarities and protein similarities from multi-scale relations between drugs, proteins, diseases and side-effects. Finally, a multiple-layer convolutional neural network (CNN) deeply integrate similarity information of drugs and proteins with the neighbor topology information. Experiments have demonstrated its effectiveness and better performance than state-of-the-art methods.","","978-1-6654-0126-5","10.1109/BIBM52615.2021.9669468","Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669468","Heterogeneous Graph Convolutional Network;Convolutional Neural Network;Multi-modal similarities","Drugs;Proteins;Protein engineering;Network topology;Noise reduction;Feature extraction;Heterogeneous networks","biology computing;diseases;drugs;feature extraction;graph theory;learning (artificial intelligence);neural nets;proteins","heterogeneous graph convolutional network;multimodal similarities;drug-target interaction prediction;drug-target interactions;drug discovery;conventional computational methods;heterogeneous network;diverse drug-related;fully explored drug;protein similarities;drugs;proteins;diseases;disease;side-effect nodes;three-layer graph convolutional network;neighbor topology information;multimodal drug similarities;multiscale relations;multiple-layer convolutional neural network;similarity information","","","","13","IEEE","14 Jan 2022","","","IEEE","IEEE Conferences"
"Compression of Solar Spectroscopic Observations: a Case Study of Mg II k Spectral Line Profiles Observed by NASA's IRIS Satellite","V. M. Sadykov; I. N. Kitiashvili; A. S. Dalda; V. Oria; A. G. Kosovichev; E. Illarionov","Physics & Astronomy Department, Georgia State University, Atlanta, GA, USA; NASA Supercomputing Division, NASA Ames Research Center, Moffett Field, CA, USA; Solar & Astrophysics Laboratory, Lockheed Martin, Palo Alto, CA, USA; Computer Science Department, New Jersey Institute of Technology, Newark, NJ, USA; Physics Department, New Jersey Institute of Technology, Newark, NJ, USA; Department of Mechanics and Mathematics, Moscow State University, Moscow, Russia","2021 International Conference on Content-Based Multimedia Indexing (CBMI)","24 Jun 2021","2021","","","1","6","In this study we extract the deep features and investigate the compression of the Mg II k spectral line profiles observed in quiet Sun regions by NASA's IRIS satellite. The data set of line profiles used for the analysis was obtained on April 20th, 2020, at the center of the solar disc, and contains almost 300,000 individual Mg II k line profiles after data cleaning. The data are separated into train and test subsets. The train subset was used to train the autoencoder of the varying embedding layer size. The early stopping criterion was implemented on the test subset to prevent the model from overfitting. Our results indicate that it is possible to compress the spectral line profiles more than 27 times (which corresponds to the reduction of the data dimensionality from 110 to 4) while having a 4 DN (Data Number) average reconstruction error, which is comparable to the variations in the line continuum. The mean squared error and the reconstruction error of even statistical moments sharply decrease when the dimensionality of the embedding layer increases from 1 to 4 and almost stop decreasing for higher numbers. The observed occasional improvements in training for values higher than 4 indicate that a better compact embedding may potentially be obtained if other training strategies and longer training times are used. The features learned for the critical four-dimensional case can be interpreted. In particular, three of these four features mainly control the line width, line asymmetry, and line dip formation respectively. The presented results are the first attempt to obtain a compact embedding for spectroscopic line profiles and confirm the value of this approach, in particular for feature extraction, data compression, and denoising.","1949-3991","978-1-6654-4220-6","10.1109/CBMI50038.2021.9461879","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9461879","Machine learning;Neural nets;Data compaction and compression;Feature extraction or construction","Training;Iris;Satellites;Instruments;NASA;Noise reduction;Neural networks","chromosphere;data compression;feature extraction;image reconstruction;learning (artificial intelligence);neural nets;regression analysis;solar corona;solar magnetism;solar radiation;solar spectra;spectral line breadth","Mg Ilk spectral line profiles;data cleaning;solar disc;data set;quiet Sun regions;NASA's IRIS satellite;solar spectroscopic observations;data compression;feature extraction;spectroscopic line profiles;four-dimensional case;longer training times;training strategies;compact embedding;embedding layer increases;Data Number;4 DN average reconstruction error;data dimensionality;early stopping criterion;varying embedding layer size;Mg","","","","11","IEEE","24 Jun 2021","","","IEEE","IEEE Conferences"
"A Virtual Data Collection Model of Distributed PVs considering Spatio-Temporal Coupling and Affine Optimization Reference","L. Ge; H. Liu; J. Yan; Y. Li; J. Zhang","Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Key Laboratory of Smart Grid of Ministry of Education, Tianjin University, Tianjin, China; Concordia Institute for Information Systems Engineering, Concordia University, Montréal, QC, Canada; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; School of Electrical and Engineering, Hebei University of Technology, Tianjin, China","IEEE Transactions on Power Systems","","2022","PP","99","1","12","The rapid development of distributed photovoltaic (DPV) made the shortage of data transmission channels and the difficulty of comprehensive coverage of measurement equipment becoming more significant. To enable a high-precision data collection of DPVs with fewer sensory devices and low computation costs, this paper proposes a virtual collection technology based on computational intelligence. To capture the spatial-temporal correlation of DPVs and find the optimal reference power station (RPS), a deep recurrent denoising autoencoder (D-RDAE)-based model is proposed in this paper. An affine artificial neural network (AANN) is constructed to tackle the uncertainty of solar radiation intensity and select RPSs. To address the high-dimensionality RPS selection, an improved honey badger algorithm (IHBA) with enhanced global search ability is proposed. The operation data of 33 DPVs in Nanjing, China, are used to train and verify the proposed method. The experimental results showed the effectiveness and superiority of the proposed method. Compared with DAE and RDAE, the deeply trained D-RDAE has the best capacity for finding the spatial-temporal correlation of DPVs. In addition, IHBA has the best global search ability compared with other 4 optimizers, and the AANN can better reduce the uncertainty of solar radiation intensity than robust and stochastic optimization techniques.","1558-0679","","10.1109/TPWRS.2022.3204176","National Key Research and Development Program of China(grant numbers:2018YFB1500800); State Key Laboratory of Power System and Generation Equipment(grant numbers:SKLD21KM10); Natural Sciences and Engineering Research Council of Canada (NSERC)(grant numbers:RGPIN-2018-06724); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9875994","PV;affine;RDAE;spatio-temporal coupling","Training;Solar radiation;Noise reduction;Sensors;Meteorology;Uncertainty;Real-time systems","","","","","","","IEEE","5 Sep 2022","","","IEEE","IEEE Early Access Articles"
"Language-Sensitive Music Emotion Recognition Models: are We Really There Yet?","J. S. Gómez-Cañón; E. Cano; A. G. Pandrea; P. Herrera; E. Gómez","Music Technology Group, Universitat Pompeu Fabra, Spain; Songquito UG, Erlangen, Germany; Music Technology Group, Universitat Pompeu Fabra, Spain; Music Technology Group, Universitat Pompeu Fabra, Spain; European Commission, Joint Research Centre, Seville, Spain","ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","13 May 2021","2021","","","576","580","Our previous research showed promising results when transferring features learned from speech to train emotion recognition models for music. In this context, we implemented a denoising autoencoder as a pretraining approach to extract features from speech in two languages (English and Mandarin). From that, we performed transfer and multi-task learning to predict classes from the arousal-valence space of music emotion. We tested and analyzed intra-linguistic and cross-linguistic settings, depending on the language of speech and lyrics of the music. This paper presents additional investigation on our approach, which reveals that: (1) performing pretraining with speech in a mixture of languages yields similar results than for specific languages - the pretraining phase appears not to exploit particular language features, (2) the music in Mandarin dataset consistently results in poor classification performance - we found low agreement in annotations, and (3) novel methodologies for representation learning (Contrastive Predictive Coding) may exploit features from both languages (i.e., pretraining on a mixture of languages) and improve classification of music emotions in both languages. From this study we conclude that more research is still needed to understand what is actually being transferred in these type of contexts.","2379-190X","978-1-7281-7605-5","10.1109/ICASSP39728.2021.9413721","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9413721","Contrastive predictive coding;speech emotion recognition;music emotion recognition;representation learning;transfer learning;multi-task learning","Emotion recognition;Speech coding;Annotations;Transfer learning;Noise reduction;Speech recognition;Predictive coding","emotion recognition;feature extraction;learning (artificial intelligence);music;natural language processing","language-sensitive music emotion recognition models;transferring features;pretraining approach;multitask learning;cross-linguistic settings;paper presents additional investigation;specific languages;pretraining phase;particular language features;poor classification performance;representation learning","","","","32","","13 May 2021","","","IEEE","IEEE Conferences"
"A Machine Learning-Based Tool for Exploring COVID-19 Scientific Literature","M. Allaoui; N. E. -H. S. B. Aissa; A. B. Belghith; M. L. Kherfi","Department of Computer Science. Kasdi Merbah University, Kasdi Merbah University, Ouargla, Algeria; Department of Computer Science. Kasdi Merbah University, Kasdi Merbah University, Ouargla, Algeria; Department of Computer Science. Kasdi Merbah University, Kasdi Merbah University, Ouargla, Algeria; LAMIA Laboratory. Université du Québec à Trois-Rivières, Université du Québec à Trois-Rivières, Trois-Rivières, Canada","2021 International Conference on Recent Advances in Mathematics and Informatics (ICRAMI)","3 Nov 2021","2021","","","1","7","The advent of the COVID-19 pandemic caused by the Sars-CoV2 virus has caused serious damage in different areas. This has prompted thousands of researchers from different disciplines (biology, medicine, artificial intelligence, economics, etc.) to publish a very large number of scientific articles in a very short period, to answer questions related to this pandemic. This abundance of literature, however, raised another problem. It has indeed become extremely difficult for a researcher or a decision-maker to stay up to date with the latest scientific advances or to locate scientific articles related to a specific aspect of this pandemic. In this paper, we present an intelligent tool based on Machine learning, which automatically organizes a large dataset of Covid-19 related scientific literature and visualizes them in a way that helps these people navigating easily through this dataset and locating the sought documents easily. The documents are first pre-processed and transformed into numerical features. Then, those features are passed through a deep denoising autoencoder followed by Uniform Manifold Approximation and Projection technique (UMAP) to reduce their dimensionality into a 2D space. The projected data are then clustered with Agglomerative Clustering Algorithm. This is followed by a topic modeling step which we performed using Latent Dirichlet Allocation (LDA), in order to assign a label to each cluster. Finally, the documents are visualized to the user in an interactive interface that we developed. The experiments we conducted proved that our tool is efficient and useful.","","978-1-6654-4171-1","10.1109/ICRAMI52622.2021.9585958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9585958","COVID-19;machine learning;deep learning;document organization;clustering;document visualization;topic modeling","COVID-19;Pandemics;Navigation;Machine learning;Organizations;Tools;Search engines","learning (artificial intelligence);natural language processing;pattern clustering","Machine learning-based tool;COVID-19 scientific literature;COVID-19 pandemic;Sars-CoV2 virus;artificial intelligence;scientific articles;latest scientific advances;intelligent tool;Covid-19 related scientific literature;sought documents","","","","34","","3 Nov 2021","","","IEEE","IEEE Conferences"
"Grammatical Error Correction: More Data with More Context","K. Parnow; Z. Li; H. Zhao","MoE Key Lab of Artificial Intelligence, AI Institude, Shanghai Jiao Tong University, China; MoE Key Lab of Artificial Intelligence, AI Institude, Shanghai Jiao Tong University, China; MoE Key Lab of Artificial Intelligence, AI Institude, Shanghai Jiao Tong University, China","2020 International Conference on Asian Language Processing (IALP)","7 Jan 2021","2020","","","24","29","Grammatical Error Correction (GEC) seriously suffers from a scarcity of data, both annotated and unannotated, as humans do not intentionally make grammatical errors. To account for this, we make use of the plentiful unlabeled plain text available and augment a dataset with artificial noise to increase our effective training data and pre-train our model as a denoising autoencoder (DAE), which offers an intuitive data augmentation solution for GEC. In a novel approach, we enhance our DAE, a Transformer Model, with a cross-document context mechanism and use a parallel encoder to encode the cross-document context before fusing the two contexts of the encoders in the decoder. Supplied by the combination of document similarity metrics and any unlabeled plain text, this serves as a new method of equipping a GEC model with supplemental context and allowing it to glean grammatical information from a separate plain text corpus. We evaluate our model on the CoNLL-2014 GEC Shared Task and achieve results that approach state-of-the-art for single models and show great potential with ever available and plentiful plain text.","","978-1-7281-7689-5","10.1109/IALP51396.2020.9310498","Research and Development; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9310498","grammatical error correction;transformer;data augmentation","Task analysis;Decoding;Context modeling;Training data;Training;Error correction;Data models","grammars;learning (artificial intelligence);natural language processing;neural nets;text analysis","single models;grammatical Error Correction;Grammatical Error Correction;grammatical errors;plentiful unlabeled plain text;effective training data;DAE;intuitive data augmentation solution;Transformer Model;cross-document context mechanism;parallel encoder;document similarity metrics;GEC model;supplemental context;grammatical information;separate plain text corpus;CoNLL-2014 GEC Shared Task","","","","31","","7 Jan 2021","","","IEEE","IEEE Conferences"
